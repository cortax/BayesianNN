{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "from Inference.GeNVI_predictive import GeNPredVI, GeNetEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Experiments.foong import Setup\n",
    "layerwidth=50\n",
    "nblayers=1\n",
    "setup=Setup(device,layerwidth=layerwidth,nblayers=nblayers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target density #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprior=setup.logPredPrior\n",
    "loglikelihood=setup.loglikelihood\n",
    "projection=setup.projection\n",
    "size_sample=setup.n_train_samples\n",
    "param_count=setup.param_count\n",
    "model=setup._model\n",
    "\n",
    "size_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Network #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation = nn.Tanh()#nn.ReLU()\n",
    "init_b = .001\n",
    "lat_dim=10\n",
    "\n",
    "\n",
    "GeN = GeNetEns(1, lat_dim, 50, param_count, activation, 0.2, init_b, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20000], Loss: 89085.109375, Entropy -136.28012084960938, Learning Rate: 0.01\n",
      "Epoch [1/20000], Loss: 49890.625, Entropy -161.16110229492188, Learning Rate: 0.01\n",
      "Epoch [2/20000], Loss: 44728.87890625, Entropy -158.67172241210938, Learning Rate: 0.01\n",
      "Epoch [3/20000], Loss: 54355.94140625, Entropy -159.9581756591797, Learning Rate: 0.01\n",
      "Epoch [4/20000], Loss: 41568.1171875, Entropy -161.0608673095703, Learning Rate: 0.01\n",
      "Epoch [5/20000], Loss: 42649.35546875, Entropy -160.11581420898438, Learning Rate: 0.01\n",
      "Epoch [6/20000], Loss: 29307.619140625, Entropy -177.43450927734375, Learning Rate: 0.01\n",
      "Epoch [7/20000], Loss: 28979.43359375, Entropy -177.1561279296875, Learning Rate: 0.01\n",
      "Epoch [8/20000], Loss: 28084.8046875, Entropy -174.587890625, Learning Rate: 0.01\n",
      "Epoch [9/20000], Loss: 32022.875, Entropy -176.0665283203125, Learning Rate: 0.01\n",
      "Epoch [10/20000], Loss: 30892.572265625, Entropy -190.51048278808594, Learning Rate: 0.01\n",
      "Epoch [11/20000], Loss: 22867.255859375, Entropy -182.73516845703125, Learning Rate: 0.01\n",
      "Epoch [12/20000], Loss: 27262.7109375, Entropy -199.9970703125, Learning Rate: 0.01\n",
      "Epoch [13/20000], Loss: 24707.046875, Entropy -190.99603271484375, Learning Rate: 0.01\n",
      "Epoch [14/20000], Loss: 17257.044921875, Entropy -208.2679443359375, Learning Rate: 0.01\n",
      "Epoch [15/20000], Loss: 18165.134765625, Entropy -203.22122192382812, Learning Rate: 0.01\n",
      "Epoch [16/20000], Loss: 18410.369140625, Entropy -204.60165405273438, Learning Rate: 0.01\n",
      "Epoch [17/20000], Loss: 15758.822265625, Entropy -207.8033447265625, Learning Rate: 0.01\n",
      "Epoch [18/20000], Loss: 13902.2255859375, Entropy -213.86424255371094, Learning Rate: 0.01\n",
      "Epoch [19/20000], Loss: 13274.5947265625, Entropy -216.81942749023438, Learning Rate: 0.01\n",
      "Epoch [20/20000], Loss: 13832.98828125, Entropy -216.96221923828125, Learning Rate: 0.01\n",
      "Epoch [21/20000], Loss: 13043.177734375, Entropy -205.9042205810547, Learning Rate: 0.01\n",
      "Epoch [22/20000], Loss: 10348.826171875, Entropy -218.40428161621094, Learning Rate: 0.01\n",
      "Epoch [23/20000], Loss: 12676.8212890625, Entropy -219.82553100585938, Learning Rate: 0.01\n",
      "Epoch [24/20000], Loss: 9666.3388671875, Entropy -217.56227111816406, Learning Rate: 0.01\n",
      "Epoch [25/20000], Loss: 10307.5703125, Entropy -226.59735107421875, Learning Rate: 0.01\n",
      "Epoch [26/20000], Loss: 11299.3125, Entropy -239.43946838378906, Learning Rate: 0.01\n",
      "Epoch [27/20000], Loss: 11216.046875, Entropy -240.0842742919922, Learning Rate: 0.01\n",
      "Epoch [28/20000], Loss: 7749.15576171875, Entropy -224.86553955078125, Learning Rate: 0.01\n",
      "Epoch [29/20000], Loss: 7877.26123046875, Entropy -231.39132690429688, Learning Rate: 0.01\n",
      "Epoch [30/20000], Loss: 7827.8681640625, Entropy -238.4767608642578, Learning Rate: 0.01\n",
      "Epoch [31/20000], Loss: 8130.4052734375, Entropy -240.87474060058594, Learning Rate: 0.01\n",
      "Epoch [32/20000], Loss: 4935.2578125, Entropy -251.1917724609375, Learning Rate: 0.01\n",
      "Epoch [33/20000], Loss: 7748.4189453125, Entropy -242.15170288085938, Learning Rate: 0.01\n",
      "Epoch [34/20000], Loss: 5692.0830078125, Entropy -246.49610900878906, Learning Rate: 0.01\n",
      "Epoch [35/20000], Loss: 6120.26171875, Entropy -247.58448791503906, Learning Rate: 0.01\n",
      "Epoch [36/20000], Loss: 5798.91162109375, Entropy -254.43592834472656, Learning Rate: 0.01\n",
      "Epoch [37/20000], Loss: 7319.259765625, Entropy -250.99563598632812, Learning Rate: 0.01\n",
      "Epoch [38/20000], Loss: 5065.67431640625, Entropy -253.1805419921875, Learning Rate: 0.01\n",
      "Epoch [39/20000], Loss: 4949.845703125, Entropy -256.10052490234375, Learning Rate: 0.01\n",
      "Epoch [40/20000], Loss: 3735.0185546875, Entropy -271.8462219238281, Learning Rate: 0.01\n",
      "Epoch [41/20000], Loss: 3847.000244140625, Entropy -260.3005065917969, Learning Rate: 0.01\n",
      "Epoch [42/20000], Loss: 3493.26025390625, Entropy -271.75799560546875, Learning Rate: 0.01\n",
      "Epoch [43/20000], Loss: 3640.146728515625, Entropy -272.92608642578125, Learning Rate: 0.01\n",
      "Epoch [44/20000], Loss: 3845.5625, Entropy -277.09674072265625, Learning Rate: 0.01\n",
      "Epoch [45/20000], Loss: 3418.611328125, Entropy -275.4016418457031, Learning Rate: 0.01\n",
      "Epoch [46/20000], Loss: 3122.6171875, Entropy -269.0386047363281, Learning Rate: 0.01\n",
      "Epoch [47/20000], Loss: 3486.6162109375, Entropy -272.05914306640625, Learning Rate: 0.01\n",
      "Epoch [48/20000], Loss: 3736.73486328125, Entropy -274.98919677734375, Learning Rate: 0.01\n",
      "Epoch [49/20000], Loss: 3552.41552734375, Entropy -279.725341796875, Learning Rate: 0.01\n",
      "Epoch [50/20000], Loss: 2697.699951171875, Entropy -282.0278015136719, Learning Rate: 0.01\n",
      "Epoch [51/20000], Loss: 2802.236572265625, Entropy -284.1983642578125, Learning Rate: 0.01\n",
      "Epoch [52/20000], Loss: 3107.97314453125, Entropy -273.1357116699219, Learning Rate: 0.01\n",
      "Epoch [53/20000], Loss: 3856.7314453125, Entropy -280.18768310546875, Learning Rate: 0.01\n",
      "Epoch [54/20000], Loss: 2988.444580078125, Entropy -279.20684814453125, Learning Rate: 0.01\n",
      "Epoch [55/20000], Loss: 3032.70751953125, Entropy -267.6570739746094, Learning Rate: 0.01\n",
      "Epoch [56/20000], Loss: 2981.649169921875, Entropy -293.12554931640625, Learning Rate: 0.01\n",
      "Epoch [57/20000], Loss: 2764.175048828125, Entropy -294.0226135253906, Learning Rate: 0.01\n",
      "Epoch [58/20000], Loss: 2937.734375, Entropy -295.8783264160156, Learning Rate: 0.01\n",
      "Epoch [59/20000], Loss: 2760.87451171875, Entropy -288.48419189453125, Learning Rate: 0.01\n",
      "Epoch [60/20000], Loss: 2885.65771484375, Entropy -297.79827880859375, Learning Rate: 0.01\n",
      "Epoch [61/20000], Loss: 2436.8212890625, Entropy -294.4333190917969, Learning Rate: 0.01\n",
      "Epoch [62/20000], Loss: 2887.90478515625, Entropy -303.8977966308594, Learning Rate: 0.01\n",
      "Epoch [63/20000], Loss: 2410.066162109375, Entropy -308.8504333496094, Learning Rate: 0.01\n",
      "Epoch [64/20000], Loss: 2315.463623046875, Entropy -296.52960205078125, Learning Rate: 0.01\n",
      "Epoch [65/20000], Loss: 2531.14306640625, Entropy -309.0476379394531, Learning Rate: 0.01\n",
      "Epoch [66/20000], Loss: 2342.184326171875, Entropy -307.5083923339844, Learning Rate: 0.01\n",
      "Epoch [67/20000], Loss: 2388.4912109375, Entropy -309.0567626953125, Learning Rate: 0.01\n",
      "Epoch [68/20000], Loss: 2250.291259765625, Entropy -309.2253112792969, Learning Rate: 0.01\n",
      "Epoch [69/20000], Loss: 2208.283203125, Entropy -310.3038024902344, Learning Rate: 0.01\n",
      "Epoch [70/20000], Loss: 2184.050537109375, Entropy -303.68389892578125, Learning Rate: 0.01\n",
      "Epoch [71/20000], Loss: 2561.61767578125, Entropy -315.1771240234375, Learning Rate: 0.01\n",
      "Epoch [72/20000], Loss: 2195.55078125, Entropy -309.31500244140625, Learning Rate: 0.01\n",
      "Epoch [73/20000], Loss: 2088.47998046875, Entropy -309.5921936035156, Learning Rate: 0.01\n",
      "Epoch [74/20000], Loss: 2368.663330078125, Entropy -316.74017333984375, Learning Rate: 0.01\n",
      "Epoch [75/20000], Loss: 2313.3818359375, Entropy -307.5862121582031, Learning Rate: 0.01\n",
      "Epoch [76/20000], Loss: 2174.73095703125, Entropy -305.85028076171875, Learning Rate: 0.01\n",
      "Epoch [77/20000], Loss: 2150.12060546875, Entropy -309.4823303222656, Learning Rate: 0.01\n",
      "Epoch [78/20000], Loss: 2187.274169921875, Entropy -313.48590087890625, Learning Rate: 0.01\n",
      "Epoch [79/20000], Loss: 2366.52294921875, Entropy -320.68450927734375, Learning Rate: 0.01\n",
      "Epoch [80/20000], Loss: 2394.75927734375, Entropy -312.9848937988281, Learning Rate: 0.01\n",
      "Epoch [81/20000], Loss: 2266.15185546875, Entropy -315.0118408203125, Learning Rate: 0.01\n",
      "Epoch [82/20000], Loss: 2042.8028564453125, Entropy -316.2297058105469, Learning Rate: 0.01\n",
      "Epoch [83/20000], Loss: 2361.38134765625, Entropy -309.0172424316406, Learning Rate: 0.01\n",
      "Epoch [84/20000], Loss: 2074.29443359375, Entropy -310.50372314453125, Learning Rate: 0.01\n",
      "Epoch [85/20000], Loss: 2188.254638671875, Entropy -314.0653991699219, Learning Rate: 0.01\n",
      "Epoch [86/20000], Loss: 2119.581787109375, Entropy -317.6689453125, Learning Rate: 0.01\n",
      "Epoch [87/20000], Loss: 2315.290771484375, Entropy -311.2543640136719, Learning Rate: 0.01\n",
      "Epoch [88/20000], Loss: 1862.0240478515625, Entropy -316.9019470214844, Learning Rate: 0.01\n",
      "Epoch [89/20000], Loss: 2178.353271484375, Entropy -322.54742431640625, Learning Rate: 0.01\n",
      "Epoch [90/20000], Loss: 2146.350341796875, Entropy -312.0964050292969, Learning Rate: 0.01\n",
      "Epoch [91/20000], Loss: 2091.406982421875, Entropy -330.58282470703125, Learning Rate: 0.01\n",
      "Epoch [92/20000], Loss: 1934.093994140625, Entropy -317.3031005859375, Learning Rate: 0.01\n",
      "Epoch [93/20000], Loss: 1942.1949462890625, Entropy -316.4220275878906, Learning Rate: 0.01\n",
      "Epoch [94/20000], Loss: 1953.7823486328125, Entropy -337.0995788574219, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/20000], Loss: 1798.3905029296875, Entropy -319.3904724121094, Learning Rate: 0.01\n",
      "Epoch [96/20000], Loss: 1912.939697265625, Entropy -328.7568664550781, Learning Rate: 0.01\n",
      "Epoch [97/20000], Loss: 1978.002685546875, Entropy -318.2452392578125, Learning Rate: 0.01\n",
      "Epoch [98/20000], Loss: 1794.4052734375, Entropy -337.9788818359375, Learning Rate: 0.01\n",
      "Epoch [99/20000], Loss: 1995.725830078125, Entropy -328.2762451171875, Learning Rate: 0.01\n",
      "Epoch [100/20000], Loss: 2025.750244140625, Entropy -337.30291748046875, Learning Rate: 0.01\n",
      "Epoch [101/20000], Loss: 1919.2333984375, Entropy -325.9880676269531, Learning Rate: 0.01\n",
      "Epoch [102/20000], Loss: 1985.9600830078125, Entropy -319.90447998046875, Learning Rate: 0.01\n",
      "Epoch [103/20000], Loss: 2071.483642578125, Entropy -314.2118225097656, Learning Rate: 0.01\n",
      "Epoch [104/20000], Loss: 1696.9681396484375, Entropy -340.02716064453125, Learning Rate: 0.01\n",
      "Epoch [105/20000], Loss: 1999.2279052734375, Entropy -327.78363037109375, Learning Rate: 0.01\n",
      "Epoch [106/20000], Loss: 2248.720458984375, Entropy -328.5998840332031, Learning Rate: 0.01\n",
      "Epoch [107/20000], Loss: 2079.2783203125, Entropy -314.0188293457031, Learning Rate: 0.01\n",
      "Epoch [108/20000], Loss: 1826.356689453125, Entropy -320.303955078125, Learning Rate: 0.01\n",
      "Epoch [109/20000], Loss: 1859.3695068359375, Entropy -324.66192626953125, Learning Rate: 0.01\n",
      "Epoch [110/20000], Loss: 2022.214599609375, Entropy -324.6711120605469, Learning Rate: 0.01\n",
      "Epoch [111/20000], Loss: 1983.9130859375, Entropy -328.7852478027344, Learning Rate: 0.01\n",
      "Epoch [112/20000], Loss: 1865.701171875, Entropy -337.97076416015625, Learning Rate: 0.01\n",
      "Epoch [113/20000], Loss: 1778.8291015625, Entropy -320.4323425292969, Learning Rate: 0.01\n",
      "Epoch [114/20000], Loss: 1928.562744140625, Entropy -319.630126953125, Learning Rate: 0.01\n",
      "Epoch [115/20000], Loss: 1766.591064453125, Entropy -332.7547912597656, Learning Rate: 0.01\n",
      "Epoch [116/20000], Loss: 1990.183837890625, Entropy -313.9794921875, Learning Rate: 0.01\n",
      "Epoch [117/20000], Loss: 1702.659423828125, Entropy -330.29107666015625, Learning Rate: 0.01\n",
      "Epoch [118/20000], Loss: 1719.4998779296875, Entropy -330.6091003417969, Learning Rate: 0.01\n",
      "Epoch [119/20000], Loss: 1788.318359375, Entropy -322.40478515625, Learning Rate: 0.01\n",
      "Epoch [120/20000], Loss: 1816.7335205078125, Entropy -332.439208984375, Learning Rate: 0.01\n",
      "Epoch [121/20000], Loss: 1861.809326171875, Entropy -336.3512268066406, Learning Rate: 0.01\n",
      "Epoch [122/20000], Loss: 1893.2052001953125, Entropy -333.08697509765625, Learning Rate: 0.01\n",
      "Epoch [123/20000], Loss: 1716.800048828125, Entropy -323.656005859375, Learning Rate: 0.01\n",
      "Epoch [124/20000], Loss: 1721.8995361328125, Entropy -330.5989685058594, Learning Rate: 0.01\n",
      "Epoch [125/20000], Loss: 1676.597900390625, Entropy -323.81427001953125, Learning Rate: 0.01\n",
      "Epoch [126/20000], Loss: 1976.6719970703125, Entropy -331.2441711425781, Learning Rate: 0.01\n",
      "Epoch [127/20000], Loss: 1865.768310546875, Entropy -320.5516052246094, Learning Rate: 0.01\n",
      "Epoch [128/20000], Loss: 1768.3642578125, Entropy -322.1962890625, Learning Rate: 0.01\n",
      "Epoch [129/20000], Loss: 1801.0015869140625, Entropy -339.4674072265625, Learning Rate: 0.01\n",
      "Epoch [130/20000], Loss: 1946.6597900390625, Entropy -324.718017578125, Learning Rate: 0.01\n",
      "Epoch [131/20000], Loss: 1821.775390625, Entropy -314.9585266113281, Learning Rate: 0.01\n",
      "Epoch [132/20000], Loss: 1965.2548828125, Entropy -333.8177185058594, Learning Rate: 0.01\n",
      "Epoch [133/20000], Loss: 2001.1641845703125, Entropy -332.87701416015625, Learning Rate: 0.01\n",
      "Epoch [134/20000], Loss: 1782.2166748046875, Entropy -344.0426025390625, Learning Rate: 0.01\n",
      "Epoch [135/20000], Loss: 1862.7174072265625, Entropy -330.19342041015625, Learning Rate: 0.01\n",
      "Epoch [136/20000], Loss: 1810.1221923828125, Entropy -335.9626159667969, Learning Rate: 0.01\n",
      "Epoch [137/20000], Loss: 1895.30029296875, Entropy -330.70526123046875, Learning Rate: 0.01\n",
      "Epoch [138/20000], Loss: 1744.131591796875, Entropy -325.6908874511719, Learning Rate: 0.01\n",
      "Epoch [139/20000], Loss: 1844.6910400390625, Entropy -336.7582702636719, Learning Rate: 0.01\n",
      "Epoch [140/20000], Loss: 1804.2998046875, Entropy -324.9040832519531, Learning Rate: 0.01\n",
      "Epoch [141/20000], Loss: 1856.751953125, Entropy -306.7538757324219, Learning Rate: 0.01\n",
      "Epoch [142/20000], Loss: 1871.054931640625, Entropy -325.9379577636719, Learning Rate: 0.01\n",
      "Epoch [143/20000], Loss: 1754.1680908203125, Entropy -317.275390625, Learning Rate: 0.01\n",
      "Epoch [144/20000], Loss: 1767.55126953125, Entropy -322.65570068359375, Learning Rate: 0.01\n",
      "Epoch [145/20000], Loss: 1747.0941162109375, Entropy -328.00982666015625, Learning Rate: 0.01\n",
      "Epoch [146/20000], Loss: 1682.1181640625, Entropy -331.0832824707031, Learning Rate: 0.01\n",
      "Epoch [147/20000], Loss: 1852.10205078125, Entropy -323.5081787109375, Learning Rate: 0.01\n",
      "Epoch [148/20000], Loss: 1693.98388671875, Entropy -325.1667785644531, Learning Rate: 0.01\n",
      "Epoch [149/20000], Loss: 1836.425537109375, Entropy -330.8644714355469, Learning Rate: 0.01\n",
      "Epoch [150/20000], Loss: 1543.7637939453125, Entropy -327.4889831542969, Learning Rate: 0.01\n",
      "Epoch [151/20000], Loss: 1855.8868408203125, Entropy -331.8695983886719, Learning Rate: 0.01\n",
      "Epoch [152/20000], Loss: 1952.51708984375, Entropy -330.8914794921875, Learning Rate: 0.01\n",
      "Epoch [153/20000], Loss: 1698.547607421875, Entropy -324.2832336425781, Learning Rate: 0.01\n",
      "Epoch [154/20000], Loss: 2004.982177734375, Entropy -328.9599304199219, Learning Rate: 0.01\n",
      "Epoch [155/20000], Loss: 1595.421630859375, Entropy -317.984130859375, Learning Rate: 0.01\n",
      "Epoch [156/20000], Loss: 1804.3291015625, Entropy -334.4671325683594, Learning Rate: 0.01\n",
      "Epoch [157/20000], Loss: 1668.530517578125, Entropy -341.052001953125, Learning Rate: 0.01\n",
      "Epoch [158/20000], Loss: 1747.9481201171875, Entropy -324.6026611328125, Learning Rate: 0.01\n",
      "Epoch [159/20000], Loss: 1674.91552734375, Entropy -330.4937744140625, Learning Rate: 0.01\n",
      "Epoch [160/20000], Loss: 1760.8787841796875, Entropy -324.78704833984375, Learning Rate: 0.01\n",
      "Epoch [161/20000], Loss: 1674.572021484375, Entropy -343.200927734375, Learning Rate: 0.01\n",
      "Epoch [162/20000], Loss: 1832.8292236328125, Entropy -345.60540771484375, Learning Rate: 0.01\n",
      "Epoch [163/20000], Loss: 1861.694580078125, Entropy -329.0792236328125, Learning Rate: 0.01\n",
      "Epoch [164/20000], Loss: 1794.074462890625, Entropy -328.280517578125, Learning Rate: 0.01\n",
      "Epoch [165/20000], Loss: 1752.0894775390625, Entropy -342.2784729003906, Learning Rate: 0.01\n",
      "Epoch [166/20000], Loss: 1594.6766357421875, Entropy -324.7525329589844, Learning Rate: 0.01\n",
      "Epoch [167/20000], Loss: 1595.9217529296875, Entropy -328.6580810546875, Learning Rate: 0.01\n",
      "Epoch [168/20000], Loss: 1657.265625, Entropy -320.22186279296875, Learning Rate: 0.01\n",
      "Epoch [169/20000], Loss: 1694.5029296875, Entropy -333.6592102050781, Learning Rate: 0.01\n",
      "Epoch [170/20000], Loss: 1738.112060546875, Entropy -320.9020690917969, Learning Rate: 0.01\n",
      "Epoch [171/20000], Loss: 1587.5247802734375, Entropy -321.0892028808594, Learning Rate: 0.01\n",
      "Epoch [172/20000], Loss: 1680.0244140625, Entropy -326.18975830078125, Learning Rate: 0.01\n",
      "Epoch [173/20000], Loss: 1661.94580078125, Entropy -334.54034423828125, Learning Rate: 0.01\n",
      "Epoch [174/20000], Loss: 1678.9886474609375, Entropy -328.01556396484375, Learning Rate: 0.01\n",
      "Epoch [175/20000], Loss: 1718.620849609375, Entropy -339.7710266113281, Learning Rate: 0.01\n",
      "Epoch [176/20000], Loss: 1570.4476318359375, Entropy -333.79962158203125, Learning Rate: 0.01\n",
      "Epoch [177/20000], Loss: 1604.52685546875, Entropy -325.6445007324219, Learning Rate: 0.01\n",
      "Epoch [178/20000], Loss: 1644.518798828125, Entropy -331.44976806640625, Learning Rate: 0.01\n",
      "Epoch [179/20000], Loss: 1702.349365234375, Entropy -323.3926086425781, Learning Rate: 0.01\n",
      "Epoch [180/20000], Loss: 1826.571044921875, Entropy -324.0740051269531, Learning Rate: 0.01\n",
      "Epoch [181/20000], Loss: 1603.114501953125, Entropy -318.1201477050781, Learning Rate: 0.01\n",
      "Epoch [182/20000], Loss: 1654.521240234375, Entropy -333.39166259765625, Learning Rate: 0.01\n",
      "Epoch [183/20000], Loss: 1673.6446533203125, Entropy -338.2473449707031, Learning Rate: 0.01\n",
      "Epoch [184/20000], Loss: 1625.2259521484375, Entropy -316.8776550292969, Learning Rate: 0.01\n",
      "Epoch [185/20000], Loss: 1566.26953125, Entropy -330.8529357910156, Learning Rate: 0.01\n",
      "Epoch [186/20000], Loss: 1677.669189453125, Entropy -329.0274353027344, Learning Rate: 0.01\n",
      "Epoch [187/20000], Loss: 1643.335693359375, Entropy -338.60955810546875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/20000], Loss: 1680.5211181640625, Entropy -317.638671875, Learning Rate: 0.01\n",
      "Epoch [189/20000], Loss: 1629.5357666015625, Entropy -335.58758544921875, Learning Rate: 0.01\n",
      "Epoch [190/20000], Loss: 1494.0672607421875, Entropy -326.2001647949219, Learning Rate: 0.01\n",
      "Epoch [191/20000], Loss: 1599.5201416015625, Entropy -328.001708984375, Learning Rate: 0.01\n",
      "Epoch [192/20000], Loss: 1585.463623046875, Entropy -325.571533203125, Learning Rate: 0.01\n",
      "Epoch [193/20000], Loss: 1641.484375, Entropy -333.9484558105469, Learning Rate: 0.01\n",
      "Epoch [194/20000], Loss: 1644.2777099609375, Entropy -326.2671813964844, Learning Rate: 0.01\n",
      "Epoch [195/20000], Loss: 1737.3441162109375, Entropy -325.3345031738281, Learning Rate: 0.01\n",
      "Epoch [196/20000], Loss: 1626.23046875, Entropy -329.121337890625, Learning Rate: 0.01\n",
      "Epoch [197/20000], Loss: 1456.265625, Entropy -328.5011901855469, Learning Rate: 0.01\n",
      "Epoch [198/20000], Loss: 1579.00146484375, Entropy -323.97784423828125, Learning Rate: 0.01\n",
      "Epoch [199/20000], Loss: 1530.9180908203125, Entropy -320.8714294433594, Learning Rate: 0.01\n",
      "Epoch [200/20000], Loss: 1584.014892578125, Entropy -327.3383483886719, Learning Rate: 0.01\n",
      "Epoch [201/20000], Loss: 1574.5133056640625, Entropy -333.3302307128906, Learning Rate: 0.01\n",
      "Epoch [202/20000], Loss: 1619.067626953125, Entropy -323.5378723144531, Learning Rate: 0.01\n",
      "Epoch [203/20000], Loss: 1619.814208984375, Entropy -319.55419921875, Learning Rate: 0.01\n",
      "Epoch [204/20000], Loss: 1686.074951171875, Entropy -327.3092041015625, Learning Rate: 0.01\n",
      "Epoch [205/20000], Loss: 1493.294677734375, Entropy -324.43975830078125, Learning Rate: 0.01\n",
      "Epoch [206/20000], Loss: 1533.2275390625, Entropy -326.7994384765625, Learning Rate: 0.01\n",
      "Epoch [207/20000], Loss: 1505.6064453125, Entropy -338.05731201171875, Learning Rate: 0.01\n",
      "Epoch [208/20000], Loss: 1465.771484375, Entropy -318.39056396484375, Learning Rate: 0.01\n",
      "Epoch [209/20000], Loss: 1550.69775390625, Entropy -329.07965087890625, Learning Rate: 0.01\n",
      "Epoch [210/20000], Loss: 1476.910888671875, Entropy -323.43035888671875, Learning Rate: 0.01\n",
      "Epoch [211/20000], Loss: 1484.459228515625, Entropy -317.9260559082031, Learning Rate: 0.01\n",
      "Epoch [212/20000], Loss: 1437.84033203125, Entropy -330.2430419921875, Learning Rate: 0.01\n",
      "Epoch [213/20000], Loss: 1578.758544921875, Entropy -328.25860595703125, Learning Rate: 0.01\n",
      "Epoch [214/20000], Loss: 1566.665771484375, Entropy -342.40826416015625, Learning Rate: 0.01\n",
      "Epoch [215/20000], Loss: 1516.824462890625, Entropy -324.0392150878906, Learning Rate: 0.01\n",
      "Epoch [216/20000], Loss: 1593.0013427734375, Entropy -334.9621887207031, Learning Rate: 0.01\n",
      "Epoch [217/20000], Loss: 1491.719482421875, Entropy -328.40692138671875, Learning Rate: 0.01\n",
      "Epoch [218/20000], Loss: 1509.57470703125, Entropy -327.6104431152344, Learning Rate: 0.01\n",
      "Epoch [219/20000], Loss: 1515.84716796875, Entropy -321.63128662109375, Learning Rate: 0.01\n",
      "Epoch [220/20000], Loss: 1519.492919921875, Entropy -330.8621520996094, Learning Rate: 0.01\n",
      "Epoch [221/20000], Loss: 1597.774169921875, Entropy -331.3055114746094, Learning Rate: 0.01\n",
      "Epoch [222/20000], Loss: 1408.8291015625, Entropy -319.25726318359375, Learning Rate: 0.01\n",
      "Epoch [223/20000], Loss: 1448.55029296875, Entropy -323.7294921875, Learning Rate: 0.01\n",
      "Epoch [224/20000], Loss: 1574.77783203125, Entropy -323.3381042480469, Learning Rate: 0.01\n",
      "Epoch [225/20000], Loss: 1599.24853515625, Entropy -333.7604064941406, Learning Rate: 0.01\n",
      "Epoch [226/20000], Loss: 1561.796630859375, Entropy -321.5888671875, Learning Rate: 0.01\n",
      "Epoch [227/20000], Loss: 1509.8839111328125, Entropy -320.9209289550781, Learning Rate: 0.01\n",
      "Epoch [228/20000], Loss: 1538.41552734375, Entropy -330.9158630371094, Learning Rate: 0.01\n",
      "Epoch [229/20000], Loss: 1423.289306640625, Entropy -323.6293640136719, Learning Rate: 0.01\n",
      "Epoch [230/20000], Loss: 1416.07421875, Entropy -321.97601318359375, Learning Rate: 0.01\n",
      "Epoch [231/20000], Loss: 1675.423828125, Entropy -329.7745361328125, Learning Rate: 0.01\n",
      "Epoch [232/20000], Loss: 1436.7100830078125, Entropy -315.85040283203125, Learning Rate: 0.01\n",
      "Epoch [233/20000], Loss: 1403.626220703125, Entropy -327.6056213378906, Learning Rate: 0.01\n",
      "Epoch [234/20000], Loss: 1445.079345703125, Entropy -325.7455139160156, Learning Rate: 0.01\n",
      "Epoch [235/20000], Loss: 1363.1551513671875, Entropy -328.1284484863281, Learning Rate: 0.01\n",
      "Epoch [236/20000], Loss: 1560.0142822265625, Entropy -321.4037780761719, Learning Rate: 0.01\n",
      "Epoch [237/20000], Loss: 1523.438720703125, Entropy -315.7377624511719, Learning Rate: 0.01\n",
      "Epoch [238/20000], Loss: 1398.16943359375, Entropy -337.855712890625, Learning Rate: 0.01\n",
      "Epoch [239/20000], Loss: 1362.458251953125, Entropy -320.618896484375, Learning Rate: 0.01\n",
      "Epoch [240/20000], Loss: 1461.7215576171875, Entropy -320.2875671386719, Learning Rate: 0.01\n",
      "Epoch [241/20000], Loss: 1370.421630859375, Entropy -315.87054443359375, Learning Rate: 0.01\n",
      "Epoch [242/20000], Loss: 1469.52099609375, Entropy -330.32281494140625, Learning Rate: 0.01\n",
      "Epoch [243/20000], Loss: 1503.87744140625, Entropy -326.21221923828125, Learning Rate: 0.01\n",
      "Epoch [244/20000], Loss: 1410.298583984375, Entropy -320.4354553222656, Learning Rate: 0.01\n",
      "Epoch [245/20000], Loss: 1452.429443359375, Entropy -319.047607421875, Learning Rate: 0.01\n",
      "Epoch [246/20000], Loss: 1432.8155517578125, Entropy -330.0616455078125, Learning Rate: 0.01\n",
      "Epoch [247/20000], Loss: 1457.2235107421875, Entropy -323.4964599609375, Learning Rate: 0.01\n",
      "Epoch [248/20000], Loss: 1508.446533203125, Entropy -335.5694580078125, Learning Rate: 0.01\n",
      "Epoch [249/20000], Loss: 1379.9674072265625, Entropy -325.37200927734375, Learning Rate: 0.01\n",
      "Epoch [250/20000], Loss: 1356.001953125, Entropy -325.6607360839844, Learning Rate: 0.01\n",
      "Epoch [251/20000], Loss: 1506.5345458984375, Entropy -322.09033203125, Learning Rate: 0.01\n",
      "Epoch [252/20000], Loss: 1345.023681640625, Entropy -331.2267761230469, Learning Rate: 0.01\n",
      "Epoch [253/20000], Loss: 1502.5477294921875, Entropy -324.47613525390625, Learning Rate: 0.01\n",
      "Epoch [254/20000], Loss: 1447.19873046875, Entropy -329.0101013183594, Learning Rate: 0.01\n",
      "Epoch [255/20000], Loss: 1542.3853759765625, Entropy -317.8644714355469, Learning Rate: 0.01\n",
      "Epoch [256/20000], Loss: 1426.225341796875, Entropy -315.2684326171875, Learning Rate: 0.01\n",
      "Epoch [257/20000], Loss: 1444.06591796875, Entropy -328.8772277832031, Learning Rate: 0.01\n",
      "Epoch [258/20000], Loss: 1546.8582763671875, Entropy -320.672607421875, Learning Rate: 0.01\n",
      "Epoch [259/20000], Loss: 1411.29248046875, Entropy -317.6838684082031, Learning Rate: 0.01\n",
      "Epoch [260/20000], Loss: 1279.4241943359375, Entropy -333.5111083984375, Learning Rate: 0.01\n",
      "Epoch [261/20000], Loss: 1267.70703125, Entropy -328.377197265625, Learning Rate: 0.01\n",
      "Epoch [262/20000], Loss: 1398.5809326171875, Entropy -322.802978515625, Learning Rate: 0.01\n",
      "Epoch [263/20000], Loss: 1319.46630859375, Entropy -320.21875, Learning Rate: 0.01\n",
      "Epoch [264/20000], Loss: 1389.365966796875, Entropy -336.56048583984375, Learning Rate: 0.01\n",
      "Epoch [265/20000], Loss: 1406.3388671875, Entropy -317.48785400390625, Learning Rate: 0.01\n",
      "Epoch [266/20000], Loss: 1343.128662109375, Entropy -326.92633056640625, Learning Rate: 0.01\n",
      "Epoch [267/20000], Loss: 1390.571044921875, Entropy -329.4771423339844, Learning Rate: 0.01\n",
      "Epoch [268/20000], Loss: 1386.7015380859375, Entropy -334.8966369628906, Learning Rate: 0.01\n",
      "Epoch [269/20000], Loss: 1349.1419677734375, Entropy -318.6666564941406, Learning Rate: 0.01\n",
      "Epoch [270/20000], Loss: 1299.9376220703125, Entropy -322.22650146484375, Learning Rate: 0.01\n",
      "Epoch [271/20000], Loss: 1401.53369140625, Entropy -328.82550048828125, Learning Rate: 0.01\n",
      "Epoch [272/20000], Loss: 1443.7418212890625, Entropy -328.4090270996094, Learning Rate: 0.01\n",
      "Epoch [273/20000], Loss: 1439.6026611328125, Entropy -329.3499450683594, Learning Rate: 0.01\n",
      "Epoch [274/20000], Loss: 1201.8804931640625, Entropy -322.7218933105469, Learning Rate: 0.01\n",
      "Epoch [275/20000], Loss: 1281.281982421875, Entropy -323.9335021972656, Learning Rate: 0.01\n",
      "Epoch [276/20000], Loss: 1288.9088134765625, Entropy -319.07501220703125, Learning Rate: 0.01\n",
      "Epoch [277/20000], Loss: 1225.2265625, Entropy -323.0640869140625, Learning Rate: 0.01\n",
      "Epoch [278/20000], Loss: 1289.65869140625, Entropy -324.211669921875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [279/20000], Loss: 1267.088134765625, Entropy -323.55999755859375, Learning Rate: 0.01\n",
      "Epoch [280/20000], Loss: 1458.201904296875, Entropy -316.1460876464844, Learning Rate: 0.01\n",
      "Epoch [281/20000], Loss: 1343.509521484375, Entropy -306.0685119628906, Learning Rate: 0.01\n",
      "Epoch [282/20000], Loss: 1240.931396484375, Entropy -315.3670349121094, Learning Rate: 0.01\n",
      "Epoch [283/20000], Loss: 1343.1796875, Entropy -321.6116943359375, Learning Rate: 0.01\n",
      "Epoch [284/20000], Loss: 1329.9061279296875, Entropy -317.4237365722656, Learning Rate: 0.01\n",
      "Epoch [285/20000], Loss: 1334.140380859375, Entropy -326.87158203125, Learning Rate: 0.01\n",
      "Epoch [286/20000], Loss: 1245.87646484375, Entropy -325.5681457519531, Learning Rate: 0.01\n",
      "Epoch [287/20000], Loss: 1285.4041748046875, Entropy -321.25836181640625, Learning Rate: 0.01\n",
      "Epoch [288/20000], Loss: 1305.937744140625, Entropy -323.1769714355469, Learning Rate: 0.01\n",
      "Epoch [289/20000], Loss: 1229.771484375, Entropy -315.79449462890625, Learning Rate: 0.01\n",
      "Epoch [290/20000], Loss: 1326.4869384765625, Entropy -324.0722351074219, Learning Rate: 0.01\n",
      "Epoch [291/20000], Loss: 1294.8436279296875, Entropy -320.2075500488281, Learning Rate: 0.01\n",
      "Epoch [292/20000], Loss: 1532.971435546875, Entropy -305.5543518066406, Learning Rate: 0.01\n",
      "Epoch [293/20000], Loss: 1376.5887451171875, Entropy -314.5902099609375, Learning Rate: 0.01\n",
      "Epoch [294/20000], Loss: 1210.1005859375, Entropy -311.4545593261719, Learning Rate: 0.01\n",
      "Epoch [295/20000], Loss: 1184.76220703125, Entropy -310.3672180175781, Learning Rate: 0.01\n",
      "Epoch [296/20000], Loss: 1193.4443359375, Entropy -321.1458740234375, Learning Rate: 0.01\n",
      "Epoch [297/20000], Loss: 1227.0252685546875, Entropy -319.4717712402344, Learning Rate: 0.01\n",
      "Epoch [298/20000], Loss: 1288.65625, Entropy -315.2409973144531, Learning Rate: 0.01\n",
      "Epoch [299/20000], Loss: 1278.958984375, Entropy -324.60772705078125, Learning Rate: 0.01\n",
      "Epoch [300/20000], Loss: 1381.2056884765625, Entropy -313.413818359375, Learning Rate: 0.01\n",
      "Epoch [301/20000], Loss: 1246.65771484375, Entropy -320.94464111328125, Learning Rate: 0.01\n",
      "Epoch [302/20000], Loss: 1273.4501953125, Entropy -318.1592102050781, Learning Rate: 0.01\n",
      "Epoch [303/20000], Loss: 1284.0010986328125, Entropy -304.8988342285156, Learning Rate: 0.01\n",
      "Epoch [304/20000], Loss: 1272.9993896484375, Entropy -315.3910827636719, Learning Rate: 0.01\n",
      "Epoch [305/20000], Loss: 1345.0504150390625, Entropy -315.0079650878906, Learning Rate: 0.01\n",
      "Epoch [306/20000], Loss: 1254.80712890625, Entropy -319.9986572265625, Learning Rate: 0.01\n",
      "Epoch [307/20000], Loss: 1134.274658203125, Entropy -309.84368896484375, Learning Rate: 0.01\n",
      "Epoch [308/20000], Loss: 1245.77001953125, Entropy -307.06719970703125, Learning Rate: 0.01\n",
      "Epoch [309/20000], Loss: 1348.655029296875, Entropy -312.7937927246094, Learning Rate: 0.01\n",
      "Epoch [310/20000], Loss: 1411.215087890625, Entropy -312.5145568847656, Learning Rate: 0.01\n",
      "Epoch [311/20000], Loss: 1317.8909912109375, Entropy -310.8600158691406, Learning Rate: 0.01\n",
      "Epoch [312/20000], Loss: 1134.28076171875, Entropy -309.3139953613281, Learning Rate: 0.01\n",
      "Epoch [313/20000], Loss: 1170.6109619140625, Entropy -308.5323791503906, Learning Rate: 0.01\n",
      "Epoch [314/20000], Loss: 1224.4814453125, Entropy -310.8765563964844, Learning Rate: 0.01\n",
      "Epoch [315/20000], Loss: 1211.02490234375, Entropy -304.4786682128906, Learning Rate: 0.01\n",
      "Epoch [316/20000], Loss: 1189.4151611328125, Entropy -313.96173095703125, Learning Rate: 0.01\n",
      "Epoch [317/20000], Loss: 1166.904541015625, Entropy -311.12640380859375, Learning Rate: 0.01\n",
      "Epoch [318/20000], Loss: 1107.7984619140625, Entropy -307.6148681640625, Learning Rate: 0.01\n",
      "Epoch [319/20000], Loss: 1211.9652099609375, Entropy -308.7635498046875, Learning Rate: 0.01\n",
      "Epoch [320/20000], Loss: 1220.33984375, Entropy -308.1040344238281, Learning Rate: 0.01\n",
      "Epoch [321/20000], Loss: 1368.9107666015625, Entropy -307.3558654785156, Learning Rate: 0.01\n",
      "Epoch [322/20000], Loss: 1152.46630859375, Entropy -313.5909118652344, Learning Rate: 0.01\n",
      "Epoch [323/20000], Loss: 1161.95263671875, Entropy -322.4099426269531, Learning Rate: 0.01\n",
      "Epoch [324/20000], Loss: 1094.447509765625, Entropy -309.6295166015625, Learning Rate: 0.01\n",
      "Epoch [325/20000], Loss: 1063.220947265625, Entropy -318.5032653808594, Learning Rate: 0.01\n",
      "Epoch [326/20000], Loss: 1060.9903564453125, Entropy -307.2379150390625, Learning Rate: 0.01\n",
      "Epoch [327/20000], Loss: 1168.2642822265625, Entropy -323.92230224609375, Learning Rate: 0.01\n",
      "Epoch [328/20000], Loss: 1151.5372314453125, Entropy -304.6905517578125, Learning Rate: 0.01\n",
      "Epoch [329/20000], Loss: 1164.0394287109375, Entropy -316.3421936035156, Learning Rate: 0.01\n",
      "Epoch [330/20000], Loss: 1136.74609375, Entropy -314.4327697753906, Learning Rate: 0.01\n",
      "Epoch [331/20000], Loss: 1224.1029052734375, Entropy -321.1784973144531, Learning Rate: 0.01\n",
      "Epoch [332/20000], Loss: 1053.316650390625, Entropy -311.3229675292969, Learning Rate: 0.01\n",
      "Epoch [333/20000], Loss: 1060.71728515625, Entropy -306.97869873046875, Learning Rate: 0.01\n",
      "Epoch [334/20000], Loss: 1155.228515625, Entropy -308.07391357421875, Learning Rate: 0.01\n",
      "Epoch [335/20000], Loss: 1262.4962158203125, Entropy -314.45587158203125, Learning Rate: 0.01\n",
      "Epoch [336/20000], Loss: 1170.635498046875, Entropy -304.75811767578125, Learning Rate: 0.01\n",
      "Epoch [337/20000], Loss: 1133.892578125, Entropy -317.4127197265625, Learning Rate: 0.01\n",
      "Epoch [338/20000], Loss: 1299.547607421875, Entropy -315.3702697753906, Learning Rate: 0.01\n",
      "Epoch [339/20000], Loss: 1112.514892578125, Entropy -304.4439392089844, Learning Rate: 0.01\n",
      "Epoch [340/20000], Loss: 1130.2962646484375, Entropy -306.8131408691406, Learning Rate: 0.01\n",
      "Epoch [341/20000], Loss: 1195.1329345703125, Entropy -307.8432312011719, Learning Rate: 0.01\n",
      "Epoch [342/20000], Loss: 1092.5079345703125, Entropy -304.6747741699219, Learning Rate: 0.01\n",
      "Epoch [343/20000], Loss: 1043.211669921875, Entropy -320.3329772949219, Learning Rate: 0.01\n",
      "Epoch [344/20000], Loss: 1147.3226318359375, Entropy -313.3068542480469, Learning Rate: 0.01\n",
      "Epoch [345/20000], Loss: 1063.1177978515625, Entropy -312.23004150390625, Learning Rate: 0.01\n",
      "Epoch [346/20000], Loss: 1139.55224609375, Entropy -312.94989013671875, Learning Rate: 0.01\n",
      "Epoch [347/20000], Loss: 1238.825439453125, Entropy -306.5372619628906, Learning Rate: 0.01\n",
      "Epoch [348/20000], Loss: 1078.0552978515625, Entropy -308.85968017578125, Learning Rate: 0.01\n",
      "Epoch [349/20000], Loss: 1143.243408203125, Entropy -304.2962341308594, Learning Rate: 0.01\n",
      "Epoch [350/20000], Loss: 1115.6363525390625, Entropy -314.2435607910156, Learning Rate: 0.01\n",
      "Epoch [351/20000], Loss: 1080.093505859375, Entropy -307.8875427246094, Learning Rate: 0.01\n",
      "Epoch [352/20000], Loss: 1156.4300537109375, Entropy -301.3469543457031, Learning Rate: 0.01\n",
      "Epoch [353/20000], Loss: 1106.483154296875, Entropy -304.83587646484375, Learning Rate: 0.01\n",
      "Epoch [354/20000], Loss: 1314.5577392578125, Entropy -311.03131103515625, Learning Rate: 0.01\n",
      "Epoch [355/20000], Loss: 1171.36669921875, Entropy -302.2623291015625, Learning Rate: 0.01\n",
      "Epoch [356/20000], Loss: 1048.0494384765625, Entropy -318.929443359375, Learning Rate: 0.01\n",
      "Epoch [357/20000], Loss: 1175.129638671875, Entropy -314.34722900390625, Learning Rate: 0.01\n",
      "Epoch [358/20000], Loss: 1167.221923828125, Entropy -300.38165283203125, Learning Rate: 0.01\n",
      "Epoch [359/20000], Loss: 991.3927001953125, Entropy -306.9681701660156, Learning Rate: 0.01\n",
      "Epoch [360/20000], Loss: 1136.09765625, Entropy -302.73828125, Learning Rate: 0.01\n",
      "Epoch [361/20000], Loss: 1142.71435546875, Entropy -309.9732666015625, Learning Rate: 0.01\n",
      "Epoch [362/20000], Loss: 1027.30224609375, Entropy -309.8597717285156, Learning Rate: 0.01\n",
      "Epoch [363/20000], Loss: 1100.50439453125, Entropy -304.6171569824219, Learning Rate: 0.01\n",
      "Epoch [364/20000], Loss: 1119.987548828125, Entropy -302.2895812988281, Learning Rate: 0.01\n",
      "Epoch [365/20000], Loss: 1137.50341796875, Entropy -298.8994445800781, Learning Rate: 0.01\n",
      "Epoch [366/20000], Loss: 1025.544677734375, Entropy -301.2154235839844, Learning Rate: 0.01\n",
      "Epoch [367/20000], Loss: 1139.736328125, Entropy -308.0260314941406, Learning Rate: 0.01\n",
      "Epoch [368/20000], Loss: 1164.307861328125, Entropy -305.7491149902344, Learning Rate: 0.01\n",
      "Epoch [369/20000], Loss: 933.566162109375, Entropy -299.3363037109375, Learning Rate: 0.01\n",
      "Epoch [370/20000], Loss: 949.8629760742188, Entropy -304.3088073730469, Learning Rate: 0.01\n",
      "Epoch [371/20000], Loss: 1084.2025146484375, Entropy -299.073486328125, Learning Rate: 0.01\n",
      "Epoch [372/20000], Loss: 1240.0286865234375, Entropy -303.0325622558594, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [373/20000], Loss: 1009.3816528320312, Entropy -302.21826171875, Learning Rate: 0.01\n",
      "Epoch [374/20000], Loss: 1131.904296875, Entropy -310.6736145019531, Learning Rate: 0.01\n",
      "Epoch [375/20000], Loss: 1010.6746826171875, Entropy -307.0614929199219, Learning Rate: 0.01\n",
      "Epoch [376/20000], Loss: 1065.6573486328125, Entropy -310.6112976074219, Learning Rate: 0.01\n",
      "Epoch [377/20000], Loss: 1134.45947265625, Entropy -306.77386474609375, Learning Rate: 0.01\n",
      "Epoch [378/20000], Loss: 1129.329833984375, Entropy -317.6338806152344, Learning Rate: 0.01\n",
      "Epoch [379/20000], Loss: 1032.0523681640625, Entropy -299.53857421875, Learning Rate: 0.01\n",
      "Epoch [380/20000], Loss: 1165.02099609375, Entropy -304.46771240234375, Learning Rate: 0.01\n",
      "Epoch [381/20000], Loss: 1179.9071044921875, Entropy -297.8587951660156, Learning Rate: 0.01\n",
      "Epoch [382/20000], Loss: 1116.1619873046875, Entropy -301.7459716796875, Learning Rate: 0.01\n",
      "Epoch [383/20000], Loss: 1106.4718017578125, Entropy -309.18505859375, Learning Rate: 0.01\n",
      "Epoch [384/20000], Loss: 1121.1025390625, Entropy -303.98974609375, Learning Rate: 0.01\n",
      "Epoch [385/20000], Loss: 975.3598022460938, Entropy -301.3154296875, Learning Rate: 0.01\n",
      "Epoch [386/20000], Loss: 917.436767578125, Entropy -301.7236633300781, Learning Rate: 0.01\n",
      "Epoch [387/20000], Loss: 1098.7933349609375, Entropy -303.3691711425781, Learning Rate: 0.01\n",
      "Epoch [388/20000], Loss: 1139.1605224609375, Entropy -292.92486572265625, Learning Rate: 0.01\n",
      "Epoch [389/20000], Loss: 1149.1658935546875, Entropy -299.04827880859375, Learning Rate: 0.01\n",
      "Epoch [390/20000], Loss: 998.1185913085938, Entropy -294.6264343261719, Learning Rate: 0.01\n",
      "Epoch [391/20000], Loss: 1096.228271484375, Entropy -307.35467529296875, Learning Rate: 0.01\n",
      "Epoch [392/20000], Loss: 1171.7225341796875, Entropy -293.84051513671875, Learning Rate: 0.01\n",
      "Epoch [393/20000], Loss: 1128.266357421875, Entropy -305.7264099121094, Learning Rate: 0.01\n",
      "Epoch [394/20000], Loss: 1218.437255859375, Entropy -302.07421875, Learning Rate: 0.01\n",
      "Epoch [395/20000], Loss: 1198.4158935546875, Entropy -306.7475280761719, Learning Rate: 0.01\n",
      "Epoch [396/20000], Loss: 889.0140380859375, Entropy -310.1665344238281, Learning Rate: 0.01\n",
      "Epoch [397/20000], Loss: 949.0438232421875, Entropy -308.4297180175781, Learning Rate: 0.01\n",
      "Epoch [398/20000], Loss: 1029.53564453125, Entropy -304.01055908203125, Learning Rate: 0.01\n",
      "Epoch [399/20000], Loss: 1126.483642578125, Entropy -292.6139831542969, Learning Rate: 0.01\n",
      "Epoch [400/20000], Loss: 1113.656005859375, Entropy -305.4530944824219, Learning Rate: 0.01\n",
      "Epoch [401/20000], Loss: 1062.6529541015625, Entropy -314.3340759277344, Learning Rate: 0.01\n",
      "Epoch [402/20000], Loss: 1022.5562744140625, Entropy -302.3113708496094, Learning Rate: 0.01\n",
      "Epoch [403/20000], Loss: 995.7843017578125, Entropy -307.562255859375, Learning Rate: 0.01\n",
      "Epoch [404/20000], Loss: 917.2373046875, Entropy -301.61737060546875, Learning Rate: 0.01\n",
      "Epoch [405/20000], Loss: 1051.240234375, Entropy -303.77325439453125, Learning Rate: 0.01\n",
      "Epoch [406/20000], Loss: 981.74072265625, Entropy -304.33795166015625, Learning Rate: 0.01\n",
      "Epoch [407/20000], Loss: 1024.943115234375, Entropy -311.4128723144531, Learning Rate: 0.01\n",
      "Epoch [408/20000], Loss: 1058.818115234375, Entropy -295.72821044921875, Learning Rate: 0.01\n",
      "Epoch [409/20000], Loss: 1044.463623046875, Entropy -302.7825622558594, Learning Rate: 0.01\n",
      "Epoch [410/20000], Loss: 981.2362060546875, Entropy -304.41839599609375, Learning Rate: 0.01\n",
      "Epoch [411/20000], Loss: 962.885498046875, Entropy -299.64739990234375, Learning Rate: 0.01\n",
      "Epoch [412/20000], Loss: 1086.6915283203125, Entropy -297.05645751953125, Learning Rate: 0.01\n",
      "Epoch [413/20000], Loss: 844.2960205078125, Entropy -307.19415283203125, Learning Rate: 0.01\n",
      "Epoch [414/20000], Loss: 904.5592041015625, Entropy -297.8673095703125, Learning Rate: 0.01\n",
      "Epoch [415/20000], Loss: 1073.6202392578125, Entropy -310.8041076660156, Learning Rate: 0.01\n",
      "Epoch [416/20000], Loss: 974.836669921875, Entropy -309.2835693359375, Learning Rate: 0.01\n",
      "Epoch [417/20000], Loss: 802.0797119140625, Entropy -315.7284240722656, Learning Rate: 0.01\n",
      "Epoch [418/20000], Loss: 981.8939208984375, Entropy -304.8085632324219, Learning Rate: 0.01\n",
      "Epoch [419/20000], Loss: 895.089111328125, Entropy -304.5945129394531, Learning Rate: 0.01\n",
      "Epoch [420/20000], Loss: 942.7281494140625, Entropy -307.48272705078125, Learning Rate: 0.01\n",
      "Epoch [421/20000], Loss: 869.2232055664062, Entropy -299.6044006347656, Learning Rate: 0.01\n",
      "Epoch [422/20000], Loss: 802.1845703125, Entropy -303.19317626953125, Learning Rate: 0.01\n",
      "Epoch [423/20000], Loss: 937.70068359375, Entropy -313.2920227050781, Learning Rate: 0.01\n",
      "Epoch [424/20000], Loss: 942.9341430664062, Entropy -302.5843505859375, Learning Rate: 0.01\n",
      "Epoch [425/20000], Loss: 884.2115478515625, Entropy -314.4303894042969, Learning Rate: 0.01\n",
      "Epoch [426/20000], Loss: 867.2174072265625, Entropy -297.5795593261719, Learning Rate: 0.01\n",
      "Epoch [427/20000], Loss: 879.615478515625, Entropy -307.7648010253906, Learning Rate: 0.01\n",
      "Epoch [428/20000], Loss: 817.6861572265625, Entropy -305.4010925292969, Learning Rate: 0.01\n",
      "Epoch [429/20000], Loss: 896.68701171875, Entropy -297.9872741699219, Learning Rate: 0.01\n",
      "Epoch [430/20000], Loss: 840.80322265625, Entropy -309.8803405761719, Learning Rate: 0.01\n",
      "Epoch [431/20000], Loss: 853.7415771484375, Entropy -299.9653015136719, Learning Rate: 0.01\n",
      "Epoch [432/20000], Loss: 839.990478515625, Entropy -302.1078186035156, Learning Rate: 0.01\n",
      "Epoch [433/20000], Loss: 953.4603271484375, Entropy -296.7623291015625, Learning Rate: 0.01\n",
      "Epoch [434/20000], Loss: 785.8816528320312, Entropy -292.1044006347656, Learning Rate: 0.01\n",
      "Epoch [435/20000], Loss: 980.435791015625, Entropy -307.4658508300781, Learning Rate: 0.01\n",
      "Epoch [436/20000], Loss: 758.0870361328125, Entropy -304.3249816894531, Learning Rate: 0.01\n",
      "Epoch [437/20000], Loss: 740.9764404296875, Entropy -300.07330322265625, Learning Rate: 0.01\n",
      "Epoch [438/20000], Loss: 821.8084106445312, Entropy -305.52069091796875, Learning Rate: 0.01\n",
      "Epoch [439/20000], Loss: 814.4434814453125, Entropy -306.1654357910156, Learning Rate: 0.01\n",
      "Epoch [440/20000], Loss: 841.9609375, Entropy -300.0636901855469, Learning Rate: 0.01\n",
      "Epoch [441/20000], Loss: 856.003173828125, Entropy -306.8010559082031, Learning Rate: 0.01\n",
      "Epoch [442/20000], Loss: 824.9571533203125, Entropy -298.78375244140625, Learning Rate: 0.01\n",
      "Epoch [443/20000], Loss: 829.9085693359375, Entropy -300.99871826171875, Learning Rate: 0.01\n",
      "Epoch [444/20000], Loss: 806.9183959960938, Entropy -306.4679870605469, Learning Rate: 0.01\n",
      "Epoch [445/20000], Loss: 885.1043090820312, Entropy -301.3304138183594, Learning Rate: 0.01\n",
      "Epoch [446/20000], Loss: 786.5714111328125, Entropy -307.1723937988281, Learning Rate: 0.01\n",
      "Epoch [447/20000], Loss: 814.593017578125, Entropy -310.121337890625, Learning Rate: 0.01\n",
      "Epoch [448/20000], Loss: 846.7999267578125, Entropy -315.2341613769531, Learning Rate: 0.01\n",
      "Epoch [449/20000], Loss: 888.6882934570312, Entropy -299.97564697265625, Learning Rate: 0.01\n",
      "Epoch [450/20000], Loss: 792.724365234375, Entropy -306.0722961425781, Learning Rate: 0.01\n",
      "Epoch [451/20000], Loss: 936.8509521484375, Entropy -289.76727294921875, Learning Rate: 0.01\n",
      "Epoch [452/20000], Loss: 824.736572265625, Entropy -290.450927734375, Learning Rate: 0.01\n",
      "Epoch [453/20000], Loss: 760.9765625, Entropy -293.64093017578125, Learning Rate: 0.01\n",
      "Epoch [454/20000], Loss: 1117.311279296875, Entropy -289.5382995605469, Learning Rate: 0.01\n",
      "Epoch [455/20000], Loss: 976.97021484375, Entropy -299.3098449707031, Learning Rate: 0.01\n",
      "Epoch [456/20000], Loss: 845.992431640625, Entropy -306.646728515625, Learning Rate: 0.01\n",
      "Epoch [457/20000], Loss: 955.2913818359375, Entropy -301.5849304199219, Learning Rate: 0.01\n",
      "Epoch [458/20000], Loss: 1018.927734375, Entropy -296.2308349609375, Learning Rate: 0.01\n",
      "Epoch [459/20000], Loss: 958.6129760742188, Entropy -289.10723876953125, Learning Rate: 0.01\n",
      "Epoch [460/20000], Loss: 831.5155029296875, Entropy -293.60699462890625, Learning Rate: 0.01\n",
      "Epoch [461/20000], Loss: 811.683837890625, Entropy -300.8010559082031, Learning Rate: 0.01\n",
      "Epoch [462/20000], Loss: 854.57275390625, Entropy -298.024169921875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [463/20000], Loss: 792.1941528320312, Entropy -308.0457458496094, Learning Rate: 0.01\n",
      "Epoch [464/20000], Loss: 957.6594848632812, Entropy -299.06658935546875, Learning Rate: 0.01\n",
      "Epoch [465/20000], Loss: 948.3997802734375, Entropy -299.2910461425781, Learning Rate: 0.01\n",
      "Epoch [466/20000], Loss: 951.24560546875, Entropy -293.451904296875, Learning Rate: 0.01\n",
      "Epoch [467/20000], Loss: 1063.5947265625, Entropy -302.0303039550781, Learning Rate: 0.01\n",
      "Epoch [468/20000], Loss: 732.165771484375, Entropy -303.95068359375, Learning Rate: 0.01\n",
      "Epoch [469/20000], Loss: 746.941162109375, Entropy -304.40826416015625, Learning Rate: 0.01\n",
      "Epoch [470/20000], Loss: 852.3648681640625, Entropy -296.9445495605469, Learning Rate: 0.01\n",
      "Epoch [471/20000], Loss: 869.423583984375, Entropy -290.62432861328125, Learning Rate: 0.01\n",
      "Epoch [472/20000], Loss: 745.2137451171875, Entropy -305.75433349609375, Learning Rate: 0.01\n",
      "Epoch [473/20000], Loss: 856.609130859375, Entropy -305.4410400390625, Learning Rate: 0.01\n",
      "Epoch [474/20000], Loss: 763.3408203125, Entropy -305.0434265136719, Learning Rate: 0.01\n",
      "Epoch [475/20000], Loss: 839.7608642578125, Entropy -296.015869140625, Learning Rate: 0.01\n",
      "Epoch [476/20000], Loss: 852.6900024414062, Entropy -303.2029724121094, Learning Rate: 0.01\n",
      "Epoch [477/20000], Loss: 772.344970703125, Entropy -307.83917236328125, Learning Rate: 0.01\n",
      "Epoch [478/20000], Loss: 1008.0521240234375, Entropy -291.14599609375, Learning Rate: 0.01\n",
      "Epoch [479/20000], Loss: 776.0140380859375, Entropy -298.8533935546875, Learning Rate: 0.01\n",
      "Epoch [480/20000], Loss: 843.1041259765625, Entropy -300.88507080078125, Learning Rate: 0.01\n",
      "Epoch [481/20000], Loss: 922.65380859375, Entropy -298.7288818359375, Learning Rate: 0.01\n",
      "Epoch [482/20000], Loss: 908.5220947265625, Entropy -307.1752014160156, Learning Rate: 0.01\n",
      "Epoch [483/20000], Loss: 771.76123046875, Entropy -302.541015625, Learning Rate: 0.01\n",
      "Epoch [484/20000], Loss: 1006.849853515625, Entropy -295.6971740722656, Learning Rate: 0.01\n",
      "Epoch [485/20000], Loss: 906.358154296875, Entropy -304.7950744628906, Learning Rate: 0.01\n",
      "Epoch [486/20000], Loss: 751.9207153320312, Entropy -294.4288635253906, Learning Rate: 0.01\n",
      "Epoch [487/20000], Loss: 765.6480712890625, Entropy -300.6199951171875, Learning Rate: 0.01\n",
      "Epoch [488/20000], Loss: 671.3800048828125, Entropy -298.3463439941406, Learning Rate: 0.01\n",
      "Epoch [489/20000], Loss: 705.3338012695312, Entropy -303.0171813964844, Learning Rate: 0.01\n",
      "Epoch [490/20000], Loss: 807.5294189453125, Entropy -300.4906005859375, Learning Rate: 0.01\n",
      "Epoch [491/20000], Loss: 745.6510620117188, Entropy -306.39471435546875, Learning Rate: 0.01\n",
      "Epoch [492/20000], Loss: 668.9515380859375, Entropy -301.4735107421875, Learning Rate: 0.01\n",
      "Epoch [493/20000], Loss: 865.9407958984375, Entropy -298.6442565917969, Learning Rate: 0.01\n",
      "Epoch [494/20000], Loss: 787.6387939453125, Entropy -292.3636779785156, Learning Rate: 0.01\n",
      "Epoch [495/20000], Loss: 705.7916870117188, Entropy -313.8592834472656, Learning Rate: 0.01\n",
      "Epoch [496/20000], Loss: 690.8138427734375, Entropy -303.0096435546875, Learning Rate: 0.01\n",
      "Epoch [497/20000], Loss: 718.31298828125, Entropy -311.2468566894531, Learning Rate: 0.01\n",
      "Epoch [498/20000], Loss: 704.355224609375, Entropy -303.9291687011719, Learning Rate: 0.01\n",
      "Epoch [499/20000], Loss: 655.3482055664062, Entropy -302.4835510253906, Learning Rate: 0.01\n",
      "Epoch [500/20000], Loss: 706.7975463867188, Entropy -305.14215087890625, Learning Rate: 0.01\n",
      "Epoch [501/20000], Loss: 679.4325561523438, Entropy -303.16455078125, Learning Rate: 0.01\n",
      "Epoch [502/20000], Loss: 680.8912353515625, Entropy -301.9080810546875, Learning Rate: 0.01\n",
      "Epoch [503/20000], Loss: 623.150146484375, Entropy -310.6806335449219, Learning Rate: 0.01\n",
      "Epoch [504/20000], Loss: 683.0988159179688, Entropy -308.8660583496094, Learning Rate: 0.01\n",
      "Epoch [505/20000], Loss: 668.087158203125, Entropy -318.6449890136719, Learning Rate: 0.01\n",
      "Epoch [506/20000], Loss: 655.69775390625, Entropy -301.5755615234375, Learning Rate: 0.01\n",
      "Epoch [507/20000], Loss: 671.0247802734375, Entropy -302.687744140625, Learning Rate: 0.01\n",
      "Epoch [508/20000], Loss: 594.3104248046875, Entropy -316.3929443359375, Learning Rate: 0.01\n",
      "Epoch [509/20000], Loss: 648.9779052734375, Entropy -302.02435302734375, Learning Rate: 0.01\n",
      "Epoch [510/20000], Loss: 563.5682373046875, Entropy -312.6982727050781, Learning Rate: 0.01\n",
      "Epoch [511/20000], Loss: 677.9343872070312, Entropy -308.99041748046875, Learning Rate: 0.01\n",
      "Epoch [512/20000], Loss: 689.8394775390625, Entropy -300.171875, Learning Rate: 0.01\n",
      "Epoch [513/20000], Loss: 664.1310424804688, Entropy -307.46783447265625, Learning Rate: 0.01\n",
      "Epoch [514/20000], Loss: 617.48046875, Entropy -301.47088623046875, Learning Rate: 0.01\n",
      "Epoch [515/20000], Loss: 629.7040405273438, Entropy -305.5455627441406, Learning Rate: 0.01\n",
      "Epoch [516/20000], Loss: 642.7886352539062, Entropy -319.077880859375, Learning Rate: 0.01\n",
      "Epoch [517/20000], Loss: 609.8735961914062, Entropy -308.64080810546875, Learning Rate: 0.01\n",
      "Epoch [518/20000], Loss: 616.2443237304688, Entropy -309.4553527832031, Learning Rate: 0.01\n",
      "Epoch [519/20000], Loss: 629.9027099609375, Entropy -312.91986083984375, Learning Rate: 0.01\n",
      "Epoch [520/20000], Loss: 610.5169677734375, Entropy -310.58770751953125, Learning Rate: 0.01\n",
      "Epoch [521/20000], Loss: 591.054931640625, Entropy -307.29522705078125, Learning Rate: 0.01\n",
      "Epoch [522/20000], Loss: 567.4046630859375, Entropy -303.9994201660156, Learning Rate: 0.01\n",
      "Epoch [523/20000], Loss: 610.62060546875, Entropy -309.9936218261719, Learning Rate: 0.01\n",
      "Epoch [524/20000], Loss: 561.5675048828125, Entropy -306.80096435546875, Learning Rate: 0.01\n",
      "Epoch [525/20000], Loss: 616.197021484375, Entropy -306.6884460449219, Learning Rate: 0.01\n",
      "Epoch [526/20000], Loss: 602.8843994140625, Entropy -303.6092529296875, Learning Rate: 0.01\n",
      "Epoch [527/20000], Loss: 569.9674072265625, Entropy -308.5425720214844, Learning Rate: 0.01\n",
      "Epoch [528/20000], Loss: 611.91259765625, Entropy -319.356201171875, Learning Rate: 0.01\n",
      "Epoch [529/20000], Loss: 593.867919921875, Entropy -321.67864990234375, Learning Rate: 0.01\n",
      "Epoch [530/20000], Loss: 623.1253662109375, Entropy -306.4201354980469, Learning Rate: 0.01\n",
      "Epoch [531/20000], Loss: 625.272705078125, Entropy -304.37030029296875, Learning Rate: 0.01\n",
      "Epoch [532/20000], Loss: 569.000732421875, Entropy -302.0284423828125, Learning Rate: 0.01\n",
      "Epoch [533/20000], Loss: 652.5374145507812, Entropy -300.14044189453125, Learning Rate: 0.01\n",
      "Epoch [534/20000], Loss: 637.8163452148438, Entropy -302.87701416015625, Learning Rate: 0.01\n",
      "Epoch [535/20000], Loss: 563.8216552734375, Entropy -318.8611145019531, Learning Rate: 0.01\n",
      "Epoch [536/20000], Loss: 595.3076171875, Entropy -300.8475341796875, Learning Rate: 0.01\n",
      "Epoch [537/20000], Loss: 635.0205078125, Entropy -298.7009582519531, Learning Rate: 0.01\n",
      "Epoch [538/20000], Loss: 560.4072265625, Entropy -303.5527038574219, Learning Rate: 0.01\n",
      "Epoch [539/20000], Loss: 617.4911499023438, Entropy -307.0086669921875, Learning Rate: 0.01\n",
      "Epoch [540/20000], Loss: 597.483642578125, Entropy -304.27593994140625, Learning Rate: 0.01\n",
      "Epoch [541/20000], Loss: 579.9224853515625, Entropy -314.1441345214844, Learning Rate: 0.01\n",
      "Epoch [542/20000], Loss: 577.0506591796875, Entropy -303.5610656738281, Learning Rate: 0.01\n",
      "Epoch [543/20000], Loss: 596.3287353515625, Entropy -304.7485656738281, Learning Rate: 0.01\n",
      "Epoch [544/20000], Loss: 658.2647705078125, Entropy -299.4654846191406, Learning Rate: 0.01\n",
      "Epoch [545/20000], Loss: 604.6991577148438, Entropy -297.7664794921875, Learning Rate: 0.01\n",
      "Epoch [546/20000], Loss: 588.0556640625, Entropy -308.6099853515625, Learning Rate: 0.01\n",
      "Epoch [547/20000], Loss: 545.7887573242188, Entropy -310.16656494140625, Learning Rate: 0.01\n",
      "Epoch [548/20000], Loss: 564.1768188476562, Entropy -312.1195068359375, Learning Rate: 0.01\n",
      "Epoch [549/20000], Loss: 543.3375854492188, Entropy -308.5103759765625, Learning Rate: 0.01\n",
      "Epoch [550/20000], Loss: 607.7710571289062, Entropy -301.17645263671875, Learning Rate: 0.01\n",
      "Epoch [551/20000], Loss: 557.43701171875, Entropy -311.9139709472656, Learning Rate: 0.01\n",
      "Epoch [552/20000], Loss: 609.0139770507812, Entropy -302.5539855957031, Learning Rate: 0.01\n",
      "Epoch [553/20000], Loss: 610.8760375976562, Entropy -306.58526611328125, Learning Rate: 0.01\n",
      "Epoch [554/20000], Loss: 595.6146240234375, Entropy -307.9355773925781, Learning Rate: 0.01\n",
      "Epoch [555/20000], Loss: 591.7235107421875, Entropy -307.1786193847656, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [556/20000], Loss: 603.44287109375, Entropy -310.51092529296875, Learning Rate: 0.01\n",
      "Epoch [557/20000], Loss: 553.4189453125, Entropy -311.9658508300781, Learning Rate: 0.01\n",
      "Epoch [558/20000], Loss: 540.9277954101562, Entropy -297.9893798828125, Learning Rate: 0.01\n",
      "Epoch [559/20000], Loss: 570.1697387695312, Entropy -309.96392822265625, Learning Rate: 0.01\n",
      "Epoch [560/20000], Loss: 608.4542236328125, Entropy -304.10125732421875, Learning Rate: 0.01\n",
      "Epoch [561/20000], Loss: 564.439697265625, Entropy -306.680908203125, Learning Rate: 0.01\n",
      "Epoch [562/20000], Loss: 549.484130859375, Entropy -307.9053649902344, Learning Rate: 0.01\n",
      "Epoch [563/20000], Loss: 647.13623046875, Entropy -318.9532470703125, Learning Rate: 0.01\n",
      "Epoch [564/20000], Loss: 551.9668579101562, Entropy -312.0091552734375, Learning Rate: 0.01\n",
      "Epoch [565/20000], Loss: 584.3524780273438, Entropy -301.763427734375, Learning Rate: 0.01\n",
      "Epoch [566/20000], Loss: 650.4224853515625, Entropy -313.7913513183594, Learning Rate: 0.01\n",
      "Epoch [567/20000], Loss: 694.8360595703125, Entropy -309.53759765625, Learning Rate: 0.01\n",
      "Epoch [568/20000], Loss: 577.856689453125, Entropy -315.2970275878906, Learning Rate: 0.01\n",
      "Epoch [569/20000], Loss: 584.7623291015625, Entropy -304.7536315917969, Learning Rate: 0.01\n",
      "Epoch [570/20000], Loss: 651.0885009765625, Entropy -308.6864318847656, Learning Rate: 0.01\n",
      "Epoch [571/20000], Loss: 599.2197875976562, Entropy -306.47979736328125, Learning Rate: 0.01\n",
      "Epoch [572/20000], Loss: 633.8602294921875, Entropy -299.1669921875, Learning Rate: 0.01\n",
      "Epoch [573/20000], Loss: 553.24853515625, Entropy -296.880126953125, Learning Rate: 0.01\n",
      "Epoch [574/20000], Loss: 627.0812377929688, Entropy -311.49151611328125, Learning Rate: 0.01\n",
      "Epoch [575/20000], Loss: 598.8362426757812, Entropy -304.116943359375, Learning Rate: 0.01\n",
      "Epoch [576/20000], Loss: 691.8461303710938, Entropy -318.0802917480469, Learning Rate: 0.01\n",
      "Epoch [577/20000], Loss: 606.1539916992188, Entropy -304.5928649902344, Learning Rate: 0.01\n",
      "Epoch [578/20000], Loss: 582.2210693359375, Entropy -296.1763000488281, Learning Rate: 0.01\n",
      "Epoch [579/20000], Loss: 601.1053466796875, Entropy -297.12823486328125, Learning Rate: 0.01\n",
      "Epoch [580/20000], Loss: 604.5807495117188, Entropy -292.23529052734375, Learning Rate: 0.01\n",
      "Epoch [581/20000], Loss: 582.5040893554688, Entropy -307.64013671875, Learning Rate: 0.01\n",
      "Epoch [582/20000], Loss: 588.04638671875, Entropy -306.7867736816406, Learning Rate: 0.01\n",
      "Epoch [583/20000], Loss: 542.1145629882812, Entropy -298.4656982421875, Learning Rate: 0.01\n",
      "Epoch [584/20000], Loss: 661.6112060546875, Entropy -300.498779296875, Learning Rate: 0.01\n",
      "Epoch [585/20000], Loss: 547.019287109375, Entropy -314.90960693359375, Learning Rate: 0.01\n",
      "Epoch [586/20000], Loss: 538.393798828125, Entropy -309.2596130371094, Learning Rate: 0.01\n",
      "Epoch [587/20000], Loss: 638.2638549804688, Entropy -304.4131164550781, Learning Rate: 0.01\n",
      "Epoch [588/20000], Loss: 668.332275390625, Entropy -314.5099792480469, Learning Rate: 0.01\n",
      "Epoch [589/20000], Loss: 659.2830200195312, Entropy -308.19976806640625, Learning Rate: 0.01\n",
      "Epoch [590/20000], Loss: 584.0164794921875, Entropy -306.0686340332031, Learning Rate: 0.01\n",
      "Epoch [591/20000], Loss: 589.564208984375, Entropy -306.2550964355469, Learning Rate: 0.01\n",
      "Epoch [592/20000], Loss: 557.5130615234375, Entropy -296.7685546875, Learning Rate: 0.01\n",
      "Epoch [593/20000], Loss: 590.6370849609375, Entropy -306.05706787109375, Learning Rate: 0.01\n",
      "Epoch [594/20000], Loss: 639.1917724609375, Entropy -306.26153564453125, Learning Rate: 0.01\n",
      "Epoch [595/20000], Loss: 626.2471313476562, Entropy -307.05328369140625, Learning Rate: 0.01\n",
      "Epoch [596/20000], Loss: 614.05126953125, Entropy -300.9197692871094, Learning Rate: 0.01\n",
      "Epoch [597/20000], Loss: 562.9544677734375, Entropy -309.07177734375, Learning Rate: 0.01\n",
      "Epoch [598/20000], Loss: 568.4012451171875, Entropy -306.9139709472656, Learning Rate: 0.01\n",
      "Epoch [599/20000], Loss: 682.3051147460938, Entropy -330.9015808105469, Learning Rate: 0.01\n",
      "Epoch [600/20000], Loss: 557.4465942382812, Entropy -310.9031982421875, Learning Rate: 0.01\n",
      "Epoch [601/20000], Loss: 623.4669189453125, Entropy -310.5909423828125, Learning Rate: 0.01\n",
      "Epoch [602/20000], Loss: 573.4036254882812, Entropy -302.36785888671875, Learning Rate: 0.01\n",
      "Epoch [603/20000], Loss: 588.771240234375, Entropy -302.60235595703125, Learning Rate: 0.01\n",
      "Epoch [604/20000], Loss: 619.7049560546875, Entropy -307.908203125, Learning Rate: 0.01\n",
      "Epoch [605/20000], Loss: 535.8909912109375, Entropy -304.824951171875, Learning Rate: 0.01\n",
      "Epoch [606/20000], Loss: 715.717041015625, Entropy -307.2836608886719, Learning Rate: 0.01\n",
      "Epoch [607/20000], Loss: 569.6404418945312, Entropy -300.3209228515625, Learning Rate: 0.01\n",
      "Epoch [608/20000], Loss: 537.06298828125, Entropy -303.610595703125, Learning Rate: 0.01\n",
      "Epoch [609/20000], Loss: 560.298095703125, Entropy -311.9512634277344, Learning Rate: 0.01\n",
      "Epoch [610/20000], Loss: 573.40869140625, Entropy -296.7636413574219, Learning Rate: 0.01\n",
      "Epoch [611/20000], Loss: 567.8634643554688, Entropy -301.6822814941406, Learning Rate: 0.01\n",
      "Epoch [612/20000], Loss: 563.8430786132812, Entropy -310.5457458496094, Learning Rate: 0.01\n",
      "Epoch [613/20000], Loss: 665.12451171875, Entropy -317.88995361328125, Learning Rate: 0.01\n",
      "Epoch [614/20000], Loss: 588.6641235351562, Entropy -315.59942626953125, Learning Rate: 0.01\n",
      "Epoch [615/20000], Loss: 565.718505859375, Entropy -310.9694519042969, Learning Rate: 0.01\n",
      "Epoch [616/20000], Loss: 621.5810546875, Entropy -311.9460144042969, Learning Rate: 0.01\n",
      "Epoch [617/20000], Loss: 569.8125, Entropy -301.603515625, Learning Rate: 0.01\n",
      "Epoch [618/20000], Loss: 543.7435913085938, Entropy -308.5395812988281, Learning Rate: 0.01\n",
      "Epoch [619/20000], Loss: 533.8739624023438, Entropy -303.3432312011719, Learning Rate: 0.01\n",
      "Epoch [620/20000], Loss: 541.4575805664062, Entropy -304.75909423828125, Learning Rate: 0.01\n",
      "Epoch [621/20000], Loss: 570.5198974609375, Entropy -299.7591857910156, Learning Rate: 0.01\n",
      "Epoch [622/20000], Loss: 489.28485107421875, Entropy -312.0819091796875, Learning Rate: 0.01\n",
      "Epoch [623/20000], Loss: 544.5679931640625, Entropy -304.54510498046875, Learning Rate: 0.01\n",
      "Epoch [624/20000], Loss: 462.9001159667969, Entropy -304.48541259765625, Learning Rate: 0.01\n",
      "Epoch [625/20000], Loss: 543.8463134765625, Entropy -308.44464111328125, Learning Rate: 0.01\n",
      "Epoch [626/20000], Loss: 581.2846069335938, Entropy -314.8387451171875, Learning Rate: 0.01\n",
      "Epoch [627/20000], Loss: 539.1876831054688, Entropy -307.94317626953125, Learning Rate: 0.01\n",
      "Epoch [628/20000], Loss: 632.3740234375, Entropy -306.0024719238281, Learning Rate: 0.01\n",
      "Epoch [629/20000], Loss: 538.68505859375, Entropy -315.9373779296875, Learning Rate: 0.01\n",
      "Epoch [630/20000], Loss: 546.93310546875, Entropy -309.0991516113281, Learning Rate: 0.01\n",
      "Epoch [631/20000], Loss: 571.5684204101562, Entropy -300.70843505859375, Learning Rate: 0.01\n",
      "Epoch [632/20000], Loss: 579.1365356445312, Entropy -305.5464782714844, Learning Rate: 0.01\n",
      "Epoch [633/20000], Loss: 534.954345703125, Entropy -313.0537109375, Learning Rate: 0.01\n",
      "Epoch [634/20000], Loss: 673.7294921875, Entropy -311.75, Learning Rate: 0.01\n",
      "Epoch [635/20000], Loss: 544.9586181640625, Entropy -305.251220703125, Learning Rate: 0.01\n",
      "Epoch [636/20000], Loss: 651.46728515625, Entropy -311.5632629394531, Learning Rate: 0.01\n",
      "Epoch [637/20000], Loss: 550.3922119140625, Entropy -303.63372802734375, Learning Rate: 0.01\n",
      "Epoch [638/20000], Loss: 592.5823974609375, Entropy -308.6448669433594, Learning Rate: 0.01\n",
      "Epoch [639/20000], Loss: 587.9102172851562, Entropy -304.176513671875, Learning Rate: 0.01\n",
      "Epoch [640/20000], Loss: 521.3946533203125, Entropy -314.5248107910156, Learning Rate: 0.01\n",
      "Epoch [641/20000], Loss: 563.3111572265625, Entropy -322.5155944824219, Learning Rate: 0.01\n",
      "Epoch [642/20000], Loss: 534.650634765625, Entropy -311.28106689453125, Learning Rate: 0.01\n",
      "Epoch [643/20000], Loss: 568.8742065429688, Entropy -309.09869384765625, Learning Rate: 0.01\n",
      "Epoch [644/20000], Loss: 484.64599609375, Entropy -313.7182922363281, Learning Rate: 0.01\n",
      "Epoch [645/20000], Loss: 510.0582275390625, Entropy -301.79998779296875, Learning Rate: 0.01\n",
      "Epoch [646/20000], Loss: 552.122314453125, Entropy -298.412841796875, Learning Rate: 0.01\n",
      "Epoch [647/20000], Loss: 568.4190673828125, Entropy -312.6501770019531, Learning Rate: 0.01\n",
      "Epoch [648/20000], Loss: 492.3929748535156, Entropy -308.9181823730469, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [649/20000], Loss: 473.5792236328125, Entropy -314.34332275390625, Learning Rate: 0.01\n",
      "Epoch [650/20000], Loss: 502.8977966308594, Entropy -312.0518798828125, Learning Rate: 0.01\n",
      "Epoch [651/20000], Loss: 501.81719970703125, Entropy -310.6452941894531, Learning Rate: 0.01\n",
      "Epoch [652/20000], Loss: 560.114501953125, Entropy -307.1305236816406, Learning Rate: 0.01\n",
      "Epoch [653/20000], Loss: 478.79119873046875, Entropy -309.1282043457031, Learning Rate: 0.01\n",
      "Epoch [654/20000], Loss: 544.5543823242188, Entropy -306.753173828125, Learning Rate: 0.01\n",
      "Epoch [655/20000], Loss: 525.9109497070312, Entropy -300.0104675292969, Learning Rate: 0.01\n",
      "Epoch [656/20000], Loss: 535.0779418945312, Entropy -320.2261047363281, Learning Rate: 0.01\n",
      "Epoch [657/20000], Loss: 495.71051025390625, Entropy -308.59423828125, Learning Rate: 0.01\n",
      "Epoch [658/20000], Loss: 509.76251220703125, Entropy -311.86669921875, Learning Rate: 0.01\n",
      "Epoch [659/20000], Loss: 588.265869140625, Entropy -310.4834289550781, Learning Rate: 0.01\n",
      "Epoch [660/20000], Loss: 623.8109130859375, Entropy -307.95654296875, Learning Rate: 0.01\n",
      "Epoch [661/20000], Loss: 483.24981689453125, Entropy -320.3674011230469, Learning Rate: 0.01\n",
      "Epoch [662/20000], Loss: 464.8701171875, Entropy -306.3687438964844, Learning Rate: 0.01\n",
      "Epoch [663/20000], Loss: 496.1864013671875, Entropy -321.80029296875, Learning Rate: 0.01\n",
      "Epoch [664/20000], Loss: 501.8763122558594, Entropy -304.0786437988281, Learning Rate: 0.01\n",
      "Epoch [665/20000], Loss: 488.81573486328125, Entropy -307.5653991699219, Learning Rate: 0.01\n",
      "Epoch [666/20000], Loss: 554.7472534179688, Entropy -307.6516418457031, Learning Rate: 0.01\n",
      "Epoch [667/20000], Loss: 476.9063720703125, Entropy -312.30816650390625, Learning Rate: 0.01\n",
      "Epoch [668/20000], Loss: 489.48638916015625, Entropy -313.438232421875, Learning Rate: 0.01\n",
      "Epoch [669/20000], Loss: 491.5252380371094, Entropy -312.3494873046875, Learning Rate: 0.01\n",
      "Epoch [670/20000], Loss: 502.476318359375, Entropy -306.8796081542969, Learning Rate: 0.01\n",
      "Epoch [671/20000], Loss: 480.6108703613281, Entropy -311.4647216796875, Learning Rate: 0.01\n",
      "Epoch [672/20000], Loss: 479.6291198730469, Entropy -311.2292785644531, Learning Rate: 0.01\n",
      "Epoch [673/20000], Loss: 483.02178955078125, Entropy -311.56854248046875, Learning Rate: 0.01\n",
      "Epoch [674/20000], Loss: 476.964111328125, Entropy -315.74151611328125, Learning Rate: 0.01\n",
      "Epoch [675/20000], Loss: 503.6627502441406, Entropy -312.28375244140625, Learning Rate: 0.01\n",
      "Epoch [676/20000], Loss: 545.5442504882812, Entropy -296.3947448730469, Learning Rate: 0.01\n",
      "Epoch [677/20000], Loss: 470.6473388671875, Entropy -312.0583801269531, Learning Rate: 0.01\n",
      "Epoch [678/20000], Loss: 550.8743896484375, Entropy -294.3526611328125, Learning Rate: 0.01\n",
      "Epoch [679/20000], Loss: 499.7686462402344, Entropy -307.7403259277344, Learning Rate: 0.01\n",
      "Epoch [680/20000], Loss: 489.3859558105469, Entropy -303.2947998046875, Learning Rate: 0.01\n",
      "Epoch [681/20000], Loss: 510.7547912597656, Entropy -308.77459716796875, Learning Rate: 0.01\n",
      "Epoch [682/20000], Loss: 498.90948486328125, Entropy -306.182373046875, Learning Rate: 0.01\n",
      "Epoch [683/20000], Loss: 470.25982666015625, Entropy -314.10406494140625, Learning Rate: 0.01\n",
      "Epoch [684/20000], Loss: 525.0347290039062, Entropy -319.6195983886719, Learning Rate: 0.01\n",
      "Epoch [685/20000], Loss: 543.6527709960938, Entropy -303.35052490234375, Learning Rate: 0.01\n",
      "Epoch [686/20000], Loss: 492.0113220214844, Entropy -311.3465881347656, Learning Rate: 0.01\n",
      "Epoch [687/20000], Loss: 472.0231628417969, Entropy -309.78948974609375, Learning Rate: 0.01\n",
      "Epoch [688/20000], Loss: 490.0072937011719, Entropy -304.239501953125, Learning Rate: 0.01\n",
      "Epoch [689/20000], Loss: 427.9971008300781, Entropy -305.93560791015625, Learning Rate: 0.01\n",
      "Epoch [690/20000], Loss: 509.4897155761719, Entropy -310.4459228515625, Learning Rate: 0.01\n",
      "Epoch [691/20000], Loss: 465.9252624511719, Entropy -311.9294128417969, Learning Rate: 0.01\n",
      "Epoch [692/20000], Loss: 448.7927551269531, Entropy -317.0868225097656, Learning Rate: 0.01\n",
      "Epoch [693/20000], Loss: 472.0845031738281, Entropy -323.366455078125, Learning Rate: 0.01\n",
      "Epoch [694/20000], Loss: 487.1486511230469, Entropy -321.27630615234375, Learning Rate: 0.01\n",
      "Epoch [695/20000], Loss: 465.64678955078125, Entropy -305.53497314453125, Learning Rate: 0.01\n",
      "Epoch [696/20000], Loss: 481.1716613769531, Entropy -317.7930908203125, Learning Rate: 0.01\n",
      "Epoch [697/20000], Loss: 482.3254089355469, Entropy -307.5072326660156, Learning Rate: 0.01\n",
      "Epoch [698/20000], Loss: 460.65966796875, Entropy -311.1095886230469, Learning Rate: 0.01\n",
      "Epoch [699/20000], Loss: 502.8316345214844, Entropy -307.8128356933594, Learning Rate: 0.01\n",
      "Epoch [700/20000], Loss: 448.47674560546875, Entropy -314.9007568359375, Learning Rate: 0.01\n",
      "Epoch [701/20000], Loss: 497.5705871582031, Entropy -303.8224182128906, Learning Rate: 0.01\n",
      "Epoch [702/20000], Loss: 483.1058654785156, Entropy -309.4335021972656, Learning Rate: 0.01\n",
      "Epoch [703/20000], Loss: 481.4329833984375, Entropy -309.6657409667969, Learning Rate: 0.01\n",
      "Epoch [704/20000], Loss: 496.0075378417969, Entropy -316.2279357910156, Learning Rate: 0.01\n",
      "Epoch [705/20000], Loss: 522.0226440429688, Entropy -308.5736083984375, Learning Rate: 0.01\n",
      "Epoch [706/20000], Loss: 466.8615417480469, Entropy -314.10357666015625, Learning Rate: 0.01\n",
      "Epoch [707/20000], Loss: 440.62750244140625, Entropy -309.45111083984375, Learning Rate: 0.01\n",
      "Epoch [708/20000], Loss: 451.83416748046875, Entropy -310.3066101074219, Learning Rate: 0.01\n",
      "Epoch [709/20000], Loss: 497.46966552734375, Entropy -319.7127685546875, Learning Rate: 0.01\n",
      "Epoch [710/20000], Loss: 417.70587158203125, Entropy -314.8899841308594, Learning Rate: 0.01\n",
      "Epoch [711/20000], Loss: 500.1806335449219, Entropy -309.8393249511719, Learning Rate: 0.01\n",
      "Epoch [712/20000], Loss: 480.91192626953125, Entropy -305.3943786621094, Learning Rate: 0.01\n",
      "Epoch [713/20000], Loss: 493.1042785644531, Entropy -318.03558349609375, Learning Rate: 0.01\n",
      "Epoch [714/20000], Loss: 456.34490966796875, Entropy -313.2397155761719, Learning Rate: 0.01\n",
      "Epoch [715/20000], Loss: 461.8284912109375, Entropy -311.21405029296875, Learning Rate: 0.01\n",
      "Epoch [716/20000], Loss: 435.5240478515625, Entropy -310.5632019042969, Learning Rate: 0.01\n",
      "Epoch [717/20000], Loss: 510.4292297363281, Entropy -303.3242492675781, Learning Rate: 0.01\n",
      "Epoch [718/20000], Loss: 456.14068603515625, Entropy -323.6278076171875, Learning Rate: 0.01\n",
      "Epoch [719/20000], Loss: 506.78021240234375, Entropy -314.206298828125, Learning Rate: 0.01\n",
      "Epoch [720/20000], Loss: 477.9952392578125, Entropy -313.5205993652344, Learning Rate: 0.01\n",
      "Epoch [721/20000], Loss: 445.5953063964844, Entropy -296.8906555175781, Learning Rate: 0.01\n",
      "Epoch [722/20000], Loss: 453.3801574707031, Entropy -308.8103332519531, Learning Rate: 0.01\n",
      "Epoch [723/20000], Loss: 453.98638916015625, Entropy -313.58197021484375, Learning Rate: 0.01\n",
      "Epoch [724/20000], Loss: 455.28778076171875, Entropy -302.45855712890625, Learning Rate: 0.01\n",
      "Epoch [725/20000], Loss: 483.21246337890625, Entropy -313.4549255371094, Learning Rate: 0.01\n",
      "Epoch [726/20000], Loss: 539.2012939453125, Entropy -323.00091552734375, Learning Rate: 0.01\n",
      "Epoch [727/20000], Loss: 472.3516845703125, Entropy -324.2041931152344, Learning Rate: 0.01\n",
      "Epoch [728/20000], Loss: 435.21075439453125, Entropy -310.3614807128906, Learning Rate: 0.01\n",
      "Epoch [729/20000], Loss: 516.1268310546875, Entropy -318.3593444824219, Learning Rate: 0.01\n",
      "Epoch [730/20000], Loss: 480.3247375488281, Entropy -319.27508544921875, Learning Rate: 0.01\n",
      "Epoch [731/20000], Loss: 487.7171325683594, Entropy -307.8757629394531, Learning Rate: 0.01\n",
      "Epoch [732/20000], Loss: 410.6148376464844, Entropy -306.3951721191406, Learning Rate: 0.01\n",
      "Epoch [733/20000], Loss: 426.98907470703125, Entropy -300.843017578125, Learning Rate: 0.01\n",
      "Epoch [734/20000], Loss: 469.2989807128906, Entropy -317.52099609375, Learning Rate: 0.01\n",
      "Epoch [735/20000], Loss: 453.5332946777344, Entropy -311.84991455078125, Learning Rate: 0.01\n",
      "Epoch [736/20000], Loss: 449.9482116699219, Entropy -309.8985900878906, Learning Rate: 0.01\n",
      "Epoch [737/20000], Loss: 455.4429931640625, Entropy -303.64556884765625, Learning Rate: 0.01\n",
      "Epoch [738/20000], Loss: 458.0407409667969, Entropy -304.3695373535156, Learning Rate: 0.01\n",
      "Epoch [739/20000], Loss: 587.6959228515625, Entropy -310.9761657714844, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [740/20000], Loss: 507.2984619140625, Entropy -300.93475341796875, Learning Rate: 0.01\n",
      "Epoch [741/20000], Loss: 445.4347839355469, Entropy -306.8363952636719, Learning Rate: 0.01\n",
      "Epoch [742/20000], Loss: 441.7808532714844, Entropy -308.5944519042969, Learning Rate: 0.01\n",
      "Epoch [743/20000], Loss: 459.0234069824219, Entropy -300.6339416503906, Learning Rate: 0.01\n",
      "Epoch [744/20000], Loss: 475.2225036621094, Entropy -298.0064392089844, Learning Rate: 0.01\n",
      "Epoch [745/20000], Loss: 446.44537353515625, Entropy -304.4190979003906, Learning Rate: 0.01\n",
      "Epoch [746/20000], Loss: 424.1172180175781, Entropy -305.6619873046875, Learning Rate: 0.01\n",
      "Epoch [747/20000], Loss: 452.4306640625, Entropy -313.7783203125, Learning Rate: 0.01\n",
      "Epoch [748/20000], Loss: 456.53466796875, Entropy -299.579345703125, Learning Rate: 0.01\n",
      "Epoch [749/20000], Loss: 494.5725402832031, Entropy -303.8283996582031, Learning Rate: 0.01\n",
      "Epoch [750/20000], Loss: 426.0593566894531, Entropy -296.7239685058594, Learning Rate: 0.01\n",
      "Epoch [751/20000], Loss: 506.5506286621094, Entropy -316.8500061035156, Learning Rate: 0.01\n",
      "Epoch [752/20000], Loss: 418.4139099121094, Entropy -317.404296875, Learning Rate: 0.01\n",
      "Epoch [753/20000], Loss: 418.35284423828125, Entropy -318.102783203125, Learning Rate: 0.01\n",
      "Epoch [754/20000], Loss: 446.69805908203125, Entropy -293.51959228515625, Learning Rate: 0.01\n",
      "Epoch [755/20000], Loss: 421.996337890625, Entropy -302.7497863769531, Learning Rate: 0.01\n",
      "Epoch [756/20000], Loss: 454.67230224609375, Entropy -318.23162841796875, Learning Rate: 0.01\n",
      "Epoch [757/20000], Loss: 442.0281982421875, Entropy -309.369384765625, Learning Rate: 0.01\n",
      "Epoch [758/20000], Loss: 439.7959899902344, Entropy -313.6243896484375, Learning Rate: 0.01\n",
      "Epoch [759/20000], Loss: 423.29656982421875, Entropy -307.6640319824219, Learning Rate: 0.01\n",
      "Epoch [760/20000], Loss: 430.2900390625, Entropy -302.1551513671875, Learning Rate: 0.01\n",
      "Epoch [761/20000], Loss: 465.9599914550781, Entropy -313.7811279296875, Learning Rate: 0.01\n",
      "Epoch [762/20000], Loss: 461.7557678222656, Entropy -302.0436096191406, Learning Rate: 0.01\n",
      "Epoch [763/20000], Loss: 435.8763732910156, Entropy -301.1242980957031, Learning Rate: 0.01\n",
      "Epoch [764/20000], Loss: 453.28753662109375, Entropy -304.8157958984375, Learning Rate: 0.01\n",
      "Epoch [765/20000], Loss: 463.2471008300781, Entropy -307.3209533691406, Learning Rate: 0.01\n",
      "Epoch [766/20000], Loss: 461.8932189941406, Entropy -325.0235290527344, Learning Rate: 0.01\n",
      "Epoch [767/20000], Loss: 457.30426025390625, Entropy -309.9580383300781, Learning Rate: 0.01\n",
      "Epoch [768/20000], Loss: 443.1866455078125, Entropy -310.6717224121094, Learning Rate: 0.01\n",
      "Epoch [769/20000], Loss: 450.7947082519531, Entropy -311.9234313964844, Learning Rate: 0.01\n",
      "Epoch [770/20000], Loss: 452.4067077636719, Entropy -313.1039123535156, Learning Rate: 0.01\n",
      "Epoch [771/20000], Loss: 447.4424743652344, Entropy -308.6197204589844, Learning Rate: 0.01\n",
      "Epoch [772/20000], Loss: 426.861083984375, Entropy -306.38970947265625, Learning Rate: 0.01\n",
      "Epoch [773/20000], Loss: 432.4820556640625, Entropy -305.6761169433594, Learning Rate: 0.01\n",
      "Epoch [774/20000], Loss: 450.2959289550781, Entropy -311.2088928222656, Learning Rate: 0.01\n",
      "Epoch [775/20000], Loss: 443.7830505371094, Entropy -300.2682800292969, Learning Rate: 0.01\n",
      "Epoch [776/20000], Loss: 458.30230712890625, Entropy -305.3501892089844, Learning Rate: 0.01\n",
      "Epoch [777/20000], Loss: 450.0295715332031, Entropy -297.1693115234375, Learning Rate: 0.01\n",
      "Epoch [778/20000], Loss: 487.90228271484375, Entropy -321.4539489746094, Learning Rate: 0.01\n",
      "Epoch [779/20000], Loss: 447.1377868652344, Entropy -314.4365234375, Learning Rate: 0.01\n",
      "Epoch [780/20000], Loss: 434.5990295410156, Entropy -302.7041320800781, Learning Rate: 0.01\n",
      "Epoch [781/20000], Loss: 402.660400390625, Entropy -304.4585266113281, Learning Rate: 0.01\n",
      "Epoch [782/20000], Loss: 452.1282653808594, Entropy -315.473388671875, Learning Rate: 0.01\n",
      "Epoch [783/20000], Loss: 407.85406494140625, Entropy -309.21405029296875, Learning Rate: 0.01\n",
      "Epoch [784/20000], Loss: 438.5121154785156, Entropy -313.46759033203125, Learning Rate: 0.01\n",
      "Epoch [785/20000], Loss: 426.8085632324219, Entropy -307.1684265136719, Learning Rate: 0.01\n",
      "Epoch [786/20000], Loss: 449.9617004394531, Entropy -316.16314697265625, Learning Rate: 0.01\n",
      "Epoch [787/20000], Loss: 399.5289306640625, Entropy -301.1258544921875, Learning Rate: 0.01\n",
      "Epoch [788/20000], Loss: 407.6059265136719, Entropy -302.56549072265625, Learning Rate: 0.01\n",
      "Epoch [789/20000], Loss: 404.6824645996094, Entropy -306.1812744140625, Learning Rate: 0.01\n",
      "Epoch [790/20000], Loss: 418.5638427734375, Entropy -308.9594421386719, Learning Rate: 0.01\n",
      "Epoch [791/20000], Loss: 402.33966064453125, Entropy -308.06365966796875, Learning Rate: 0.01\n",
      "Epoch [792/20000], Loss: 433.52777099609375, Entropy -305.96246337890625, Learning Rate: 0.01\n",
      "Epoch [793/20000], Loss: 445.52777099609375, Entropy -309.72967529296875, Learning Rate: 0.01\n",
      "Epoch [794/20000], Loss: 408.2818908691406, Entropy -306.4004211425781, Learning Rate: 0.01\n",
      "Epoch [795/20000], Loss: 405.0646057128906, Entropy -307.3537292480469, Learning Rate: 0.01\n",
      "Epoch [796/20000], Loss: 421.79608154296875, Entropy -314.9432373046875, Learning Rate: 0.01\n",
      "Epoch [797/20000], Loss: 392.20880126953125, Entropy -303.0883483886719, Learning Rate: 0.01\n",
      "Epoch [798/20000], Loss: 409.7532043457031, Entropy -311.31842041015625, Learning Rate: 0.01\n",
      "Epoch [799/20000], Loss: 406.6842041015625, Entropy -300.7718505859375, Learning Rate: 0.01\n",
      "Epoch [800/20000], Loss: 405.1200256347656, Entropy -303.5465087890625, Learning Rate: 0.01\n",
      "Epoch [801/20000], Loss: 402.71087646484375, Entropy -311.72833251953125, Learning Rate: 0.01\n",
      "Epoch [802/20000], Loss: 416.8758850097656, Entropy -304.2004699707031, Learning Rate: 0.01\n",
      "Epoch [803/20000], Loss: 400.3828125, Entropy -298.4454650878906, Learning Rate: 0.01\n",
      "Epoch [804/20000], Loss: 407.94158935546875, Entropy -303.6582946777344, Learning Rate: 0.01\n",
      "Epoch [805/20000], Loss: 413.4630432128906, Entropy -311.850830078125, Learning Rate: 0.01\n",
      "Epoch [806/20000], Loss: 418.09759521484375, Entropy -320.02294921875, Learning Rate: 0.01\n",
      "Epoch [807/20000], Loss: 406.6331787109375, Entropy -298.87359619140625, Learning Rate: 0.01\n",
      "Epoch [808/20000], Loss: 416.0777587890625, Entropy -306.4638671875, Learning Rate: 0.01\n",
      "Epoch [809/20000], Loss: 412.2005920410156, Entropy -312.56207275390625, Learning Rate: 0.01\n",
      "Epoch [810/20000], Loss: 428.71112060546875, Entropy -311.84210205078125, Learning Rate: 0.01\n",
      "Epoch [811/20000], Loss: 400.5185546875, Entropy -314.836669921875, Learning Rate: 0.01\n",
      "Epoch [812/20000], Loss: 407.8678283691406, Entropy -296.86968994140625, Learning Rate: 0.01\n",
      "Epoch [813/20000], Loss: 444.5110778808594, Entropy -310.0052795410156, Learning Rate: 0.01\n",
      "Epoch [814/20000], Loss: 425.2884216308594, Entropy -307.6409606933594, Learning Rate: 0.01\n",
      "Epoch [815/20000], Loss: 409.541748046875, Entropy -302.30303955078125, Learning Rate: 0.01\n",
      "Epoch [816/20000], Loss: 393.843017578125, Entropy -311.400146484375, Learning Rate: 0.01\n",
      "Epoch [817/20000], Loss: 409.6941833496094, Entropy -304.1076965332031, Learning Rate: 0.01\n",
      "Epoch [818/20000], Loss: 407.23175048828125, Entropy -303.0970764160156, Learning Rate: 0.01\n",
      "Epoch [819/20000], Loss: 409.5192565917969, Entropy -310.5984802246094, Learning Rate: 0.01\n",
      "Epoch [820/20000], Loss: 406.3958740234375, Entropy -311.69219970703125, Learning Rate: 0.01\n",
      "Epoch [821/20000], Loss: 428.776123046875, Entropy -312.1368713378906, Learning Rate: 0.01\n",
      "Epoch [822/20000], Loss: 406.9250183105469, Entropy -311.3194885253906, Learning Rate: 0.01\n",
      "Epoch [823/20000], Loss: 377.13330078125, Entropy -305.5146789550781, Learning Rate: 0.01\n",
      "Epoch [824/20000], Loss: 415.3059387207031, Entropy -303.7246398925781, Learning Rate: 0.01\n",
      "Epoch [825/20000], Loss: 425.72930908203125, Entropy -307.4045104980469, Learning Rate: 0.01\n",
      "Epoch [826/20000], Loss: 403.2340393066406, Entropy -301.53277587890625, Learning Rate: 0.01\n",
      "Epoch [827/20000], Loss: 445.8148498535156, Entropy -308.0728454589844, Learning Rate: 0.01\n",
      "Epoch [828/20000], Loss: 417.97857666015625, Entropy -309.01416015625, Learning Rate: 0.01\n",
      "Epoch [829/20000], Loss: 435.2430725097656, Entropy -307.6544494628906, Learning Rate: 0.01\n",
      "Epoch [830/20000], Loss: 418.3761291503906, Entropy -300.4089050292969, Learning Rate: 0.01\n",
      "Epoch [831/20000], Loss: 469.735107421875, Entropy -310.6146545410156, Learning Rate: 0.01\n",
      "Epoch [832/20000], Loss: 417.32666015625, Entropy -323.7676086425781, Learning Rate: 0.01\n",
      "Epoch [833/20000], Loss: 444.1634826660156, Entropy -303.4426574707031, Learning Rate: 0.01\n",
      "Epoch [834/20000], Loss: 419.6899719238281, Entropy -302.251220703125, Learning Rate: 0.01\n",
      "Epoch [835/20000], Loss: 420.70452880859375, Entropy -313.99774169921875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [836/20000], Loss: 402.12713623046875, Entropy -304.7756652832031, Learning Rate: 0.01\n",
      "Epoch [837/20000], Loss: 432.707275390625, Entropy -298.1007080078125, Learning Rate: 0.01\n",
      "Epoch [838/20000], Loss: 390.9140625, Entropy -303.8779296875, Learning Rate: 0.01\n",
      "Epoch [839/20000], Loss: 491.19683837890625, Entropy -305.9703674316406, Learning Rate: 0.01\n",
      "Epoch [840/20000], Loss: 459.0841064453125, Entropy -310.8755187988281, Learning Rate: 0.01\n",
      "Epoch [841/20000], Loss: 434.41619873046875, Entropy -305.7409362792969, Learning Rate: 0.01\n",
      "Epoch [842/20000], Loss: 421.26910400390625, Entropy -309.8941345214844, Learning Rate: 0.01\n",
      "Epoch [843/20000], Loss: 446.0752868652344, Entropy -295.4693298339844, Learning Rate: 0.01\n",
      "Epoch [844/20000], Loss: 425.062744140625, Entropy -303.3408508300781, Learning Rate: 0.01\n",
      "Epoch [845/20000], Loss: 431.7080383300781, Entropy -306.7557067871094, Learning Rate: 0.01\n",
      "Epoch [846/20000], Loss: 430.55426025390625, Entropy -302.69427490234375, Learning Rate: 0.01\n",
      "Epoch [847/20000], Loss: 424.4131774902344, Entropy -307.8724060058594, Learning Rate: 0.01\n",
      "Epoch [848/20000], Loss: 410.93963623046875, Entropy -294.381103515625, Learning Rate: 0.01\n",
      "Epoch [849/20000], Loss: 461.0199279785156, Entropy -302.4671325683594, Learning Rate: 0.01\n",
      "Epoch [850/20000], Loss: 412.27886962890625, Entropy -303.2276306152344, Learning Rate: 0.01\n",
      "Epoch [851/20000], Loss: 521.7008056640625, Entropy -303.1854553222656, Learning Rate: 0.01\n",
      "Epoch [852/20000], Loss: 393.9745788574219, Entropy -302.7015686035156, Learning Rate: 0.01\n",
      "Epoch [853/20000], Loss: 537.5551147460938, Entropy -315.7872314453125, Learning Rate: 0.01\n",
      "Epoch [854/20000], Loss: 397.07373046875, Entropy -312.62371826171875, Learning Rate: 0.01\n",
      "Epoch [855/20000], Loss: 510.631103515625, Entropy -300.44598388671875, Learning Rate: 0.01\n",
      "Epoch [856/20000], Loss: 436.6861572265625, Entropy -298.2830810546875, Learning Rate: 0.01\n",
      "Epoch [857/20000], Loss: 552.5821533203125, Entropy -307.15289306640625, Learning Rate: 0.01\n",
      "Epoch [858/20000], Loss: 450.1731872558594, Entropy -301.40863037109375, Learning Rate: 0.01\n",
      "Epoch [859/20000], Loss: 526.12451171875, Entropy -293.3321228027344, Learning Rate: 0.01\n",
      "Epoch [860/20000], Loss: 424.5635681152344, Entropy -305.1350402832031, Learning Rate: 0.01\n",
      "Epoch [861/20000], Loss: 539.778076171875, Entropy -293.929931640625, Learning Rate: 0.01\n",
      "Epoch [862/20000], Loss: 503.29095458984375, Entropy -294.7770690917969, Learning Rate: 0.01\n",
      "Epoch [863/20000], Loss: 433.2890930175781, Entropy -295.1962890625, Learning Rate: 0.01\n",
      "Epoch [864/20000], Loss: 502.37615966796875, Entropy -301.46343994140625, Learning Rate: 0.01\n",
      "Epoch [865/20000], Loss: 480.92730712890625, Entropy -299.2293701171875, Learning Rate: 0.01\n",
      "Epoch [866/20000], Loss: 528.4160766601562, Entropy -305.8106994628906, Learning Rate: 0.01\n",
      "Epoch [867/20000], Loss: 460.4310302734375, Entropy -309.265625, Learning Rate: 0.01\n",
      "Epoch [868/20000], Loss: 484.6479187011719, Entropy -306.36871337890625, Learning Rate: 0.01\n",
      "Epoch [869/20000], Loss: 481.7507019042969, Entropy -290.0602722167969, Learning Rate: 0.01\n",
      "Epoch [870/20000], Loss: 493.76141357421875, Entropy -300.00909423828125, Learning Rate: 0.01\n",
      "Epoch [871/20000], Loss: 515.9525756835938, Entropy -301.10687255859375, Learning Rate: 0.01\n",
      "Epoch [872/20000], Loss: 421.891845703125, Entropy -295.513427734375, Learning Rate: 0.01\n",
      "Epoch [873/20000], Loss: 494.6756286621094, Entropy -299.1532287597656, Learning Rate: 0.01\n",
      "Epoch [874/20000], Loss: 442.0887451171875, Entropy -305.5611877441406, Learning Rate: 0.01\n",
      "Epoch [875/20000], Loss: 425.4519348144531, Entropy -304.3150634765625, Learning Rate: 0.01\n",
      "Epoch [876/20000], Loss: 456.7786865234375, Entropy -302.8671875, Learning Rate: 0.01\n",
      "Epoch [877/20000], Loss: 433.348388671875, Entropy -292.89947509765625, Learning Rate: 0.01\n",
      "Epoch [878/20000], Loss: 499.3855895996094, Entropy -297.7743835449219, Learning Rate: 0.01\n",
      "Epoch [879/20000], Loss: 414.80078125, Entropy -309.2226867675781, Learning Rate: 0.01\n",
      "Epoch [880/20000], Loss: 495.9669494628906, Entropy -306.8255615234375, Learning Rate: 0.01\n",
      "Epoch [881/20000], Loss: 415.6402282714844, Entropy -295.37249755859375, Learning Rate: 0.01\n",
      "Epoch [882/20000], Loss: 496.5089111328125, Entropy -291.4371337890625, Learning Rate: 0.01\n",
      "Epoch [883/20000], Loss: 515.1082763671875, Entropy -292.1673889160156, Learning Rate: 0.01\n",
      "Epoch [884/20000], Loss: 446.1355285644531, Entropy -301.5662536621094, Learning Rate: 0.01\n",
      "Epoch [885/20000], Loss: 399.2633056640625, Entropy -298.344970703125, Learning Rate: 0.01\n",
      "Epoch [886/20000], Loss: 466.2231140136719, Entropy -297.3139953613281, Learning Rate: 0.01\n",
      "Epoch [887/20000], Loss: 500.3589172363281, Entropy -295.92864990234375, Learning Rate: 0.01\n",
      "Epoch [888/20000], Loss: 403.5938415527344, Entropy -299.006591796875, Learning Rate: 0.01\n",
      "Epoch [889/20000], Loss: 480.2541809082031, Entropy -294.6261291503906, Learning Rate: 0.01\n",
      "Epoch [890/20000], Loss: 480.504638671875, Entropy -293.59002685546875, Learning Rate: 0.01\n",
      "Epoch [891/20000], Loss: 430.39892578125, Entropy -295.5115966796875, Learning Rate: 0.01\n",
      "Epoch [892/20000], Loss: 425.7352600097656, Entropy -306.4823913574219, Learning Rate: 0.01\n",
      "Epoch [893/20000], Loss: 439.3065185546875, Entropy -302.8695983886719, Learning Rate: 0.01\n",
      "Epoch [894/20000], Loss: 427.291259765625, Entropy -298.7908020019531, Learning Rate: 0.01\n",
      "Epoch [895/20000], Loss: 443.37646484375, Entropy -303.5064392089844, Learning Rate: 0.01\n",
      "Epoch [896/20000], Loss: 482.87432861328125, Entropy -306.39654541015625, Learning Rate: 0.01\n",
      "Epoch [897/20000], Loss: 428.84356689453125, Entropy -300.5057373046875, Learning Rate: 0.01\n",
      "Epoch [898/20000], Loss: 414.8287353515625, Entropy -292.3038330078125, Learning Rate: 0.01\n",
      "Epoch [899/20000], Loss: 484.0726318359375, Entropy -289.1356506347656, Learning Rate: 0.01\n",
      "Epoch [900/20000], Loss: 485.39910888671875, Entropy -297.09503173828125, Learning Rate: 0.01\n",
      "Epoch [901/20000], Loss: 413.5185241699219, Entropy -293.1620788574219, Learning Rate: 0.01\n",
      "Epoch [902/20000], Loss: 440.50421142578125, Entropy -295.3158264160156, Learning Rate: 0.01\n",
      "Epoch [903/20000], Loss: 411.6908874511719, Entropy -298.2042236328125, Learning Rate: 0.01\n",
      "Epoch [904/20000], Loss: 419.8569641113281, Entropy -306.773193359375, Learning Rate: 0.01\n",
      "Epoch [905/20000], Loss: 395.36114501953125, Entropy -307.7579040527344, Learning Rate: 0.01\n",
      "Epoch [906/20000], Loss: 393.1239013671875, Entropy -296.87939453125, Learning Rate: 0.01\n",
      "Epoch [907/20000], Loss: 416.49774169921875, Entropy -310.7587585449219, Learning Rate: 0.01\n",
      "Epoch [908/20000], Loss: 362.55828857421875, Entropy -306.7678527832031, Learning Rate: 0.01\n",
      "Epoch [909/20000], Loss: 433.8571472167969, Entropy -302.4237976074219, Learning Rate: 0.01\n",
      "Epoch [910/20000], Loss: 417.8065185546875, Entropy -305.105712890625, Learning Rate: 0.01\n",
      "Epoch [911/20000], Loss: 394.49530029296875, Entropy -303.2630310058594, Learning Rate: 0.01\n",
      "Epoch [912/20000], Loss: 412.1475524902344, Entropy -315.6575622558594, Learning Rate: 0.01\n",
      "Epoch [913/20000], Loss: 403.43853759765625, Entropy -302.5769348144531, Learning Rate: 0.01\n",
      "Epoch [914/20000], Loss: 409.8597106933594, Entropy -298.5706787109375, Learning Rate: 0.01\n",
      "Epoch [915/20000], Loss: 369.323486328125, Entropy -304.2925109863281, Learning Rate: 0.01\n",
      "Epoch [916/20000], Loss: 403.72564697265625, Entropy -316.30572509765625, Learning Rate: 0.01\n",
      "Epoch [917/20000], Loss: 403.37506103515625, Entropy -303.634765625, Learning Rate: 0.01\n",
      "Epoch [918/20000], Loss: 372.7135925292969, Entropy -301.20892333984375, Learning Rate: 0.01\n",
      "Epoch [919/20000], Loss: 379.06982421875, Entropy -307.19873046875, Learning Rate: 0.01\n",
      "Epoch [920/20000], Loss: 377.5359802246094, Entropy -297.8207092285156, Learning Rate: 0.01\n",
      "Epoch [921/20000], Loss: 411.6298828125, Entropy -301.63458251953125, Learning Rate: 0.01\n",
      "Epoch [922/20000], Loss: 401.7056884765625, Entropy -306.3587646484375, Learning Rate: 0.01\n",
      "Epoch [923/20000], Loss: 389.23077392578125, Entropy -301.233642578125, Learning Rate: 0.01\n",
      "Epoch [924/20000], Loss: 393.50531005859375, Entropy -309.1162414550781, Learning Rate: 0.01\n",
      "Epoch [925/20000], Loss: 376.2705383300781, Entropy -309.1130676269531, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [926/20000], Loss: 377.2156982421875, Entropy -305.57220458984375, Learning Rate: 0.01\n",
      "Epoch [927/20000], Loss: 374.24456787109375, Entropy -298.1004638671875, Learning Rate: 0.01\n",
      "Epoch [928/20000], Loss: 389.873046875, Entropy -307.0273132324219, Learning Rate: 0.01\n",
      "Epoch [929/20000], Loss: 373.3970947265625, Entropy -302.01171875, Learning Rate: 0.01\n",
      "Epoch [930/20000], Loss: 368.7176818847656, Entropy -303.95440673828125, Learning Rate: 0.01\n",
      "Epoch [931/20000], Loss: 411.636474609375, Entropy -296.4813537597656, Learning Rate: 0.01\n",
      "Epoch [932/20000], Loss: 395.028076171875, Entropy -295.0154113769531, Learning Rate: 0.01\n",
      "Epoch [933/20000], Loss: 413.4057312011719, Entropy -305.8996887207031, Learning Rate: 0.01\n",
      "Epoch [934/20000], Loss: 444.5777893066406, Entropy -298.8409423828125, Learning Rate: 0.01\n",
      "Epoch [935/20000], Loss: 430.3473815917969, Entropy -295.05364990234375, Learning Rate: 0.01\n",
      "Epoch [936/20000], Loss: 424.95355224609375, Entropy -300.84832763671875, Learning Rate: 0.01\n",
      "Epoch [937/20000], Loss: 423.34039306640625, Entropy -298.54119873046875, Learning Rate: 0.01\n",
      "Epoch [938/20000], Loss: 414.42022705078125, Entropy -297.8713073730469, Learning Rate: 0.01\n",
      "Epoch [939/20000], Loss: 377.1474914550781, Entropy -305.4147644042969, Learning Rate: 0.01\n",
      "Epoch [940/20000], Loss: 399.8438720703125, Entropy -291.1104431152344, Learning Rate: 0.01\n",
      "Epoch [941/20000], Loss: 398.7101745605469, Entropy -287.3765869140625, Learning Rate: 0.01\n",
      "Epoch [942/20000], Loss: 421.0780029296875, Entropy -305.2747497558594, Learning Rate: 0.01\n",
      "Epoch [943/20000], Loss: 443.301025390625, Entropy -301.65277099609375, Learning Rate: 0.01\n",
      "Epoch [944/20000], Loss: 365.90081787109375, Entropy -301.7689208984375, Learning Rate: 0.01\n",
      "Epoch [945/20000], Loss: 396.35015869140625, Entropy -292.7349548339844, Learning Rate: 0.01\n",
      "Epoch [946/20000], Loss: 424.63458251953125, Entropy -300.76641845703125, Learning Rate: 0.01\n",
      "Epoch [947/20000], Loss: 393.68975830078125, Entropy -300.305419921875, Learning Rate: 0.01\n",
      "Epoch [948/20000], Loss: 415.0294189453125, Entropy -299.72637939453125, Learning Rate: 0.01\n",
      "Epoch [949/20000], Loss: 387.8436584472656, Entropy -308.03759765625, Learning Rate: 0.01\n",
      "Epoch [950/20000], Loss: 411.14697265625, Entropy -297.6102600097656, Learning Rate: 0.01\n",
      "Epoch [951/20000], Loss: 387.56719970703125, Entropy -295.14984130859375, Learning Rate: 0.01\n",
      "Epoch [952/20000], Loss: 411.052490234375, Entropy -291.6661682128906, Learning Rate: 0.01\n",
      "Epoch [953/20000], Loss: 430.6249694824219, Entropy -305.0191650390625, Learning Rate: 0.01\n",
      "Epoch [954/20000], Loss: 373.66766357421875, Entropy -301.98016357421875, Learning Rate: 0.01\n",
      "Epoch [955/20000], Loss: 427.4932556152344, Entropy -291.9551696777344, Learning Rate: 0.01\n",
      "Epoch [956/20000], Loss: 443.6896667480469, Entropy -302.2880859375, Learning Rate: 0.01\n",
      "Epoch [957/20000], Loss: 391.39385986328125, Entropy -297.07159423828125, Learning Rate: 0.01\n",
      "Epoch [958/20000], Loss: 403.45526123046875, Entropy -298.700927734375, Learning Rate: 0.01\n",
      "Epoch [959/20000], Loss: 417.9107666015625, Entropy -295.9295654296875, Learning Rate: 0.01\n",
      "Epoch [960/20000], Loss: 447.75421142578125, Entropy -299.851318359375, Learning Rate: 0.01\n",
      "Epoch [961/20000], Loss: 401.7887268066406, Entropy -294.6810607910156, Learning Rate: 0.01\n",
      "Epoch [962/20000], Loss: 389.2058410644531, Entropy -299.70819091796875, Learning Rate: 0.01\n",
      "Epoch [963/20000], Loss: 453.27056884765625, Entropy -310.6800537109375, Learning Rate: 0.01\n",
      "Epoch [964/20000], Loss: 497.79730224609375, Entropy -297.966796875, Learning Rate: 0.01\n",
      "Epoch [965/20000], Loss: 423.64752197265625, Entropy -307.1491394042969, Learning Rate: 0.01\n",
      "Epoch [966/20000], Loss: 432.2073669433594, Entropy -299.5889587402344, Learning Rate: 0.01\n",
      "Epoch [967/20000], Loss: 530.2398071289062, Entropy -298.54669189453125, Learning Rate: 0.01\n",
      "Epoch [968/20000], Loss: 566.646484375, Entropy -300.6085510253906, Learning Rate: 0.01\n",
      "Epoch [969/20000], Loss: 398.0495300292969, Entropy -298.4312438964844, Learning Rate: 0.01\n",
      "Epoch [970/20000], Loss: 579.814697265625, Entropy -304.41766357421875, Learning Rate: 0.01\n",
      "Epoch [971/20000], Loss: 429.4981994628906, Entropy -302.25665283203125, Learning Rate: 0.01\n",
      "Epoch [972/20000], Loss: 554.8416748046875, Entropy -294.57366943359375, Learning Rate: 0.01\n",
      "Epoch [973/20000], Loss: 414.7273864746094, Entropy -288.3023986816406, Learning Rate: 0.01\n",
      "Epoch [974/20000], Loss: 457.2300720214844, Entropy -286.75506591796875, Learning Rate: 0.01\n",
      "Epoch [975/20000], Loss: 446.5106201171875, Entropy -293.9859313964844, Learning Rate: 0.01\n",
      "Epoch [976/20000], Loss: 420.7916564941406, Entropy -300.6389465332031, Learning Rate: 0.01\n",
      "Epoch [977/20000], Loss: 383.246826171875, Entropy -297.331787109375, Learning Rate: 0.01\n",
      "Epoch [978/20000], Loss: 417.924072265625, Entropy -287.8824768066406, Learning Rate: 0.01\n",
      "Epoch [979/20000], Loss: 440.7457275390625, Entropy -297.73980712890625, Learning Rate: 0.01\n",
      "Epoch [980/20000], Loss: 424.6252136230469, Entropy -303.93157958984375, Learning Rate: 0.01\n",
      "Epoch [981/20000], Loss: 398.142578125, Entropy -302.2689514160156, Learning Rate: 0.01\n",
      "Epoch [982/20000], Loss: 396.76397705078125, Entropy -297.9962158203125, Learning Rate: 0.01\n",
      "Epoch [983/20000], Loss: 391.519775390625, Entropy -304.3587341308594, Learning Rate: 0.01\n",
      "Epoch [984/20000], Loss: 378.3550720214844, Entropy -304.2257385253906, Learning Rate: 0.01\n",
      "Epoch [985/20000], Loss: 367.3839111328125, Entropy -300.9026794433594, Learning Rate: 0.01\n",
      "Epoch [986/20000], Loss: 385.6539306640625, Entropy -298.36395263671875, Learning Rate: 0.01\n",
      "Epoch [987/20000], Loss: 372.3230285644531, Entropy -305.051025390625, Learning Rate: 0.01\n",
      "Epoch [988/20000], Loss: 441.4713439941406, Entropy -303.09368896484375, Learning Rate: 0.01\n",
      "Epoch [989/20000], Loss: 432.5638122558594, Entropy -311.35015869140625, Learning Rate: 0.01\n",
      "Epoch [990/20000], Loss: 445.7187805175781, Entropy -304.4527587890625, Learning Rate: 0.01\n",
      "Epoch [991/20000], Loss: 408.6744384765625, Entropy -302.2630920410156, Learning Rate: 0.01\n",
      "Epoch [992/20000], Loss: 381.2738037109375, Entropy -301.32537841796875, Learning Rate: 0.01\n",
      "Epoch [993/20000], Loss: 415.7701110839844, Entropy -298.00732421875, Learning Rate: 0.01\n",
      "Epoch [994/20000], Loss: 380.05218505859375, Entropy -304.4723815917969, Learning Rate: 0.01\n",
      "Epoch [995/20000], Loss: 430.2707824707031, Entropy -306.8172607421875, Learning Rate: 0.01\n",
      "Epoch [996/20000], Loss: 391.20806884765625, Entropy -299.8619079589844, Learning Rate: 0.01\n",
      "Epoch [997/20000], Loss: 387.4166259765625, Entropy -295.4460144042969, Learning Rate: 0.01\n",
      "Epoch [998/20000], Loss: 397.7401428222656, Entropy -286.54095458984375, Learning Rate: 0.01\n",
      "Epoch [999/20000], Loss: 477.0685119628906, Entropy -295.8476257324219, Learning Rate: 0.01\n",
      "Epoch [1000/20000], Loss: 369.49066162109375, Entropy -299.1353759765625, Learning Rate: 0.01\n",
      "Epoch [1001/20000], Loss: 433.4701843261719, Entropy -297.5978088378906, Learning Rate: 0.01\n",
      "Epoch [1002/20000], Loss: 438.0005798339844, Entropy -300.0003967285156, Learning Rate: 0.01\n",
      "Epoch [1003/20000], Loss: 482.6493835449219, Entropy -291.7653503417969, Learning Rate: 0.01\n",
      "Epoch [1004/20000], Loss: 385.30816650390625, Entropy -297.6810302734375, Learning Rate: 0.01\n",
      "Epoch [1005/20000], Loss: 388.9018859863281, Entropy -299.92083740234375, Learning Rate: 0.01\n",
      "Epoch [1006/20000], Loss: 395.61053466796875, Entropy -294.13568115234375, Learning Rate: 0.01\n",
      "Epoch [1007/20000], Loss: 418.3808288574219, Entropy -289.7642517089844, Learning Rate: 0.01\n",
      "Epoch [1008/20000], Loss: 457.9623107910156, Entropy -302.9592590332031, Learning Rate: 0.01\n",
      "Epoch [1009/20000], Loss: 382.18328857421875, Entropy -294.8818664550781, Learning Rate: 0.01\n",
      "Epoch [1010/20000], Loss: 415.531494140625, Entropy -306.7623596191406, Learning Rate: 0.01\n",
      "Epoch [1011/20000], Loss: 422.4456787109375, Entropy -292.1092529296875, Learning Rate: 0.01\n",
      "Epoch [1012/20000], Loss: 417.68328857421875, Entropy -296.9383544921875, Learning Rate: 0.01\n",
      "Epoch [1013/20000], Loss: 357.46649169921875, Entropy -291.0313720703125, Learning Rate: 0.01\n",
      "Epoch [1014/20000], Loss: 408.571044921875, Entropy -294.431640625, Learning Rate: 0.01\n",
      "Epoch [1015/20000], Loss: 403.6304016113281, Entropy -295.26776123046875, Learning Rate: 0.01\n",
      "Epoch [1016/20000], Loss: 382.2937316894531, Entropy -299.21270751953125, Learning Rate: 0.01\n",
      "Epoch [1017/20000], Loss: 389.4683837890625, Entropy -306.89141845703125, Learning Rate: 0.01\n",
      "Epoch [1018/20000], Loss: 364.8201904296875, Entropy -296.4327392578125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1019/20000], Loss: 378.5650634765625, Entropy -302.3364562988281, Learning Rate: 0.01\n",
      "Epoch [1020/20000], Loss: 355.5525207519531, Entropy -295.81854248046875, Learning Rate: 0.01\n",
      "Epoch [1021/20000], Loss: 360.90863037109375, Entropy -285.7655334472656, Learning Rate: 0.01\n",
      "Epoch [1022/20000], Loss: 408.14788818359375, Entropy -301.5827331542969, Learning Rate: 0.01\n",
      "Epoch [1023/20000], Loss: 373.4361572265625, Entropy -299.1121826171875, Learning Rate: 0.01\n",
      "Epoch [1024/20000], Loss: 387.00885009765625, Entropy -309.55328369140625, Learning Rate: 0.01\n",
      "Epoch [1025/20000], Loss: 392.57196044921875, Entropy -290.30645751953125, Learning Rate: 0.01\n",
      "Epoch [1026/20000], Loss: 369.63763427734375, Entropy -312.4107971191406, Learning Rate: 0.01\n",
      "Epoch [1027/20000], Loss: 353.6659240722656, Entropy -291.81109619140625, Learning Rate: 0.01\n",
      "Epoch [1028/20000], Loss: 361.338134765625, Entropy -289.7742614746094, Learning Rate: 0.01\n",
      "Epoch [1029/20000], Loss: 363.97467041015625, Entropy -305.5037536621094, Learning Rate: 0.01\n",
      "Epoch [1030/20000], Loss: 366.41375732421875, Entropy -302.19091796875, Learning Rate: 0.01\n",
      "Epoch [1031/20000], Loss: 352.6512145996094, Entropy -290.7195129394531, Learning Rate: 0.01\n",
      "Epoch [1032/20000], Loss: 376.0940246582031, Entropy -302.6898498535156, Learning Rate: 0.01\n",
      "Epoch [1033/20000], Loss: 347.1741638183594, Entropy -293.46661376953125, Learning Rate: 0.01\n",
      "Epoch [1034/20000], Loss: 373.6226501464844, Entropy -299.9615478515625, Learning Rate: 0.01\n",
      "Epoch [1035/20000], Loss: 375.4450378417969, Entropy -297.5164489746094, Learning Rate: 0.01\n",
      "Epoch [1036/20000], Loss: 374.953857421875, Entropy -301.4232482910156, Learning Rate: 0.01\n",
      "Epoch [1037/20000], Loss: 386.7954406738281, Entropy -292.1099853515625, Learning Rate: 0.01\n",
      "Epoch [1038/20000], Loss: 416.4457092285156, Entropy -294.70904541015625, Learning Rate: 0.01\n",
      "Epoch [1039/20000], Loss: 354.8437805175781, Entropy -301.2069091796875, Learning Rate: 0.01\n",
      "Epoch [1040/20000], Loss: 393.0504455566406, Entropy -295.4743347167969, Learning Rate: 0.01\n",
      "Epoch [1041/20000], Loss: 414.1209411621094, Entropy -304.27960205078125, Learning Rate: 0.01\n",
      "Epoch [1042/20000], Loss: 348.51763916015625, Entropy -312.63470458984375, Learning Rate: 0.01\n",
      "Epoch [1043/20000], Loss: 376.60479736328125, Entropy -309.3335266113281, Learning Rate: 0.01\n",
      "Epoch [1044/20000], Loss: 371.09478759765625, Entropy -300.269287109375, Learning Rate: 0.01\n",
      "Epoch [1045/20000], Loss: 371.8822021484375, Entropy -312.5887756347656, Learning Rate: 0.01\n",
      "Epoch [1046/20000], Loss: 378.6601867675781, Entropy -294.75347900390625, Learning Rate: 0.01\n",
      "Epoch [1047/20000], Loss: 356.7809143066406, Entropy -287.89520263671875, Learning Rate: 0.01\n",
      "Epoch [1048/20000], Loss: 373.19696044921875, Entropy -297.5123596191406, Learning Rate: 0.01\n",
      "Epoch [1049/20000], Loss: 384.3730773925781, Entropy -301.78546142578125, Learning Rate: 0.01\n",
      "Epoch [1050/20000], Loss: 346.61248779296875, Entropy -295.9948425292969, Learning Rate: 0.01\n",
      "Epoch [1051/20000], Loss: 352.4989013671875, Entropy -283.8351135253906, Learning Rate: 0.01\n",
      "Epoch [1052/20000], Loss: 366.10919189453125, Entropy -293.6914367675781, Learning Rate: 0.01\n",
      "Epoch [1053/20000], Loss: 395.8899841308594, Entropy -291.8305969238281, Learning Rate: 0.01\n",
      "Epoch [1054/20000], Loss: 391.1183166503906, Entropy -297.642333984375, Learning Rate: 0.01\n",
      "Epoch [1055/20000], Loss: 351.26361083984375, Entropy -307.44842529296875, Learning Rate: 0.01\n",
      "Epoch [1056/20000], Loss: 412.0675354003906, Entropy -297.8624267578125, Learning Rate: 0.01\n",
      "Epoch [1057/20000], Loss: 343.0127258300781, Entropy -284.5640869140625, Learning Rate: 0.01\n",
      "Epoch [1058/20000], Loss: 379.1053466796875, Entropy -289.341064453125, Learning Rate: 0.01\n",
      "Epoch [1059/20000], Loss: 354.66192626953125, Entropy -294.33544921875, Learning Rate: 0.01\n",
      "Epoch [1060/20000], Loss: 383.29815673828125, Entropy -289.0963439941406, Learning Rate: 0.01\n",
      "Epoch [1061/20000], Loss: 371.9888610839844, Entropy -298.6891174316406, Learning Rate: 0.01\n",
      "Epoch [1062/20000], Loss: 349.423828125, Entropy -287.4861755371094, Learning Rate: 0.01\n",
      "Epoch [1063/20000], Loss: 387.5774230957031, Entropy -287.149169921875, Learning Rate: 0.01\n",
      "Epoch [1064/20000], Loss: 356.7294616699219, Entropy -289.3109130859375, Learning Rate: 0.01\n",
      "Epoch [1065/20000], Loss: 367.34326171875, Entropy -293.13385009765625, Learning Rate: 0.01\n",
      "Epoch [1066/20000], Loss: 380.78668212890625, Entropy -292.4546203613281, Learning Rate: 0.01\n",
      "Epoch [1067/20000], Loss: 363.333251953125, Entropy -299.6767578125, Learning Rate: 0.01\n",
      "Epoch [1068/20000], Loss: 395.9267272949219, Entropy -293.66656494140625, Learning Rate: 0.01\n",
      "Epoch [1069/20000], Loss: 370.7023620605469, Entropy -281.54730224609375, Learning Rate: 0.01\n",
      "Epoch [1070/20000], Loss: 388.76708984375, Entropy -296.3413391113281, Learning Rate: 0.01\n",
      "Epoch [1071/20000], Loss: 363.4161682128906, Entropy -295.1869812011719, Learning Rate: 0.01\n",
      "Epoch [1072/20000], Loss: 414.3821716308594, Entropy -292.3919677734375, Learning Rate: 0.01\n",
      "Epoch [1073/20000], Loss: 420.19989013671875, Entropy -291.63616943359375, Learning Rate: 0.01\n",
      "Epoch [1074/20000], Loss: 370.24017333984375, Entropy -293.0039367675781, Learning Rate: 0.01\n",
      "Epoch [1075/20000], Loss: 394.917236328125, Entropy -290.8653564453125, Learning Rate: 0.01\n",
      "Epoch [1076/20000], Loss: 387.71221923828125, Entropy -296.2506408691406, Learning Rate: 0.01\n",
      "Epoch [1077/20000], Loss: 397.76123046875, Entropy -283.4728698730469, Learning Rate: 0.01\n",
      "Epoch [1078/20000], Loss: 409.3376159667969, Entropy -296.2366943359375, Learning Rate: 0.01\n",
      "Epoch [1079/20000], Loss: 356.4417724609375, Entropy -304.0713806152344, Learning Rate: 0.01\n",
      "Epoch [1080/20000], Loss: 375.2325439453125, Entropy -300.7882080078125, Learning Rate: 0.01\n",
      "Epoch [1081/20000], Loss: 421.5824890136719, Entropy -295.8177795410156, Learning Rate: 0.01\n",
      "Epoch [1082/20000], Loss: 403.06597900390625, Entropy -302.0291442871094, Learning Rate: 0.01\n",
      "Epoch [1083/20000], Loss: 396.4053955078125, Entropy -291.5633850097656, Learning Rate: 0.01\n",
      "Epoch [1084/20000], Loss: 383.0101318359375, Entropy -288.4151306152344, Learning Rate: 0.01\n",
      "Epoch [1085/20000], Loss: 375.1905517578125, Entropy -287.90460205078125, Learning Rate: 0.01\n",
      "Epoch [1086/20000], Loss: 392.6993408203125, Entropy -289.91839599609375, Learning Rate: 0.01\n",
      "Epoch [1087/20000], Loss: 375.8912353515625, Entropy -292.00189208984375, Learning Rate: 0.01\n",
      "Epoch [1088/20000], Loss: 385.19110107421875, Entropy -299.6229553222656, Learning Rate: 0.01\n",
      "Epoch [1089/20000], Loss: 422.2158508300781, Entropy -294.8736877441406, Learning Rate: 0.01\n",
      "Epoch [1090/20000], Loss: 401.3858642578125, Entropy -295.19573974609375, Learning Rate: 0.01\n",
      "Epoch [1091/20000], Loss: 369.19384765625, Entropy -303.48333740234375, Learning Rate: 0.01\n",
      "Epoch [1092/20000], Loss: 413.98895263671875, Entropy -290.96112060546875, Learning Rate: 0.01\n",
      "Epoch [1093/20000], Loss: 353.93115234375, Entropy -296.5709228515625, Learning Rate: 0.01\n",
      "Epoch [1094/20000], Loss: 384.2835693359375, Entropy -285.80963134765625, Learning Rate: 0.01\n",
      "Epoch [1095/20000], Loss: 376.96258544921875, Entropy -284.413330078125, Learning Rate: 0.01\n",
      "Epoch [1096/20000], Loss: 374.06597900390625, Entropy -290.8597412109375, Learning Rate: 0.01\n",
      "Epoch [1097/20000], Loss: 402.96307373046875, Entropy -290.98590087890625, Learning Rate: 0.01\n",
      "Epoch [1098/20000], Loss: 338.96966552734375, Entropy -295.542724609375, Learning Rate: 0.01\n",
      "Epoch [1099/20000], Loss: 366.5823059082031, Entropy -296.2652282714844, Learning Rate: 0.01\n",
      "Epoch [1100/20000], Loss: 371.2998962402344, Entropy -299.85797119140625, Learning Rate: 0.01\n",
      "Epoch [1101/20000], Loss: 341.0500793457031, Entropy -301.4833068847656, Learning Rate: 0.01\n",
      "Epoch [1102/20000], Loss: 364.8791809082031, Entropy -304.07830810546875, Learning Rate: 0.01\n",
      "Epoch [1103/20000], Loss: 351.48492431640625, Entropy -304.9993591308594, Learning Rate: 0.01\n",
      "Epoch [1104/20000], Loss: 368.2830810546875, Entropy -302.4112548828125, Learning Rate: 0.01\n",
      "Epoch [1105/20000], Loss: 363.7051696777344, Entropy -296.83905029296875, Learning Rate: 0.01\n",
      "Epoch [1106/20000], Loss: 349.9814147949219, Entropy -305.9812316894531, Learning Rate: 0.01\n",
      "Epoch [1107/20000], Loss: 366.8096008300781, Entropy -286.0637512207031, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1108/20000], Loss: 349.3965759277344, Entropy -290.7292785644531, Learning Rate: 0.01\n",
      "Epoch [1109/20000], Loss: 364.61981201171875, Entropy -300.8970031738281, Learning Rate: 0.01\n",
      "Epoch [1110/20000], Loss: 335.162353515625, Entropy -298.7696228027344, Learning Rate: 0.01\n",
      "Epoch [1111/20000], Loss: 355.9797668457031, Entropy -293.11029052734375, Learning Rate: 0.01\n",
      "Epoch [1112/20000], Loss: 315.9027404785156, Entropy -283.7261962890625, Learning Rate: 0.01\n",
      "Epoch [1113/20000], Loss: 405.91351318359375, Entropy -301.93157958984375, Learning Rate: 0.01\n",
      "Epoch [1114/20000], Loss: 345.13690185546875, Entropy -293.3191223144531, Learning Rate: 0.01\n",
      "Epoch [1115/20000], Loss: 380.33563232421875, Entropy -289.6327209472656, Learning Rate: 0.01\n",
      "Epoch [1116/20000], Loss: 342.3551025390625, Entropy -300.17071533203125, Learning Rate: 0.01\n",
      "Epoch [1117/20000], Loss: 326.50396728515625, Entropy -285.8707275390625, Learning Rate: 0.01\n",
      "Epoch [1118/20000], Loss: 391.4093017578125, Entropy -288.6715087890625, Learning Rate: 0.01\n",
      "Epoch [1119/20000], Loss: 342.6768493652344, Entropy -283.0919494628906, Learning Rate: 0.01\n",
      "Epoch [1120/20000], Loss: 382.08795166015625, Entropy -285.9350280761719, Learning Rate: 0.01\n",
      "Epoch [1121/20000], Loss: 380.7911376953125, Entropy -289.36126708984375, Learning Rate: 0.01\n",
      "Epoch [1122/20000], Loss: 341.4377746582031, Entropy -289.7944641113281, Learning Rate: 0.01\n",
      "Epoch [1123/20000], Loss: 357.9700927734375, Entropy -302.07635498046875, Learning Rate: 0.01\n",
      "Epoch [1124/20000], Loss: 328.1991271972656, Entropy -287.25543212890625, Learning Rate: 0.01\n",
      "Epoch [1125/20000], Loss: 361.21844482421875, Entropy -296.2758483886719, Learning Rate: 0.01\n",
      "Epoch [1126/20000], Loss: 348.5443115234375, Entropy -289.5724792480469, Learning Rate: 0.01\n",
      "Epoch [1127/20000], Loss: 349.9892883300781, Entropy -292.9627685546875, Learning Rate: 0.01\n",
      "Epoch [1128/20000], Loss: 347.59698486328125, Entropy -290.4215393066406, Learning Rate: 0.01\n",
      "Epoch [1129/20000], Loss: 369.87152099609375, Entropy -295.8173828125, Learning Rate: 0.01\n",
      "Epoch [1130/20000], Loss: 335.6439208984375, Entropy -293.2003173828125, Learning Rate: 0.01\n",
      "Epoch [1131/20000], Loss: 365.109130859375, Entropy -297.7485046386719, Learning Rate: 0.01\n",
      "Epoch [1132/20000], Loss: 352.93487548828125, Entropy -286.8524475097656, Learning Rate: 0.01\n",
      "Epoch [1133/20000], Loss: 345.6328125, Entropy -293.59954833984375, Learning Rate: 0.01\n",
      "Epoch [1134/20000], Loss: 359.5951232910156, Entropy -301.39593505859375, Learning Rate: 0.01\n",
      "Epoch [1135/20000], Loss: 331.28106689453125, Entropy -289.421142578125, Learning Rate: 0.01\n",
      "Epoch [1136/20000], Loss: 347.0902099609375, Entropy -299.16558837890625, Learning Rate: 0.01\n",
      "Epoch [1137/20000], Loss: 351.57763671875, Entropy -293.02154541015625, Learning Rate: 0.01\n",
      "Epoch [1138/20000], Loss: 363.8554992675781, Entropy -296.9584655761719, Learning Rate: 0.01\n",
      "Epoch [1139/20000], Loss: 336.17828369140625, Entropy -300.7450256347656, Learning Rate: 0.01\n",
      "Epoch [1140/20000], Loss: 335.633544921875, Entropy -298.4833068847656, Learning Rate: 0.01\n",
      "Epoch [1141/20000], Loss: 322.8687744140625, Entropy -295.3353271484375, Learning Rate: 0.01\n",
      "Epoch [1142/20000], Loss: 339.3087463378906, Entropy -292.5074157714844, Learning Rate: 0.01\n",
      "Epoch [1143/20000], Loss: 349.32708740234375, Entropy -292.11041259765625, Learning Rate: 0.01\n",
      "Epoch [1144/20000], Loss: 332.24700927734375, Entropy -293.424072265625, Learning Rate: 0.01\n",
      "Epoch [1145/20000], Loss: 335.14361572265625, Entropy -295.77532958984375, Learning Rate: 0.01\n",
      "Epoch [1146/20000], Loss: 352.9617614746094, Entropy -281.82537841796875, Learning Rate: 0.01\n",
      "Epoch [1147/20000], Loss: 337.4117126464844, Entropy -296.2333984375, Learning Rate: 0.01\n",
      "Epoch [1148/20000], Loss: 360.730224609375, Entropy -292.68701171875, Learning Rate: 0.01\n",
      "Epoch [1149/20000], Loss: 345.93487548828125, Entropy -286.9837951660156, Learning Rate: 0.01\n",
      "Epoch [1150/20000], Loss: 364.8038330078125, Entropy -285.9382019042969, Learning Rate: 0.01\n",
      "Epoch [1151/20000], Loss: 382.105712890625, Entropy -282.7774963378906, Learning Rate: 0.01\n",
      "Epoch [1152/20000], Loss: 360.03839111328125, Entropy -292.7806396484375, Learning Rate: 0.01\n",
      "Epoch [1153/20000], Loss: 415.1960754394531, Entropy -294.3668212890625, Learning Rate: 0.01\n",
      "Epoch [1154/20000], Loss: 360.0054016113281, Entropy -278.41363525390625, Learning Rate: 0.01\n",
      "Epoch [1155/20000], Loss: 391.3873596191406, Entropy -280.21978759765625, Learning Rate: 0.01\n",
      "Epoch [1156/20000], Loss: 377.3130798339844, Entropy -295.9866638183594, Learning Rate: 0.01\n",
      "Epoch [1157/20000], Loss: 349.37042236328125, Entropy -297.60955810546875, Learning Rate: 0.01\n",
      "Epoch [1158/20000], Loss: 328.2082214355469, Entropy -291.7901916503906, Learning Rate: 0.01\n",
      "Epoch [1159/20000], Loss: 348.37274169921875, Entropy -293.31463623046875, Learning Rate: 0.01\n",
      "Epoch [1160/20000], Loss: 323.3702392578125, Entropy -290.1125183105469, Learning Rate: 0.01\n",
      "Epoch [1161/20000], Loss: 330.4479064941406, Entropy -282.54608154296875, Learning Rate: 0.01\n",
      "Epoch [1162/20000], Loss: 339.3909912109375, Entropy -288.4754333496094, Learning Rate: 0.01\n",
      "Epoch [1163/20000], Loss: 337.1144714355469, Entropy -295.4717712402344, Learning Rate: 0.01\n",
      "Epoch [1164/20000], Loss: 332.5364990234375, Entropy -281.9766540527344, Learning Rate: 0.01\n",
      "Epoch [1165/20000], Loss: 363.67413330078125, Entropy -291.426513671875, Learning Rate: 0.01\n",
      "Epoch [1166/20000], Loss: 364.2850646972656, Entropy -291.5284118652344, Learning Rate: 0.01\n",
      "Epoch [1167/20000], Loss: 352.00128173828125, Entropy -288.65826416015625, Learning Rate: 0.01\n",
      "Epoch [1168/20000], Loss: 334.1632385253906, Entropy -292.49810791015625, Learning Rate: 0.01\n",
      "Epoch [1169/20000], Loss: 343.18536376953125, Entropy -288.66754150390625, Learning Rate: 0.01\n",
      "Epoch [1170/20000], Loss: 353.4599914550781, Entropy -293.544677734375, Learning Rate: 0.01\n",
      "Epoch [1171/20000], Loss: 334.6579284667969, Entropy -283.09124755859375, Learning Rate: 0.01\n",
      "Epoch [1172/20000], Loss: 352.8755187988281, Entropy -295.7738952636719, Learning Rate: 0.01\n",
      "Epoch [1173/20000], Loss: 344.29296875, Entropy -290.5645446777344, Learning Rate: 0.01\n",
      "Epoch [1174/20000], Loss: 356.5620422363281, Entropy -292.83941650390625, Learning Rate: 0.01\n",
      "Epoch [1175/20000], Loss: 328.4322509765625, Entropy -295.4251708984375, Learning Rate: 0.01\n",
      "Epoch [1176/20000], Loss: 337.3808288574219, Entropy -291.71368408203125, Learning Rate: 0.01\n",
      "Epoch [1177/20000], Loss: 361.0760803222656, Entropy -290.31317138671875, Learning Rate: 0.01\n",
      "Epoch [1178/20000], Loss: 362.77667236328125, Entropy -293.4429016113281, Learning Rate: 0.01\n",
      "Epoch [1179/20000], Loss: 316.802978515625, Entropy -297.5907287597656, Learning Rate: 0.01\n",
      "Epoch [1180/20000], Loss: 336.86419677734375, Entropy -281.6229553222656, Learning Rate: 0.01\n",
      "Epoch [1181/20000], Loss: 358.31787109375, Entropy -307.7752990722656, Learning Rate: 0.01\n",
      "Epoch [1182/20000], Loss: 358.42864990234375, Entropy -293.14691162109375, Learning Rate: 0.01\n",
      "Epoch [1183/20000], Loss: 339.6285400390625, Entropy -299.03814697265625, Learning Rate: 0.01\n",
      "Epoch [1184/20000], Loss: 329.2908935546875, Entropy -293.5577697753906, Learning Rate: 0.01\n",
      "Epoch [1185/20000], Loss: 323.38494873046875, Entropy -282.137939453125, Learning Rate: 0.01\n",
      "Epoch [1186/20000], Loss: 342.3721923828125, Entropy -294.3628234863281, Learning Rate: 0.01\n",
      "Epoch [1187/20000], Loss: 314.040771484375, Entropy -285.9705505371094, Learning Rate: 0.01\n",
      "Epoch [1188/20000], Loss: 351.3297119140625, Entropy -289.5953674316406, Learning Rate: 0.01\n",
      "Epoch [1189/20000], Loss: 334.9757080078125, Entropy -295.1988220214844, Learning Rate: 0.01\n",
      "Epoch [1190/20000], Loss: 318.4375915527344, Entropy -290.13018798828125, Learning Rate: 0.01\n",
      "Epoch [1191/20000], Loss: 345.9637756347656, Entropy -289.4735107421875, Learning Rate: 0.01\n",
      "Epoch [1192/20000], Loss: 320.19793701171875, Entropy -296.5553283691406, Learning Rate: 0.01\n",
      "Epoch [1193/20000], Loss: 327.6308898925781, Entropy -293.38531494140625, Learning Rate: 0.01\n",
      "Epoch [1194/20000], Loss: 321.9400939941406, Entropy -289.8983459472656, Learning Rate: 0.01\n",
      "Epoch [1195/20000], Loss: 320.27618408203125, Entropy -294.85369873046875, Learning Rate: 0.01\n",
      "Epoch [1196/20000], Loss: 331.1178283691406, Entropy -291.2926330566406, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1197/20000], Loss: 319.069091796875, Entropy -280.4422607421875, Learning Rate: 0.01\n",
      "Epoch [1198/20000], Loss: 317.4502258300781, Entropy -274.559814453125, Learning Rate: 0.01\n",
      "Epoch [1199/20000], Loss: 324.59906005859375, Entropy -298.12353515625, Learning Rate: 0.01\n",
      "Epoch [1200/20000], Loss: 322.2686462402344, Entropy -297.64678955078125, Learning Rate: 0.01\n",
      "Epoch [1201/20000], Loss: 331.8499450683594, Entropy -277.4972229003906, Learning Rate: 0.01\n",
      "Epoch [1202/20000], Loss: 325.81622314453125, Entropy -288.2611083984375, Learning Rate: 0.01\n",
      "Epoch [1203/20000], Loss: 343.6490478515625, Entropy -299.1167907714844, Learning Rate: 0.01\n",
      "Epoch [1204/20000], Loss: 306.897216796875, Entropy -293.569580078125, Learning Rate: 0.01\n",
      "Epoch [1205/20000], Loss: 362.26080322265625, Entropy -299.71368408203125, Learning Rate: 0.01\n",
      "Epoch [1206/20000], Loss: 371.24951171875, Entropy -290.4444274902344, Learning Rate: 0.01\n",
      "Epoch [1207/20000], Loss: 356.459228515625, Entropy -287.96759033203125, Learning Rate: 0.01\n",
      "Epoch [1208/20000], Loss: 338.10418701171875, Entropy -286.9778747558594, Learning Rate: 0.01\n",
      "Epoch [1209/20000], Loss: 350.7205505371094, Entropy -281.6641845703125, Learning Rate: 0.01\n",
      "Epoch [1210/20000], Loss: 313.9842224121094, Entropy -291.5378723144531, Learning Rate: 0.01\n",
      "Epoch [1211/20000], Loss: 321.8405456542969, Entropy -282.5435791015625, Learning Rate: 0.01\n",
      "Epoch [1212/20000], Loss: 341.03411865234375, Entropy -290.2564697265625, Learning Rate: 0.01\n",
      "Epoch [1213/20000], Loss: 332.3245849609375, Entropy -295.8789978027344, Learning Rate: 0.01\n",
      "Epoch [1214/20000], Loss: 402.84490966796875, Entropy -286.7395324707031, Learning Rate: 0.01\n",
      "Epoch [1215/20000], Loss: 369.8375549316406, Entropy -288.2598876953125, Learning Rate: 0.01\n",
      "Epoch [1216/20000], Loss: 329.61090087890625, Entropy -280.29150390625, Learning Rate: 0.01\n",
      "Epoch [1217/20000], Loss: 343.74871826171875, Entropy -282.094970703125, Learning Rate: 0.01\n",
      "Epoch [1218/20000], Loss: 326.712646484375, Entropy -294.5101013183594, Learning Rate: 0.01\n",
      "Epoch [1219/20000], Loss: 332.5578918457031, Entropy -278.93182373046875, Learning Rate: 0.01\n",
      "Epoch [1220/20000], Loss: 345.9386291503906, Entropy -296.0946044921875, Learning Rate: 0.01\n",
      "Epoch [1221/20000], Loss: 312.66290283203125, Entropy -280.565673828125, Learning Rate: 0.01\n",
      "Epoch [1222/20000], Loss: 332.40386962890625, Entropy -290.11126708984375, Learning Rate: 0.01\n",
      "Epoch [1223/20000], Loss: 333.6025085449219, Entropy -281.970947265625, Learning Rate: 0.01\n",
      "Epoch [1224/20000], Loss: 341.40032958984375, Entropy -280.65997314453125, Learning Rate: 0.01\n",
      "Epoch [1225/20000], Loss: 321.78662109375, Entropy -298.5677795410156, Learning Rate: 0.01\n",
      "Epoch [1226/20000], Loss: 345.93414306640625, Entropy -295.951904296875, Learning Rate: 0.01\n",
      "Epoch [1227/20000], Loss: 319.6524353027344, Entropy -293.1747131347656, Learning Rate: 0.01\n",
      "Epoch [1228/20000], Loss: 340.2088928222656, Entropy -297.7178039550781, Learning Rate: 0.01\n",
      "Epoch [1229/20000], Loss: 305.18609619140625, Entropy -285.2159423828125, Learning Rate: 0.01\n",
      "Epoch [1230/20000], Loss: 319.727783203125, Entropy -286.6118469238281, Learning Rate: 0.01\n",
      "Epoch [1231/20000], Loss: 321.1124267578125, Entropy -282.8347473144531, Learning Rate: 0.01\n",
      "Epoch [1232/20000], Loss: 340.47607421875, Entropy -287.9826965332031, Learning Rate: 0.01\n",
      "Epoch [1233/20000], Loss: 329.96368408203125, Entropy -291.9734802246094, Learning Rate: 0.01\n",
      "Epoch [1234/20000], Loss: 328.10333251953125, Entropy -294.76446533203125, Learning Rate: 0.01\n",
      "Epoch [1235/20000], Loss: 328.98382568359375, Entropy -281.3023376464844, Learning Rate: 0.01\n",
      "Epoch [1236/20000], Loss: 323.4488830566406, Entropy -293.2997131347656, Learning Rate: 0.01\n",
      "Epoch [1237/20000], Loss: 348.53387451171875, Entropy -292.76177978515625, Learning Rate: 0.01\n",
      "Epoch [1238/20000], Loss: 423.4188537597656, Entropy -294.14715576171875, Learning Rate: 0.01\n",
      "Epoch [1239/20000], Loss: 347.3984375, Entropy -289.3086853027344, Learning Rate: 0.01\n",
      "Epoch [1240/20000], Loss: 374.98095703125, Entropy -296.5844421386719, Learning Rate: 0.01\n",
      "Epoch [1241/20000], Loss: 366.947509765625, Entropy -296.9378662109375, Learning Rate: 0.01\n",
      "Epoch [1242/20000], Loss: 415.2914733886719, Entropy -293.6783752441406, Learning Rate: 0.01\n",
      "Epoch [1243/20000], Loss: 336.80511474609375, Entropy -282.2581787109375, Learning Rate: 0.01\n",
      "Epoch [1244/20000], Loss: 384.7899475097656, Entropy -293.60028076171875, Learning Rate: 0.01\n",
      "Epoch [1245/20000], Loss: 368.43963623046875, Entropy -291.6946716308594, Learning Rate: 0.01\n",
      "Epoch [1246/20000], Loss: 391.92877197265625, Entropy -288.0558776855469, Learning Rate: 0.01\n",
      "Epoch [1247/20000], Loss: 342.9681396484375, Entropy -288.3554992675781, Learning Rate: 0.01\n",
      "Epoch [1248/20000], Loss: 373.0774841308594, Entropy -296.92779541015625, Learning Rate: 0.01\n",
      "Epoch [1249/20000], Loss: 341.4507141113281, Entropy -288.1384582519531, Learning Rate: 0.01\n",
      "Epoch [1250/20000], Loss: 363.0931396484375, Entropy -282.2861328125, Learning Rate: 0.01\n",
      "Epoch [1251/20000], Loss: 336.5707702636719, Entropy -299.6795959472656, Learning Rate: 0.01\n",
      "Epoch [1252/20000], Loss: 337.06884765625, Entropy -292.7459716796875, Learning Rate: 0.01\n",
      "Epoch [1253/20000], Loss: 333.68603515625, Entropy -280.3627624511719, Learning Rate: 0.01\n",
      "Epoch [1254/20000], Loss: 342.30181884765625, Entropy -288.27056884765625, Learning Rate: 0.01\n",
      "Epoch [1255/20000], Loss: 363.6285705566406, Entropy -276.4029541015625, Learning Rate: 0.01\n",
      "Epoch [1256/20000], Loss: 364.9717102050781, Entropy -286.6669921875, Learning Rate: 0.01\n",
      "Epoch [1257/20000], Loss: 311.8879699707031, Entropy -283.7886962890625, Learning Rate: 0.01\n",
      "Epoch [1258/20000], Loss: 373.8251037597656, Entropy -283.52996826171875, Learning Rate: 0.01\n",
      "Epoch [1259/20000], Loss: 348.9754943847656, Entropy -298.408203125, Learning Rate: 0.01\n",
      "Epoch [1260/20000], Loss: 316.6090393066406, Entropy -290.8829040527344, Learning Rate: 0.01\n",
      "Epoch [1261/20000], Loss: 388.48895263671875, Entropy -284.8009338378906, Learning Rate: 0.01\n",
      "Epoch [1262/20000], Loss: 353.2645568847656, Entropy -297.96710205078125, Learning Rate: 0.01\n",
      "Epoch [1263/20000], Loss: 377.5321044921875, Entropy -280.20782470703125, Learning Rate: 0.01\n",
      "Epoch [1264/20000], Loss: 401.48565673828125, Entropy -283.4815673828125, Learning Rate: 0.01\n",
      "Epoch [1265/20000], Loss: 351.3361511230469, Entropy -282.69049072265625, Learning Rate: 0.01\n",
      "Epoch [1266/20000], Loss: 414.06988525390625, Entropy -270.40167236328125, Learning Rate: 0.01\n",
      "Epoch [1267/20000], Loss: 403.2944030761719, Entropy -285.52020263671875, Learning Rate: 0.01\n",
      "Epoch [1268/20000], Loss: 316.29486083984375, Entropy -288.6826477050781, Learning Rate: 0.01\n",
      "Epoch [1269/20000], Loss: 414.1814270019531, Entropy -285.99737548828125, Learning Rate: 0.01\n",
      "Epoch [1270/20000], Loss: 366.936767578125, Entropy -289.0185852050781, Learning Rate: 0.01\n",
      "Epoch [1271/20000], Loss: 364.4345703125, Entropy -280.3216552734375, Learning Rate: 0.01\n",
      "Epoch [1272/20000], Loss: 379.36328125, Entropy -281.6347961425781, Learning Rate: 0.01\n",
      "Epoch [1273/20000], Loss: 352.9449462890625, Entropy -279.9589538574219, Learning Rate: 0.01\n",
      "Epoch [1274/20000], Loss: 341.00164794921875, Entropy -288.6304931640625, Learning Rate: 0.01\n",
      "Epoch [1275/20000], Loss: 410.8154602050781, Entropy -295.0972595214844, Learning Rate: 0.01\n",
      "Epoch [1276/20000], Loss: 389.78314208984375, Entropy -278.7188720703125, Learning Rate: 0.01\n",
      "Epoch [1277/20000], Loss: 340.4822998046875, Entropy -280.7625732421875, Learning Rate: 0.01\n",
      "Epoch [1278/20000], Loss: 444.28533935546875, Entropy -276.20025634765625, Learning Rate: 0.01\n",
      "Epoch [1279/20000], Loss: 448.5127868652344, Entropy -280.3002624511719, Learning Rate: 0.01\n",
      "Epoch [1280/20000], Loss: 334.15948486328125, Entropy -284.7960205078125, Learning Rate: 0.01\n",
      "Epoch [1281/20000], Loss: 401.6417236328125, Entropy -279.50445556640625, Learning Rate: 0.01\n",
      "Epoch [1282/20000], Loss: 464.8858337402344, Entropy -273.6340637207031, Learning Rate: 0.01\n",
      "Epoch [1283/20000], Loss: 337.36767578125, Entropy -280.8697814941406, Learning Rate: 0.01\n",
      "Epoch [1284/20000], Loss: 403.7032775878906, Entropy -279.6652526855469, Learning Rate: 0.01\n",
      "Epoch [1285/20000], Loss: 359.2324523925781, Entropy -290.33697509765625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1286/20000], Loss: 325.0377502441406, Entropy -279.6839599609375, Learning Rate: 0.01\n",
      "Epoch [1287/20000], Loss: 371.3866271972656, Entropy -279.66656494140625, Learning Rate: 0.01\n",
      "Epoch [1288/20000], Loss: 417.7072448730469, Entropy -300.3462829589844, Learning Rate: 0.01\n",
      "Epoch [1289/20000], Loss: 352.6400146484375, Entropy -292.41058349609375, Learning Rate: 0.01\n",
      "Epoch [1290/20000], Loss: 441.058837890625, Entropy -284.2987060546875, Learning Rate: 0.01\n",
      "Epoch [1291/20000], Loss: 563.3292236328125, Entropy -283.3150329589844, Learning Rate: 0.01\n",
      "Epoch [1292/20000], Loss: 351.64324951171875, Entropy -287.99334716796875, Learning Rate: 0.01\n",
      "Epoch [1293/20000], Loss: 396.1650085449219, Entropy -284.8944091796875, Learning Rate: 0.01\n",
      "Epoch [1294/20000], Loss: 446.8260498046875, Entropy -274.3955078125, Learning Rate: 0.01\n",
      "Epoch [1295/20000], Loss: 383.65472412109375, Entropy -280.8855285644531, Learning Rate: 0.01\n",
      "Epoch [1296/20000], Loss: 338.1208801269531, Entropy -283.6927490234375, Learning Rate: 0.01\n",
      "Epoch [1297/20000], Loss: 416.5439453125, Entropy -287.4550476074219, Learning Rate: 0.01\n",
      "Epoch [1298/20000], Loss: 360.2266845703125, Entropy -282.640380859375, Learning Rate: 0.01\n",
      "Epoch [1299/20000], Loss: 322.9757385253906, Entropy -286.36712646484375, Learning Rate: 0.01\n",
      "Epoch [1300/20000], Loss: 366.9480895996094, Entropy -287.9099426269531, Learning Rate: 0.01\n",
      "Epoch [1301/20000], Loss: 379.0489196777344, Entropy -283.6815185546875, Learning Rate: 0.01\n",
      "Epoch [1302/20000], Loss: 329.98828125, Entropy -282.5326232910156, Learning Rate: 0.01\n",
      "Epoch [1303/20000], Loss: 383.1004943847656, Entropy -282.1653747558594, Learning Rate: 0.01\n",
      "Epoch [1304/20000], Loss: 372.8477783203125, Entropy -281.0342102050781, Learning Rate: 0.01\n",
      "Epoch [1305/20000], Loss: 319.4742431640625, Entropy -284.315185546875, Learning Rate: 0.01\n",
      "Epoch [1306/20000], Loss: 492.8121337890625, Entropy -282.8575134277344, Learning Rate: 0.01\n",
      "Epoch [1307/20000], Loss: 479.7767028808594, Entropy -299.8482971191406, Learning Rate: 0.01\n",
      "Epoch [1308/20000], Loss: 331.8068542480469, Entropy -288.01873779296875, Learning Rate: 0.01\n",
      "Epoch [1309/20000], Loss: 477.55487060546875, Entropy -283.23919677734375, Learning Rate: 0.01\n",
      "Epoch [1310/20000], Loss: 425.0446472167969, Entropy -278.4871826171875, Learning Rate: 0.01\n",
      "Epoch [1311/20000], Loss: 369.2944030761719, Entropy -286.1942138671875, Learning Rate: 0.01\n",
      "Epoch [1312/20000], Loss: 501.2655334472656, Entropy -291.707763671875, Learning Rate: 0.01\n",
      "Epoch [1313/20000], Loss: 354.6319885253906, Entropy -281.9111328125, Learning Rate: 0.01\n",
      "Epoch [1314/20000], Loss: 429.80035400390625, Entropy -290.335693359375, Learning Rate: 0.01\n",
      "Epoch [1315/20000], Loss: 507.47454833984375, Entropy -291.75054931640625, Learning Rate: 0.01\n",
      "Epoch [1316/20000], Loss: 347.5174865722656, Entropy -286.1554870605469, Learning Rate: 0.01\n",
      "Epoch [1317/20000], Loss: 356.368896484375, Entropy -282.3745422363281, Learning Rate: 0.01\n",
      "Epoch [1318/20000], Loss: 368.9573059082031, Entropy -283.098388671875, Learning Rate: 0.01\n",
      "Epoch [1319/20000], Loss: 345.03753662109375, Entropy -285.4906311035156, Learning Rate: 0.01\n",
      "Epoch [1320/20000], Loss: 394.7472229003906, Entropy -287.3472900390625, Learning Rate: 0.01\n",
      "Epoch [1321/20000], Loss: 366.4952087402344, Entropy -290.5522155761719, Learning Rate: 0.01\n",
      "Epoch [1322/20000], Loss: 353.2480163574219, Entropy -291.0921325683594, Learning Rate: 0.01\n",
      "Epoch [1323/20000], Loss: 394.3519287109375, Entropy -287.5755310058594, Learning Rate: 0.01\n",
      "Epoch [1324/20000], Loss: 420.44573974609375, Entropy -291.9405517578125, Learning Rate: 0.01\n",
      "Epoch [1325/20000], Loss: 340.00897216796875, Entropy -294.6401672363281, Learning Rate: 0.01\n",
      "Epoch [1326/20000], Loss: 368.1023254394531, Entropy -281.59222412109375, Learning Rate: 0.01\n",
      "Epoch [1327/20000], Loss: 389.6978759765625, Entropy -287.1087646484375, Learning Rate: 0.01\n",
      "Epoch [1328/20000], Loss: 382.36517333984375, Entropy -278.2328796386719, Learning Rate: 0.01\n",
      "Epoch [1329/20000], Loss: 332.9672546386719, Entropy -290.82403564453125, Learning Rate: 0.01\n",
      "Epoch [1330/20000], Loss: 317.6373291015625, Entropy -281.0185852050781, Learning Rate: 0.01\n",
      "Epoch [1331/20000], Loss: 371.8134765625, Entropy -276.90496826171875, Learning Rate: 0.01\n",
      "Epoch [1332/20000], Loss: 340.55291748046875, Entropy -298.03656005859375, Learning Rate: 0.01\n",
      "Epoch [1333/20000], Loss: 370.4905090332031, Entropy -281.04693603515625, Learning Rate: 0.01\n",
      "Epoch [1334/20000], Loss: 336.4367980957031, Entropy -294.2904357910156, Learning Rate: 0.01\n",
      "Epoch [1335/20000], Loss: 314.5565490722656, Entropy -278.2694091796875, Learning Rate: 0.01\n",
      "Epoch [1336/20000], Loss: 331.35107421875, Entropy -281.4429626464844, Learning Rate: 0.01\n",
      "Epoch [1337/20000], Loss: 304.9535827636719, Entropy -282.9750061035156, Learning Rate: 0.01\n",
      "Epoch [1338/20000], Loss: 359.348388671875, Entropy -294.9143981933594, Learning Rate: 0.01\n",
      "Epoch [1339/20000], Loss: 364.2789306640625, Entropy -291.34375, Learning Rate: 0.01\n",
      "Epoch [1340/20000], Loss: 350.3830261230469, Entropy -297.310302734375, Learning Rate: 0.01\n",
      "Epoch [1341/20000], Loss: 338.10406494140625, Entropy -276.46832275390625, Learning Rate: 0.01\n",
      "Epoch [1342/20000], Loss: 342.5616760253906, Entropy -283.31903076171875, Learning Rate: 0.01\n",
      "Epoch [1343/20000], Loss: 318.6233215332031, Entropy -282.16229248046875, Learning Rate: 0.01\n",
      "Epoch [1344/20000], Loss: 322.5260925292969, Entropy -291.13787841796875, Learning Rate: 0.01\n",
      "Epoch [1345/20000], Loss: 326.03558349609375, Entropy -293.1211853027344, Learning Rate: 0.01\n",
      "Epoch [1346/20000], Loss: 305.9669189453125, Entropy -277.8251647949219, Learning Rate: 0.01\n",
      "Epoch [1347/20000], Loss: 314.4588317871094, Entropy -281.9980773925781, Learning Rate: 0.01\n",
      "Epoch [1348/20000], Loss: 346.755859375, Entropy -285.77215576171875, Learning Rate: 0.01\n",
      "Epoch [1349/20000], Loss: 323.83624267578125, Entropy -287.1540222167969, Learning Rate: 0.01\n",
      "Epoch [1350/20000], Loss: 316.7069091796875, Entropy -284.32928466796875, Learning Rate: 0.01\n",
      "Epoch [1351/20000], Loss: 312.283935546875, Entropy -285.96771240234375, Learning Rate: 0.01\n",
      "Epoch [1352/20000], Loss: 348.05694580078125, Entropy -289.5567321777344, Learning Rate: 0.01\n",
      "Epoch [1353/20000], Loss: 309.84674072265625, Entropy -278.42803955078125, Learning Rate: 0.01\n",
      "Epoch [1354/20000], Loss: 308.7744140625, Entropy -284.0958251953125, Learning Rate: 0.01\n",
      "Epoch [1355/20000], Loss: 323.8392333984375, Entropy -286.78460693359375, Learning Rate: 0.01\n",
      "Epoch [1356/20000], Loss: 334.563720703125, Entropy -294.5962829589844, Learning Rate: 0.01\n",
      "Epoch [1357/20000], Loss: 313.4358825683594, Entropy -287.1451110839844, Learning Rate: 0.01\n",
      "Epoch [1358/20000], Loss: 312.1832275390625, Entropy -280.48046875, Learning Rate: 0.01\n",
      "Epoch [1359/20000], Loss: 312.174560546875, Entropy -286.58642578125, Learning Rate: 0.01\n",
      "Epoch [1360/20000], Loss: 323.8190002441406, Entropy -291.86688232421875, Learning Rate: 0.01\n",
      "Epoch [1361/20000], Loss: 301.58380126953125, Entropy -286.23468017578125, Learning Rate: 0.01\n",
      "Epoch [1362/20000], Loss: 312.60247802734375, Entropy -287.6965637207031, Learning Rate: 0.01\n",
      "Epoch [1363/20000], Loss: 296.72674560546875, Entropy -291.55072021484375, Learning Rate: 0.01\n",
      "Epoch [1364/20000], Loss: 294.75799560546875, Entropy -285.0939025878906, Learning Rate: 0.01\n",
      "Epoch [1365/20000], Loss: 297.5999755859375, Entropy -282.4510498046875, Learning Rate: 0.01\n",
      "Epoch [1366/20000], Loss: 313.4047546386719, Entropy -302.88922119140625, Learning Rate: 0.01\n",
      "Epoch [1367/20000], Loss: 321.5087890625, Entropy -290.78094482421875, Learning Rate: 0.01\n",
      "Epoch [1368/20000], Loss: 295.56024169921875, Entropy -280.7630920410156, Learning Rate: 0.01\n",
      "Epoch [1369/20000], Loss: 291.19970703125, Entropy -276.8736877441406, Learning Rate: 0.01\n",
      "Epoch [1370/20000], Loss: 331.52447509765625, Entropy -286.0512390136719, Learning Rate: 0.01\n",
      "Epoch [1371/20000], Loss: 307.8641052246094, Entropy -286.42401123046875, Learning Rate: 0.01\n",
      "Epoch [1372/20000], Loss: 295.65069580078125, Entropy -281.77716064453125, Learning Rate: 0.01\n",
      "Epoch [1373/20000], Loss: 320.1163330078125, Entropy -291.2801513671875, Learning Rate: 0.01\n",
      "Epoch [1374/20000], Loss: 305.023193359375, Entropy -294.9721374511719, Learning Rate: 0.01\n",
      "Epoch [1375/20000], Loss: 319.44744873046875, Entropy -279.2216491699219, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1376/20000], Loss: 291.687744140625, Entropy -275.11669921875, Learning Rate: 0.01\n",
      "Epoch [1377/20000], Loss: 309.2670593261719, Entropy -286.72149658203125, Learning Rate: 0.01\n",
      "Epoch [1378/20000], Loss: 328.14788818359375, Entropy -282.1130676269531, Learning Rate: 0.01\n",
      "Epoch [1379/20000], Loss: 289.87811279296875, Entropy -279.5465087890625, Learning Rate: 0.01\n",
      "Epoch [1380/20000], Loss: 296.84918212890625, Entropy -282.0206298828125, Learning Rate: 0.01\n",
      "Epoch [1381/20000], Loss: 326.1874694824219, Entropy -289.7647705078125, Learning Rate: 0.01\n",
      "Epoch [1382/20000], Loss: 287.89227294921875, Entropy -283.2535705566406, Learning Rate: 0.01\n",
      "Epoch [1383/20000], Loss: 322.32794189453125, Entropy -296.7508239746094, Learning Rate: 0.01\n",
      "Epoch [1384/20000], Loss: 320.1363525390625, Entropy -287.6680908203125, Learning Rate: 0.01\n",
      "Epoch [1385/20000], Loss: 306.4442443847656, Entropy -286.46636962890625, Learning Rate: 0.01\n",
      "Epoch [1386/20000], Loss: 293.142822265625, Entropy -284.5986328125, Learning Rate: 0.01\n",
      "Epoch [1387/20000], Loss: 310.04290771484375, Entropy -281.5011901855469, Learning Rate: 0.01\n",
      "Epoch [1388/20000], Loss: 302.7120361328125, Entropy -281.84307861328125, Learning Rate: 0.01\n",
      "Epoch [1389/20000], Loss: 326.05889892578125, Entropy -279.9998779296875, Learning Rate: 0.01\n",
      "Epoch [1390/20000], Loss: 294.2181091308594, Entropy -285.45855712890625, Learning Rate: 0.01\n",
      "Epoch [1391/20000], Loss: 330.0147705078125, Entropy -278.9810485839844, Learning Rate: 0.01\n",
      "Epoch [1392/20000], Loss: 330.74945068359375, Entropy -289.4341735839844, Learning Rate: 0.01\n",
      "Epoch [1393/20000], Loss: 312.0224304199219, Entropy -280.7112731933594, Learning Rate: 0.01\n",
      "Epoch [1394/20000], Loss: 285.5978088378906, Entropy -277.9227600097656, Learning Rate: 0.01\n",
      "Epoch [1395/20000], Loss: 324.85723876953125, Entropy -288.7138977050781, Learning Rate: 0.01\n",
      "Epoch [1396/20000], Loss: 313.7421875, Entropy -297.3558044433594, Learning Rate: 0.01\n",
      "Epoch [1397/20000], Loss: 299.84130859375, Entropy -284.511474609375, Learning Rate: 0.01\n",
      "Epoch [1398/20000], Loss: 328.3011169433594, Entropy -290.0455322265625, Learning Rate: 0.01\n",
      "Epoch [1399/20000], Loss: 309.9670104980469, Entropy -291.4912414550781, Learning Rate: 0.01\n",
      "Epoch [1400/20000], Loss: 321.3237609863281, Entropy -282.6146240234375, Learning Rate: 0.01\n",
      "Epoch [1401/20000], Loss: 287.81072998046875, Entropy -291.1654357910156, Learning Rate: 0.01\n",
      "Epoch [1402/20000], Loss: 351.46697998046875, Entropy -286.8132019042969, Learning Rate: 0.01\n",
      "Epoch [1403/20000], Loss: 296.7209777832031, Entropy -277.0397033691406, Learning Rate: 0.01\n",
      "Epoch [1404/20000], Loss: 352.0740966796875, Entropy -279.674560546875, Learning Rate: 0.01\n",
      "Epoch [1405/20000], Loss: 329.86846923828125, Entropy -278.0974426269531, Learning Rate: 0.01\n",
      "Epoch [1406/20000], Loss: 309.6595458984375, Entropy -274.9180603027344, Learning Rate: 0.01\n",
      "Epoch [1407/20000], Loss: 351.3369140625, Entropy -281.7158203125, Learning Rate: 0.01\n",
      "Epoch [1408/20000], Loss: 319.9932861328125, Entropy -276.2210693359375, Learning Rate: 0.01\n",
      "Epoch [1409/20000], Loss: 312.6315002441406, Entropy -266.55999755859375, Learning Rate: 0.01\n",
      "Epoch [1410/20000], Loss: 287.0164794921875, Entropy -274.0840148925781, Learning Rate: 0.01\n",
      "Epoch [1411/20000], Loss: 332.2926330566406, Entropy -282.72039794921875, Learning Rate: 0.01\n",
      "Epoch [1412/20000], Loss: 287.33123779296875, Entropy -285.1311950683594, Learning Rate: 0.01\n",
      "Epoch [1413/20000], Loss: 344.7354431152344, Entropy -291.24456787109375, Learning Rate: 0.01\n",
      "Epoch [1414/20000], Loss: 341.7866516113281, Entropy -281.0055847167969, Learning Rate: 0.01\n",
      "Epoch [1415/20000], Loss: 279.4290771484375, Entropy -274.0011291503906, Learning Rate: 0.01\n",
      "Epoch [1416/20000], Loss: 312.3377685546875, Entropy -275.06256103515625, Learning Rate: 0.01\n",
      "Epoch [1417/20000], Loss: 308.60302734375, Entropy -278.76019287109375, Learning Rate: 0.01\n",
      "Epoch [1418/20000], Loss: 338.02911376953125, Entropy -279.5496826171875, Learning Rate: 0.01\n",
      "Epoch [1419/20000], Loss: 307.0834045410156, Entropy -288.6690673828125, Learning Rate: 0.01\n",
      "Epoch [1420/20000], Loss: 329.29132080078125, Entropy -284.3062438964844, Learning Rate: 0.01\n",
      "Epoch [1421/20000], Loss: 293.5799865722656, Entropy -285.8035583496094, Learning Rate: 0.01\n",
      "Epoch [1422/20000], Loss: 330.5445556640625, Entropy -295.61370849609375, Learning Rate: 0.01\n",
      "Epoch [1423/20000], Loss: 303.53326416015625, Entropy -283.1243591308594, Learning Rate: 0.01\n",
      "Epoch [1424/20000], Loss: 315.593505859375, Entropy -276.514892578125, Learning Rate: 0.01\n",
      "Epoch [1425/20000], Loss: 336.2422790527344, Entropy -288.3577880859375, Learning Rate: 0.01\n",
      "Epoch [1426/20000], Loss: 308.6672668457031, Entropy -285.21124267578125, Learning Rate: 0.01\n",
      "Epoch [1427/20000], Loss: 338.4010009765625, Entropy -284.10357666015625, Learning Rate: 0.01\n",
      "Epoch [1428/20000], Loss: 299.4327392578125, Entropy -281.0457763671875, Learning Rate: 0.01\n",
      "Epoch [1429/20000], Loss: 312.348388671875, Entropy -273.7024230957031, Learning Rate: 0.01\n",
      "Epoch [1430/20000], Loss: 304.65496826171875, Entropy -283.3343811035156, Learning Rate: 0.01\n",
      "Epoch [1431/20000], Loss: 316.29779052734375, Entropy -286.6119079589844, Learning Rate: 0.01\n",
      "Epoch [1432/20000], Loss: 298.8829345703125, Entropy -286.63751220703125, Learning Rate: 0.01\n",
      "Epoch [1433/20000], Loss: 297.5531921386719, Entropy -284.91680908203125, Learning Rate: 0.01\n",
      "Epoch [1434/20000], Loss: 310.3044738769531, Entropy -290.1517028808594, Learning Rate: 0.01\n",
      "Epoch [1435/20000], Loss: 318.5755920410156, Entropy -290.34454345703125, Learning Rate: 0.01\n",
      "Epoch [1436/20000], Loss: 306.2769775390625, Entropy -272.7745361328125, Learning Rate: 0.01\n",
      "Epoch [1437/20000], Loss: 303.4835510253906, Entropy -282.85101318359375, Learning Rate: 0.01\n",
      "Epoch [1438/20000], Loss: 321.4581298828125, Entropy -279.099365234375, Learning Rate: 0.01\n",
      "Epoch [1439/20000], Loss: 282.740478515625, Entropy -274.6469421386719, Learning Rate: 0.01\n",
      "Epoch [1440/20000], Loss: 310.48004150390625, Entropy -282.9044189453125, Learning Rate: 0.01\n",
      "Epoch [1441/20000], Loss: 294.6601867675781, Entropy -279.2154235839844, Learning Rate: 0.01\n",
      "Epoch [1442/20000], Loss: 305.6181640625, Entropy -293.26483154296875, Learning Rate: 0.01\n",
      "Epoch [1443/20000], Loss: 298.4075622558594, Entropy -280.33740234375, Learning Rate: 0.01\n",
      "Epoch [1444/20000], Loss: 301.70916748046875, Entropy -287.0036315917969, Learning Rate: 0.01\n",
      "Epoch [1445/20000], Loss: 306.98040771484375, Entropy -281.5933532714844, Learning Rate: 0.01\n",
      "Epoch [1446/20000], Loss: 338.79241943359375, Entropy -284.239013671875, Learning Rate: 0.01\n",
      "Epoch [1447/20000], Loss: 274.8139343261719, Entropy -275.9255676269531, Learning Rate: 0.01\n",
      "Epoch [1448/20000], Loss: 339.90325927734375, Entropy -283.278076171875, Learning Rate: 0.01\n",
      "Epoch [1449/20000], Loss: 302.46221923828125, Entropy -290.8808288574219, Learning Rate: 0.01\n",
      "Epoch [1450/20000], Loss: 344.5370788574219, Entropy -273.57135009765625, Learning Rate: 0.01\n",
      "Epoch [1451/20000], Loss: 294.63372802734375, Entropy -281.0291748046875, Learning Rate: 0.01\n",
      "Epoch [1452/20000], Loss: 322.0150451660156, Entropy -270.7515563964844, Learning Rate: 0.01\n",
      "Epoch [1453/20000], Loss: 357.1571350097656, Entropy -277.727294921875, Learning Rate: 0.01\n",
      "Epoch [1454/20000], Loss: 370.2559814453125, Entropy -280.30865478515625, Learning Rate: 0.01\n",
      "Epoch [1455/20000], Loss: 350.48388671875, Entropy -286.86492919921875, Learning Rate: 0.01\n",
      "Epoch [1456/20000], Loss: 335.57159423828125, Entropy -289.0048522949219, Learning Rate: 0.01\n",
      "Epoch [1457/20000], Loss: 383.7907409667969, Entropy -269.9635009765625, Learning Rate: 0.01\n",
      "Epoch [1458/20000], Loss: 308.2135009765625, Entropy -279.0233154296875, Learning Rate: 0.01\n",
      "Epoch [1459/20000], Loss: 354.71331787109375, Entropy -277.911865234375, Learning Rate: 0.01\n",
      "Epoch [1460/20000], Loss: 310.05029296875, Entropy -270.66680908203125, Learning Rate: 0.01\n",
      "Epoch [1461/20000], Loss: 320.03253173828125, Entropy -277.24957275390625, Learning Rate: 0.01\n",
      "Epoch [1462/20000], Loss: 312.23529052734375, Entropy -285.64691162109375, Learning Rate: 0.01\n",
      "Epoch [1463/20000], Loss: 331.0800476074219, Entropy -280.449462890625, Learning Rate: 0.01\n",
      "Epoch [1464/20000], Loss: 298.4250793457031, Entropy -282.7193908691406, Learning Rate: 0.01\n",
      "Epoch [1465/20000], Loss: 326.398681640625, Entropy -277.5013427734375, Learning Rate: 0.01\n",
      "Epoch [1466/20000], Loss: 330.0419921875, Entropy -272.6960754394531, Learning Rate: 0.01\n",
      "Epoch [1467/20000], Loss: 318.5722961425781, Entropy -265.8310241699219, Learning Rate: 0.01\n",
      "Epoch [1468/20000], Loss: 341.1634216308594, Entropy -286.20709228515625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1469/20000], Loss: 280.91796875, Entropy -271.9715270996094, Learning Rate: 0.01\n",
      "Epoch [1470/20000], Loss: 317.8755798339844, Entropy -288.78472900390625, Learning Rate: 0.01\n",
      "Epoch [1471/20000], Loss: 304.5879821777344, Entropy -284.91510009765625, Learning Rate: 0.01\n",
      "Epoch [1472/20000], Loss: 302.3880310058594, Entropy -279.3114318847656, Learning Rate: 0.01\n",
      "Epoch [1473/20000], Loss: 304.33740234375, Entropy -277.1700439453125, Learning Rate: 0.01\n",
      "Epoch [1474/20000], Loss: 304.76129150390625, Entropy -272.79840087890625, Learning Rate: 0.01\n",
      "Epoch [1475/20000], Loss: 289.7817687988281, Entropy -274.57427978515625, Learning Rate: 0.01\n",
      "Epoch [1476/20000], Loss: 304.6180419921875, Entropy -286.97711181640625, Learning Rate: 0.01\n",
      "Epoch [1477/20000], Loss: 362.2147521972656, Entropy -276.415771484375, Learning Rate: 0.01\n",
      "Epoch [1478/20000], Loss: 340.32623291015625, Entropy -275.46832275390625, Learning Rate: 0.01\n",
      "Epoch [1479/20000], Loss: 298.3951110839844, Entropy -291.55389404296875, Learning Rate: 0.01\n",
      "Epoch [1480/20000], Loss: 311.0296325683594, Entropy -271.8454895019531, Learning Rate: 0.01\n",
      "Epoch [1481/20000], Loss: 338.492431640625, Entropy -279.52923583984375, Learning Rate: 0.01\n",
      "Epoch [1482/20000], Loss: 292.5616149902344, Entropy -278.9814147949219, Learning Rate: 0.01\n",
      "Epoch [1483/20000], Loss: 289.0075988769531, Entropy -269.5999450683594, Learning Rate: 0.01\n",
      "Epoch [1484/20000], Loss: 299.1783142089844, Entropy -280.8166198730469, Learning Rate: 0.01\n",
      "Epoch [1485/20000], Loss: 291.27685546875, Entropy -282.07464599609375, Learning Rate: 0.01\n",
      "Epoch [1486/20000], Loss: 292.793212890625, Entropy -287.7872619628906, Learning Rate: 0.01\n",
      "Epoch [1487/20000], Loss: 284.0379638671875, Entropy -278.672119140625, Learning Rate: 0.01\n",
      "Epoch [1488/20000], Loss: 280.7033996582031, Entropy -273.1274719238281, Learning Rate: 0.01\n",
      "Epoch [1489/20000], Loss: 286.04974365234375, Entropy -279.67718505859375, Learning Rate: 0.01\n",
      "Epoch [1490/20000], Loss: 292.9967956542969, Entropy -279.4300231933594, Learning Rate: 0.01\n",
      "Epoch [1491/20000], Loss: 294.5825500488281, Entropy -283.4762268066406, Learning Rate: 0.01\n",
      "Epoch [1492/20000], Loss: 292.7299499511719, Entropy -281.72271728515625, Learning Rate: 0.01\n",
      "Epoch [1493/20000], Loss: 295.47467041015625, Entropy -286.45989990234375, Learning Rate: 0.01\n",
      "Epoch [1494/20000], Loss: 278.6936340332031, Entropy -282.8402099609375, Learning Rate: 0.01\n",
      "Epoch [1495/20000], Loss: 291.6391296386719, Entropy -282.8172607421875, Learning Rate: 0.01\n",
      "Epoch [1496/20000], Loss: 287.6885986328125, Entropy -278.7294616699219, Learning Rate: 0.01\n",
      "Epoch [1497/20000], Loss: 271.7686767578125, Entropy -267.6830139160156, Learning Rate: 0.01\n",
      "Epoch [1498/20000], Loss: 297.88690185546875, Entropy -283.7811584472656, Learning Rate: 0.01\n",
      "Epoch [1499/20000], Loss: 317.251953125, Entropy -272.4464416503906, Learning Rate: 0.01\n",
      "Epoch [1500/20000], Loss: 342.9196472167969, Entropy -289.1006774902344, Learning Rate: 0.01\n",
      "Epoch [1501/20000], Loss: 306.83575439453125, Entropy -281.7254943847656, Learning Rate: 0.01\n",
      "Epoch [1502/20000], Loss: 299.2721252441406, Entropy -291.1029357910156, Learning Rate: 0.01\n",
      "Epoch [1503/20000], Loss: 296.34991455078125, Entropy -281.996337890625, Learning Rate: 0.01\n",
      "Epoch [1504/20000], Loss: 284.74066162109375, Entropy -265.53900146484375, Learning Rate: 0.01\n",
      "Epoch [1505/20000], Loss: 287.0989990234375, Entropy -286.6473083496094, Learning Rate: 0.01\n",
      "Epoch [1506/20000], Loss: 280.5567321777344, Entropy -266.89483642578125, Learning Rate: 0.01\n",
      "Epoch [1507/20000], Loss: 310.4726257324219, Entropy -269.1572265625, Learning Rate: 0.01\n",
      "Epoch [1508/20000], Loss: 316.8768310546875, Entropy -276.5001220703125, Learning Rate: 0.01\n",
      "Epoch [1509/20000], Loss: 297.8922119140625, Entropy -279.98388671875, Learning Rate: 0.01\n",
      "Epoch [1510/20000], Loss: 293.84759521484375, Entropy -280.6529541015625, Learning Rate: 0.01\n",
      "Epoch [1511/20000], Loss: 315.33905029296875, Entropy -269.3962707519531, Learning Rate: 0.01\n",
      "Epoch [1512/20000], Loss: 270.80780029296875, Entropy -276.8550109863281, Learning Rate: 0.01\n",
      "Epoch [1513/20000], Loss: 306.55108642578125, Entropy -279.3968200683594, Learning Rate: 0.01\n",
      "Epoch [1514/20000], Loss: 300.4302062988281, Entropy -275.87017822265625, Learning Rate: 0.01\n",
      "Epoch [1515/20000], Loss: 293.9151611328125, Entropy -273.400390625, Learning Rate: 0.01\n",
      "Epoch [1516/20000], Loss: 303.4450988769531, Entropy -279.4162292480469, Learning Rate: 0.01\n",
      "Epoch [1517/20000], Loss: 267.63739013671875, Entropy -273.5139465332031, Learning Rate: 0.01\n",
      "Epoch [1518/20000], Loss: 300.3867492675781, Entropy -279.1122131347656, Learning Rate: 0.01\n",
      "Epoch [1519/20000], Loss: 288.4262390136719, Entropy -285.76458740234375, Learning Rate: 0.01\n",
      "Epoch [1520/20000], Loss: 268.75018310546875, Entropy -278.0616455078125, Learning Rate: 0.01\n",
      "Epoch [1521/20000], Loss: 281.1050109863281, Entropy -270.223876953125, Learning Rate: 0.01\n",
      "Epoch [1522/20000], Loss: 285.3902587890625, Entropy -287.03973388671875, Learning Rate: 0.01\n",
      "Epoch [1523/20000], Loss: 289.537109375, Entropy -267.97125244140625, Learning Rate: 0.01\n",
      "Epoch [1524/20000], Loss: 310.9183044433594, Entropy -291.01629638671875, Learning Rate: 0.01\n",
      "Epoch [1525/20000], Loss: 282.02105712890625, Entropy -275.15631103515625, Learning Rate: 0.01\n",
      "Epoch [1526/20000], Loss: 294.44940185546875, Entropy -277.86468505859375, Learning Rate: 0.01\n",
      "Epoch [1527/20000], Loss: 286.96826171875, Entropy -288.077880859375, Learning Rate: 0.01\n",
      "Epoch [1528/20000], Loss: 320.6163330078125, Entropy -267.5346984863281, Learning Rate: 0.01\n",
      "Epoch [1529/20000], Loss: 328.0648193359375, Entropy -282.1494140625, Learning Rate: 0.01\n",
      "Epoch [1530/20000], Loss: 293.60992431640625, Entropy -271.3093566894531, Learning Rate: 0.01\n",
      "Epoch [1531/20000], Loss: 281.2739562988281, Entropy -283.0400390625, Learning Rate: 0.01\n",
      "Epoch [1532/20000], Loss: 291.181884765625, Entropy -274.8542785644531, Learning Rate: 0.01\n",
      "Epoch [1533/20000], Loss: 322.091796875, Entropy -284.4123229980469, Learning Rate: 0.01\n",
      "Epoch [1534/20000], Loss: 346.09228515625, Entropy -281.80377197265625, Learning Rate: 0.01\n",
      "Epoch [1535/20000], Loss: 301.4588623046875, Entropy -292.852294921875, Learning Rate: 0.01\n",
      "Epoch [1536/20000], Loss: 284.18438720703125, Entropy -288.879638671875, Learning Rate: 0.01\n",
      "Epoch [1537/20000], Loss: 343.7611389160156, Entropy -276.5746765136719, Learning Rate: 0.01\n",
      "Epoch [1538/20000], Loss: 427.2100830078125, Entropy -282.41949462890625, Learning Rate: 0.01\n",
      "Epoch [1539/20000], Loss: 321.8844299316406, Entropy -287.1840515136719, Learning Rate: 0.01\n",
      "Epoch [1540/20000], Loss: 382.1917419433594, Entropy -279.2312927246094, Learning Rate: 0.01\n",
      "Epoch [1541/20000], Loss: 632.378173828125, Entropy -276.40496826171875, Learning Rate: 0.01\n",
      "Epoch [1542/20000], Loss: 596.8637084960938, Entropy -265.8794250488281, Learning Rate: 0.01\n",
      "Epoch [1543/20000], Loss: 382.62335205078125, Entropy -280.43524169921875, Learning Rate: 0.01\n",
      "Epoch [1544/20000], Loss: 429.50848388671875, Entropy -278.042236328125, Learning Rate: 0.01\n",
      "Epoch [1545/20000], Loss: 546.4469604492188, Entropy -274.61724853515625, Learning Rate: 0.01\n",
      "Epoch [1546/20000], Loss: 366.5397644042969, Entropy -272.831298828125, Learning Rate: 0.01\n",
      "Epoch [1547/20000], Loss: 457.6922302246094, Entropy -271.7983093261719, Learning Rate: 0.01\n",
      "Epoch [1548/20000], Loss: 629.8535766601562, Entropy -269.779296875, Learning Rate: 0.01\n",
      "Epoch [1549/20000], Loss: 564.2003784179688, Entropy -288.676025390625, Learning Rate: 0.01\n",
      "Epoch [1550/20000], Loss: 386.3170166015625, Entropy -262.0699768066406, Learning Rate: 0.01\n",
      "Epoch [1551/20000], Loss: 370.20306396484375, Entropy -273.1364440917969, Learning Rate: 0.01\n",
      "Epoch [1552/20000], Loss: 371.8489990234375, Entropy -279.47503662109375, Learning Rate: 0.01\n",
      "Epoch [1553/20000], Loss: 373.49871826171875, Entropy -283.6791687011719, Learning Rate: 0.01\n",
      "Epoch [1554/20000], Loss: 400.283447265625, Entropy -277.22515869140625, Learning Rate: 0.01\n",
      "Epoch [1555/20000], Loss: 379.0713195800781, Entropy -279.2784118652344, Learning Rate: 0.01\n",
      "Epoch [1556/20000], Loss: 444.26739501953125, Entropy -282.3735046386719, Learning Rate: 0.01\n",
      "Epoch [1557/20000], Loss: 435.1304016113281, Entropy -265.84979248046875, Learning Rate: 0.01\n",
      "Epoch [1558/20000], Loss: 344.8668212890625, Entropy -270.4243469238281, Learning Rate: 0.01\n",
      "Epoch [1559/20000], Loss: 402.4074401855469, Entropy -282.0312194824219, Learning Rate: 0.01\n",
      "Epoch [1560/20000], Loss: 732.829345703125, Entropy -279.09686279296875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1561/20000], Loss: 738.56689453125, Entropy -273.7005310058594, Learning Rate: 0.01\n",
      "Epoch [1562/20000], Loss: 465.705078125, Entropy -277.6795654296875, Learning Rate: 0.01\n",
      "Epoch [1563/20000], Loss: 475.57904052734375, Entropy -275.26068115234375, Learning Rate: 0.01\n",
      "Epoch [1564/20000], Loss: 400.6473693847656, Entropy -281.2041015625, Learning Rate: 0.01\n",
      "Epoch [1565/20000], Loss: 360.9371337890625, Entropy -265.2735290527344, Learning Rate: 0.01\n",
      "Epoch [1566/20000], Loss: 402.4032897949219, Entropy -267.81524658203125, Learning Rate: 0.01\n",
      "Epoch [1567/20000], Loss: 585.7222290039062, Entropy -270.57098388671875, Learning Rate: 0.01\n",
      "Epoch [1568/20000], Loss: 697.658935546875, Entropy -269.521240234375, Learning Rate: 0.01\n",
      "Epoch [1569/20000], Loss: 524.4517822265625, Entropy -277.75433349609375, Learning Rate: 0.01\n",
      "Epoch [1570/20000], Loss: 791.9850463867188, Entropy -282.54638671875, Learning Rate: 0.01\n",
      "Epoch [1571/20000], Loss: 371.1376647949219, Entropy -274.21466064453125, Learning Rate: 0.01\n",
      "Epoch [1572/20000], Loss: 465.72906494140625, Entropy -282.07421875, Learning Rate: 0.01\n",
      "Epoch [1573/20000], Loss: 309.3136291503906, Entropy -280.06683349609375, Learning Rate: 0.01\n",
      "Epoch [1574/20000], Loss: 418.8851623535156, Entropy -275.5751647949219, Learning Rate: 0.01\n",
      "Epoch [1575/20000], Loss: 323.11669921875, Entropy -277.2915954589844, Learning Rate: 0.01\n",
      "Epoch [1576/20000], Loss: 436.7234191894531, Entropy -273.1028137207031, Learning Rate: 0.01\n",
      "Epoch [1577/20000], Loss: 437.54730224609375, Entropy -274.37530517578125, Learning Rate: 0.01\n",
      "Epoch [1578/20000], Loss: 395.3221130371094, Entropy -280.4910888671875, Learning Rate: 0.01\n",
      "Epoch [1579/20000], Loss: 348.13079833984375, Entropy -282.4474792480469, Learning Rate: 0.01\n",
      "Epoch [1580/20000], Loss: 369.75897216796875, Entropy -281.2363586425781, Learning Rate: 0.01\n",
      "Epoch [1581/20000], Loss: 420.7453308105469, Entropy -295.96197509765625, Learning Rate: 0.01\n",
      "Epoch [1582/20000], Loss: 378.5501708984375, Entropy -287.5323181152344, Learning Rate: 0.01\n",
      "Epoch [1583/20000], Loss: 354.34124755859375, Entropy -288.6394958496094, Learning Rate: 0.01\n",
      "Epoch [1584/20000], Loss: 348.5835266113281, Entropy -275.4554443359375, Learning Rate: 0.01\n",
      "Epoch [1585/20000], Loss: 358.0956726074219, Entropy -294.2152404785156, Learning Rate: 0.01\n",
      "Epoch [1586/20000], Loss: 356.2857666015625, Entropy -271.3173522949219, Learning Rate: 0.01\n",
      "Epoch [1587/20000], Loss: 360.687255859375, Entropy -278.1972351074219, Learning Rate: 0.01\n",
      "Epoch [1588/20000], Loss: 342.411376953125, Entropy -281.35931396484375, Learning Rate: 0.01\n",
      "Epoch [1589/20000], Loss: 343.32177734375, Entropy -273.9757385253906, Learning Rate: 0.01\n",
      "Epoch [1590/20000], Loss: 319.288818359375, Entropy -283.1145935058594, Learning Rate: 0.01\n",
      "Epoch [1591/20000], Loss: 336.63037109375, Entropy -278.22930908203125, Learning Rate: 0.01\n",
      "Epoch [1592/20000], Loss: 313.61468505859375, Entropy -286.109375, Learning Rate: 0.01\n",
      "Epoch [1593/20000], Loss: 308.349365234375, Entropy -289.63970947265625, Learning Rate: 0.01\n",
      "Epoch [1594/20000], Loss: 305.47845458984375, Entropy -280.404541015625, Learning Rate: 0.01\n",
      "Epoch [1595/20000], Loss: 290.9570617675781, Entropy -278.0381774902344, Learning Rate: 0.01\n",
      "Epoch [1596/20000], Loss: 291.41107177734375, Entropy -279.3579406738281, Learning Rate: 0.01\n",
      "Epoch [1597/20000], Loss: 324.96429443359375, Entropy -276.06561279296875, Learning Rate: 0.01\n",
      "Epoch [1598/20000], Loss: 322.1841735839844, Entropy -280.6723327636719, Learning Rate: 0.01\n",
      "Epoch [1599/20000], Loss: 286.8087463378906, Entropy -276.1064147949219, Learning Rate: 0.01\n",
      "Epoch [1600/20000], Loss: 322.6565856933594, Entropy -275.9088134765625, Learning Rate: 0.01\n",
      "Epoch [1601/20000], Loss: 304.48681640625, Entropy -283.1268310546875, Learning Rate: 0.01\n",
      "Epoch [1602/20000], Loss: 317.0043640136719, Entropy -289.3173828125, Learning Rate: 0.01\n",
      "Epoch [1603/20000], Loss: 302.569091796875, Entropy -287.46759033203125, Learning Rate: 0.01\n",
      "Epoch [1604/20000], Loss: 317.572998046875, Entropy -286.5831298828125, Learning Rate: 0.01\n",
      "Epoch [1605/20000], Loss: 282.46856689453125, Entropy -277.5177307128906, Learning Rate: 0.01\n",
      "Epoch [1606/20000], Loss: 304.18487548828125, Entropy -295.8188781738281, Learning Rate: 0.01\n",
      "Epoch [1607/20000], Loss: 300.17315673828125, Entropy -281.623779296875, Learning Rate: 0.01\n",
      "Epoch [1608/20000], Loss: 287.0462646484375, Entropy -287.96978759765625, Learning Rate: 0.01\n",
      "Epoch [1609/20000], Loss: 303.29656982421875, Entropy -283.15728759765625, Learning Rate: 0.01\n",
      "Epoch [1610/20000], Loss: 305.79608154296875, Entropy -292.83245849609375, Learning Rate: 0.01\n",
      "Epoch [1611/20000], Loss: 306.2593688964844, Entropy -280.8540344238281, Learning Rate: 0.01\n",
      "Epoch [1612/20000], Loss: 297.66143798828125, Entropy -283.96844482421875, Learning Rate: 0.01\n",
      "Epoch [1613/20000], Loss: 283.77740478515625, Entropy -279.0843505859375, Learning Rate: 0.01\n",
      "Epoch [1614/20000], Loss: 284.14471435546875, Entropy -280.499267578125, Learning Rate: 0.01\n",
      "Epoch [1615/20000], Loss: 294.29046630859375, Entropy -290.3883361816406, Learning Rate: 0.01\n",
      "Epoch [1616/20000], Loss: 293.8465576171875, Entropy -282.6692810058594, Learning Rate: 0.01\n",
      "Epoch [1617/20000], Loss: 287.63409423828125, Entropy -280.4100341796875, Learning Rate: 0.01\n",
      "Epoch [1618/20000], Loss: 285.63275146484375, Entropy -271.89532470703125, Learning Rate: 0.01\n",
      "Epoch [1619/20000], Loss: 286.7381591796875, Entropy -274.17803955078125, Learning Rate: 0.01\n",
      "Epoch [1620/20000], Loss: 284.75823974609375, Entropy -278.9869079589844, Learning Rate: 0.01\n",
      "Epoch [1621/20000], Loss: 288.73345947265625, Entropy -287.7509765625, Learning Rate: 0.01\n",
      "Epoch [1622/20000], Loss: 283.12939453125, Entropy -288.7855529785156, Learning Rate: 0.01\n",
      "Epoch [1623/20000], Loss: 281.5091552734375, Entropy -281.53216552734375, Learning Rate: 0.01\n",
      "Epoch [1624/20000], Loss: 269.5944519042969, Entropy -274.9864501953125, Learning Rate: 0.01\n",
      "Epoch [1625/20000], Loss: 272.0740966796875, Entropy -274.50714111328125, Learning Rate: 0.01\n",
      "Epoch [1626/20000], Loss: 287.7232971191406, Entropy -281.19842529296875, Learning Rate: 0.01\n",
      "Epoch [1627/20000], Loss: 273.2072448730469, Entropy -275.6850280761719, Learning Rate: 0.01\n",
      "Epoch [1628/20000], Loss: 269.4615478515625, Entropy -276.88909912109375, Learning Rate: 0.01\n",
      "Epoch [1629/20000], Loss: 283.626708984375, Entropy -285.5975646972656, Learning Rate: 0.01\n",
      "Epoch [1630/20000], Loss: 281.167236328125, Entropy -278.7885437011719, Learning Rate: 0.01\n",
      "Epoch [1631/20000], Loss: 287.93585205078125, Entropy -287.5201416015625, Learning Rate: 0.01\n",
      "Epoch [1632/20000], Loss: 266.34820556640625, Entropy -272.1819763183594, Learning Rate: 0.01\n",
      "Epoch [1633/20000], Loss: 274.55487060546875, Entropy -277.345947265625, Learning Rate: 0.01\n",
      "Epoch [1634/20000], Loss: 254.94679260253906, Entropy -272.02288818359375, Learning Rate: 0.01\n",
      "Epoch [1635/20000], Loss: 280.49603271484375, Entropy -295.4835205078125, Learning Rate: 0.01\n",
      "Epoch [1636/20000], Loss: 278.163330078125, Entropy -288.66290283203125, Learning Rate: 0.01\n",
      "Epoch [1637/20000], Loss: 280.2821044921875, Entropy -287.5375061035156, Learning Rate: 0.01\n",
      "Epoch [1638/20000], Loss: 270.05499267578125, Entropy -278.9284973144531, Learning Rate: 0.01\n",
      "Epoch [1639/20000], Loss: 270.49462890625, Entropy -286.8791809082031, Learning Rate: 0.01\n",
      "Epoch [1640/20000], Loss: 278.4106140136719, Entropy -286.0533142089844, Learning Rate: 0.01\n",
      "Epoch [1641/20000], Loss: 267.4864501953125, Entropy -276.2353210449219, Learning Rate: 0.01\n",
      "Epoch [1642/20000], Loss: 271.7325439453125, Entropy -272.3283996582031, Learning Rate: 0.01\n",
      "Epoch [1643/20000], Loss: 270.65948486328125, Entropy -273.2735595703125, Learning Rate: 0.01\n",
      "Epoch [1644/20000], Loss: 296.85931396484375, Entropy -270.4571228027344, Learning Rate: 0.01\n",
      "Epoch [1645/20000], Loss: 258.9306335449219, Entropy -272.22052001953125, Learning Rate: 0.01\n",
      "Epoch [1646/20000], Loss: 286.75640869140625, Entropy -271.8749084472656, Learning Rate: 0.01\n",
      "Epoch [1647/20000], Loss: 295.4268493652344, Entropy -287.6140441894531, Learning Rate: 0.01\n",
      "Epoch [1648/20000], Loss: 266.450439453125, Entropy -272.76727294921875, Learning Rate: 0.01\n",
      "Epoch [1649/20000], Loss: 281.35443115234375, Entropy -265.2339782714844, Learning Rate: 0.01\n",
      "Epoch [1650/20000], Loss: 285.45263671875, Entropy -278.4767761230469, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1651/20000], Loss: 345.0693054199219, Entropy -273.9559326171875, Learning Rate: 0.01\n",
      "Epoch [1652/20000], Loss: 307.31195068359375, Entropy -267.3170166015625, Learning Rate: 0.01\n",
      "Epoch [1653/20000], Loss: 275.19866943359375, Entropy -277.9290466308594, Learning Rate: 0.01\n",
      "Epoch [1654/20000], Loss: 310.4690856933594, Entropy -282.7070007324219, Learning Rate: 0.01\n",
      "Epoch [1655/20000], Loss: 276.6147155761719, Entropy -278.1032409667969, Learning Rate: 0.01\n",
      "Epoch [1656/20000], Loss: 274.775634765625, Entropy -283.0684814453125, Learning Rate: 0.01\n",
      "Epoch [1657/20000], Loss: 296.4366149902344, Entropy -273.5942687988281, Learning Rate: 0.01\n",
      "Epoch [1658/20000], Loss: 263.08251953125, Entropy -275.93701171875, Learning Rate: 0.01\n",
      "Epoch [1659/20000], Loss: 272.278076171875, Entropy -271.15216064453125, Learning Rate: 0.01\n",
      "Epoch [1660/20000], Loss: 275.50390625, Entropy -280.324951171875, Learning Rate: 0.01\n",
      "Epoch [1661/20000], Loss: 273.2162170410156, Entropy -282.229248046875, Learning Rate: 0.01\n",
      "Epoch [1662/20000], Loss: 281.5836181640625, Entropy -276.87255859375, Learning Rate: 0.01\n",
      "Epoch [1663/20000], Loss: 251.6099090576172, Entropy -263.752197265625, Learning Rate: 0.01\n",
      "Epoch [1664/20000], Loss: 272.353515625, Entropy -281.0066223144531, Learning Rate: 0.01\n",
      "Epoch [1665/20000], Loss: 268.36279296875, Entropy -274.6217346191406, Learning Rate: 0.01\n",
      "Epoch [1666/20000], Loss: 263.13677978515625, Entropy -276.2983093261719, Learning Rate: 0.01\n",
      "Epoch [1667/20000], Loss: 268.93988037109375, Entropy -277.3146667480469, Learning Rate: 0.01\n",
      "Epoch [1668/20000], Loss: 259.8441162109375, Entropy -275.76287841796875, Learning Rate: 0.01\n",
      "Epoch [1669/20000], Loss: 251.81065368652344, Entropy -266.68170166015625, Learning Rate: 0.01\n",
      "Epoch [1670/20000], Loss: 272.0335693359375, Entropy -275.4215393066406, Learning Rate: 0.01\n",
      "Epoch [1671/20000], Loss: 258.33013916015625, Entropy -282.3723449707031, Learning Rate: 0.01\n",
      "Epoch [1672/20000], Loss: 271.433349609375, Entropy -279.6341247558594, Learning Rate: 0.01\n",
      "Epoch [1673/20000], Loss: 260.97998046875, Entropy -283.7432556152344, Learning Rate: 0.01\n",
      "Epoch [1674/20000], Loss: 258.0650939941406, Entropy -278.2716064453125, Learning Rate: 0.01\n",
      "Epoch [1675/20000], Loss: 258.2610778808594, Entropy -267.08221435546875, Learning Rate: 0.01\n",
      "Epoch [1676/20000], Loss: 260.18280029296875, Entropy -268.9079895019531, Learning Rate: 0.01\n",
      "Epoch [1677/20000], Loss: 272.9061279296875, Entropy -276.37249755859375, Learning Rate: 0.01\n",
      "Epoch [1678/20000], Loss: 252.34173583984375, Entropy -271.45855712890625, Learning Rate: 0.01\n",
      "Epoch [1679/20000], Loss: 259.90435791015625, Entropy -280.4499206542969, Learning Rate: 0.01\n",
      "Epoch [1680/20000], Loss: 264.0057067871094, Entropy -269.3623962402344, Learning Rate: 0.01\n",
      "Epoch [1681/20000], Loss: 258.48291015625, Entropy -274.9444274902344, Learning Rate: 0.01\n",
      "Epoch [1682/20000], Loss: 261.00286865234375, Entropy -271.8272705078125, Learning Rate: 0.01\n",
      "Epoch [1683/20000], Loss: 250.6471710205078, Entropy -274.7513427734375, Learning Rate: 0.01\n",
      "Epoch [1684/20000], Loss: 267.1666259765625, Entropy -279.6417236328125, Learning Rate: 0.01\n",
      "Epoch [1685/20000], Loss: 269.9564208984375, Entropy -276.2785339355469, Learning Rate: 0.01\n",
      "Epoch [1686/20000], Loss: 256.78448486328125, Entropy -273.4932861328125, Learning Rate: 0.01\n",
      "Epoch [1687/20000], Loss: 257.130126953125, Entropy -274.7289123535156, Learning Rate: 0.01\n",
      "Epoch [1688/20000], Loss: 265.57958984375, Entropy -267.2311096191406, Learning Rate: 0.01\n",
      "Epoch [1689/20000], Loss: 240.44131469726562, Entropy -260.9693908691406, Learning Rate: 0.01\n",
      "Epoch [1690/20000], Loss: 256.96392822265625, Entropy -280.48394775390625, Learning Rate: 0.01\n",
      "Epoch [1691/20000], Loss: 272.86138916015625, Entropy -291.9546203613281, Learning Rate: 0.01\n",
      "Epoch [1692/20000], Loss: 259.30987548828125, Entropy -278.301513671875, Learning Rate: 0.01\n",
      "Epoch [1693/20000], Loss: 249.549072265625, Entropy -275.5604248046875, Learning Rate: 0.01\n",
      "Epoch [1694/20000], Loss: 264.8380126953125, Entropy -277.0673522949219, Learning Rate: 0.01\n",
      "Epoch [1695/20000], Loss: 254.43499755859375, Entropy -279.042236328125, Learning Rate: 0.01\n",
      "Epoch [1696/20000], Loss: 272.53857421875, Entropy -274.6653137207031, Learning Rate: 0.01\n",
      "Epoch [1697/20000], Loss: 273.895751953125, Entropy -270.0074768066406, Learning Rate: 0.01\n",
      "Epoch [1698/20000], Loss: 255.2783966064453, Entropy -263.6988830566406, Learning Rate: 0.01\n",
      "Epoch [1699/20000], Loss: 265.63592529296875, Entropy -265.1799621582031, Learning Rate: 0.01\n",
      "Epoch [1700/20000], Loss: 270.5860595703125, Entropy -277.9111328125, Learning Rate: 0.01\n",
      "Epoch [1701/20000], Loss: 265.0910949707031, Entropy -283.6734313964844, Learning Rate: 0.01\n",
      "Epoch [1702/20000], Loss: 265.2755432128906, Entropy -274.5690002441406, Learning Rate: 0.01\n",
      "Epoch [1703/20000], Loss: 258.28704833984375, Entropy -268.9932861328125, Learning Rate: 0.01\n",
      "Epoch [1704/20000], Loss: 249.595703125, Entropy -262.25579833984375, Learning Rate: 0.01\n",
      "Epoch [1705/20000], Loss: 271.1072998046875, Entropy -268.9694519042969, Learning Rate: 0.01\n",
      "Epoch [1706/20000], Loss: 256.3104553222656, Entropy -272.2466735839844, Learning Rate: 0.01\n",
      "Epoch [1707/20000], Loss: 252.1341094970703, Entropy -272.32666015625, Learning Rate: 0.01\n",
      "Epoch [1708/20000], Loss: 254.48141479492188, Entropy -268.28668212890625, Learning Rate: 0.01\n",
      "Epoch [1709/20000], Loss: 259.26519775390625, Entropy -271.91107177734375, Learning Rate: 0.01\n",
      "Epoch [1710/20000], Loss: 262.4339599609375, Entropy -267.05133056640625, Learning Rate: 0.01\n",
      "Epoch [1711/20000], Loss: 256.5250549316406, Entropy -252.50982666015625, Learning Rate: 0.01\n",
      "Epoch [1712/20000], Loss: 285.8837890625, Entropy -271.668701171875, Learning Rate: 0.01\n",
      "Epoch [1713/20000], Loss: 289.61785888671875, Entropy -265.409423828125, Learning Rate: 0.01\n",
      "Epoch [1714/20000], Loss: 312.21405029296875, Entropy -274.4532775878906, Learning Rate: 0.01\n",
      "Epoch [1715/20000], Loss: 336.0479736328125, Entropy -263.7122802734375, Learning Rate: 0.01\n",
      "Epoch [1716/20000], Loss: 292.642333984375, Entropy -269.7137756347656, Learning Rate: 0.01\n",
      "Epoch [1717/20000], Loss: 330.0404968261719, Entropy -273.42706298828125, Learning Rate: 0.01\n",
      "Epoch [1718/20000], Loss: 309.74114990234375, Entropy -265.6887512207031, Learning Rate: 0.01\n",
      "Epoch [1719/20000], Loss: 262.60748291015625, Entropy -273.2143859863281, Learning Rate: 0.01\n",
      "Epoch [1720/20000], Loss: 301.1211853027344, Entropy -274.9833984375, Learning Rate: 0.01\n",
      "Epoch [1721/20000], Loss: 302.95062255859375, Entropy -273.7431640625, Learning Rate: 0.01\n",
      "Epoch [1722/20000], Loss: 270.4249267578125, Entropy -261.93560791015625, Learning Rate: 0.01\n",
      "Epoch [1723/20000], Loss: 256.3857421875, Entropy -263.07171630859375, Learning Rate: 0.01\n",
      "Epoch [1724/20000], Loss: 357.6083068847656, Entropy -272.8956298828125, Learning Rate: 0.01\n",
      "Epoch [1725/20000], Loss: 278.14056396484375, Entropy -271.8311767578125, Learning Rate: 0.01\n",
      "Epoch [1726/20000], Loss: 324.21142578125, Entropy -269.794921875, Learning Rate: 0.01\n",
      "Epoch [1727/20000], Loss: 378.08538818359375, Entropy -276.8477478027344, Learning Rate: 0.01\n",
      "Epoch [1728/20000], Loss: 333.22601318359375, Entropy -279.9794006347656, Learning Rate: 0.01\n",
      "Epoch [1729/20000], Loss: 291.4786376953125, Entropy -264.9120178222656, Learning Rate: 0.01\n",
      "Epoch [1730/20000], Loss: 296.175537109375, Entropy -262.33209228515625, Learning Rate: 0.01\n",
      "Epoch [1731/20000], Loss: 299.1015319824219, Entropy -267.660400390625, Learning Rate: 0.01\n",
      "Epoch [1732/20000], Loss: 283.12371826171875, Entropy -269.9595031738281, Learning Rate: 0.01\n",
      "Epoch [1733/20000], Loss: 274.5075988769531, Entropy -264.9800109863281, Learning Rate: 0.01\n",
      "Epoch [1734/20000], Loss: 294.32098388671875, Entropy -271.8368835449219, Learning Rate: 0.01\n",
      "Epoch [1735/20000], Loss: 271.1432189941406, Entropy -268.71588134765625, Learning Rate: 0.01\n",
      "Epoch [1736/20000], Loss: 284.3135986328125, Entropy -268.77471923828125, Learning Rate: 0.01\n",
      "Epoch [1737/20000], Loss: 281.9053039550781, Entropy -268.8131103515625, Learning Rate: 0.01\n",
      "Epoch [1738/20000], Loss: 289.1681213378906, Entropy -267.5304870605469, Learning Rate: 0.01\n",
      "Epoch [1739/20000], Loss: 305.00006103515625, Entropy -277.57635498046875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1740/20000], Loss: 260.21636962890625, Entropy -274.30828857421875, Learning Rate: 0.01\n",
      "Epoch [1741/20000], Loss: 274.57977294921875, Entropy -281.7615661621094, Learning Rate: 0.01\n",
      "Epoch [1742/20000], Loss: 262.08306884765625, Entropy -270.6748046875, Learning Rate: 0.01\n",
      "Epoch [1743/20000], Loss: 301.5649108886719, Entropy -281.8471984863281, Learning Rate: 0.01\n",
      "Epoch [1744/20000], Loss: 252.22601318359375, Entropy -270.1849365234375, Learning Rate: 0.01\n",
      "Epoch [1745/20000], Loss: 293.5733337402344, Entropy -279.2743835449219, Learning Rate: 0.01\n",
      "Epoch [1746/20000], Loss: 287.4068908691406, Entropy -263.6633605957031, Learning Rate: 0.01\n",
      "Epoch [1747/20000], Loss: 261.0028076171875, Entropy -272.3326110839844, Learning Rate: 0.01\n",
      "Epoch [1748/20000], Loss: 269.5245361328125, Entropy -272.35699462890625, Learning Rate: 0.01\n",
      "Epoch [1749/20000], Loss: 263.674560546875, Entropy -272.9138488769531, Learning Rate: 0.01\n",
      "Epoch [1750/20000], Loss: 257.3985595703125, Entropy -265.49761962890625, Learning Rate: 0.01\n",
      "Epoch [1751/20000], Loss: 266.58984375, Entropy -266.70562744140625, Learning Rate: 0.01\n",
      "Epoch [1752/20000], Loss: 249.5196990966797, Entropy -258.8975830078125, Learning Rate: 0.01\n",
      "Epoch [1753/20000], Loss: 278.2286376953125, Entropy -281.1235656738281, Learning Rate: 0.01\n",
      "Epoch [1754/20000], Loss: 268.5943603515625, Entropy -272.9801940917969, Learning Rate: 0.01\n",
      "Epoch [1755/20000], Loss: 264.21270751953125, Entropy -273.7797546386719, Learning Rate: 0.01\n",
      "Epoch [1756/20000], Loss: 257.94696044921875, Entropy -263.7898864746094, Learning Rate: 0.01\n",
      "Epoch [1757/20000], Loss: 254.68096923828125, Entropy -266.7728271484375, Learning Rate: 0.01\n",
      "Epoch [1758/20000], Loss: 260.1532287597656, Entropy -263.5640563964844, Learning Rate: 0.01\n",
      "Epoch [1759/20000], Loss: 288.03289794921875, Entropy -273.3505859375, Learning Rate: 0.01\n",
      "Epoch [1760/20000], Loss: 276.98553466796875, Entropy -267.8648681640625, Learning Rate: 0.01\n",
      "Epoch [1761/20000], Loss: 245.55255126953125, Entropy -265.9552917480469, Learning Rate: 0.01\n",
      "Epoch [1762/20000], Loss: 256.1920166015625, Entropy -253.71493530273438, Learning Rate: 0.01\n",
      "Epoch [1763/20000], Loss: 287.5933837890625, Entropy -270.3279724121094, Learning Rate: 0.01\n",
      "Epoch [1764/20000], Loss: 270.6148681640625, Entropy -263.5996398925781, Learning Rate: 0.01\n",
      "Epoch [1765/20000], Loss: 273.6839599609375, Entropy -272.9093933105469, Learning Rate: 0.01\n",
      "Epoch [1766/20000], Loss: 313.4718017578125, Entropy -266.6492004394531, Learning Rate: 0.01\n",
      "Epoch [1767/20000], Loss: 310.324462890625, Entropy -269.9605712890625, Learning Rate: 0.01\n",
      "Epoch [1768/20000], Loss: 283.2943420410156, Entropy -284.0119323730469, Learning Rate: 0.01\n",
      "Epoch [1769/20000], Loss: 277.89678955078125, Entropy -275.3365173339844, Learning Rate: 0.01\n",
      "Epoch [1770/20000], Loss: 279.7043151855469, Entropy -278.3625183105469, Learning Rate: 0.01\n",
      "Epoch [1771/20000], Loss: 271.6416931152344, Entropy -271.109375, Learning Rate: 0.01\n",
      "Epoch [1772/20000], Loss: 262.219970703125, Entropy -267.05706787109375, Learning Rate: 0.01\n",
      "Epoch [1773/20000], Loss: 254.64671325683594, Entropy -270.3470764160156, Learning Rate: 0.01\n",
      "Epoch [1774/20000], Loss: 245.0857696533203, Entropy -251.68226623535156, Learning Rate: 0.01\n",
      "Epoch [1775/20000], Loss: 270.22186279296875, Entropy -271.0656433105469, Learning Rate: 0.01\n",
      "Epoch [1776/20000], Loss: 266.453857421875, Entropy -266.2345886230469, Learning Rate: 0.01\n",
      "Epoch [1777/20000], Loss: 255.79226684570312, Entropy -260.75897216796875, Learning Rate: 0.01\n",
      "Epoch [1778/20000], Loss: 256.1845703125, Entropy -266.9368896484375, Learning Rate: 0.01\n",
      "Epoch [1779/20000], Loss: 249.67034912109375, Entropy -261.63519287109375, Learning Rate: 0.01\n",
      "Epoch [1780/20000], Loss: 255.36846923828125, Entropy -264.6571044921875, Learning Rate: 0.01\n",
      "Epoch [1781/20000], Loss: 247.95497131347656, Entropy -257.8446044921875, Learning Rate: 0.01\n",
      "Epoch [1782/20000], Loss: 252.9925537109375, Entropy -268.2059326171875, Learning Rate: 0.01\n",
      "Epoch [1783/20000], Loss: 264.9878845214844, Entropy -279.5850830078125, Learning Rate: 0.01\n",
      "Epoch [1784/20000], Loss: 256.6076965332031, Entropy -270.2933349609375, Learning Rate: 0.01\n",
      "Epoch [1785/20000], Loss: 262.31982421875, Entropy -266.9841613769531, Learning Rate: 0.01\n",
      "Epoch [1786/20000], Loss: 265.7537841796875, Entropy -261.75506591796875, Learning Rate: 0.01\n",
      "Epoch [1787/20000], Loss: 274.57171630859375, Entropy -273.38482666015625, Learning Rate: 0.01\n",
      "Epoch [1788/20000], Loss: 267.09326171875, Entropy -267.13714599609375, Learning Rate: 0.01\n",
      "Epoch [1789/20000], Loss: 250.1392059326172, Entropy -258.0906677246094, Learning Rate: 0.01\n",
      "Epoch [1790/20000], Loss: 246.49354553222656, Entropy -261.6243896484375, Learning Rate: 0.01\n",
      "Epoch [1791/20000], Loss: 264.40087890625, Entropy -268.3455810546875, Learning Rate: 0.01\n",
      "Epoch [1792/20000], Loss: 294.49078369140625, Entropy -279.26275634765625, Learning Rate: 0.01\n",
      "Epoch [1793/20000], Loss: 267.106689453125, Entropy -261.1569519042969, Learning Rate: 0.01\n",
      "Epoch [1794/20000], Loss: 241.93817138671875, Entropy -260.9692687988281, Learning Rate: 0.01\n",
      "Epoch [1795/20000], Loss: 276.774658203125, Entropy -261.580322265625, Learning Rate: 0.01\n",
      "Epoch [1796/20000], Loss: 342.67498779296875, Entropy -281.9012756347656, Learning Rate: 0.01\n",
      "Epoch [1797/20000], Loss: 314.86114501953125, Entropy -261.80535888671875, Learning Rate: 0.01\n",
      "Epoch [1798/20000], Loss: 272.3456115722656, Entropy -271.0804748535156, Learning Rate: 0.01\n",
      "Epoch [1799/20000], Loss: 284.8019104003906, Entropy -267.8581848144531, Learning Rate: 0.01\n",
      "Epoch [1800/20000], Loss: 337.7440490722656, Entropy -272.4006042480469, Learning Rate: 0.01\n",
      "Epoch [1801/20000], Loss: 315.6222229003906, Entropy -287.8167724609375, Learning Rate: 0.01\n",
      "Epoch [1802/20000], Loss: 291.30340576171875, Entropy -266.98974609375, Learning Rate: 0.01\n",
      "Epoch [1803/20000], Loss: 263.59228515625, Entropy -266.575927734375, Learning Rate: 0.01\n",
      "Epoch [1804/20000], Loss: 280.4297790527344, Entropy -266.22528076171875, Learning Rate: 0.01\n",
      "Epoch [1805/20000], Loss: 264.7030944824219, Entropy -265.12237548828125, Learning Rate: 0.01\n",
      "Epoch [1806/20000], Loss: 261.4318542480469, Entropy -270.30377197265625, Learning Rate: 0.01\n",
      "Epoch [1807/20000], Loss: 257.04132080078125, Entropy -271.71746826171875, Learning Rate: 0.01\n",
      "Epoch [1808/20000], Loss: 301.18896484375, Entropy -266.33013916015625, Learning Rate: 0.01\n",
      "Epoch [1809/20000], Loss: 294.8972473144531, Entropy -269.4261779785156, Learning Rate: 0.01\n",
      "Epoch [1810/20000], Loss: 310.78155517578125, Entropy -271.5035095214844, Learning Rate: 0.01\n",
      "Epoch [1811/20000], Loss: 288.75244140625, Entropy -268.0262756347656, Learning Rate: 0.01\n",
      "Epoch [1812/20000], Loss: 277.30035400390625, Entropy -283.7118835449219, Learning Rate: 0.01\n",
      "Epoch [1813/20000], Loss: 269.8853759765625, Entropy -292.87774658203125, Learning Rate: 0.01\n",
      "Epoch [1814/20000], Loss: 286.046630859375, Entropy -263.0380859375, Learning Rate: 0.01\n",
      "Epoch [1815/20000], Loss: 289.4679870605469, Entropy -273.84967041015625, Learning Rate: 0.01\n",
      "Epoch [1816/20000], Loss: 295.38720703125, Entropy -270.90411376953125, Learning Rate: 0.01\n",
      "Epoch [1817/20000], Loss: 356.2220153808594, Entropy -282.8609313964844, Learning Rate: 0.01\n",
      "Epoch [1818/20000], Loss: 421.5072326660156, Entropy -268.4960021972656, Learning Rate: 0.01\n",
      "Epoch [1819/20000], Loss: 354.0046081542969, Entropy -285.5959167480469, Learning Rate: 0.01\n",
      "Epoch [1820/20000], Loss: 320.0719299316406, Entropy -266.10321044921875, Learning Rate: 0.01\n",
      "Epoch [1821/20000], Loss: 313.1796875, Entropy -266.137451171875, Learning Rate: 0.01\n",
      "Epoch [1822/20000], Loss: 339.75787353515625, Entropy -270.2370300292969, Learning Rate: 0.01\n",
      "Epoch [1823/20000], Loss: 338.5935363769531, Entropy -267.2895812988281, Learning Rate: 0.01\n",
      "Epoch [1824/20000], Loss: 333.3865966796875, Entropy -270.37823486328125, Learning Rate: 0.01\n",
      "Epoch [1825/20000], Loss: 442.1552734375, Entropy -271.0324401855469, Learning Rate: 0.01\n",
      "Epoch [1826/20000], Loss: 512.3076782226562, Entropy -255.31690979003906, Learning Rate: 0.01\n",
      "Epoch [1827/20000], Loss: 410.8514404296875, Entropy -280.1755676269531, Learning Rate: 0.01\n",
      "Epoch [1828/20000], Loss: 364.78924560546875, Entropy -274.5196838378906, Learning Rate: 0.01\n",
      "Epoch [1829/20000], Loss: 322.32220458984375, Entropy -266.3895568847656, Learning Rate: 0.01\n",
      "Epoch [1830/20000], Loss: 365.4433898925781, Entropy -265.8091125488281, Learning Rate: 0.01\n",
      "Epoch [1831/20000], Loss: 319.94134521484375, Entropy -261.0303039550781, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1832/20000], Loss: 298.65374755859375, Entropy -274.058349609375, Learning Rate: 0.01\n",
      "Epoch [1833/20000], Loss: 381.8087463378906, Entropy -272.54132080078125, Learning Rate: 0.01\n",
      "Epoch [1834/20000], Loss: 428.8969421386719, Entropy -270.921630859375, Learning Rate: 0.01\n",
      "Epoch [1835/20000], Loss: 340.5280456542969, Entropy -263.3376159667969, Learning Rate: 0.01\n",
      "Epoch [1836/20000], Loss: 339.8699035644531, Entropy -268.7764587402344, Learning Rate: 0.01\n",
      "Epoch [1837/20000], Loss: 485.11334228515625, Entropy -268.329833984375, Learning Rate: 0.01\n",
      "Epoch [1838/20000], Loss: 304.137939453125, Entropy -272.2554931640625, Learning Rate: 0.01\n",
      "Epoch [1839/20000], Loss: 351.7755126953125, Entropy -271.28472900390625, Learning Rate: 0.01\n",
      "Epoch [1840/20000], Loss: 390.54608154296875, Entropy -273.4028625488281, Learning Rate: 0.01\n",
      "Epoch [1841/20000], Loss: 295.8435974121094, Entropy -276.3013610839844, Learning Rate: 0.01\n",
      "Epoch [1842/20000], Loss: 348.3616943359375, Entropy -273.2889404296875, Learning Rate: 0.01\n",
      "Epoch [1843/20000], Loss: 328.4714660644531, Entropy -285.3000793457031, Learning Rate: 0.01\n",
      "Epoch [1844/20000], Loss: 298.74957275390625, Entropy -275.9669494628906, Learning Rate: 0.01\n",
      "Epoch [1845/20000], Loss: 344.076416015625, Entropy -280.9944763183594, Learning Rate: 0.01\n",
      "Epoch [1846/20000], Loss: 272.9613342285156, Entropy -272.79571533203125, Learning Rate: 0.01\n",
      "Epoch [1847/20000], Loss: 319.62054443359375, Entropy -266.01751708984375, Learning Rate: 0.01\n",
      "Epoch [1848/20000], Loss: 323.8310546875, Entropy -272.2792053222656, Learning Rate: 0.01\n",
      "Epoch [1849/20000], Loss: 280.7431640625, Entropy -279.538330078125, Learning Rate: 0.01\n",
      "Epoch [1850/20000], Loss: 338.044677734375, Entropy -263.2074890136719, Learning Rate: 0.01\n",
      "Epoch [1851/20000], Loss: 345.4484558105469, Entropy -274.3427429199219, Learning Rate: 0.01\n",
      "Epoch [1852/20000], Loss: 332.90423583984375, Entropy -272.39495849609375, Learning Rate: 0.01\n",
      "Epoch [1853/20000], Loss: 309.3324890136719, Entropy -272.4089050292969, Learning Rate: 0.01\n",
      "Epoch [1854/20000], Loss: 298.9639892578125, Entropy -270.5729064941406, Learning Rate: 0.01\n",
      "Epoch [1855/20000], Loss: 292.4862060546875, Entropy -274.6378173828125, Learning Rate: 0.01\n",
      "Epoch [1856/20000], Loss: 319.004638671875, Entropy -269.4609375, Learning Rate: 0.01\n",
      "Epoch [1857/20000], Loss: 284.1488037109375, Entropy -272.3695068359375, Learning Rate: 0.01\n",
      "Epoch [1858/20000], Loss: 273.0346984863281, Entropy -265.9809875488281, Learning Rate: 0.01\n",
      "Epoch [1859/20000], Loss: 267.46636962890625, Entropy -268.6842346191406, Learning Rate: 0.01\n",
      "Epoch [1860/20000], Loss: 291.6014099121094, Entropy -274.7174987792969, Learning Rate: 0.01\n",
      "Epoch [1861/20000], Loss: 304.4692687988281, Entropy -274.0260925292969, Learning Rate: 0.01\n",
      "Epoch [1862/20000], Loss: 267.0705871582031, Entropy -276.2373962402344, Learning Rate: 0.01\n",
      "Epoch [1863/20000], Loss: 310.6591491699219, Entropy -274.9630432128906, Learning Rate: 0.01\n",
      "Epoch [1864/20000], Loss: 349.76055908203125, Entropy -284.0892639160156, Learning Rate: 0.01\n",
      "Epoch [1865/20000], Loss: 279.45916748046875, Entropy -285.835693359375, Learning Rate: 0.01\n",
      "Epoch [1866/20000], Loss: 300.3494567871094, Entropy -279.1922912597656, Learning Rate: 0.01\n",
      "Epoch [1867/20000], Loss: 320.3147277832031, Entropy -273.68243408203125, Learning Rate: 0.01\n",
      "Epoch [1868/20000], Loss: 286.77520751953125, Entropy -282.9779968261719, Learning Rate: 0.01\n",
      "Epoch [1869/20000], Loss: 281.9371337890625, Entropy -278.31365966796875, Learning Rate: 0.01\n",
      "Epoch [1870/20000], Loss: 266.4501037597656, Entropy -276.98406982421875, Learning Rate: 0.01\n",
      "Epoch [1871/20000], Loss: 262.4156188964844, Entropy -276.8461608886719, Learning Rate: 0.01\n",
      "Epoch [1872/20000], Loss: 296.8931884765625, Entropy -287.2152099609375, Learning Rate: 0.01\n",
      "Epoch [1873/20000], Loss: 256.684326171875, Entropy -263.6138610839844, Learning Rate: 0.01\n",
      "Epoch [1874/20000], Loss: 259.2032470703125, Entropy -262.56182861328125, Learning Rate: 0.01\n",
      "Epoch [1875/20000], Loss: 301.52490234375, Entropy -272.19427490234375, Learning Rate: 0.01\n",
      "Epoch [1876/20000], Loss: 303.09698486328125, Entropy -273.96002197265625, Learning Rate: 0.01\n",
      "Epoch [1877/20000], Loss: 266.41412353515625, Entropy -267.8695373535156, Learning Rate: 0.01\n",
      "Epoch [1878/20000], Loss: 261.9107666015625, Entropy -265.1766052246094, Learning Rate: 0.01\n",
      "Epoch [1879/20000], Loss: 283.3765869140625, Entropy -271.93902587890625, Learning Rate: 0.01\n",
      "Epoch [1880/20000], Loss: 263.71087646484375, Entropy -274.56781005859375, Learning Rate: 0.01\n",
      "Epoch [1881/20000], Loss: 266.32342529296875, Entropy -275.1238098144531, Learning Rate: 0.01\n",
      "Epoch [1882/20000], Loss: 277.4717712402344, Entropy -273.60675048828125, Learning Rate: 0.01\n",
      "Epoch [1883/20000], Loss: 286.82269287109375, Entropy -276.60028076171875, Learning Rate: 0.01\n",
      "Epoch [1884/20000], Loss: 260.4942626953125, Entropy -257.63446044921875, Learning Rate: 0.01\n",
      "Epoch [1885/20000], Loss: 268.41943359375, Entropy -268.2989501953125, Learning Rate: 0.01\n",
      "Epoch [1886/20000], Loss: 292.74212646484375, Entropy -275.1549072265625, Learning Rate: 0.01\n",
      "Epoch [1887/20000], Loss: 288.98052978515625, Entropy -266.6351623535156, Learning Rate: 0.01\n",
      "Epoch [1888/20000], Loss: 328.9530029296875, Entropy -278.9785461425781, Learning Rate: 0.01\n",
      "Epoch [1889/20000], Loss: 281.6421813964844, Entropy -273.28973388671875, Learning Rate: 0.01\n",
      "Epoch [1890/20000], Loss: 271.6274719238281, Entropy -268.02276611328125, Learning Rate: 0.01\n",
      "Epoch [1891/20000], Loss: 275.48736572265625, Entropy -272.25177001953125, Learning Rate: 0.005\n",
      "Epoch [1892/20000], Loss: 261.4808044433594, Entropy -268.5496826171875, Learning Rate: 0.005\n",
      "Epoch [1893/20000], Loss: 269.33575439453125, Entropy -287.6282043457031, Learning Rate: 0.005\n",
      "Epoch [1894/20000], Loss: 263.4280700683594, Entropy -284.40185546875, Learning Rate: 0.005\n",
      "Epoch [1895/20000], Loss: 264.4095458984375, Entropy -270.3798522949219, Learning Rate: 0.005\n",
      "Epoch [1896/20000], Loss: 256.897705078125, Entropy -271.4960021972656, Learning Rate: 0.005\n",
      "Epoch [1897/20000], Loss: 275.6832580566406, Entropy -286.7796630859375, Learning Rate: 0.005\n",
      "Epoch [1898/20000], Loss: 261.682373046875, Entropy -266.287841796875, Learning Rate: 0.005\n",
      "Epoch [1899/20000], Loss: 252.9683380126953, Entropy -277.8440856933594, Learning Rate: 0.005\n",
      "Epoch [1900/20000], Loss: 246.3775177001953, Entropy -259.669189453125, Learning Rate: 0.005\n",
      "Epoch [1901/20000], Loss: 258.7738037109375, Entropy -272.723388671875, Learning Rate: 0.005\n",
      "Epoch [1902/20000], Loss: 243.15249633789062, Entropy -262.8937683105469, Learning Rate: 0.005\n",
      "Epoch [1903/20000], Loss: 257.9710693359375, Entropy -270.866943359375, Learning Rate: 0.005\n",
      "Epoch [1904/20000], Loss: 240.69805908203125, Entropy -262.9150085449219, Learning Rate: 0.005\n",
      "Epoch [1905/20000], Loss: 245.05882263183594, Entropy -271.9300537109375, Learning Rate: 0.005\n",
      "Epoch [1906/20000], Loss: 256.454345703125, Entropy -279.5922546386719, Learning Rate: 0.005\n",
      "Epoch [1907/20000], Loss: 253.3433380126953, Entropy -272.4429016113281, Learning Rate: 0.005\n",
      "Epoch [1908/20000], Loss: 256.1358337402344, Entropy -281.3925476074219, Learning Rate: 0.005\n",
      "Epoch [1909/20000], Loss: 249.81556701660156, Entropy -281.0833740234375, Learning Rate: 0.005\n",
      "Epoch [1910/20000], Loss: 248.7382049560547, Entropy -267.54254150390625, Learning Rate: 0.005\n",
      "Epoch [1911/20000], Loss: 243.18101501464844, Entropy -263.8976745605469, Learning Rate: 0.005\n",
      "Epoch [1912/20000], Loss: 259.6324462890625, Entropy -277.9931945800781, Learning Rate: 0.005\n",
      "Epoch [1913/20000], Loss: 252.6992950439453, Entropy -276.1606140136719, Learning Rate: 0.005\n",
      "Epoch [1914/20000], Loss: 242.21591186523438, Entropy -267.90570068359375, Learning Rate: 0.005\n",
      "Epoch [1915/20000], Loss: 257.18536376953125, Entropy -285.00152587890625, Learning Rate: 0.005\n",
      "Epoch [1916/20000], Loss: 246.89248657226562, Entropy -269.3770751953125, Learning Rate: 0.005\n",
      "Epoch [1917/20000], Loss: 245.89048767089844, Entropy -274.59698486328125, Learning Rate: 0.005\n",
      "Epoch [1918/20000], Loss: 243.5629425048828, Entropy -266.0549621582031, Learning Rate: 0.005\n",
      "Epoch [1919/20000], Loss: 241.5681610107422, Entropy -268.9186096191406, Learning Rate: 0.005\n",
      "Epoch [1920/20000], Loss: 243.8545684814453, Entropy -267.274658203125, Learning Rate: 0.005\n",
      "Epoch [1921/20000], Loss: 232.40951538085938, Entropy -259.8211975097656, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1922/20000], Loss: 241.3329620361328, Entropy -271.1288146972656, Learning Rate: 0.005\n",
      "Epoch [1923/20000], Loss: 240.3331298828125, Entropy -269.533203125, Learning Rate: 0.005\n",
      "Epoch [1924/20000], Loss: 234.73529052734375, Entropy -259.143310546875, Learning Rate: 0.005\n",
      "Epoch [1925/20000], Loss: 251.1017303466797, Entropy -278.3334045410156, Learning Rate: 0.005\n",
      "Epoch [1926/20000], Loss: 244.66143798828125, Entropy -270.5467224121094, Learning Rate: 0.005\n",
      "Epoch [1927/20000], Loss: 235.80899047851562, Entropy -259.99298095703125, Learning Rate: 0.005\n",
      "Epoch [1928/20000], Loss: 236.7686767578125, Entropy -268.3791198730469, Learning Rate: 0.005\n",
      "Epoch [1929/20000], Loss: 244.79884338378906, Entropy -270.8168029785156, Learning Rate: 0.005\n",
      "Epoch [1930/20000], Loss: 248.93597412109375, Entropy -270.4076232910156, Learning Rate: 0.005\n",
      "Epoch [1931/20000], Loss: 251.74559020996094, Entropy -268.8642883300781, Learning Rate: 0.005\n",
      "Epoch [1932/20000], Loss: 244.73403930664062, Entropy -281.0318603515625, Learning Rate: 0.005\n",
      "Epoch [1933/20000], Loss: 242.85484313964844, Entropy -278.883544921875, Learning Rate: 0.005\n",
      "Epoch [1934/20000], Loss: 241.0948028564453, Entropy -275.3641052246094, Learning Rate: 0.005\n",
      "Epoch [1935/20000], Loss: 244.7943572998047, Entropy -277.2095031738281, Learning Rate: 0.005\n",
      "Epoch [1936/20000], Loss: 236.8612060546875, Entropy -263.4412536621094, Learning Rate: 0.005\n",
      "Epoch [1937/20000], Loss: 241.22230529785156, Entropy -271.9605407714844, Learning Rate: 0.005\n",
      "Epoch [1938/20000], Loss: 244.59890747070312, Entropy -266.8915100097656, Learning Rate: 0.005\n",
      "Epoch [1939/20000], Loss: 248.08152770996094, Entropy -274.0694580078125, Learning Rate: 0.005\n",
      "Epoch [1940/20000], Loss: 234.1129913330078, Entropy -269.20916748046875, Learning Rate: 0.005\n",
      "Epoch [1941/20000], Loss: 233.42147827148438, Entropy -257.8761291503906, Learning Rate: 0.005\n",
      "Epoch [1942/20000], Loss: 241.36122131347656, Entropy -269.359130859375, Learning Rate: 0.005\n",
      "Epoch [1943/20000], Loss: 235.2218475341797, Entropy -262.1477355957031, Learning Rate: 0.005\n",
      "Epoch [1944/20000], Loss: 227.07684326171875, Entropy -258.9046630859375, Learning Rate: 0.005\n",
      "Epoch [1945/20000], Loss: 234.95338439941406, Entropy -266.1809997558594, Learning Rate: 0.005\n",
      "Epoch [1946/20000], Loss: 230.24237060546875, Entropy -258.173828125, Learning Rate: 0.005\n",
      "Epoch [1947/20000], Loss: 233.06747436523438, Entropy -262.7106628417969, Learning Rate: 0.005\n",
      "Epoch [1948/20000], Loss: 239.34829711914062, Entropy -269.02862548828125, Learning Rate: 0.005\n",
      "Epoch [1949/20000], Loss: 246.02027893066406, Entropy -272.1132507324219, Learning Rate: 0.005\n",
      "Epoch [1950/20000], Loss: 248.405517578125, Entropy -272.6344299316406, Learning Rate: 0.005\n",
      "Epoch [1951/20000], Loss: 240.04124450683594, Entropy -272.07452392578125, Learning Rate: 0.005\n",
      "Epoch [1952/20000], Loss: 228.91293334960938, Entropy -261.114013671875, Learning Rate: 0.005\n",
      "Epoch [1953/20000], Loss: 234.2164764404297, Entropy -268.6700134277344, Learning Rate: 0.005\n",
      "Epoch [1954/20000], Loss: 231.74658203125, Entropy -262.7432861328125, Learning Rate: 0.005\n",
      "Epoch [1955/20000], Loss: 227.5192413330078, Entropy -255.283447265625, Learning Rate: 0.005\n",
      "Epoch [1956/20000], Loss: 231.1156768798828, Entropy -270.5196533203125, Learning Rate: 0.005\n",
      "Epoch [1957/20000], Loss: 233.52581787109375, Entropy -269.2798156738281, Learning Rate: 0.005\n",
      "Epoch [1958/20000], Loss: 246.77304077148438, Entropy -277.085205078125, Learning Rate: 0.005\n",
      "Epoch [1959/20000], Loss: 232.3478546142578, Entropy -269.4212951660156, Learning Rate: 0.005\n",
      "Epoch [1960/20000], Loss: 244.25881958007812, Entropy -270.01190185546875, Learning Rate: 0.005\n",
      "Epoch [1961/20000], Loss: 247.43630981445312, Entropy -272.0594482421875, Learning Rate: 0.005\n",
      "Epoch [1962/20000], Loss: 235.58282470703125, Entropy -264.0039978027344, Learning Rate: 0.005\n",
      "Epoch [1963/20000], Loss: 237.86581420898438, Entropy -273.6007385253906, Learning Rate: 0.005\n",
      "Epoch [1964/20000], Loss: 237.25637817382812, Entropy -265.3391418457031, Learning Rate: 0.005\n",
      "Epoch [1965/20000], Loss: 230.23146057128906, Entropy -264.9101257324219, Learning Rate: 0.005\n",
      "Epoch [1966/20000], Loss: 237.22174072265625, Entropy -271.5097961425781, Learning Rate: 0.005\n",
      "Epoch [1967/20000], Loss: 234.55690002441406, Entropy -266.26806640625, Learning Rate: 0.005\n",
      "Epoch [1968/20000], Loss: 243.7689971923828, Entropy -278.41534423828125, Learning Rate: 0.005\n",
      "Epoch [1969/20000], Loss: 224.58087158203125, Entropy -260.55712890625, Learning Rate: 0.005\n",
      "Epoch [1970/20000], Loss: 236.9998779296875, Entropy -257.7284851074219, Learning Rate: 0.005\n",
      "Epoch [1971/20000], Loss: 228.9440460205078, Entropy -258.49017333984375, Learning Rate: 0.005\n",
      "Epoch [1972/20000], Loss: 246.95657348632812, Entropy -275.0927429199219, Learning Rate: 0.005\n",
      "Epoch [1973/20000], Loss: 242.87435913085938, Entropy -271.65594482421875, Learning Rate: 0.005\n",
      "Epoch [1974/20000], Loss: 230.80833435058594, Entropy -264.81524658203125, Learning Rate: 0.005\n",
      "Epoch [1975/20000], Loss: 231.750732421875, Entropy -260.1831359863281, Learning Rate: 0.005\n",
      "Epoch [1976/20000], Loss: 243.90187072753906, Entropy -271.2023620605469, Learning Rate: 0.005\n",
      "Epoch [1977/20000], Loss: 230.69598388671875, Entropy -266.4964599609375, Learning Rate: 0.005\n",
      "Epoch [1978/20000], Loss: 236.22589111328125, Entropy -266.67822265625, Learning Rate: 0.005\n",
      "Epoch [1979/20000], Loss: 234.74456787109375, Entropy -265.4278869628906, Learning Rate: 0.005\n",
      "Epoch [1980/20000], Loss: 243.78143310546875, Entropy -268.5581970214844, Learning Rate: 0.005\n",
      "Epoch [1981/20000], Loss: 232.3759765625, Entropy -267.5704650878906, Learning Rate: 0.005\n",
      "Epoch [1982/20000], Loss: 241.12890625, Entropy -273.76129150390625, Learning Rate: 0.005\n",
      "Epoch [1983/20000], Loss: 239.37710571289062, Entropy -271.8069152832031, Learning Rate: 0.005\n",
      "Epoch [1984/20000], Loss: 236.54359436035156, Entropy -265.7355041503906, Learning Rate: 0.005\n",
      "Epoch [1985/20000], Loss: 235.5865936279297, Entropy -265.6715393066406, Learning Rate: 0.005\n",
      "Epoch [1986/20000], Loss: 232.370361328125, Entropy -262.31976318359375, Learning Rate: 0.005\n",
      "Epoch [1987/20000], Loss: 254.12989807128906, Entropy -281.660400390625, Learning Rate: 0.005\n",
      "Epoch [1988/20000], Loss: 237.78997802734375, Entropy -268.26434326171875, Learning Rate: 0.005\n",
      "Epoch [1989/20000], Loss: 243.98876953125, Entropy -276.280029296875, Learning Rate: 0.005\n",
      "Epoch [1990/20000], Loss: 228.7435302734375, Entropy -252.86911010742188, Learning Rate: 0.005\n",
      "Epoch [1991/20000], Loss: 240.8870086669922, Entropy -263.5057067871094, Learning Rate: 0.005\n",
      "Epoch [1992/20000], Loss: 223.4495849609375, Entropy -256.39288330078125, Learning Rate: 0.005\n",
      "Epoch [1993/20000], Loss: 241.14108276367188, Entropy -269.7044982910156, Learning Rate: 0.005\n",
      "Epoch [1994/20000], Loss: 232.06890869140625, Entropy -265.4421081542969, Learning Rate: 0.005\n",
      "Epoch [1995/20000], Loss: 236.79461669921875, Entropy -269.5721740722656, Learning Rate: 0.005\n",
      "Epoch [1996/20000], Loss: 238.84580993652344, Entropy -265.2070617675781, Learning Rate: 0.005\n",
      "Epoch [1997/20000], Loss: 239.3705291748047, Entropy -270.18109130859375, Learning Rate: 0.005\n",
      "Epoch [1998/20000], Loss: 233.102783203125, Entropy -266.1418151855469, Learning Rate: 0.005\n",
      "Epoch [1999/20000], Loss: 245.3004608154297, Entropy -270.36199951171875, Learning Rate: 0.005\n",
      "Epoch [2000/20000], Loss: 235.49119567871094, Entropy -265.94891357421875, Learning Rate: 0.005\n",
      "Epoch [2001/20000], Loss: 227.8634033203125, Entropy -262.47039794921875, Learning Rate: 0.005\n",
      "Epoch [2002/20000], Loss: 232.47657775878906, Entropy -267.2943420410156, Learning Rate: 0.005\n",
      "Epoch [2003/20000], Loss: 230.2871551513672, Entropy -265.16473388671875, Learning Rate: 0.005\n",
      "Epoch [2004/20000], Loss: 238.99452209472656, Entropy -265.25408935546875, Learning Rate: 0.005\n",
      "Epoch [2005/20000], Loss: 235.62750244140625, Entropy -269.3121643066406, Learning Rate: 0.005\n",
      "Epoch [2006/20000], Loss: 234.6780242919922, Entropy -257.49737548828125, Learning Rate: 0.005\n",
      "Epoch [2007/20000], Loss: 236.5751495361328, Entropy -265.0027160644531, Learning Rate: 0.005\n",
      "Epoch [2008/20000], Loss: 226.98684692382812, Entropy -258.9537048339844, Learning Rate: 0.005\n",
      "Epoch [2009/20000], Loss: 230.9632568359375, Entropy -265.58160400390625, Learning Rate: 0.005\n",
      "Epoch [2010/20000], Loss: 237.87339782714844, Entropy -261.3834533691406, Learning Rate: 0.005\n",
      "Epoch [2011/20000], Loss: 237.55166625976562, Entropy -265.9921875, Learning Rate: 0.005\n",
      "Epoch [2012/20000], Loss: 221.56446838378906, Entropy -258.2113952636719, Learning Rate: 0.005\n",
      "Epoch [2013/20000], Loss: 215.56797790527344, Entropy -250.26187133789062, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2014/20000], Loss: 238.20635986328125, Entropy -265.373046875, Learning Rate: 0.005\n",
      "Epoch [2015/20000], Loss: 224.821044921875, Entropy -255.99827575683594, Learning Rate: 0.005\n",
      "Epoch [2016/20000], Loss: 226.5830841064453, Entropy -258.2346496582031, Learning Rate: 0.005\n",
      "Epoch [2017/20000], Loss: 234.92636108398438, Entropy -263.9459228515625, Learning Rate: 0.005\n",
      "Epoch [2018/20000], Loss: 241.92498779296875, Entropy -278.61199951171875, Learning Rate: 0.005\n",
      "Epoch [2019/20000], Loss: 230.1602783203125, Entropy -254.42498779296875, Learning Rate: 0.005\n",
      "Epoch [2020/20000], Loss: 236.77798461914062, Entropy -268.4649963378906, Learning Rate: 0.005\n",
      "Epoch [2021/20000], Loss: 231.22296142578125, Entropy -259.28594970703125, Learning Rate: 0.005\n",
      "Epoch [2022/20000], Loss: 241.46893310546875, Entropy -267.7049560546875, Learning Rate: 0.005\n",
      "Epoch [2023/20000], Loss: 227.92239379882812, Entropy -250.92572021484375, Learning Rate: 0.005\n",
      "Epoch [2024/20000], Loss: 234.35459899902344, Entropy -268.7826843261719, Learning Rate: 0.005\n",
      "Epoch [2025/20000], Loss: 220.4042205810547, Entropy -251.36441040039062, Learning Rate: 0.005\n",
      "Epoch [2026/20000], Loss: 221.8645477294922, Entropy -258.0982360839844, Learning Rate: 0.005\n",
      "Epoch [2027/20000], Loss: 225.00576782226562, Entropy -259.7696533203125, Learning Rate: 0.005\n",
      "Epoch [2028/20000], Loss: 227.61279296875, Entropy -260.25628662109375, Learning Rate: 0.005\n",
      "Epoch [2029/20000], Loss: 237.6171875, Entropy -258.0253601074219, Learning Rate: 0.005\n",
      "Epoch [2030/20000], Loss: 240.52369689941406, Entropy -264.5632629394531, Learning Rate: 0.005\n",
      "Epoch [2031/20000], Loss: 233.79840087890625, Entropy -265.41064453125, Learning Rate: 0.005\n",
      "Epoch [2032/20000], Loss: 236.31590270996094, Entropy -274.6174011230469, Learning Rate: 0.005\n",
      "Epoch [2033/20000], Loss: 230.62939453125, Entropy -261.0368957519531, Learning Rate: 0.005\n",
      "Epoch [2034/20000], Loss: 228.1921844482422, Entropy -268.1020202636719, Learning Rate: 0.005\n",
      "Epoch [2035/20000], Loss: 230.4813995361328, Entropy -263.3928527832031, Learning Rate: 0.005\n",
      "Epoch [2036/20000], Loss: 220.4945526123047, Entropy -254.3885955810547, Learning Rate: 0.005\n",
      "Epoch [2037/20000], Loss: 230.52340698242188, Entropy -264.4607849121094, Learning Rate: 0.005\n",
      "Epoch [2038/20000], Loss: 237.48634338378906, Entropy -263.98846435546875, Learning Rate: 0.005\n",
      "Epoch [2039/20000], Loss: 238.31739807128906, Entropy -270.91485595703125, Learning Rate: 0.005\n",
      "Epoch [2040/20000], Loss: 225.57485961914062, Entropy -255.273681640625, Learning Rate: 0.005\n",
      "Epoch [2041/20000], Loss: 225.27073669433594, Entropy -260.42108154296875, Learning Rate: 0.005\n",
      "Epoch [2042/20000], Loss: 225.22808837890625, Entropy -254.85267639160156, Learning Rate: 0.005\n",
      "Epoch [2043/20000], Loss: 220.2845458984375, Entropy -254.59078979492188, Learning Rate: 0.005\n",
      "Epoch [2044/20000], Loss: 234.50669860839844, Entropy -265.2464599609375, Learning Rate: 0.005\n",
      "Epoch [2045/20000], Loss: 234.1361083984375, Entropy -268.6393737792969, Learning Rate: 0.005\n",
      "Epoch [2046/20000], Loss: 230.7032928466797, Entropy -257.2902526855469, Learning Rate: 0.005\n",
      "Epoch [2047/20000], Loss: 229.77127075195312, Entropy -265.0213623046875, Learning Rate: 0.005\n",
      "Epoch [2048/20000], Loss: 220.06065368652344, Entropy -253.14146423339844, Learning Rate: 0.005\n",
      "Epoch [2049/20000], Loss: 238.48533630371094, Entropy -273.7872619628906, Learning Rate: 0.005\n",
      "Epoch [2050/20000], Loss: 238.2037811279297, Entropy -262.31768798828125, Learning Rate: 0.005\n",
      "Epoch [2051/20000], Loss: 236.9066925048828, Entropy -248.3657989501953, Learning Rate: 0.005\n",
      "Epoch [2052/20000], Loss: 231.11888122558594, Entropy -254.7620849609375, Learning Rate: 0.005\n",
      "Epoch [2053/20000], Loss: 225.4755096435547, Entropy -258.1792297363281, Learning Rate: 0.005\n",
      "Epoch [2054/20000], Loss: 227.6510009765625, Entropy -253.762451171875, Learning Rate: 0.005\n",
      "Epoch [2055/20000], Loss: 227.37832641601562, Entropy -254.22174072265625, Learning Rate: 0.005\n",
      "Epoch [2056/20000], Loss: 230.97586059570312, Entropy -266.19439697265625, Learning Rate: 0.005\n",
      "Epoch [2057/20000], Loss: 227.6970977783203, Entropy -256.68389892578125, Learning Rate: 0.005\n",
      "Epoch [2058/20000], Loss: 241.88136291503906, Entropy -270.5826721191406, Learning Rate: 0.005\n",
      "Epoch [2059/20000], Loss: 225.88027954101562, Entropy -257.5166015625, Learning Rate: 0.005\n",
      "Epoch [2060/20000], Loss: 228.2792205810547, Entropy -260.3212585449219, Learning Rate: 0.005\n",
      "Epoch [2061/20000], Loss: 241.11160278320312, Entropy -268.2227783203125, Learning Rate: 0.005\n",
      "Epoch [2062/20000], Loss: 240.21620178222656, Entropy -269.77301025390625, Learning Rate: 0.005\n",
      "Epoch [2063/20000], Loss: 230.83287048339844, Entropy -261.9327087402344, Learning Rate: 0.005\n",
      "Epoch [2064/20000], Loss: 221.26397705078125, Entropy -253.39291381835938, Learning Rate: 0.005\n",
      "Epoch [2065/20000], Loss: 247.78463745117188, Entropy -279.1944580078125, Learning Rate: 0.005\n",
      "Epoch [2066/20000], Loss: 235.37254333496094, Entropy -263.6976013183594, Learning Rate: 0.005\n",
      "Epoch [2067/20000], Loss: 230.3238525390625, Entropy -264.2397155761719, Learning Rate: 0.005\n",
      "Epoch [2068/20000], Loss: 230.35658264160156, Entropy -258.95257568359375, Learning Rate: 0.005\n",
      "Epoch [2069/20000], Loss: 223.04861450195312, Entropy -252.38223266601562, Learning Rate: 0.005\n",
      "Epoch [2070/20000], Loss: 223.5504150390625, Entropy -259.16754150390625, Learning Rate: 0.005\n",
      "Epoch [2071/20000], Loss: 220.54336547851562, Entropy -246.98947143554688, Learning Rate: 0.005\n",
      "Epoch [2072/20000], Loss: 225.56149291992188, Entropy -260.1004333496094, Learning Rate: 0.005\n",
      "Epoch [2073/20000], Loss: 224.4320526123047, Entropy -247.72506713867188, Learning Rate: 0.005\n",
      "Epoch [2074/20000], Loss: 227.88531494140625, Entropy -251.62286376953125, Learning Rate: 0.005\n",
      "Epoch [2075/20000], Loss: 234.7471160888672, Entropy -265.2889404296875, Learning Rate: 0.005\n",
      "Epoch [2076/20000], Loss: 233.95314025878906, Entropy -268.15167236328125, Learning Rate: 0.005\n",
      "Epoch [2077/20000], Loss: 223.04798889160156, Entropy -254.37103271484375, Learning Rate: 0.005\n",
      "Epoch [2078/20000], Loss: 227.03131103515625, Entropy -260.6696472167969, Learning Rate: 0.005\n",
      "Epoch [2079/20000], Loss: 219.4108428955078, Entropy -253.37510681152344, Learning Rate: 0.005\n",
      "Epoch [2080/20000], Loss: 221.27256774902344, Entropy -245.72808837890625, Learning Rate: 0.005\n",
      "Epoch [2081/20000], Loss: 232.00103759765625, Entropy -259.609130859375, Learning Rate: 0.005\n",
      "Epoch [2082/20000], Loss: 226.8448944091797, Entropy -252.6400909423828, Learning Rate: 0.005\n",
      "Epoch [2083/20000], Loss: 230.29014587402344, Entropy -256.3078918457031, Learning Rate: 0.005\n",
      "Epoch [2084/20000], Loss: 228.4479217529297, Entropy -253.7027130126953, Learning Rate: 0.005\n",
      "Epoch [2085/20000], Loss: 229.83370971679688, Entropy -260.6922607421875, Learning Rate: 0.005\n",
      "Epoch [2086/20000], Loss: 216.4762420654297, Entropy -252.78182983398438, Learning Rate: 0.005\n",
      "Epoch [2087/20000], Loss: 239.6605682373047, Entropy -268.9503173828125, Learning Rate: 0.005\n",
      "Epoch [2088/20000], Loss: 230.04916381835938, Entropy -261.72283935546875, Learning Rate: 0.005\n",
      "Epoch [2089/20000], Loss: 243.20327758789062, Entropy -264.713623046875, Learning Rate: 0.005\n",
      "Epoch [2090/20000], Loss: 229.0362091064453, Entropy -259.827880859375, Learning Rate: 0.005\n",
      "Epoch [2091/20000], Loss: 236.7423858642578, Entropy -261.5925598144531, Learning Rate: 0.005\n",
      "Epoch [2092/20000], Loss: 220.9307098388672, Entropy -251.6483154296875, Learning Rate: 0.005\n",
      "Epoch [2093/20000], Loss: 223.6577911376953, Entropy -260.6982727050781, Learning Rate: 0.005\n",
      "Epoch [2094/20000], Loss: 224.8624725341797, Entropy -261.8002624511719, Learning Rate: 0.005\n",
      "Epoch [2095/20000], Loss: 233.43447875976562, Entropy -269.4945373535156, Learning Rate: 0.005\n",
      "Epoch [2096/20000], Loss: 231.7849884033203, Entropy -269.310546875, Learning Rate: 0.005\n",
      "Epoch [2097/20000], Loss: 236.31678771972656, Entropy -267.7841491699219, Learning Rate: 0.005\n",
      "Epoch [2098/20000], Loss: 225.72962951660156, Entropy -253.63638305664062, Learning Rate: 0.005\n",
      "Epoch [2099/20000], Loss: 231.9257049560547, Entropy -264.6378479003906, Learning Rate: 0.005\n",
      "Epoch [2100/20000], Loss: 219.01779174804688, Entropy -246.77713012695312, Learning Rate: 0.005\n",
      "Epoch [2101/20000], Loss: 228.723388671875, Entropy -261.8149719238281, Learning Rate: 0.005\n",
      "Epoch [2102/20000], Loss: 235.66954040527344, Entropy -274.2607727050781, Learning Rate: 0.005\n",
      "Epoch [2103/20000], Loss: 223.32571411132812, Entropy -255.78079223632812, Learning Rate: 0.005\n",
      "Epoch [2104/20000], Loss: 222.32325744628906, Entropy -258.6907043457031, Learning Rate: 0.005\n",
      "Epoch [2105/20000], Loss: 222.5088348388672, Entropy -254.81997680664062, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2106/20000], Loss: 227.9835968017578, Entropy -256.0639343261719, Learning Rate: 0.005\n",
      "Epoch [2107/20000], Loss: 231.0516357421875, Entropy -262.57769775390625, Learning Rate: 0.005\n",
      "Epoch [2108/20000], Loss: 222.44317626953125, Entropy -257.00054931640625, Learning Rate: 0.005\n",
      "Epoch [2109/20000], Loss: 217.42286682128906, Entropy -255.67791748046875, Learning Rate: 0.005\n",
      "Epoch [2110/20000], Loss: 215.44622802734375, Entropy -248.108154296875, Learning Rate: 0.005\n",
      "Epoch [2111/20000], Loss: 228.454345703125, Entropy -265.4592590332031, Learning Rate: 0.005\n",
      "Epoch [2112/20000], Loss: 217.7484893798828, Entropy -253.6874542236328, Learning Rate: 0.005\n",
      "Epoch [2113/20000], Loss: 232.0520782470703, Entropy -262.2785339355469, Learning Rate: 0.005\n",
      "Epoch [2114/20000], Loss: 230.26632690429688, Entropy -254.87298583984375, Learning Rate: 0.005\n",
      "Epoch [2115/20000], Loss: 230.6044158935547, Entropy -258.46026611328125, Learning Rate: 0.005\n",
      "Epoch [2116/20000], Loss: 230.55821228027344, Entropy -255.63232421875, Learning Rate: 0.005\n",
      "Epoch [2117/20000], Loss: 241.28598022460938, Entropy -269.44805908203125, Learning Rate: 0.005\n",
      "Epoch [2118/20000], Loss: 236.47512817382812, Entropy -261.1852111816406, Learning Rate: 0.005\n",
      "Epoch [2119/20000], Loss: 219.85325622558594, Entropy -258.3016357421875, Learning Rate: 0.005\n",
      "Epoch [2120/20000], Loss: 242.8582305908203, Entropy -259.8417053222656, Learning Rate: 0.005\n",
      "Epoch [2121/20000], Loss: 226.10255432128906, Entropy -256.5121154785156, Learning Rate: 0.005\n",
      "Epoch [2122/20000], Loss: 233.19703674316406, Entropy -265.5639953613281, Learning Rate: 0.005\n",
      "Epoch [2123/20000], Loss: 229.7215576171875, Entropy -266.10089111328125, Learning Rate: 0.005\n",
      "Epoch [2124/20000], Loss: 236.75381469726562, Entropy -265.9475402832031, Learning Rate: 0.005\n",
      "Epoch [2125/20000], Loss: 225.74557495117188, Entropy -252.51797485351562, Learning Rate: 0.005\n",
      "Epoch [2126/20000], Loss: 232.0477294921875, Entropy -268.493408203125, Learning Rate: 0.005\n",
      "Epoch [2127/20000], Loss: 227.68116760253906, Entropy -259.56658935546875, Learning Rate: 0.005\n",
      "Epoch [2128/20000], Loss: 236.19174194335938, Entropy -268.1242980957031, Learning Rate: 0.005\n",
      "Epoch [2129/20000], Loss: 214.0629119873047, Entropy -249.89573669433594, Learning Rate: 0.005\n",
      "Epoch [2130/20000], Loss: 228.2566375732422, Entropy -257.35394287109375, Learning Rate: 0.005\n",
      "Epoch [2131/20000], Loss: 228.85482788085938, Entropy -267.3222961425781, Learning Rate: 0.005\n",
      "Epoch [2132/20000], Loss: 217.28463745117188, Entropy -252.32635498046875, Learning Rate: 0.005\n",
      "Epoch [2133/20000], Loss: 228.9888916015625, Entropy -260.9420166015625, Learning Rate: 0.005\n",
      "Epoch [2134/20000], Loss: 224.17640686035156, Entropy -263.38995361328125, Learning Rate: 0.005\n",
      "Epoch [2135/20000], Loss: 232.8546142578125, Entropy -266.91546630859375, Learning Rate: 0.005\n",
      "Epoch [2136/20000], Loss: 217.9829559326172, Entropy -256.68707275390625, Learning Rate: 0.005\n",
      "Epoch [2137/20000], Loss: 220.8309326171875, Entropy -253.29763793945312, Learning Rate: 0.005\n",
      "Epoch [2138/20000], Loss: 224.6082305908203, Entropy -261.2520446777344, Learning Rate: 0.005\n",
      "Epoch [2139/20000], Loss: 231.67457580566406, Entropy -266.6387023925781, Learning Rate: 0.005\n",
      "Epoch [2140/20000], Loss: 240.60679626464844, Entropy -267.8247375488281, Learning Rate: 0.005\n",
      "Epoch [2141/20000], Loss: 220.38331604003906, Entropy -247.32847595214844, Learning Rate: 0.005\n",
      "Epoch [2142/20000], Loss: 218.46372985839844, Entropy -251.22735595703125, Learning Rate: 0.005\n",
      "Epoch [2143/20000], Loss: 228.5157470703125, Entropy -255.67959594726562, Learning Rate: 0.005\n",
      "Epoch [2144/20000], Loss: 231.10398864746094, Entropy -256.5283203125, Learning Rate: 0.005\n",
      "Epoch [2145/20000], Loss: 232.83209228515625, Entropy -253.24288940429688, Learning Rate: 0.005\n",
      "Epoch [2146/20000], Loss: 233.27130126953125, Entropy -260.36187744140625, Learning Rate: 0.005\n",
      "Epoch [2147/20000], Loss: 237.2953643798828, Entropy -269.5579528808594, Learning Rate: 0.005\n",
      "Epoch [2148/20000], Loss: 232.05126953125, Entropy -261.87640380859375, Learning Rate: 0.005\n",
      "Epoch [2149/20000], Loss: 238.4633331298828, Entropy -259.8111877441406, Learning Rate: 0.005\n",
      "Epoch [2150/20000], Loss: 255.1425018310547, Entropy -267.6494445800781, Learning Rate: 0.005\n",
      "Epoch [2151/20000], Loss: 221.42047119140625, Entropy -251.23089599609375, Learning Rate: 0.005\n",
      "Epoch [2152/20000], Loss: 264.6416015625, Entropy -264.3193054199219, Learning Rate: 0.005\n",
      "Epoch [2153/20000], Loss: 235.93186950683594, Entropy -264.7577209472656, Learning Rate: 0.005\n",
      "Epoch [2154/20000], Loss: 257.9717102050781, Entropy -261.14813232421875, Learning Rate: 0.005\n",
      "Epoch [2155/20000], Loss: 243.71124267578125, Entropy -252.87615966796875, Learning Rate: 0.005\n",
      "Epoch [2156/20000], Loss: 237.8391571044922, Entropy -256.1397705078125, Learning Rate: 0.005\n",
      "Epoch [2157/20000], Loss: 253.620361328125, Entropy -259.0453796386719, Learning Rate: 0.005\n",
      "Epoch [2158/20000], Loss: 229.8219757080078, Entropy -251.61558532714844, Learning Rate: 0.005\n",
      "Epoch [2159/20000], Loss: 252.7906036376953, Entropy -244.26571655273438, Learning Rate: 0.005\n",
      "Epoch [2160/20000], Loss: 221.7693634033203, Entropy -255.67393493652344, Learning Rate: 0.005\n",
      "Epoch [2161/20000], Loss: 246.73988342285156, Entropy -254.34600830078125, Learning Rate: 0.005\n",
      "Epoch [2162/20000], Loss: 225.5211181640625, Entropy -252.0980224609375, Learning Rate: 0.005\n",
      "Epoch [2163/20000], Loss: 246.8770294189453, Entropy -254.4451446533203, Learning Rate: 0.005\n",
      "Epoch [2164/20000], Loss: 239.02273559570312, Entropy -254.6103515625, Learning Rate: 0.005\n",
      "Epoch [2165/20000], Loss: 234.97215270996094, Entropy -265.9125061035156, Learning Rate: 0.005\n",
      "Epoch [2166/20000], Loss: 242.32044982910156, Entropy -261.330810546875, Learning Rate: 0.005\n",
      "Epoch [2167/20000], Loss: 228.15988159179688, Entropy -255.12030029296875, Learning Rate: 0.005\n",
      "Epoch [2168/20000], Loss: 241.75001525878906, Entropy -254.64633178710938, Learning Rate: 0.005\n",
      "Epoch [2169/20000], Loss: 234.37435913085938, Entropy -260.61541748046875, Learning Rate: 0.005\n",
      "Epoch [2170/20000], Loss: 237.6936492919922, Entropy -257.9541931152344, Learning Rate: 0.005\n",
      "Epoch [2171/20000], Loss: 234.29637145996094, Entropy -257.7242431640625, Learning Rate: 0.005\n",
      "Epoch [2172/20000], Loss: 240.86212158203125, Entropy -256.1820068359375, Learning Rate: 0.005\n",
      "Epoch [2173/20000], Loss: 245.74957275390625, Entropy -279.5887451171875, Learning Rate: 0.005\n",
      "Epoch [2174/20000], Loss: 220.42381286621094, Entropy -248.45761108398438, Learning Rate: 0.005\n",
      "Epoch [2175/20000], Loss: 228.85987854003906, Entropy -265.4944152832031, Learning Rate: 0.005\n",
      "Epoch [2176/20000], Loss: 230.75160217285156, Entropy -259.30609130859375, Learning Rate: 0.005\n",
      "Epoch [2177/20000], Loss: 225.5104217529297, Entropy -253.66893005371094, Learning Rate: 0.005\n",
      "Epoch [2178/20000], Loss: 225.95652770996094, Entropy -248.853515625, Learning Rate: 0.005\n",
      "Epoch [2179/20000], Loss: 242.15191650390625, Entropy -264.4986572265625, Learning Rate: 0.005\n",
      "Epoch [2180/20000], Loss: 228.43092346191406, Entropy -248.87164306640625, Learning Rate: 0.005\n",
      "Epoch [2181/20000], Loss: 221.9058380126953, Entropy -257.025390625, Learning Rate: 0.005\n",
      "Epoch [2182/20000], Loss: 231.55506896972656, Entropy -264.62042236328125, Learning Rate: 0.005\n",
      "Epoch [2183/20000], Loss: 227.1829376220703, Entropy -248.7095184326172, Learning Rate: 0.005\n",
      "Epoch [2184/20000], Loss: 234.8204803466797, Entropy -263.04791259765625, Learning Rate: 0.005\n",
      "Epoch [2185/20000], Loss: 220.2591552734375, Entropy -250.90423583984375, Learning Rate: 0.005\n",
      "Epoch [2186/20000], Loss: 225.05709838867188, Entropy -252.7987518310547, Learning Rate: 0.005\n",
      "Epoch [2187/20000], Loss: 212.2276611328125, Entropy -247.04647827148438, Learning Rate: 0.005\n",
      "Epoch [2188/20000], Loss: 231.54286193847656, Entropy -251.43869018554688, Learning Rate: 0.005\n",
      "Epoch [2189/20000], Loss: 235.3561248779297, Entropy -272.4326477050781, Learning Rate: 0.005\n",
      "Epoch [2190/20000], Loss: 226.0376739501953, Entropy -247.05038452148438, Learning Rate: 0.005\n",
      "Epoch [2191/20000], Loss: 236.89181518554688, Entropy -261.79254150390625, Learning Rate: 0.005\n",
      "Epoch [2192/20000], Loss: 219.3831024169922, Entropy -248.29736328125, Learning Rate: 0.005\n",
      "Epoch [2193/20000], Loss: 223.15586853027344, Entropy -254.3356475830078, Learning Rate: 0.005\n",
      "Epoch [2194/20000], Loss: 224.2901611328125, Entropy -262.9339904785156, Learning Rate: 0.005\n",
      "Epoch [2195/20000], Loss: 233.02578735351562, Entropy -258.245849609375, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2196/20000], Loss: 226.6757049560547, Entropy -252.46072387695312, Learning Rate: 0.005\n",
      "Epoch [2197/20000], Loss: 230.3648681640625, Entropy -259.73651123046875, Learning Rate: 0.005\n",
      "Epoch [2198/20000], Loss: 213.10220336914062, Entropy -252.62945556640625, Learning Rate: 0.005\n",
      "Epoch [2199/20000], Loss: 221.7588348388672, Entropy -253.6132049560547, Learning Rate: 0.005\n",
      "Epoch [2200/20000], Loss: 234.5636444091797, Entropy -268.6758728027344, Learning Rate: 0.005\n",
      "Epoch [2201/20000], Loss: 212.6389923095703, Entropy -248.07493591308594, Learning Rate: 0.005\n",
      "Epoch [2202/20000], Loss: 211.6649932861328, Entropy -245.5442352294922, Learning Rate: 0.005\n",
      "Epoch [2203/20000], Loss: 220.0751495361328, Entropy -251.24612426757812, Learning Rate: 0.005\n",
      "Epoch [2204/20000], Loss: 225.61509704589844, Entropy -259.2342529296875, Learning Rate: 0.005\n",
      "Epoch [2205/20000], Loss: 231.798095703125, Entropy -266.4790344238281, Learning Rate: 0.005\n",
      "Epoch [2206/20000], Loss: 221.94747924804688, Entropy -250.851318359375, Learning Rate: 0.005\n",
      "Epoch [2207/20000], Loss: 225.00970458984375, Entropy -255.06422424316406, Learning Rate: 0.005\n",
      "Epoch [2208/20000], Loss: 220.8414306640625, Entropy -258.30682373046875, Learning Rate: 0.005\n",
      "Epoch [2209/20000], Loss: 209.2963104248047, Entropy -246.73867797851562, Learning Rate: 0.005\n",
      "Epoch [2210/20000], Loss: 226.80020141601562, Entropy -260.7943115234375, Learning Rate: 0.005\n",
      "Epoch [2211/20000], Loss: 208.65672302246094, Entropy -251.17955017089844, Learning Rate: 0.005\n",
      "Epoch [2212/20000], Loss: 209.29405212402344, Entropy -243.65863037109375, Learning Rate: 0.005\n",
      "Epoch [2213/20000], Loss: 211.47152709960938, Entropy -243.19168090820312, Learning Rate: 0.005\n",
      "Epoch [2214/20000], Loss: 224.69223022460938, Entropy -259.4833984375, Learning Rate: 0.005\n",
      "Epoch [2215/20000], Loss: 223.14505004882812, Entropy -257.06915283203125, Learning Rate: 0.005\n",
      "Epoch [2216/20000], Loss: 218.86000061035156, Entropy -248.11798095703125, Learning Rate: 0.005\n",
      "Epoch [2217/20000], Loss: 212.6792755126953, Entropy -250.02691650390625, Learning Rate: 0.005\n",
      "Epoch [2218/20000], Loss: 219.95310974121094, Entropy -250.91429138183594, Learning Rate: 0.005\n",
      "Epoch [2219/20000], Loss: 225.17420959472656, Entropy -255.9359130859375, Learning Rate: 0.005\n",
      "Epoch [2220/20000], Loss: 225.6171417236328, Entropy -262.3330078125, Learning Rate: 0.005\n",
      "Epoch [2221/20000], Loss: 225.19183349609375, Entropy -259.03619384765625, Learning Rate: 0.005\n",
      "Epoch [2222/20000], Loss: 220.61175537109375, Entropy -249.09725952148438, Learning Rate: 0.005\n",
      "Epoch [2223/20000], Loss: 242.03546142578125, Entropy -272.2266845703125, Learning Rate: 0.005\n",
      "Epoch [2224/20000], Loss: 221.4384002685547, Entropy -253.9742431640625, Learning Rate: 0.005\n",
      "Epoch [2225/20000], Loss: 225.4860382080078, Entropy -260.8906555175781, Learning Rate: 0.005\n",
      "Epoch [2226/20000], Loss: 222.8903350830078, Entropy -257.34173583984375, Learning Rate: 0.005\n",
      "Epoch [2227/20000], Loss: 225.90560913085938, Entropy -254.01495361328125, Learning Rate: 0.005\n",
      "Epoch [2228/20000], Loss: 222.89364624023438, Entropy -252.11788940429688, Learning Rate: 0.005\n",
      "Epoch [2229/20000], Loss: 226.790771484375, Entropy -261.74139404296875, Learning Rate: 0.005\n",
      "Epoch [2230/20000], Loss: 226.2294921875, Entropy -258.3138732910156, Learning Rate: 0.005\n",
      "Epoch [2231/20000], Loss: 227.931884765625, Entropy -252.1683349609375, Learning Rate: 0.005\n",
      "Epoch [2232/20000], Loss: 227.0657958984375, Entropy -260.693359375, Learning Rate: 0.005\n",
      "Epoch [2233/20000], Loss: 223.12957763671875, Entropy -259.86749267578125, Learning Rate: 0.005\n",
      "Epoch [2234/20000], Loss: 210.52027893066406, Entropy -245.4300537109375, Learning Rate: 0.005\n",
      "Epoch [2235/20000], Loss: 234.08189392089844, Entropy -256.5421142578125, Learning Rate: 0.005\n",
      "Epoch [2236/20000], Loss: 229.26473999023438, Entropy -255.70245361328125, Learning Rate: 0.005\n",
      "Epoch [2237/20000], Loss: 218.42259216308594, Entropy -252.356689453125, Learning Rate: 0.005\n",
      "Epoch [2238/20000], Loss: 231.69528198242188, Entropy -263.3998107910156, Learning Rate: 0.005\n",
      "Epoch [2239/20000], Loss: 227.24185180664062, Entropy -253.12188720703125, Learning Rate: 0.005\n",
      "Epoch [2240/20000], Loss: 216.6619873046875, Entropy -255.0921173095703, Learning Rate: 0.005\n",
      "Epoch [2241/20000], Loss: 225.2939453125, Entropy -263.05364990234375, Learning Rate: 0.005\n",
      "Epoch [2242/20000], Loss: 223.41397094726562, Entropy -255.30325317382812, Learning Rate: 0.005\n",
      "Epoch [2243/20000], Loss: 226.35496520996094, Entropy -262.0011901855469, Learning Rate: 0.005\n",
      "Epoch [2244/20000], Loss: 220.60952758789062, Entropy -252.33291625976562, Learning Rate: 0.005\n",
      "Epoch [2245/20000], Loss: 234.31430053710938, Entropy -263.6497497558594, Learning Rate: 0.005\n",
      "Epoch [2246/20000], Loss: 228.2373046875, Entropy -261.76123046875, Learning Rate: 0.005\n",
      "Epoch [2247/20000], Loss: 218.25625610351562, Entropy -252.09939575195312, Learning Rate: 0.005\n",
      "Epoch [2248/20000], Loss: 227.16497802734375, Entropy -260.59490966796875, Learning Rate: 0.005\n",
      "Epoch [2249/20000], Loss: 228.8533477783203, Entropy -252.48562622070312, Learning Rate: 0.005\n",
      "Epoch [2250/20000], Loss: 213.546142578125, Entropy -250.75054931640625, Learning Rate: 0.005\n",
      "Epoch [2251/20000], Loss: 223.93719482421875, Entropy -258.0899658203125, Learning Rate: 0.005\n",
      "Epoch [2252/20000], Loss: 223.939697265625, Entropy -251.57247924804688, Learning Rate: 0.005\n",
      "Epoch [2253/20000], Loss: 228.6818084716797, Entropy -252.0699462890625, Learning Rate: 0.005\n",
      "Epoch [2254/20000], Loss: 222.16795349121094, Entropy -250.993896484375, Learning Rate: 0.005\n",
      "Epoch [2255/20000], Loss: 229.63174438476562, Entropy -255.02626037597656, Learning Rate: 0.005\n",
      "Epoch [2256/20000], Loss: 223.24407958984375, Entropy -252.07196044921875, Learning Rate: 0.005\n",
      "Epoch [2257/20000], Loss: 229.57777404785156, Entropy -263.51849365234375, Learning Rate: 0.005\n",
      "Epoch [2258/20000], Loss: 225.45611572265625, Entropy -258.80291748046875, Learning Rate: 0.005\n",
      "Epoch [2259/20000], Loss: 219.82505798339844, Entropy -252.88583374023438, Learning Rate: 0.005\n",
      "Epoch [2260/20000], Loss: 226.88087463378906, Entropy -258.9272155761719, Learning Rate: 0.005\n",
      "Epoch [2261/20000], Loss: 230.0107879638672, Entropy -256.83074951171875, Learning Rate: 0.005\n",
      "Epoch [2262/20000], Loss: 230.96522521972656, Entropy -257.8452453613281, Learning Rate: 0.005\n",
      "Epoch [2263/20000], Loss: 210.73948669433594, Entropy -243.59609985351562, Learning Rate: 0.005\n",
      "Epoch [2264/20000], Loss: 215.48260498046875, Entropy -246.76776123046875, Learning Rate: 0.005\n",
      "Epoch [2265/20000], Loss: 233.07994079589844, Entropy -255.79495239257812, Learning Rate: 0.005\n",
      "Epoch [2266/20000], Loss: 232.8960723876953, Entropy -260.7798156738281, Learning Rate: 0.005\n",
      "Epoch [2267/20000], Loss: 221.15692138671875, Entropy -253.78213500976562, Learning Rate: 0.005\n",
      "Epoch [2268/20000], Loss: 233.56248474121094, Entropy -266.6443176269531, Learning Rate: 0.005\n",
      "Epoch [2269/20000], Loss: 228.29327392578125, Entropy -257.5899658203125, Learning Rate: 0.005\n",
      "Epoch [2270/20000], Loss: 215.41909790039062, Entropy -248.81298828125, Learning Rate: 0.005\n",
      "Epoch [2271/20000], Loss: 214.21722412109375, Entropy -252.8243865966797, Learning Rate: 0.005\n",
      "Epoch [2272/20000], Loss: 223.57017517089844, Entropy -249.3220672607422, Learning Rate: 0.005\n",
      "Epoch [2273/20000], Loss: 225.5121612548828, Entropy -261.1138610839844, Learning Rate: 0.005\n",
      "Epoch [2274/20000], Loss: 205.91868591308594, Entropy -241.30752563476562, Learning Rate: 0.005\n",
      "Epoch [2275/20000], Loss: 224.53994750976562, Entropy -255.29998779296875, Learning Rate: 0.005\n",
      "Epoch [2276/20000], Loss: 222.93797302246094, Entropy -262.6462097167969, Learning Rate: 0.005\n",
      "Epoch [2277/20000], Loss: 221.55364990234375, Entropy -255.78579711914062, Learning Rate: 0.005\n",
      "Epoch [2278/20000], Loss: 216.61895751953125, Entropy -246.96365356445312, Learning Rate: 0.005\n",
      "Epoch [2279/20000], Loss: 248.00958251953125, Entropy -266.8416748046875, Learning Rate: 0.005\n",
      "Epoch [2280/20000], Loss: 214.41616821289062, Entropy -249.27767944335938, Learning Rate: 0.005\n",
      "Epoch [2281/20000], Loss: 209.52392578125, Entropy -253.22232055664062, Learning Rate: 0.005\n",
      "Epoch [2282/20000], Loss: 229.45724487304688, Entropy -256.0060729980469, Learning Rate: 0.005\n",
      "Epoch [2283/20000], Loss: 222.58689880371094, Entropy -250.30433654785156, Learning Rate: 0.005\n",
      "Epoch [2284/20000], Loss: 217.32728576660156, Entropy -251.99447631835938, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2285/20000], Loss: 232.10809326171875, Entropy -263.937255859375, Learning Rate: 0.005\n",
      "Epoch [2286/20000], Loss: 227.3362274169922, Entropy -260.962646484375, Learning Rate: 0.005\n",
      "Epoch [2287/20000], Loss: 227.66015625, Entropy -254.6703643798828, Learning Rate: 0.005\n",
      "Epoch [2288/20000], Loss: 234.55520629882812, Entropy -261.0522766113281, Learning Rate: 0.005\n",
      "Epoch [2289/20000], Loss: 218.16844177246094, Entropy -252.2718048095703, Learning Rate: 0.005\n",
      "Epoch [2290/20000], Loss: 230.26486206054688, Entropy -257.39385986328125, Learning Rate: 0.005\n",
      "Epoch [2291/20000], Loss: 235.789306640625, Entropy -267.2652282714844, Learning Rate: 0.005\n",
      "Epoch [2292/20000], Loss: 223.7627410888672, Entropy -258.3629455566406, Learning Rate: 0.005\n",
      "Epoch [2293/20000], Loss: 229.03753662109375, Entropy -251.1154022216797, Learning Rate: 0.005\n",
      "Epoch [2294/20000], Loss: 236.4744873046875, Entropy -265.49945068359375, Learning Rate: 0.005\n",
      "Epoch [2295/20000], Loss: 228.53163146972656, Entropy -255.92044067382812, Learning Rate: 0.005\n",
      "Epoch [2296/20000], Loss: 219.85025024414062, Entropy -250.26771545410156, Learning Rate: 0.005\n",
      "Epoch [2297/20000], Loss: 224.8643798828125, Entropy -253.938232421875, Learning Rate: 0.005\n",
      "Epoch [2298/20000], Loss: 236.91062927246094, Entropy -257.3817138671875, Learning Rate: 0.005\n",
      "Epoch [2299/20000], Loss: 217.55238342285156, Entropy -249.9518280029297, Learning Rate: 0.005\n",
      "Epoch [2300/20000], Loss: 216.51576232910156, Entropy -246.87692260742188, Learning Rate: 0.005\n",
      "Epoch [2301/20000], Loss: 220.39959716796875, Entropy -251.3027801513672, Learning Rate: 0.005\n",
      "Epoch [2302/20000], Loss: 219.51693725585938, Entropy -251.90863037109375, Learning Rate: 0.005\n",
      "Epoch [2303/20000], Loss: 227.60543823242188, Entropy -256.3558654785156, Learning Rate: 0.005\n",
      "Epoch [2304/20000], Loss: 219.94972229003906, Entropy -252.65756225585938, Learning Rate: 0.005\n",
      "Epoch [2305/20000], Loss: 236.01988220214844, Entropy -264.9842224121094, Learning Rate: 0.005\n",
      "Epoch [2306/20000], Loss: 230.94541931152344, Entropy -256.16009521484375, Learning Rate: 0.005\n",
      "Epoch [2307/20000], Loss: 233.24171447753906, Entropy -268.680419921875, Learning Rate: 0.005\n",
      "Epoch [2308/20000], Loss: 223.9054412841797, Entropy -251.4099884033203, Learning Rate: 0.005\n",
      "Epoch [2309/20000], Loss: 237.36813354492188, Entropy -262.36529541015625, Learning Rate: 0.005\n",
      "Epoch [2310/20000], Loss: 224.69528198242188, Entropy -262.3539733886719, Learning Rate: 0.005\n",
      "Epoch [2311/20000], Loss: 218.59141540527344, Entropy -243.63941955566406, Learning Rate: 0.005\n",
      "Epoch [2312/20000], Loss: 220.36380004882812, Entropy -249.0148162841797, Learning Rate: 0.005\n",
      "Epoch [2313/20000], Loss: 213.39532470703125, Entropy -243.00692749023438, Learning Rate: 0.005\n",
      "Epoch [2314/20000], Loss: 226.35699462890625, Entropy -242.5103302001953, Learning Rate: 0.005\n",
      "Epoch [2315/20000], Loss: 237.55120849609375, Entropy -254.49169921875, Learning Rate: 0.005\n",
      "Epoch [2316/20000], Loss: 212.15431213378906, Entropy -240.6505126953125, Learning Rate: 0.005\n",
      "Epoch [2317/20000], Loss: 221.03103637695312, Entropy -238.0504150390625, Learning Rate: 0.005\n",
      "Epoch [2318/20000], Loss: 220.4940948486328, Entropy -244.60061645507812, Learning Rate: 0.005\n",
      "Epoch [2319/20000], Loss: 231.33119201660156, Entropy -241.34637451171875, Learning Rate: 0.005\n",
      "Epoch [2320/20000], Loss: 235.61441040039062, Entropy -259.9767150878906, Learning Rate: 0.005\n",
      "Epoch [2321/20000], Loss: 225.158203125, Entropy -247.73724365234375, Learning Rate: 0.005\n",
      "Epoch [2322/20000], Loss: 240.5728302001953, Entropy -247.01046752929688, Learning Rate: 0.005\n",
      "Epoch [2323/20000], Loss: 212.8450164794922, Entropy -246.18344116210938, Learning Rate: 0.005\n",
      "Epoch [2324/20000], Loss: 226.8339080810547, Entropy -245.03558349609375, Learning Rate: 0.005\n",
      "Epoch [2325/20000], Loss: 226.25775146484375, Entropy -257.0152587890625, Learning Rate: 0.005\n",
      "Epoch [2326/20000], Loss: 221.238525390625, Entropy -246.141845703125, Learning Rate: 0.005\n",
      "Epoch [2327/20000], Loss: 229.69956970214844, Entropy -255.66390991210938, Learning Rate: 0.005\n",
      "Epoch [2328/20000], Loss: 218.12310791015625, Entropy -251.2745361328125, Learning Rate: 0.005\n",
      "Epoch [2329/20000], Loss: 239.83389282226562, Entropy -255.68356323242188, Learning Rate: 0.005\n",
      "Epoch [2330/20000], Loss: 230.613037109375, Entropy -253.68600463867188, Learning Rate: 0.005\n",
      "Epoch [2331/20000], Loss: 220.00778198242188, Entropy -257.7484130859375, Learning Rate: 0.005\n",
      "Epoch [2332/20000], Loss: 233.1439208984375, Entropy -254.22622680664062, Learning Rate: 0.005\n",
      "Epoch [2333/20000], Loss: 223.8966064453125, Entropy -246.81707763671875, Learning Rate: 0.005\n",
      "Epoch [2334/20000], Loss: 221.96990966796875, Entropy -254.90032958984375, Learning Rate: 0.005\n",
      "Epoch [2335/20000], Loss: 248.14002990722656, Entropy -256.0160217285156, Learning Rate: 0.005\n",
      "Epoch [2336/20000], Loss: 232.88990783691406, Entropy -259.44073486328125, Learning Rate: 0.005\n",
      "Epoch [2337/20000], Loss: 221.27597045898438, Entropy -245.9251708984375, Learning Rate: 0.005\n",
      "Epoch [2338/20000], Loss: 246.0753173828125, Entropy -262.99884033203125, Learning Rate: 0.005\n",
      "Epoch [2339/20000], Loss: 223.67333984375, Entropy -254.6849365234375, Learning Rate: 0.005\n",
      "Epoch [2340/20000], Loss: 216.3771209716797, Entropy -249.48231506347656, Learning Rate: 0.005\n",
      "Epoch [2341/20000], Loss: 211.8158416748047, Entropy -238.88548278808594, Learning Rate: 0.005\n",
      "Epoch [2342/20000], Loss: 225.6317138671875, Entropy -257.119140625, Learning Rate: 0.005\n",
      "Epoch [2343/20000], Loss: 234.91014099121094, Entropy -252.05062866210938, Learning Rate: 0.005\n",
      "Epoch [2344/20000], Loss: 226.470458984375, Entropy -262.1857604980469, Learning Rate: 0.005\n",
      "Epoch [2345/20000], Loss: 229.93247985839844, Entropy -244.07342529296875, Learning Rate: 0.005\n",
      "Epoch [2346/20000], Loss: 219.43194580078125, Entropy -246.48092651367188, Learning Rate: 0.005\n",
      "Epoch [2347/20000], Loss: 225.29331970214844, Entropy -250.52017211914062, Learning Rate: 0.005\n",
      "Epoch [2348/20000], Loss: 204.26275634765625, Entropy -228.53115844726562, Learning Rate: 0.005\n",
      "Epoch [2349/20000], Loss: 214.94100952148438, Entropy -246.61050415039062, Learning Rate: 0.005\n",
      "Epoch [2350/20000], Loss: 231.54501342773438, Entropy -252.74160766601562, Learning Rate: 0.005\n",
      "Epoch [2351/20000], Loss: 221.83119201660156, Entropy -246.486083984375, Learning Rate: 0.005\n",
      "Epoch [2352/20000], Loss: 211.78428649902344, Entropy -243.8283233642578, Learning Rate: 0.005\n",
      "Epoch [2353/20000], Loss: 218.2897186279297, Entropy -246.23367309570312, Learning Rate: 0.005\n",
      "Epoch [2354/20000], Loss: 229.02777099609375, Entropy -259.6224060058594, Learning Rate: 0.005\n",
      "Epoch [2355/20000], Loss: 222.28807067871094, Entropy -247.9453582763672, Learning Rate: 0.005\n",
      "Epoch [2356/20000], Loss: 223.20350646972656, Entropy -245.65646362304688, Learning Rate: 0.005\n",
      "Epoch [2357/20000], Loss: 214.857421875, Entropy -248.04283142089844, Learning Rate: 0.005\n",
      "Epoch [2358/20000], Loss: 211.5868377685547, Entropy -236.16976928710938, Learning Rate: 0.005\n",
      "Epoch [2359/20000], Loss: 211.90188598632812, Entropy -243.72811889648438, Learning Rate: 0.005\n",
      "Epoch [2360/20000], Loss: 218.537841796875, Entropy -248.43954467773438, Learning Rate: 0.005\n",
      "Epoch [2361/20000], Loss: 238.9296112060547, Entropy -252.39462280273438, Learning Rate: 0.005\n",
      "Epoch [2362/20000], Loss: 214.5406951904297, Entropy -241.85198974609375, Learning Rate: 0.005\n",
      "Epoch [2363/20000], Loss: 214.96998596191406, Entropy -254.826416015625, Learning Rate: 0.005\n",
      "Epoch [2364/20000], Loss: 214.41802978515625, Entropy -246.12796020507812, Learning Rate: 0.005\n",
      "Epoch [2365/20000], Loss: 222.10189819335938, Entropy -252.6918487548828, Learning Rate: 0.005\n",
      "Epoch [2366/20000], Loss: 226.31736755371094, Entropy -253.42208862304688, Learning Rate: 0.005\n",
      "Epoch [2367/20000], Loss: 231.59117126464844, Entropy -257.8654479980469, Learning Rate: 0.005\n",
      "Epoch [2368/20000], Loss: 212.14794921875, Entropy -241.6416473388672, Learning Rate: 0.005\n",
      "Epoch [2369/20000], Loss: 211.54786682128906, Entropy -247.63650512695312, Learning Rate: 0.005\n",
      "Epoch [2370/20000], Loss: 206.3722381591797, Entropy -242.2232666015625, Learning Rate: 0.005\n",
      "Epoch [2371/20000], Loss: 225.09683227539062, Entropy -251.47589111328125, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2372/20000], Loss: 215.92428588867188, Entropy -245.09620666503906, Learning Rate: 0.005\n",
      "Epoch [2373/20000], Loss: 233.5260467529297, Entropy -257.9691467285156, Learning Rate: 0.005\n",
      "Epoch [2374/20000], Loss: 267.42626953125, Entropy -269.6859436035156, Learning Rate: 0.005\n",
      "Epoch [2375/20000], Loss: 218.3908233642578, Entropy -246.17555236816406, Learning Rate: 0.005\n",
      "Epoch [2376/20000], Loss: 225.64242553710938, Entropy -250.6092071533203, Learning Rate: 0.005\n",
      "Epoch [2377/20000], Loss: 242.8526153564453, Entropy -250.79689025878906, Learning Rate: 0.005\n",
      "Epoch [2378/20000], Loss: 234.3055419921875, Entropy -263.6324768066406, Learning Rate: 0.005\n",
      "Epoch [2379/20000], Loss: 222.1458740234375, Entropy -249.22293090820312, Learning Rate: 0.005\n",
      "Epoch [2380/20000], Loss: 250.1496124267578, Entropy -262.8265686035156, Learning Rate: 0.005\n",
      "Epoch [2381/20000], Loss: 227.3163299560547, Entropy -252.92999267578125, Learning Rate: 0.005\n",
      "Epoch [2382/20000], Loss: 240.60023498535156, Entropy -244.27142333984375, Learning Rate: 0.005\n",
      "Epoch [2383/20000], Loss: 227.9728546142578, Entropy -243.26417541503906, Learning Rate: 0.005\n",
      "Epoch [2384/20000], Loss: 228.4117431640625, Entropy -243.6686553955078, Learning Rate: 0.005\n",
      "Epoch [2385/20000], Loss: 259.5414733886719, Entropy -245.75059509277344, Learning Rate: 0.005\n",
      "Epoch [2386/20000], Loss: 219.15452575683594, Entropy -237.4462890625, Learning Rate: 0.005\n",
      "Epoch [2387/20000], Loss: 231.3233642578125, Entropy -252.93283081054688, Learning Rate: 0.005\n",
      "Epoch [2388/20000], Loss: 231.31871032714844, Entropy -249.3320770263672, Learning Rate: 0.005\n",
      "Epoch [2389/20000], Loss: 213.8432159423828, Entropy -233.85549926757812, Learning Rate: 0.005\n",
      "Epoch [2390/20000], Loss: 220.8062286376953, Entropy -249.287841796875, Learning Rate: 0.005\n",
      "Epoch [2391/20000], Loss: 242.05181884765625, Entropy -254.35198974609375, Learning Rate: 0.005\n",
      "Epoch [2392/20000], Loss: 249.562744140625, Entropy -258.6053771972656, Learning Rate: 0.005\n",
      "Epoch [2393/20000], Loss: 209.86807250976562, Entropy -228.20323181152344, Learning Rate: 0.005\n",
      "Epoch [2394/20000], Loss: 236.3208465576172, Entropy -250.2969970703125, Learning Rate: 0.005\n",
      "Epoch [2395/20000], Loss: 238.042236328125, Entropy -250.68310546875, Learning Rate: 0.005\n",
      "Epoch [2396/20000], Loss: 211.69725036621094, Entropy -247.4661407470703, Learning Rate: 0.005\n",
      "Epoch [2397/20000], Loss: 215.03421020507812, Entropy -242.9559326171875, Learning Rate: 0.005\n",
      "Epoch [2398/20000], Loss: 222.02293395996094, Entropy -252.1988525390625, Learning Rate: 0.005\n",
      "Epoch [2399/20000], Loss: 220.96731567382812, Entropy -247.02529907226562, Learning Rate: 0.005\n",
      "Epoch [2400/20000], Loss: 226.3821563720703, Entropy -245.58975219726562, Learning Rate: 0.005\n",
      "Epoch [2401/20000], Loss: 220.90196228027344, Entropy -246.9715576171875, Learning Rate: 0.005\n",
      "Epoch [2402/20000], Loss: 224.91387939453125, Entropy -245.18312072753906, Learning Rate: 0.005\n",
      "Epoch [2403/20000], Loss: 213.80416870117188, Entropy -242.38751220703125, Learning Rate: 0.005\n",
      "Epoch [2404/20000], Loss: 220.38548278808594, Entropy -244.82627868652344, Learning Rate: 0.005\n",
      "Epoch [2405/20000], Loss: 214.70079040527344, Entropy -247.47264099121094, Learning Rate: 0.005\n",
      "Epoch [2406/20000], Loss: 216.5726318359375, Entropy -256.50079345703125, Learning Rate: 0.005\n",
      "Epoch [2407/20000], Loss: 217.7188262939453, Entropy -255.02955627441406, Learning Rate: 0.005\n",
      "Epoch [2408/20000], Loss: 215.82374572753906, Entropy -249.0083770751953, Learning Rate: 0.005\n",
      "Epoch [2409/20000], Loss: 221.05300903320312, Entropy -250.4618377685547, Learning Rate: 0.005\n",
      "Epoch [2410/20000], Loss: 224.27806091308594, Entropy -253.0213165283203, Learning Rate: 0.005\n",
      "Epoch [2411/20000], Loss: 225.6017608642578, Entropy -255.35804748535156, Learning Rate: 0.005\n",
      "Epoch [2412/20000], Loss: 219.7178497314453, Entropy -254.0242919921875, Learning Rate: 0.005\n",
      "Epoch [2413/20000], Loss: 215.22708129882812, Entropy -242.93003845214844, Learning Rate: 0.005\n",
      "Epoch [2414/20000], Loss: 225.34539794921875, Entropy -255.1681671142578, Learning Rate: 0.005\n",
      "Epoch [2415/20000], Loss: 234.59722900390625, Entropy -263.3430480957031, Learning Rate: 0.005\n",
      "Epoch [2416/20000], Loss: 222.8060302734375, Entropy -249.44223022460938, Learning Rate: 0.005\n",
      "Epoch [2417/20000], Loss: 214.6326904296875, Entropy -250.14755249023438, Learning Rate: 0.005\n",
      "Epoch [2418/20000], Loss: 208.2447967529297, Entropy -234.97647094726562, Learning Rate: 0.005\n",
      "Epoch [2419/20000], Loss: 220.46609497070312, Entropy -250.51132202148438, Learning Rate: 0.005\n",
      "Epoch [2420/20000], Loss: 217.4881134033203, Entropy -242.751953125, Learning Rate: 0.005\n",
      "Epoch [2421/20000], Loss: 216.18165588378906, Entropy -235.87106323242188, Learning Rate: 0.005\n",
      "Epoch [2422/20000], Loss: 222.44761657714844, Entropy -258.9516296386719, Learning Rate: 0.005\n",
      "Epoch [2423/20000], Loss: 212.044677734375, Entropy -237.74916076660156, Learning Rate: 0.005\n",
      "Epoch [2424/20000], Loss: 226.0880126953125, Entropy -251.2264404296875, Learning Rate: 0.005\n",
      "Epoch [2425/20000], Loss: 224.05941772460938, Entropy -245.21853637695312, Learning Rate: 0.005\n",
      "Epoch [2426/20000], Loss: 213.45555114746094, Entropy -247.19256591796875, Learning Rate: 0.005\n",
      "Epoch [2427/20000], Loss: 216.74221801757812, Entropy -248.5634765625, Learning Rate: 0.005\n",
      "Epoch [2428/20000], Loss: 227.1675262451172, Entropy -248.70614624023438, Learning Rate: 0.005\n",
      "Epoch [2429/20000], Loss: 213.23117065429688, Entropy -248.34918212890625, Learning Rate: 0.005\n",
      "Epoch [2430/20000], Loss: 208.2427520751953, Entropy -237.78427124023438, Learning Rate: 0.005\n",
      "Epoch [2431/20000], Loss: 209.42066955566406, Entropy -236.94284057617188, Learning Rate: 0.005\n",
      "Epoch [2432/20000], Loss: 225.69479370117188, Entropy -254.49131774902344, Learning Rate: 0.005\n",
      "Epoch [2433/20000], Loss: 228.0911102294922, Entropy -248.87583923339844, Learning Rate: 0.005\n",
      "Epoch [2434/20000], Loss: 229.6040496826172, Entropy -261.2664794921875, Learning Rate: 0.005\n",
      "Epoch [2435/20000], Loss: 225.5844268798828, Entropy -254.8417510986328, Learning Rate: 0.005\n",
      "Epoch [2436/20000], Loss: 218.83311462402344, Entropy -240.73129272460938, Learning Rate: 0.005\n",
      "Epoch [2437/20000], Loss: 208.87046813964844, Entropy -244.45541381835938, Learning Rate: 0.005\n",
      "Epoch [2438/20000], Loss: 220.3400115966797, Entropy -237.95303344726562, Learning Rate: 0.005\n",
      "Epoch [2439/20000], Loss: 231.2056427001953, Entropy -251.40301513671875, Learning Rate: 0.005\n",
      "Epoch [2440/20000], Loss: 214.65597534179688, Entropy -253.15817260742188, Learning Rate: 0.005\n",
      "Epoch [2441/20000], Loss: 242.68203735351562, Entropy -257.17425537109375, Learning Rate: 0.005\n",
      "Epoch [2442/20000], Loss: 220.08697509765625, Entropy -244.03688049316406, Learning Rate: 0.005\n",
      "Epoch [2443/20000], Loss: 220.8357391357422, Entropy -249.28721618652344, Learning Rate: 0.005\n",
      "Epoch [2444/20000], Loss: 226.82620239257812, Entropy -247.45774841308594, Learning Rate: 0.005\n",
      "Epoch [2445/20000], Loss: 210.84527587890625, Entropy -235.62742614746094, Learning Rate: 0.005\n",
      "Epoch [2446/20000], Loss: 215.30844116210938, Entropy -249.0469970703125, Learning Rate: 0.005\n",
      "Epoch [2447/20000], Loss: 227.83969116210938, Entropy -247.53756713867188, Learning Rate: 0.005\n",
      "Epoch [2448/20000], Loss: 222.32852172851562, Entropy -252.08505249023438, Learning Rate: 0.005\n",
      "Epoch [2449/20000], Loss: 266.33245849609375, Entropy -244.74839782714844, Learning Rate: 0.005\n",
      "Epoch [2450/20000], Loss: 237.11573791503906, Entropy -245.1461181640625, Learning Rate: 0.005\n",
      "Epoch [2451/20000], Loss: 209.8990936279297, Entropy -242.8236541748047, Learning Rate: 0.005\n",
      "Epoch [2452/20000], Loss: 252.31497192382812, Entropy -252.34710693359375, Learning Rate: 0.005\n",
      "Epoch [2453/20000], Loss: 218.341796875, Entropy -237.61770629882812, Learning Rate: 0.005\n",
      "Epoch [2454/20000], Loss: 225.64878845214844, Entropy -246.16119384765625, Learning Rate: 0.005\n",
      "Epoch [2455/20000], Loss: 247.82608032226562, Entropy -248.5261688232422, Learning Rate: 0.005\n",
      "Epoch [2456/20000], Loss: 235.95082092285156, Entropy -253.13449096679688, Learning Rate: 0.005\n",
      "Epoch [2457/20000], Loss: 222.0484161376953, Entropy -230.6050262451172, Learning Rate: 0.005\n",
      "Epoch [2458/20000], Loss: 227.62811279296875, Entropy -249.15777587890625, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2459/20000], Loss: 221.57177734375, Entropy -254.2811279296875, Learning Rate: 0.005\n",
      "Epoch [2460/20000], Loss: 233.782470703125, Entropy -249.78103637695312, Learning Rate: 0.005\n",
      "Epoch [2461/20000], Loss: 219.8586883544922, Entropy -242.2587432861328, Learning Rate: 0.005\n",
      "Epoch [2462/20000], Loss: 240.54811096191406, Entropy -244.99594116210938, Learning Rate: 0.005\n",
      "Epoch [2463/20000], Loss: 227.78494262695312, Entropy -243.35421752929688, Learning Rate: 0.005\n",
      "Epoch [2464/20000], Loss: 223.88717651367188, Entropy -250.14910888671875, Learning Rate: 0.005\n",
      "Epoch [2465/20000], Loss: 231.4388885498047, Entropy -242.46368408203125, Learning Rate: 0.005\n",
      "Epoch [2466/20000], Loss: 224.385986328125, Entropy -247.57859802246094, Learning Rate: 0.005\n",
      "Epoch [2467/20000], Loss: 229.58892822265625, Entropy -232.06500244140625, Learning Rate: 0.005\n",
      "Epoch [2468/20000], Loss: 232.89077758789062, Entropy -246.38882446289062, Learning Rate: 0.005\n",
      "Epoch [2469/20000], Loss: 221.64312744140625, Entropy -248.54876708984375, Learning Rate: 0.005\n",
      "Epoch [2470/20000], Loss: 241.26455688476562, Entropy -242.90765380859375, Learning Rate: 0.005\n",
      "Epoch [2471/20000], Loss: 255.44728088378906, Entropy -264.661376953125, Learning Rate: 0.005\n",
      "Epoch [2472/20000], Loss: 223.212890625, Entropy -247.6478271484375, Learning Rate: 0.005\n",
      "Epoch [2473/20000], Loss: 242.80259704589844, Entropy -247.14739990234375, Learning Rate: 0.005\n",
      "Epoch [2474/20000], Loss: 229.8218231201172, Entropy -241.89060974121094, Learning Rate: 0.005\n",
      "Epoch [2475/20000], Loss: 222.12689208984375, Entropy -250.84255981445312, Learning Rate: 0.005\n",
      "Epoch [2476/20000], Loss: 240.70982360839844, Entropy -257.1219177246094, Learning Rate: 0.005\n",
      "Epoch [2477/20000], Loss: 234.19198608398438, Entropy -254.7004852294922, Learning Rate: 0.005\n",
      "Epoch [2478/20000], Loss: 204.47528076171875, Entropy -241.77206420898438, Learning Rate: 0.005\n",
      "Epoch [2479/20000], Loss: 218.54698181152344, Entropy -239.50149536132812, Learning Rate: 0.005\n",
      "Epoch [2480/20000], Loss: 224.4650421142578, Entropy -253.8500518798828, Learning Rate: 0.005\n",
      "Epoch [2481/20000], Loss: 220.65008544921875, Entropy -251.71896362304688, Learning Rate: 0.005\n",
      "Epoch [2482/20000], Loss: 216.8036651611328, Entropy -251.55636596679688, Learning Rate: 0.005\n",
      "Epoch [2483/20000], Loss: 224.146728515625, Entropy -250.90618896484375, Learning Rate: 0.005\n",
      "Epoch [2484/20000], Loss: 218.36598205566406, Entropy -250.02593994140625, Learning Rate: 0.005\n",
      "Epoch [2485/20000], Loss: 215.09091186523438, Entropy -239.24923706054688, Learning Rate: 0.005\n",
      "Epoch [2486/20000], Loss: 214.119140625, Entropy -244.29730224609375, Learning Rate: 0.005\n",
      "Epoch [2487/20000], Loss: 215.34152221679688, Entropy -245.01937866210938, Learning Rate: 0.005\n",
      "Epoch [2488/20000], Loss: 214.78265380859375, Entropy -241.99562072753906, Learning Rate: 0.005\n",
      "Epoch [2489/20000], Loss: 217.04586791992188, Entropy -244.37826538085938, Learning Rate: 0.005\n",
      "Epoch [2490/20000], Loss: 222.6784210205078, Entropy -249.3795166015625, Learning Rate: 0.005\n",
      "Epoch [2491/20000], Loss: 225.8300018310547, Entropy -247.16798400878906, Learning Rate: 0.005\n",
      "Epoch [2492/20000], Loss: 244.25003051757812, Entropy -255.63311767578125, Learning Rate: 0.005\n",
      "Epoch [2493/20000], Loss: 213.58761596679688, Entropy -249.85089111328125, Learning Rate: 0.005\n",
      "Epoch [2494/20000], Loss: 215.02740478515625, Entropy -237.12692260742188, Learning Rate: 0.005\n",
      "Epoch [2495/20000], Loss: 229.38555908203125, Entropy -249.41270446777344, Learning Rate: 0.005\n",
      "Epoch [2496/20000], Loss: 224.1031036376953, Entropy -248.17120361328125, Learning Rate: 0.005\n",
      "Epoch [2497/20000], Loss: 226.14334106445312, Entropy -247.67306518554688, Learning Rate: 0.005\n",
      "Epoch [2498/20000], Loss: 216.95944213867188, Entropy -243.5275421142578, Learning Rate: 0.005\n",
      "Epoch [2499/20000], Loss: 215.77317810058594, Entropy -244.80133056640625, Learning Rate: 0.005\n",
      "Epoch [2500/20000], Loss: 206.6331329345703, Entropy -239.94761657714844, Learning Rate: 0.005\n",
      "Epoch [2501/20000], Loss: 204.15538024902344, Entropy -239.68641662597656, Learning Rate: 0.005\n",
      "Epoch [2502/20000], Loss: 213.6095428466797, Entropy -242.10491943359375, Learning Rate: 0.005\n",
      "Epoch [2503/20000], Loss: 240.27650451660156, Entropy -260.3050537109375, Learning Rate: 0.005\n",
      "Epoch [2504/20000], Loss: 233.3347930908203, Entropy -256.3238525390625, Learning Rate: 0.005\n",
      "Epoch [2505/20000], Loss: 223.08865356445312, Entropy -242.66452026367188, Learning Rate: 0.005\n",
      "Epoch [2506/20000], Loss: 216.0480194091797, Entropy -249.06752014160156, Learning Rate: 0.005\n",
      "Epoch [2507/20000], Loss: 210.01808166503906, Entropy -237.36300659179688, Learning Rate: 0.005\n",
      "Epoch [2508/20000], Loss: 226.92684936523438, Entropy -245.0098876953125, Learning Rate: 0.005\n",
      "Epoch [2509/20000], Loss: 211.00550842285156, Entropy -242.54054260253906, Learning Rate: 0.005\n",
      "Epoch [2510/20000], Loss: 221.50741577148438, Entropy -244.13388061523438, Learning Rate: 0.005\n",
      "Epoch [2511/20000], Loss: 221.4532012939453, Entropy -237.99942016601562, Learning Rate: 0.005\n",
      "Epoch [2512/20000], Loss: 218.74563598632812, Entropy -247.4689483642578, Learning Rate: 0.005\n",
      "Epoch [2513/20000], Loss: 217.10397338867188, Entropy -253.58140563964844, Learning Rate: 0.005\n",
      "Epoch [2514/20000], Loss: 216.10418701171875, Entropy -242.2186279296875, Learning Rate: 0.005\n",
      "Epoch [2515/20000], Loss: 223.6600799560547, Entropy -244.64305114746094, Learning Rate: 0.005\n",
      "Epoch [2516/20000], Loss: 220.31182861328125, Entropy -248.8785400390625, Learning Rate: 0.005\n",
      "Epoch [2517/20000], Loss: 209.35223388671875, Entropy -248.15721130371094, Learning Rate: 0.005\n",
      "Epoch [2518/20000], Loss: 217.2728729248047, Entropy -251.18527221679688, Learning Rate: 0.005\n",
      "Epoch [2519/20000], Loss: 227.59120178222656, Entropy -260.11724853515625, Learning Rate: 0.005\n",
      "Epoch [2520/20000], Loss: 229.08523559570312, Entropy -250.8877716064453, Learning Rate: 0.005\n",
      "Epoch [2521/20000], Loss: 213.8670196533203, Entropy -247.6578369140625, Learning Rate: 0.005\n",
      "Epoch [2522/20000], Loss: 221.2850341796875, Entropy -247.06088256835938, Learning Rate: 0.005\n",
      "Epoch [2523/20000], Loss: 218.52133178710938, Entropy -241.1514129638672, Learning Rate: 0.005\n",
      "Epoch [2524/20000], Loss: 201.6421356201172, Entropy -237.20162963867188, Learning Rate: 0.005\n",
      "Epoch [2525/20000], Loss: 230.36328125, Entropy -250.00193786621094, Learning Rate: 0.005\n",
      "Epoch [2526/20000], Loss: 234.93699645996094, Entropy -256.3489074707031, Learning Rate: 0.005\n",
      "Epoch [2527/20000], Loss: 204.12338256835938, Entropy -239.35723876953125, Learning Rate: 0.005\n",
      "Epoch [2528/20000], Loss: 216.01400756835938, Entropy -247.28378295898438, Learning Rate: 0.005\n",
      "Epoch [2529/20000], Loss: 214.3475341796875, Entropy -237.16763305664062, Learning Rate: 0.005\n",
      "Epoch [2530/20000], Loss: 213.91665649414062, Entropy -252.4365234375, Learning Rate: 0.005\n",
      "Epoch [2531/20000], Loss: 219.01744079589844, Entropy -246.7083282470703, Learning Rate: 0.005\n",
      "Epoch [2532/20000], Loss: 236.2027587890625, Entropy -248.91433715820312, Learning Rate: 0.005\n",
      "Epoch [2533/20000], Loss: 223.32003784179688, Entropy -252.82879638671875, Learning Rate: 0.005\n",
      "Epoch [2534/20000], Loss: 219.8190460205078, Entropy -242.48367309570312, Learning Rate: 0.005\n",
      "Epoch [2535/20000], Loss: 238.3883514404297, Entropy -251.86477661132812, Learning Rate: 0.005\n",
      "Epoch [2536/20000], Loss: 229.57518005371094, Entropy -242.45152282714844, Learning Rate: 0.005\n",
      "Epoch [2537/20000], Loss: 221.85494995117188, Entropy -250.7137908935547, Learning Rate: 0.005\n",
      "Epoch [2538/20000], Loss: 222.3242645263672, Entropy -248.25662231445312, Learning Rate: 0.005\n",
      "Epoch [2539/20000], Loss: 214.9980926513672, Entropy -243.60879516601562, Learning Rate: 0.005\n",
      "Epoch [2540/20000], Loss: 222.91783142089844, Entropy -251.95651245117188, Learning Rate: 0.005\n",
      "Epoch [2541/20000], Loss: 216.70802307128906, Entropy -238.284912109375, Learning Rate: 0.005\n",
      "Epoch [2542/20000], Loss: 225.9332733154297, Entropy -239.40869140625, Learning Rate: 0.005\n",
      "Epoch [2543/20000], Loss: 224.84194946289062, Entropy -242.57630920410156, Learning Rate: 0.005\n",
      "Epoch [2544/20000], Loss: 219.7465057373047, Entropy -238.45289611816406, Learning Rate: 0.005\n",
      "Epoch [2545/20000], Loss: 226.4238739013672, Entropy -244.7788848876953, Learning Rate: 0.005\n",
      "Epoch [2546/20000], Loss: 216.12286376953125, Entropy -241.4036865234375, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2547/20000], Loss: 241.303466796875, Entropy -246.12828063964844, Learning Rate: 0.005\n",
      "Epoch [2548/20000], Loss: 228.93679809570312, Entropy -248.52767944335938, Learning Rate: 0.005\n",
      "Epoch [2549/20000], Loss: 217.01295471191406, Entropy -235.00453186035156, Learning Rate: 0.005\n",
      "Epoch [2550/20000], Loss: 281.42828369140625, Entropy -253.3560333251953, Learning Rate: 0.005\n",
      "Epoch [2551/20000], Loss: 239.61170959472656, Entropy -245.49249267578125, Learning Rate: 0.005\n",
      "Epoch [2552/20000], Loss: 212.95436096191406, Entropy -248.7726593017578, Learning Rate: 0.005\n",
      "Epoch [2553/20000], Loss: 248.224365234375, Entropy -238.6448974609375, Learning Rate: 0.005\n",
      "Epoch [2554/20000], Loss: 247.85415649414062, Entropy -242.85964965820312, Learning Rate: 0.005\n",
      "Epoch [2555/20000], Loss: 229.28659057617188, Entropy -251.59495544433594, Learning Rate: 0.005\n",
      "Epoch [2556/20000], Loss: 236.77955627441406, Entropy -242.69384765625, Learning Rate: 0.005\n",
      "Epoch [2557/20000], Loss: 223.702392578125, Entropy -232.60662841796875, Learning Rate: 0.005\n",
      "Epoch [2558/20000], Loss: 217.5263671875, Entropy -241.46453857421875, Learning Rate: 0.005\n",
      "Epoch [2559/20000], Loss: 233.53126525878906, Entropy -240.69281005859375, Learning Rate: 0.005\n",
      "Epoch [2560/20000], Loss: 224.23890686035156, Entropy -245.43887329101562, Learning Rate: 0.005\n",
      "Epoch [2561/20000], Loss: 209.23838806152344, Entropy -245.6913604736328, Learning Rate: 0.005\n",
      "Epoch [2562/20000], Loss: 241.88783264160156, Entropy -249.04757690429688, Learning Rate: 0.005\n",
      "Epoch [2563/20000], Loss: 240.0955047607422, Entropy -255.4957733154297, Learning Rate: 0.005\n",
      "Epoch [2564/20000], Loss: 220.66461181640625, Entropy -249.14483642578125, Learning Rate: 0.005\n",
      "Epoch [2565/20000], Loss: 238.40367126464844, Entropy -248.56834411621094, Learning Rate: 0.005\n",
      "Epoch [2566/20000], Loss: 236.03573608398438, Entropy -242.32440185546875, Learning Rate: 0.005\n",
      "Epoch [2567/20000], Loss: 231.05174255371094, Entropy -239.68655395507812, Learning Rate: 0.005\n",
      "Epoch [2568/20000], Loss: 226.09754943847656, Entropy -229.22921752929688, Learning Rate: 0.005\n",
      "Epoch [2569/20000], Loss: 231.40716552734375, Entropy -240.8390655517578, Learning Rate: 0.005\n",
      "Epoch [2570/20000], Loss: 244.53009033203125, Entropy -248.78268432617188, Learning Rate: 0.005\n",
      "Epoch [2571/20000], Loss: 229.00132751464844, Entropy -255.2047576904297, Learning Rate: 0.005\n",
      "Epoch [2572/20000], Loss: 221.56698608398438, Entropy -245.15374755859375, Learning Rate: 0.005\n",
      "Epoch [2573/20000], Loss: 255.21932983398438, Entropy -240.25759887695312, Learning Rate: 0.005\n",
      "Epoch [2574/20000], Loss: 230.44143676757812, Entropy -244.75387573242188, Learning Rate: 0.005\n",
      "Epoch [2575/20000], Loss: 213.0157928466797, Entropy -235.78953552246094, Learning Rate: 0.005\n",
      "Epoch [2576/20000], Loss: 236.9435272216797, Entropy -252.96847534179688, Learning Rate: 0.005\n",
      "Epoch [2577/20000], Loss: 229.14605712890625, Entropy -229.5054473876953, Learning Rate: 0.005\n",
      "Epoch [2578/20000], Loss: 236.9624481201172, Entropy -244.86190795898438, Learning Rate: 0.005\n",
      "Epoch [2579/20000], Loss: 224.7205352783203, Entropy -245.47036743164062, Learning Rate: 0.005\n",
      "Epoch [2580/20000], Loss: 224.3565216064453, Entropy -238.77536010742188, Learning Rate: 0.005\n",
      "Epoch [2581/20000], Loss: 215.12196350097656, Entropy -235.35177612304688, Learning Rate: 0.005\n",
      "Epoch [2582/20000], Loss: 222.88818359375, Entropy -250.52294921875, Learning Rate: 0.005\n",
      "Epoch [2583/20000], Loss: 224.07049560546875, Entropy -242.1881561279297, Learning Rate: 0.005\n",
      "Epoch [2584/20000], Loss: 232.3579864501953, Entropy -251.75460815429688, Learning Rate: 0.005\n",
      "Epoch [2585/20000], Loss: 217.93521118164062, Entropy -249.4808349609375, Learning Rate: 0.005\n",
      "Epoch [2586/20000], Loss: 245.54638671875, Entropy -240.37127685546875, Learning Rate: 0.005\n",
      "Epoch [2587/20000], Loss: 235.4241485595703, Entropy -239.15286254882812, Learning Rate: 0.005\n",
      "Epoch [2588/20000], Loss: 200.9030303955078, Entropy -233.14239501953125, Learning Rate: 0.005\n",
      "Epoch [2589/20000], Loss: 241.59266662597656, Entropy -233.0035858154297, Learning Rate: 0.005\n",
      "Epoch [2590/20000], Loss: 256.82965087890625, Entropy -244.64404296875, Learning Rate: 0.005\n",
      "Epoch [2591/20000], Loss: 214.77548217773438, Entropy -246.02305603027344, Learning Rate: 0.005\n",
      "Epoch [2592/20000], Loss: 237.34701538085938, Entropy -250.57810974121094, Learning Rate: 0.005\n",
      "Epoch [2593/20000], Loss: 226.90264892578125, Entropy -238.87933349609375, Learning Rate: 0.005\n",
      "Epoch [2594/20000], Loss: 220.7789306640625, Entropy -243.9998779296875, Learning Rate: 0.005\n",
      "Epoch [2595/20000], Loss: 223.7267303466797, Entropy -245.31117248535156, Learning Rate: 0.005\n",
      "Epoch [2596/20000], Loss: 230.73123168945312, Entropy -255.9712371826172, Learning Rate: 0.005\n",
      "Epoch [2597/20000], Loss: 205.95321655273438, Entropy -241.51348876953125, Learning Rate: 0.005\n",
      "Epoch [2598/20000], Loss: 225.53134155273438, Entropy -247.07669067382812, Learning Rate: 0.005\n",
      "Epoch [2599/20000], Loss: 219.66156005859375, Entropy -246.37933349609375, Learning Rate: 0.005\n",
      "Epoch [2600/20000], Loss: 216.29725646972656, Entropy -239.4371337890625, Learning Rate: 0.005\n",
      "Epoch [2601/20000], Loss: 213.23789978027344, Entropy -239.1868438720703, Learning Rate: 0.005\n",
      "Epoch [2602/20000], Loss: 228.2873992919922, Entropy -250.7805938720703, Learning Rate: 0.005\n",
      "Epoch [2603/20000], Loss: 224.46482849121094, Entropy -243.9974365234375, Learning Rate: 0.005\n",
      "Epoch [2604/20000], Loss: 222.54103088378906, Entropy -245.3307342529297, Learning Rate: 0.005\n",
      "Epoch [2605/20000], Loss: 222.82614135742188, Entropy -243.9584503173828, Learning Rate: 0.005\n",
      "Epoch [2606/20000], Loss: 220.94119262695312, Entropy -247.98574829101562, Learning Rate: 0.005\n",
      "Epoch [2607/20000], Loss: 225.52816772460938, Entropy -257.5727844238281, Learning Rate: 0.005\n",
      "Epoch [2608/20000], Loss: 230.9641571044922, Entropy -244.7039794921875, Learning Rate: 0.005\n",
      "Epoch [2609/20000], Loss: 231.12782287597656, Entropy -238.05059814453125, Learning Rate: 0.005\n",
      "Epoch [2610/20000], Loss: 219.1663818359375, Entropy -242.4654083251953, Learning Rate: 0.005\n",
      "Epoch [2611/20000], Loss: 210.7022705078125, Entropy -229.6922149658203, Learning Rate: 0.005\n",
      "Epoch [2612/20000], Loss: 265.7833557128906, Entropy -258.6681823730469, Learning Rate: 0.005\n",
      "Epoch [2613/20000], Loss: 228.3104248046875, Entropy -239.56204223632812, Learning Rate: 0.005\n",
      "Epoch [2614/20000], Loss: 216.72865295410156, Entropy -251.36167907714844, Learning Rate: 0.005\n",
      "Epoch [2615/20000], Loss: 236.2654571533203, Entropy -237.88253784179688, Learning Rate: 0.005\n",
      "Epoch [2616/20000], Loss: 247.4842987060547, Entropy -241.7126007080078, Learning Rate: 0.005\n",
      "Epoch [2617/20000], Loss: 247.3354949951172, Entropy -264.716064453125, Learning Rate: 0.005\n",
      "Epoch [2618/20000], Loss: 217.0017852783203, Entropy -241.7815704345703, Learning Rate: 0.005\n",
      "Epoch [2619/20000], Loss: 226.74510192871094, Entropy -243.74588012695312, Learning Rate: 0.005\n",
      "Epoch [2620/20000], Loss: 213.13125610351562, Entropy -235.17051696777344, Learning Rate: 0.005\n",
      "Epoch [2621/20000], Loss: 222.616455078125, Entropy -241.04342651367188, Learning Rate: 0.005\n",
      "Epoch [2622/20000], Loss: 224.84617614746094, Entropy -238.6728057861328, Learning Rate: 0.005\n",
      "Epoch [2623/20000], Loss: 225.0915069580078, Entropy -237.23739624023438, Learning Rate: 0.005\n",
      "Epoch [2624/20000], Loss: 239.80401611328125, Entropy -236.86077880859375, Learning Rate: 0.005\n",
      "Epoch [2625/20000], Loss: 210.32147216796875, Entropy -242.96060180664062, Learning Rate: 0.005\n",
      "Epoch [2626/20000], Loss: 224.43504333496094, Entropy -236.07135009765625, Learning Rate: 0.005\n",
      "Epoch [2627/20000], Loss: 232.42396545410156, Entropy -254.21922302246094, Learning Rate: 0.005\n",
      "Epoch [2628/20000], Loss: 209.8598175048828, Entropy -236.36669921875, Learning Rate: 0.005\n",
      "Epoch [2629/20000], Loss: 235.79771423339844, Entropy -239.0867919921875, Learning Rate: 0.005\n",
      "Epoch [2630/20000], Loss: 248.5947265625, Entropy -264.07275390625, Learning Rate: 0.005\n",
      "Epoch [2631/20000], Loss: 218.16912841796875, Entropy -247.15614318847656, Learning Rate: 0.005\n",
      "Epoch [2632/20000], Loss: 225.87698364257812, Entropy -239.35183715820312, Learning Rate: 0.005\n",
      "Epoch [2633/20000], Loss: 240.63125610351562, Entropy -240.71986389160156, Learning Rate: 0.005\n",
      "Epoch [2634/20000], Loss: 220.72747802734375, Entropy -247.93161010742188, Learning Rate: 0.005\n",
      "Epoch [2635/20000], Loss: 213.1448974609375, Entropy -237.48611450195312, Learning Rate: 0.005\n",
      "Epoch [2636/20000], Loss: 212.31509399414062, Entropy -237.21914672851562, Learning Rate: 0.005\n",
      "Epoch [2637/20000], Loss: 231.80545043945312, Entropy -259.6027526855469, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2638/20000], Loss: 231.5618133544922, Entropy -249.47398376464844, Learning Rate: 0.005\n",
      "Epoch [2639/20000], Loss: 220.16204833984375, Entropy -244.80886840820312, Learning Rate: 0.005\n",
      "Epoch [2640/20000], Loss: 235.8441925048828, Entropy -252.270751953125, Learning Rate: 0.005\n",
      "Epoch [2641/20000], Loss: 253.72720336914062, Entropy -249.18704223632812, Learning Rate: 0.005\n",
      "Epoch [2642/20000], Loss: 232.23646545410156, Entropy -240.6494140625, Learning Rate: 0.005\n",
      "Epoch [2643/20000], Loss: 221.50930786132812, Entropy -251.47122192382812, Learning Rate: 0.005\n",
      "Epoch [2644/20000], Loss: 248.45925903320312, Entropy -232.37860107421875, Learning Rate: 0.005\n",
      "Epoch [2645/20000], Loss: 234.39486694335938, Entropy -244.60885620117188, Learning Rate: 0.005\n",
      "Epoch [2646/20000], Loss: 235.1136016845703, Entropy -239.10360717773438, Learning Rate: 0.005\n",
      "Epoch [2647/20000], Loss: 224.14935302734375, Entropy -244.62966918945312, Learning Rate: 0.005\n",
      "Epoch [2648/20000], Loss: 228.5120391845703, Entropy -232.63290405273438, Learning Rate: 0.005\n",
      "Epoch [2649/20000], Loss: 246.73788452148438, Entropy -239.53030395507812, Learning Rate: 0.005\n",
      "Epoch [2650/20000], Loss: 234.71412658691406, Entropy -246.47564697265625, Learning Rate: 0.005\n",
      "Epoch [2651/20000], Loss: 221.14410400390625, Entropy -239.0406494140625, Learning Rate: 0.005\n",
      "Epoch [2652/20000], Loss: 231.40670776367188, Entropy -247.13583374023438, Learning Rate: 0.005\n",
      "Epoch [2653/20000], Loss: 227.8963623046875, Entropy -234.03819274902344, Learning Rate: 0.005\n",
      "Epoch [2654/20000], Loss: 220.47230529785156, Entropy -242.6262969970703, Learning Rate: 0.005\n",
      "Epoch [2655/20000], Loss: 224.93035888671875, Entropy -254.59803771972656, Learning Rate: 0.005\n",
      "Epoch [2656/20000], Loss: 251.32974243164062, Entropy -249.0371856689453, Learning Rate: 0.005\n",
      "Epoch [2657/20000], Loss: 274.9810791015625, Entropy -251.08407592773438, Learning Rate: 0.005\n",
      "Epoch [2658/20000], Loss: 217.45750427246094, Entropy -241.10733032226562, Learning Rate: 0.005\n",
      "Epoch [2659/20000], Loss: 278.0633544921875, Entropy -244.07052612304688, Learning Rate: 0.005\n",
      "Epoch [2660/20000], Loss: 250.94131469726562, Entropy -247.48388671875, Learning Rate: 0.005\n",
      "Epoch [2661/20000], Loss: 214.2194061279297, Entropy -239.38442993164062, Learning Rate: 0.005\n",
      "Epoch [2662/20000], Loss: 270.73565673828125, Entropy -246.18206787109375, Learning Rate: 0.005\n",
      "Epoch [2663/20000], Loss: 230.4811248779297, Entropy -226.41073608398438, Learning Rate: 0.005\n",
      "Epoch [2664/20000], Loss: 216.3413848876953, Entropy -240.07192993164062, Learning Rate: 0.005\n",
      "Epoch [2665/20000], Loss: 308.1592712402344, Entropy -242.35887145996094, Learning Rate: 0.005\n",
      "Epoch [2666/20000], Loss: 318.445068359375, Entropy -239.22830200195312, Learning Rate: 0.005\n",
      "Epoch [2667/20000], Loss: 238.98583984375, Entropy -241.09991455078125, Learning Rate: 0.005\n",
      "Epoch [2668/20000], Loss: 251.22811889648438, Entropy -238.11532592773438, Learning Rate: 0.005\n",
      "Epoch [2669/20000], Loss: 286.6235046386719, Entropy -244.56101989746094, Learning Rate: 0.005\n",
      "Epoch [2670/20000], Loss: 223.16268920898438, Entropy -245.03659057617188, Learning Rate: 0.005\n",
      "Epoch [2671/20000], Loss: 244.49122619628906, Entropy -256.5715637207031, Learning Rate: 0.005\n",
      "Epoch [2672/20000], Loss: 259.76556396484375, Entropy -256.1666259765625, Learning Rate: 0.005\n",
      "Epoch [2673/20000], Loss: 231.02590942382812, Entropy -251.0876922607422, Learning Rate: 0.005\n",
      "Epoch [2674/20000], Loss: 249.8370361328125, Entropy -249.96763610839844, Learning Rate: 0.005\n",
      "Epoch [2675/20000], Loss: 220.1024627685547, Entropy -230.07843017578125, Learning Rate: 0.005\n",
      "Epoch [2676/20000], Loss: 228.17762756347656, Entropy -252.84213256835938, Learning Rate: 0.005\n",
      "Epoch [2677/20000], Loss: 222.9688720703125, Entropy -247.05909729003906, Learning Rate: 0.005\n",
      "Epoch [2678/20000], Loss: 238.12376403808594, Entropy -236.40826416015625, Learning Rate: 0.005\n",
      "Epoch [2679/20000], Loss: 243.8510284423828, Entropy -248.1886444091797, Learning Rate: 0.005\n",
      "Epoch [2680/20000], Loss: 212.025146484375, Entropy -246.41403198242188, Learning Rate: 0.005\n",
      "Epoch [2681/20000], Loss: 220.24696350097656, Entropy -235.99855041503906, Learning Rate: 0.005\n",
      "Epoch [2682/20000], Loss: 215.1202392578125, Entropy -235.8618927001953, Learning Rate: 0.005\n",
      "Epoch [2683/20000], Loss: 239.29652404785156, Entropy -249.57147216796875, Learning Rate: 0.005\n",
      "Epoch [2684/20000], Loss: 207.9771728515625, Entropy -238.41061401367188, Learning Rate: 0.005\n",
      "Epoch [2685/20000], Loss: 214.4675750732422, Entropy -230.9499053955078, Learning Rate: 0.005\n",
      "Epoch [2686/20000], Loss: 240.80960083007812, Entropy -253.9420623779297, Learning Rate: 0.005\n",
      "Epoch [2687/20000], Loss: 222.5829620361328, Entropy -242.3048095703125, Learning Rate: 0.005\n",
      "Epoch [2688/20000], Loss: 262.0250549316406, Entropy -247.83270263671875, Learning Rate: 0.005\n",
      "Epoch [2689/20000], Loss: 220.0298614501953, Entropy -238.6424560546875, Learning Rate: 0.005\n",
      "Epoch [2690/20000], Loss: 213.7512664794922, Entropy -238.53250122070312, Learning Rate: 0.005\n",
      "Epoch [2691/20000], Loss: 236.15072631835938, Entropy -234.98715209960938, Learning Rate: 0.005\n",
      "Epoch [2692/20000], Loss: 239.1857452392578, Entropy -243.15615844726562, Learning Rate: 0.005\n",
      "Epoch [2693/20000], Loss: 219.57382202148438, Entropy -254.18263244628906, Learning Rate: 0.005\n",
      "Epoch [2694/20000], Loss: 233.87753295898438, Entropy -234.31300354003906, Learning Rate: 0.005\n",
      "Epoch [2695/20000], Loss: 231.87696838378906, Entropy -257.5788879394531, Learning Rate: 0.005\n",
      "Epoch [2696/20000], Loss: 225.6138153076172, Entropy -244.9842529296875, Learning Rate: 0.005\n",
      "Epoch [2697/20000], Loss: 243.92413330078125, Entropy -235.54129028320312, Learning Rate: 0.005\n",
      "Epoch [2698/20000], Loss: 214.08912658691406, Entropy -243.00210571289062, Learning Rate: 0.005\n",
      "Epoch [2699/20000], Loss: 227.50608825683594, Entropy -248.53057861328125, Learning Rate: 0.005\n",
      "Epoch [2700/20000], Loss: 232.37367248535156, Entropy -253.74606323242188, Learning Rate: 0.005\n",
      "Epoch [2701/20000], Loss: 204.0178680419922, Entropy -237.68345642089844, Learning Rate: 0.005\n",
      "Epoch [2702/20000], Loss: 223.36167907714844, Entropy -239.40887451171875, Learning Rate: 0.005\n",
      "Epoch [2703/20000], Loss: 225.12083435058594, Entropy -247.69613647460938, Learning Rate: 0.005\n",
      "Epoch [2704/20000], Loss: 213.6192626953125, Entropy -226.92950439453125, Learning Rate: 0.005\n",
      "Epoch [2705/20000], Loss: 224.4532012939453, Entropy -246.55728149414062, Learning Rate: 0.005\n",
      "Epoch [2706/20000], Loss: 215.25930786132812, Entropy -241.7439727783203, Learning Rate: 0.005\n",
      "Epoch [2707/20000], Loss: 217.49330139160156, Entropy -234.40374755859375, Learning Rate: 0.005\n",
      "Epoch [2708/20000], Loss: 234.25741577148438, Entropy -247.0479736328125, Learning Rate: 0.005\n",
      "Epoch [2709/20000], Loss: 212.3781280517578, Entropy -246.705810546875, Learning Rate: 0.005\n",
      "Epoch [2710/20000], Loss: 220.08926391601562, Entropy -237.74908447265625, Learning Rate: 0.005\n",
      "Epoch [2711/20000], Loss: 232.264404296875, Entropy -245.2623748779297, Learning Rate: 0.005\n",
      "Epoch [2712/20000], Loss: 233.34971618652344, Entropy -252.47140502929688, Learning Rate: 0.005\n",
      "Epoch [2713/20000], Loss: 217.18768310546875, Entropy -245.4120330810547, Learning Rate: 0.005\n",
      "Epoch [2714/20000], Loss: 219.69137573242188, Entropy -239.43675231933594, Learning Rate: 0.005\n",
      "Epoch [2715/20000], Loss: 208.31362915039062, Entropy -241.4916229248047, Learning Rate: 0.005\n",
      "Epoch [2716/20000], Loss: 217.5209503173828, Entropy -250.1572265625, Learning Rate: 0.005\n",
      "Epoch [2717/20000], Loss: 210.8485565185547, Entropy -230.76145935058594, Learning Rate: 0.005\n",
      "Epoch [2718/20000], Loss: 211.2816619873047, Entropy -231.79652404785156, Learning Rate: 0.005\n",
      "Epoch [2719/20000], Loss: 228.5817108154297, Entropy -244.96104431152344, Learning Rate: 0.005\n",
      "Epoch [2720/20000], Loss: 241.1672821044922, Entropy -246.85418701171875, Learning Rate: 0.005\n",
      "Epoch [2721/20000], Loss: 229.92926025390625, Entropy -252.28118896484375, Learning Rate: 0.005\n",
      "Epoch [2722/20000], Loss: 227.18154907226562, Entropy -249.80838012695312, Learning Rate: 0.005\n",
      "Epoch [2723/20000], Loss: 254.37103271484375, Entropy -235.6265411376953, Learning Rate: 0.005\n",
      "Epoch [2724/20000], Loss: 251.39248657226562, Entropy -243.25711059570312, Learning Rate: 0.005\n",
      "Epoch [2725/20000], Loss: 217.36622619628906, Entropy -242.75393676757812, Learning Rate: 0.005\n",
      "Epoch [2726/20000], Loss: 211.96522521972656, Entropy -240.85633850097656, Learning Rate: 0.005\n",
      "Epoch [2727/20000], Loss: 247.31349182128906, Entropy -243.9095001220703, Learning Rate: 0.005\n",
      "Epoch [2728/20000], Loss: 236.1790313720703, Entropy -244.31663513183594, Learning Rate: 0.005\n",
      "Epoch [2729/20000], Loss: 208.15472412109375, Entropy -238.38124084472656, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2730/20000], Loss: 226.13792419433594, Entropy -233.85366821289062, Learning Rate: 0.005\n",
      "Epoch [2731/20000], Loss: 246.3640899658203, Entropy -237.09844970703125, Learning Rate: 0.005\n",
      "Epoch [2732/20000], Loss: 214.22633361816406, Entropy -236.658935546875, Learning Rate: 0.005\n",
      "Epoch [2733/20000], Loss: 208.04629516601562, Entropy -238.8199005126953, Learning Rate: 0.005\n",
      "Epoch [2734/20000], Loss: 237.1197967529297, Entropy -243.6385498046875, Learning Rate: 0.005\n",
      "Epoch [2735/20000], Loss: 240.28121948242188, Entropy -249.4530487060547, Learning Rate: 0.005\n",
      "Epoch [2736/20000], Loss: 215.01634216308594, Entropy -244.43408203125, Learning Rate: 0.005\n",
      "Epoch [2737/20000], Loss: 232.5524139404297, Entropy -246.71829223632812, Learning Rate: 0.005\n",
      "Epoch [2738/20000], Loss: 237.00477600097656, Entropy -246.6712646484375, Learning Rate: 0.005\n",
      "Epoch [2739/20000], Loss: 217.90220642089844, Entropy -247.12753295898438, Learning Rate: 0.005\n",
      "Epoch [2740/20000], Loss: 218.12548828125, Entropy -237.4613037109375, Learning Rate: 0.005\n",
      "Epoch [2741/20000], Loss: 217.38389587402344, Entropy -238.68585205078125, Learning Rate: 0.005\n",
      "Epoch [2742/20000], Loss: 227.61996459960938, Entropy -234.7178955078125, Learning Rate: 0.005\n",
      "Epoch [2743/20000], Loss: 211.79441833496094, Entropy -240.58355712890625, Learning Rate: 0.005\n",
      "Epoch [2744/20000], Loss: 217.05052185058594, Entropy -245.65005493164062, Learning Rate: 0.005\n",
      "Epoch [2745/20000], Loss: 238.6146240234375, Entropy -247.2669219970703, Learning Rate: 0.005\n",
      "Epoch [2746/20000], Loss: 223.9561004638672, Entropy -238.35748291015625, Learning Rate: 0.005\n",
      "Epoch [2747/20000], Loss: 208.01617431640625, Entropy -229.3775177001953, Learning Rate: 0.005\n",
      "Epoch [2748/20000], Loss: 213.95742797851562, Entropy -240.2544708251953, Learning Rate: 0.005\n",
      "Epoch [2749/20000], Loss: 229.18807983398438, Entropy -244.61654663085938, Learning Rate: 0.005\n",
      "Epoch [2750/20000], Loss: 223.6883087158203, Entropy -238.67962646484375, Learning Rate: 0.005\n",
      "Epoch [2751/20000], Loss: 219.6651611328125, Entropy -234.4119415283203, Learning Rate: 0.005\n",
      "Epoch [2752/20000], Loss: 236.8966522216797, Entropy -236.78909301757812, Learning Rate: 0.005\n",
      "Epoch [2753/20000], Loss: 227.2953338623047, Entropy -246.18228149414062, Learning Rate: 0.005\n",
      "Epoch [2754/20000], Loss: 221.06564331054688, Entropy -248.92869567871094, Learning Rate: 0.005\n",
      "Epoch [2755/20000], Loss: 216.18678283691406, Entropy -239.325439453125, Learning Rate: 0.005\n",
      "Epoch [2756/20000], Loss: 216.13311767578125, Entropy -244.37200927734375, Learning Rate: 0.005\n",
      "Epoch [2757/20000], Loss: 207.44651794433594, Entropy -243.55368041992188, Learning Rate: 0.005\n",
      "Epoch [2758/20000], Loss: 217.5598602294922, Entropy -253.10781860351562, Learning Rate: 0.005\n",
      "Epoch [2759/20000], Loss: 213.197509765625, Entropy -230.21994018554688, Learning Rate: 0.005\n",
      "Epoch [2760/20000], Loss: 219.96139526367188, Entropy -251.73004150390625, Learning Rate: 0.005\n",
      "Epoch [2761/20000], Loss: 211.8617401123047, Entropy -250.98675537109375, Learning Rate: 0.005\n",
      "Epoch [2762/20000], Loss: 218.5880889892578, Entropy -250.0670928955078, Learning Rate: 0.005\n",
      "Epoch [2763/20000], Loss: 213.7606658935547, Entropy -240.45266723632812, Learning Rate: 0.005\n",
      "Epoch [2764/20000], Loss: 216.40525817871094, Entropy -249.64675903320312, Learning Rate: 0.005\n",
      "Epoch [2765/20000], Loss: 200.78140258789062, Entropy -234.07028198242188, Learning Rate: 0.005\n",
      "Epoch [2766/20000], Loss: 224.7440185546875, Entropy -249.4744873046875, Learning Rate: 0.005\n",
      "Epoch [2767/20000], Loss: 212.13832092285156, Entropy -237.7353515625, Learning Rate: 0.005\n",
      "Epoch [2768/20000], Loss: 210.2898712158203, Entropy -242.34506225585938, Learning Rate: 0.005\n",
      "Epoch [2769/20000], Loss: 211.8308563232422, Entropy -245.90869140625, Learning Rate: 0.005\n",
      "Epoch [2770/20000], Loss: 206.02508544921875, Entropy -234.48089599609375, Learning Rate: 0.005\n",
      "Epoch [2771/20000], Loss: 220.41627502441406, Entropy -246.88609313964844, Learning Rate: 0.005\n",
      "Epoch [2772/20000], Loss: 211.59886169433594, Entropy -238.00311279296875, Learning Rate: 0.005\n",
      "Epoch [2773/20000], Loss: 220.2493133544922, Entropy -239.0640411376953, Learning Rate: 0.005\n",
      "Epoch [2774/20000], Loss: 209.185791015625, Entropy -237.8091278076172, Learning Rate: 0.005\n",
      "Epoch [2775/20000], Loss: 206.6486053466797, Entropy -232.78207397460938, Learning Rate: 0.005\n",
      "Epoch [2776/20000], Loss: 216.32330322265625, Entropy -247.1917266845703, Learning Rate: 0.005\n",
      "Epoch [2777/20000], Loss: 199.9829864501953, Entropy -235.89108276367188, Learning Rate: 0.005\n",
      "Epoch [2778/20000], Loss: 205.01866149902344, Entropy -234.92770385742188, Learning Rate: 0.005\n",
      "Epoch [2779/20000], Loss: 196.63958740234375, Entropy -226.0792236328125, Learning Rate: 0.005\n",
      "Epoch [2780/20000], Loss: 211.05706787109375, Entropy -248.38870239257812, Learning Rate: 0.005\n",
      "Epoch [2781/20000], Loss: 215.8485107421875, Entropy -242.3018341064453, Learning Rate: 0.005\n",
      "Epoch [2782/20000], Loss: 210.50831604003906, Entropy -237.1253204345703, Learning Rate: 0.005\n",
      "Epoch [2783/20000], Loss: 210.5400390625, Entropy -238.6674346923828, Learning Rate: 0.005\n",
      "Epoch [2784/20000], Loss: 206.78428649902344, Entropy -243.8779754638672, Learning Rate: 0.005\n",
      "Epoch [2785/20000], Loss: 222.3700714111328, Entropy -251.0322723388672, Learning Rate: 0.005\n",
      "Epoch [2786/20000], Loss: 209.56149291992188, Entropy -235.4005126953125, Learning Rate: 0.005\n",
      "Epoch [2787/20000], Loss: 211.72994995117188, Entropy -242.88168334960938, Learning Rate: 0.005\n",
      "Epoch [2788/20000], Loss: 209.3473358154297, Entropy -232.2286376953125, Learning Rate: 0.005\n",
      "Epoch [2789/20000], Loss: 201.4512481689453, Entropy -222.68316650390625, Learning Rate: 0.005\n",
      "Epoch [2790/20000], Loss: 210.52084350585938, Entropy -242.79180908203125, Learning Rate: 0.005\n",
      "Epoch [2791/20000], Loss: 206.77951049804688, Entropy -236.8468017578125, Learning Rate: 0.005\n",
      "Epoch [2792/20000], Loss: 210.5244140625, Entropy -239.35626220703125, Learning Rate: 0.005\n",
      "Epoch [2793/20000], Loss: 201.3605194091797, Entropy -237.25619506835938, Learning Rate: 0.005\n",
      "Epoch [2794/20000], Loss: 214.24383544921875, Entropy -238.28948974609375, Learning Rate: 0.005\n",
      "Epoch [2795/20000], Loss: 201.94786071777344, Entropy -223.81300354003906, Learning Rate: 0.005\n",
      "Epoch [2796/20000], Loss: 221.370361328125, Entropy -240.2378692626953, Learning Rate: 0.005\n",
      "Epoch [2797/20000], Loss: 203.55918884277344, Entropy -238.82406616210938, Learning Rate: 0.005\n",
      "Epoch [2798/20000], Loss: 196.38600158691406, Entropy -227.1559600830078, Learning Rate: 0.005\n",
      "Epoch [2799/20000], Loss: 205.0536346435547, Entropy -236.0933380126953, Learning Rate: 0.005\n",
      "Epoch [2800/20000], Loss: 203.43301391601562, Entropy -236.54556274414062, Learning Rate: 0.005\n",
      "Epoch [2801/20000], Loss: 213.2443084716797, Entropy -247.98394775390625, Learning Rate: 0.005\n",
      "Epoch [2802/20000], Loss: 205.66761779785156, Entropy -240.34136962890625, Learning Rate: 0.005\n",
      "Epoch [2803/20000], Loss: 215.85438537597656, Entropy -246.10479736328125, Learning Rate: 0.005\n",
      "Epoch [2804/20000], Loss: 201.36517333984375, Entropy -240.65786743164062, Learning Rate: 0.005\n",
      "Epoch [2805/20000], Loss: 198.7190399169922, Entropy -237.3594970703125, Learning Rate: 0.005\n",
      "Epoch [2806/20000], Loss: 198.88417053222656, Entropy -231.69554138183594, Learning Rate: 0.005\n",
      "Epoch [2807/20000], Loss: 198.5330352783203, Entropy -224.1627197265625, Learning Rate: 0.005\n",
      "Epoch [2808/20000], Loss: 199.61007690429688, Entropy -239.567138671875, Learning Rate: 0.005\n",
      "Epoch [2809/20000], Loss: 207.01492309570312, Entropy -239.65576171875, Learning Rate: 0.005\n",
      "Epoch [2810/20000], Loss: 203.39871215820312, Entropy -235.7832794189453, Learning Rate: 0.005\n",
      "Epoch [2811/20000], Loss: 205.20127868652344, Entropy -244.0418243408203, Learning Rate: 0.005\n",
      "Epoch [2812/20000], Loss: 203.12026977539062, Entropy -233.948974609375, Learning Rate: 0.005\n",
      "Epoch [2813/20000], Loss: 210.0229034423828, Entropy -234.99761962890625, Learning Rate: 0.005\n",
      "Epoch [2814/20000], Loss: 199.78329467773438, Entropy -236.2526397705078, Learning Rate: 0.005\n",
      "Epoch [2815/20000], Loss: 207.96670532226562, Entropy -241.10308837890625, Learning Rate: 0.005\n",
      "Epoch [2816/20000], Loss: 222.38397216796875, Entropy -243.3567352294922, Learning Rate: 0.005\n",
      "Epoch [2817/20000], Loss: 230.68792724609375, Entropy -259.1383361816406, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2818/20000], Loss: 199.68438720703125, Entropy -229.4183807373047, Learning Rate: 0.005\n",
      "Epoch [2819/20000], Loss: 219.4644012451172, Entropy -250.09564208984375, Learning Rate: 0.005\n",
      "Epoch [2820/20000], Loss: 204.5182342529297, Entropy -227.03390502929688, Learning Rate: 0.005\n",
      "Epoch [2821/20000], Loss: 222.04367065429688, Entropy -247.86038208007812, Learning Rate: 0.005\n",
      "Epoch [2822/20000], Loss: 221.19598388671875, Entropy -235.79710388183594, Learning Rate: 0.005\n",
      "Epoch [2823/20000], Loss: 218.6065673828125, Entropy -227.67230224609375, Learning Rate: 0.005\n",
      "Epoch [2824/20000], Loss: 200.42117309570312, Entropy -232.09251403808594, Learning Rate: 0.005\n",
      "Epoch [2825/20000], Loss: 232.0738983154297, Entropy -245.90216064453125, Learning Rate: 0.005\n",
      "Epoch [2826/20000], Loss: 213.4599609375, Entropy -232.80551147460938, Learning Rate: 0.005\n",
      "Epoch [2827/20000], Loss: 210.65081787109375, Entropy -233.99082946777344, Learning Rate: 0.005\n",
      "Epoch [2828/20000], Loss: 232.1736602783203, Entropy -240.3974609375, Learning Rate: 0.005\n",
      "Epoch [2829/20000], Loss: 220.9104461669922, Entropy -236.96835327148438, Learning Rate: 0.005\n",
      "Epoch [2830/20000], Loss: 207.07070922851562, Entropy -230.3033447265625, Learning Rate: 0.005\n",
      "Epoch [2831/20000], Loss: 223.92236328125, Entropy -237.72564697265625, Learning Rate: 0.005\n",
      "Epoch [2832/20000], Loss: 206.12290954589844, Entropy -235.88714599609375, Learning Rate: 0.005\n",
      "Epoch [2833/20000], Loss: 217.38705444335938, Entropy -241.2277374267578, Learning Rate: 0.005\n",
      "Epoch [2834/20000], Loss: 230.57620239257812, Entropy -244.49571228027344, Learning Rate: 0.005\n",
      "Epoch [2835/20000], Loss: 219.17959594726562, Entropy -248.36351013183594, Learning Rate: 0.005\n",
      "Epoch [2836/20000], Loss: 199.20233154296875, Entropy -228.588623046875, Learning Rate: 0.005\n",
      "Epoch [2837/20000], Loss: 218.96923828125, Entropy -239.8829345703125, Learning Rate: 0.005\n",
      "Epoch [2838/20000], Loss: 210.22799682617188, Entropy -230.7753143310547, Learning Rate: 0.005\n",
      "Epoch [2839/20000], Loss: 210.7415771484375, Entropy -246.08364868164062, Learning Rate: 0.005\n",
      "Epoch [2840/20000], Loss: 216.94200134277344, Entropy -242.6510009765625, Learning Rate: 0.005\n",
      "Epoch [2841/20000], Loss: 210.32798767089844, Entropy -230.171142578125, Learning Rate: 0.005\n",
      "Epoch [2842/20000], Loss: 202.03314208984375, Entropy -239.70361328125, Learning Rate: 0.005\n",
      "Epoch [2843/20000], Loss: 206.1385498046875, Entropy -235.58998107910156, Learning Rate: 0.005\n",
      "Epoch [2844/20000], Loss: 206.40733337402344, Entropy -238.88291931152344, Learning Rate: 0.005\n",
      "Epoch [2845/20000], Loss: 197.0382537841797, Entropy -234.4922637939453, Learning Rate: 0.005\n",
      "Epoch [2846/20000], Loss: 204.972412109375, Entropy -232.31271362304688, Learning Rate: 0.005\n",
      "Epoch [2847/20000], Loss: 218.2606658935547, Entropy -240.81124877929688, Learning Rate: 0.005\n",
      "Epoch [2848/20000], Loss: 223.5337677001953, Entropy -244.92501831054688, Learning Rate: 0.005\n",
      "Epoch [2849/20000], Loss: 204.465576171875, Entropy -238.861572265625, Learning Rate: 0.005\n",
      "Epoch [2850/20000], Loss: 218.95010375976562, Entropy -244.6597442626953, Learning Rate: 0.005\n",
      "Epoch [2851/20000], Loss: 213.83370971679688, Entropy -236.6228485107422, Learning Rate: 0.005\n",
      "Epoch [2852/20000], Loss: 217.45521545410156, Entropy -251.3129119873047, Learning Rate: 0.005\n",
      "Epoch [2853/20000], Loss: 213.8514862060547, Entropy -238.6893768310547, Learning Rate: 0.005\n",
      "Epoch [2854/20000], Loss: 204.39382934570312, Entropy -229.28128051757812, Learning Rate: 0.005\n",
      "Epoch [2855/20000], Loss: 216.9803466796875, Entropy -238.6639404296875, Learning Rate: 0.005\n",
      "Epoch [2856/20000], Loss: 205.9286651611328, Entropy -232.49546813964844, Learning Rate: 0.005\n",
      "Epoch [2857/20000], Loss: 214.40975952148438, Entropy -225.98178100585938, Learning Rate: 0.005\n",
      "Epoch [2858/20000], Loss: 216.01345825195312, Entropy -230.11593627929688, Learning Rate: 0.005\n",
      "Epoch [2859/20000], Loss: 218.5225372314453, Entropy -244.23719787597656, Learning Rate: 0.005\n",
      "Epoch [2860/20000], Loss: 200.77224731445312, Entropy -228.68634033203125, Learning Rate: 0.005\n",
      "Epoch [2861/20000], Loss: 212.65469360351562, Entropy -226.81117248535156, Learning Rate: 0.005\n",
      "Epoch [2862/20000], Loss: 214.35838317871094, Entropy -230.66587829589844, Learning Rate: 0.005\n",
      "Epoch [2863/20000], Loss: 215.78359985351562, Entropy -245.9127655029297, Learning Rate: 0.005\n",
      "Epoch [2864/20000], Loss: 200.48219299316406, Entropy -232.17552185058594, Learning Rate: 0.005\n",
      "Epoch [2865/20000], Loss: 220.71852111816406, Entropy -231.02976989746094, Learning Rate: 0.005\n",
      "Epoch [2866/20000], Loss: 201.2196807861328, Entropy -233.08853149414062, Learning Rate: 0.005\n",
      "Epoch [2867/20000], Loss: 210.5215606689453, Entropy -244.2323760986328, Learning Rate: 0.005\n",
      "Epoch [2868/20000], Loss: 222.31341552734375, Entropy -252.85601806640625, Learning Rate: 0.005\n",
      "Epoch [2869/20000], Loss: 214.83303833007812, Entropy -240.7268524169922, Learning Rate: 0.005\n",
      "Epoch [2870/20000], Loss: 202.13864135742188, Entropy -232.63584899902344, Learning Rate: 0.005\n",
      "Epoch [2871/20000], Loss: 206.82659912109375, Entropy -230.39620971679688, Learning Rate: 0.005\n",
      "Epoch [2872/20000], Loss: 205.50885009765625, Entropy -231.9918212890625, Learning Rate: 0.005\n",
      "Epoch [2873/20000], Loss: 196.08209228515625, Entropy -231.33474731445312, Learning Rate: 0.005\n",
      "Epoch [2874/20000], Loss: 228.09432983398438, Entropy -259.20111083984375, Learning Rate: 0.005\n",
      "Epoch [2875/20000], Loss: 210.50042724609375, Entropy -245.3014373779297, Learning Rate: 0.005\n",
      "Epoch [2876/20000], Loss: 200.83441162109375, Entropy -231.66558837890625, Learning Rate: 0.005\n",
      "Epoch [2877/20000], Loss: 232.5106201171875, Entropy -239.83831787109375, Learning Rate: 0.005\n",
      "Epoch [2878/20000], Loss: 244.31039428710938, Entropy -241.4178466796875, Learning Rate: 0.005\n",
      "Epoch [2879/20000], Loss: 200.10943603515625, Entropy -220.74855041503906, Learning Rate: 0.005\n",
      "Epoch [2880/20000], Loss: 208.40528869628906, Entropy -228.62155151367188, Learning Rate: 0.005\n",
      "Epoch [2881/20000], Loss: 273.5201416015625, Entropy -240.67855834960938, Learning Rate: 0.005\n",
      "Epoch [2882/20000], Loss: 281.2709655761719, Entropy -235.98934936523438, Learning Rate: 0.005\n",
      "Epoch [2883/20000], Loss: 211.93582153320312, Entropy -238.00808715820312, Learning Rate: 0.005\n",
      "Epoch [2884/20000], Loss: 257.9124755859375, Entropy -255.90951538085938, Learning Rate: 0.005\n",
      "Epoch [2885/20000], Loss: 336.16436767578125, Entropy -243.1920623779297, Learning Rate: 0.005\n",
      "Epoch [2886/20000], Loss: 294.5421142578125, Entropy -238.18458557128906, Learning Rate: 0.005\n",
      "Epoch [2887/20000], Loss: 205.15525817871094, Entropy -239.1848907470703, Learning Rate: 0.005\n",
      "Epoch [2888/20000], Loss: 283.66607666015625, Entropy -232.89041137695312, Learning Rate: 0.005\n",
      "Epoch [2889/20000], Loss: 319.27197265625, Entropy -232.44512939453125, Learning Rate: 0.005\n",
      "Epoch [2890/20000], Loss: 220.78575134277344, Entropy -242.01585388183594, Learning Rate: 0.005\n",
      "Epoch [2891/20000], Loss: 256.0147705078125, Entropy -238.62542724609375, Learning Rate: 0.005\n",
      "Epoch [2892/20000], Loss: 253.55023193359375, Entropy -238.7522430419922, Learning Rate: 0.005\n",
      "Epoch [2893/20000], Loss: 224.67962646484375, Entropy -236.51702880859375, Learning Rate: 0.005\n",
      "Epoch [2894/20000], Loss: 224.72781372070312, Entropy -233.88287353515625, Learning Rate: 0.005\n",
      "Epoch [2895/20000], Loss: 232.21347045898438, Entropy -243.97494506835938, Learning Rate: 0.005\n",
      "Epoch [2896/20000], Loss: 210.9076690673828, Entropy -225.57546997070312, Learning Rate: 0.005\n",
      "Epoch [2897/20000], Loss: 207.77088928222656, Entropy -233.73263549804688, Learning Rate: 0.005\n",
      "Epoch [2898/20000], Loss: 206.0891571044922, Entropy -228.05404663085938, Learning Rate: 0.005\n",
      "Epoch [2899/20000], Loss: 227.84646606445312, Entropy -231.02001953125, Learning Rate: 0.005\n",
      "Epoch [2900/20000], Loss: 246.53207397460938, Entropy -251.54112243652344, Learning Rate: 0.005\n",
      "Epoch [2901/20000], Loss: 222.2104949951172, Entropy -232.45083618164062, Learning Rate: 0.005\n",
      "Epoch [2902/20000], Loss: 247.00518798828125, Entropy -253.50079345703125, Learning Rate: 0.005\n",
      "Epoch [2903/20000], Loss: 264.22418212890625, Entropy -240.59756469726562, Learning Rate: 0.005\n",
      "Epoch [2904/20000], Loss: 213.46023559570312, Entropy -226.4018096923828, Learning Rate: 0.005\n",
      "Epoch [2905/20000], Loss: 253.1105499267578, Entropy -242.96250915527344, Learning Rate: 0.005\n",
      "Epoch [2906/20000], Loss: 367.1123962402344, Entropy -227.92617797851562, Learning Rate: 0.005\n",
      "Epoch [2907/20000], Loss: 338.6004333496094, Entropy -226.78619384765625, Learning Rate: 0.005\n",
      "Epoch [2908/20000], Loss: 248.84884643554688, Entropy -236.16989135742188, Learning Rate: 0.005\n",
      "Epoch [2909/20000], Loss: 307.6698913574219, Entropy -245.47479248046875, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2910/20000], Loss: 317.5117492675781, Entropy -240.142333984375, Learning Rate: 0.005\n",
      "Epoch [2911/20000], Loss: 235.9637908935547, Entropy -242.29039001464844, Learning Rate: 0.005\n",
      "Epoch [2912/20000], Loss: 292.5999755859375, Entropy -229.8614959716797, Learning Rate: 0.005\n",
      "Epoch [2913/20000], Loss: 345.352294921875, Entropy -235.41015625, Learning Rate: 0.005\n",
      "Epoch [2914/20000], Loss: 222.89076232910156, Entropy -237.4931182861328, Learning Rate: 0.005\n",
      "Epoch [2915/20000], Loss: 305.1919860839844, Entropy -236.04937744140625, Learning Rate: 0.005\n",
      "Epoch [2916/20000], Loss: 284.8262634277344, Entropy -241.81138610839844, Learning Rate: 0.005\n",
      "Epoch [2917/20000], Loss: 233.60421752929688, Entropy -230.20535278320312, Learning Rate: 0.005\n",
      "Epoch [2918/20000], Loss: 320.99530029296875, Entropy -248.357421875, Learning Rate: 0.005\n",
      "Epoch [2919/20000], Loss: 233.99185180664062, Entropy -238.4676055908203, Learning Rate: 0.005\n",
      "Epoch [2920/20000], Loss: 288.3974304199219, Entropy -234.08734130859375, Learning Rate: 0.005\n",
      "Epoch [2921/20000], Loss: 308.5103759765625, Entropy -233.01513671875, Learning Rate: 0.005\n",
      "Epoch [2922/20000], Loss: 212.3597869873047, Entropy -240.2913818359375, Learning Rate: 0.005\n",
      "Epoch [2923/20000], Loss: 309.8538818359375, Entropy -232.37115478515625, Learning Rate: 0.005\n",
      "Epoch [2924/20000], Loss: 263.72509765625, Entropy -229.96963500976562, Learning Rate: 0.005\n",
      "Epoch [2925/20000], Loss: 217.7123260498047, Entropy -240.3861846923828, Learning Rate: 0.005\n",
      "Epoch [2926/20000], Loss: 296.7556457519531, Entropy -242.0186309814453, Learning Rate: 0.005\n",
      "Epoch [2927/20000], Loss: 214.57913208007812, Entropy -235.04368591308594, Learning Rate: 0.005\n",
      "Epoch [2928/20000], Loss: 276.4474792480469, Entropy -248.85671997070312, Learning Rate: 0.005\n",
      "Epoch [2929/20000], Loss: 271.7354736328125, Entropy -239.52696228027344, Learning Rate: 0.005\n",
      "Epoch [2930/20000], Loss: 210.6668701171875, Entropy -234.36065673828125, Learning Rate: 0.005\n",
      "Epoch [2931/20000], Loss: 260.0427551269531, Entropy -244.4739990234375, Learning Rate: 0.005\n",
      "Epoch [2932/20000], Loss: 212.8820037841797, Entropy -238.8436279296875, Learning Rate: 0.005\n",
      "Epoch [2933/20000], Loss: 213.85284423828125, Entropy -241.58895874023438, Learning Rate: 0.005\n",
      "Epoch [2934/20000], Loss: 238.56114196777344, Entropy -241.67779541015625, Learning Rate: 0.005\n",
      "Epoch [2935/20000], Loss: 211.98606872558594, Entropy -240.50851440429688, Learning Rate: 0.005\n",
      "Epoch [2936/20000], Loss: 220.05972290039062, Entropy -236.0834197998047, Learning Rate: 0.005\n",
      "Epoch [2937/20000], Loss: 236.1820526123047, Entropy -261.2472229003906, Learning Rate: 0.005\n",
      "Epoch [2938/20000], Loss: 226.2460479736328, Entropy -240.49746704101562, Learning Rate: 0.005\n",
      "Epoch [2939/20000], Loss: 223.7046356201172, Entropy -228.3559112548828, Learning Rate: 0.005\n",
      "Epoch [2940/20000], Loss: 228.673828125, Entropy -244.94528198242188, Learning Rate: 0.005\n",
      "Epoch [2941/20000], Loss: 227.82652282714844, Entropy -241.18484497070312, Learning Rate: 0.005\n",
      "Epoch [2942/20000], Loss: 222.04531860351562, Entropy -241.7673797607422, Learning Rate: 0.005\n",
      "Epoch [2943/20000], Loss: 229.85476684570312, Entropy -250.02798461914062, Learning Rate: 0.005\n",
      "Epoch [2944/20000], Loss: 232.16302490234375, Entropy -254.32496643066406, Learning Rate: 0.005\n",
      "Epoch [2945/20000], Loss: 228.53504943847656, Entropy -251.01388549804688, Learning Rate: 0.005\n",
      "Epoch [2946/20000], Loss: 229.07554626464844, Entropy -233.8943634033203, Learning Rate: 0.005\n",
      "Epoch [2947/20000], Loss: 215.86337280273438, Entropy -244.58291625976562, Learning Rate: 0.005\n",
      "Epoch [2948/20000], Loss: 224.67239379882812, Entropy -238.9844970703125, Learning Rate: 0.005\n",
      "Epoch [2949/20000], Loss: 223.22158813476562, Entropy -236.62918090820312, Learning Rate: 0.005\n",
      "Epoch [2950/20000], Loss: 221.24057006835938, Entropy -240.91883850097656, Learning Rate: 0.005\n",
      "Epoch [2951/20000], Loss: 232.8985137939453, Entropy -235.73736572265625, Learning Rate: 0.005\n",
      "Epoch [2952/20000], Loss: 204.4740447998047, Entropy -239.56777954101562, Learning Rate: 0.005\n",
      "Epoch [2953/20000], Loss: 223.0976104736328, Entropy -225.1490020751953, Learning Rate: 0.005\n",
      "Epoch [2954/20000], Loss: 224.90223693847656, Entropy -241.85958862304688, Learning Rate: 0.005\n",
      "Epoch [2955/20000], Loss: 214.89671325683594, Entropy -243.02532958984375, Learning Rate: 0.005\n",
      "Epoch [2956/20000], Loss: 266.3349914550781, Entropy -250.27169799804688, Learning Rate: 0.005\n",
      "Epoch [2957/20000], Loss: 232.38442993164062, Entropy -239.4641876220703, Learning Rate: 0.005\n",
      "Epoch [2958/20000], Loss: 214.8723907470703, Entropy -227.77597045898438, Learning Rate: 0.005\n",
      "Epoch [2959/20000], Loss: 244.87574768066406, Entropy -242.1807861328125, Learning Rate: 0.005\n",
      "Epoch [2960/20000], Loss: 226.88487243652344, Entropy -237.80191040039062, Learning Rate: 0.005\n",
      "Epoch [2961/20000], Loss: 230.916748046875, Entropy -226.21275329589844, Learning Rate: 0.005\n",
      "Epoch [2962/20000], Loss: 200.0487823486328, Entropy -223.5601348876953, Learning Rate: 0.005\n",
      "Epoch [2963/20000], Loss: 220.84864807128906, Entropy -237.29400634765625, Learning Rate: 0.005\n",
      "Epoch [2964/20000], Loss: 224.34625244140625, Entropy -229.54957580566406, Learning Rate: 0.005\n",
      "Epoch [2965/20000], Loss: 210.0223388671875, Entropy -229.83990478515625, Learning Rate: 0.005\n",
      "Epoch [2966/20000], Loss: 205.09593200683594, Entropy -222.94264221191406, Learning Rate: 0.005\n",
      "Epoch [2967/20000], Loss: 213.38148498535156, Entropy -235.86549377441406, Learning Rate: 0.005\n",
      "Epoch [2968/20000], Loss: 213.66561889648438, Entropy -245.2711181640625, Learning Rate: 0.005\n",
      "Epoch [2969/20000], Loss: 226.64439392089844, Entropy -243.84861755371094, Learning Rate: 0.005\n",
      "Epoch [2970/20000], Loss: 219.42803955078125, Entropy -246.82476806640625, Learning Rate: 0.005\n",
      "Epoch [2971/20000], Loss: 215.78382873535156, Entropy -240.5228271484375, Learning Rate: 0.005\n",
      "Epoch [2972/20000], Loss: 208.11085510253906, Entropy -237.5870361328125, Learning Rate: 0.005\n",
      "Epoch [2973/20000], Loss: 216.22476196289062, Entropy -230.2030029296875, Learning Rate: 0.005\n",
      "Epoch [2974/20000], Loss: 209.77651977539062, Entropy -235.02682495117188, Learning Rate: 0.005\n",
      "Epoch [2975/20000], Loss: 214.64593505859375, Entropy -248.57733154296875, Learning Rate: 0.005\n",
      "Epoch [2976/20000], Loss: 205.56553649902344, Entropy -224.47799682617188, Learning Rate: 0.005\n",
      "Epoch [2977/20000], Loss: 211.7670440673828, Entropy -240.03466796875, Learning Rate: 0.005\n",
      "Epoch [2978/20000], Loss: 193.44569396972656, Entropy -226.211669921875, Learning Rate: 0.005\n",
      "Epoch [2979/20000], Loss: 222.47073364257812, Entropy -247.153076171875, Learning Rate: 0.005\n",
      "Epoch [2980/20000], Loss: 211.0281219482422, Entropy -235.41061401367188, Learning Rate: 0.005\n",
      "Epoch [2981/20000], Loss: 204.7842559814453, Entropy -240.17605590820312, Learning Rate: 0.005\n",
      "Epoch [2982/20000], Loss: 203.53994750976562, Entropy -238.90316772460938, Learning Rate: 0.005\n",
      "Epoch [2983/20000], Loss: 193.93975830078125, Entropy -218.2400665283203, Learning Rate: 0.005\n",
      "Epoch [2984/20000], Loss: 208.65066528320312, Entropy -237.379150390625, Learning Rate: 0.005\n",
      "Epoch [2985/20000], Loss: 207.55914306640625, Entropy -231.65155029296875, Learning Rate: 0.005\n",
      "Epoch [2986/20000], Loss: 213.39260864257812, Entropy -246.78245544433594, Learning Rate: 0.005\n",
      "Epoch [2987/20000], Loss: 208.28790283203125, Entropy -235.55245971679688, Learning Rate: 0.005\n",
      "Epoch [2988/20000], Loss: 218.8511505126953, Entropy -234.88735961914062, Learning Rate: 0.005\n",
      "Epoch [2989/20000], Loss: 213.06280517578125, Entropy -228.76083374023438, Learning Rate: 0.005\n",
      "Epoch [2990/20000], Loss: 233.20785522460938, Entropy -230.07748413085938, Learning Rate: 0.005\n",
      "Epoch [2991/20000], Loss: 210.42288208007812, Entropy -243.42391967773438, Learning Rate: 0.005\n",
      "Epoch [2992/20000], Loss: 206.78884887695312, Entropy -228.65533447265625, Learning Rate: 0.005\n",
      "Epoch [2993/20000], Loss: 212.80343627929688, Entropy -234.10279846191406, Learning Rate: 0.005\n",
      "Epoch [2994/20000], Loss: 216.84591674804688, Entropy -244.8394012451172, Learning Rate: 0.005\n",
      "Epoch [2995/20000], Loss: 224.677001953125, Entropy -235.78167724609375, Learning Rate: 0.005\n",
      "Epoch [2996/20000], Loss: 244.0303497314453, Entropy -255.46530151367188, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2997/20000], Loss: 200.23194885253906, Entropy -229.59759521484375, Learning Rate: 0.005\n",
      "Epoch [2998/20000], Loss: 205.42236328125, Entropy -231.67506408691406, Learning Rate: 0.005\n",
      "Epoch [2999/20000], Loss: 211.45448303222656, Entropy -230.13027954101562, Learning Rate: 0.005\n",
      "Epoch [3000/20000], Loss: 205.04820251464844, Entropy -231.04209899902344, Learning Rate: 0.005\n",
      "Epoch [3001/20000], Loss: 193.0867156982422, Entropy -228.65968322753906, Learning Rate: 0.005\n",
      "Epoch [3002/20000], Loss: 228.2379913330078, Entropy -236.80764770507812, Learning Rate: 0.005\n",
      "Epoch [3003/20000], Loss: 214.63314819335938, Entropy -234.2362060546875, Learning Rate: 0.005\n",
      "Epoch [3004/20000], Loss: 196.41758728027344, Entropy -227.74986267089844, Learning Rate: 0.005\n",
      "Epoch [3005/20000], Loss: 213.511474609375, Entropy -239.70065307617188, Learning Rate: 0.005\n",
      "Epoch [3006/20000], Loss: 209.494873046875, Entropy -242.0604248046875, Learning Rate: 0.005\n",
      "Epoch [3007/20000], Loss: 211.6668701171875, Entropy -233.2744140625, Learning Rate: 0.005\n",
      "Epoch [3008/20000], Loss: 222.6605224609375, Entropy -244.32444763183594, Learning Rate: 0.005\n",
      "Epoch [3009/20000], Loss: 219.16830444335938, Entropy -242.38558959960938, Learning Rate: 0.005\n",
      "Epoch [3010/20000], Loss: 221.22218322753906, Entropy -245.58770751953125, Learning Rate: 0.005\n",
      "Epoch [3011/20000], Loss: 199.4143829345703, Entropy -224.76148986816406, Learning Rate: 0.005\n",
      "Epoch [3012/20000], Loss: 223.74197387695312, Entropy -236.710205078125, Learning Rate: 0.005\n",
      "Epoch [3013/20000], Loss: 236.03024291992188, Entropy -253.22958374023438, Learning Rate: 0.005\n",
      "Epoch [3014/20000], Loss: 200.69593811035156, Entropy -239.17684936523438, Learning Rate: 0.005\n",
      "Epoch [3015/20000], Loss: 231.7516326904297, Entropy -246.86947631835938, Learning Rate: 0.005\n",
      "Epoch [3016/20000], Loss: 226.30909729003906, Entropy -244.72586059570312, Learning Rate: 0.005\n",
      "Epoch [3017/20000], Loss: 218.6023406982422, Entropy -245.51272583007812, Learning Rate: 0.005\n",
      "Epoch [3018/20000], Loss: 214.3241424560547, Entropy -240.75942993164062, Learning Rate: 0.005\n",
      "Epoch [3019/20000], Loss: 208.96583557128906, Entropy -235.9664764404297, Learning Rate: 0.005\n",
      "Epoch [3020/20000], Loss: 217.86558532714844, Entropy -234.13650512695312, Learning Rate: 0.005\n",
      "Epoch [3021/20000], Loss: 208.8706512451172, Entropy -240.89828491210938, Learning Rate: 0.005\n",
      "Epoch [3022/20000], Loss: 220.30099487304688, Entropy -243.52130126953125, Learning Rate: 0.005\n",
      "Epoch [3023/20000], Loss: 224.9235382080078, Entropy -234.5673828125, Learning Rate: 0.005\n",
      "Epoch [3024/20000], Loss: 213.5996856689453, Entropy -249.6878662109375, Learning Rate: 0.005\n",
      "Epoch [3025/20000], Loss: 202.91864013671875, Entropy -232.51673889160156, Learning Rate: 0.005\n",
      "Epoch [3026/20000], Loss: 230.32298278808594, Entropy -241.36419677734375, Learning Rate: 0.005\n",
      "Epoch [3027/20000], Loss: 224.2751007080078, Entropy -245.64300537109375, Learning Rate: 0.005\n",
      "Epoch [3028/20000], Loss: 195.48397827148438, Entropy -232.1883544921875, Learning Rate: 0.005\n",
      "Epoch [3029/20000], Loss: 196.84584045410156, Entropy -228.53054809570312, Learning Rate: 0.005\n",
      "Epoch [3030/20000], Loss: 213.9535369873047, Entropy -228.38157653808594, Learning Rate: 0.005\n",
      "Epoch [3031/20000], Loss: 218.2902069091797, Entropy -244.99896240234375, Learning Rate: 0.005\n",
      "Epoch [3032/20000], Loss: 195.45620727539062, Entropy -227.4701690673828, Learning Rate: 0.005\n",
      "Epoch [3033/20000], Loss: 199.6082305908203, Entropy -233.4988250732422, Learning Rate: 0.005\n",
      "Epoch [3034/20000], Loss: 192.21463012695312, Entropy -216.96435546875, Learning Rate: 0.005\n",
      "Epoch [3035/20000], Loss: 200.781982421875, Entropy -232.6166534423828, Learning Rate: 0.005\n",
      "Epoch [3036/20000], Loss: 214.3553924560547, Entropy -241.00357055664062, Learning Rate: 0.005\n",
      "Epoch [3037/20000], Loss: 201.73004150390625, Entropy -241.9576416015625, Learning Rate: 0.005\n",
      "Epoch [3038/20000], Loss: 213.49832153320312, Entropy -247.03829956054688, Learning Rate: 0.005\n",
      "Epoch [3039/20000], Loss: 211.78802490234375, Entropy -244.8208465576172, Learning Rate: 0.005\n",
      "Epoch [3040/20000], Loss: 212.87709045410156, Entropy -240.93756103515625, Learning Rate: 0.005\n",
      "Epoch [3041/20000], Loss: 205.48167419433594, Entropy -236.89630126953125, Learning Rate: 0.005\n",
      "Epoch [3042/20000], Loss: 193.89280700683594, Entropy -225.21005249023438, Learning Rate: 0.005\n",
      "Epoch [3043/20000], Loss: 218.7118682861328, Entropy -249.5985870361328, Learning Rate: 0.005\n",
      "Epoch [3044/20000], Loss: 205.9969024658203, Entropy -238.75439453125, Learning Rate: 0.005\n",
      "Epoch [3045/20000], Loss: 208.88821411132812, Entropy -238.3987274169922, Learning Rate: 0.005\n",
      "Epoch [3046/20000], Loss: 207.11839294433594, Entropy -226.43431091308594, Learning Rate: 0.005\n",
      "Epoch [3047/20000], Loss: 211.02757263183594, Entropy -236.04367065429688, Learning Rate: 0.005\n",
      "Epoch [3048/20000], Loss: 219.3380889892578, Entropy -251.5941925048828, Learning Rate: 0.005\n",
      "Epoch [3049/20000], Loss: 208.47177124023438, Entropy -235.36724853515625, Learning Rate: 0.005\n",
      "Epoch [3050/20000], Loss: 205.7749481201172, Entropy -234.25624084472656, Learning Rate: 0.005\n",
      "Epoch [3051/20000], Loss: 221.24913024902344, Entropy -243.89918518066406, Learning Rate: 0.005\n",
      "Epoch [3052/20000], Loss: 220.4240264892578, Entropy -251.35556030273438, Learning Rate: 0.005\n",
      "Epoch [3053/20000], Loss: 212.28695678710938, Entropy -247.94700622558594, Learning Rate: 0.005\n",
      "Epoch [3054/20000], Loss: 200.61038208007812, Entropy -226.6123504638672, Learning Rate: 0.005\n",
      "Epoch [3055/20000], Loss: 206.25433349609375, Entropy -228.71966552734375, Learning Rate: 0.005\n",
      "Epoch [3056/20000], Loss: 195.3084259033203, Entropy -225.5633087158203, Learning Rate: 0.005\n",
      "Epoch [3057/20000], Loss: 204.8914031982422, Entropy -241.10525512695312, Learning Rate: 0.005\n",
      "Epoch [3058/20000], Loss: 189.41624450683594, Entropy -227.51304626464844, Learning Rate: 0.005\n",
      "Epoch [3059/20000], Loss: 206.1131591796875, Entropy -232.2138671875, Learning Rate: 0.005\n",
      "Epoch [3060/20000], Loss: 194.6539306640625, Entropy -230.7935791015625, Learning Rate: 0.005\n",
      "Epoch [3061/20000], Loss: 194.43788146972656, Entropy -234.3848419189453, Learning Rate: 0.005\n",
      "Epoch [3062/20000], Loss: 208.99737548828125, Entropy -248.9610595703125, Learning Rate: 0.005\n",
      "Epoch [3063/20000], Loss: 199.91001892089844, Entropy -231.57192993164062, Learning Rate: 0.005\n",
      "Epoch [3064/20000], Loss: 203.81895446777344, Entropy -237.61766052246094, Learning Rate: 0.005\n",
      "Epoch [3065/20000], Loss: 196.84475708007812, Entropy -232.99127197265625, Learning Rate: 0.005\n",
      "Epoch [3066/20000], Loss: 187.35606384277344, Entropy -220.50775146484375, Learning Rate: 0.005\n",
      "Epoch [3067/20000], Loss: 206.6957550048828, Entropy -232.7899627685547, Learning Rate: 0.005\n",
      "Epoch [3068/20000], Loss: 201.77365112304688, Entropy -226.4166717529297, Learning Rate: 0.005\n",
      "Epoch [3069/20000], Loss: 203.44964599609375, Entropy -243.91708374023438, Learning Rate: 0.005\n",
      "Epoch [3070/20000], Loss: 205.44659423828125, Entropy -234.68374633789062, Learning Rate: 0.005\n",
      "Epoch [3071/20000], Loss: 199.15725708007812, Entropy -230.37921142578125, Learning Rate: 0.005\n",
      "Epoch [3072/20000], Loss: 192.37351989746094, Entropy -232.46380615234375, Learning Rate: 0.005\n",
      "Epoch [3073/20000], Loss: 204.0709686279297, Entropy -240.00320434570312, Learning Rate: 0.005\n",
      "Epoch [3074/20000], Loss: 202.51930236816406, Entropy -238.05201721191406, Learning Rate: 0.005\n",
      "Epoch [3075/20000], Loss: 197.43905639648438, Entropy -234.78298950195312, Learning Rate: 0.005\n",
      "Epoch [3076/20000], Loss: 192.96328735351562, Entropy -226.33892822265625, Learning Rate: 0.005\n",
      "Epoch [3077/20000], Loss: 196.2767791748047, Entropy -232.69476318359375, Learning Rate: 0.005\n",
      "Epoch [3078/20000], Loss: 197.8928680419922, Entropy -230.90045166015625, Learning Rate: 0.005\n",
      "Epoch [3079/20000], Loss: 202.09817504882812, Entropy -238.85813903808594, Learning Rate: 0.005\n",
      "Epoch [3080/20000], Loss: 205.74710083007812, Entropy -237.72512817382812, Learning Rate: 0.005\n",
      "Epoch [3081/20000], Loss: 197.96031188964844, Entropy -232.5299835205078, Learning Rate: 0.005\n",
      "Epoch [3082/20000], Loss: 202.37554931640625, Entropy -238.14109802246094, Learning Rate: 0.005\n",
      "Epoch [3083/20000], Loss: 210.81845092773438, Entropy -244.19895935058594, Learning Rate: 0.005\n",
      "Epoch [3084/20000], Loss: 202.2847900390625, Entropy -233.11386108398438, Learning Rate: 0.005\n",
      "Epoch [3085/20000], Loss: 200.51010131835938, Entropy -233.01214599609375, Learning Rate: 0.005\n",
      "Epoch [3086/20000], Loss: 190.5092315673828, Entropy -212.0132598876953, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3087/20000], Loss: 214.8727569580078, Entropy -217.20205688476562, Learning Rate: 0.005\n",
      "Epoch [3088/20000], Loss: 214.82069396972656, Entropy -236.85177612304688, Learning Rate: 0.005\n",
      "Epoch [3089/20000], Loss: 196.05526733398438, Entropy -229.48358154296875, Learning Rate: 0.005\n",
      "Epoch [3090/20000], Loss: 208.20660400390625, Entropy -236.80213928222656, Learning Rate: 0.005\n",
      "Epoch [3091/20000], Loss: 220.67945861816406, Entropy -226.71450805664062, Learning Rate: 0.005\n",
      "Epoch [3092/20000], Loss: 204.04689025878906, Entropy -227.41763305664062, Learning Rate: 0.005\n",
      "Epoch [3093/20000], Loss: 193.84814453125, Entropy -230.15484619140625, Learning Rate: 0.005\n",
      "Epoch [3094/20000], Loss: 217.90335083007812, Entropy -235.15321350097656, Learning Rate: 0.005\n",
      "Epoch [3095/20000], Loss: 226.4058074951172, Entropy -239.6004638671875, Learning Rate: 0.005\n",
      "Epoch [3096/20000], Loss: 199.75445556640625, Entropy -236.03323364257812, Learning Rate: 0.005\n",
      "Epoch [3097/20000], Loss: 209.39064025878906, Entropy -242.35064697265625, Learning Rate: 0.005\n",
      "Epoch [3098/20000], Loss: 216.55105590820312, Entropy -232.6400604248047, Learning Rate: 0.005\n",
      "Epoch [3099/20000], Loss: 205.20663452148438, Entropy -236.77462768554688, Learning Rate: 0.005\n",
      "Epoch [3100/20000], Loss: 201.036376953125, Entropy -242.7353515625, Learning Rate: 0.005\n",
      "Epoch [3101/20000], Loss: 202.7414093017578, Entropy -229.02291870117188, Learning Rate: 0.005\n",
      "Epoch [3102/20000], Loss: 204.7498321533203, Entropy -235.66397094726562, Learning Rate: 0.005\n",
      "Epoch [3103/20000], Loss: 195.53553771972656, Entropy -234.34451293945312, Learning Rate: 0.005\n",
      "Epoch [3104/20000], Loss: 212.34756469726562, Entropy -235.9488983154297, Learning Rate: 0.005\n",
      "Epoch [3105/20000], Loss: 200.8661346435547, Entropy -226.727783203125, Learning Rate: 0.005\n",
      "Epoch [3106/20000], Loss: 212.32574462890625, Entropy -238.2326202392578, Learning Rate: 0.005\n",
      "Epoch [3107/20000], Loss: 208.87185668945312, Entropy -233.64932250976562, Learning Rate: 0.005\n",
      "Epoch [3108/20000], Loss: 204.138671875, Entropy -235.79940795898438, Learning Rate: 0.005\n",
      "Epoch [3109/20000], Loss: 188.25013732910156, Entropy -227.25418090820312, Learning Rate: 0.005\n",
      "Epoch [3110/20000], Loss: 208.77084350585938, Entropy -231.95181274414062, Learning Rate: 0.005\n",
      "Epoch [3111/20000], Loss: 216.01255798339844, Entropy -234.18185424804688, Learning Rate: 0.005\n",
      "Epoch [3112/20000], Loss: 219.8056640625, Entropy -233.71810913085938, Learning Rate: 0.005\n",
      "Epoch [3113/20000], Loss: 195.0911407470703, Entropy -229.69863891601562, Learning Rate: 0.005\n",
      "Epoch [3114/20000], Loss: 198.810302734375, Entropy -224.68893432617188, Learning Rate: 0.005\n",
      "Epoch [3115/20000], Loss: 223.13314819335938, Entropy -238.52505493164062, Learning Rate: 0.005\n",
      "Epoch [3116/20000], Loss: 219.66128540039062, Entropy -238.72100830078125, Learning Rate: 0.005\n",
      "Epoch [3117/20000], Loss: 199.83238220214844, Entropy -226.84552001953125, Learning Rate: 0.005\n",
      "Epoch [3118/20000], Loss: 198.2328643798828, Entropy -224.9389190673828, Learning Rate: 0.005\n",
      "Epoch [3119/20000], Loss: 205.69851684570312, Entropy -229.55104064941406, Learning Rate: 0.005\n",
      "Epoch [3120/20000], Loss: 193.9016876220703, Entropy -229.8556671142578, Learning Rate: 0.005\n",
      "Epoch [3121/20000], Loss: 200.00820922851562, Entropy -229.45425415039062, Learning Rate: 0.005\n",
      "Epoch [3122/20000], Loss: 227.1331787109375, Entropy -234.20797729492188, Learning Rate: 0.005\n",
      "Epoch [3123/20000], Loss: 208.8662109375, Entropy -228.76988220214844, Learning Rate: 0.005\n",
      "Epoch [3124/20000], Loss: 179.83309936523438, Entropy -216.9483642578125, Learning Rate: 0.005\n",
      "Epoch [3125/20000], Loss: 230.86497497558594, Entropy -233.19009399414062, Learning Rate: 0.005\n",
      "Epoch [3126/20000], Loss: 211.19085693359375, Entropy -226.65989685058594, Learning Rate: 0.005\n",
      "Epoch [3127/20000], Loss: 197.372314453125, Entropy -236.54159545898438, Learning Rate: 0.005\n",
      "Epoch [3128/20000], Loss: 200.86373901367188, Entropy -221.22421264648438, Learning Rate: 0.005\n",
      "Epoch [3129/20000], Loss: 229.937255859375, Entropy -241.49676513671875, Learning Rate: 0.005\n",
      "Epoch [3130/20000], Loss: 199.22720336914062, Entropy -227.36209106445312, Learning Rate: 0.005\n",
      "Epoch [3131/20000], Loss: 205.53179931640625, Entropy -223.35443115234375, Learning Rate: 0.005\n",
      "Epoch [3132/20000], Loss: 206.48924255371094, Entropy -216.80641174316406, Learning Rate: 0.005\n",
      "Epoch [3133/20000], Loss: 220.58364868164062, Entropy -223.6469268798828, Learning Rate: 0.005\n",
      "Epoch [3134/20000], Loss: 208.0082244873047, Entropy -237.53329467773438, Learning Rate: 0.005\n",
      "Epoch [3135/20000], Loss: 217.56683349609375, Entropy -239.00994873046875, Learning Rate: 0.005\n",
      "Epoch [3136/20000], Loss: 220.15403747558594, Entropy -229.14996337890625, Learning Rate: 0.005\n",
      "Epoch [3137/20000], Loss: 210.7313690185547, Entropy -222.80380249023438, Learning Rate: 0.005\n",
      "Epoch [3138/20000], Loss: 198.25518798828125, Entropy -238.70077514648438, Learning Rate: 0.005\n",
      "Epoch [3139/20000], Loss: 218.81503295898438, Entropy -224.07077026367188, Learning Rate: 0.005\n",
      "Epoch [3140/20000], Loss: 224.35691833496094, Entropy -226.07943725585938, Learning Rate: 0.005\n",
      "Epoch [3141/20000], Loss: 200.73252868652344, Entropy -231.80747985839844, Learning Rate: 0.005\n",
      "Epoch [3142/20000], Loss: 217.4851531982422, Entropy -224.95504760742188, Learning Rate: 0.005\n",
      "Epoch [3143/20000], Loss: 225.37635803222656, Entropy -225.40135192871094, Learning Rate: 0.005\n",
      "Epoch [3144/20000], Loss: 212.19082641601562, Entropy -226.84109497070312, Learning Rate: 0.005\n",
      "Epoch [3145/20000], Loss: 203.84095764160156, Entropy -233.89468383789062, Learning Rate: 0.005\n",
      "Epoch [3146/20000], Loss: 231.5181884765625, Entropy -245.06300354003906, Learning Rate: 0.005\n",
      "Epoch [3147/20000], Loss: 202.53819274902344, Entropy -218.57179260253906, Learning Rate: 0.005\n",
      "Epoch [3148/20000], Loss: 204.8603973388672, Entropy -234.49755859375, Learning Rate: 0.005\n",
      "Epoch [3149/20000], Loss: 209.74986267089844, Entropy -228.08596801757812, Learning Rate: 0.005\n",
      "Epoch [3150/20000], Loss: 233.72674560546875, Entropy -219.3961181640625, Learning Rate: 0.005\n",
      "Epoch [3151/20000], Loss: 225.95846557617188, Entropy -234.83419799804688, Learning Rate: 0.005\n",
      "Epoch [3152/20000], Loss: 204.5187225341797, Entropy -230.05967712402344, Learning Rate: 0.005\n",
      "Epoch [3153/20000], Loss: 256.71539306640625, Entropy -239.6037139892578, Learning Rate: 0.005\n",
      "Epoch [3154/20000], Loss: 250.2447509765625, Entropy -237.69287109375, Learning Rate: 0.005\n",
      "Epoch [3155/20000], Loss: 227.77023315429688, Entropy -236.47471618652344, Learning Rate: 0.005\n",
      "Epoch [3156/20000], Loss: 215.81956481933594, Entropy -233.6208038330078, Learning Rate: 0.005\n",
      "Epoch [3157/20000], Loss: 213.40020751953125, Entropy -234.27212524414062, Learning Rate: 0.005\n",
      "Epoch [3158/20000], Loss: 196.32891845703125, Entropy -219.08932495117188, Learning Rate: 0.005\n",
      "Epoch [3159/20000], Loss: 203.8126678466797, Entropy -227.14926147460938, Learning Rate: 0.005\n",
      "Epoch [3160/20000], Loss: 198.37081909179688, Entropy -229.0914306640625, Learning Rate: 0.005\n",
      "Epoch [3161/20000], Loss: 195.53829956054688, Entropy -227.28501892089844, Learning Rate: 0.005\n",
      "Epoch [3162/20000], Loss: 195.39210510253906, Entropy -232.69241333007812, Learning Rate: 0.005\n",
      "Epoch [3163/20000], Loss: 197.294677734375, Entropy -224.0122528076172, Learning Rate: 0.005\n",
      "Epoch [3164/20000], Loss: 205.6545867919922, Entropy -239.18316650390625, Learning Rate: 0.005\n",
      "Epoch [3165/20000], Loss: 195.93527221679688, Entropy -226.8527374267578, Learning Rate: 0.005\n",
      "Epoch [3166/20000], Loss: 210.70989990234375, Entropy -236.36830139160156, Learning Rate: 0.005\n",
      "Epoch [3167/20000], Loss: 189.92103576660156, Entropy -218.89678955078125, Learning Rate: 0.005\n",
      "Epoch [3168/20000], Loss: 197.3220672607422, Entropy -224.3104248046875, Learning Rate: 0.005\n",
      "Epoch [3169/20000], Loss: 198.7398681640625, Entropy -227.5472412109375, Learning Rate: 0.005\n",
      "Epoch [3170/20000], Loss: 205.5620880126953, Entropy -228.79653930664062, Learning Rate: 0.005\n",
      "Epoch [3171/20000], Loss: 188.74029541015625, Entropy -224.32675170898438, Learning Rate: 0.005\n",
      "Epoch [3172/20000], Loss: 192.25233459472656, Entropy -225.4025421142578, Learning Rate: 0.005\n",
      "Epoch [3173/20000], Loss: 202.80824279785156, Entropy -236.0553741455078, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3174/20000], Loss: 198.00254821777344, Entropy -224.1089324951172, Learning Rate: 0.005\n",
      "Epoch [3175/20000], Loss: 197.91664123535156, Entropy -235.61236572265625, Learning Rate: 0.005\n",
      "Epoch [3176/20000], Loss: 193.92864990234375, Entropy -220.00021362304688, Learning Rate: 0.005\n",
      "Epoch [3177/20000], Loss: 209.07522583007812, Entropy -240.86727905273438, Learning Rate: 0.005\n",
      "Epoch [3178/20000], Loss: 196.38629150390625, Entropy -233.33599853515625, Learning Rate: 0.005\n",
      "Epoch [3179/20000], Loss: 191.2213592529297, Entropy -220.0517578125, Learning Rate: 0.005\n",
      "Epoch [3180/20000], Loss: 210.48654174804688, Entropy -238.2843475341797, Learning Rate: 0.005\n",
      "Epoch [3181/20000], Loss: 206.93878173828125, Entropy -231.53631591796875, Learning Rate: 0.005\n",
      "Epoch [3182/20000], Loss: 202.95339965820312, Entropy -232.1083221435547, Learning Rate: 0.005\n",
      "Epoch [3183/20000], Loss: 200.2845001220703, Entropy -236.67796325683594, Learning Rate: 0.005\n",
      "Epoch [3184/20000], Loss: 197.96470642089844, Entropy -227.0379180908203, Learning Rate: 0.005\n",
      "Epoch [3185/20000], Loss: 222.61898803710938, Entropy -234.51036071777344, Learning Rate: 0.005\n",
      "Epoch [3186/20000], Loss: 216.1241912841797, Entropy -229.62632751464844, Learning Rate: 0.005\n",
      "Epoch [3187/20000], Loss: 201.2961883544922, Entropy -236.2579345703125, Learning Rate: 0.005\n",
      "Epoch [3188/20000], Loss: 190.6211700439453, Entropy -218.43409729003906, Learning Rate: 0.005\n",
      "Epoch [3189/20000], Loss: 197.5768585205078, Entropy -218.24668884277344, Learning Rate: 0.005\n",
      "Epoch [3190/20000], Loss: 201.50796508789062, Entropy -227.5336456298828, Learning Rate: 0.005\n",
      "Epoch [3191/20000], Loss: 185.07264709472656, Entropy -225.21080017089844, Learning Rate: 0.005\n",
      "Epoch [3192/20000], Loss: 193.8271942138672, Entropy -218.948974609375, Learning Rate: 0.005\n",
      "Epoch [3193/20000], Loss: 207.65292358398438, Entropy -237.65765380859375, Learning Rate: 0.005\n",
      "Epoch [3194/20000], Loss: 179.50653076171875, Entropy -203.303466796875, Learning Rate: 0.005\n",
      "Epoch [3195/20000], Loss: 203.16554260253906, Entropy -232.52537536621094, Learning Rate: 0.005\n",
      "Epoch [3196/20000], Loss: 205.42381286621094, Entropy -224.03726196289062, Learning Rate: 0.005\n",
      "Epoch [3197/20000], Loss: 209.2913360595703, Entropy -227.7982635498047, Learning Rate: 0.005\n",
      "Epoch [3198/20000], Loss: 209.43017578125, Entropy -232.1787109375, Learning Rate: 0.005\n",
      "Epoch [3199/20000], Loss: 194.58139038085938, Entropy -229.43106079101562, Learning Rate: 0.005\n",
      "Epoch [3200/20000], Loss: 193.73269653320312, Entropy -226.33676147460938, Learning Rate: 0.005\n",
      "Epoch [3201/20000], Loss: 201.39659118652344, Entropy -226.93450927734375, Learning Rate: 0.005\n",
      "Epoch [3202/20000], Loss: 191.3827667236328, Entropy -221.1785888671875, Learning Rate: 0.005\n",
      "Epoch [3203/20000], Loss: 184.6310577392578, Entropy -217.22325134277344, Learning Rate: 0.005\n",
      "Epoch [3204/20000], Loss: 213.6185302734375, Entropy -229.4663848876953, Learning Rate: 0.005\n",
      "Epoch [3205/20000], Loss: 197.14208984375, Entropy -220.90296936035156, Learning Rate: 0.005\n",
      "Epoch [3206/20000], Loss: 204.36753845214844, Entropy -227.6699676513672, Learning Rate: 0.005\n",
      "Epoch [3207/20000], Loss: 215.5975341796875, Entropy -235.36131286621094, Learning Rate: 0.005\n",
      "Epoch [3208/20000], Loss: 247.3521728515625, Entropy -226.6702880859375, Learning Rate: 0.005\n",
      "Epoch [3209/20000], Loss: 237.1043701171875, Entropy -229.09861755371094, Learning Rate: 0.005\n",
      "Epoch [3210/20000], Loss: 205.9622802734375, Entropy -239.08799743652344, Learning Rate: 0.005\n",
      "Epoch [3211/20000], Loss: 251.24154663085938, Entropy -240.44009399414062, Learning Rate: 0.005\n",
      "Epoch [3212/20000], Loss: 271.23785400390625, Entropy -214.4620361328125, Learning Rate: 0.005\n",
      "Epoch [3213/20000], Loss: 243.62765502929688, Entropy -229.69558715820312, Learning Rate: 0.005\n",
      "Epoch [3214/20000], Loss: 216.6568603515625, Entropy -233.4132537841797, Learning Rate: 0.005\n",
      "Epoch [3215/20000], Loss: 227.0792236328125, Entropy -229.747314453125, Learning Rate: 0.005\n",
      "Epoch [3216/20000], Loss: 232.06405639648438, Entropy -230.2049102783203, Learning Rate: 0.005\n",
      "Epoch [3217/20000], Loss: 230.1393280029297, Entropy -228.72525024414062, Learning Rate: 0.005\n",
      "Epoch [3218/20000], Loss: 219.5648651123047, Entropy -223.65570068359375, Learning Rate: 0.005\n",
      "Epoch [3219/20000], Loss: 200.25350952148438, Entropy -216.11318969726562, Learning Rate: 0.005\n",
      "Epoch [3220/20000], Loss: 226.47015380859375, Entropy -228.9720001220703, Learning Rate: 0.005\n",
      "Epoch [3221/20000], Loss: 201.9497528076172, Entropy -217.69358825683594, Learning Rate: 0.005\n",
      "Epoch [3222/20000], Loss: 195.88397216796875, Entropy -231.97915649414062, Learning Rate: 0.005\n",
      "Epoch [3223/20000], Loss: 241.8336639404297, Entropy -223.33358764648438, Learning Rate: 0.005\n",
      "Epoch [3224/20000], Loss: 240.83668518066406, Entropy -232.06747436523438, Learning Rate: 0.005\n",
      "Epoch [3225/20000], Loss: 191.06039428710938, Entropy -213.37318420410156, Learning Rate: 0.005\n",
      "Epoch [3226/20000], Loss: 223.56326293945312, Entropy -234.7444305419922, Learning Rate: 0.005\n",
      "Epoch [3227/20000], Loss: 255.32376098632812, Entropy -234.83816528320312, Learning Rate: 0.005\n",
      "Epoch [3228/20000], Loss: 223.7176513671875, Entropy -221.53463745117188, Learning Rate: 0.005\n",
      "Epoch [3229/20000], Loss: 214.11663818359375, Entropy -230.89959716796875, Learning Rate: 0.005\n",
      "Epoch [3230/20000], Loss: 243.39541625976562, Entropy -223.99566650390625, Learning Rate: 0.005\n",
      "Epoch [3231/20000], Loss: 234.62391662597656, Entropy -240.8699188232422, Learning Rate: 0.005\n",
      "Epoch [3232/20000], Loss: 194.4541473388672, Entropy -220.0576171875, Learning Rate: 0.005\n",
      "Epoch [3233/20000], Loss: 225.16973876953125, Entropy -241.44874572753906, Learning Rate: 0.005\n",
      "Epoch [3234/20000], Loss: 202.71743774414062, Entropy -223.09341430664062, Learning Rate: 0.005\n",
      "Epoch [3235/20000], Loss: 206.44483947753906, Entropy -222.92214965820312, Learning Rate: 0.005\n",
      "Epoch [3236/20000], Loss: 248.8145294189453, Entropy -235.69985961914062, Learning Rate: 0.005\n",
      "Epoch [3237/20000], Loss: 255.06365966796875, Entropy -220.48004150390625, Learning Rate: 0.005\n",
      "Epoch [3238/20000], Loss: 227.33204650878906, Entropy -236.18408203125, Learning Rate: 0.005\n",
      "Epoch [3239/20000], Loss: 280.89752197265625, Entropy -244.0418701171875, Learning Rate: 0.005\n",
      "Epoch [3240/20000], Loss: 270.7283935546875, Entropy -218.42999267578125, Learning Rate: 0.005\n",
      "Epoch [3241/20000], Loss: 202.0167999267578, Entropy -214.8975830078125, Learning Rate: 0.005\n",
      "Epoch [3242/20000], Loss: 247.82095336914062, Entropy -236.24026489257812, Learning Rate: 0.005\n",
      "Epoch [3243/20000], Loss: 274.9689636230469, Entropy -224.3409423828125, Learning Rate: 0.005\n",
      "Epoch [3244/20000], Loss: 213.79798889160156, Entropy -217.97959899902344, Learning Rate: 0.005\n",
      "Epoch [3245/20000], Loss: 237.124755859375, Entropy -255.80496215820312, Learning Rate: 0.005\n",
      "Epoch [3246/20000], Loss: 261.06988525390625, Entropy -226.72068786621094, Learning Rate: 0.005\n",
      "Epoch [3247/20000], Loss: 203.32444763183594, Entropy -223.7383575439453, Learning Rate: 0.005\n",
      "Epoch [3248/20000], Loss: 207.848388671875, Entropy -215.38494873046875, Learning Rate: 0.005\n",
      "Epoch [3249/20000], Loss: 216.62759399414062, Entropy -231.55702209472656, Learning Rate: 0.005\n",
      "Epoch [3250/20000], Loss: 197.08404541015625, Entropy -218.3526611328125, Learning Rate: 0.005\n",
      "Epoch [3251/20000], Loss: 216.0952911376953, Entropy -225.66754150390625, Learning Rate: 0.005\n",
      "Epoch [3252/20000], Loss: 218.00428771972656, Entropy -224.22299194335938, Learning Rate: 0.005\n",
      "Epoch [3253/20000], Loss: 211.02096557617188, Entropy -230.41629028320312, Learning Rate: 0.005\n",
      "Epoch [3254/20000], Loss: 201.50596618652344, Entropy -233.49362182617188, Learning Rate: 0.005\n",
      "Epoch [3255/20000], Loss: 208.49700927734375, Entropy -231.285400390625, Learning Rate: 0.005\n",
      "Epoch [3256/20000], Loss: 209.5993194580078, Entropy -223.2825469970703, Learning Rate: 0.005\n",
      "Epoch [3257/20000], Loss: 212.08192443847656, Entropy -233.5220489501953, Learning Rate: 0.005\n",
      "Epoch [3258/20000], Loss: 208.10865783691406, Entropy -221.6488037109375, Learning Rate: 0.005\n",
      "Epoch [3259/20000], Loss: 206.44923400878906, Entropy -230.68809509277344, Learning Rate: 0.005\n",
      "Epoch [3260/20000], Loss: 227.99630737304688, Entropy -215.6688232421875, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3261/20000], Loss: 283.811279296875, Entropy -234.53952026367188, Learning Rate: 0.005\n",
      "Epoch [3262/20000], Loss: 254.74990844726562, Entropy -222.224365234375, Learning Rate: 0.005\n",
      "Epoch [3263/20000], Loss: 223.85720825195312, Entropy -244.20980834960938, Learning Rate: 0.005\n",
      "Epoch [3264/20000], Loss: 218.49571228027344, Entropy -228.89373779296875, Learning Rate: 0.005\n",
      "Epoch [3265/20000], Loss: 222.3813018798828, Entropy -229.83575439453125, Learning Rate: 0.005\n",
      "Epoch [3266/20000], Loss: 215.0159912109375, Entropy -236.6479034423828, Learning Rate: 0.005\n",
      "Epoch [3267/20000], Loss: 203.14450073242188, Entropy -226.3008270263672, Learning Rate: 0.005\n",
      "Epoch [3268/20000], Loss: 297.8820495605469, Entropy -231.72207641601562, Learning Rate: 0.005\n",
      "Epoch [3269/20000], Loss: 318.83660888671875, Entropy -229.236572265625, Learning Rate: 0.005\n",
      "Epoch [3270/20000], Loss: 235.94691467285156, Entropy -218.5587615966797, Learning Rate: 0.005\n",
      "Epoch [3271/20000], Loss: 210.503173828125, Entropy -223.04623413085938, Learning Rate: 0.005\n",
      "Epoch [3272/20000], Loss: 308.37640380859375, Entropy -239.6731719970703, Learning Rate: 0.005\n",
      "Epoch [3273/20000], Loss: 254.2691650390625, Entropy -220.06358337402344, Learning Rate: 0.005\n",
      "Epoch [3274/20000], Loss: 231.82252502441406, Entropy -241.59625244140625, Learning Rate: 0.005\n",
      "Epoch [3275/20000], Loss: 297.2012023925781, Entropy -219.914306640625, Learning Rate: 0.005\n",
      "Epoch [3276/20000], Loss: 223.9786376953125, Entropy -218.9192352294922, Learning Rate: 0.005\n",
      "Epoch [3277/20000], Loss: 238.3643798828125, Entropy -223.89532470703125, Learning Rate: 0.005\n",
      "Epoch [3278/20000], Loss: 263.55120849609375, Entropy -226.87869262695312, Learning Rate: 0.005\n",
      "Epoch [3279/20000], Loss: 217.1918182373047, Entropy -224.74920654296875, Learning Rate: 0.005\n",
      "Epoch [3280/20000], Loss: 345.2466125488281, Entropy -231.7113037109375, Learning Rate: 0.005\n",
      "Epoch [3281/20000], Loss: 359.86724853515625, Entropy -237.9141845703125, Learning Rate: 0.005\n",
      "Epoch [3282/20000], Loss: 230.73049926757812, Entropy -225.69888305664062, Learning Rate: 0.005\n",
      "Epoch [3283/20000], Loss: 230.04795837402344, Entropy -227.03807067871094, Learning Rate: 0.005\n",
      "Epoch [3284/20000], Loss: 319.2579345703125, Entropy -234.17808532714844, Learning Rate: 0.005\n",
      "Epoch [3285/20000], Loss: 247.6927032470703, Entropy -225.02635192871094, Learning Rate: 0.005\n",
      "Epoch [3286/20000], Loss: 310.07879638671875, Entropy -227.93409729003906, Learning Rate: 0.005\n",
      "Epoch [3287/20000], Loss: 307.6832580566406, Entropy -230.3812255859375, Learning Rate: 0.005\n",
      "Epoch [3288/20000], Loss: 220.72213745117188, Entropy -222.4639129638672, Learning Rate: 0.005\n",
      "Epoch [3289/20000], Loss: 306.2847900390625, Entropy -218.4281463623047, Learning Rate: 0.005\n",
      "Epoch [3290/20000], Loss: 293.7933349609375, Entropy -238.71307373046875, Learning Rate: 0.005\n",
      "Epoch [3291/20000], Loss: 215.21804809570312, Entropy -233.02488708496094, Learning Rate: 0.005\n",
      "Epoch [3292/20000], Loss: 285.8505859375, Entropy -227.1854248046875, Learning Rate: 0.005\n",
      "Epoch [3293/20000], Loss: 230.9097442626953, Entropy -236.30380249023438, Learning Rate: 0.005\n",
      "Epoch [3294/20000], Loss: 219.2550506591797, Entropy -229.96661376953125, Learning Rate: 0.005\n",
      "Epoch [3295/20000], Loss: 238.87925720214844, Entropy -225.7720947265625, Learning Rate: 0.005\n",
      "Epoch [3296/20000], Loss: 194.6119384765625, Entropy -216.42178344726562, Learning Rate: 0.005\n",
      "Epoch [3297/20000], Loss: 242.98049926757812, Entropy -228.82981872558594, Learning Rate: 0.005\n",
      "Epoch [3298/20000], Loss: 215.8587646484375, Entropy -242.17562866210938, Learning Rate: 0.005\n",
      "Epoch [3299/20000], Loss: 219.87948608398438, Entropy -225.75640869140625, Learning Rate: 0.005\n",
      "Epoch [3300/20000], Loss: 242.14205932617188, Entropy -221.05929565429688, Learning Rate: 0.005\n",
      "Epoch [3301/20000], Loss: 205.60353088378906, Entropy -231.77308654785156, Learning Rate: 0.005\n",
      "Epoch [3302/20000], Loss: 237.33807373046875, Entropy -232.67779541015625, Learning Rate: 0.005\n",
      "Epoch [3303/20000], Loss: 201.07931518554688, Entropy -224.09359741210938, Learning Rate: 0.005\n",
      "Epoch [3304/20000], Loss: 236.10064697265625, Entropy -231.38108825683594, Learning Rate: 0.005\n",
      "Epoch [3305/20000], Loss: 239.08306884765625, Entropy -237.4564208984375, Learning Rate: 0.005\n",
      "Epoch [3306/20000], Loss: 214.4776611328125, Entropy -242.42697143554688, Learning Rate: 0.005\n",
      "Epoch [3307/20000], Loss: 261.4632568359375, Entropy -253.08087158203125, Learning Rate: 0.005\n",
      "Epoch [3308/20000], Loss: 219.15811157226562, Entropy -232.15122985839844, Learning Rate: 0.005\n",
      "Epoch [3309/20000], Loss: 230.06259155273438, Entropy -231.5138397216797, Learning Rate: 0.005\n",
      "Epoch [3310/20000], Loss: 231.12911987304688, Entropy -228.64120483398438, Learning Rate: 0.005\n",
      "Epoch [3311/20000], Loss: 210.39028930664062, Entropy -227.56591796875, Learning Rate: 0.005\n",
      "Epoch [3312/20000], Loss: 246.5620880126953, Entropy -233.89224243164062, Learning Rate: 0.005\n",
      "Epoch [3313/20000], Loss: 211.5676727294922, Entropy -236.8345947265625, Learning Rate: 0.005\n",
      "Epoch [3314/20000], Loss: 243.24896240234375, Entropy -228.25003051757812, Learning Rate: 0.005\n",
      "Epoch [3315/20000], Loss: 201.6425323486328, Entropy -222.7711181640625, Learning Rate: 0.005\n",
      "Epoch [3316/20000], Loss: 224.30615234375, Entropy -238.48910522460938, Learning Rate: 0.005\n",
      "Epoch [3317/20000], Loss: 259.61260986328125, Entropy -235.87933349609375, Learning Rate: 0.005\n",
      "Epoch [3318/20000], Loss: 200.5597686767578, Entropy -227.67816162109375, Learning Rate: 0.005\n",
      "Epoch [3319/20000], Loss: 230.0531768798828, Entropy -229.95059204101562, Learning Rate: 0.005\n",
      "Epoch [3320/20000], Loss: 229.98858642578125, Entropy -230.63107299804688, Learning Rate: 0.005\n",
      "Epoch [3321/20000], Loss: 203.3770751953125, Entropy -228.17333984375, Learning Rate: 0.005\n",
      "Epoch [3322/20000], Loss: 203.69696044921875, Entropy -221.16986083984375, Learning Rate: 0.005\n",
      "Epoch [3323/20000], Loss: 212.32424926757812, Entropy -226.70806884765625, Learning Rate: 0.005\n",
      "Epoch [3324/20000], Loss: 210.142822265625, Entropy -230.97947692871094, Learning Rate: 0.005\n",
      "Epoch [3325/20000], Loss: 203.66326904296875, Entropy -228.77276611328125, Learning Rate: 0.005\n",
      "Epoch [3326/20000], Loss: 206.57266235351562, Entropy -229.1224822998047, Learning Rate: 0.005\n",
      "Epoch [3327/20000], Loss: 188.56674194335938, Entropy -220.1726837158203, Learning Rate: 0.005\n",
      "Epoch [3328/20000], Loss: 200.3227996826172, Entropy -230.46151733398438, Learning Rate: 0.005\n",
      "Epoch [3329/20000], Loss: 195.93338012695312, Entropy -215.68304443359375, Learning Rate: 0.005\n",
      "Epoch [3330/20000], Loss: 198.52407836914062, Entropy -223.98260498046875, Learning Rate: 0.005\n",
      "Epoch [3331/20000], Loss: 201.8526153564453, Entropy -233.75228881835938, Learning Rate: 0.005\n",
      "Epoch [3332/20000], Loss: 199.14321899414062, Entropy -226.659423828125, Learning Rate: 0.005\n",
      "Epoch [3333/20000], Loss: 199.24917602539062, Entropy -231.4894256591797, Learning Rate: 0.005\n",
      "Epoch [3334/20000], Loss: 204.45436096191406, Entropy -243.81700134277344, Learning Rate: 0.005\n",
      "Epoch [3335/20000], Loss: 204.9194793701172, Entropy -223.82479858398438, Learning Rate: 0.005\n",
      "Epoch [3336/20000], Loss: 189.4001922607422, Entropy -224.18800354003906, Learning Rate: 0.005\n",
      "Epoch [3337/20000], Loss: 193.25350952148438, Entropy -223.11976623535156, Learning Rate: 0.005\n",
      "Epoch [3338/20000], Loss: 180.00747680664062, Entropy -216.37167358398438, Learning Rate: 0.005\n",
      "Epoch [3339/20000], Loss: 207.76512145996094, Entropy -236.0341796875, Learning Rate: 0.005\n",
      "Epoch [3340/20000], Loss: 203.31472778320312, Entropy -230.9832305908203, Learning Rate: 0.005\n",
      "Epoch [3341/20000], Loss: 203.25222778320312, Entropy -230.07354736328125, Learning Rate: 0.005\n",
      "Epoch [3342/20000], Loss: 196.53550720214844, Entropy -229.5730743408203, Learning Rate: 0.005\n",
      "Epoch [3343/20000], Loss: 196.7535400390625, Entropy -226.36016845703125, Learning Rate: 0.005\n",
      "Epoch [3344/20000], Loss: 206.19699096679688, Entropy -237.2959747314453, Learning Rate: 0.005\n",
      "Epoch [3345/20000], Loss: 188.23995971679688, Entropy -223.55746459960938, Learning Rate: 0.005\n",
      "Epoch [3346/20000], Loss: 202.6784210205078, Entropy -233.82142639160156, Learning Rate: 0.005\n",
      "Epoch [3347/20000], Loss: 184.04197692871094, Entropy -211.2032012939453, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3348/20000], Loss: 188.1087188720703, Entropy -220.56378173828125, Learning Rate: 0.005\n",
      "Epoch [3349/20000], Loss: 199.05300903320312, Entropy -226.36614990234375, Learning Rate: 0.005\n",
      "Epoch [3350/20000], Loss: 203.26039123535156, Entropy -237.3026885986328, Learning Rate: 0.005\n",
      "Epoch [3351/20000], Loss: 200.1826171875, Entropy -243.07632446289062, Learning Rate: 0.005\n",
      "Epoch [3352/20000], Loss: 192.5716552734375, Entropy -222.64114379882812, Learning Rate: 0.005\n",
      "Epoch [3353/20000], Loss: 190.80722045898438, Entropy -225.78140258789062, Learning Rate: 0.005\n",
      "Epoch [3354/20000], Loss: 197.62257385253906, Entropy -240.31878662109375, Learning Rate: 0.005\n",
      "Epoch [3355/20000], Loss: 207.55992126464844, Entropy -243.95811462402344, Learning Rate: 0.005\n",
      "Epoch [3356/20000], Loss: 198.8963165283203, Entropy -242.28262329101562, Learning Rate: 0.005\n",
      "Epoch [3357/20000], Loss: 190.60557556152344, Entropy -231.81973266601562, Learning Rate: 0.005\n",
      "Epoch [3358/20000], Loss: 189.8683319091797, Entropy -225.4279022216797, Learning Rate: 0.005\n",
      "Epoch [3359/20000], Loss: 193.31536865234375, Entropy -232.86399841308594, Learning Rate: 0.005\n",
      "Epoch [3360/20000], Loss: 195.08206176757812, Entropy -230.49960327148438, Learning Rate: 0.005\n",
      "Epoch [3361/20000], Loss: 194.2472381591797, Entropy -231.438720703125, Learning Rate: 0.005\n",
      "Epoch [3362/20000], Loss: 194.7693328857422, Entropy -222.593994140625, Learning Rate: 0.005\n",
      "Epoch [3363/20000], Loss: 188.87205505371094, Entropy -232.53378295898438, Learning Rate: 0.005\n",
      "Epoch [3364/20000], Loss: 193.77615356445312, Entropy -225.69607543945312, Learning Rate: 0.005\n",
      "Epoch [3365/20000], Loss: 193.55722045898438, Entropy -235.21414184570312, Learning Rate: 0.005\n",
      "Epoch [3366/20000], Loss: 190.29930114746094, Entropy -230.73269653320312, Learning Rate: 0.005\n",
      "Epoch [3367/20000], Loss: 192.08116149902344, Entropy -227.0404510498047, Learning Rate: 0.005\n",
      "Epoch [3368/20000], Loss: 189.88360595703125, Entropy -226.9071502685547, Learning Rate: 0.005\n",
      "Epoch [3369/20000], Loss: 185.02944946289062, Entropy -221.68975830078125, Learning Rate: 0.005\n",
      "Epoch [3370/20000], Loss: 191.46632385253906, Entropy -227.91952514648438, Learning Rate: 0.005\n",
      "Epoch [3371/20000], Loss: 186.15585327148438, Entropy -220.51585388183594, Learning Rate: 0.005\n",
      "Epoch [3372/20000], Loss: 184.74522399902344, Entropy -218.74366760253906, Learning Rate: 0.005\n",
      "Epoch [3373/20000], Loss: 195.116455078125, Entropy -226.4257354736328, Learning Rate: 0.005\n",
      "Epoch [3374/20000], Loss: 192.61795043945312, Entropy -229.02291870117188, Learning Rate: 0.005\n",
      "Epoch [3375/20000], Loss: 182.37986755371094, Entropy -227.2747039794922, Learning Rate: 0.005\n",
      "Epoch [3376/20000], Loss: 198.14474487304688, Entropy -234.65927124023438, Learning Rate: 0.005\n",
      "Epoch [3377/20000], Loss: 186.6344757080078, Entropy -217.46099853515625, Learning Rate: 0.005\n",
      "Epoch [3378/20000], Loss: 184.61195373535156, Entropy -222.02545166015625, Learning Rate: 0.005\n",
      "Epoch [3379/20000], Loss: 197.594482421875, Entropy -234.05322265625, Learning Rate: 0.005\n",
      "Epoch [3380/20000], Loss: 188.30877685546875, Entropy -229.037353515625, Learning Rate: 0.005\n",
      "Epoch [3381/20000], Loss: 187.77210998535156, Entropy -227.1719512939453, Learning Rate: 0.005\n",
      "Epoch [3382/20000], Loss: 187.15805053710938, Entropy -223.99903869628906, Learning Rate: 0.005\n",
      "Epoch [3383/20000], Loss: 202.35147094726562, Entropy -243.17877197265625, Learning Rate: 0.005\n",
      "Epoch [3384/20000], Loss: 186.5347900390625, Entropy -226.93997192382812, Learning Rate: 0.005\n",
      "Epoch [3385/20000], Loss: 184.12307739257812, Entropy -226.418701171875, Learning Rate: 0.005\n",
      "Epoch [3386/20000], Loss: 198.30433654785156, Entropy -229.69863891601562, Learning Rate: 0.005\n",
      "Epoch [3387/20000], Loss: 184.67201232910156, Entropy -226.12310791015625, Learning Rate: 0.005\n",
      "Epoch [3388/20000], Loss: 183.50567626953125, Entropy -222.99014282226562, Learning Rate: 0.005\n",
      "Epoch [3389/20000], Loss: 184.3560028076172, Entropy -227.71649169921875, Learning Rate: 0.005\n",
      "Epoch [3390/20000], Loss: 182.32275390625, Entropy -222.64845275878906, Learning Rate: 0.005\n",
      "Epoch [3391/20000], Loss: 199.95858764648438, Entropy -229.78219604492188, Learning Rate: 0.005\n",
      "Epoch [3392/20000], Loss: 189.2837371826172, Entropy -230.2554931640625, Learning Rate: 0.005\n",
      "Epoch [3393/20000], Loss: 185.4747772216797, Entropy -227.08294677734375, Learning Rate: 0.005\n",
      "Epoch [3394/20000], Loss: 190.94491577148438, Entropy -227.40200805664062, Learning Rate: 0.005\n",
      "Epoch [3395/20000], Loss: 181.14894104003906, Entropy -219.54046630859375, Learning Rate: 0.005\n",
      "Epoch [3396/20000], Loss: 190.4874267578125, Entropy -233.83566284179688, Learning Rate: 0.0025\n",
      "Epoch [3397/20000], Loss: 186.64707946777344, Entropy -227.47134399414062, Learning Rate: 0.0025\n",
      "Epoch [3398/20000], Loss: 190.1323699951172, Entropy -231.02911376953125, Learning Rate: 0.0025\n",
      "Epoch [3399/20000], Loss: 189.1922149658203, Entropy -225.12515258789062, Learning Rate: 0.0025\n",
      "Epoch [3400/20000], Loss: 188.52487182617188, Entropy -227.01707458496094, Learning Rate: 0.0025\n",
      "Epoch [3401/20000], Loss: 183.62913513183594, Entropy -220.36997985839844, Learning Rate: 0.0025\n",
      "Epoch [3402/20000], Loss: 186.9989013671875, Entropy -230.44717407226562, Learning Rate: 0.0025\n",
      "Epoch [3403/20000], Loss: 198.63816833496094, Entropy -236.934326171875, Learning Rate: 0.0025\n",
      "Epoch [3404/20000], Loss: 177.6870574951172, Entropy -221.19097900390625, Learning Rate: 0.0025\n",
      "Epoch [3405/20000], Loss: 180.37545776367188, Entropy -225.29383850097656, Learning Rate: 0.0025\n",
      "Epoch [3406/20000], Loss: 176.20216369628906, Entropy -210.1840057373047, Learning Rate: 0.0025\n",
      "Epoch [3407/20000], Loss: 187.0261688232422, Entropy -227.11099243164062, Learning Rate: 0.0025\n",
      "Epoch [3408/20000], Loss: 187.2584991455078, Entropy -226.4973907470703, Learning Rate: 0.0025\n",
      "Epoch [3409/20000], Loss: 180.30967712402344, Entropy -216.23272705078125, Learning Rate: 0.0025\n",
      "Epoch [3410/20000], Loss: 185.4866180419922, Entropy -225.04330444335938, Learning Rate: 0.0025\n",
      "Epoch [3411/20000], Loss: 186.88499450683594, Entropy -224.19964599609375, Learning Rate: 0.0025\n",
      "Epoch [3412/20000], Loss: 187.11151123046875, Entropy -230.39181518554688, Learning Rate: 0.0025\n",
      "Epoch [3413/20000], Loss: 191.1874237060547, Entropy -231.68907165527344, Learning Rate: 0.0025\n",
      "Epoch [3414/20000], Loss: 172.53311157226562, Entropy -213.63235473632812, Learning Rate: 0.0025\n",
      "Epoch [3415/20000], Loss: 187.2064208984375, Entropy -230.271484375, Learning Rate: 0.0025\n",
      "Epoch [3416/20000], Loss: 181.2484588623047, Entropy -223.43223571777344, Learning Rate: 0.0025\n",
      "Epoch [3417/20000], Loss: 180.3694610595703, Entropy -227.57730102539062, Learning Rate: 0.0025\n",
      "Epoch [3418/20000], Loss: 186.3624725341797, Entropy -229.73095703125, Learning Rate: 0.0025\n",
      "Epoch [3419/20000], Loss: 186.24566650390625, Entropy -226.62533569335938, Learning Rate: 0.0025\n",
      "Epoch [3420/20000], Loss: 181.2158660888672, Entropy -226.70616149902344, Learning Rate: 0.0025\n",
      "Epoch [3421/20000], Loss: 189.435302734375, Entropy -232.7918701171875, Learning Rate: 0.0025\n",
      "Epoch [3422/20000], Loss: 178.36692810058594, Entropy -214.5897216796875, Learning Rate: 0.0025\n",
      "Epoch [3423/20000], Loss: 179.84320068359375, Entropy -224.31634521484375, Learning Rate: 0.0025\n",
      "Epoch [3424/20000], Loss: 188.9737548828125, Entropy -226.45819091796875, Learning Rate: 0.0025\n",
      "Epoch [3425/20000], Loss: 190.66195678710938, Entropy -231.63827514648438, Learning Rate: 0.0025\n",
      "Epoch [3426/20000], Loss: 182.0920867919922, Entropy -226.42184448242188, Learning Rate: 0.0025\n",
      "Epoch [3427/20000], Loss: 192.36390686035156, Entropy -233.94650268554688, Learning Rate: 0.0025\n",
      "Epoch [3428/20000], Loss: 188.0395965576172, Entropy -226.65447998046875, Learning Rate: 0.0025\n",
      "Epoch [3429/20000], Loss: 164.69204711914062, Entropy -203.93426513671875, Learning Rate: 0.0025\n",
      "Epoch [3430/20000], Loss: 199.7663116455078, Entropy -237.81076049804688, Learning Rate: 0.0025\n",
      "Epoch [3431/20000], Loss: 180.9332275390625, Entropy -221.09671020507812, Learning Rate: 0.0025\n",
      "Epoch [3432/20000], Loss: 187.24803161621094, Entropy -224.6834259033203, Learning Rate: 0.0025\n",
      "Epoch [3433/20000], Loss: 191.16836547851562, Entropy -237.26564025878906, Learning Rate: 0.0025\n",
      "Epoch [3434/20000], Loss: 179.8170166015625, Entropy -219.74874877929688, Learning Rate: 0.0025\n",
      "Epoch [3435/20000], Loss: 184.7928009033203, Entropy -223.2620849609375, Learning Rate: 0.0025\n",
      "Epoch [3436/20000], Loss: 184.87611389160156, Entropy -221.6947021484375, Learning Rate: 0.0025\n",
      "Epoch [3437/20000], Loss: 179.7529296875, Entropy -219.2194061279297, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3438/20000], Loss: 180.03118896484375, Entropy -210.66888427734375, Learning Rate: 0.0025\n",
      "Epoch [3439/20000], Loss: 187.32986450195312, Entropy -226.44064331054688, Learning Rate: 0.0025\n",
      "Epoch [3440/20000], Loss: 177.48219299316406, Entropy -217.1600341796875, Learning Rate: 0.0025\n",
      "Epoch [3441/20000], Loss: 191.57669067382812, Entropy -234.915771484375, Learning Rate: 0.0025\n",
      "Epoch [3442/20000], Loss: 183.02549743652344, Entropy -227.8255615234375, Learning Rate: 0.0025\n",
      "Epoch [3443/20000], Loss: 192.564453125, Entropy -228.1666259765625, Learning Rate: 0.0025\n",
      "Epoch [3444/20000], Loss: 196.4944610595703, Entropy -233.38687133789062, Learning Rate: 0.0025\n",
      "Epoch [3445/20000], Loss: 189.39051818847656, Entropy -222.6382293701172, Learning Rate: 0.0025\n",
      "Epoch [3446/20000], Loss: 177.49806213378906, Entropy -217.9709930419922, Learning Rate: 0.0025\n",
      "Epoch [3447/20000], Loss: 191.3656005859375, Entropy -234.27493286132812, Learning Rate: 0.0025\n",
      "Epoch [3448/20000], Loss: 184.57080078125, Entropy -218.44317626953125, Learning Rate: 0.0025\n",
      "Epoch [3449/20000], Loss: 179.04566955566406, Entropy -214.96861267089844, Learning Rate: 0.0025\n",
      "Epoch [3450/20000], Loss: 184.48583984375, Entropy -226.25762939453125, Learning Rate: 0.0025\n",
      "Epoch [3451/20000], Loss: 179.88748168945312, Entropy -221.28082275390625, Learning Rate: 0.0025\n",
      "Epoch [3452/20000], Loss: 181.50640869140625, Entropy -224.59376525878906, Learning Rate: 0.0025\n",
      "Epoch [3453/20000], Loss: 188.33285522460938, Entropy -229.867919921875, Learning Rate: 0.0025\n",
      "Epoch [3454/20000], Loss: 183.91928100585938, Entropy -222.02374267578125, Learning Rate: 0.0025\n",
      "Epoch [3455/20000], Loss: 174.07142639160156, Entropy -207.02056884765625, Learning Rate: 0.0025\n",
      "Epoch [3456/20000], Loss: 190.56948852539062, Entropy -222.0277099609375, Learning Rate: 0.0025\n",
      "Epoch [3457/20000], Loss: 191.763671875, Entropy -231.10415649414062, Learning Rate: 0.0025\n",
      "Epoch [3458/20000], Loss: 189.1173858642578, Entropy -228.29550170898438, Learning Rate: 0.0025\n",
      "Epoch [3459/20000], Loss: 188.34161376953125, Entropy -225.03567504882812, Learning Rate: 0.0025\n",
      "Epoch [3460/20000], Loss: 181.10650634765625, Entropy -219.38673400878906, Learning Rate: 0.0025\n",
      "Epoch [3461/20000], Loss: 188.7876739501953, Entropy -229.4395751953125, Learning Rate: 0.0025\n",
      "Epoch [3462/20000], Loss: 186.4017791748047, Entropy -230.74557495117188, Learning Rate: 0.0025\n",
      "Epoch [3463/20000], Loss: 178.71078491210938, Entropy -215.71893310546875, Learning Rate: 0.0025\n",
      "Epoch [3464/20000], Loss: 181.7698516845703, Entropy -220.43246459960938, Learning Rate: 0.0025\n",
      "Epoch [3465/20000], Loss: 180.43606567382812, Entropy -218.3284912109375, Learning Rate: 0.0025\n",
      "Epoch [3466/20000], Loss: 180.76913452148438, Entropy -222.83447265625, Learning Rate: 0.0025\n",
      "Epoch [3467/20000], Loss: 194.59202575683594, Entropy -239.836669921875, Learning Rate: 0.0025\n",
      "Epoch [3468/20000], Loss: 174.48513793945312, Entropy -217.43263244628906, Learning Rate: 0.0025\n",
      "Epoch [3469/20000], Loss: 189.8332977294922, Entropy -229.98593139648438, Learning Rate: 0.0025\n",
      "Epoch [3470/20000], Loss: 180.43589782714844, Entropy -219.68507385253906, Learning Rate: 0.0025\n",
      "Epoch [3471/20000], Loss: 189.0647735595703, Entropy -226.64398193359375, Learning Rate: 0.0025\n",
      "Epoch [3472/20000], Loss: 180.37069702148438, Entropy -220.75497436523438, Learning Rate: 0.0025\n",
      "Epoch [3473/20000], Loss: 189.5391845703125, Entropy -230.70785522460938, Learning Rate: 0.0025\n",
      "Epoch [3474/20000], Loss: 192.94448852539062, Entropy -236.4012908935547, Learning Rate: 0.0025\n",
      "Epoch [3475/20000], Loss: 191.36404418945312, Entropy -231.82122802734375, Learning Rate: 0.0025\n",
      "Epoch [3476/20000], Loss: 189.76272583007812, Entropy -235.511474609375, Learning Rate: 0.0025\n",
      "Epoch [3477/20000], Loss: 183.713623046875, Entropy -223.88392639160156, Learning Rate: 0.0025\n",
      "Epoch [3478/20000], Loss: 188.25210571289062, Entropy -227.10604858398438, Learning Rate: 0.0025\n",
      "Epoch [3479/20000], Loss: 188.71839904785156, Entropy -227.88613891601562, Learning Rate: 0.0025\n",
      "Epoch [3480/20000], Loss: 184.987548828125, Entropy -223.48562622070312, Learning Rate: 0.0025\n",
      "Epoch [3481/20000], Loss: 183.59091186523438, Entropy -220.3570556640625, Learning Rate: 0.0025\n",
      "Epoch [3482/20000], Loss: 184.20050048828125, Entropy -223.5707550048828, Learning Rate: 0.0025\n",
      "Epoch [3483/20000], Loss: 188.56109619140625, Entropy -228.46331787109375, Learning Rate: 0.0025\n",
      "Epoch [3484/20000], Loss: 180.8975830078125, Entropy -215.72817993164062, Learning Rate: 0.0025\n",
      "Epoch [3485/20000], Loss: 186.85128784179688, Entropy -224.22560119628906, Learning Rate: 0.0025\n",
      "Epoch [3486/20000], Loss: 182.49012756347656, Entropy -226.29843139648438, Learning Rate: 0.0025\n",
      "Epoch [3487/20000], Loss: 183.52493286132812, Entropy -225.70826721191406, Learning Rate: 0.0025\n",
      "Epoch [3488/20000], Loss: 188.74192810058594, Entropy -233.6583251953125, Learning Rate: 0.0025\n",
      "Epoch [3489/20000], Loss: 184.49447631835938, Entropy -220.83078002929688, Learning Rate: 0.0025\n",
      "Epoch [3490/20000], Loss: 169.70880126953125, Entropy -207.49449157714844, Learning Rate: 0.0025\n",
      "Epoch [3491/20000], Loss: 175.1505126953125, Entropy -215.9351806640625, Learning Rate: 0.0025\n",
      "Epoch [3492/20000], Loss: 187.56283569335938, Entropy -225.6508331298828, Learning Rate: 0.0025\n",
      "Epoch [3493/20000], Loss: 188.39305114746094, Entropy -225.51358032226562, Learning Rate: 0.0025\n",
      "Epoch [3494/20000], Loss: 175.87216186523438, Entropy -214.99058532714844, Learning Rate: 0.0025\n",
      "Epoch [3495/20000], Loss: 175.85391235351562, Entropy -218.2603759765625, Learning Rate: 0.0025\n",
      "Epoch [3496/20000], Loss: 185.87460327148438, Entropy -222.52822875976562, Learning Rate: 0.0025\n",
      "Epoch [3497/20000], Loss: 195.74050903320312, Entropy -234.56161499023438, Learning Rate: 0.0025\n",
      "Epoch [3498/20000], Loss: 182.1177520751953, Entropy -224.41433715820312, Learning Rate: 0.0025\n",
      "Epoch [3499/20000], Loss: 188.81507873535156, Entropy -226.3260955810547, Learning Rate: 0.0025\n",
      "Epoch [3500/20000], Loss: 195.86643981933594, Entropy -229.71107482910156, Learning Rate: 0.0025\n",
      "Epoch [3501/20000], Loss: 186.2279052734375, Entropy -224.92213439941406, Learning Rate: 0.0025\n",
      "Epoch [3502/20000], Loss: 181.31375122070312, Entropy -219.10748291015625, Learning Rate: 0.0025\n",
      "Epoch [3503/20000], Loss: 181.2882843017578, Entropy -223.6507568359375, Learning Rate: 0.0025\n",
      "Epoch [3504/20000], Loss: 180.6920623779297, Entropy -221.0852813720703, Learning Rate: 0.0025\n",
      "Epoch [3505/20000], Loss: 180.85891723632812, Entropy -217.17864990234375, Learning Rate: 0.0025\n",
      "Epoch [3506/20000], Loss: 188.508056640625, Entropy -225.37461853027344, Learning Rate: 0.0025\n",
      "Epoch [3507/20000], Loss: 180.60604858398438, Entropy -214.6895751953125, Learning Rate: 0.0025\n",
      "Epoch [3508/20000], Loss: 184.33799743652344, Entropy -224.18753051757812, Learning Rate: 0.0025\n",
      "Epoch [3509/20000], Loss: 181.53787231445312, Entropy -212.53726196289062, Learning Rate: 0.0025\n",
      "Epoch [3510/20000], Loss: 188.66961669921875, Entropy -223.88014221191406, Learning Rate: 0.0025\n",
      "Epoch [3511/20000], Loss: 188.22357177734375, Entropy -225.30508422851562, Learning Rate: 0.0025\n",
      "Epoch [3512/20000], Loss: 193.88784790039062, Entropy -239.07887268066406, Learning Rate: 0.0025\n",
      "Epoch [3513/20000], Loss: 190.84527587890625, Entropy -226.91644287109375, Learning Rate: 0.0025\n",
      "Epoch [3514/20000], Loss: 177.56594848632812, Entropy -217.5010986328125, Learning Rate: 0.0025\n",
      "Epoch [3515/20000], Loss: 186.9274444580078, Entropy -229.7105255126953, Learning Rate: 0.0025\n",
      "Epoch [3516/20000], Loss: 182.7373809814453, Entropy -225.9739990234375, Learning Rate: 0.0025\n",
      "Epoch [3517/20000], Loss: 187.14157104492188, Entropy -224.6893310546875, Learning Rate: 0.0025\n",
      "Epoch [3518/20000], Loss: 180.7028350830078, Entropy -220.75970458984375, Learning Rate: 0.0025\n",
      "Epoch [3519/20000], Loss: 180.83811950683594, Entropy -222.83815002441406, Learning Rate: 0.0025\n",
      "Epoch [3520/20000], Loss: 185.04910278320312, Entropy -222.824951171875, Learning Rate: 0.0025\n",
      "Epoch [3521/20000], Loss: 199.12391662597656, Entropy -237.235107421875, Learning Rate: 0.0025\n",
      "Epoch [3522/20000], Loss: 183.29124450683594, Entropy -218.58116149902344, Learning Rate: 0.0025\n",
      "Epoch [3523/20000], Loss: 186.5028533935547, Entropy -227.4776153564453, Learning Rate: 0.0025\n",
      "Epoch [3524/20000], Loss: 196.02359008789062, Entropy -233.32542419433594, Learning Rate: 0.0025\n",
      "Epoch [3525/20000], Loss: 183.8950958251953, Entropy -217.63592529296875, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3526/20000], Loss: 185.9245147705078, Entropy -221.80140686035156, Learning Rate: 0.0025\n",
      "Epoch [3527/20000], Loss: 187.72979736328125, Entropy -224.12100219726562, Learning Rate: 0.0025\n",
      "Epoch [3528/20000], Loss: 179.37948608398438, Entropy -217.32415771484375, Learning Rate: 0.0025\n",
      "Epoch [3529/20000], Loss: 191.071533203125, Entropy -226.18426513671875, Learning Rate: 0.0025\n",
      "Epoch [3530/20000], Loss: 183.76004028320312, Entropy -221.2775115966797, Learning Rate: 0.0025\n",
      "Epoch [3531/20000], Loss: 173.99400329589844, Entropy -211.13656616210938, Learning Rate: 0.0025\n",
      "Epoch [3532/20000], Loss: 181.09576416015625, Entropy -224.04295349121094, Learning Rate: 0.0025\n",
      "Epoch [3533/20000], Loss: 182.442138671875, Entropy -223.09878540039062, Learning Rate: 0.0025\n",
      "Epoch [3534/20000], Loss: 182.5247344970703, Entropy -225.55894470214844, Learning Rate: 0.0025\n",
      "Epoch [3535/20000], Loss: 173.05703735351562, Entropy -214.81814575195312, Learning Rate: 0.0025\n",
      "Epoch [3536/20000], Loss: 181.11715698242188, Entropy -220.24160766601562, Learning Rate: 0.0025\n",
      "Epoch [3537/20000], Loss: 176.6183319091797, Entropy -213.06719970703125, Learning Rate: 0.0025\n",
      "Epoch [3538/20000], Loss: 185.69386291503906, Entropy -220.80319213867188, Learning Rate: 0.0025\n",
      "Epoch [3539/20000], Loss: 186.1670379638672, Entropy -229.23757934570312, Learning Rate: 0.0025\n",
      "Epoch [3540/20000], Loss: 180.87994384765625, Entropy -220.00648498535156, Learning Rate: 0.0025\n",
      "Epoch [3541/20000], Loss: 178.57994079589844, Entropy -221.99838256835938, Learning Rate: 0.0025\n",
      "Epoch [3542/20000], Loss: 195.715576171875, Entropy -237.13050842285156, Learning Rate: 0.0025\n",
      "Epoch [3543/20000], Loss: 177.49880981445312, Entropy -216.24301147460938, Learning Rate: 0.0025\n",
      "Epoch [3544/20000], Loss: 180.88075256347656, Entropy -219.07846069335938, Learning Rate: 0.0025\n",
      "Epoch [3545/20000], Loss: 173.60260009765625, Entropy -212.50811767578125, Learning Rate: 0.0025\n",
      "Epoch [3546/20000], Loss: 170.1977081298828, Entropy -212.98065185546875, Learning Rate: 0.0025\n",
      "Epoch [3547/20000], Loss: 179.17587280273438, Entropy -222.05206298828125, Learning Rate: 0.0025\n",
      "Epoch [3548/20000], Loss: 184.0794677734375, Entropy -226.74600219726562, Learning Rate: 0.0025\n",
      "Epoch [3549/20000], Loss: 184.68592834472656, Entropy -217.875, Learning Rate: 0.0025\n",
      "Epoch [3550/20000], Loss: 178.46847534179688, Entropy -213.95436096191406, Learning Rate: 0.0025\n",
      "Epoch [3551/20000], Loss: 178.93930053710938, Entropy -214.46539306640625, Learning Rate: 0.0025\n",
      "Epoch [3552/20000], Loss: 181.6370391845703, Entropy -216.4152374267578, Learning Rate: 0.0025\n",
      "Epoch [3553/20000], Loss: 178.83705139160156, Entropy -215.52011108398438, Learning Rate: 0.0025\n",
      "Epoch [3554/20000], Loss: 177.34727478027344, Entropy -216.4252166748047, Learning Rate: 0.0025\n",
      "Epoch [3555/20000], Loss: 185.01925659179688, Entropy -218.60951232910156, Learning Rate: 0.0025\n",
      "Epoch [3556/20000], Loss: 189.1596221923828, Entropy -224.779296875, Learning Rate: 0.0025\n",
      "Epoch [3557/20000], Loss: 180.1088409423828, Entropy -221.5363006591797, Learning Rate: 0.0025\n",
      "Epoch [3558/20000], Loss: 176.37625122070312, Entropy -217.60528564453125, Learning Rate: 0.0025\n",
      "Epoch [3559/20000], Loss: 186.32460021972656, Entropy -226.08929443359375, Learning Rate: 0.0025\n",
      "Epoch [3560/20000], Loss: 190.38055419921875, Entropy -226.73912048339844, Learning Rate: 0.0025\n",
      "Epoch [3561/20000], Loss: 191.9425506591797, Entropy -235.77545166015625, Learning Rate: 0.0025\n",
      "Epoch [3562/20000], Loss: 185.3418426513672, Entropy -221.96388244628906, Learning Rate: 0.0025\n",
      "Epoch [3563/20000], Loss: 175.42367553710938, Entropy -209.91880798339844, Learning Rate: 0.0025\n",
      "Epoch [3564/20000], Loss: 175.17745971679688, Entropy -220.85958862304688, Learning Rate: 0.0025\n",
      "Epoch [3565/20000], Loss: 185.09759521484375, Entropy -218.08819580078125, Learning Rate: 0.0025\n",
      "Epoch [3566/20000], Loss: 168.34458923339844, Entropy -205.19192504882812, Learning Rate: 0.0025\n",
      "Epoch [3567/20000], Loss: 184.04763793945312, Entropy -219.48358154296875, Learning Rate: 0.0025\n",
      "Epoch [3568/20000], Loss: 170.5890350341797, Entropy -207.67013549804688, Learning Rate: 0.0025\n",
      "Epoch [3569/20000], Loss: 193.7664794921875, Entropy -231.9020538330078, Learning Rate: 0.0025\n",
      "Epoch [3570/20000], Loss: 180.1016387939453, Entropy -214.65512084960938, Learning Rate: 0.0025\n",
      "Epoch [3571/20000], Loss: 172.9278106689453, Entropy -219.275146484375, Learning Rate: 0.0025\n",
      "Epoch [3572/20000], Loss: 179.34213256835938, Entropy -217.19573974609375, Learning Rate: 0.0025\n",
      "Epoch [3573/20000], Loss: 171.458984375, Entropy -208.26315307617188, Learning Rate: 0.0025\n",
      "Epoch [3574/20000], Loss: 169.63980102539062, Entropy -201.62123107910156, Learning Rate: 0.0025\n",
      "Epoch [3575/20000], Loss: 172.1171112060547, Entropy -209.16763305664062, Learning Rate: 0.0025\n",
      "Epoch [3576/20000], Loss: 169.1508331298828, Entropy -209.02845764160156, Learning Rate: 0.0025\n",
      "Epoch [3577/20000], Loss: 177.53749084472656, Entropy -213.19598388671875, Learning Rate: 0.0025\n",
      "Epoch [3578/20000], Loss: 167.4052276611328, Entropy -208.70179748535156, Learning Rate: 0.0025\n",
      "Epoch [3579/20000], Loss: 180.8748779296875, Entropy -227.4844207763672, Learning Rate: 0.0025\n",
      "Epoch [3580/20000], Loss: 182.25839233398438, Entropy -219.7738037109375, Learning Rate: 0.0025\n",
      "Epoch [3581/20000], Loss: 188.54827880859375, Entropy -230.91893005371094, Learning Rate: 0.0025\n",
      "Epoch [3582/20000], Loss: 185.4923858642578, Entropy -226.97384643554688, Learning Rate: 0.0025\n",
      "Epoch [3583/20000], Loss: 178.3834686279297, Entropy -220.38226318359375, Learning Rate: 0.0025\n",
      "Epoch [3584/20000], Loss: 176.44467163085938, Entropy -211.3701629638672, Learning Rate: 0.0025\n",
      "Epoch [3585/20000], Loss: 183.5679931640625, Entropy -226.00473022460938, Learning Rate: 0.0025\n",
      "Epoch [3586/20000], Loss: 182.51773071289062, Entropy -225.54034423828125, Learning Rate: 0.0025\n",
      "Epoch [3587/20000], Loss: 186.60076904296875, Entropy -235.9384765625, Learning Rate: 0.0025\n",
      "Epoch [3588/20000], Loss: 177.21075439453125, Entropy -214.51168823242188, Learning Rate: 0.0025\n",
      "Epoch [3589/20000], Loss: 182.80917358398438, Entropy -216.43077087402344, Learning Rate: 0.0025\n",
      "Epoch [3590/20000], Loss: 182.9397735595703, Entropy -219.60296630859375, Learning Rate: 0.0025\n",
      "Epoch [3591/20000], Loss: 172.43673706054688, Entropy -217.42398071289062, Learning Rate: 0.0025\n",
      "Epoch [3592/20000], Loss: 169.90692138671875, Entropy -210.13694763183594, Learning Rate: 0.0025\n",
      "Epoch [3593/20000], Loss: 181.49378967285156, Entropy -219.53355407714844, Learning Rate: 0.0025\n",
      "Epoch [3594/20000], Loss: 186.48973083496094, Entropy -225.8814239501953, Learning Rate: 0.0025\n",
      "Epoch [3595/20000], Loss: 171.80661010742188, Entropy -214.11293029785156, Learning Rate: 0.0025\n",
      "Epoch [3596/20000], Loss: 178.359619140625, Entropy -216.79815673828125, Learning Rate: 0.0025\n",
      "Epoch [3597/20000], Loss: 179.38778686523438, Entropy -219.6066436767578, Learning Rate: 0.0025\n",
      "Epoch [3598/20000], Loss: 178.6002960205078, Entropy -222.92210388183594, Learning Rate: 0.0025\n",
      "Epoch [3599/20000], Loss: 177.6509246826172, Entropy -210.69180297851562, Learning Rate: 0.0025\n",
      "Epoch [3600/20000], Loss: 195.8690185546875, Entropy -228.42001342773438, Learning Rate: 0.0025\n",
      "Epoch [3601/20000], Loss: 172.02841186523438, Entropy -212.7936248779297, Learning Rate: 0.0025\n",
      "Epoch [3602/20000], Loss: 181.931640625, Entropy -221.4504852294922, Learning Rate: 0.0025\n",
      "Epoch [3603/20000], Loss: 181.6811065673828, Entropy -219.208984375, Learning Rate: 0.0025\n",
      "Epoch [3604/20000], Loss: 177.67959594726562, Entropy -219.66839599609375, Learning Rate: 0.0025\n",
      "Epoch [3605/20000], Loss: 172.75448608398438, Entropy -212.54107666015625, Learning Rate: 0.0025\n",
      "Epoch [3606/20000], Loss: 191.99835205078125, Entropy -231.16787719726562, Learning Rate: 0.0025\n",
      "Epoch [3607/20000], Loss: 178.19183349609375, Entropy -211.8193359375, Learning Rate: 0.0025\n",
      "Epoch [3608/20000], Loss: 172.4764404296875, Entropy -205.38412475585938, Learning Rate: 0.0025\n",
      "Epoch [3609/20000], Loss: 186.9246826171875, Entropy -217.33152770996094, Learning Rate: 0.0025\n",
      "Epoch [3610/20000], Loss: 187.744140625, Entropy -229.47824096679688, Learning Rate: 0.0025\n",
      "Epoch [3611/20000], Loss: 177.4036865234375, Entropy -214.2095947265625, Learning Rate: 0.0025\n",
      "Epoch [3612/20000], Loss: 169.32505798339844, Entropy -206.8887481689453, Learning Rate: 0.0025\n",
      "Epoch [3613/20000], Loss: 189.33692932128906, Entropy -228.84848022460938, Learning Rate: 0.0025\n",
      "Epoch [3614/20000], Loss: 180.53079223632812, Entropy -221.88064575195312, Learning Rate: 0.0025\n",
      "Epoch [3615/20000], Loss: 198.79315185546875, Entropy -236.45663452148438, Learning Rate: 0.0025\n",
      "Epoch [3616/20000], Loss: 181.8594970703125, Entropy -220.14781188964844, Learning Rate: 0.0025\n",
      "Epoch [3617/20000], Loss: 184.263671875, Entropy -221.68714904785156, Learning Rate: 0.0025\n",
      "Epoch [3618/20000], Loss: 175.40989685058594, Entropy -211.1898651123047, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3619/20000], Loss: 184.56288146972656, Entropy -227.8417510986328, Learning Rate: 0.0025\n",
      "Epoch [3620/20000], Loss: 180.0849151611328, Entropy -223.95596313476562, Learning Rate: 0.0025\n",
      "Epoch [3621/20000], Loss: 185.23570251464844, Entropy -221.96798706054688, Learning Rate: 0.0025\n",
      "Epoch [3622/20000], Loss: 175.1737518310547, Entropy -215.27117919921875, Learning Rate: 0.0025\n",
      "Epoch [3623/20000], Loss: 191.57447814941406, Entropy -219.08106994628906, Learning Rate: 0.0025\n",
      "Epoch [3624/20000], Loss: 188.18521118164062, Entropy -231.2538299560547, Learning Rate: 0.0025\n",
      "Epoch [3625/20000], Loss: 195.79153442382812, Entropy -230.53253173828125, Learning Rate: 0.0025\n",
      "Epoch [3626/20000], Loss: 189.89035034179688, Entropy -224.83413696289062, Learning Rate: 0.0025\n",
      "Epoch [3627/20000], Loss: 184.82098388671875, Entropy -225.22113037109375, Learning Rate: 0.0025\n",
      "Epoch [3628/20000], Loss: 180.4563446044922, Entropy -221.92848205566406, Learning Rate: 0.0025\n",
      "Epoch [3629/20000], Loss: 181.40737915039062, Entropy -223.5187530517578, Learning Rate: 0.0025\n",
      "Epoch [3630/20000], Loss: 183.22332763671875, Entropy -218.2442626953125, Learning Rate: 0.0025\n",
      "Epoch [3631/20000], Loss: 174.4860382080078, Entropy -214.2023468017578, Learning Rate: 0.00125\n",
      "Epoch [3632/20000], Loss: 184.21060180664062, Entropy -220.07350158691406, Learning Rate: 0.00125\n",
      "Epoch [3633/20000], Loss: 188.2982940673828, Entropy -227.3260040283203, Learning Rate: 0.00125\n",
      "Epoch [3634/20000], Loss: 183.4977264404297, Entropy -222.79229736328125, Learning Rate: 0.00125\n",
      "Epoch [3635/20000], Loss: 171.96322631835938, Entropy -210.38113403320312, Learning Rate: 0.00125\n",
      "Epoch [3636/20000], Loss: 169.76475524902344, Entropy -207.7125244140625, Learning Rate: 0.00125\n",
      "Epoch [3637/20000], Loss: 185.20291137695312, Entropy -225.74551391601562, Learning Rate: 0.00125\n",
      "Epoch [3638/20000], Loss: 201.25201416015625, Entropy -221.13975524902344, Learning Rate: 0.00125\n",
      "Epoch [3639/20000], Loss: 176.36085510253906, Entropy -218.50897216796875, Learning Rate: 0.00125\n",
      "Epoch [3640/20000], Loss: 178.57473754882812, Entropy -219.170654296875, Learning Rate: 0.00125\n",
      "Epoch [3641/20000], Loss: 185.18211364746094, Entropy -226.08973693847656, Learning Rate: 0.00125\n",
      "Epoch [3642/20000], Loss: 189.7069091796875, Entropy -233.97518920898438, Learning Rate: 0.00125\n",
      "Epoch [3643/20000], Loss: 177.67555236816406, Entropy -216.9990997314453, Learning Rate: 0.00125\n",
      "Epoch [3644/20000], Loss: 174.2648468017578, Entropy -207.52975463867188, Learning Rate: 0.00125\n",
      "Epoch [3645/20000], Loss: 173.2948760986328, Entropy -212.54002380371094, Learning Rate: 0.00125\n",
      "Epoch [3646/20000], Loss: 174.6109619140625, Entropy -215.63525390625, Learning Rate: 0.00125\n",
      "Epoch [3647/20000], Loss: 171.36215209960938, Entropy -215.08612060546875, Learning Rate: 0.00125\n",
      "Epoch [3648/20000], Loss: 184.79591369628906, Entropy -220.65086364746094, Learning Rate: 0.00125\n",
      "Epoch [3649/20000], Loss: 178.90139770507812, Entropy -216.82623291015625, Learning Rate: 0.00125\n",
      "Epoch [3650/20000], Loss: 173.9076690673828, Entropy -209.64486694335938, Learning Rate: 0.00125\n",
      "Epoch [3651/20000], Loss: 184.7615509033203, Entropy -227.0431365966797, Learning Rate: 0.00125\n",
      "Epoch [3652/20000], Loss: 178.63890075683594, Entropy -219.34915161132812, Learning Rate: 0.00125\n",
      "Epoch [3653/20000], Loss: 186.46295166015625, Entropy -225.17543029785156, Learning Rate: 0.00125\n",
      "Epoch [3654/20000], Loss: 175.76707458496094, Entropy -208.56716918945312, Learning Rate: 0.00125\n",
      "Epoch [3655/20000], Loss: 182.03916931152344, Entropy -223.7342529296875, Learning Rate: 0.00125\n",
      "Epoch [3656/20000], Loss: 184.8374786376953, Entropy -218.6257781982422, Learning Rate: 0.00125\n",
      "Epoch [3657/20000], Loss: 178.7271728515625, Entropy -217.4584197998047, Learning Rate: 0.00125\n",
      "Epoch [3658/20000], Loss: 176.32675170898438, Entropy -222.87713623046875, Learning Rate: 0.00125\n",
      "Epoch [3659/20000], Loss: 175.943359375, Entropy -214.58859252929688, Learning Rate: 0.00125\n",
      "Epoch [3660/20000], Loss: 180.482666015625, Entropy -225.95822143554688, Learning Rate: 0.00125\n",
      "Epoch [3661/20000], Loss: 180.0904541015625, Entropy -227.45347595214844, Learning Rate: 0.00125\n",
      "Epoch [3662/20000], Loss: 181.56651306152344, Entropy -218.890625, Learning Rate: 0.00125\n",
      "Epoch [3663/20000], Loss: 175.10638427734375, Entropy -209.45272827148438, Learning Rate: 0.00125\n",
      "Epoch [3664/20000], Loss: 175.79335021972656, Entropy -215.37828063964844, Learning Rate: 0.00125\n",
      "Epoch [3665/20000], Loss: 170.53468322753906, Entropy -211.07972717285156, Learning Rate: 0.00125\n",
      "Epoch [3666/20000], Loss: 172.8516082763672, Entropy -212.1904296875, Learning Rate: 0.00125\n",
      "Epoch [3667/20000], Loss: 169.33673095703125, Entropy -209.9759521484375, Learning Rate: 0.00125\n",
      "Epoch [3668/20000], Loss: 167.08889770507812, Entropy -203.19015502929688, Learning Rate: 0.00125\n",
      "Epoch [3669/20000], Loss: 175.1490478515625, Entropy -211.23867797851562, Learning Rate: 0.00125\n",
      "Epoch [3670/20000], Loss: 188.5050506591797, Entropy -225.04946899414062, Learning Rate: 0.00125\n",
      "Epoch [3671/20000], Loss: 178.5668487548828, Entropy -219.04957580566406, Learning Rate: 0.00125\n",
      "Epoch [3672/20000], Loss: 178.30795288085938, Entropy -216.1995086669922, Learning Rate: 0.00125\n",
      "Epoch [3673/20000], Loss: 186.28236389160156, Entropy -230.05874633789062, Learning Rate: 0.00125\n",
      "Epoch [3674/20000], Loss: 174.9416046142578, Entropy -209.5288543701172, Learning Rate: 0.00125\n",
      "Epoch [3675/20000], Loss: 183.77415466308594, Entropy -224.99961853027344, Learning Rate: 0.00125\n",
      "Epoch [3676/20000], Loss: 180.34950256347656, Entropy -214.4034423828125, Learning Rate: 0.00125\n",
      "Epoch [3677/20000], Loss: 195.0071258544922, Entropy -232.0409393310547, Learning Rate: 0.00125\n",
      "Epoch [3678/20000], Loss: 181.90577697753906, Entropy -223.19659423828125, Learning Rate: 0.00125\n",
      "Epoch [3679/20000], Loss: 172.4778289794922, Entropy -208.80906677246094, Learning Rate: 0.00125\n",
      "Epoch [3680/20000], Loss: 192.89100646972656, Entropy -237.3035888671875, Learning Rate: 0.00125\n",
      "Epoch [3681/20000], Loss: 185.27452087402344, Entropy -225.9215087890625, Learning Rate: 0.00125\n",
      "Epoch [3682/20000], Loss: 174.66619873046875, Entropy -218.1666259765625, Learning Rate: 0.00125\n",
      "Epoch [3683/20000], Loss: 181.710205078125, Entropy -217.56674194335938, Learning Rate: 0.00125\n",
      "Epoch [3684/20000], Loss: 182.24819946289062, Entropy -222.62362670898438, Learning Rate: 0.00125\n",
      "Epoch [3685/20000], Loss: 173.2323760986328, Entropy -213.3350067138672, Learning Rate: 0.00125\n",
      "Epoch [3686/20000], Loss: 178.71302795410156, Entropy -213.2005157470703, Learning Rate: 0.00125\n",
      "Epoch [3687/20000], Loss: 175.94174194335938, Entropy -214.33328247070312, Learning Rate: 0.00125\n",
      "Epoch [3688/20000], Loss: 188.68411254882812, Entropy -231.87533569335938, Learning Rate: 0.00125\n",
      "Epoch [3689/20000], Loss: 170.13876342773438, Entropy -204.1975555419922, Learning Rate: 0.00125\n",
      "Epoch [3690/20000], Loss: 179.395751953125, Entropy -219.2378387451172, Learning Rate: 0.00125\n",
      "Epoch [3691/20000], Loss: 175.44052124023438, Entropy -213.16827392578125, Learning Rate: 0.00125\n",
      "Epoch [3692/20000], Loss: 186.71417236328125, Entropy -223.70848083496094, Learning Rate: 0.00125\n",
      "Epoch [3693/20000], Loss: 172.10055541992188, Entropy -212.39669799804688, Learning Rate: 0.00125\n",
      "Epoch [3694/20000], Loss: 186.5422821044922, Entropy -223.876953125, Learning Rate: 0.00125\n",
      "Epoch [3695/20000], Loss: 185.7901153564453, Entropy -227.46908569335938, Learning Rate: 0.00125\n",
      "Epoch [3696/20000], Loss: 175.16192626953125, Entropy -216.05430603027344, Learning Rate: 0.00125\n",
      "Epoch [3697/20000], Loss: 174.23712158203125, Entropy -210.05735778808594, Learning Rate: 0.00125\n",
      "Epoch [3698/20000], Loss: 177.44619750976562, Entropy -212.957275390625, Learning Rate: 0.00125\n",
      "Epoch [3699/20000], Loss: 182.5620574951172, Entropy -215.73135375976562, Learning Rate: 0.00125\n",
      "Epoch [3700/20000], Loss: 188.07598876953125, Entropy -227.22311401367188, Learning Rate: 0.00125\n",
      "Epoch [3701/20000], Loss: 170.4713897705078, Entropy -209.20135498046875, Learning Rate: 0.00125\n",
      "Epoch [3702/20000], Loss: 182.6143035888672, Entropy -218.02210998535156, Learning Rate: 0.00125\n",
      "Epoch [3703/20000], Loss: 183.90789794921875, Entropy -224.3558349609375, Learning Rate: 0.00125\n",
      "Epoch [3704/20000], Loss: 179.61700439453125, Entropy -221.0183563232422, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3705/20000], Loss: 175.52642822265625, Entropy -214.43167114257812, Learning Rate: 0.00125\n",
      "Epoch [3706/20000], Loss: 174.8350830078125, Entropy -207.75509643554688, Learning Rate: 0.00125\n",
      "Epoch [3707/20000], Loss: 180.5675048828125, Entropy -222.65066528320312, Learning Rate: 0.00125\n",
      "Epoch [3708/20000], Loss: 178.86309814453125, Entropy -218.43466186523438, Learning Rate: 0.00125\n",
      "Epoch [3709/20000], Loss: 176.16087341308594, Entropy -209.43218994140625, Learning Rate: 0.00125\n",
      "Epoch [3710/20000], Loss: 178.04600524902344, Entropy -220.1763153076172, Learning Rate: 0.00125\n",
      "Epoch [3711/20000], Loss: 180.0844268798828, Entropy -217.74032592773438, Learning Rate: 0.00125\n",
      "Epoch [3712/20000], Loss: 183.7838134765625, Entropy -226.44668579101562, Learning Rate: 0.00125\n",
      "Epoch [3713/20000], Loss: 179.865234375, Entropy -221.54055786132812, Learning Rate: 0.00125\n",
      "Epoch [3714/20000], Loss: 186.59933471679688, Entropy -217.01931762695312, Learning Rate: 0.00125\n",
      "Epoch [3715/20000], Loss: 187.51895141601562, Entropy -230.6451873779297, Learning Rate: 0.00125\n",
      "Epoch [3716/20000], Loss: 171.28271484375, Entropy -209.96885681152344, Learning Rate: 0.00125\n",
      "Epoch [3717/20000], Loss: 173.2891387939453, Entropy -213.41676330566406, Learning Rate: 0.00125\n",
      "Epoch [3718/20000], Loss: 176.77638244628906, Entropy -215.6674346923828, Learning Rate: 0.00125\n",
      "Epoch [3719/20000], Loss: 170.29478454589844, Entropy -208.3848876953125, Learning Rate: 0.00125\n",
      "Epoch [3720/20000], Loss: 178.90103149414062, Entropy -216.66566467285156, Learning Rate: 0.00125\n",
      "Epoch [3721/20000], Loss: 176.21299743652344, Entropy -210.83534240722656, Learning Rate: 0.00125\n",
      "Epoch [3722/20000], Loss: 174.86074829101562, Entropy -216.96258544921875, Learning Rate: 0.00125\n",
      "Epoch [3723/20000], Loss: 175.12318420410156, Entropy -209.28619384765625, Learning Rate: 0.00125\n",
      "Epoch [3724/20000], Loss: 177.49124145507812, Entropy -217.2606201171875, Learning Rate: 0.00125\n",
      "Epoch [3725/20000], Loss: 181.5284881591797, Entropy -221.46498107910156, Learning Rate: 0.00125\n",
      "Epoch [3726/20000], Loss: 181.51747131347656, Entropy -223.79977416992188, Learning Rate: 0.00125\n",
      "Epoch [3727/20000], Loss: 177.90245056152344, Entropy -219.46568298339844, Learning Rate: 0.00125\n",
      "Epoch [3728/20000], Loss: 170.6759796142578, Entropy -213.87728881835938, Learning Rate: 0.00125\n",
      "Epoch [3729/20000], Loss: 170.8249053955078, Entropy -208.68649291992188, Learning Rate: 0.00125\n",
      "Epoch [3730/20000], Loss: 174.45187377929688, Entropy -212.06161499023438, Learning Rate: 0.00125\n",
      "Epoch [3731/20000], Loss: 176.49034118652344, Entropy -218.92694091796875, Learning Rate: 0.00125\n",
      "Epoch [3732/20000], Loss: 177.66441345214844, Entropy -214.95480346679688, Learning Rate: 0.00125\n",
      "Epoch [3733/20000], Loss: 178.91847229003906, Entropy -214.1186065673828, Learning Rate: 0.00125\n",
      "Epoch [3734/20000], Loss: 181.5608673095703, Entropy -220.4055633544922, Learning Rate: 0.00125\n",
      "Epoch [3735/20000], Loss: 172.0679168701172, Entropy -217.38308715820312, Learning Rate: 0.00125\n",
      "Epoch [3736/20000], Loss: 182.01864624023438, Entropy -218.22169494628906, Learning Rate: 0.00125\n",
      "Epoch [3737/20000], Loss: 177.71640014648438, Entropy -219.06919860839844, Learning Rate: 0.00125\n",
      "Epoch [3738/20000], Loss: 179.48402404785156, Entropy -217.171875, Learning Rate: 0.00125\n",
      "Epoch [3739/20000], Loss: 170.3343048095703, Entropy -203.40098571777344, Learning Rate: 0.00125\n",
      "Epoch [3740/20000], Loss: 180.56198120117188, Entropy -213.00567626953125, Learning Rate: 0.00125\n",
      "Epoch [3741/20000], Loss: 183.6326904296875, Entropy -220.69090270996094, Learning Rate: 0.00125\n",
      "Epoch [3742/20000], Loss: 177.97752380371094, Entropy -219.91323852539062, Learning Rate: 0.00125\n",
      "Epoch [3743/20000], Loss: 178.5050811767578, Entropy -214.5391387939453, Learning Rate: 0.00125\n",
      "Epoch [3744/20000], Loss: 178.94467163085938, Entropy -214.0358428955078, Learning Rate: 0.00125\n",
      "Epoch [3745/20000], Loss: 175.8843994140625, Entropy -217.60186767578125, Learning Rate: 0.00125\n",
      "Epoch [3746/20000], Loss: 176.5452880859375, Entropy -213.51486206054688, Learning Rate: 0.00125\n",
      "Epoch [3747/20000], Loss: 177.41197204589844, Entropy -215.89151000976562, Learning Rate: 0.00125\n",
      "Epoch [3748/20000], Loss: 180.47100830078125, Entropy -218.06680297851562, Learning Rate: 0.00125\n",
      "Epoch [3749/20000], Loss: 174.05599975585938, Entropy -209.32525634765625, Learning Rate: 0.00125\n",
      "Epoch [3750/20000], Loss: 173.1766357421875, Entropy -210.99862670898438, Learning Rate: 0.00125\n",
      "Epoch [3751/20000], Loss: 190.8035430908203, Entropy -235.3543701171875, Learning Rate: 0.00125\n",
      "Epoch [3752/20000], Loss: 181.13394165039062, Entropy -218.41299438476562, Learning Rate: 0.00125\n",
      "Epoch [3753/20000], Loss: 176.31683349609375, Entropy -211.30746459960938, Learning Rate: 0.00125\n",
      "Epoch [3754/20000], Loss: 179.82786560058594, Entropy -218.29620361328125, Learning Rate: 0.00125\n",
      "Epoch [3755/20000], Loss: 173.75833129882812, Entropy -213.71514892578125, Learning Rate: 0.00125\n",
      "Epoch [3756/20000], Loss: 186.8241729736328, Entropy -228.0189208984375, Learning Rate: 0.00125\n",
      "Epoch [3757/20000], Loss: 187.3423309326172, Entropy -229.2566375732422, Learning Rate: 0.00125\n",
      "Epoch [3758/20000], Loss: 180.8819122314453, Entropy -225.107177734375, Learning Rate: 0.00125\n",
      "Epoch [3759/20000], Loss: 175.826904296875, Entropy -210.79519653320312, Learning Rate: 0.00125\n",
      "Epoch [3760/20000], Loss: 172.3787078857422, Entropy -215.2367401123047, Learning Rate: 0.00125\n",
      "Epoch [3761/20000], Loss: 179.17916870117188, Entropy -211.67190551757812, Learning Rate: 0.00125\n",
      "Epoch [3762/20000], Loss: 177.8350067138672, Entropy -224.541015625, Learning Rate: 0.00125\n",
      "Epoch [3763/20000], Loss: 179.40399169921875, Entropy -212.9578857421875, Learning Rate: 0.00125\n",
      "Epoch [3764/20000], Loss: 177.92080688476562, Entropy -215.95774841308594, Learning Rate: 0.00125\n",
      "Epoch [3765/20000], Loss: 187.75155639648438, Entropy -228.96163940429688, Learning Rate: 0.00125\n",
      "Epoch [3766/20000], Loss: 177.5404510498047, Entropy -214.21206665039062, Learning Rate: 0.00125\n",
      "Epoch [3767/20000], Loss: 189.69935607910156, Entropy -232.97122192382812, Learning Rate: 0.00125\n",
      "Epoch [3768/20000], Loss: 180.70330810546875, Entropy -220.12844848632812, Learning Rate: 0.00125\n",
      "Epoch [3769/20000], Loss: 176.01370239257812, Entropy -213.932861328125, Learning Rate: 0.00125\n",
      "Epoch [3770/20000], Loss: 186.37106323242188, Entropy -227.18902587890625, Learning Rate: 0.00125\n",
      "Epoch [3771/20000], Loss: 175.0624237060547, Entropy -216.46615600585938, Learning Rate: 0.00125\n",
      "Epoch [3772/20000], Loss: 188.947509765625, Entropy -230.04702758789062, Learning Rate: 0.00125\n",
      "Epoch [3773/20000], Loss: 185.17324829101562, Entropy -217.07083129882812, Learning Rate: 0.00125\n",
      "Epoch [3774/20000], Loss: 185.2028350830078, Entropy -220.15090942382812, Learning Rate: 0.00125\n",
      "Epoch [3775/20000], Loss: 184.19764709472656, Entropy -225.80093383789062, Learning Rate: 0.00125\n",
      "Epoch [3776/20000], Loss: 191.63804626464844, Entropy -231.8238983154297, Learning Rate: 0.00125\n",
      "Epoch [3777/20000], Loss: 185.59219360351562, Entropy -220.70416259765625, Learning Rate: 0.00125\n",
      "Epoch [3778/20000], Loss: 179.57785034179688, Entropy -220.04986572265625, Learning Rate: 0.00125\n",
      "Epoch [3779/20000], Loss: 174.82757568359375, Entropy -221.63922119140625, Learning Rate: 0.00125\n",
      "Epoch [3780/20000], Loss: 181.6444854736328, Entropy -227.00326538085938, Learning Rate: 0.00125\n",
      "Epoch [3781/20000], Loss: 179.2241668701172, Entropy -220.9229736328125, Learning Rate: 0.00125\n",
      "Epoch [3782/20000], Loss: 176.2168426513672, Entropy -216.02090454101562, Learning Rate: 0.00125\n",
      "Epoch [3783/20000], Loss: 173.3313446044922, Entropy -209.57418823242188, Learning Rate: 0.00125\n",
      "Epoch [3784/20000], Loss: 172.11341857910156, Entropy -211.8534698486328, Learning Rate: 0.00125\n",
      "Epoch [3785/20000], Loss: 168.23995971679688, Entropy -205.89511108398438, Learning Rate: 0.00125\n",
      "Epoch [3786/20000], Loss: 172.66119384765625, Entropy -210.01348876953125, Learning Rate: 0.00125\n",
      "Epoch [3787/20000], Loss: 176.65939331054688, Entropy -218.15814208984375, Learning Rate: 0.00125\n",
      "Epoch [3788/20000], Loss: 189.29209899902344, Entropy -231.39865112304688, Learning Rate: 0.00125\n",
      "Epoch [3789/20000], Loss: 185.4440155029297, Entropy -222.00462341308594, Learning Rate: 0.00125\n",
      "Epoch [3790/20000], Loss: 176.4318389892578, Entropy -216.4317626953125, Learning Rate: 0.00125\n",
      "Epoch [3791/20000], Loss: 181.3873748779297, Entropy -218.23458862304688, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3792/20000], Loss: 179.98646545410156, Entropy -222.59017944335938, Learning Rate: 0.00125\n",
      "Epoch [3793/20000], Loss: 177.44253540039062, Entropy -214.88046264648438, Learning Rate: 0.00125\n",
      "Epoch [3794/20000], Loss: 187.67758178710938, Entropy -230.26324462890625, Learning Rate: 0.00125\n",
      "Epoch [3795/20000], Loss: 171.70860290527344, Entropy -214.9000244140625, Learning Rate: 0.00125\n",
      "Epoch [3796/20000], Loss: 174.5400390625, Entropy -214.7436065673828, Learning Rate: 0.00125\n",
      "Epoch [3797/20000], Loss: 177.5437469482422, Entropy -209.97515869140625, Learning Rate: 0.00125\n",
      "Epoch [3798/20000], Loss: 178.5402374267578, Entropy -211.89569091796875, Learning Rate: 0.00125\n",
      "Epoch [3799/20000], Loss: 176.6728515625, Entropy -216.66566467285156, Learning Rate: 0.00125\n",
      "Epoch [3800/20000], Loss: 182.82086181640625, Entropy -210.11355590820312, Learning Rate: 0.00125\n",
      "Epoch [3801/20000], Loss: 185.3445587158203, Entropy -221.51815795898438, Learning Rate: 0.00125\n",
      "Epoch [3802/20000], Loss: 171.55874633789062, Entropy -213.25323486328125, Learning Rate: 0.00125\n",
      "Epoch [3803/20000], Loss: 184.14581298828125, Entropy -217.69464111328125, Learning Rate: 0.00125\n",
      "Epoch [3804/20000], Loss: 177.54214477539062, Entropy -213.6263427734375, Learning Rate: 0.00125\n",
      "Epoch [3805/20000], Loss: 176.0132598876953, Entropy -220.4332275390625, Learning Rate: 0.00125\n",
      "Epoch [3806/20000], Loss: 182.25970458984375, Entropy -222.7237548828125, Learning Rate: 0.00125\n",
      "Epoch [3807/20000], Loss: 179.20065307617188, Entropy -216.10162353515625, Learning Rate: 0.00125\n",
      "Epoch [3808/20000], Loss: 172.24435424804688, Entropy -210.1605987548828, Learning Rate: 0.00125\n",
      "Epoch [3809/20000], Loss: 177.16217041015625, Entropy -210.5493621826172, Learning Rate: 0.00125\n",
      "Epoch [3810/20000], Loss: 172.611328125, Entropy -216.95480346679688, Learning Rate: 0.00125\n",
      "Epoch [3811/20000], Loss: 175.11294555664062, Entropy -210.93289184570312, Learning Rate: 0.00125\n",
      "Epoch [3812/20000], Loss: 185.54989624023438, Entropy -224.4208221435547, Learning Rate: 0.00125\n",
      "Epoch [3813/20000], Loss: 176.96163940429688, Entropy -215.73280334472656, Learning Rate: 0.00125\n",
      "Epoch [3814/20000], Loss: 172.5299072265625, Entropy -203.05357360839844, Learning Rate: 0.00125\n",
      "Epoch [3815/20000], Loss: 180.29444885253906, Entropy -217.91741943359375, Learning Rate: 0.00125\n",
      "Epoch [3816/20000], Loss: 169.76609802246094, Entropy -205.28140258789062, Learning Rate: 0.00125\n",
      "Epoch [3817/20000], Loss: 185.43502807617188, Entropy -225.86972045898438, Learning Rate: 0.00125\n",
      "Epoch [3818/20000], Loss: 175.07298278808594, Entropy -211.4414825439453, Learning Rate: 0.00125\n",
      "Epoch [3819/20000], Loss: 180.76211547851562, Entropy -209.5792999267578, Learning Rate: 0.00125\n",
      "Epoch [3820/20000], Loss: 181.3948974609375, Entropy -224.5669708251953, Learning Rate: 0.00125\n",
      "Epoch [3821/20000], Loss: 174.2313232421875, Entropy -213.528076171875, Learning Rate: 0.00125\n",
      "Epoch [3822/20000], Loss: 172.45587158203125, Entropy -211.93577575683594, Learning Rate: 0.00125\n",
      "Epoch [3823/20000], Loss: 177.25555419921875, Entropy -212.08653259277344, Learning Rate: 0.00125\n",
      "Epoch [3824/20000], Loss: 176.8282928466797, Entropy -215.61790466308594, Learning Rate: 0.00125\n",
      "Epoch [3825/20000], Loss: 179.89491271972656, Entropy -224.4243621826172, Learning Rate: 0.00125\n",
      "Epoch [3826/20000], Loss: 181.60391235351562, Entropy -222.2001495361328, Learning Rate: 0.00125\n",
      "Epoch [3827/20000], Loss: 185.7828826904297, Entropy -224.85623168945312, Learning Rate: 0.00125\n",
      "Epoch [3828/20000], Loss: 174.01455688476562, Entropy -208.033935546875, Learning Rate: 0.00125\n",
      "Epoch [3829/20000], Loss: 187.50460815429688, Entropy -221.52008056640625, Learning Rate: 0.00125\n",
      "Epoch [3830/20000], Loss: 177.15774536132812, Entropy -217.01748657226562, Learning Rate: 0.00125\n",
      "Epoch [3831/20000], Loss: 191.78082275390625, Entropy -235.9141845703125, Learning Rate: 0.00125\n",
      "Epoch [3832/20000], Loss: 175.74191284179688, Entropy -218.74093627929688, Learning Rate: 0.000625\n",
      "Epoch [3833/20000], Loss: 201.65562438964844, Entropy -243.5521240234375, Learning Rate: 0.000625\n",
      "Epoch [3834/20000], Loss: 178.66355895996094, Entropy -217.66383361816406, Learning Rate: 0.000625\n",
      "Epoch [3835/20000], Loss: 183.8415985107422, Entropy -230.12123107910156, Learning Rate: 0.000625\n",
      "Epoch [3836/20000], Loss: 178.1559600830078, Entropy -219.61480712890625, Learning Rate: 0.000625\n",
      "Epoch [3837/20000], Loss: 176.94345092773438, Entropy -212.55245971679688, Learning Rate: 0.000625\n",
      "Epoch [3838/20000], Loss: 176.87278747558594, Entropy -215.99452209472656, Learning Rate: 0.000625\n",
      "Epoch [3839/20000], Loss: 190.82176208496094, Entropy -232.50143432617188, Learning Rate: 0.000625\n",
      "Epoch [3840/20000], Loss: 186.7941436767578, Entropy -225.27926635742188, Learning Rate: 0.000625\n",
      "Epoch [3841/20000], Loss: 173.39697265625, Entropy -210.89088439941406, Learning Rate: 0.000625\n",
      "Epoch [3842/20000], Loss: 185.66990661621094, Entropy -220.15084838867188, Learning Rate: 0.000625\n",
      "Epoch [3843/20000], Loss: 172.70556640625, Entropy -213.96507263183594, Learning Rate: 0.000625\n",
      "Epoch [3844/20000], Loss: 165.18093872070312, Entropy -209.47775268554688, Learning Rate: 0.000625\n",
      "Epoch [3845/20000], Loss: 175.03335571289062, Entropy -198.96722412109375, Learning Rate: 0.000625\n",
      "Epoch [3846/20000], Loss: 169.62367248535156, Entropy -209.56253051757812, Learning Rate: 0.000625\n",
      "Epoch [3847/20000], Loss: 187.85446166992188, Entropy -222.98507690429688, Learning Rate: 0.000625\n",
      "Epoch [3848/20000], Loss: 180.29959106445312, Entropy -224.07339477539062, Learning Rate: 0.000625\n",
      "Epoch [3849/20000], Loss: 179.16275024414062, Entropy -220.96563720703125, Learning Rate: 0.000625\n",
      "Epoch [3850/20000], Loss: 173.17091369628906, Entropy -211.35850524902344, Learning Rate: 0.000625\n",
      "Epoch [3851/20000], Loss: 176.1253662109375, Entropy -207.5581817626953, Learning Rate: 0.000625\n",
      "Epoch [3852/20000], Loss: 172.32150268554688, Entropy -212.02003479003906, Learning Rate: 0.000625\n",
      "Epoch [3853/20000], Loss: 189.4812469482422, Entropy -225.71795654296875, Learning Rate: 0.000625\n",
      "Epoch [3854/20000], Loss: 173.7010040283203, Entropy -210.5944366455078, Learning Rate: 0.000625\n",
      "Epoch [3855/20000], Loss: 183.8834228515625, Entropy -223.3777313232422, Learning Rate: 0.000625\n",
      "Epoch [3856/20000], Loss: 183.2599639892578, Entropy -221.3918914794922, Learning Rate: 0.000625\n",
      "Epoch [3857/20000], Loss: 170.74668884277344, Entropy -210.7254638671875, Learning Rate: 0.000625\n",
      "Epoch [3858/20000], Loss: 171.51551818847656, Entropy -212.12696838378906, Learning Rate: 0.000625\n",
      "Epoch [3859/20000], Loss: 173.94041442871094, Entropy -214.8094482421875, Learning Rate: 0.000625\n",
      "Epoch [3860/20000], Loss: 184.11648559570312, Entropy -222.41793823242188, Learning Rate: 0.000625\n",
      "Epoch [3861/20000], Loss: 183.80926513671875, Entropy -221.26368713378906, Learning Rate: 0.000625\n",
      "Epoch [3862/20000], Loss: 180.5184783935547, Entropy -218.52134704589844, Learning Rate: 0.000625\n",
      "Epoch [3863/20000], Loss: 186.0606231689453, Entropy -227.27256774902344, Learning Rate: 0.000625\n",
      "Epoch [3864/20000], Loss: 184.42881774902344, Entropy -219.69195556640625, Learning Rate: 0.000625\n",
      "Epoch [3865/20000], Loss: 177.32777404785156, Entropy -215.3522186279297, Learning Rate: 0.000625\n",
      "Epoch [3866/20000], Loss: 186.08929443359375, Entropy -229.5708770751953, Learning Rate: 0.000625\n",
      "Epoch [3867/20000], Loss: 183.47186279296875, Entropy -223.15841674804688, Learning Rate: 0.000625\n",
      "Epoch [3868/20000], Loss: 171.83871459960938, Entropy -214.87509155273438, Learning Rate: 0.000625\n",
      "Epoch [3869/20000], Loss: 172.89566040039062, Entropy -211.2500457763672, Learning Rate: 0.000625\n",
      "Epoch [3870/20000], Loss: 177.64344787597656, Entropy -219.33457946777344, Learning Rate: 0.000625\n",
      "Epoch [3871/20000], Loss: 183.58941650390625, Entropy -224.9599609375, Learning Rate: 0.000625\n",
      "Epoch [3872/20000], Loss: 182.00308227539062, Entropy -221.53060913085938, Learning Rate: 0.000625\n",
      "Epoch [3873/20000], Loss: 176.0302276611328, Entropy -218.6573028564453, Learning Rate: 0.000625\n",
      "Epoch [3874/20000], Loss: 179.7381134033203, Entropy -218.00462341308594, Learning Rate: 0.000625\n",
      "Epoch [3875/20000], Loss: 175.03302001953125, Entropy -209.41921997070312, Learning Rate: 0.000625\n",
      "Epoch [3876/20000], Loss: 187.7718048095703, Entropy -232.9552001953125, Learning Rate: 0.000625\n",
      "Epoch [3877/20000], Loss: 180.65542602539062, Entropy -223.35772705078125, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3878/20000], Loss: 174.92181396484375, Entropy -217.80740356445312, Learning Rate: 0.000625\n",
      "Epoch [3879/20000], Loss: 173.2582550048828, Entropy -209.97329711914062, Learning Rate: 0.000625\n",
      "Epoch [3880/20000], Loss: 169.14535522460938, Entropy -205.72601318359375, Learning Rate: 0.000625\n",
      "Epoch [3881/20000], Loss: 190.17820739746094, Entropy -235.68972778320312, Learning Rate: 0.000625\n",
      "Epoch [3882/20000], Loss: 175.6754608154297, Entropy -213.58018493652344, Learning Rate: 0.000625\n",
      "Epoch [3883/20000], Loss: 183.4165802001953, Entropy -218.12655639648438, Learning Rate: 0.000625\n",
      "Epoch [3884/20000], Loss: 181.7421417236328, Entropy -224.17222595214844, Learning Rate: 0.000625\n",
      "Epoch [3885/20000], Loss: 194.10108947753906, Entropy -231.99224853515625, Learning Rate: 0.000625\n",
      "Epoch [3886/20000], Loss: 174.34918212890625, Entropy -210.11102294921875, Learning Rate: 0.000625\n",
      "Epoch [3887/20000], Loss: 186.34005737304688, Entropy -223.8653564453125, Learning Rate: 0.000625\n",
      "Epoch [3888/20000], Loss: 176.0188446044922, Entropy -216.3990020751953, Learning Rate: 0.000625\n",
      "Epoch [3889/20000], Loss: 166.71218872070312, Entropy -197.98880004882812, Learning Rate: 0.000625\n",
      "Epoch [3890/20000], Loss: 180.9553680419922, Entropy -220.26211547851562, Learning Rate: 0.000625\n",
      "Epoch [3891/20000], Loss: 169.45584106445312, Entropy -211.39700317382812, Learning Rate: 0.000625\n",
      "Epoch [3892/20000], Loss: 175.424560546875, Entropy -216.16000366210938, Learning Rate: 0.000625\n",
      "Epoch [3893/20000], Loss: 176.40919494628906, Entropy -215.18385314941406, Learning Rate: 0.000625\n",
      "Epoch [3894/20000], Loss: 173.70188903808594, Entropy -212.60787963867188, Learning Rate: 0.000625\n",
      "Epoch [3895/20000], Loss: 172.38845825195312, Entropy -212.46011352539062, Learning Rate: 0.000625\n",
      "Epoch [3896/20000], Loss: 171.74606323242188, Entropy -210.4580078125, Learning Rate: 0.000625\n",
      "Epoch [3897/20000], Loss: 193.6442108154297, Entropy -230.0708465576172, Learning Rate: 0.000625\n",
      "Epoch [3898/20000], Loss: 170.19888305664062, Entropy -204.65371704101562, Learning Rate: 0.000625\n",
      "Epoch [3899/20000], Loss: 178.08181762695312, Entropy -219.58721923828125, Learning Rate: 0.000625\n",
      "Epoch [3900/20000], Loss: 172.46670532226562, Entropy -210.5680694580078, Learning Rate: 0.000625\n",
      "Epoch [3901/20000], Loss: 174.92437744140625, Entropy -209.11097717285156, Learning Rate: 0.000625\n",
      "Epoch [3902/20000], Loss: 175.73690795898438, Entropy -212.219970703125, Learning Rate: 0.000625\n",
      "Epoch [3903/20000], Loss: 174.10748291015625, Entropy -212.5625, Learning Rate: 0.000625\n",
      "Epoch [3904/20000], Loss: 172.5865936279297, Entropy -212.64248657226562, Learning Rate: 0.000625\n",
      "Epoch [3905/20000], Loss: 183.45933532714844, Entropy -224.626708984375, Learning Rate: 0.000625\n",
      "Epoch [3906/20000], Loss: 175.7950439453125, Entropy -214.57212829589844, Learning Rate: 0.000625\n",
      "Epoch [3907/20000], Loss: 182.8411865234375, Entropy -226.8911895751953, Learning Rate: 0.000625\n",
      "Epoch [3908/20000], Loss: 186.32415771484375, Entropy -219.8908233642578, Learning Rate: 0.000625\n",
      "Epoch [3909/20000], Loss: 171.93838500976562, Entropy -209.9606170654297, Learning Rate: 0.000625\n",
      "Epoch [3910/20000], Loss: 186.7567901611328, Entropy -222.14627075195312, Learning Rate: 0.000625\n",
      "Epoch [3911/20000], Loss: 172.9821319580078, Entropy -210.81002807617188, Learning Rate: 0.000625\n",
      "Epoch [3912/20000], Loss: 177.75563049316406, Entropy -212.8957977294922, Learning Rate: 0.000625\n",
      "Epoch [3913/20000], Loss: 178.81736755371094, Entropy -226.70509338378906, Learning Rate: 0.000625\n",
      "Epoch [3914/20000], Loss: 190.96693420410156, Entropy -228.5286865234375, Learning Rate: 0.000625\n",
      "Epoch [3915/20000], Loss: 174.9469451904297, Entropy -204.26171875, Learning Rate: 0.000625\n",
      "Epoch [3916/20000], Loss: 174.68614196777344, Entropy -215.3002471923828, Learning Rate: 0.000625\n",
      "Epoch [3917/20000], Loss: 170.27027893066406, Entropy -219.4684295654297, Learning Rate: 0.000625\n",
      "Epoch [3918/20000], Loss: 188.47096252441406, Entropy -227.9517822265625, Learning Rate: 0.000625\n",
      "Epoch [3919/20000], Loss: 179.36761474609375, Entropy -219.0563201904297, Learning Rate: 0.000625\n",
      "Epoch [3920/20000], Loss: 164.18923950195312, Entropy -211.63217163085938, Learning Rate: 0.000625\n",
      "Epoch [3921/20000], Loss: 175.1326904296875, Entropy -214.3955078125, Learning Rate: 0.000625\n",
      "Epoch [3922/20000], Loss: 176.37242126464844, Entropy -210.21861267089844, Learning Rate: 0.000625\n",
      "Epoch [3923/20000], Loss: 167.32568359375, Entropy -207.225341796875, Learning Rate: 0.000625\n",
      "Epoch [3924/20000], Loss: 176.15675354003906, Entropy -215.85498046875, Learning Rate: 0.000625\n",
      "Epoch [3925/20000], Loss: 176.02589416503906, Entropy -211.86758422851562, Learning Rate: 0.000625\n",
      "Epoch [3926/20000], Loss: 174.5011749267578, Entropy -215.49307250976562, Learning Rate: 0.000625\n",
      "Epoch [3927/20000], Loss: 174.18060302734375, Entropy -210.49136352539062, Learning Rate: 0.000625\n",
      "Epoch [3928/20000], Loss: 178.32113647460938, Entropy -218.78988647460938, Learning Rate: 0.000625\n",
      "Epoch [3929/20000], Loss: 178.0021514892578, Entropy -214.7154998779297, Learning Rate: 0.000625\n",
      "Epoch [3930/20000], Loss: 178.38455200195312, Entropy -217.41539001464844, Learning Rate: 0.000625\n",
      "Epoch [3931/20000], Loss: 184.49229431152344, Entropy -233.9507293701172, Learning Rate: 0.000625\n",
      "Epoch [3932/20000], Loss: 163.33447265625, Entropy -205.69931030273438, Learning Rate: 0.000625\n",
      "Epoch [3933/20000], Loss: 174.4488525390625, Entropy -215.21533203125, Learning Rate: 0.000625\n",
      "Epoch [3934/20000], Loss: 180.14683532714844, Entropy -227.2748565673828, Learning Rate: 0.000625\n",
      "Epoch [3935/20000], Loss: 186.16629028320312, Entropy -230.80438232421875, Learning Rate: 0.000625\n",
      "Epoch [3936/20000], Loss: 189.7230224609375, Entropy -233.02450561523438, Learning Rate: 0.000625\n",
      "Epoch [3937/20000], Loss: 176.9090118408203, Entropy -209.56103515625, Learning Rate: 0.000625\n",
      "Epoch [3938/20000], Loss: 177.2752227783203, Entropy -219.1417236328125, Learning Rate: 0.000625\n",
      "Epoch [3939/20000], Loss: 184.5477752685547, Entropy -217.20693969726562, Learning Rate: 0.000625\n",
      "Epoch [3940/20000], Loss: 175.1549072265625, Entropy -212.94320678710938, Learning Rate: 0.000625\n",
      "Epoch [3941/20000], Loss: 190.30380249023438, Entropy -232.2813262939453, Learning Rate: 0.000625\n",
      "Epoch [3942/20000], Loss: 177.0364532470703, Entropy -218.62908935546875, Learning Rate: 0.000625\n",
      "Epoch [3943/20000], Loss: 184.08575439453125, Entropy -224.01638793945312, Learning Rate: 0.000625\n",
      "Epoch [3944/20000], Loss: 171.56170654296875, Entropy -206.45632934570312, Learning Rate: 0.000625\n",
      "Epoch [3945/20000], Loss: 175.3532257080078, Entropy -210.19436645507812, Learning Rate: 0.000625\n",
      "Epoch [3946/20000], Loss: 173.91880798339844, Entropy -209.96609497070312, Learning Rate: 0.000625\n",
      "Epoch [3947/20000], Loss: 179.65200805664062, Entropy -215.5997314453125, Learning Rate: 0.000625\n",
      "Epoch [3948/20000], Loss: 176.5634307861328, Entropy -218.45407104492188, Learning Rate: 0.000625\n",
      "Epoch [3949/20000], Loss: 183.8375244140625, Entropy -214.61819458007812, Learning Rate: 0.000625\n",
      "Epoch [3950/20000], Loss: 188.65025329589844, Entropy -229.42166137695312, Learning Rate: 0.000625\n",
      "Epoch [3951/20000], Loss: 182.74063110351562, Entropy -220.5691375732422, Learning Rate: 0.000625\n",
      "Epoch [3952/20000], Loss: 184.44151306152344, Entropy -226.55825805664062, Learning Rate: 0.000625\n",
      "Epoch [3953/20000], Loss: 186.658935546875, Entropy -221.86935424804688, Learning Rate: 0.000625\n",
      "Epoch [3954/20000], Loss: 177.29981994628906, Entropy -217.33648681640625, Learning Rate: 0.000625\n",
      "Epoch [3955/20000], Loss: 183.16580200195312, Entropy -222.89450073242188, Learning Rate: 0.000625\n",
      "Epoch [3956/20000], Loss: 168.66123962402344, Entropy -206.650146484375, Learning Rate: 0.000625\n",
      "Epoch [3957/20000], Loss: 181.46524047851562, Entropy -219.20050048828125, Learning Rate: 0.000625\n",
      "Epoch [3958/20000], Loss: 176.7899169921875, Entropy -211.2150421142578, Learning Rate: 0.000625\n",
      "Epoch [3959/20000], Loss: 176.24844360351562, Entropy -212.7767791748047, Learning Rate: 0.000625\n",
      "Epoch [3960/20000], Loss: 175.03309631347656, Entropy -215.34164428710938, Learning Rate: 0.000625\n",
      "Epoch [3961/20000], Loss: 180.56820678710938, Entropy -226.98597717285156, Learning Rate: 0.000625\n",
      "Epoch [3962/20000], Loss: 178.98941040039062, Entropy -214.48663330078125, Learning Rate: 0.000625\n",
      "Epoch [3963/20000], Loss: 172.61740112304688, Entropy -211.06161499023438, Learning Rate: 0.000625\n",
      "Epoch [3964/20000], Loss: 172.7734375, Entropy -207.6813201904297, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3965/20000], Loss: 171.46641540527344, Entropy -207.89645385742188, Learning Rate: 0.000625\n",
      "Epoch [3966/20000], Loss: 178.93746948242188, Entropy -208.27401733398438, Learning Rate: 0.000625\n",
      "Epoch [3967/20000], Loss: 171.3600616455078, Entropy -212.2745819091797, Learning Rate: 0.000625\n",
      "Epoch [3968/20000], Loss: 176.9078369140625, Entropy -215.36297607421875, Learning Rate: 0.000625\n",
      "Epoch [3969/20000], Loss: 177.01902770996094, Entropy -213.38185119628906, Learning Rate: 0.000625\n",
      "Epoch [3970/20000], Loss: 166.8234405517578, Entropy -196.49612426757812, Learning Rate: 0.000625\n",
      "Epoch [3971/20000], Loss: 167.3090057373047, Entropy -205.66339111328125, Learning Rate: 0.000625\n",
      "Epoch [3972/20000], Loss: 169.44879150390625, Entropy -204.51589965820312, Learning Rate: 0.000625\n",
      "Epoch [3973/20000], Loss: 181.69061279296875, Entropy -226.18150329589844, Learning Rate: 0.000625\n",
      "Epoch [3974/20000], Loss: 186.14547729492188, Entropy -220.49143981933594, Learning Rate: 0.000625\n",
      "Epoch [3975/20000], Loss: 180.50424194335938, Entropy -219.094970703125, Learning Rate: 0.000625\n",
      "Epoch [3976/20000], Loss: 176.62594604492188, Entropy -218.36549377441406, Learning Rate: 0.000625\n",
      "Epoch [3977/20000], Loss: 185.87060546875, Entropy -216.5313720703125, Learning Rate: 0.000625\n",
      "Epoch [3978/20000], Loss: 175.59837341308594, Entropy -212.8907012939453, Learning Rate: 0.000625\n",
      "Epoch [3979/20000], Loss: 181.0286865234375, Entropy -220.45733642578125, Learning Rate: 0.000625\n",
      "Epoch [3980/20000], Loss: 174.69186401367188, Entropy -206.81533813476562, Learning Rate: 0.000625\n",
      "Epoch [3981/20000], Loss: 171.98583984375, Entropy -212.04901123046875, Learning Rate: 0.000625\n",
      "Epoch [3982/20000], Loss: 169.33645629882812, Entropy -206.00982666015625, Learning Rate: 0.000625\n",
      "Epoch [3983/20000], Loss: 169.165283203125, Entropy -211.24920654296875, Learning Rate: 0.000625\n",
      "Epoch [3984/20000], Loss: 177.9845733642578, Entropy -217.386474609375, Learning Rate: 0.000625\n",
      "Epoch [3985/20000], Loss: 167.4925079345703, Entropy -201.1823272705078, Learning Rate: 0.000625\n",
      "Epoch [3986/20000], Loss: 182.00108337402344, Entropy -216.9416961669922, Learning Rate: 0.000625\n",
      "Epoch [3987/20000], Loss: 181.3108367919922, Entropy -222.40774536132812, Learning Rate: 0.000625\n",
      "Epoch [3988/20000], Loss: 180.5018310546875, Entropy -225.30697631835938, Learning Rate: 0.000625\n",
      "Epoch [3989/20000], Loss: 174.95590209960938, Entropy -212.25816345214844, Learning Rate: 0.000625\n",
      "Epoch [3990/20000], Loss: 186.10816955566406, Entropy -221.5492706298828, Learning Rate: 0.000625\n",
      "Epoch [3991/20000], Loss: 187.08050537109375, Entropy -230.07325744628906, Learning Rate: 0.000625\n",
      "Epoch [3992/20000], Loss: 185.03173828125, Entropy -221.24327087402344, Learning Rate: 0.000625\n",
      "Epoch [3993/20000], Loss: 180.20654296875, Entropy -225.1970672607422, Learning Rate: 0.000625\n",
      "Epoch [3994/20000], Loss: 181.72816467285156, Entropy -221.27371215820312, Learning Rate: 0.000625\n",
      "Epoch [3995/20000], Loss: 176.6543426513672, Entropy -215.91952514648438, Learning Rate: 0.000625\n",
      "Epoch [3996/20000], Loss: 174.35308837890625, Entropy -214.30075073242188, Learning Rate: 0.000625\n",
      "Epoch [3997/20000], Loss: 177.5902557373047, Entropy -218.59817504882812, Learning Rate: 0.000625\n",
      "Epoch [3998/20000], Loss: 180.82046508789062, Entropy -225.63648986816406, Learning Rate: 0.000625\n",
      "Epoch [3999/20000], Loss: 180.10154724121094, Entropy -222.0406951904297, Learning Rate: 0.000625\n",
      "Epoch [4000/20000], Loss: 177.6355743408203, Entropy -213.4710693359375, Learning Rate: 0.000625\n",
      "Epoch [4001/20000], Loss: 172.17874145507812, Entropy -209.60186767578125, Learning Rate: 0.000625\n",
      "Epoch [4002/20000], Loss: 179.98574829101562, Entropy -210.3294677734375, Learning Rate: 0.000625\n",
      "Epoch [4003/20000], Loss: 172.10903930664062, Entropy -210.45089721679688, Learning Rate: 0.000625\n",
      "Epoch [4004/20000], Loss: 182.03456115722656, Entropy -210.8730926513672, Learning Rate: 0.000625\n",
      "Epoch [4005/20000], Loss: 170.3567657470703, Entropy -208.84805297851562, Learning Rate: 0.000625\n",
      "Epoch [4006/20000], Loss: 183.99072265625, Entropy -223.00970458984375, Learning Rate: 0.000625\n",
      "Epoch [4007/20000], Loss: 175.36468505859375, Entropy -213.53707885742188, Learning Rate: 0.000625\n",
      "Epoch [4008/20000], Loss: 172.36260986328125, Entropy -216.24807739257812, Learning Rate: 0.000625\n",
      "Epoch [4009/20000], Loss: 168.97117614746094, Entropy -210.47991943359375, Learning Rate: 0.000625\n",
      "Epoch [4010/20000], Loss: 176.92327880859375, Entropy -218.05238342285156, Learning Rate: 0.000625\n",
      "Epoch [4011/20000], Loss: 178.65008544921875, Entropy -220.93917846679688, Learning Rate: 0.000625\n",
      "Epoch [4012/20000], Loss: 179.33851623535156, Entropy -216.61801147460938, Learning Rate: 0.000625\n",
      "Epoch [4013/20000], Loss: 172.783203125, Entropy -203.2668914794922, Learning Rate: 0.000625\n",
      "Epoch [4014/20000], Loss: 179.1661376953125, Entropy -217.68386840820312, Learning Rate: 0.000625\n",
      "Epoch [4015/20000], Loss: 182.2511444091797, Entropy -216.67323303222656, Learning Rate: 0.000625\n",
      "Epoch [4016/20000], Loss: 172.53570556640625, Entropy -201.7659912109375, Learning Rate: 0.000625\n",
      "Epoch [4017/20000], Loss: 171.48208618164062, Entropy -214.92864990234375, Learning Rate: 0.000625\n",
      "Epoch [4018/20000], Loss: 183.36656188964844, Entropy -220.8914031982422, Learning Rate: 0.000625\n",
      "Epoch [4019/20000], Loss: 176.9023895263672, Entropy -213.83920288085938, Learning Rate: 0.000625\n",
      "Epoch [4020/20000], Loss: 181.37823486328125, Entropy -217.88319396972656, Learning Rate: 0.000625\n",
      "Epoch [4021/20000], Loss: 182.71510314941406, Entropy -224.06185913085938, Learning Rate: 0.000625\n",
      "Epoch [4022/20000], Loss: 176.16177368164062, Entropy -214.87530517578125, Learning Rate: 0.000625\n",
      "Epoch [4023/20000], Loss: 171.59921264648438, Entropy -207.68731689453125, Learning Rate: 0.000625\n",
      "Epoch [4024/20000], Loss: 177.7650146484375, Entropy -223.39183044433594, Learning Rate: 0.000625\n",
      "Epoch [4025/20000], Loss: 186.11065673828125, Entropy -230.19847106933594, Learning Rate: 0.000625\n",
      "Epoch [4026/20000], Loss: 178.69232177734375, Entropy -220.34434509277344, Learning Rate: 0.000625\n",
      "Epoch [4027/20000], Loss: 175.48480224609375, Entropy -218.9013671875, Learning Rate: 0.000625\n",
      "Epoch [4028/20000], Loss: 184.66729736328125, Entropy -220.30654907226562, Learning Rate: 0.000625\n",
      "Epoch [4029/20000], Loss: 177.71694946289062, Entropy -216.669189453125, Learning Rate: 0.000625\n",
      "Epoch [4030/20000], Loss: 173.06048583984375, Entropy -199.7010498046875, Learning Rate: 0.000625\n",
      "Epoch [4031/20000], Loss: 174.78042602539062, Entropy -219.6320343017578, Learning Rate: 0.000625\n",
      "Epoch [4032/20000], Loss: 177.12594604492188, Entropy -219.09963989257812, Learning Rate: 0.000625\n",
      "Epoch [4033/20000], Loss: 186.56114196777344, Entropy -222.28915405273438, Learning Rate: 0.000625\n",
      "Epoch [4034/20000], Loss: 175.89254760742188, Entropy -213.06671142578125, Learning Rate: 0.000625\n",
      "Epoch [4035/20000], Loss: 185.54354858398438, Entropy -226.6866912841797, Learning Rate: 0.000625\n",
      "Epoch [4036/20000], Loss: 174.90640258789062, Entropy -209.9046173095703, Learning Rate: 0.000625\n",
      "Epoch [4037/20000], Loss: 169.64117431640625, Entropy -210.36541748046875, Learning Rate: 0.000625\n",
      "Epoch [4038/20000], Loss: 186.33984375, Entropy -227.00453186035156, Learning Rate: 0.000625\n",
      "Epoch [4039/20000], Loss: 176.82945251464844, Entropy -213.57168579101562, Learning Rate: 0.000625\n",
      "Epoch [4040/20000], Loss: 173.8924102783203, Entropy -218.61582946777344, Learning Rate: 0.000625\n",
      "Epoch [4041/20000], Loss: 175.5783233642578, Entropy -219.0876922607422, Learning Rate: 0.000625\n",
      "Epoch [4042/20000], Loss: 166.01443481445312, Entropy -201.8427734375, Learning Rate: 0.000625\n",
      "Epoch [4043/20000], Loss: 170.39642333984375, Entropy -209.61822509765625, Learning Rate: 0.000625\n",
      "Epoch [4044/20000], Loss: 182.46922302246094, Entropy -213.9957275390625, Learning Rate: 0.000625\n",
      "Epoch [4045/20000], Loss: 165.95468139648438, Entropy -204.52493286132812, Learning Rate: 0.000625\n",
      "Epoch [4046/20000], Loss: 168.563232421875, Entropy -210.09317016601562, Learning Rate: 0.000625\n",
      "Epoch [4047/20000], Loss: 175.56793212890625, Entropy -219.44854736328125, Learning Rate: 0.000625\n",
      "Epoch [4048/20000], Loss: 172.912353515625, Entropy -209.08218383789062, Learning Rate: 0.000625\n",
      "Epoch [4049/20000], Loss: 180.58587646484375, Entropy -219.2711944580078, Learning Rate: 0.000625\n",
      "Epoch [4050/20000], Loss: 176.30320739746094, Entropy -219.9612274169922, Learning Rate: 0.000625\n",
      "Epoch [4051/20000], Loss: 176.77438354492188, Entropy -218.05914306640625, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4052/20000], Loss: 172.3992156982422, Entropy -206.5894317626953, Learning Rate: 0.000625\n",
      "Epoch [4053/20000], Loss: 180.16293334960938, Entropy -213.62496948242188, Learning Rate: 0.000625\n",
      "Epoch [4054/20000], Loss: 181.46267700195312, Entropy -222.8195037841797, Learning Rate: 0.000625\n",
      "Epoch [4055/20000], Loss: 174.119384765625, Entropy -209.63168334960938, Learning Rate: 0.000625\n",
      "Epoch [4056/20000], Loss: 181.5585479736328, Entropy -211.30270385742188, Learning Rate: 0.000625\n",
      "Epoch [4057/20000], Loss: 171.2571563720703, Entropy -206.8966064453125, Learning Rate: 0.000625\n",
      "Epoch [4058/20000], Loss: 189.3028564453125, Entropy -225.48741149902344, Learning Rate: 0.000625\n",
      "Epoch [4059/20000], Loss: 173.36447143554688, Entropy -213.6754150390625, Learning Rate: 0.000625\n",
      "Epoch [4060/20000], Loss: 172.30369567871094, Entropy -209.46633911132812, Learning Rate: 0.000625\n",
      "Epoch [4061/20000], Loss: 176.1862335205078, Entropy -217.47747802734375, Learning Rate: 0.000625\n",
      "Epoch [4062/20000], Loss: 187.7037811279297, Entropy -217.92446899414062, Learning Rate: 0.000625\n",
      "Epoch [4063/20000], Loss: 174.3374786376953, Entropy -210.86392211914062, Learning Rate: 0.000625\n",
      "Epoch [4064/20000], Loss: 179.84324645996094, Entropy -214.24813842773438, Learning Rate: 0.000625\n",
      "Epoch [4065/20000], Loss: 174.1336669921875, Entropy -212.09503173828125, Learning Rate: 0.000625\n",
      "Epoch [4066/20000], Loss: 169.2881622314453, Entropy -209.8482208251953, Learning Rate: 0.000625\n",
      "Epoch [4067/20000], Loss: 181.09913635253906, Entropy -216.23342895507812, Learning Rate: 0.000625\n",
      "Epoch [4068/20000], Loss: 175.38331604003906, Entropy -212.89825439453125, Learning Rate: 0.000625\n",
      "Epoch [4069/20000], Loss: 177.4054718017578, Entropy -209.50796508789062, Learning Rate: 0.000625\n",
      "Epoch [4070/20000], Loss: 184.64328002929688, Entropy -226.8518829345703, Learning Rate: 0.000625\n",
      "Epoch [4071/20000], Loss: 186.36061096191406, Entropy -214.50759887695312, Learning Rate: 0.000625\n",
      "Epoch [4072/20000], Loss: 165.59779357910156, Entropy -200.5054473876953, Learning Rate: 0.000625\n",
      "Epoch [4073/20000], Loss: 166.6444854736328, Entropy -204.76055908203125, Learning Rate: 0.000625\n",
      "Epoch [4074/20000], Loss: 171.0240478515625, Entropy -207.5758056640625, Learning Rate: 0.000625\n",
      "Epoch [4075/20000], Loss: 188.9761199951172, Entropy -229.27676391601562, Learning Rate: 0.000625\n",
      "Epoch [4076/20000], Loss: 185.4419403076172, Entropy -224.56007385253906, Learning Rate: 0.000625\n",
      "Epoch [4077/20000], Loss: 173.8663787841797, Entropy -213.44528198242188, Learning Rate: 0.000625\n",
      "Epoch [4078/20000], Loss: 180.73553466796875, Entropy -213.2290802001953, Learning Rate: 0.000625\n",
      "Epoch [4079/20000], Loss: 167.62924194335938, Entropy -209.95751953125, Learning Rate: 0.000625\n",
      "Epoch [4080/20000], Loss: 180.0271453857422, Entropy -218.00454711914062, Learning Rate: 0.000625\n",
      "Epoch [4081/20000], Loss: 182.34593200683594, Entropy -221.78384399414062, Learning Rate: 0.000625\n",
      "Epoch [4082/20000], Loss: 176.57725524902344, Entropy -215.87876892089844, Learning Rate: 0.000625\n",
      "Epoch [4083/20000], Loss: 173.53060913085938, Entropy -215.89773559570312, Learning Rate: 0.000625\n",
      "Epoch [4084/20000], Loss: 172.23727416992188, Entropy -207.396240234375, Learning Rate: 0.000625\n",
      "Epoch [4085/20000], Loss: 190.59658813476562, Entropy -232.70751953125, Learning Rate: 0.000625\n",
      "Epoch [4086/20000], Loss: 166.0112762451172, Entropy -204.7964630126953, Learning Rate: 0.000625\n",
      "Epoch [4087/20000], Loss: 182.14315795898438, Entropy -221.19088745117188, Learning Rate: 0.000625\n",
      "Epoch [4088/20000], Loss: 181.43527221679688, Entropy -227.673095703125, Learning Rate: 0.000625\n",
      "Epoch [4089/20000], Loss: 167.16949462890625, Entropy -210.14617919921875, Learning Rate: 0.000625\n",
      "Epoch [4090/20000], Loss: 171.6448974609375, Entropy -206.64476013183594, Learning Rate: 0.000625\n",
      "Epoch [4091/20000], Loss: 171.5015106201172, Entropy -212.67431640625, Learning Rate: 0.000625\n",
      "Epoch [4092/20000], Loss: 184.99835205078125, Entropy -226.3970489501953, Learning Rate: 0.000625\n",
      "Epoch [4093/20000], Loss: 177.78968811035156, Entropy -222.16873168945312, Learning Rate: 0.000625\n",
      "Epoch [4094/20000], Loss: 165.00814819335938, Entropy -205.94345092773438, Learning Rate: 0.000625\n",
      "Epoch [4095/20000], Loss: 175.52357482910156, Entropy -209.49795532226562, Learning Rate: 0.000625\n",
      "Epoch [4096/20000], Loss: 174.18768310546875, Entropy -209.21481323242188, Learning Rate: 0.000625\n",
      "Epoch [4097/20000], Loss: 175.2899169921875, Entropy -214.55386352539062, Learning Rate: 0.000625\n",
      "Epoch [4098/20000], Loss: 175.28335571289062, Entropy -211.2044219970703, Learning Rate: 0.000625\n",
      "Epoch [4099/20000], Loss: 181.12022399902344, Entropy -222.66439819335938, Learning Rate: 0.000625\n",
      "Epoch [4100/20000], Loss: 174.8855438232422, Entropy -209.06787109375, Learning Rate: 0.000625\n",
      "Epoch [4101/20000], Loss: 173.20120239257812, Entropy -212.917724609375, Learning Rate: 0.000625\n",
      "Epoch [4102/20000], Loss: 171.42283630371094, Entropy -210.31417846679688, Learning Rate: 0.000625\n",
      "Epoch [4103/20000], Loss: 175.5510711669922, Entropy -211.88540649414062, Learning Rate: 0.000625\n",
      "Epoch [4104/20000], Loss: 184.87460327148438, Entropy -226.19509887695312, Learning Rate: 0.000625\n",
      "Epoch [4105/20000], Loss: 193.90481567382812, Entropy -243.53125, Learning Rate: 0.000625\n",
      "Epoch [4106/20000], Loss: 185.7716522216797, Entropy -221.4190673828125, Learning Rate: 0.000625\n",
      "Epoch [4107/20000], Loss: 174.2403106689453, Entropy -215.84031677246094, Learning Rate: 0.000625\n",
      "Epoch [4108/20000], Loss: 181.44444274902344, Entropy -214.37501525878906, Learning Rate: 0.000625\n",
      "Epoch [4109/20000], Loss: 173.17263793945312, Entropy -208.84600830078125, Learning Rate: 0.000625\n",
      "Epoch [4110/20000], Loss: 175.92063903808594, Entropy -215.75669860839844, Learning Rate: 0.000625\n",
      "Epoch [4111/20000], Loss: 170.90065002441406, Entropy -213.36627197265625, Learning Rate: 0.000625\n",
      "Epoch [4112/20000], Loss: 184.06285095214844, Entropy -223.45765686035156, Learning Rate: 0.000625\n",
      "Epoch [4113/20000], Loss: 194.2496795654297, Entropy -232.82223510742188, Learning Rate: 0.000625\n",
      "Epoch [4114/20000], Loss: 176.3486785888672, Entropy -214.37423706054688, Learning Rate: 0.000625\n",
      "Epoch [4115/20000], Loss: 177.45819091796875, Entropy -217.17489624023438, Learning Rate: 0.000625\n",
      "Epoch [4116/20000], Loss: 170.52584838867188, Entropy -209.2166748046875, Learning Rate: 0.000625\n",
      "Epoch [4117/20000], Loss: 179.00555419921875, Entropy -221.65187072753906, Learning Rate: 0.000625\n",
      "Epoch [4118/20000], Loss: 170.08328247070312, Entropy -207.64524841308594, Learning Rate: 0.000625\n",
      "Epoch [4119/20000], Loss: 176.41078186035156, Entropy -219.87002563476562, Learning Rate: 0.000625\n",
      "Epoch [4120/20000], Loss: 170.932861328125, Entropy -206.87367248535156, Learning Rate: 0.000625\n",
      "Epoch [4121/20000], Loss: 171.5301513671875, Entropy -211.83621215820312, Learning Rate: 0.000625\n",
      "Epoch [4122/20000], Loss: 178.7425994873047, Entropy -223.39251708984375, Learning Rate: 0.000625\n",
      "Epoch [4123/20000], Loss: 182.80545043945312, Entropy -222.19798278808594, Learning Rate: 0.000625\n",
      "Epoch [4124/20000], Loss: 174.74649047851562, Entropy -212.938720703125, Learning Rate: 0.000625\n",
      "Epoch [4125/20000], Loss: 172.16395568847656, Entropy -212.82386779785156, Learning Rate: 0.000625\n",
      "Epoch [4126/20000], Loss: 182.67434692382812, Entropy -222.12094116210938, Learning Rate: 0.000625\n",
      "Epoch [4127/20000], Loss: 190.5917510986328, Entropy -238.22467041015625, Learning Rate: 0.000625\n",
      "Epoch [4128/20000], Loss: 175.3716278076172, Entropy -211.47540283203125, Learning Rate: 0.000625\n",
      "Epoch [4129/20000], Loss: 179.55609130859375, Entropy -215.91204833984375, Learning Rate: 0.000625\n",
      "Epoch [4130/20000], Loss: 164.91314697265625, Entropy -197.89434814453125, Learning Rate: 0.000625\n",
      "Epoch [4131/20000], Loss: 176.10479736328125, Entropy -213.9107666015625, Learning Rate: 0.000625\n",
      "Epoch [4132/20000], Loss: 169.27261352539062, Entropy -212.44393920898438, Learning Rate: 0.000625\n",
      "Epoch [4133/20000], Loss: 169.48779296875, Entropy -206.81259155273438, Learning Rate: 0.000625\n",
      "Epoch [4134/20000], Loss: 182.6039581298828, Entropy -226.70718383789062, Learning Rate: 0.0003125\n",
      "Epoch [4135/20000], Loss: 176.28395080566406, Entropy -213.30201721191406, Learning Rate: 0.0003125\n",
      "Epoch [4136/20000], Loss: 185.2967987060547, Entropy -224.04319763183594, Learning Rate: 0.0003125\n",
      "Epoch [4137/20000], Loss: 173.58712768554688, Entropy -205.84710693359375, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4138/20000], Loss: 172.3380126953125, Entropy -212.27249145507812, Learning Rate: 0.0003125\n",
      "Epoch [4139/20000], Loss: 177.14476013183594, Entropy -206.1450958251953, Learning Rate: 0.0003125\n",
      "Epoch [4140/20000], Loss: 176.03773498535156, Entropy -209.0830535888672, Learning Rate: 0.0003125\n",
      "Epoch [4141/20000], Loss: 185.98489379882812, Entropy -227.86460876464844, Learning Rate: 0.0003125\n",
      "Epoch [4142/20000], Loss: 178.43377685546875, Entropy -216.07928466796875, Learning Rate: 0.0003125\n",
      "Epoch [4143/20000], Loss: 176.66561889648438, Entropy -218.3973846435547, Learning Rate: 0.0003125\n",
      "Epoch [4144/20000], Loss: 177.71658325195312, Entropy -217.89144897460938, Learning Rate: 0.0003125\n",
      "Epoch [4145/20000], Loss: 167.05677795410156, Entropy -210.9077911376953, Learning Rate: 0.0003125\n",
      "Epoch [4146/20000], Loss: 176.2644805908203, Entropy -216.52703857421875, Learning Rate: 0.0003125\n",
      "Epoch [4147/20000], Loss: 171.58448791503906, Entropy -211.95840454101562, Learning Rate: 0.0003125\n",
      "Epoch [4148/20000], Loss: 179.46160888671875, Entropy -217.07293701171875, Learning Rate: 0.0003125\n",
      "Epoch [4149/20000], Loss: 182.6975860595703, Entropy -226.55453491210938, Learning Rate: 0.0003125\n",
      "Epoch [4150/20000], Loss: 186.13040161132812, Entropy -226.23904418945312, Learning Rate: 0.0003125\n",
      "Epoch [4151/20000], Loss: 174.6654510498047, Entropy -204.4985809326172, Learning Rate: 0.0003125\n",
      "Epoch [4152/20000], Loss: 174.78750610351562, Entropy -216.6168670654297, Learning Rate: 0.0003125\n",
      "Epoch [4153/20000], Loss: 176.53834533691406, Entropy -216.35867309570312, Learning Rate: 0.0003125\n",
      "Epoch [4154/20000], Loss: 180.34658813476562, Entropy -218.31874084472656, Learning Rate: 0.0003125\n",
      "Epoch [4155/20000], Loss: 172.38522338867188, Entropy -208.964599609375, Learning Rate: 0.0003125\n",
      "Epoch [4156/20000], Loss: 175.46725463867188, Entropy -208.8817596435547, Learning Rate: 0.0003125\n",
      "Epoch [4157/20000], Loss: 181.59568786621094, Entropy -218.85333251953125, Learning Rate: 0.0003125\n",
      "Epoch [4158/20000], Loss: 167.23719787597656, Entropy -200.12881469726562, Learning Rate: 0.0003125\n",
      "Epoch [4159/20000], Loss: 176.35931396484375, Entropy -218.17381286621094, Learning Rate: 0.0003125\n",
      "Epoch [4160/20000], Loss: 180.49392700195312, Entropy -217.70765686035156, Learning Rate: 0.0003125\n",
      "Epoch [4161/20000], Loss: 183.17745971679688, Entropy -224.9077911376953, Learning Rate: 0.0003125\n",
      "Epoch [4162/20000], Loss: 183.1940155029297, Entropy -213.55674743652344, Learning Rate: 0.0003125\n",
      "Epoch [4163/20000], Loss: 170.22877502441406, Entropy -206.72665405273438, Learning Rate: 0.0003125\n",
      "Epoch [4164/20000], Loss: 182.73500061035156, Entropy -224.3596954345703, Learning Rate: 0.0003125\n",
      "Epoch [4165/20000], Loss: 175.31983947753906, Entropy -220.55935668945312, Learning Rate: 0.0003125\n",
      "Epoch [4166/20000], Loss: 178.1490020751953, Entropy -212.5113983154297, Learning Rate: 0.0003125\n",
      "Epoch [4167/20000], Loss: 175.1082000732422, Entropy -208.27633666992188, Learning Rate: 0.0003125\n",
      "Epoch [4168/20000], Loss: 189.48997497558594, Entropy -232.3816375732422, Learning Rate: 0.0003125\n",
      "Epoch [4169/20000], Loss: 186.89320373535156, Entropy -225.50564575195312, Learning Rate: 0.0003125\n",
      "Epoch [4170/20000], Loss: 174.02163696289062, Entropy -211.21240234375, Learning Rate: 0.0003125\n",
      "Epoch [4171/20000], Loss: 177.14935302734375, Entropy -218.37039184570312, Learning Rate: 0.0003125\n",
      "Epoch [4172/20000], Loss: 171.70925903320312, Entropy -207.62054443359375, Learning Rate: 0.0003125\n",
      "Epoch [4173/20000], Loss: 171.8772735595703, Entropy -205.52574157714844, Learning Rate: 0.0003125\n",
      "Epoch [4174/20000], Loss: 171.57669067382812, Entropy -207.20852661132812, Learning Rate: 0.0003125\n",
      "Epoch [4175/20000], Loss: 173.14381408691406, Entropy -213.40420532226562, Learning Rate: 0.0003125\n",
      "Epoch [4176/20000], Loss: 169.60299682617188, Entropy -208.69827270507812, Learning Rate: 0.0003125\n",
      "Epoch [4177/20000], Loss: 175.74539184570312, Entropy -213.31008911132812, Learning Rate: 0.0003125\n",
      "Epoch [4178/20000], Loss: 177.63197326660156, Entropy -208.52699279785156, Learning Rate: 0.0003125\n",
      "Epoch [4179/20000], Loss: 185.67762756347656, Entropy -219.36898803710938, Learning Rate: 0.0003125\n",
      "Epoch [4180/20000], Loss: 177.71653747558594, Entropy -213.03213500976562, Learning Rate: 0.0003125\n",
      "Epoch [4181/20000], Loss: 181.12754821777344, Entropy -225.86764526367188, Learning Rate: 0.0003125\n",
      "Epoch [4182/20000], Loss: 174.31912231445312, Entropy -210.5883026123047, Learning Rate: 0.0003125\n",
      "Epoch [4183/20000], Loss: 182.01226806640625, Entropy -218.37269592285156, Learning Rate: 0.0003125\n",
      "Epoch [4184/20000], Loss: 177.50669860839844, Entropy -220.5058135986328, Learning Rate: 0.0003125\n",
      "Epoch [4185/20000], Loss: 174.1036834716797, Entropy -212.67254638671875, Learning Rate: 0.0003125\n",
      "Epoch [4186/20000], Loss: 175.572265625, Entropy -212.37887573242188, Learning Rate: 0.0003125\n",
      "Epoch [4187/20000], Loss: 175.42520141601562, Entropy -213.36831665039062, Learning Rate: 0.0003125\n",
      "Epoch [4188/20000], Loss: 181.61715698242188, Entropy -214.97760009765625, Learning Rate: 0.0003125\n",
      "Epoch [4189/20000], Loss: 187.6878204345703, Entropy -226.26556396484375, Learning Rate: 0.0003125\n",
      "Epoch [4190/20000], Loss: 178.2411346435547, Entropy -216.6290283203125, Learning Rate: 0.0003125\n",
      "Epoch [4191/20000], Loss: 180.5116729736328, Entropy -215.6593780517578, Learning Rate: 0.0003125\n",
      "Epoch [4192/20000], Loss: 171.82835388183594, Entropy -209.21580505371094, Learning Rate: 0.0003125\n",
      "Epoch [4193/20000], Loss: 167.98480224609375, Entropy -208.51092529296875, Learning Rate: 0.0003125\n",
      "Epoch [4194/20000], Loss: 171.55010986328125, Entropy -216.83071899414062, Learning Rate: 0.0003125\n",
      "Epoch [4195/20000], Loss: 169.8835906982422, Entropy -207.7876434326172, Learning Rate: 0.0003125\n",
      "Epoch [4196/20000], Loss: 173.697021484375, Entropy -211.0312957763672, Learning Rate: 0.0003125\n",
      "Epoch [4197/20000], Loss: 171.252197265625, Entropy -215.9549560546875, Learning Rate: 0.0003125\n",
      "Epoch [4198/20000], Loss: 190.03012084960938, Entropy -225.1739044189453, Learning Rate: 0.0003125\n",
      "Epoch [4199/20000], Loss: 168.2181854248047, Entropy -208.57254028320312, Learning Rate: 0.0003125\n",
      "Epoch [4200/20000], Loss: 177.57740783691406, Entropy -214.8854217529297, Learning Rate: 0.0003125\n",
      "Epoch [4201/20000], Loss: 187.1614227294922, Entropy -225.95648193359375, Learning Rate: 0.0003125\n",
      "Epoch [4202/20000], Loss: 183.95237731933594, Entropy -225.90333557128906, Learning Rate: 0.0003125\n",
      "Epoch [4203/20000], Loss: 184.77183532714844, Entropy -220.20672607421875, Learning Rate: 0.0003125\n",
      "Epoch [4204/20000], Loss: 169.98204040527344, Entropy -205.85879516601562, Learning Rate: 0.0003125\n",
      "Epoch [4205/20000], Loss: 172.56991577148438, Entropy -208.21856689453125, Learning Rate: 0.0003125\n",
      "Epoch [4206/20000], Loss: 183.0911407470703, Entropy -220.24501037597656, Learning Rate: 0.0003125\n",
      "Epoch [4207/20000], Loss: 178.7124481201172, Entropy -217.21560668945312, Learning Rate: 0.0003125\n",
      "Epoch [4208/20000], Loss: 177.80157470703125, Entropy -221.20343017578125, Learning Rate: 0.0003125\n",
      "Epoch [4209/20000], Loss: 170.33595275878906, Entropy -212.5114288330078, Learning Rate: 0.0003125\n",
      "Epoch [4210/20000], Loss: 181.553466796875, Entropy -226.15756225585938, Learning Rate: 0.0003125\n",
      "Epoch [4211/20000], Loss: 170.39764404296875, Entropy -206.8492431640625, Learning Rate: 0.0003125\n",
      "Epoch [4212/20000], Loss: 178.40499877929688, Entropy -218.98184204101562, Learning Rate: 0.0003125\n",
      "Epoch [4213/20000], Loss: 174.08969116210938, Entropy -210.76632690429688, Learning Rate: 0.0003125\n",
      "Epoch [4214/20000], Loss: 176.7401580810547, Entropy -212.13462829589844, Learning Rate: 0.0003125\n",
      "Epoch [4215/20000], Loss: 167.43624877929688, Entropy -203.59913635253906, Learning Rate: 0.0003125\n",
      "Epoch [4216/20000], Loss: 179.02220153808594, Entropy -218.304443359375, Learning Rate: 0.0003125\n",
      "Epoch [4217/20000], Loss: 184.92881774902344, Entropy -228.61013793945312, Learning Rate: 0.0003125\n",
      "Epoch [4218/20000], Loss: 180.54856872558594, Entropy -220.14236450195312, Learning Rate: 0.0003125\n",
      "Epoch [4219/20000], Loss: 173.48342895507812, Entropy -211.05599975585938, Learning Rate: 0.0003125\n",
      "Epoch [4220/20000], Loss: 179.66404724121094, Entropy -219.26828002929688, Learning Rate: 0.0003125\n",
      "Epoch [4221/20000], Loss: 177.9867401123047, Entropy -220.4315185546875, Learning Rate: 0.0003125\n",
      "Epoch [4222/20000], Loss: 179.1720733642578, Entropy -218.82501220703125, Learning Rate: 0.0003125\n",
      "Epoch [4223/20000], Loss: 186.82603454589844, Entropy -223.13868713378906, Learning Rate: 0.0003125\n",
      "Epoch [4224/20000], Loss: 175.90069580078125, Entropy -213.19300842285156, Learning Rate: 0.0003125\n",
      "Epoch [4225/20000], Loss: 174.10049438476562, Entropy -207.03138732910156, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4226/20000], Loss: 177.4490203857422, Entropy -214.27005004882812, Learning Rate: 0.0003125\n",
      "Epoch [4227/20000], Loss: 171.2942657470703, Entropy -209.4279022216797, Learning Rate: 0.0003125\n",
      "Epoch [4228/20000], Loss: 169.26995849609375, Entropy -208.7446746826172, Learning Rate: 0.0003125\n",
      "Epoch [4229/20000], Loss: 182.98016357421875, Entropy -215.1219940185547, Learning Rate: 0.0003125\n",
      "Epoch [4230/20000], Loss: 183.38088989257812, Entropy -228.0645294189453, Learning Rate: 0.0003125\n",
      "Epoch [4231/20000], Loss: 172.1244354248047, Entropy -212.2197723388672, Learning Rate: 0.0003125\n",
      "Epoch [4232/20000], Loss: 172.93809509277344, Entropy -207.42645263671875, Learning Rate: 0.0003125\n",
      "Epoch [4233/20000], Loss: 174.6506805419922, Entropy -215.1859893798828, Learning Rate: 0.0003125\n",
      "Epoch [4234/20000], Loss: 169.0449981689453, Entropy -208.79612731933594, Learning Rate: 0.0003125\n",
      "Epoch [4235/20000], Loss: 177.08187866210938, Entropy -212.3809814453125, Learning Rate: 0.0003125\n",
      "Epoch [4236/20000], Loss: 168.00296020507812, Entropy -205.3870849609375, Learning Rate: 0.0003125\n",
      "Epoch [4237/20000], Loss: 179.30496215820312, Entropy -222.4111328125, Learning Rate: 0.0003125\n",
      "Epoch [4238/20000], Loss: 177.4904022216797, Entropy -210.8779296875, Learning Rate: 0.0003125\n",
      "Epoch [4239/20000], Loss: 176.3636474609375, Entropy -211.56683349609375, Learning Rate: 0.0003125\n",
      "Epoch [4240/20000], Loss: 182.75247192382812, Entropy -223.05763244628906, Learning Rate: 0.0003125\n",
      "Epoch [4241/20000], Loss: 165.964111328125, Entropy -204.15744018554688, Learning Rate: 0.0003125\n",
      "Epoch [4242/20000], Loss: 177.83615112304688, Entropy -219.0193328857422, Learning Rate: 0.0003125\n",
      "Epoch [4243/20000], Loss: 176.5697479248047, Entropy -213.71658325195312, Learning Rate: 0.0003125\n",
      "Epoch [4244/20000], Loss: 168.35194396972656, Entropy -206.17811584472656, Learning Rate: 0.0003125\n",
      "Epoch [4245/20000], Loss: 172.43504333496094, Entropy -211.30824279785156, Learning Rate: 0.0003125\n",
      "Epoch [4246/20000], Loss: 173.8844757080078, Entropy -208.68101501464844, Learning Rate: 0.0003125\n",
      "Epoch [4247/20000], Loss: 174.4384307861328, Entropy -212.00039672851562, Learning Rate: 0.0003125\n",
      "Epoch [4248/20000], Loss: 171.71075439453125, Entropy -207.51181030273438, Learning Rate: 0.0003125\n",
      "Epoch [4249/20000], Loss: 171.84664916992188, Entropy -212.3939971923828, Learning Rate: 0.0003125\n",
      "Epoch [4250/20000], Loss: 169.14859008789062, Entropy -207.81256103515625, Learning Rate: 0.0003125\n",
      "Epoch [4251/20000], Loss: 169.84686279296875, Entropy -209.35215759277344, Learning Rate: 0.0003125\n",
      "Epoch [4252/20000], Loss: 180.96377563476562, Entropy -220.31927490234375, Learning Rate: 0.0003125\n",
      "Epoch [4253/20000], Loss: 184.4979705810547, Entropy -226.30609130859375, Learning Rate: 0.0003125\n",
      "Epoch [4254/20000], Loss: 171.73965454101562, Entropy -211.2606658935547, Learning Rate: 0.0003125\n",
      "Epoch [4255/20000], Loss: 184.3657989501953, Entropy -218.0189208984375, Learning Rate: 0.0003125\n",
      "Epoch [4256/20000], Loss: 171.48802185058594, Entropy -213.09695434570312, Learning Rate: 0.0003125\n",
      "Epoch [4257/20000], Loss: 178.28231811523438, Entropy -219.56216430664062, Learning Rate: 0.0003125\n",
      "Epoch [4258/20000], Loss: 180.80902099609375, Entropy -221.1199188232422, Learning Rate: 0.0003125\n",
      "Epoch [4259/20000], Loss: 188.95925903320312, Entropy -206.78268432617188, Learning Rate: 0.0003125\n",
      "Epoch [4260/20000], Loss: 169.1378936767578, Entropy -204.01467895507812, Learning Rate: 0.0003125\n",
      "Epoch [4261/20000], Loss: 178.26571655273438, Entropy -216.53135681152344, Learning Rate: 0.0003125\n",
      "Epoch [4262/20000], Loss: 180.17837524414062, Entropy -216.78363037109375, Learning Rate: 0.0003125\n",
      "Epoch [4263/20000], Loss: 186.65919494628906, Entropy -223.6524658203125, Learning Rate: 0.0003125\n",
      "Epoch [4264/20000], Loss: 189.98580932617188, Entropy -231.19955444335938, Learning Rate: 0.0003125\n",
      "Epoch [4265/20000], Loss: 177.8486328125, Entropy -219.459716796875, Learning Rate: 0.0003125\n",
      "Epoch [4266/20000], Loss: 186.26919555664062, Entropy -225.15972900390625, Learning Rate: 0.0003125\n",
      "Epoch [4267/20000], Loss: 169.45265197753906, Entropy -208.5145721435547, Learning Rate: 0.0003125\n",
      "Epoch [4268/20000], Loss: 173.19131469726562, Entropy -212.53353881835938, Learning Rate: 0.0003125\n",
      "Epoch [4269/20000], Loss: 176.930419921875, Entropy -215.19882202148438, Learning Rate: 0.0003125\n",
      "Epoch [4270/20000], Loss: 179.06039428710938, Entropy -217.13223266601562, Learning Rate: 0.0003125\n",
      "Epoch [4271/20000], Loss: 176.8577117919922, Entropy -216.308837890625, Learning Rate: 0.0003125\n",
      "Epoch [4272/20000], Loss: 180.31570434570312, Entropy -217.37326049804688, Learning Rate: 0.0003125\n",
      "Epoch [4273/20000], Loss: 170.05157470703125, Entropy -213.23190307617188, Learning Rate: 0.0003125\n",
      "Epoch [4274/20000], Loss: 181.86016845703125, Entropy -219.41671752929688, Learning Rate: 0.0003125\n",
      "Epoch [4275/20000], Loss: 179.67916870117188, Entropy -216.192626953125, Learning Rate: 0.0003125\n",
      "Epoch [4276/20000], Loss: 179.5848388671875, Entropy -220.98672485351562, Learning Rate: 0.0003125\n",
      "Epoch [4277/20000], Loss: 176.3784637451172, Entropy -217.3615264892578, Learning Rate: 0.0003125\n",
      "Epoch [4278/20000], Loss: 172.85003662109375, Entropy -207.02630615234375, Learning Rate: 0.0003125\n",
      "Epoch [4279/20000], Loss: 175.2742462158203, Entropy -216.02235412597656, Learning Rate: 0.0003125\n",
      "Epoch [4280/20000], Loss: 199.91172790527344, Entropy -234.8427734375, Learning Rate: 0.0003125\n",
      "Epoch [4281/20000], Loss: 184.5158233642578, Entropy -224.5013427734375, Learning Rate: 0.0003125\n",
      "Epoch [4282/20000], Loss: 181.23095703125, Entropy -218.7978515625, Learning Rate: 0.0003125\n",
      "Epoch [4283/20000], Loss: 180.56727600097656, Entropy -220.584716796875, Learning Rate: 0.0003125\n",
      "Epoch [4284/20000], Loss: 186.33700561523438, Entropy -218.83944702148438, Learning Rate: 0.0003125\n",
      "Epoch [4285/20000], Loss: 177.26461791992188, Entropy -214.48440551757812, Learning Rate: 0.0003125\n",
      "Epoch [4286/20000], Loss: 177.48768615722656, Entropy -217.39825439453125, Learning Rate: 0.0003125\n",
      "Epoch [4287/20000], Loss: 164.74850463867188, Entropy -202.89804077148438, Learning Rate: 0.0003125\n",
      "Epoch [4288/20000], Loss: 174.09866333007812, Entropy -206.7022247314453, Learning Rate: 0.0003125\n",
      "Epoch [4289/20000], Loss: 180.8855743408203, Entropy -221.9420166015625, Learning Rate: 0.0003125\n",
      "Epoch [4290/20000], Loss: 174.8685302734375, Entropy -216.97999572753906, Learning Rate: 0.0003125\n",
      "Epoch [4291/20000], Loss: 174.02403259277344, Entropy -214.2032928466797, Learning Rate: 0.0003125\n",
      "Epoch [4292/20000], Loss: 183.16969299316406, Entropy -216.27389526367188, Learning Rate: 0.0003125\n",
      "Epoch [4293/20000], Loss: 176.92501831054688, Entropy -217.70748901367188, Learning Rate: 0.0003125\n",
      "Epoch [4294/20000], Loss: 176.25811767578125, Entropy -219.305419921875, Learning Rate: 0.0003125\n",
      "Epoch [4295/20000], Loss: 175.25657653808594, Entropy -216.7803955078125, Learning Rate: 0.0003125\n",
      "Epoch [4296/20000], Loss: 188.70733642578125, Entropy -228.12100219726562, Learning Rate: 0.0003125\n",
      "Epoch [4297/20000], Loss: 171.82301330566406, Entropy -205.10919189453125, Learning Rate: 0.0003125\n",
      "Epoch [4298/20000], Loss: 160.3944091796875, Entropy -205.46127319335938, Learning Rate: 0.0003125\n",
      "Epoch [4299/20000], Loss: 170.8629608154297, Entropy -201.14840698242188, Learning Rate: 0.0003125\n",
      "Epoch [4300/20000], Loss: 170.02999877929688, Entropy -204.22213745117188, Learning Rate: 0.0003125\n",
      "Epoch [4301/20000], Loss: 182.19334411621094, Entropy -227.6048583984375, Learning Rate: 0.0003125\n",
      "Epoch [4302/20000], Loss: 173.80850219726562, Entropy -211.5640106201172, Learning Rate: 0.0003125\n",
      "Epoch [4303/20000], Loss: 170.46578979492188, Entropy -206.26995849609375, Learning Rate: 0.0003125\n",
      "Epoch [4304/20000], Loss: 174.56402587890625, Entropy -214.9082794189453, Learning Rate: 0.0003125\n",
      "Epoch [4305/20000], Loss: 169.230712890625, Entropy -206.05819702148438, Learning Rate: 0.0003125\n",
      "Epoch [4306/20000], Loss: 175.13742065429688, Entropy -207.86126708984375, Learning Rate: 0.0003125\n",
      "Epoch [4307/20000], Loss: 170.38168334960938, Entropy -206.71141052246094, Learning Rate: 0.0003125\n",
      "Epoch [4308/20000], Loss: 171.14698791503906, Entropy -209.92669677734375, Learning Rate: 0.0003125\n",
      "Epoch [4309/20000], Loss: 174.5205078125, Entropy -210.70108032226562, Learning Rate: 0.0003125\n",
      "Epoch [4310/20000], Loss: 169.38235473632812, Entropy -206.2134552001953, Learning Rate: 0.0003125\n",
      "Epoch [4311/20000], Loss: 182.95252990722656, Entropy -221.55288696289062, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4312/20000], Loss: 185.23660278320312, Entropy -217.69921875, Learning Rate: 0.0003125\n",
      "Epoch [4313/20000], Loss: 177.7830352783203, Entropy -214.05007934570312, Learning Rate: 0.0003125\n",
      "Epoch [4314/20000], Loss: 168.17422485351562, Entropy -213.29257202148438, Learning Rate: 0.0003125\n",
      "Epoch [4315/20000], Loss: 182.82098388671875, Entropy -225.44859313964844, Learning Rate: 0.0003125\n",
      "Epoch [4316/20000], Loss: 174.8922882080078, Entropy -209.81410217285156, Learning Rate: 0.0003125\n",
      "Epoch [4317/20000], Loss: 178.72637939453125, Entropy -218.9393310546875, Learning Rate: 0.0003125\n",
      "Epoch [4318/20000], Loss: 172.3067626953125, Entropy -209.56765747070312, Learning Rate: 0.0003125\n",
      "Epoch [4319/20000], Loss: 170.22833251953125, Entropy -210.6378631591797, Learning Rate: 0.0003125\n",
      "Epoch [4320/20000], Loss: 212.13710021972656, Entropy -214.21060180664062, Learning Rate: 0.0003125\n",
      "Epoch [4321/20000], Loss: 183.92312622070312, Entropy -220.82522583007812, Learning Rate: 0.0003125\n",
      "Epoch [4322/20000], Loss: 170.33331298828125, Entropy -210.0419464111328, Learning Rate: 0.0003125\n",
      "Epoch [4323/20000], Loss: 168.3829345703125, Entropy -208.4942169189453, Learning Rate: 0.0003125\n",
      "Epoch [4324/20000], Loss: 169.39691162109375, Entropy -206.30233764648438, Learning Rate: 0.0003125\n",
      "Epoch [4325/20000], Loss: 179.3826904296875, Entropy -223.5193634033203, Learning Rate: 0.0003125\n",
      "Epoch [4326/20000], Loss: 179.3450927734375, Entropy -212.95738220214844, Learning Rate: 0.0003125\n",
      "Epoch [4327/20000], Loss: 166.19944763183594, Entropy -202.1607666015625, Learning Rate: 0.0003125\n",
      "Epoch [4328/20000], Loss: 179.761962890625, Entropy -220.53233337402344, Learning Rate: 0.0003125\n",
      "Epoch [4329/20000], Loss: 171.05282592773438, Entropy -209.38551330566406, Learning Rate: 0.0003125\n",
      "Epoch [4330/20000], Loss: 183.0635223388672, Entropy -221.45367431640625, Learning Rate: 0.0003125\n",
      "Epoch [4331/20000], Loss: 172.08026123046875, Entropy -209.32467651367188, Learning Rate: 0.0003125\n",
      "Epoch [4332/20000], Loss: 189.16600036621094, Entropy -227.7654266357422, Learning Rate: 0.0003125\n",
      "Epoch [4333/20000], Loss: 167.5251922607422, Entropy -213.9969024658203, Learning Rate: 0.0003125\n",
      "Epoch [4334/20000], Loss: 174.4954071044922, Entropy -208.1519012451172, Learning Rate: 0.0003125\n",
      "Epoch [4335/20000], Loss: 168.7584991455078, Entropy -205.4765625, Learning Rate: 0.0003125\n",
      "Epoch [4336/20000], Loss: 183.35061645507812, Entropy -221.28125, Learning Rate: 0.0003125\n",
      "Epoch [4337/20000], Loss: 177.97413635253906, Entropy -213.8882293701172, Learning Rate: 0.0003125\n",
      "Epoch [4338/20000], Loss: 171.5005340576172, Entropy -213.7474365234375, Learning Rate: 0.0003125\n",
      "Epoch [4339/20000], Loss: 174.4962921142578, Entropy -214.57876586914062, Learning Rate: 0.0003125\n",
      "Epoch [4340/20000], Loss: 173.62078857421875, Entropy -212.24124145507812, Learning Rate: 0.0003125\n",
      "Epoch [4341/20000], Loss: 178.9429168701172, Entropy -219.20455932617188, Learning Rate: 0.0003125\n",
      "Epoch [4342/20000], Loss: 168.90443420410156, Entropy -213.4457244873047, Learning Rate: 0.0003125\n",
      "Epoch [4343/20000], Loss: 175.65162658691406, Entropy -220.83705139160156, Learning Rate: 0.0003125\n",
      "Epoch [4344/20000], Loss: 170.8536376953125, Entropy -205.80484008789062, Learning Rate: 0.0003125\n",
      "Epoch [4345/20000], Loss: 170.34585571289062, Entropy -206.7718505859375, Learning Rate: 0.0003125\n",
      "Epoch [4346/20000], Loss: 183.87942504882812, Entropy -218.13795471191406, Learning Rate: 0.0003125\n",
      "Epoch [4347/20000], Loss: 176.698486328125, Entropy -218.6541290283203, Learning Rate: 0.0003125\n",
      "Epoch [4348/20000], Loss: 168.17747497558594, Entropy -199.15623474121094, Learning Rate: 0.0003125\n",
      "Epoch [4349/20000], Loss: 174.21681213378906, Entropy -213.6803436279297, Learning Rate: 0.0003125\n",
      "Epoch [4350/20000], Loss: 177.49325561523438, Entropy -212.6031494140625, Learning Rate: 0.0003125\n",
      "Epoch [4351/20000], Loss: 179.43795776367188, Entropy -224.19259643554688, Learning Rate: 0.0003125\n",
      "Epoch [4352/20000], Loss: 186.2704315185547, Entropy -222.05088806152344, Learning Rate: 0.0003125\n",
      "Epoch [4353/20000], Loss: 184.19252014160156, Entropy -225.78262329101562, Learning Rate: 0.0003125\n",
      "Epoch [4354/20000], Loss: 173.52029418945312, Entropy -201.12667846679688, Learning Rate: 0.0003125\n",
      "Epoch [4355/20000], Loss: 179.16456604003906, Entropy -218.36724853515625, Learning Rate: 0.0003125\n",
      "Epoch [4356/20000], Loss: 187.10247802734375, Entropy -231.76556396484375, Learning Rate: 0.0003125\n",
      "Epoch [4357/20000], Loss: 178.8585662841797, Entropy -210.3921661376953, Learning Rate: 0.0003125\n",
      "Epoch [4358/20000], Loss: 180.76055908203125, Entropy -218.77667236328125, Learning Rate: 0.0003125\n",
      "Epoch [4359/20000], Loss: 173.9011688232422, Entropy -214.50344848632812, Learning Rate: 0.0003125\n",
      "Epoch [4360/20000], Loss: 175.63644409179688, Entropy -215.33982849121094, Learning Rate: 0.0003125\n",
      "Epoch [4361/20000], Loss: 175.22938537597656, Entropy -216.4421844482422, Learning Rate: 0.0003125\n",
      "Epoch [4362/20000], Loss: 176.73292541503906, Entropy -211.5959014892578, Learning Rate: 0.0003125\n",
      "Epoch [4363/20000], Loss: 175.65797424316406, Entropy -212.07168579101562, Learning Rate: 0.0003125\n",
      "Epoch [4364/20000], Loss: 176.4827117919922, Entropy -211.08238220214844, Learning Rate: 0.0003125\n",
      "Epoch [4365/20000], Loss: 174.42572021484375, Entropy -209.4550018310547, Learning Rate: 0.0003125\n",
      "Epoch [4366/20000], Loss: 176.147705078125, Entropy -214.98934936523438, Learning Rate: 0.0003125\n",
      "Epoch [4367/20000], Loss: 179.20030212402344, Entropy -218.6474151611328, Learning Rate: 0.0003125\n",
      "Epoch [4368/20000], Loss: 174.329345703125, Entropy -213.93235778808594, Learning Rate: 0.0003125\n",
      "Epoch [4369/20000], Loss: 185.58087158203125, Entropy -225.08193969726562, Learning Rate: 0.0003125\n",
      "Epoch [4370/20000], Loss: 182.69754028320312, Entropy -216.2662811279297, Learning Rate: 0.0003125\n",
      "Epoch [4371/20000], Loss: 168.23313903808594, Entropy -202.99176025390625, Learning Rate: 0.0003125\n",
      "Epoch [4372/20000], Loss: 184.3016357421875, Entropy -220.9630889892578, Learning Rate: 0.0003125\n",
      "Epoch [4373/20000], Loss: 176.46878051757812, Entropy -221.7688446044922, Learning Rate: 0.0003125\n",
      "Epoch [4374/20000], Loss: 170.32347106933594, Entropy -206.29583740234375, Learning Rate: 0.0003125\n",
      "Epoch [4375/20000], Loss: 178.9711456298828, Entropy -224.91012573242188, Learning Rate: 0.0003125\n",
      "Epoch [4376/20000], Loss: 181.9149169921875, Entropy -220.48460388183594, Learning Rate: 0.0003125\n",
      "Epoch [4377/20000], Loss: 177.7332763671875, Entropy -212.6844482421875, Learning Rate: 0.0003125\n",
      "Epoch [4378/20000], Loss: 179.7622833251953, Entropy -215.42298889160156, Learning Rate: 0.0003125\n",
      "Epoch [4379/20000], Loss: 173.91297912597656, Entropy -206.55686950683594, Learning Rate: 0.0003125\n",
      "Epoch [4380/20000], Loss: 181.20338439941406, Entropy -219.1988525390625, Learning Rate: 0.0003125\n",
      "Epoch [4381/20000], Loss: 172.9486846923828, Entropy -213.68186950683594, Learning Rate: 0.0003125\n",
      "Epoch [4382/20000], Loss: 174.20504760742188, Entropy -217.04794311523438, Learning Rate: 0.0003125\n",
      "Epoch [4383/20000], Loss: 176.9183807373047, Entropy -216.85682678222656, Learning Rate: 0.0003125\n",
      "Epoch [4384/20000], Loss: 176.85189819335938, Entropy -220.6181182861328, Learning Rate: 0.0003125\n",
      "Epoch [4385/20000], Loss: 179.55978393554688, Entropy -218.28042602539062, Learning Rate: 0.0003125\n",
      "Epoch [4386/20000], Loss: 211.63462829589844, Entropy -219.70870971679688, Learning Rate: 0.0003125\n",
      "Epoch [4387/20000], Loss: 178.0972442626953, Entropy -209.248779296875, Learning Rate: 0.0003125\n",
      "Epoch [4388/20000], Loss: 176.04287719726562, Entropy -205.80018615722656, Learning Rate: 0.0003125\n",
      "Epoch [4389/20000], Loss: 178.65980529785156, Entropy -211.10116577148438, Learning Rate: 0.0003125\n",
      "Epoch [4390/20000], Loss: 174.55897521972656, Entropy -215.19760131835938, Learning Rate: 0.0003125\n",
      "Epoch [4391/20000], Loss: 177.07064819335938, Entropy -210.1881866455078, Learning Rate: 0.0003125\n",
      "Epoch [4392/20000], Loss: 172.63775634765625, Entropy -198.5757598876953, Learning Rate: 0.0003125\n",
      "Epoch [4393/20000], Loss: 178.98402404785156, Entropy -207.10916137695312, Learning Rate: 0.0003125\n",
      "Epoch [4394/20000], Loss: 177.95359802246094, Entropy -217.64053344726562, Learning Rate: 0.0003125\n",
      "Epoch [4395/20000], Loss: 175.98471069335938, Entropy -218.73452758789062, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4396/20000], Loss: 179.2685546875, Entropy -216.47567749023438, Learning Rate: 0.0003125\n",
      "Epoch [4397/20000], Loss: 177.6698760986328, Entropy -220.73631286621094, Learning Rate: 0.0003125\n",
      "Epoch [4398/20000], Loss: 181.42904663085938, Entropy -217.3065185546875, Learning Rate: 0.0003125\n",
      "Epoch [4399/20000], Loss: 180.1215362548828, Entropy -214.00526428222656, Learning Rate: 0.0003125\n",
      "Epoch [4400/20000], Loss: 174.94937133789062, Entropy -216.29196166992188, Learning Rate: 0.0003125\n",
      "Epoch [4401/20000], Loss: 168.86294555664062, Entropy -203.4417266845703, Learning Rate: 0.0003125\n",
      "Epoch [4402/20000], Loss: 184.3194580078125, Entropy -225.67520141601562, Learning Rate: 0.0003125\n",
      "Epoch [4403/20000], Loss: 177.973876953125, Entropy -217.9982147216797, Learning Rate: 0.0003125\n",
      "Epoch [4404/20000], Loss: 181.61508178710938, Entropy -216.4894561767578, Learning Rate: 0.0003125\n",
      "Epoch [4405/20000], Loss: 177.17388916015625, Entropy -212.27676391601562, Learning Rate: 0.0003125\n",
      "Epoch [4406/20000], Loss: 181.77870178222656, Entropy -222.7388153076172, Learning Rate: 0.0003125\n",
      "Epoch [4407/20000], Loss: 168.79861450195312, Entropy -207.59005737304688, Learning Rate: 0.0003125\n",
      "Epoch [4408/20000], Loss: 186.78184509277344, Entropy -227.07518005371094, Learning Rate: 0.0003125\n",
      "Epoch [4409/20000], Loss: 184.2389678955078, Entropy -228.2032928466797, Learning Rate: 0.0003125\n",
      "Epoch [4410/20000], Loss: 176.83639526367188, Entropy -213.2373809814453, Learning Rate: 0.0003125\n",
      "Epoch [4411/20000], Loss: 177.26612854003906, Entropy -208.35755920410156, Learning Rate: 0.0003125\n",
      "Epoch [4412/20000], Loss: 189.4739532470703, Entropy -230.33624267578125, Learning Rate: 0.0003125\n",
      "Epoch [4413/20000], Loss: 171.35623168945312, Entropy -207.9153289794922, Learning Rate: 0.0003125\n",
      "Epoch [4414/20000], Loss: 173.51560974121094, Entropy -212.74002075195312, Learning Rate: 0.0003125\n",
      "Epoch [4415/20000], Loss: 179.9463348388672, Entropy -215.8364715576172, Learning Rate: 0.0003125\n",
      "Epoch [4416/20000], Loss: 182.00811767578125, Entropy -225.28599548339844, Learning Rate: 0.0003125\n",
      "Epoch [4417/20000], Loss: 172.33656311035156, Entropy -210.94668579101562, Learning Rate: 0.0003125\n",
      "Epoch [4418/20000], Loss: 172.81564331054688, Entropy -200.33023071289062, Learning Rate: 0.0003125\n",
      "Epoch [4419/20000], Loss: 172.87318420410156, Entropy -214.6127471923828, Learning Rate: 0.0003125\n",
      "Epoch [4420/20000], Loss: 174.45797729492188, Entropy -216.9586181640625, Learning Rate: 0.0003125\n",
      "Epoch [4421/20000], Loss: 171.1593780517578, Entropy -211.4061737060547, Learning Rate: 0.0003125\n",
      "Epoch [4422/20000], Loss: 182.69908142089844, Entropy -227.2753448486328, Learning Rate: 0.0003125\n",
      "Epoch [4423/20000], Loss: 173.7540740966797, Entropy -214.72508239746094, Learning Rate: 0.0003125\n",
      "Epoch [4424/20000], Loss: 172.52493286132812, Entropy -215.47328186035156, Learning Rate: 0.0003125\n",
      "Epoch [4425/20000], Loss: 170.4483184814453, Entropy -205.32241821289062, Learning Rate: 0.0003125\n",
      "Epoch [4426/20000], Loss: 182.92218017578125, Entropy -218.80113220214844, Learning Rate: 0.0003125\n",
      "Epoch [4427/20000], Loss: 181.3599090576172, Entropy -219.11605834960938, Learning Rate: 0.0003125\n",
      "Epoch [4428/20000], Loss: 176.27980041503906, Entropy -212.091552734375, Learning Rate: 0.0003125\n",
      "Epoch [4429/20000], Loss: 169.38674926757812, Entropy -211.22976684570312, Learning Rate: 0.0003125\n",
      "Epoch [4430/20000], Loss: 169.1953582763672, Entropy -207.19216918945312, Learning Rate: 0.0003125\n",
      "Epoch [4431/20000], Loss: 173.88059997558594, Entropy -212.83734130859375, Learning Rate: 0.0003125\n",
      "Epoch [4432/20000], Loss: 173.71495056152344, Entropy -208.64828491210938, Learning Rate: 0.0003125\n",
      "Epoch [4433/20000], Loss: 177.43113708496094, Entropy -214.54400634765625, Learning Rate: 0.0003125\n",
      "Epoch [4434/20000], Loss: 173.39617919921875, Entropy -212.98757934570312, Learning Rate: 0.0003125\n",
      "Epoch [4435/20000], Loss: 173.6468505859375, Entropy -203.62330627441406, Learning Rate: 0.0003125\n",
      "Epoch [4436/20000], Loss: 177.2096405029297, Entropy -214.94100952148438, Learning Rate: 0.0003125\n",
      "Epoch [4437/20000], Loss: 169.67996215820312, Entropy -196.09310913085938, Learning Rate: 0.0003125\n",
      "Epoch [4438/20000], Loss: 177.97598266601562, Entropy -217.65426635742188, Learning Rate: 0.0003125\n",
      "Epoch [4439/20000], Loss: 165.47845458984375, Entropy -199.50497436523438, Learning Rate: 0.0003125\n",
      "Epoch [4440/20000], Loss: 171.81272888183594, Entropy -217.086669921875, Learning Rate: 0.0003125\n",
      "Epoch [4441/20000], Loss: 177.02899169921875, Entropy -213.46023559570312, Learning Rate: 0.0003125\n",
      "Epoch [4442/20000], Loss: 173.5125274658203, Entropy -208.4622344970703, Learning Rate: 0.0003125\n",
      "Epoch [4443/20000], Loss: 175.2455596923828, Entropy -208.15475463867188, Learning Rate: 0.0003125\n",
      "Epoch [4444/20000], Loss: 183.56829833984375, Entropy -227.68589782714844, Learning Rate: 0.0003125\n",
      "Epoch [4445/20000], Loss: 180.41482543945312, Entropy -218.86141967773438, Learning Rate: 0.0003125\n",
      "Epoch [4446/20000], Loss: 181.2718048095703, Entropy -224.2886505126953, Learning Rate: 0.0003125\n",
      "Epoch [4447/20000], Loss: 185.49252319335938, Entropy -222.5377655029297, Learning Rate: 0.0003125\n",
      "Epoch [4448/20000], Loss: 168.98919677734375, Entropy -203.98516845703125, Learning Rate: 0.0003125\n",
      "Epoch [4449/20000], Loss: 173.59910583496094, Entropy -211.32994079589844, Learning Rate: 0.0003125\n",
      "Epoch [4450/20000], Loss: 172.01515197753906, Entropy -211.32958984375, Learning Rate: 0.0003125\n",
      "Epoch [4451/20000], Loss: 178.38929748535156, Entropy -218.5980987548828, Learning Rate: 0.0003125\n",
      "Epoch [4452/20000], Loss: 165.22427368164062, Entropy -204.37332153320312, Learning Rate: 0.0003125\n",
      "Epoch [4453/20000], Loss: 172.6528778076172, Entropy -210.5853729248047, Learning Rate: 0.0003125\n",
      "Epoch [4454/20000], Loss: 179.7032012939453, Entropy -220.0557861328125, Learning Rate: 0.0003125\n",
      "Epoch [4455/20000], Loss: 169.29803466796875, Entropy -205.4172821044922, Learning Rate: 0.0003125\n",
      "Epoch [4456/20000], Loss: 177.2647705078125, Entropy -216.21676635742188, Learning Rate: 0.0003125\n",
      "Epoch [4457/20000], Loss: 176.89675903320312, Entropy -218.60572814941406, Learning Rate: 0.0003125\n",
      "Epoch [4458/20000], Loss: 179.15428161621094, Entropy -215.88525390625, Learning Rate: 0.0003125\n",
      "Epoch [4459/20000], Loss: 172.0743408203125, Entropy -208.86532592773438, Learning Rate: 0.0003125\n",
      "Epoch [4460/20000], Loss: 168.2301483154297, Entropy -202.96347045898438, Learning Rate: 0.0003125\n",
      "Epoch [4461/20000], Loss: 181.33766174316406, Entropy -217.4731903076172, Learning Rate: 0.0003125\n",
      "Epoch [4462/20000], Loss: 178.0625762939453, Entropy -215.86279296875, Learning Rate: 0.0003125\n",
      "Epoch [4463/20000], Loss: 171.67652893066406, Entropy -212.48086547851562, Learning Rate: 0.0003125\n",
      "Epoch [4464/20000], Loss: 173.6186981201172, Entropy -213.85025024414062, Learning Rate: 0.0003125\n",
      "Epoch [4465/20000], Loss: 175.94171142578125, Entropy -214.46142578125, Learning Rate: 0.0003125\n",
      "Epoch [4466/20000], Loss: 177.28329467773438, Entropy -215.4156494140625, Learning Rate: 0.0003125\n",
      "Epoch [4467/20000], Loss: 167.92312622070312, Entropy -202.7010498046875, Learning Rate: 0.0003125\n",
      "Epoch [4468/20000], Loss: 178.37551879882812, Entropy -214.0896759033203, Learning Rate: 0.0003125\n",
      "Epoch [4469/20000], Loss: 179.65652465820312, Entropy -224.33099365234375, Learning Rate: 0.0003125\n",
      "Epoch [4470/20000], Loss: 179.43362426757812, Entropy -213.93789672851562, Learning Rate: 0.0003125\n",
      "Epoch [4471/20000], Loss: 172.53286743164062, Entropy -213.97731018066406, Learning Rate: 0.0003125\n",
      "Epoch [4472/20000], Loss: 180.1527557373047, Entropy -222.44869995117188, Learning Rate: 0.0003125\n",
      "Epoch [4473/20000], Loss: 179.6962432861328, Entropy -221.340087890625, Learning Rate: 0.0003125\n",
      "Epoch [4474/20000], Loss: 180.56642150878906, Entropy -221.94586181640625, Learning Rate: 0.0003125\n",
      "Epoch [4475/20000], Loss: 170.6034698486328, Entropy -207.35421752929688, Learning Rate: 0.0003125\n",
      "Epoch [4476/20000], Loss: 174.03343200683594, Entropy -212.6143798828125, Learning Rate: 0.0003125\n",
      "Epoch [4477/20000], Loss: 173.26866149902344, Entropy -209.19378662109375, Learning Rate: 0.0003125\n",
      "Epoch [4478/20000], Loss: 174.94239807128906, Entropy -205.051025390625, Learning Rate: 0.0003125\n",
      "Epoch [4479/20000], Loss: 174.14120483398438, Entropy -213.87283325195312, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4480/20000], Loss: 177.31182861328125, Entropy -218.56182861328125, Learning Rate: 0.0003125\n",
      "Epoch [4481/20000], Loss: 178.26951599121094, Entropy -219.38076782226562, Learning Rate: 0.0003125\n",
      "Epoch [4482/20000], Loss: 168.04010009765625, Entropy -207.0789794921875, Learning Rate: 0.0003125\n",
      "Epoch [4483/20000], Loss: 181.14683532714844, Entropy -216.00070190429688, Learning Rate: 0.0003125\n",
      "Epoch [4484/20000], Loss: 170.47817993164062, Entropy -207.1827850341797, Learning Rate: 0.0003125\n",
      "Epoch [4485/20000], Loss: 173.73233032226562, Entropy -212.4350128173828, Learning Rate: 0.0003125\n",
      "Epoch [4486/20000], Loss: 174.25735473632812, Entropy -208.7048797607422, Learning Rate: 0.0003125\n",
      "Epoch [4487/20000], Loss: 164.83274841308594, Entropy -208.36279296875, Learning Rate: 0.0003125\n",
      "Epoch [4488/20000], Loss: 175.46942138671875, Entropy -210.2025909423828, Learning Rate: 0.0003125\n",
      "Epoch [4489/20000], Loss: 178.57559204101562, Entropy -220.69541931152344, Learning Rate: 0.0003125\n",
      "Epoch [4490/20000], Loss: 187.215576171875, Entropy -222.02308654785156, Learning Rate: 0.0003125\n",
      "Epoch [4491/20000], Loss: 168.019775390625, Entropy -209.87840270996094, Learning Rate: 0.0003125\n",
      "Epoch [4492/20000], Loss: 178.8585968017578, Entropy -224.46151733398438, Learning Rate: 0.0003125\n",
      "Epoch [4493/20000], Loss: 175.46217346191406, Entropy -211.02471923828125, Learning Rate: 0.0003125\n",
      "Epoch [4494/20000], Loss: 178.65594482421875, Entropy -216.3701934814453, Learning Rate: 0.0003125\n",
      "Epoch [4495/20000], Loss: 173.23556518554688, Entropy -207.091552734375, Learning Rate: 0.0003125\n",
      "Epoch [4496/20000], Loss: 176.70118713378906, Entropy -218.37071228027344, Learning Rate: 0.0003125\n",
      "Epoch [4497/20000], Loss: 172.5892333984375, Entropy -210.2520751953125, Learning Rate: 0.0003125\n",
      "Epoch [4498/20000], Loss: 168.4201202392578, Entropy -206.2536163330078, Learning Rate: 0.0003125\n",
      "Epoch [4499/20000], Loss: 174.96524047851562, Entropy -206.20645141601562, Learning Rate: 0.0003125\n",
      "Epoch [4500/20000], Loss: 182.05032348632812, Entropy -221.05429077148438, Learning Rate: 0.00015625\n",
      "Epoch [4501/20000], Loss: 183.31039428710938, Entropy -216.16015625, Learning Rate: 0.00015625\n",
      "Epoch [4502/20000], Loss: 184.0468292236328, Entropy -218.89447021484375, Learning Rate: 0.00015625\n",
      "Epoch [4503/20000], Loss: 171.2451629638672, Entropy -216.03219604492188, Learning Rate: 0.00015625\n",
      "Epoch [4504/20000], Loss: 183.57582092285156, Entropy -215.8629150390625, Learning Rate: 0.00015625\n",
      "Epoch [4505/20000], Loss: 173.6606903076172, Entropy -213.38014221191406, Learning Rate: 0.00015625\n",
      "Epoch [4506/20000], Loss: 169.9952850341797, Entropy -204.32200622558594, Learning Rate: 0.00015625\n",
      "Epoch [4507/20000], Loss: 177.9716796875, Entropy -214.80764770507812, Learning Rate: 0.00015625\n",
      "Epoch [4508/20000], Loss: 175.88246154785156, Entropy -205.84471130371094, Learning Rate: 0.00015625\n",
      "Epoch [4509/20000], Loss: 180.18240356445312, Entropy -224.35931396484375, Learning Rate: 0.00015625\n",
      "Epoch [4510/20000], Loss: 165.077880859375, Entropy -204.00140380859375, Learning Rate: 0.00015625\n",
      "Epoch [4511/20000], Loss: 181.22471618652344, Entropy -225.2755126953125, Learning Rate: 0.00015625\n",
      "Epoch [4512/20000], Loss: 177.04978942871094, Entropy -214.44903564453125, Learning Rate: 0.00015625\n",
      "Epoch [4513/20000], Loss: 177.3863067626953, Entropy -212.77847290039062, Learning Rate: 0.00015625\n",
      "Epoch [4514/20000], Loss: 168.39366149902344, Entropy -207.41317749023438, Learning Rate: 0.00015625\n",
      "Epoch [4515/20000], Loss: 173.84716796875, Entropy -214.6373748779297, Learning Rate: 0.00015625\n",
      "Epoch [4516/20000], Loss: 179.93701171875, Entropy -219.7376708984375, Learning Rate: 0.00015625\n",
      "Epoch [4517/20000], Loss: 171.6685028076172, Entropy -209.07769775390625, Learning Rate: 0.00015625\n",
      "Epoch [4518/20000], Loss: 165.4633026123047, Entropy -202.3079833984375, Learning Rate: 0.00015625\n",
      "Epoch [4519/20000], Loss: 170.6602783203125, Entropy -207.5480194091797, Learning Rate: 0.00015625\n",
      "Epoch [4520/20000], Loss: 177.77053833007812, Entropy -218.72360229492188, Learning Rate: 0.00015625\n",
      "Epoch [4521/20000], Loss: 175.95120239257812, Entropy -214.35736083984375, Learning Rate: 0.00015625\n",
      "Epoch [4522/20000], Loss: 173.90316772460938, Entropy -211.41087341308594, Learning Rate: 0.00015625\n",
      "Epoch [4523/20000], Loss: 177.20436096191406, Entropy -214.78634643554688, Learning Rate: 0.00015625\n",
      "Epoch [4524/20000], Loss: 173.82167053222656, Entropy -207.8438720703125, Learning Rate: 0.00015625\n",
      "Epoch [4525/20000], Loss: 179.3697509765625, Entropy -213.2631378173828, Learning Rate: 0.00015625\n",
      "Epoch [4526/20000], Loss: 166.95062255859375, Entropy -204.72044372558594, Learning Rate: 0.00015625\n",
      "Epoch [4527/20000], Loss: 177.6045684814453, Entropy -219.2216033935547, Learning Rate: 0.00015625\n",
      "Epoch [4528/20000], Loss: 185.5064697265625, Entropy -227.93435668945312, Learning Rate: 0.00015625\n",
      "Epoch [4529/20000], Loss: 176.88951110839844, Entropy -214.81590270996094, Learning Rate: 0.00015625\n",
      "Epoch [4530/20000], Loss: 174.3007354736328, Entropy -209.4404296875, Learning Rate: 0.00015625\n",
      "Epoch [4531/20000], Loss: 172.44166564941406, Entropy -211.77920532226562, Learning Rate: 0.00015625\n",
      "Epoch [4532/20000], Loss: 171.25779724121094, Entropy -204.2998809814453, Learning Rate: 0.00015625\n",
      "Epoch [4533/20000], Loss: 176.07684326171875, Entropy -207.22901916503906, Learning Rate: 0.00015625\n",
      "Epoch [4534/20000], Loss: 170.21873474121094, Entropy -210.2721710205078, Learning Rate: 0.00015625\n",
      "Epoch [4535/20000], Loss: 175.31871032714844, Entropy -210.87265014648438, Learning Rate: 0.00015625\n",
      "Epoch [4536/20000], Loss: 163.88966369628906, Entropy -199.32781982421875, Learning Rate: 0.00015625\n",
      "Epoch [4537/20000], Loss: 175.30694580078125, Entropy -212.71817016601562, Learning Rate: 0.00015625\n",
      "Epoch [4538/20000], Loss: 172.6763916015625, Entropy -211.84262084960938, Learning Rate: 0.00015625\n",
      "Epoch [4539/20000], Loss: 175.79713439941406, Entropy -213.307861328125, Learning Rate: 0.00015625\n",
      "Epoch [4540/20000], Loss: 170.55587768554688, Entropy -209.1659393310547, Learning Rate: 0.00015625\n",
      "Epoch [4541/20000], Loss: 179.36070251464844, Entropy -218.52145385742188, Learning Rate: 0.00015625\n",
      "Epoch [4542/20000], Loss: 170.5737762451172, Entropy -207.2457275390625, Learning Rate: 0.00015625\n",
      "Epoch [4543/20000], Loss: 176.46621704101562, Entropy -216.3063507080078, Learning Rate: 0.00015625\n",
      "Epoch [4544/20000], Loss: 175.93685913085938, Entropy -216.78697204589844, Learning Rate: 0.00015625\n",
      "Epoch [4545/20000], Loss: 184.91177368164062, Entropy -216.22080993652344, Learning Rate: 0.00015625\n",
      "Epoch [4546/20000], Loss: 176.85108947753906, Entropy -213.62063598632812, Learning Rate: 0.00015625\n",
      "Epoch [4547/20000], Loss: 170.37838745117188, Entropy -203.1944580078125, Learning Rate: 0.00015625\n",
      "Epoch [4548/20000], Loss: 170.2718505859375, Entropy -210.27078247070312, Learning Rate: 0.00015625\n",
      "Epoch [4549/20000], Loss: 164.63844299316406, Entropy -199.9886016845703, Learning Rate: 0.00015625\n",
      "Epoch [4550/20000], Loss: 182.37713623046875, Entropy -225.1451416015625, Learning Rate: 0.00015625\n",
      "Epoch [4551/20000], Loss: 170.85800170898438, Entropy -202.9232940673828, Learning Rate: 0.00015625\n",
      "Epoch [4552/20000], Loss: 166.34420776367188, Entropy -210.21334838867188, Learning Rate: 0.00015625\n",
      "Epoch [4553/20000], Loss: 180.79347229003906, Entropy -210.674072265625, Learning Rate: 0.00015625\n",
      "Epoch [4554/20000], Loss: 173.7930450439453, Entropy -211.3556365966797, Learning Rate: 0.00015625\n",
      "Epoch [4555/20000], Loss: 163.42286682128906, Entropy -206.47665405273438, Learning Rate: 0.00015625\n",
      "Epoch [4556/20000], Loss: 178.02565002441406, Entropy -212.20620727539062, Learning Rate: 0.00015625\n",
      "Epoch [4557/20000], Loss: 179.98739624023438, Entropy -219.88795471191406, Learning Rate: 0.00015625\n",
      "Epoch [4558/20000], Loss: 180.78465270996094, Entropy -217.982177734375, Learning Rate: 0.00015625\n",
      "Epoch [4559/20000], Loss: 174.9081268310547, Entropy -211.51437377929688, Learning Rate: 0.00015625\n",
      "Epoch [4560/20000], Loss: 173.30923461914062, Entropy -209.39881896972656, Learning Rate: 0.00015625\n",
      "Epoch [4561/20000], Loss: 170.1908721923828, Entropy -213.64076232910156, Learning Rate: 0.00015625\n",
      "Epoch [4562/20000], Loss: 165.2030487060547, Entropy -206.3720245361328, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4563/20000], Loss: 176.7667694091797, Entropy -216.55145263671875, Learning Rate: 0.00015625\n",
      "Epoch [4564/20000], Loss: 179.86328125, Entropy -216.4163818359375, Learning Rate: 0.00015625\n",
      "Epoch [4565/20000], Loss: 178.6796875, Entropy -216.3122100830078, Learning Rate: 0.00015625\n",
      "Epoch [4566/20000], Loss: 170.59591674804688, Entropy -205.230224609375, Learning Rate: 0.00015625\n",
      "Epoch [4567/20000], Loss: 174.2942352294922, Entropy -205.9176483154297, Learning Rate: 0.00015625\n",
      "Epoch [4568/20000], Loss: 183.40322875976562, Entropy -222.24488830566406, Learning Rate: 0.00015625\n",
      "Epoch [4569/20000], Loss: 182.25755310058594, Entropy -220.87017822265625, Learning Rate: 0.00015625\n",
      "Epoch [4570/20000], Loss: 187.4097900390625, Entropy -224.03451538085938, Learning Rate: 0.00015625\n",
      "Epoch [4571/20000], Loss: 167.83480834960938, Entropy -204.24827575683594, Learning Rate: 0.00015625\n",
      "Epoch [4572/20000], Loss: 187.20994567871094, Entropy -222.90371704101562, Learning Rate: 0.00015625\n",
      "Epoch [4573/20000], Loss: 179.9052276611328, Entropy -217.39865112304688, Learning Rate: 0.00015625\n",
      "Epoch [4574/20000], Loss: 173.7451629638672, Entropy -213.24281311035156, Learning Rate: 0.00015625\n",
      "Epoch [4575/20000], Loss: 178.10626220703125, Entropy -220.66336059570312, Learning Rate: 0.00015625\n",
      "Epoch [4576/20000], Loss: 173.60140991210938, Entropy -211.33258056640625, Learning Rate: 0.00015625\n",
      "Epoch [4577/20000], Loss: 166.79689025878906, Entropy -207.18267822265625, Learning Rate: 0.00015625\n",
      "Epoch [4578/20000], Loss: 171.8897705078125, Entropy -211.2158203125, Learning Rate: 0.00015625\n",
      "Epoch [4579/20000], Loss: 185.47657775878906, Entropy -218.5162811279297, Learning Rate: 0.00015625\n",
      "Epoch [4580/20000], Loss: 171.93795776367188, Entropy -210.49627685546875, Learning Rate: 0.00015625\n",
      "Epoch [4581/20000], Loss: 175.8589324951172, Entropy -212.8947296142578, Learning Rate: 0.00015625\n",
      "Epoch [4582/20000], Loss: 167.91903686523438, Entropy -203.38168334960938, Learning Rate: 0.00015625\n",
      "Epoch [4583/20000], Loss: 181.80734252929688, Entropy -222.177978515625, Learning Rate: 0.00015625\n",
      "Epoch [4584/20000], Loss: 184.60592651367188, Entropy -226.44012451171875, Learning Rate: 0.00015625\n",
      "Epoch [4585/20000], Loss: 174.7296142578125, Entropy -206.84942626953125, Learning Rate: 0.00015625\n",
      "Epoch [4586/20000], Loss: 181.3193817138672, Entropy -220.82916259765625, Learning Rate: 0.00015625\n",
      "Epoch [4587/20000], Loss: 169.05226135253906, Entropy -205.90948486328125, Learning Rate: 0.00015625\n",
      "Epoch [4588/20000], Loss: 179.30873107910156, Entropy -217.66720581054688, Learning Rate: 0.00015625\n",
      "Epoch [4589/20000], Loss: 181.3974151611328, Entropy -219.82901000976562, Learning Rate: 0.00015625\n",
      "Epoch [4590/20000], Loss: 175.25643920898438, Entropy -220.24310302734375, Learning Rate: 0.00015625\n",
      "Epoch [4591/20000], Loss: 189.99591064453125, Entropy -224.24728393554688, Learning Rate: 0.00015625\n",
      "Epoch [4592/20000], Loss: 173.49124145507812, Entropy -205.69920349121094, Learning Rate: 0.00015625\n",
      "Epoch [4593/20000], Loss: 172.7675323486328, Entropy -209.98675537109375, Learning Rate: 0.00015625\n",
      "Epoch [4594/20000], Loss: 172.0085906982422, Entropy -212.3289794921875, Learning Rate: 0.00015625\n",
      "Epoch [4595/20000], Loss: 176.9270782470703, Entropy -213.93179321289062, Learning Rate: 0.00015625\n",
      "Epoch [4596/20000], Loss: 168.8614501953125, Entropy -206.7427978515625, Learning Rate: 0.00015625\n",
      "Epoch [4597/20000], Loss: 174.60594177246094, Entropy -204.82220458984375, Learning Rate: 0.00015625\n",
      "Epoch [4598/20000], Loss: 169.45452880859375, Entropy -206.15777587890625, Learning Rate: 0.00015625\n",
      "Epoch [4599/20000], Loss: 167.43089294433594, Entropy -208.6554718017578, Learning Rate: 0.00015625\n",
      "Epoch [4600/20000], Loss: 176.830078125, Entropy -216.14785766601562, Learning Rate: 0.00015625\n",
      "Epoch [4601/20000], Loss: 173.0214385986328, Entropy -215.6983642578125, Learning Rate: 0.00015625\n",
      "Epoch [4602/20000], Loss: 185.97193908691406, Entropy -220.35775756835938, Learning Rate: 0.00015625\n",
      "Epoch [4603/20000], Loss: 178.22622680664062, Entropy -220.16761779785156, Learning Rate: 0.00015625\n",
      "Epoch [4604/20000], Loss: 175.84512329101562, Entropy -217.6326904296875, Learning Rate: 0.00015625\n",
      "Epoch [4605/20000], Loss: 167.97364807128906, Entropy -211.46031188964844, Learning Rate: 0.00015625\n",
      "Epoch [4606/20000], Loss: 172.42388916015625, Entropy -206.74636840820312, Learning Rate: 0.00015625\n",
      "Epoch [4607/20000], Loss: 178.15972900390625, Entropy -212.8769073486328, Learning Rate: 0.00015625\n",
      "Epoch [4608/20000], Loss: 186.1997833251953, Entropy -225.49472045898438, Learning Rate: 0.00015625\n",
      "Epoch [4609/20000], Loss: 184.67324829101562, Entropy -225.079345703125, Learning Rate: 0.00015625\n",
      "Epoch [4610/20000], Loss: 164.2532958984375, Entropy -199.08926391601562, Learning Rate: 0.00015625\n",
      "Epoch [4611/20000], Loss: 166.40838623046875, Entropy -201.73533630371094, Learning Rate: 0.00015625\n",
      "Epoch [4612/20000], Loss: 170.9754180908203, Entropy -209.8167724609375, Learning Rate: 0.00015625\n",
      "Epoch [4613/20000], Loss: 170.54287719726562, Entropy -207.833984375, Learning Rate: 0.00015625\n",
      "Epoch [4614/20000], Loss: 178.93988037109375, Entropy -214.23666381835938, Learning Rate: 0.00015625\n",
      "Epoch [4615/20000], Loss: 183.44064331054688, Entropy -217.530517578125, Learning Rate: 0.00015625\n",
      "Epoch [4616/20000], Loss: 182.49234008789062, Entropy -225.41015625, Learning Rate: 0.00015625\n",
      "Epoch [4617/20000], Loss: 170.87298583984375, Entropy -209.24807739257812, Learning Rate: 0.00015625\n",
      "Epoch [4618/20000], Loss: 176.85311889648438, Entropy -219.420166015625, Learning Rate: 0.00015625\n",
      "Epoch [4619/20000], Loss: 165.9644317626953, Entropy -207.4272918701172, Learning Rate: 0.00015625\n",
      "Epoch [4620/20000], Loss: 175.4469757080078, Entropy -208.447509765625, Learning Rate: 0.00015625\n",
      "Epoch [4621/20000], Loss: 170.8934326171875, Entropy -205.83216857910156, Learning Rate: 0.00015625\n",
      "Epoch [4622/20000], Loss: 178.76803588867188, Entropy -210.8883819580078, Learning Rate: 0.00015625\n",
      "Epoch [4623/20000], Loss: 173.50308227539062, Entropy -213.4112548828125, Learning Rate: 0.00015625\n",
      "Epoch [4624/20000], Loss: 173.58982849121094, Entropy -208.47698974609375, Learning Rate: 0.00015625\n",
      "Epoch [4625/20000], Loss: 182.27809143066406, Entropy -217.27279663085938, Learning Rate: 0.00015625\n",
      "Epoch [4626/20000], Loss: 181.41221618652344, Entropy -222.03233337402344, Learning Rate: 0.00015625\n",
      "Epoch [4627/20000], Loss: 168.09152221679688, Entropy -205.866455078125, Learning Rate: 0.00015625\n",
      "Epoch [4628/20000], Loss: 182.87228393554688, Entropy -225.4359130859375, Learning Rate: 0.00015625\n",
      "Epoch [4629/20000], Loss: 166.92684936523438, Entropy -204.28775024414062, Learning Rate: 0.00015625\n",
      "Epoch [4630/20000], Loss: 183.60311889648438, Entropy -214.35968017578125, Learning Rate: 0.00015625\n",
      "Epoch [4631/20000], Loss: 175.5916748046875, Entropy -212.1859893798828, Learning Rate: 0.00015625\n",
      "Epoch [4632/20000], Loss: 176.36767578125, Entropy -213.13534545898438, Learning Rate: 0.00015625\n",
      "Epoch [4633/20000], Loss: 174.0048370361328, Entropy -214.92776489257812, Learning Rate: 0.00015625\n",
      "Epoch [4634/20000], Loss: 176.6234893798828, Entropy -221.0464324951172, Learning Rate: 0.00015625\n",
      "Epoch [4635/20000], Loss: 169.84170532226562, Entropy -208.9648895263672, Learning Rate: 0.00015625\n",
      "Epoch [4636/20000], Loss: 185.05003356933594, Entropy -229.44505310058594, Learning Rate: 0.00015625\n",
      "Epoch [4637/20000], Loss: 168.65121459960938, Entropy -198.87921142578125, Learning Rate: 0.00015625\n",
      "Epoch [4638/20000], Loss: 189.62037658691406, Entropy -220.35845947265625, Learning Rate: 0.00015625\n",
      "Epoch [4639/20000], Loss: 172.2024383544922, Entropy -213.8788299560547, Learning Rate: 0.00015625\n",
      "Epoch [4640/20000], Loss: 171.50694274902344, Entropy -209.25186157226562, Learning Rate: 0.00015625\n",
      "Epoch [4641/20000], Loss: 182.49334716796875, Entropy -218.82302856445312, Learning Rate: 0.00015625\n",
      "Epoch [4642/20000], Loss: 166.64796447753906, Entropy -204.76382446289062, Learning Rate: 0.00015625\n",
      "Epoch [4643/20000], Loss: 171.5259246826172, Entropy -205.87779235839844, Learning Rate: 0.00015625\n",
      "Epoch [4644/20000], Loss: 189.4707794189453, Entropy -228.20858764648438, Learning Rate: 0.00015625\n",
      "Epoch [4645/20000], Loss: 179.69253540039062, Entropy -217.46832275390625, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4646/20000], Loss: 167.38092041015625, Entropy -208.5634307861328, Learning Rate: 0.00015625\n",
      "Epoch [4647/20000], Loss: 168.08697509765625, Entropy -210.7176971435547, Learning Rate: 0.00015625\n",
      "Epoch [4648/20000], Loss: 174.2216033935547, Entropy -208.85186767578125, Learning Rate: 0.00015625\n",
      "Epoch [4649/20000], Loss: 170.0179443359375, Entropy -209.46014404296875, Learning Rate: 0.00015625\n",
      "Epoch [4650/20000], Loss: 174.0943603515625, Entropy -208.48239135742188, Learning Rate: 0.00015625\n",
      "Epoch [4651/20000], Loss: 172.61483764648438, Entropy -212.89505004882812, Learning Rate: 0.00015625\n",
      "Epoch [4652/20000], Loss: 165.61373901367188, Entropy -210.37545776367188, Learning Rate: 0.00015625\n",
      "Epoch [4653/20000], Loss: 170.3699493408203, Entropy -206.4126434326172, Learning Rate: 0.00015625\n",
      "Epoch [4654/20000], Loss: 173.77706909179688, Entropy -215.35150146484375, Learning Rate: 0.00015625\n",
      "Epoch [4655/20000], Loss: 171.09202575683594, Entropy -212.32330322265625, Learning Rate: 0.00015625\n",
      "Epoch [4656/20000], Loss: 177.50538635253906, Entropy -213.49465942382812, Learning Rate: 0.00015625\n",
      "Epoch [4657/20000], Loss: 182.6133575439453, Entropy -217.87435913085938, Learning Rate: 0.00015625\n",
      "Epoch [4658/20000], Loss: 184.96961975097656, Entropy -225.00408935546875, Learning Rate: 0.00015625\n",
      "Epoch [4659/20000], Loss: 169.74954223632812, Entropy -205.44944763183594, Learning Rate: 0.00015625\n",
      "Epoch [4660/20000], Loss: 177.6220245361328, Entropy -213.39830017089844, Learning Rate: 0.00015625\n",
      "Epoch [4661/20000], Loss: 179.3970947265625, Entropy -219.25694274902344, Learning Rate: 0.00015625\n",
      "Epoch [4662/20000], Loss: 163.9418182373047, Entropy -196.5408935546875, Learning Rate: 0.00015625\n",
      "Epoch [4663/20000], Loss: 171.68582153320312, Entropy -210.12449645996094, Learning Rate: 0.00015625\n",
      "Epoch [4664/20000], Loss: 170.13612365722656, Entropy -209.24813842773438, Learning Rate: 0.00015625\n",
      "Epoch [4665/20000], Loss: 171.2411651611328, Entropy -211.05514526367188, Learning Rate: 0.00015625\n",
      "Epoch [4666/20000], Loss: 176.46324157714844, Entropy -216.09715270996094, Learning Rate: 0.00015625\n",
      "Epoch [4667/20000], Loss: 172.43716430664062, Entropy -205.71255493164062, Learning Rate: 0.00015625\n",
      "Epoch [4668/20000], Loss: 175.41268920898438, Entropy -206.37457275390625, Learning Rate: 0.00015625\n",
      "Epoch [4669/20000], Loss: 171.14170837402344, Entropy -210.3783721923828, Learning Rate: 0.00015625\n",
      "Epoch [4670/20000], Loss: 176.87982177734375, Entropy -215.91372680664062, Learning Rate: 0.00015625\n",
      "Epoch [4671/20000], Loss: 180.3629608154297, Entropy -222.03829956054688, Learning Rate: 0.00015625\n",
      "Epoch [4672/20000], Loss: 175.37136840820312, Entropy -216.9837646484375, Learning Rate: 0.00015625\n",
      "Epoch [4673/20000], Loss: 179.1981658935547, Entropy -212.6078338623047, Learning Rate: 0.00015625\n",
      "Epoch [4674/20000], Loss: 180.7351837158203, Entropy -221.8470458984375, Learning Rate: 0.00015625\n",
      "Epoch [4675/20000], Loss: 181.4833984375, Entropy -221.35585021972656, Learning Rate: 0.00015625\n",
      "Epoch [4676/20000], Loss: 169.54788208007812, Entropy -207.32090759277344, Learning Rate: 0.00015625\n",
      "Epoch [4677/20000], Loss: 183.28245544433594, Entropy -224.4257049560547, Learning Rate: 0.00015625\n",
      "Epoch [4678/20000], Loss: 184.78411865234375, Entropy -216.0411834716797, Learning Rate: 0.00015625\n",
      "Epoch [4679/20000], Loss: 182.69882202148438, Entropy -222.5862579345703, Learning Rate: 0.00015625\n",
      "Epoch [4680/20000], Loss: 168.25253295898438, Entropy -211.10520935058594, Learning Rate: 0.00015625\n",
      "Epoch [4681/20000], Loss: 179.09642028808594, Entropy -216.10595703125, Learning Rate: 0.00015625\n",
      "Epoch [4682/20000], Loss: 178.31678771972656, Entropy -218.07305908203125, Learning Rate: 0.00015625\n",
      "Epoch [4683/20000], Loss: 172.48214721679688, Entropy -213.34364318847656, Learning Rate: 0.00015625\n",
      "Epoch [4684/20000], Loss: 177.60166931152344, Entropy -213.45703125, Learning Rate: 0.00015625\n",
      "Epoch [4685/20000], Loss: 181.81185913085938, Entropy -214.97996520996094, Learning Rate: 0.00015625\n",
      "Epoch [4686/20000], Loss: 178.1311492919922, Entropy -216.23294067382812, Learning Rate: 0.00015625\n",
      "Epoch [4687/20000], Loss: 180.99893188476562, Entropy -218.3599395751953, Learning Rate: 0.00015625\n",
      "Epoch [4688/20000], Loss: 178.0465087890625, Entropy -217.4904022216797, Learning Rate: 0.00015625\n",
      "Epoch [4689/20000], Loss: 178.2111053466797, Entropy -215.75869750976562, Learning Rate: 0.00015625\n",
      "Epoch [4690/20000], Loss: 171.26036071777344, Entropy -213.06423950195312, Learning Rate: 0.00015625\n",
      "Epoch [4691/20000], Loss: 181.78977966308594, Entropy -217.42637634277344, Learning Rate: 0.00015625\n",
      "Epoch [4692/20000], Loss: 176.5264434814453, Entropy -207.24183654785156, Learning Rate: 0.00015625\n",
      "Epoch [4693/20000], Loss: 174.19773864746094, Entropy -218.27418518066406, Learning Rate: 0.00015625\n",
      "Epoch [4694/20000], Loss: 176.91058349609375, Entropy -218.47793579101562, Learning Rate: 0.00015625\n",
      "Epoch [4695/20000], Loss: 175.4034881591797, Entropy -216.23397827148438, Learning Rate: 0.00015625\n",
      "Epoch [4696/20000], Loss: 168.92909240722656, Entropy -206.094482421875, Learning Rate: 0.00015625\n",
      "Epoch [4697/20000], Loss: 166.9026336669922, Entropy -200.4954376220703, Learning Rate: 0.00015625\n",
      "Epoch [4698/20000], Loss: 174.7579345703125, Entropy -212.53358459472656, Learning Rate: 0.00015625\n",
      "Epoch [4699/20000], Loss: 174.2645263671875, Entropy -210.7227325439453, Learning Rate: 0.00015625\n",
      "Epoch [4700/20000], Loss: 177.16038513183594, Entropy -221.72930908203125, Learning Rate: 0.00015625\n",
      "Epoch [4701/20000], Loss: 177.74993896484375, Entropy -217.89537048339844, Learning Rate: 7.8125e-05\n",
      "Epoch [4702/20000], Loss: 178.1114501953125, Entropy -219.7731170654297, Learning Rate: 7.8125e-05\n",
      "Epoch [4703/20000], Loss: 173.08108520507812, Entropy -211.69154357910156, Learning Rate: 7.8125e-05\n",
      "Epoch [4704/20000], Loss: 173.80091857910156, Entropy -213.16331481933594, Learning Rate: 7.8125e-05\n",
      "Epoch [4705/20000], Loss: 162.924560546875, Entropy -201.62681579589844, Learning Rate: 7.8125e-05\n",
      "Epoch [4706/20000], Loss: 187.06492614746094, Entropy -230.32058715820312, Learning Rate: 7.8125e-05\n",
      "Epoch [4707/20000], Loss: 168.88247680664062, Entropy -210.88644409179688, Learning Rate: 7.8125e-05\n",
      "Epoch [4708/20000], Loss: 179.60577392578125, Entropy -221.8188018798828, Learning Rate: 7.8125e-05\n",
      "Epoch [4709/20000], Loss: 169.0809326171875, Entropy -207.52700805664062, Learning Rate: 7.8125e-05\n",
      "Epoch [4710/20000], Loss: 177.8785400390625, Entropy -216.49864196777344, Learning Rate: 7.8125e-05\n",
      "Epoch [4711/20000], Loss: 179.32066345214844, Entropy -218.55905151367188, Learning Rate: 7.8125e-05\n",
      "Epoch [4712/20000], Loss: 173.340576171875, Entropy -207.9970703125, Learning Rate: 7.8125e-05\n",
      "Epoch [4713/20000], Loss: 177.29611206054688, Entropy -216.09719848632812, Learning Rate: 7.8125e-05\n",
      "Epoch [4714/20000], Loss: 181.37400817871094, Entropy -218.20724487304688, Learning Rate: 7.8125e-05\n",
      "Epoch [4715/20000], Loss: 170.77076721191406, Entropy -209.36233520507812, Learning Rate: 7.8125e-05\n",
      "Epoch [4716/20000], Loss: 182.7489013671875, Entropy -231.02439880371094, Learning Rate: 7.8125e-05\n",
      "Epoch [4717/20000], Loss: 184.0435028076172, Entropy -223.34185791015625, Learning Rate: 7.8125e-05\n",
      "Epoch [4718/20000], Loss: 186.16751098632812, Entropy -227.43927001953125, Learning Rate: 7.8125e-05\n",
      "Epoch [4719/20000], Loss: 173.72677612304688, Entropy -209.64981079101562, Learning Rate: 7.8125e-05\n",
      "Epoch [4720/20000], Loss: 171.6595001220703, Entropy -210.21925354003906, Learning Rate: 7.8125e-05\n",
      "Epoch [4721/20000], Loss: 171.00875854492188, Entropy -207.96038818359375, Learning Rate: 7.8125e-05\n",
      "Epoch [4722/20000], Loss: 192.63206481933594, Entropy -226.47509765625, Learning Rate: 7.8125e-05\n",
      "Epoch [4723/20000], Loss: 180.0691680908203, Entropy -214.4066162109375, Learning Rate: 7.8125e-05\n",
      "Epoch [4724/20000], Loss: 169.34642028808594, Entropy -203.26666259765625, Learning Rate: 7.8125e-05\n",
      "Epoch [4725/20000], Loss: 171.42657470703125, Entropy -207.5988006591797, Learning Rate: 7.8125e-05\n",
      "Epoch [4726/20000], Loss: 185.16156005859375, Entropy -222.5437774658203, Learning Rate: 7.8125e-05\n",
      "Epoch [4727/20000], Loss: 171.3388214111328, Entropy -205.0899658203125, Learning Rate: 7.8125e-05\n",
      "Epoch [4728/20000], Loss: 176.13650512695312, Entropy -215.33050537109375, Learning Rate: 7.8125e-05\n",
      "Epoch [4729/20000], Loss: 172.92942810058594, Entropy -218.21234130859375, Learning Rate: 7.8125e-05\n",
      "Epoch [4730/20000], Loss: 172.3076934814453, Entropy -209.03538513183594, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4731/20000], Loss: 169.17091369628906, Entropy -206.86483764648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4732/20000], Loss: 183.1824951171875, Entropy -223.11294555664062, Learning Rate: 7.8125e-05\n",
      "Epoch [4733/20000], Loss: 170.96832275390625, Entropy -212.98049926757812, Learning Rate: 7.8125e-05\n",
      "Epoch [4734/20000], Loss: 166.7449188232422, Entropy -207.67970275878906, Learning Rate: 7.8125e-05\n",
      "Epoch [4735/20000], Loss: 179.52053833007812, Entropy -217.58102416992188, Learning Rate: 7.8125e-05\n",
      "Epoch [4736/20000], Loss: 185.9111328125, Entropy -216.2245635986328, Learning Rate: 7.8125e-05\n",
      "Epoch [4737/20000], Loss: 176.2753143310547, Entropy -211.78802490234375, Learning Rate: 7.8125e-05\n",
      "Epoch [4738/20000], Loss: 172.79348754882812, Entropy -216.3323516845703, Learning Rate: 7.8125e-05\n",
      "Epoch [4739/20000], Loss: 178.1310272216797, Entropy -218.95516967773438, Learning Rate: 7.8125e-05\n",
      "Epoch [4740/20000], Loss: 181.92776489257812, Entropy -222.7646484375, Learning Rate: 7.8125e-05\n",
      "Epoch [4741/20000], Loss: 165.34820556640625, Entropy -194.24008178710938, Learning Rate: 7.8125e-05\n",
      "Epoch [4742/20000], Loss: 182.80197143554688, Entropy -220.08937072753906, Learning Rate: 7.8125e-05\n",
      "Epoch [4743/20000], Loss: 178.51426696777344, Entropy -216.92344665527344, Learning Rate: 7.8125e-05\n",
      "Epoch [4744/20000], Loss: 170.88458251953125, Entropy -210.60101318359375, Learning Rate: 7.8125e-05\n",
      "Epoch [4745/20000], Loss: 185.0867156982422, Entropy -226.92910766601562, Learning Rate: 7.8125e-05\n",
      "Epoch [4746/20000], Loss: 168.5225372314453, Entropy -206.102294921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4747/20000], Loss: 169.78604125976562, Entropy -207.18719482421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4748/20000], Loss: 183.62042236328125, Entropy -218.8965301513672, Learning Rate: 7.8125e-05\n",
      "Epoch [4749/20000], Loss: 168.4389190673828, Entropy -208.79905700683594, Learning Rate: 7.8125e-05\n",
      "Epoch [4750/20000], Loss: 169.015625, Entropy -206.64979553222656, Learning Rate: 7.8125e-05\n",
      "Epoch [4751/20000], Loss: 178.95140075683594, Entropy -213.007080078125, Learning Rate: 7.8125e-05\n",
      "Epoch [4752/20000], Loss: 172.3865966796875, Entropy -210.64096069335938, Learning Rate: 7.8125e-05\n",
      "Epoch [4753/20000], Loss: 179.04898071289062, Entropy -212.69190979003906, Learning Rate: 7.8125e-05\n",
      "Epoch [4754/20000], Loss: 170.75782775878906, Entropy -211.71629333496094, Learning Rate: 7.8125e-05\n",
      "Epoch [4755/20000], Loss: 186.38169860839844, Entropy -231.55126953125, Learning Rate: 7.8125e-05\n",
      "Epoch [4756/20000], Loss: 181.3376007080078, Entropy -222.14183044433594, Learning Rate: 7.8125e-05\n",
      "Epoch [4757/20000], Loss: 168.1419677734375, Entropy -207.5903778076172, Learning Rate: 7.8125e-05\n",
      "Epoch [4758/20000], Loss: 183.93585205078125, Entropy -223.8240966796875, Learning Rate: 7.8125e-05\n",
      "Epoch [4759/20000], Loss: 175.52145385742188, Entropy -217.80511474609375, Learning Rate: 7.8125e-05\n",
      "Epoch [4760/20000], Loss: 176.97108459472656, Entropy -217.73963928222656, Learning Rate: 7.8125e-05\n",
      "Epoch [4761/20000], Loss: 177.78829956054688, Entropy -217.03756713867188, Learning Rate: 7.8125e-05\n",
      "Epoch [4762/20000], Loss: 174.84107971191406, Entropy -220.25831604003906, Learning Rate: 7.8125e-05\n",
      "Epoch [4763/20000], Loss: 179.28868103027344, Entropy -220.94674682617188, Learning Rate: 7.8125e-05\n",
      "Epoch [4764/20000], Loss: 171.5321807861328, Entropy -207.8748779296875, Learning Rate: 7.8125e-05\n",
      "Epoch [4765/20000], Loss: 172.24632263183594, Entropy -208.36834716796875, Learning Rate: 7.8125e-05\n",
      "Epoch [4766/20000], Loss: 169.4505157470703, Entropy -209.07147216796875, Learning Rate: 7.8125e-05\n",
      "Epoch [4767/20000], Loss: 182.05601501464844, Entropy -218.66090393066406, Learning Rate: 7.8125e-05\n",
      "Epoch [4768/20000], Loss: 173.91249084472656, Entropy -210.7221221923828, Learning Rate: 7.8125e-05\n",
      "Epoch [4769/20000], Loss: 171.16366577148438, Entropy -201.91102600097656, Learning Rate: 7.8125e-05\n",
      "Epoch [4770/20000], Loss: 177.32276916503906, Entropy -216.85301208496094, Learning Rate: 7.8125e-05\n",
      "Epoch [4771/20000], Loss: 169.7491455078125, Entropy -212.21315002441406, Learning Rate: 7.8125e-05\n",
      "Epoch [4772/20000], Loss: 174.0297393798828, Entropy -211.9144287109375, Learning Rate: 7.8125e-05\n",
      "Epoch [4773/20000], Loss: 180.1461639404297, Entropy -220.31906127929688, Learning Rate: 7.8125e-05\n",
      "Epoch [4774/20000], Loss: 181.80740356445312, Entropy -211.05630493164062, Learning Rate: 7.8125e-05\n",
      "Epoch [4775/20000], Loss: 165.4619903564453, Entropy -199.2978515625, Learning Rate: 7.8125e-05\n",
      "Epoch [4776/20000], Loss: 173.30303955078125, Entropy -206.6856689453125, Learning Rate: 7.8125e-05\n",
      "Epoch [4777/20000], Loss: 175.02664184570312, Entropy -211.44952392578125, Learning Rate: 7.8125e-05\n",
      "Epoch [4778/20000], Loss: 179.06039428710938, Entropy -211.48764038085938, Learning Rate: 7.8125e-05\n",
      "Epoch [4779/20000], Loss: 172.8610076904297, Entropy -206.95774841308594, Learning Rate: 7.8125e-05\n",
      "Epoch [4780/20000], Loss: 182.22116088867188, Entropy -222.1591796875, Learning Rate: 7.8125e-05\n",
      "Epoch [4781/20000], Loss: 180.66561889648438, Entropy -221.29159545898438, Learning Rate: 7.8125e-05\n",
      "Epoch [4782/20000], Loss: 165.2892303466797, Entropy -202.9464111328125, Learning Rate: 7.8125e-05\n",
      "Epoch [4783/20000], Loss: 177.55426025390625, Entropy -221.38079833984375, Learning Rate: 7.8125e-05\n",
      "Epoch [4784/20000], Loss: 171.6215362548828, Entropy -207.7000732421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4785/20000], Loss: 177.67962646484375, Entropy -223.1169891357422, Learning Rate: 7.8125e-05\n",
      "Epoch [4786/20000], Loss: 179.41481018066406, Entropy -218.68267822265625, Learning Rate: 7.8125e-05\n",
      "Epoch [4787/20000], Loss: 187.33509826660156, Entropy -219.1563262939453, Learning Rate: 7.8125e-05\n",
      "Epoch [4788/20000], Loss: 176.43511962890625, Entropy -213.57577514648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4789/20000], Loss: 172.416259765625, Entropy -214.36068725585938, Learning Rate: 7.8125e-05\n",
      "Epoch [4790/20000], Loss: 175.42776489257812, Entropy -216.67559814453125, Learning Rate: 7.8125e-05\n",
      "Epoch [4791/20000], Loss: 185.15426635742188, Entropy -226.7777862548828, Learning Rate: 7.8125e-05\n",
      "Epoch [4792/20000], Loss: 173.5851593017578, Entropy -207.19866943359375, Learning Rate: 7.8125e-05\n",
      "Epoch [4793/20000], Loss: 170.34898376464844, Entropy -204.73358154296875, Learning Rate: 7.8125e-05\n",
      "Epoch [4794/20000], Loss: 171.68145751953125, Entropy -213.01712036132812, Learning Rate: 7.8125e-05\n",
      "Epoch [4795/20000], Loss: 167.47496032714844, Entropy -206.57618713378906, Learning Rate: 7.8125e-05\n",
      "Epoch [4796/20000], Loss: 171.01727294921875, Entropy -213.5354766845703, Learning Rate: 7.8125e-05\n",
      "Epoch [4797/20000], Loss: 171.72389221191406, Entropy -212.19906616210938, Learning Rate: 7.8125e-05\n",
      "Epoch [4798/20000], Loss: 175.91885375976562, Entropy -214.1153564453125, Learning Rate: 7.8125e-05\n",
      "Epoch [4799/20000], Loss: 175.8861846923828, Entropy -218.4451141357422, Learning Rate: 7.8125e-05\n",
      "Epoch [4800/20000], Loss: 175.67138671875, Entropy -219.86636352539062, Learning Rate: 7.8125e-05\n",
      "Epoch [4801/20000], Loss: 163.8410186767578, Entropy -198.8726043701172, Learning Rate: 7.8125e-05\n",
      "Epoch [4802/20000], Loss: 179.56692504882812, Entropy -219.61216735839844, Learning Rate: 7.8125e-05\n",
      "Epoch [4803/20000], Loss: 172.00595092773438, Entropy -210.57432556152344, Learning Rate: 7.8125e-05\n",
      "Epoch [4804/20000], Loss: 167.71595764160156, Entropy -205.9304656982422, Learning Rate: 7.8125e-05\n",
      "Epoch [4805/20000], Loss: 175.4588623046875, Entropy -219.7898712158203, Learning Rate: 7.8125e-05\n",
      "Epoch [4806/20000], Loss: 166.6151580810547, Entropy -201.71310424804688, Learning Rate: 7.8125e-05\n",
      "Epoch [4807/20000], Loss: 169.0578155517578, Entropy -210.17437744140625, Learning Rate: 7.8125e-05\n",
      "Epoch [4808/20000], Loss: 168.71005249023438, Entropy -206.515625, Learning Rate: 7.8125e-05\n",
      "Epoch [4809/20000], Loss: 180.56927490234375, Entropy -208.98800659179688, Learning Rate: 7.8125e-05\n",
      "Epoch [4810/20000], Loss: 172.938720703125, Entropy -211.021728515625, Learning Rate: 7.8125e-05\n",
      "Epoch [4811/20000], Loss: 173.74163818359375, Entropy -216.81179809570312, Learning Rate: 7.8125e-05\n",
      "Epoch [4812/20000], Loss: 179.84487915039062, Entropy -228.523193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [4813/20000], Loss: 166.10975646972656, Entropy -207.02542114257812, Learning Rate: 7.8125e-05\n",
      "Epoch [4814/20000], Loss: 172.8003387451172, Entropy -211.89968872070312, Learning Rate: 7.8125e-05\n",
      "Epoch [4815/20000], Loss: 171.49928283691406, Entropy -211.35145568847656, Learning Rate: 7.8125e-05\n",
      "Epoch [4816/20000], Loss: 180.45957946777344, Entropy -213.62184143066406, Learning Rate: 7.8125e-05\n",
      "Epoch [4817/20000], Loss: 170.42747497558594, Entropy -213.150634765625, Learning Rate: 7.8125e-05\n",
      "Epoch [4818/20000], Loss: 180.3974151611328, Entropy -220.16452026367188, Learning Rate: 7.8125e-05\n",
      "Epoch [4819/20000], Loss: 181.32199096679688, Entropy -219.98822021484375, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4820/20000], Loss: 178.7733154296875, Entropy -212.61277770996094, Learning Rate: 7.8125e-05\n",
      "Epoch [4821/20000], Loss: 184.6148223876953, Entropy -225.59616088867188, Learning Rate: 7.8125e-05\n",
      "Epoch [4822/20000], Loss: 176.45140075683594, Entropy -216.93197631835938, Learning Rate: 7.8125e-05\n",
      "Epoch [4823/20000], Loss: 169.03416442871094, Entropy -209.0198974609375, Learning Rate: 7.8125e-05\n",
      "Epoch [4824/20000], Loss: 170.6209716796875, Entropy -208.8636016845703, Learning Rate: 7.8125e-05\n",
      "Epoch [4825/20000], Loss: 184.5697479248047, Entropy -226.802490234375, Learning Rate: 7.8125e-05\n",
      "Epoch [4826/20000], Loss: 168.52536010742188, Entropy -205.9622802734375, Learning Rate: 7.8125e-05\n",
      "Epoch [4827/20000], Loss: 170.14682006835938, Entropy -209.71412658691406, Learning Rate: 7.8125e-05\n",
      "Epoch [4828/20000], Loss: 174.33566284179688, Entropy -216.51434326171875, Learning Rate: 7.8125e-05\n",
      "Epoch [4829/20000], Loss: 173.27684020996094, Entropy -209.852783203125, Learning Rate: 7.8125e-05\n",
      "Epoch [4830/20000], Loss: 180.75669860839844, Entropy -223.41561889648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4831/20000], Loss: 182.0754852294922, Entropy -222.74578857421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4832/20000], Loss: 202.57003784179688, Entropy -240.82142639160156, Learning Rate: 7.8125e-05\n",
      "Epoch [4833/20000], Loss: 175.81153869628906, Entropy -214.3868408203125, Learning Rate: 7.8125e-05\n",
      "Epoch [4834/20000], Loss: 172.63751220703125, Entropy -213.6334228515625, Learning Rate: 7.8125e-05\n",
      "Epoch [4835/20000], Loss: 186.2423095703125, Entropy -224.2899169921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4836/20000], Loss: 178.2041015625, Entropy -222.02615356445312, Learning Rate: 7.8125e-05\n",
      "Epoch [4837/20000], Loss: 176.8922119140625, Entropy -217.58164978027344, Learning Rate: 7.8125e-05\n",
      "Epoch [4838/20000], Loss: 173.22109985351562, Entropy -210.24151611328125, Learning Rate: 7.8125e-05\n",
      "Epoch [4839/20000], Loss: 174.33763122558594, Entropy -207.24029541015625, Learning Rate: 7.8125e-05\n",
      "Epoch [4840/20000], Loss: 170.72303771972656, Entropy -211.24655151367188, Learning Rate: 7.8125e-05\n",
      "Epoch [4841/20000], Loss: 172.93788146972656, Entropy -204.93531799316406, Learning Rate: 7.8125e-05\n",
      "Epoch [4842/20000], Loss: 167.57144165039062, Entropy -199.74710083007812, Learning Rate: 7.8125e-05\n",
      "Epoch [4843/20000], Loss: 176.47500610351562, Entropy -219.06884765625, Learning Rate: 7.8125e-05\n",
      "Epoch [4844/20000], Loss: 178.59239196777344, Entropy -224.224609375, Learning Rate: 7.8125e-05\n",
      "Epoch [4845/20000], Loss: 179.1649932861328, Entropy -222.44454956054688, Learning Rate: 7.8125e-05\n",
      "Epoch [4846/20000], Loss: 168.7296600341797, Entropy -202.05648803710938, Learning Rate: 7.8125e-05\n",
      "Epoch [4847/20000], Loss: 179.13851928710938, Entropy -216.49981689453125, Learning Rate: 7.8125e-05\n",
      "Epoch [4848/20000], Loss: 166.33412170410156, Entropy -205.43624877929688, Learning Rate: 7.8125e-05\n",
      "Epoch [4849/20000], Loss: 169.69590759277344, Entropy -209.74859619140625, Learning Rate: 7.8125e-05\n",
      "Epoch [4850/20000], Loss: 171.0194854736328, Entropy -213.615478515625, Learning Rate: 7.8125e-05\n",
      "Epoch [4851/20000], Loss: 176.4185028076172, Entropy -214.62588500976562, Learning Rate: 7.8125e-05\n",
      "Epoch [4852/20000], Loss: 179.32574462890625, Entropy -215.40151977539062, Learning Rate: 7.8125e-05\n",
      "Epoch [4853/20000], Loss: 169.72532653808594, Entropy -207.3275604248047, Learning Rate: 7.8125e-05\n",
      "Epoch [4854/20000], Loss: 182.6357879638672, Entropy -220.09014892578125, Learning Rate: 7.8125e-05\n",
      "Epoch [4855/20000], Loss: 171.71963500976562, Entropy -216.01004028320312, Learning Rate: 7.8125e-05\n",
      "Epoch [4856/20000], Loss: 175.13674926757812, Entropy -211.04556274414062, Learning Rate: 7.8125e-05\n",
      "Epoch [4857/20000], Loss: 174.41217041015625, Entropy -215.3650665283203, Learning Rate: 7.8125e-05\n",
      "Epoch [4858/20000], Loss: 179.57566833496094, Entropy -212.10194396972656, Learning Rate: 7.8125e-05\n",
      "Epoch [4859/20000], Loss: 172.6967010498047, Entropy -210.27198791503906, Learning Rate: 7.8125e-05\n",
      "Epoch [4860/20000], Loss: 181.00379943847656, Entropy -222.90460205078125, Learning Rate: 7.8125e-05\n",
      "Epoch [4861/20000], Loss: 169.84686279296875, Entropy -201.18133544921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4862/20000], Loss: 174.7720489501953, Entropy -202.66172790527344, Learning Rate: 7.8125e-05\n",
      "Epoch [4863/20000], Loss: 184.72998046875, Entropy -224.7748565673828, Learning Rate: 7.8125e-05\n",
      "Epoch [4864/20000], Loss: 172.9991912841797, Entropy -208.1725311279297, Learning Rate: 7.8125e-05\n",
      "Epoch [4865/20000], Loss: 171.6262664794922, Entropy -209.9005126953125, Learning Rate: 7.8125e-05\n",
      "Epoch [4866/20000], Loss: 173.18923950195312, Entropy -212.16976928710938, Learning Rate: 7.8125e-05\n",
      "Epoch [4867/20000], Loss: 182.3084716796875, Entropy -228.16590881347656, Learning Rate: 7.8125e-05\n",
      "Epoch [4868/20000], Loss: 169.00718688964844, Entropy -205.1208038330078, Learning Rate: 7.8125e-05\n",
      "Epoch [4869/20000], Loss: 173.68258666992188, Entropy -213.78387451171875, Learning Rate: 7.8125e-05\n",
      "Epoch [4870/20000], Loss: 174.16160583496094, Entropy -208.57540893554688, Learning Rate: 7.8125e-05\n",
      "Epoch [4871/20000], Loss: 179.05323791503906, Entropy -217.42929077148438, Learning Rate: 7.8125e-05\n",
      "Epoch [4872/20000], Loss: 173.20938110351562, Entropy -213.93927001953125, Learning Rate: 7.8125e-05\n",
      "Epoch [4873/20000], Loss: 173.28895568847656, Entropy -209.86233520507812, Learning Rate: 7.8125e-05\n",
      "Epoch [4874/20000], Loss: 175.026611328125, Entropy -215.22787475585938, Learning Rate: 7.8125e-05\n",
      "Epoch [4875/20000], Loss: 176.0369415283203, Entropy -210.8729248046875, Learning Rate: 7.8125e-05\n",
      "Epoch [4876/20000], Loss: 175.5632781982422, Entropy -210.876953125, Learning Rate: 7.8125e-05\n",
      "Epoch [4877/20000], Loss: 166.2821044921875, Entropy -205.46682739257812, Learning Rate: 7.8125e-05\n",
      "Epoch [4878/20000], Loss: 168.98611450195312, Entropy -205.95858764648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4879/20000], Loss: 166.4354705810547, Entropy -202.75537109375, Learning Rate: 7.8125e-05\n",
      "Epoch [4880/20000], Loss: 171.67376708984375, Entropy -213.500732421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4881/20000], Loss: 186.43394470214844, Entropy -222.70660400390625, Learning Rate: 7.8125e-05\n",
      "Epoch [4882/20000], Loss: 181.25665283203125, Entropy -223.64845275878906, Learning Rate: 7.8125e-05\n",
      "Epoch [4883/20000], Loss: 176.54595947265625, Entropy -210.78152465820312, Learning Rate: 7.8125e-05\n",
      "Epoch [4884/20000], Loss: 178.48251342773438, Entropy -220.449951171875, Learning Rate: 7.8125e-05\n",
      "Epoch [4885/20000], Loss: 176.79461669921875, Entropy -214.0568084716797, Learning Rate: 7.8125e-05\n",
      "Epoch [4886/20000], Loss: 166.16334533691406, Entropy -203.10752868652344, Learning Rate: 7.8125e-05\n",
      "Epoch [4887/20000], Loss: 185.73477172851562, Entropy -224.66668701171875, Learning Rate: 7.8125e-05\n",
      "Epoch [4888/20000], Loss: 180.649658203125, Entropy -218.76708984375, Learning Rate: 7.8125e-05\n",
      "Epoch [4889/20000], Loss: 178.89292907714844, Entropy -222.35911560058594, Learning Rate: 7.8125e-05\n",
      "Epoch [4890/20000], Loss: 163.33424377441406, Entropy -204.90255737304688, Learning Rate: 7.8125e-05\n",
      "Epoch [4891/20000], Loss: 176.6031494140625, Entropy -209.99127197265625, Learning Rate: 7.8125e-05\n",
      "Epoch [4892/20000], Loss: 169.21875, Entropy -207.38031005859375, Learning Rate: 7.8125e-05\n",
      "Epoch [4893/20000], Loss: 174.25457763671875, Entropy -218.44200134277344, Learning Rate: 7.8125e-05\n",
      "Epoch [4894/20000], Loss: 170.02597045898438, Entropy -199.58187866210938, Learning Rate: 7.8125e-05\n",
      "Epoch [4895/20000], Loss: 167.73757934570312, Entropy -201.92713928222656, Learning Rate: 7.8125e-05\n",
      "Epoch [4896/20000], Loss: 171.7255859375, Entropy -211.82083129882812, Learning Rate: 7.8125e-05\n",
      "Epoch [4897/20000], Loss: 168.8116455078125, Entropy -206.82215881347656, Learning Rate: 7.8125e-05\n",
      "Epoch [4898/20000], Loss: 172.37991333007812, Entropy -213.25772094726562, Learning Rate: 7.8125e-05\n",
      "Epoch [4899/20000], Loss: 171.2530975341797, Entropy -210.18081665039062, Learning Rate: 7.8125e-05\n",
      "Epoch [4900/20000], Loss: 173.0055389404297, Entropy -215.17620849609375, Learning Rate: 7.8125e-05\n",
      "Epoch [4901/20000], Loss: 172.20814514160156, Entropy -213.3104248046875, Learning Rate: 7.8125e-05\n",
      "Epoch [4902/20000], Loss: 171.2191162109375, Entropy -201.76901245117188, Learning Rate: 3.90625e-05\n",
      "Epoch [4903/20000], Loss: 170.50965881347656, Entropy -208.6190185546875, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4904/20000], Loss: 170.4344940185547, Entropy -209.3251953125, Learning Rate: 3.90625e-05\n",
      "Epoch [4905/20000], Loss: 173.400146484375, Entropy -209.80419921875, Learning Rate: 3.90625e-05\n",
      "Epoch [4906/20000], Loss: 182.4127960205078, Entropy -222.10006713867188, Learning Rate: 3.90625e-05\n",
      "Epoch [4907/20000], Loss: 180.47496032714844, Entropy -220.0017852783203, Learning Rate: 3.90625e-05\n",
      "Epoch [4908/20000], Loss: 182.9637908935547, Entropy -226.32359313964844, Learning Rate: 3.90625e-05\n",
      "Epoch [4909/20000], Loss: 185.38681030273438, Entropy -223.01953125, Learning Rate: 3.90625e-05\n",
      "Epoch [4910/20000], Loss: 169.26104736328125, Entropy -206.19606018066406, Learning Rate: 3.90625e-05\n",
      "Epoch [4911/20000], Loss: 169.79505920410156, Entropy -206.45654296875, Learning Rate: 3.90625e-05\n",
      "Epoch [4912/20000], Loss: 170.64219665527344, Entropy -203.50198364257812, Learning Rate: 3.90625e-05\n",
      "Epoch [4913/20000], Loss: 171.51622009277344, Entropy -207.09954833984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4914/20000], Loss: 164.0898895263672, Entropy -211.47097778320312, Learning Rate: 3.90625e-05\n",
      "Epoch [4915/20000], Loss: 175.10189819335938, Entropy -209.7089080810547, Learning Rate: 3.90625e-05\n",
      "Epoch [4916/20000], Loss: 175.733642578125, Entropy -217.1986083984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4917/20000], Loss: 182.13101196289062, Entropy -219.39576721191406, Learning Rate: 3.90625e-05\n",
      "Epoch [4918/20000], Loss: 181.2169647216797, Entropy -215.64097595214844, Learning Rate: 3.90625e-05\n",
      "Epoch [4919/20000], Loss: 168.53707885742188, Entropy -205.55349731445312, Learning Rate: 3.90625e-05\n",
      "Epoch [4920/20000], Loss: 174.04330444335938, Entropy -211.9747772216797, Learning Rate: 3.90625e-05\n",
      "Epoch [4921/20000], Loss: 167.79058837890625, Entropy -200.23690795898438, Learning Rate: 3.90625e-05\n",
      "Epoch [4922/20000], Loss: 173.379638671875, Entropy -209.85423278808594, Learning Rate: 3.90625e-05\n",
      "Epoch [4923/20000], Loss: 179.95404052734375, Entropy -218.82717895507812, Learning Rate: 3.90625e-05\n",
      "Epoch [4924/20000], Loss: 184.1173095703125, Entropy -231.8844451904297, Learning Rate: 3.90625e-05\n",
      "Epoch [4925/20000], Loss: 185.83802795410156, Entropy -226.29986572265625, Learning Rate: 3.90625e-05\n",
      "Epoch [4926/20000], Loss: 169.80670166015625, Entropy -203.2621307373047, Learning Rate: 3.90625e-05\n",
      "Epoch [4927/20000], Loss: 175.79270935058594, Entropy -216.8587646484375, Learning Rate: 3.90625e-05\n",
      "Epoch [4928/20000], Loss: 168.4456787109375, Entropy -207.7814178466797, Learning Rate: 3.90625e-05\n",
      "Epoch [4929/20000], Loss: 178.26541137695312, Entropy -212.99017333984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4930/20000], Loss: 172.78219604492188, Entropy -197.27830505371094, Learning Rate: 3.90625e-05\n",
      "Epoch [4931/20000], Loss: 177.51953125, Entropy -210.3484344482422, Learning Rate: 3.90625e-05\n",
      "Epoch [4932/20000], Loss: 173.32684326171875, Entropy -212.43630981445312, Learning Rate: 3.90625e-05\n",
      "Epoch [4933/20000], Loss: 190.6358184814453, Entropy -229.73779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [4934/20000], Loss: 172.75338745117188, Entropy -213.7789306640625, Learning Rate: 3.90625e-05\n",
      "Epoch [4935/20000], Loss: 175.47760009765625, Entropy -218.94313049316406, Learning Rate: 3.90625e-05\n",
      "Epoch [4936/20000], Loss: 180.37586975097656, Entropy -215.8418731689453, Learning Rate: 3.90625e-05\n",
      "Epoch [4937/20000], Loss: 171.07269287109375, Entropy -209.8497314453125, Learning Rate: 3.90625e-05\n",
      "Epoch [4938/20000], Loss: 190.64540100097656, Entropy -223.197265625, Learning Rate: 3.90625e-05\n",
      "Epoch [4939/20000], Loss: 177.84628295898438, Entropy -215.25631713867188, Learning Rate: 3.90625e-05\n",
      "Epoch [4940/20000], Loss: 173.51312255859375, Entropy -207.42108154296875, Learning Rate: 3.90625e-05\n",
      "Epoch [4941/20000], Loss: 179.62107849121094, Entropy -219.63519287109375, Learning Rate: 3.90625e-05\n",
      "Epoch [4942/20000], Loss: 178.9025115966797, Entropy -221.71856689453125, Learning Rate: 3.90625e-05\n",
      "Epoch [4943/20000], Loss: 173.05184936523438, Entropy -210.2587890625, Learning Rate: 3.90625e-05\n",
      "Epoch [4944/20000], Loss: 174.78225708007812, Entropy -211.07052612304688, Learning Rate: 3.90625e-05\n",
      "Epoch [4945/20000], Loss: 194.4444580078125, Entropy -236.7208251953125, Learning Rate: 3.90625e-05\n",
      "Epoch [4946/20000], Loss: 175.98284912109375, Entropy -218.67263793945312, Learning Rate: 3.90625e-05\n",
      "Epoch [4947/20000], Loss: 177.91041564941406, Entropy -213.42251586914062, Learning Rate: 3.90625e-05\n",
      "Epoch [4948/20000], Loss: 185.86328125, Entropy -215.76925659179688, Learning Rate: 3.90625e-05\n",
      "Epoch [4949/20000], Loss: 179.68035888671875, Entropy -221.30609130859375, Learning Rate: 3.90625e-05\n",
      "Epoch [4950/20000], Loss: 182.09060668945312, Entropy -227.74380493164062, Learning Rate: 3.90625e-05\n",
      "Epoch [4951/20000], Loss: 179.8152313232422, Entropy -224.2702178955078, Learning Rate: 3.90625e-05\n",
      "Epoch [4952/20000], Loss: 171.70997619628906, Entropy -211.81057739257812, Learning Rate: 3.90625e-05\n",
      "Epoch [4953/20000], Loss: 167.392578125, Entropy -202.76657104492188, Learning Rate: 3.90625e-05\n",
      "Epoch [4954/20000], Loss: 184.8347625732422, Entropy -232.68353271484375, Learning Rate: 3.90625e-05\n",
      "Epoch [4955/20000], Loss: 184.58863830566406, Entropy -232.3103485107422, Learning Rate: 3.90625e-05\n",
      "Epoch [4956/20000], Loss: 170.80528259277344, Entropy -200.4342041015625, Learning Rate: 3.90625e-05\n",
      "Epoch [4957/20000], Loss: 174.16796875, Entropy -218.20455932617188, Learning Rate: 3.90625e-05\n",
      "Epoch [4958/20000], Loss: 161.9053192138672, Entropy -203.4715118408203, Learning Rate: 3.90625e-05\n",
      "Epoch [4959/20000], Loss: 177.75674438476562, Entropy -217.1859893798828, Learning Rate: 3.90625e-05\n",
      "Epoch [4960/20000], Loss: 177.76760864257812, Entropy -210.85899353027344, Learning Rate: 3.90625e-05\n",
      "Epoch [4961/20000], Loss: 176.36026000976562, Entropy -215.33621215820312, Learning Rate: 3.90625e-05\n",
      "Epoch [4962/20000], Loss: 179.9766082763672, Entropy -217.3540496826172, Learning Rate: 3.90625e-05\n",
      "Epoch [4963/20000], Loss: 182.13291931152344, Entropy -221.93350219726562, Learning Rate: 3.90625e-05\n",
      "Epoch [4964/20000], Loss: 185.05592346191406, Entropy -222.32968139648438, Learning Rate: 3.90625e-05\n",
      "Epoch [4965/20000], Loss: 185.01577758789062, Entropy -219.4844970703125, Learning Rate: 3.90625e-05\n",
      "Epoch [4966/20000], Loss: 176.7569580078125, Entropy -225.15921020507812, Learning Rate: 3.90625e-05\n",
      "Epoch [4967/20000], Loss: 186.52151489257812, Entropy -224.66371154785156, Learning Rate: 3.90625e-05\n",
      "Epoch [4968/20000], Loss: 183.4394989013672, Entropy -223.02651977539062, Learning Rate: 3.90625e-05\n",
      "Epoch [4969/20000], Loss: 168.2973175048828, Entropy -212.72933959960938, Learning Rate: 3.90625e-05\n",
      "Epoch [4970/20000], Loss: 172.999267578125, Entropy -211.38978576660156, Learning Rate: 3.90625e-05\n",
      "Epoch [4971/20000], Loss: 171.6771697998047, Entropy -206.1730194091797, Learning Rate: 3.90625e-05\n",
      "Epoch [4972/20000], Loss: 176.37315368652344, Entropy -215.94419860839844, Learning Rate: 3.90625e-05\n",
      "Epoch [4973/20000], Loss: 178.3379364013672, Entropy -217.77777099609375, Learning Rate: 3.90625e-05\n",
      "Epoch [4974/20000], Loss: 176.96824645996094, Entropy -218.0643310546875, Learning Rate: 3.90625e-05\n",
      "Epoch [4975/20000], Loss: 174.52853393554688, Entropy -212.38912963867188, Learning Rate: 3.90625e-05\n",
      "Epoch [4976/20000], Loss: 169.78636169433594, Entropy -202.51931762695312, Learning Rate: 3.90625e-05\n",
      "Epoch [4977/20000], Loss: 171.10418701171875, Entropy -208.9227752685547, Learning Rate: 3.90625e-05\n",
      "Epoch [4978/20000], Loss: 176.53517150878906, Entropy -217.48153686523438, Learning Rate: 3.90625e-05\n",
      "Epoch [4979/20000], Loss: 179.67332458496094, Entropy -220.4109649658203, Learning Rate: 3.90625e-05\n",
      "Epoch [4980/20000], Loss: 165.3270263671875, Entropy -209.58718872070312, Learning Rate: 3.90625e-05\n",
      "Epoch [4981/20000], Loss: 169.53543090820312, Entropy -210.2393798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4982/20000], Loss: 169.3353729248047, Entropy -210.95892333984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4983/20000], Loss: 180.37623596191406, Entropy -220.39735412597656, Learning Rate: 3.90625e-05\n",
      "Epoch [4984/20000], Loss: 183.71429443359375, Entropy -225.5664520263672, Learning Rate: 3.90625e-05\n",
      "Epoch [4985/20000], Loss: 185.16683959960938, Entropy -229.18519592285156, Learning Rate: 3.90625e-05\n",
      "Epoch [4986/20000], Loss: 175.64218139648438, Entropy -215.4388885498047, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4987/20000], Loss: 174.562744140625, Entropy -214.0623779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [4988/20000], Loss: 178.13897705078125, Entropy -216.426513671875, Learning Rate: 3.90625e-05\n",
      "Epoch [4989/20000], Loss: 177.70379638671875, Entropy -213.01133728027344, Learning Rate: 3.90625e-05\n",
      "Epoch [4990/20000], Loss: 166.12184143066406, Entropy -201.8215789794922, Learning Rate: 3.90625e-05\n",
      "Epoch [4991/20000], Loss: 168.0203857421875, Entropy -212.55470275878906, Learning Rate: 3.90625e-05\n",
      "Epoch [4992/20000], Loss: 176.36416625976562, Entropy -216.4873046875, Learning Rate: 3.90625e-05\n",
      "Epoch [4993/20000], Loss: 171.55490112304688, Entropy -207.7779541015625, Learning Rate: 3.90625e-05\n",
      "Epoch [4994/20000], Loss: 168.8211669921875, Entropy -208.177001953125, Learning Rate: 3.90625e-05\n",
      "Epoch [4995/20000], Loss: 185.87290954589844, Entropy -230.43199157714844, Learning Rate: 3.90625e-05\n",
      "Epoch [4996/20000], Loss: 169.95050048828125, Entropy -211.63925170898438, Learning Rate: 3.90625e-05\n",
      "Epoch [4997/20000], Loss: 180.5222625732422, Entropy -220.06895446777344, Learning Rate: 3.90625e-05\n",
      "Epoch [4998/20000], Loss: 173.83148193359375, Entropy -211.03355407714844, Learning Rate: 3.90625e-05\n",
      "Epoch [4999/20000], Loss: 170.50746154785156, Entropy -199.59068298339844, Learning Rate: 3.90625e-05\n",
      "Epoch [5000/20000], Loss: 161.38970947265625, Entropy -203.0170440673828, Learning Rate: 3.90625e-05\n",
      "Epoch [5001/20000], Loss: 176.47964477539062, Entropy -221.11614990234375, Learning Rate: 3.90625e-05\n",
      "Epoch [5002/20000], Loss: 173.1649932861328, Entropy -208.1603546142578, Learning Rate: 3.90625e-05\n",
      "Epoch [5003/20000], Loss: 177.73365783691406, Entropy -218.88571166992188, Learning Rate: 3.90625e-05\n",
      "Epoch [5004/20000], Loss: 177.17259216308594, Entropy -213.187744140625, Learning Rate: 3.90625e-05\n",
      "Epoch [5005/20000], Loss: 183.31146240234375, Entropy -215.27633666992188, Learning Rate: 3.90625e-05\n",
      "Epoch [5006/20000], Loss: 184.3611297607422, Entropy -214.254150390625, Learning Rate: 3.90625e-05\n",
      "Epoch [5007/20000], Loss: 176.59127807617188, Entropy -209.13626098632812, Learning Rate: 3.90625e-05\n",
      "Epoch [5008/20000], Loss: 178.6298828125, Entropy -211.258544921875, Learning Rate: 3.90625e-05\n",
      "Epoch [5009/20000], Loss: 191.28895568847656, Entropy -232.0494842529297, Learning Rate: 3.90625e-05\n",
      "Epoch [5010/20000], Loss: 176.99404907226562, Entropy -219.9881134033203, Learning Rate: 3.90625e-05\n",
      "Epoch [5011/20000], Loss: 173.7507781982422, Entropy -212.29815673828125, Learning Rate: 3.90625e-05\n",
      "Epoch [5012/20000], Loss: 176.0919952392578, Entropy -211.39971923828125, Learning Rate: 3.90625e-05\n",
      "Epoch [5013/20000], Loss: 175.14813232421875, Entropy -211.5623016357422, Learning Rate: 3.90625e-05\n",
      "Epoch [5014/20000], Loss: 183.7801513671875, Entropy -222.0833282470703, Learning Rate: 3.90625e-05\n",
      "Epoch [5015/20000], Loss: 172.52285766601562, Entropy -221.86221313476562, Learning Rate: 3.90625e-05\n",
      "Epoch [5016/20000], Loss: 179.69021606445312, Entropy -220.75100708007812, Learning Rate: 3.90625e-05\n",
      "Epoch [5017/20000], Loss: 182.411865234375, Entropy -217.928955078125, Learning Rate: 3.90625e-05\n",
      "Epoch [5018/20000], Loss: 183.27447509765625, Entropy -223.6220703125, Learning Rate: 3.90625e-05\n",
      "Epoch [5019/20000], Loss: 173.67091369628906, Entropy -214.31829833984375, Learning Rate: 3.90625e-05\n",
      "Epoch [5020/20000], Loss: 184.39698791503906, Entropy -211.88319396972656, Learning Rate: 3.90625e-05\n",
      "Epoch [5021/20000], Loss: 177.40245056152344, Entropy -217.8725128173828, Learning Rate: 3.90625e-05\n",
      "Epoch [5022/20000], Loss: 190.46009826660156, Entropy -232.65969848632812, Learning Rate: 3.90625e-05\n",
      "Epoch [5023/20000], Loss: 173.71653747558594, Entropy -208.12161254882812, Learning Rate: 3.90625e-05\n",
      "Epoch [5024/20000], Loss: 183.2790069580078, Entropy -219.27081298828125, Learning Rate: 3.90625e-05\n",
      "Epoch [5025/20000], Loss: 172.38148498535156, Entropy -213.345703125, Learning Rate: 3.90625e-05\n",
      "Epoch [5026/20000], Loss: 161.37794494628906, Entropy -199.3352813720703, Learning Rate: 3.90625e-05\n",
      "Epoch [5027/20000], Loss: 179.8217315673828, Entropy -212.45806884765625, Learning Rate: 3.90625e-05\n",
      "Epoch [5028/20000], Loss: 181.5828857421875, Entropy -222.68531799316406, Learning Rate: 3.90625e-05\n",
      "Epoch [5029/20000], Loss: 175.6143798828125, Entropy -216.47764587402344, Learning Rate: 3.90625e-05\n",
      "Epoch [5030/20000], Loss: 174.00323486328125, Entropy -207.0662078857422, Learning Rate: 3.90625e-05\n",
      "Epoch [5031/20000], Loss: 173.32859802246094, Entropy -213.98548889160156, Learning Rate: 3.90625e-05\n",
      "Epoch [5032/20000], Loss: 175.3237762451172, Entropy -211.20443725585938, Learning Rate: 3.90625e-05\n",
      "Epoch [5033/20000], Loss: 170.67332458496094, Entropy -209.53652954101562, Learning Rate: 3.90625e-05\n",
      "Epoch [5034/20000], Loss: 169.271484375, Entropy -202.48602294921875, Learning Rate: 3.90625e-05\n",
      "Epoch [5035/20000], Loss: 172.45928955078125, Entropy -210.91720581054688, Learning Rate: 3.90625e-05\n",
      "Epoch [5036/20000], Loss: 178.04640197753906, Entropy -209.48959350585938, Learning Rate: 3.90625e-05\n",
      "Epoch [5037/20000], Loss: 174.04678344726562, Entropy -212.82225036621094, Learning Rate: 3.90625e-05\n",
      "Epoch [5038/20000], Loss: 174.2848663330078, Entropy -209.0953369140625, Learning Rate: 3.90625e-05\n",
      "Epoch [5039/20000], Loss: 186.88404846191406, Entropy -226.66883850097656, Learning Rate: 3.90625e-05\n",
      "Epoch [5040/20000], Loss: 175.12583923339844, Entropy -207.86061096191406, Learning Rate: 3.90625e-05\n",
      "Epoch [5041/20000], Loss: 190.5654754638672, Entropy -235.55250549316406, Learning Rate: 3.90625e-05\n",
      "Epoch [5042/20000], Loss: 177.5193634033203, Entropy -211.11557006835938, Learning Rate: 3.90625e-05\n",
      "Epoch [5043/20000], Loss: 184.43519592285156, Entropy -218.17855834960938, Learning Rate: 3.90625e-05\n",
      "Epoch [5044/20000], Loss: 175.81944274902344, Entropy -215.30938720703125, Learning Rate: 3.90625e-05\n",
      "Epoch [5045/20000], Loss: 181.7755889892578, Entropy -209.0035400390625, Learning Rate: 3.90625e-05\n",
      "Epoch [5046/20000], Loss: 175.26087951660156, Entropy -213.0481414794922, Learning Rate: 3.90625e-05\n",
      "Epoch [5047/20000], Loss: 173.904052734375, Entropy -211.01638793945312, Learning Rate: 3.90625e-05\n",
      "Epoch [5048/20000], Loss: 169.9084930419922, Entropy -205.1056671142578, Learning Rate: 3.90625e-05\n",
      "Epoch [5049/20000], Loss: 173.02243041992188, Entropy -212.6933135986328, Learning Rate: 3.90625e-05\n",
      "Epoch [5050/20000], Loss: 168.02182006835938, Entropy -207.4832305908203, Learning Rate: 3.90625e-05\n",
      "Epoch [5051/20000], Loss: 173.42733764648438, Entropy -211.67579650878906, Learning Rate: 3.90625e-05\n",
      "Epoch [5052/20000], Loss: 172.7161865234375, Entropy -209.34657287597656, Learning Rate: 3.90625e-05\n",
      "Epoch [5053/20000], Loss: 174.98023986816406, Entropy -207.0191192626953, Learning Rate: 3.90625e-05\n",
      "Epoch [5054/20000], Loss: 180.00030517578125, Entropy -216.1419677734375, Learning Rate: 3.90625e-05\n",
      "Epoch [5055/20000], Loss: 176.07981872558594, Entropy -215.27996826171875, Learning Rate: 3.90625e-05\n",
      "Epoch [5056/20000], Loss: 180.23069763183594, Entropy -221.76168823242188, Learning Rate: 3.90625e-05\n",
      "Epoch [5057/20000], Loss: 170.16952514648438, Entropy -212.1655731201172, Learning Rate: 3.90625e-05\n",
      "Epoch [5058/20000], Loss: 178.38851928710938, Entropy -215.164306640625, Learning Rate: 3.90625e-05\n",
      "Epoch [5059/20000], Loss: 174.96463012695312, Entropy -210.85601806640625, Learning Rate: 3.90625e-05\n",
      "Epoch [5060/20000], Loss: 177.8429412841797, Entropy -213.4532470703125, Learning Rate: 3.90625e-05\n",
      "Epoch [5061/20000], Loss: 178.11495971679688, Entropy -216.1874542236328, Learning Rate: 3.90625e-05\n",
      "Epoch [5062/20000], Loss: 171.27333068847656, Entropy -208.6533203125, Learning Rate: 3.90625e-05\n",
      "Epoch [5063/20000], Loss: 185.6173095703125, Entropy -208.69985961914062, Learning Rate: 3.90625e-05\n",
      "Epoch [5064/20000], Loss: 174.74794006347656, Entropy -214.0301513671875, Learning Rate: 3.90625e-05\n",
      "Epoch [5065/20000], Loss: 171.25411987304688, Entropy -207.2996368408203, Learning Rate: 3.90625e-05\n",
      "Epoch [5066/20000], Loss: 179.37660217285156, Entropy -214.26499938964844, Learning Rate: 3.90625e-05\n",
      "Epoch [5067/20000], Loss: 173.69009399414062, Entropy -208.79736328125, Learning Rate: 3.90625e-05\n",
      "Epoch [5068/20000], Loss: 170.12083435058594, Entropy -206.9328155517578, Learning Rate: 3.90625e-05\n",
      "Epoch [5069/20000], Loss: 172.89329528808594, Entropy -207.6901092529297, Learning Rate: 3.90625e-05\n",
      "Epoch [5070/20000], Loss: 170.2605743408203, Entropy -214.76077270507812, Learning Rate: 3.90625e-05\n",
      "Epoch [5071/20000], Loss: 173.73948669433594, Entropy -215.50970458984375, Learning Rate: 3.90625e-05\n",
      "Epoch [5072/20000], Loss: 167.18734741210938, Entropy -205.12083435058594, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5073/20000], Loss: 177.18545532226562, Entropy -210.46835327148438, Learning Rate: 3.90625e-05\n",
      "Epoch [5074/20000], Loss: 177.3761749267578, Entropy -209.2635955810547, Learning Rate: 3.90625e-05\n",
      "Epoch [5075/20000], Loss: 177.6365966796875, Entropy -217.43182373046875, Learning Rate: 3.90625e-05\n",
      "Epoch [5076/20000], Loss: 173.53221130371094, Entropy -213.46725463867188, Learning Rate: 3.90625e-05\n",
      "Epoch [5077/20000], Loss: 175.00962829589844, Entropy -214.13259887695312, Learning Rate: 3.90625e-05\n",
      "Epoch [5078/20000], Loss: 165.72706604003906, Entropy -204.97055053710938, Learning Rate: 3.90625e-05\n",
      "Epoch [5079/20000], Loss: 180.0094451904297, Entropy -221.4276123046875, Learning Rate: 3.90625e-05\n",
      "Epoch [5080/20000], Loss: 174.20887756347656, Entropy -208.92515563964844, Learning Rate: 3.90625e-05\n",
      "Epoch [5081/20000], Loss: 165.21783447265625, Entropy -206.16195678710938, Learning Rate: 3.90625e-05\n",
      "Epoch [5082/20000], Loss: 176.19837951660156, Entropy -208.8903350830078, Learning Rate: 3.90625e-05\n",
      "Epoch [5083/20000], Loss: 172.90982055664062, Entropy -214.86233520507812, Learning Rate: 3.90625e-05\n",
      "Epoch [5084/20000], Loss: 175.370361328125, Entropy -212.4175262451172, Learning Rate: 3.90625e-05\n",
      "Epoch [5085/20000], Loss: 168.98944091796875, Entropy -201.1114501953125, Learning Rate: 3.90625e-05\n",
      "Epoch [5086/20000], Loss: 185.63546752929688, Entropy -231.5462646484375, Learning Rate: 3.90625e-05\n",
      "Epoch [5087/20000], Loss: 174.66819763183594, Entropy -211.05606079101562, Learning Rate: 3.90625e-05\n",
      "Epoch [5088/20000], Loss: 179.0041961669922, Entropy -212.16336059570312, Learning Rate: 3.90625e-05\n",
      "Epoch [5089/20000], Loss: 174.82534790039062, Entropy -211.66900634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [5090/20000], Loss: 176.8941650390625, Entropy -221.96319580078125, Learning Rate: 3.90625e-05\n",
      "Epoch [5091/20000], Loss: 174.77890014648438, Entropy -213.16342163085938, Learning Rate: 3.90625e-05\n",
      "Epoch [5092/20000], Loss: 172.06871032714844, Entropy -213.06292724609375, Learning Rate: 3.90625e-05\n",
      "Epoch [5093/20000], Loss: 188.53797912597656, Entropy -223.13211059570312, Learning Rate: 3.90625e-05\n",
      "Epoch [5094/20000], Loss: 172.357666015625, Entropy -204.8787384033203, Learning Rate: 3.90625e-05\n",
      "Epoch [5095/20000], Loss: 180.64508056640625, Entropy -218.60757446289062, Learning Rate: 3.90625e-05\n",
      "Epoch [5096/20000], Loss: 182.25416564941406, Entropy -220.5924530029297, Learning Rate: 3.90625e-05\n",
      "Epoch [5097/20000], Loss: 169.04995727539062, Entropy -204.44752502441406, Learning Rate: 3.90625e-05\n",
      "Epoch [5098/20000], Loss: 173.97836303710938, Entropy -218.01669311523438, Learning Rate: 3.90625e-05\n",
      "Epoch [5099/20000], Loss: 178.06710815429688, Entropy -220.3701629638672, Learning Rate: 3.90625e-05\n",
      "Epoch [5100/20000], Loss: 176.64047241210938, Entropy -208.78892517089844, Learning Rate: 3.90625e-05\n",
      "Epoch [5101/20000], Loss: 176.74185180664062, Entropy -222.5023193359375, Learning Rate: 3.90625e-05\n",
      "Epoch [5102/20000], Loss: 177.67398071289062, Entropy -216.15342712402344, Learning Rate: 3.90625e-05\n",
      "Epoch [5103/20000], Loss: 169.74908447265625, Entropy -200.83343505859375, Learning Rate: 1.953125e-05\n",
      "Epoch [5104/20000], Loss: 169.78591918945312, Entropy -204.2312469482422, Learning Rate: 1.953125e-05\n",
      "Epoch [5105/20000], Loss: 167.47999572753906, Entropy -208.14657592773438, Learning Rate: 1.953125e-05\n",
      "Epoch [5106/20000], Loss: 170.99461364746094, Entropy -210.98643493652344, Learning Rate: 1.953125e-05\n",
      "Epoch [5107/20000], Loss: 181.63938903808594, Entropy -218.9832000732422, Learning Rate: 1.953125e-05\n",
      "Epoch [5108/20000], Loss: 166.0734100341797, Entropy -204.66543579101562, Learning Rate: 1.953125e-05\n",
      "Epoch [5109/20000], Loss: 172.11154174804688, Entropy -209.8076171875, Learning Rate: 1.953125e-05\n",
      "Epoch [5110/20000], Loss: 173.56539916992188, Entropy -211.05490112304688, Learning Rate: 1.953125e-05\n",
      "Epoch [5111/20000], Loss: 180.40394592285156, Entropy -214.3013153076172, Learning Rate: 1.953125e-05\n",
      "Epoch [5112/20000], Loss: 174.84884643554688, Entropy -213.78091430664062, Learning Rate: 1.953125e-05\n",
      "Epoch [5113/20000], Loss: 184.9197540283203, Entropy -220.82626342773438, Learning Rate: 1.953125e-05\n",
      "Epoch [5114/20000], Loss: 167.98353576660156, Entropy -200.91094970703125, Learning Rate: 1.953125e-05\n",
      "Epoch [5115/20000], Loss: 172.672119140625, Entropy -218.55392456054688, Learning Rate: 1.953125e-05\n",
      "Epoch [5116/20000], Loss: 185.063720703125, Entropy -221.2284698486328, Learning Rate: 1.953125e-05\n",
      "Epoch [5117/20000], Loss: 183.79681396484375, Entropy -225.7265167236328, Learning Rate: 1.953125e-05\n",
      "Epoch [5118/20000], Loss: 174.14349365234375, Entropy -212.1692657470703, Learning Rate: 1.953125e-05\n",
      "Epoch [5119/20000], Loss: 178.05194091796875, Entropy -214.26010131835938, Learning Rate: 1.953125e-05\n",
      "Epoch [5120/20000], Loss: 186.17140197753906, Entropy -224.2626495361328, Learning Rate: 1.953125e-05\n",
      "Epoch [5121/20000], Loss: 181.02357482910156, Entropy -217.78277587890625, Learning Rate: 1.953125e-05\n",
      "Epoch [5122/20000], Loss: 174.44541931152344, Entropy -216.50323486328125, Learning Rate: 1.953125e-05\n",
      "Epoch [5123/20000], Loss: 178.22119140625, Entropy -220.6595001220703, Learning Rate: 1.953125e-05\n",
      "Epoch [5124/20000], Loss: 177.6677703857422, Entropy -204.60763549804688, Learning Rate: 1.953125e-05\n",
      "Epoch [5125/20000], Loss: 185.94772338867188, Entropy -220.055419921875, Learning Rate: 1.953125e-05\n",
      "Epoch [5126/20000], Loss: 182.5670166015625, Entropy -222.8204345703125, Learning Rate: 1.953125e-05\n",
      "Epoch [5127/20000], Loss: 189.1554718017578, Entropy -222.92294311523438, Learning Rate: 1.953125e-05\n",
      "Epoch [5128/20000], Loss: 173.55386352539062, Entropy -214.28921508789062, Learning Rate: 1.953125e-05\n",
      "Epoch [5129/20000], Loss: 167.79859924316406, Entropy -210.06362915039062, Learning Rate: 1.953125e-05\n",
      "Epoch [5130/20000], Loss: 177.75033569335938, Entropy -224.048583984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5131/20000], Loss: 187.939453125, Entropy -227.0174560546875, Learning Rate: 1.953125e-05\n",
      "Epoch [5132/20000], Loss: 173.01699829101562, Entropy -213.63783264160156, Learning Rate: 1.953125e-05\n",
      "Epoch [5133/20000], Loss: 175.0206756591797, Entropy -207.73141479492188, Learning Rate: 1.953125e-05\n",
      "Epoch [5134/20000], Loss: 179.69361877441406, Entropy -213.72308349609375, Learning Rate: 1.953125e-05\n",
      "Epoch [5135/20000], Loss: 185.26197814941406, Entropy -228.74246215820312, Learning Rate: 1.953125e-05\n",
      "Epoch [5136/20000], Loss: 171.7967987060547, Entropy -208.64981079101562, Learning Rate: 1.953125e-05\n",
      "Epoch [5137/20000], Loss: 174.22708129882812, Entropy -213.08596801757812, Learning Rate: 1.953125e-05\n",
      "Epoch [5138/20000], Loss: 174.56185913085938, Entropy -217.1143035888672, Learning Rate: 1.953125e-05\n",
      "Epoch [5139/20000], Loss: 181.91046142578125, Entropy -218.90963745117188, Learning Rate: 1.953125e-05\n",
      "Epoch [5140/20000], Loss: 177.13160705566406, Entropy -213.93907165527344, Learning Rate: 1.953125e-05\n",
      "Epoch [5141/20000], Loss: 182.78536987304688, Entropy -221.87005615234375, Learning Rate: 1.953125e-05\n",
      "Epoch [5142/20000], Loss: 168.37501525878906, Entropy -205.21913146972656, Learning Rate: 1.953125e-05\n",
      "Epoch [5143/20000], Loss: 175.55618286132812, Entropy -213.15609741210938, Learning Rate: 1.953125e-05\n",
      "Epoch [5144/20000], Loss: 181.32496643066406, Entropy -223.1925506591797, Learning Rate: 1.953125e-05\n",
      "Epoch [5145/20000], Loss: 175.7716064453125, Entropy -214.8702850341797, Learning Rate: 1.953125e-05\n",
      "Epoch [5146/20000], Loss: 181.3258514404297, Entropy -225.18667602539062, Learning Rate: 1.953125e-05\n",
      "Epoch [5147/20000], Loss: 172.57119750976562, Entropy -210.7882080078125, Learning Rate: 1.953125e-05\n",
      "Epoch [5148/20000], Loss: 185.67523193359375, Entropy -219.94796752929688, Learning Rate: 1.953125e-05\n",
      "Epoch [5149/20000], Loss: 175.657470703125, Entropy -210.24749755859375, Learning Rate: 1.953125e-05\n",
      "Epoch [5150/20000], Loss: 173.87420654296875, Entropy -209.797607421875, Learning Rate: 1.953125e-05\n",
      "Epoch [5151/20000], Loss: 167.91477966308594, Entropy -206.64456176757812, Learning Rate: 1.953125e-05\n",
      "Epoch [5152/20000], Loss: 194.20489501953125, Entropy -235.6497802734375, Learning Rate: 1.953125e-05\n",
      "Epoch [5153/20000], Loss: 173.8074951171875, Entropy -204.68679809570312, Learning Rate: 1.953125e-05\n",
      "Epoch [5154/20000], Loss: 173.79859924316406, Entropy -210.615234375, Learning Rate: 1.953125e-05\n",
      "Epoch [5155/20000], Loss: 175.24923706054688, Entropy -207.8895263671875, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5156/20000], Loss: 182.20469665527344, Entropy -229.25201416015625, Learning Rate: 1.953125e-05\n",
      "Epoch [5157/20000], Loss: 178.3621063232422, Entropy -216.69798278808594, Learning Rate: 1.953125e-05\n",
      "Epoch [5158/20000], Loss: 167.93272399902344, Entropy -202.82196044921875, Learning Rate: 1.953125e-05\n",
      "Epoch [5159/20000], Loss: 170.86480712890625, Entropy -210.2996063232422, Learning Rate: 1.953125e-05\n",
      "Epoch [5160/20000], Loss: 178.41842651367188, Entropy -214.66311645507812, Learning Rate: 1.953125e-05\n",
      "Epoch [5161/20000], Loss: 174.66529846191406, Entropy -212.05313110351562, Learning Rate: 1.953125e-05\n",
      "Epoch [5162/20000], Loss: 172.92633056640625, Entropy -205.97454833984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5163/20000], Loss: 176.78994750976562, Entropy -211.25503540039062, Learning Rate: 1.953125e-05\n",
      "Epoch [5164/20000], Loss: 174.5809783935547, Entropy -212.989013671875, Learning Rate: 1.953125e-05\n",
      "Epoch [5165/20000], Loss: 173.1356964111328, Entropy -211.202880859375, Learning Rate: 1.953125e-05\n",
      "Epoch [5166/20000], Loss: 185.46119689941406, Entropy -227.79896545410156, Learning Rate: 1.953125e-05\n",
      "Epoch [5167/20000], Loss: 191.7845916748047, Entropy -221.4916534423828, Learning Rate: 1.953125e-05\n",
      "Epoch [5168/20000], Loss: 173.78106689453125, Entropy -208.06854248046875, Learning Rate: 1.953125e-05\n",
      "Epoch [5169/20000], Loss: 174.70042419433594, Entropy -209.6804962158203, Learning Rate: 1.953125e-05\n",
      "Epoch [5170/20000], Loss: 181.64230346679688, Entropy -219.1358184814453, Learning Rate: 1.953125e-05\n",
      "Epoch [5171/20000], Loss: 190.58152770996094, Entropy -222.01058959960938, Learning Rate: 1.953125e-05\n",
      "Epoch [5172/20000], Loss: 172.61111450195312, Entropy -212.47518920898438, Learning Rate: 1.953125e-05\n",
      "Epoch [5173/20000], Loss: 170.85194396972656, Entropy -207.27548217773438, Learning Rate: 1.953125e-05\n",
      "Epoch [5174/20000], Loss: 172.25344848632812, Entropy -211.99212646484375, Learning Rate: 1.953125e-05\n",
      "Epoch [5175/20000], Loss: 171.72494506835938, Entropy -207.77325439453125, Learning Rate: 1.953125e-05\n",
      "Epoch [5176/20000], Loss: 177.39193725585938, Entropy -217.35198974609375, Learning Rate: 1.953125e-05\n",
      "Epoch [5177/20000], Loss: 170.83743286132812, Entropy -212.57986450195312, Learning Rate: 1.953125e-05\n",
      "Epoch [5178/20000], Loss: 191.3487548828125, Entropy -236.8604736328125, Learning Rate: 1.953125e-05\n",
      "Epoch [5179/20000], Loss: 171.22451782226562, Entropy -207.8268280029297, Learning Rate: 1.953125e-05\n",
      "Epoch [5180/20000], Loss: 166.75779724121094, Entropy -201.73321533203125, Learning Rate: 1.953125e-05\n",
      "Epoch [5181/20000], Loss: 169.6266326904297, Entropy -210.10687255859375, Learning Rate: 1.953125e-05\n",
      "Epoch [5182/20000], Loss: 174.00119018554688, Entropy -219.45188903808594, Learning Rate: 1.953125e-05\n",
      "Epoch [5183/20000], Loss: 181.50949096679688, Entropy -221.0031280517578, Learning Rate: 1.953125e-05\n",
      "Epoch [5184/20000], Loss: 172.92210388183594, Entropy -215.8097686767578, Learning Rate: 1.953125e-05\n",
      "Epoch [5185/20000], Loss: 174.1334228515625, Entropy -209.6737518310547, Learning Rate: 1.953125e-05\n",
      "Epoch [5186/20000], Loss: 178.1553497314453, Entropy -214.5765838623047, Learning Rate: 1.953125e-05\n",
      "Epoch [5187/20000], Loss: 179.70794677734375, Entropy -208.9097900390625, Learning Rate: 1.953125e-05\n",
      "Epoch [5188/20000], Loss: 172.58529663085938, Entropy -213.65875244140625, Learning Rate: 1.953125e-05\n",
      "Epoch [5189/20000], Loss: 170.11688232421875, Entropy -208.4917449951172, Learning Rate: 1.953125e-05\n",
      "Epoch [5190/20000], Loss: 168.97238159179688, Entropy -200.75604248046875, Learning Rate: 1.953125e-05\n",
      "Epoch [5191/20000], Loss: 180.86720275878906, Entropy -216.1571807861328, Learning Rate: 1.953125e-05\n",
      "Epoch [5192/20000], Loss: 168.80215454101562, Entropy -203.00132751464844, Learning Rate: 1.953125e-05\n",
      "Epoch [5193/20000], Loss: 176.79861450195312, Entropy -214.2993621826172, Learning Rate: 1.953125e-05\n",
      "Epoch [5194/20000], Loss: 172.59405517578125, Entropy -213.42333984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5195/20000], Loss: 173.6759490966797, Entropy -210.83908081054688, Learning Rate: 1.953125e-05\n",
      "Epoch [5196/20000], Loss: 184.7965087890625, Entropy -228.8653106689453, Learning Rate: 1.953125e-05\n",
      "Epoch [5197/20000], Loss: 177.89443969726562, Entropy -215.59962463378906, Learning Rate: 1.953125e-05\n",
      "Epoch [5198/20000], Loss: 165.92015075683594, Entropy -200.21142578125, Learning Rate: 1.953125e-05\n",
      "Epoch [5199/20000], Loss: 176.669189453125, Entropy -212.538330078125, Learning Rate: 1.953125e-05\n",
      "Epoch [5200/20000], Loss: 183.7823028564453, Entropy -222.8145751953125, Learning Rate: 1.953125e-05\n",
      "Epoch [5201/20000], Loss: 171.3212432861328, Entropy -218.89451599121094, Learning Rate: 1.953125e-05\n",
      "Epoch [5202/20000], Loss: 175.30563354492188, Entropy -215.05345153808594, Learning Rate: 1.953125e-05\n",
      "Epoch [5203/20000], Loss: 169.7043914794922, Entropy -205.59329223632812, Learning Rate: 1.953125e-05\n",
      "Epoch [5204/20000], Loss: 173.6450653076172, Entropy -211.57379150390625, Learning Rate: 1.953125e-05\n",
      "Epoch [5205/20000], Loss: 171.4666748046875, Entropy -204.61956787109375, Learning Rate: 1.953125e-05\n",
      "Epoch [5206/20000], Loss: 175.1875, Entropy -206.68544006347656, Learning Rate: 1.953125e-05\n",
      "Epoch [5207/20000], Loss: 175.78099060058594, Entropy -206.66749572753906, Learning Rate: 1.953125e-05\n",
      "Epoch [5208/20000], Loss: 172.8400115966797, Entropy -211.19924926757812, Learning Rate: 1.953125e-05\n",
      "Epoch [5209/20000], Loss: 170.57528686523438, Entropy -211.17518615722656, Learning Rate: 1.953125e-05\n",
      "Epoch [5210/20000], Loss: 176.67181396484375, Entropy -219.71896362304688, Learning Rate: 1.953125e-05\n",
      "Epoch [5211/20000], Loss: 178.8880157470703, Entropy -212.7161407470703, Learning Rate: 1.953125e-05\n",
      "Epoch [5212/20000], Loss: 183.31866455078125, Entropy -219.4781036376953, Learning Rate: 1.953125e-05\n",
      "Epoch [5213/20000], Loss: 168.3481903076172, Entropy -203.68727111816406, Learning Rate: 1.953125e-05\n",
      "Epoch [5214/20000], Loss: 181.38107299804688, Entropy -216.24301147460938, Learning Rate: 1.953125e-05\n",
      "Epoch [5215/20000], Loss: 170.64854431152344, Entropy -208.80934143066406, Learning Rate: 1.953125e-05\n",
      "Epoch [5216/20000], Loss: 166.93482971191406, Entropy -210.7454833984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5217/20000], Loss: 171.07810974121094, Entropy -212.82174682617188, Learning Rate: 1.953125e-05\n",
      "Epoch [5218/20000], Loss: 172.87721252441406, Entropy -214.17288208007812, Learning Rate: 1.953125e-05\n",
      "Epoch [5219/20000], Loss: 180.543212890625, Entropy -215.0942840576172, Learning Rate: 1.953125e-05\n",
      "Epoch [5220/20000], Loss: 166.70877075195312, Entropy -202.93527221679688, Learning Rate: 1.953125e-05\n",
      "Epoch [5221/20000], Loss: 179.08517456054688, Entropy -215.9285125732422, Learning Rate: 1.953125e-05\n",
      "Epoch [5222/20000], Loss: 182.76678466796875, Entropy -224.86419677734375, Learning Rate: 1.953125e-05\n",
      "Epoch [5223/20000], Loss: 173.9104461669922, Entropy -215.58181762695312, Learning Rate: 1.953125e-05\n",
      "Epoch [5224/20000], Loss: 166.3140106201172, Entropy -204.70346069335938, Learning Rate: 1.953125e-05\n",
      "Epoch [5225/20000], Loss: 170.7290496826172, Entropy -208.34121704101562, Learning Rate: 1.953125e-05\n",
      "Epoch [5226/20000], Loss: 177.85089111328125, Entropy -218.84732055664062, Learning Rate: 1.953125e-05\n",
      "Epoch [5227/20000], Loss: 168.9606475830078, Entropy -205.9852294921875, Learning Rate: 1.953125e-05\n",
      "Epoch [5228/20000], Loss: 172.624755859375, Entropy -210.367919921875, Learning Rate: 1.953125e-05\n",
      "Epoch [5229/20000], Loss: 182.4435577392578, Entropy -208.6775360107422, Learning Rate: 1.953125e-05\n",
      "Epoch [5230/20000], Loss: 173.33102416992188, Entropy -205.53936767578125, Learning Rate: 1.953125e-05\n",
      "Epoch [5231/20000], Loss: 175.11219787597656, Entropy -214.00791931152344, Learning Rate: 1.953125e-05\n",
      "Epoch [5232/20000], Loss: 166.5465850830078, Entropy -206.080322265625, Learning Rate: 1.953125e-05\n",
      "Epoch [5233/20000], Loss: 178.0073699951172, Entropy -215.27584838867188, Learning Rate: 1.953125e-05\n",
      "Epoch [5234/20000], Loss: 171.94969177246094, Entropy -212.20181274414062, Learning Rate: 1.953125e-05\n",
      "Epoch [5235/20000], Loss: 177.01641845703125, Entropy -215.72470092773438, Learning Rate: 1.953125e-05\n",
      "Epoch [5236/20000], Loss: 175.5403289794922, Entropy -216.27914428710938, Learning Rate: 1.953125e-05\n",
      "Epoch [5237/20000], Loss: 171.9516143798828, Entropy -208.95297241210938, Learning Rate: 1.953125e-05\n",
      "Epoch [5238/20000], Loss: 180.61904907226562, Entropy -217.34014892578125, Learning Rate: 1.953125e-05\n",
      "Epoch [5239/20000], Loss: 170.8287353515625, Entropy -205.44349670410156, Learning Rate: 1.953125e-05\n",
      "Epoch [5240/20000], Loss: 178.57302856445312, Entropy -221.18228149414062, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5241/20000], Loss: 174.33985900878906, Entropy -214.5469970703125, Learning Rate: 1.953125e-05\n",
      "Epoch [5242/20000], Loss: 167.8283233642578, Entropy -206.00283813476562, Learning Rate: 1.953125e-05\n",
      "Epoch [5243/20000], Loss: 167.6239013671875, Entropy -207.4329376220703, Learning Rate: 1.953125e-05\n",
      "Epoch [5244/20000], Loss: 168.20712280273438, Entropy -208.36795043945312, Learning Rate: 1.953125e-05\n",
      "Epoch [5245/20000], Loss: 186.90646362304688, Entropy -221.940673828125, Learning Rate: 1.953125e-05\n",
      "Epoch [5246/20000], Loss: 174.6110382080078, Entropy -206.06471252441406, Learning Rate: 1.953125e-05\n",
      "Epoch [5247/20000], Loss: 175.50338745117188, Entropy -209.59413146972656, Learning Rate: 1.953125e-05\n",
      "Epoch [5248/20000], Loss: 180.84178161621094, Entropy -221.12013244628906, Learning Rate: 1.953125e-05\n",
      "Epoch [5249/20000], Loss: 174.74095153808594, Entropy -217.22120666503906, Learning Rate: 1.953125e-05\n",
      "Epoch [5250/20000], Loss: 166.6112060546875, Entropy -203.20339965820312, Learning Rate: 1.953125e-05\n",
      "Epoch [5251/20000], Loss: 170.8848114013672, Entropy -213.1071014404297, Learning Rate: 1.953125e-05\n",
      "Epoch [5252/20000], Loss: 176.52406311035156, Entropy -215.53436279296875, Learning Rate: 1.953125e-05\n",
      "Epoch [5253/20000], Loss: 177.90138244628906, Entropy -210.0684814453125, Learning Rate: 1.953125e-05\n",
      "Epoch [5254/20000], Loss: 175.40721130371094, Entropy -216.12594604492188, Learning Rate: 1.953125e-05\n",
      "Epoch [5255/20000], Loss: 164.35206604003906, Entropy -196.92388916015625, Learning Rate: 1.953125e-05\n",
      "Epoch [5256/20000], Loss: 177.48434448242188, Entropy -219.08908081054688, Learning Rate: 1.953125e-05\n",
      "Epoch [5257/20000], Loss: 174.1948699951172, Entropy -212.36788940429688, Learning Rate: 1.953125e-05\n",
      "Epoch [5258/20000], Loss: 170.3490447998047, Entropy -204.28248596191406, Learning Rate: 1.953125e-05\n",
      "Epoch [5259/20000], Loss: 172.76625061035156, Entropy -205.81455993652344, Learning Rate: 1.953125e-05\n",
      "Epoch [5260/20000], Loss: 180.24412536621094, Entropy -220.4955291748047, Learning Rate: 1.953125e-05\n",
      "Epoch [5261/20000], Loss: 164.5189208984375, Entropy -207.65818786621094, Learning Rate: 1.953125e-05\n",
      "Epoch [5262/20000], Loss: 174.18772888183594, Entropy -207.84912109375, Learning Rate: 1.953125e-05\n",
      "Epoch [5263/20000], Loss: 163.82899475097656, Entropy -205.15501403808594, Learning Rate: 1.953125e-05\n",
      "Epoch [5264/20000], Loss: 173.31947326660156, Entropy -200.76153564453125, Learning Rate: 1.953125e-05\n",
      "Epoch [5265/20000], Loss: 173.60614013671875, Entropy -211.4542999267578, Learning Rate: 1.953125e-05\n",
      "Epoch [5266/20000], Loss: 173.31654357910156, Entropy -217.07481384277344, Learning Rate: 1.953125e-05\n",
      "Epoch [5267/20000], Loss: 173.97256469726562, Entropy -213.93283081054688, Learning Rate: 1.953125e-05\n",
      "Epoch [5268/20000], Loss: 174.23178100585938, Entropy -216.77853393554688, Learning Rate: 1.953125e-05\n",
      "Epoch [5269/20000], Loss: 165.12045288085938, Entropy -202.38238525390625, Learning Rate: 1.953125e-05\n",
      "Epoch [5270/20000], Loss: 172.53717041015625, Entropy -207.11114501953125, Learning Rate: 1.953125e-05\n",
      "Epoch [5271/20000], Loss: 174.63156127929688, Entropy -215.80064392089844, Learning Rate: 1.953125e-05\n",
      "Epoch [5272/20000], Loss: 173.3563995361328, Entropy -209.07968139648438, Learning Rate: 1.953125e-05\n",
      "Epoch [5273/20000], Loss: 172.5377655029297, Entropy -216.2113037109375, Learning Rate: 1.953125e-05\n",
      "Epoch [5274/20000], Loss: 187.89564514160156, Entropy -221.98214721679688, Learning Rate: 1.953125e-05\n",
      "Epoch [5275/20000], Loss: 165.80264282226562, Entropy -204.85438537597656, Learning Rate: 1.953125e-05\n",
      "Epoch [5276/20000], Loss: 178.11212158203125, Entropy -223.752197265625, Learning Rate: 1.953125e-05\n",
      "Epoch [5277/20000], Loss: 171.0394287109375, Entropy -208.96713256835938, Learning Rate: 1.953125e-05\n",
      "Epoch [5278/20000], Loss: 174.18649291992188, Entropy -208.94876098632812, Learning Rate: 1.953125e-05\n",
      "Epoch [5279/20000], Loss: 178.02911376953125, Entropy -211.04058837890625, Learning Rate: 1.953125e-05\n",
      "Epoch [5280/20000], Loss: 174.90550231933594, Entropy -221.48614501953125, Learning Rate: 1.953125e-05\n",
      "Epoch [5281/20000], Loss: 178.15309143066406, Entropy -211.28672790527344, Learning Rate: 1.953125e-05\n",
      "Epoch [5282/20000], Loss: 168.36251831054688, Entropy -208.35610961914062, Learning Rate: 1.953125e-05\n",
      "Epoch [5283/20000], Loss: 179.71774291992188, Entropy -215.51019287109375, Learning Rate: 1.953125e-05\n",
      "Epoch [5284/20000], Loss: 171.01828002929688, Entropy -201.53277587890625, Learning Rate: 1.953125e-05\n",
      "Epoch [5285/20000], Loss: 179.16958618164062, Entropy -211.09092712402344, Learning Rate: 1.953125e-05\n",
      "Epoch [5286/20000], Loss: 178.94354248046875, Entropy -219.08193969726562, Learning Rate: 1.953125e-05\n",
      "Epoch [5287/20000], Loss: 174.7772979736328, Entropy -215.43417358398438, Learning Rate: 1.953125e-05\n",
      "Epoch [5288/20000], Loss: 175.50949096679688, Entropy -224.75587463378906, Learning Rate: 1.953125e-05\n",
      "Epoch [5289/20000], Loss: 173.03262329101562, Entropy -214.71078491210938, Learning Rate: 1.953125e-05\n",
      "Epoch [5290/20000], Loss: 169.78457641601562, Entropy -210.72213745117188, Learning Rate: 1.953125e-05\n",
      "Epoch [5291/20000], Loss: 172.08436584472656, Entropy -209.23391723632812, Learning Rate: 1.953125e-05\n",
      "Epoch [5292/20000], Loss: 174.41217041015625, Entropy -208.75003051757812, Learning Rate: 1.953125e-05\n",
      "Epoch [5293/20000], Loss: 165.20555114746094, Entropy -208.79110717773438, Learning Rate: 1.953125e-05\n",
      "Epoch [5294/20000], Loss: 169.59934997558594, Entropy -203.77926635742188, Learning Rate: 1.953125e-05\n",
      "Epoch [5295/20000], Loss: 177.82861328125, Entropy -212.650146484375, Learning Rate: 1.953125e-05\n",
      "Epoch [5296/20000], Loss: 173.5062713623047, Entropy -216.89695739746094, Learning Rate: 1.953125e-05\n",
      "Epoch [5297/20000], Loss: 173.22906494140625, Entropy -213.25323486328125, Learning Rate: 1.953125e-05\n",
      "Epoch [5298/20000], Loss: 185.7774658203125, Entropy -223.13442993164062, Learning Rate: 1.953125e-05\n",
      "Epoch [5299/20000], Loss: 169.06878662109375, Entropy -205.8768768310547, Learning Rate: 1.953125e-05\n",
      "Epoch [5300/20000], Loss: 183.36102294921875, Entropy -218.30535888671875, Learning Rate: 1.953125e-05\n",
      "Epoch [5301/20000], Loss: 172.6239776611328, Entropy -212.3184051513672, Learning Rate: 1.953125e-05\n",
      "Epoch [5302/20000], Loss: 178.74847412109375, Entropy -216.31964111328125, Learning Rate: 1.953125e-05\n",
      "Epoch [5303/20000], Loss: 175.14222717285156, Entropy -208.14950561523438, Learning Rate: 1.953125e-05\n",
      "Epoch [5304/20000], Loss: 180.28952026367188, Entropy -213.32904052734375, Learning Rate: 9.765625e-06\n",
      "4298 [tensor(160.3944, device='cuda:0'), tensor(-205.4613, device='cuda:0'), tensor(-129.8078, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "k_MC=100#size_sample\n",
    "\n",
    "#sample, = ax.scatter([],[],color='red',alpha=0.07)\n",
    "#fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "'''\n",
    "def show(GeN,n,alpha=0.07):\n",
    "    Z=GeN(n).detach().clone().cpu()\n",
    "    plt.pcolormesh(grid_x.numpy(),grid_y.numpy(),p.exp().numpy())\n",
    "    plt.scatter(Z[:,0],Z[:,1],color='red',alpha=alpha) \n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "''' \n",
    "\n",
    "def show(GeN,n):\n",
    "    #Z=GeN(200).detach()\n",
    "    #fig=setup.makePlot(Z,device)\n",
    "    #plt.show()\n",
    "    return\n",
    "    \n",
    "#lr =.03 for lat_dim 5\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    optimizer = GeNPredVI(loglikelihood, logprior, projection, k_MC,\n",
    "\t\t                                    0, 100, 1000, 50, 50,\n",
    "\t\t                                    20000, .01, .00001, 200, .5,\n",
    "\t\t                                    device, True, temp_dir, save_best=True)\n",
    "    best_epoch, scores=optimizer.run(GeN,show)\n",
    "print(best_epoch,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1632bf6e10>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_entropy\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('KL divergence')\n",
    "plt.plot(time, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1632bda950>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=torch.as_tensor(optimizer.score_elbo)\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('ELBO')\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f161c6a0490>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_lr\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(160.3944, device='cuda:0'),\n",
       " tensor(-205.4613, device='cuda:0'),\n",
       " tensor(-129.8078, device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show(GeN,n):\n",
    "    Z=GeN(n).detach()\n",
    "    fig=setup.makePlot(Z,device)\n",
    "    plt.title('('+str(nblayers)+' with '+str(layerwidth)+' units) Predictive VI: GeNVI lat_dim='+str(lat_dim))\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "\n",
    "    \n",
    "show(GeN,1000)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f15cc520810>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "X=torch.Tensor([[-.7]]).to(device)#torch.arange(-2.,2.,0.1)\n",
    "Y=model(X,GeN(500).detach()).squeeze().cpu()\n",
    "\n",
    "sns.distplot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLPP_train, nLPP_validation, nLPP_test, RSE_train, RSE_validation, RSE_test=setup.evaluate_metrics(GeN(1000).detach(),'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nLPP_valid: (tensor(-0.8674), tensor(0.6742))\n",
      "SE_valid: (tensor(0.0102), tensor(0.0145))\n",
      "nLPP_test: (tensor(0.2972), tensor(0.9900))\n",
      "SE_test: (tensor(0.1923), tensor(0.2653))\n"
     ]
    }
   ],
   "source": [
    "print('nLPP_valid: '+str(nLPP_validation))\n",
    "print('SE_valid: '+str(RSE_validation))\n",
    "print('nLPP_test: '+str(nLPP_test))\n",
    "print('SE_test: '+str(RSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un choix de points $x_0,...,x_{n-1}$, on dfinit:\n",
    "$$\n",
    "d(\\theta,\\theta')=\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert\n",
    "$$\n",
    "ou\n",
    "$$\n",
    "d_2(\\theta,\\theta')=\\biggl(\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert^2\\biggr)^{\\frac{1}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(f\\in A)=P(\\{\\theta \\mid f_\\theta\\in A\\})$\n",
    "\n",
    "$\\theta \\mapsto f_\\theta$ (is it continuous?)\n",
    "\n",
    "relation entre $d(\\theta,\\theta')$ et $d(f_\\theta,f_\\theta')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
