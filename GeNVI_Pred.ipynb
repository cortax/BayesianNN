{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Inference.GeNVI_predictive import GeNPredVI, GeNetEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Experiments.foong import Setup\n",
    "layerwidth=50\n",
    "nblayers=1\n",
    "#setup=Setup(device,layerwidth=layerwidth,nblayers=nblayers)\n",
    "setup=Setup(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target density #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 151)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprior=setup.logPredPrior\n",
    "loglikelihood=setup.loglikelihood\n",
    "projection=setup.projection\n",
    "size_sample=setup.n_train_samples\n",
    "param_count=setup.param_count\n",
    "model=setup._model\n",
    "\n",
    "size_sample,param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Network #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation = nn.Tanh()#nn.ReLU()\n",
    "init_b = .001\n",
    "lat_dim=2\n",
    "\n",
    "\n",
    "GeN = GeNetEns(1, lat_dim, 50, param_count, activation, 0.2, init_b, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20000], Loss: 114064.65625, Entropy -223.99819946289062, Learning Rate: 0.01\n",
      "Epoch [1/20000], Loss: 101109.7890625, Entropy -245.84234619140625, Learning Rate: 0.01\n",
      "Epoch [2/20000], Loss: 90652.859375, Entropy -243.38302612304688, Learning Rate: 0.01\n",
      "Epoch [3/20000], Loss: 42142.92578125, Entropy -251.78564453125, Learning Rate: 0.01\n",
      "Epoch [4/20000], Loss: 31277.61328125, Entropy -242.8852081298828, Learning Rate: 0.01\n",
      "Epoch [5/20000], Loss: 42497.44921875, Entropy -264.3345031738281, Learning Rate: 0.01\n",
      "Epoch [6/20000], Loss: 32202.890625, Entropy -278.2082824707031, Learning Rate: 0.01\n",
      "Epoch [7/20000], Loss: 13635.5263671875, Entropy -272.9484558105469, Learning Rate: 0.01\n",
      "Epoch [8/20000], Loss: 17278.41015625, Entropy -288.6051940917969, Learning Rate: 0.01\n",
      "Epoch [9/20000], Loss: 28200.935546875, Entropy -271.3655700683594, Learning Rate: 0.01\n",
      "Epoch [10/20000], Loss: 22850.541015625, Entropy -264.9554443359375, Learning Rate: 0.01\n",
      "Epoch [11/20000], Loss: 21288.98828125, Entropy -292.62359619140625, Learning Rate: 0.01\n",
      "Epoch [12/20000], Loss: 8588.833984375, Entropy -318.7648010253906, Learning Rate: 0.01\n",
      "Epoch [13/20000], Loss: 7435.56640625, Entropy -303.6900634765625, Learning Rate: 0.01\n",
      "Epoch [14/20000], Loss: 10902.8818359375, Entropy -295.2523498535156, Learning Rate: 0.01\n",
      "Epoch [15/20000], Loss: 13372.220703125, Entropy -296.8896789550781, Learning Rate: 0.01\n",
      "Epoch [16/20000], Loss: 10988.0458984375, Entropy -307.9447326660156, Learning Rate: 0.01\n",
      "Epoch [17/20000], Loss: 10965.208984375, Entropy -302.5520935058594, Learning Rate: 0.01\n",
      "Epoch [18/20000], Loss: 11447.185546875, Entropy -285.1961364746094, Learning Rate: 0.01\n",
      "Epoch [19/20000], Loss: 6799.34619140625, Entropy -312.20037841796875, Learning Rate: 0.01\n",
      "Epoch [20/20000], Loss: 6900.91162109375, Entropy -315.3816223144531, Learning Rate: 0.01\n",
      "Epoch [21/20000], Loss: 6183.66748046875, Entropy -322.28466796875, Learning Rate: 0.01\n",
      "Epoch [22/20000], Loss: 6156.59521484375, Entropy -305.2986755371094, Learning Rate: 0.01\n",
      "Epoch [23/20000], Loss: 3756.704833984375, Entropy -328.17059326171875, Learning Rate: 0.01\n",
      "Epoch [24/20000], Loss: 5034.46484375, Entropy -326.43182373046875, Learning Rate: 0.01\n",
      "Epoch [25/20000], Loss: 5006.34423828125, Entropy -321.9814453125, Learning Rate: 0.01\n",
      "Epoch [26/20000], Loss: 4650.1669921875, Entropy -310.3183898925781, Learning Rate: 0.01\n",
      "Epoch [27/20000], Loss: 6119.74169921875, Entropy -328.2143859863281, Learning Rate: 0.01\n",
      "Epoch [28/20000], Loss: 5205.80078125, Entropy -330.04248046875, Learning Rate: 0.01\n",
      "Epoch [29/20000], Loss: 4294.8466796875, Entropy -306.8733215332031, Learning Rate: 0.01\n",
      "Epoch [30/20000], Loss: 4338.6123046875, Entropy -333.1676940917969, Learning Rate: 0.01\n",
      "Epoch [31/20000], Loss: 3713.26220703125, Entropy -344.97711181640625, Learning Rate: 0.01\n",
      "Epoch [32/20000], Loss: 2300.090087890625, Entropy -361.0633544921875, Learning Rate: 0.01\n",
      "Epoch [33/20000], Loss: 2553.806396484375, Entropy -353.18359375, Learning Rate: 0.01\n",
      "Epoch [34/20000], Loss: 3835.180419921875, Entropy -326.88104248046875, Learning Rate: 0.01\n",
      "Epoch [35/20000], Loss: 3662.546142578125, Entropy -350.0989990234375, Learning Rate: 0.01\n",
      "Epoch [36/20000], Loss: 2482.565673828125, Entropy -374.13934326171875, Learning Rate: 0.01\n",
      "Epoch [37/20000], Loss: 1802.611572265625, Entropy -338.3620910644531, Learning Rate: 0.01\n",
      "Epoch [38/20000], Loss: 2331.040771484375, Entropy -368.34613037109375, Learning Rate: 0.01\n",
      "Epoch [39/20000], Loss: 2138.958251953125, Entropy -345.12237548828125, Learning Rate: 0.01\n",
      "Epoch [40/20000], Loss: 2277.468017578125, Entropy -348.55279541015625, Learning Rate: 0.01\n",
      "Epoch [41/20000], Loss: 2103.18798828125, Entropy -358.0479431152344, Learning Rate: 0.01\n",
      "Epoch [42/20000], Loss: 1927.3505859375, Entropy -353.6663513183594, Learning Rate: 0.01\n",
      "Epoch [43/20000], Loss: 1715.1201171875, Entropy -375.432373046875, Learning Rate: 0.01\n",
      "Epoch [44/20000], Loss: 1496.2099609375, Entropy -373.10565185546875, Learning Rate: 0.01\n",
      "Epoch [45/20000], Loss: 2012.6336669921875, Entropy -373.6097106933594, Learning Rate: 0.01\n",
      "Epoch [46/20000], Loss: 1994.900146484375, Entropy -380.65545654296875, Learning Rate: 0.01\n",
      "Epoch [47/20000], Loss: 1725.500732421875, Entropy -375.57843017578125, Learning Rate: 0.01\n",
      "Epoch [48/20000], Loss: 1590.347412109375, Entropy -376.59222412109375, Learning Rate: 0.01\n",
      "Epoch [49/20000], Loss: 1434.9171142578125, Entropy -369.5304870605469, Learning Rate: 0.01\n",
      "Epoch [50/20000], Loss: 1990.5079345703125, Entropy -379.4508361816406, Learning Rate: 0.01\n",
      "Epoch [51/20000], Loss: 1709.4197998046875, Entropy -368.0425109863281, Learning Rate: 0.01\n",
      "Epoch [52/20000], Loss: 1505.854248046875, Entropy -381.78765869140625, Learning Rate: 0.01\n",
      "Epoch [53/20000], Loss: 1421.175048828125, Entropy -392.7999267578125, Learning Rate: 0.01\n",
      "Epoch [54/20000], Loss: 1260.0421142578125, Entropy -385.3409423828125, Learning Rate: 0.01\n",
      "Epoch [55/20000], Loss: 1539.4990234375, Entropy -376.4876708984375, Learning Rate: 0.01\n",
      "Epoch [56/20000], Loss: 1321.8251953125, Entropy -381.77178955078125, Learning Rate: 0.01\n",
      "Epoch [57/20000], Loss: 1327.5091552734375, Entropy -369.301025390625, Learning Rate: 0.01\n",
      "Epoch [58/20000], Loss: 1330.179931640625, Entropy -370.0411376953125, Learning Rate: 0.01\n",
      "Epoch [59/20000], Loss: 1374.0826416015625, Entropy -395.12432861328125, Learning Rate: 0.01\n",
      "Epoch [60/20000], Loss: 1315.7578125, Entropy -388.29034423828125, Learning Rate: 0.01\n",
      "Epoch [61/20000], Loss: 1128.002197265625, Entropy -388.2400817871094, Learning Rate: 0.01\n",
      "Epoch [62/20000], Loss: 1219.523193359375, Entropy -386.61676025390625, Learning Rate: 0.01\n",
      "Epoch [63/20000], Loss: 1243.966796875, Entropy -365.3887634277344, Learning Rate: 0.01\n",
      "Epoch [64/20000], Loss: 1071.418212890625, Entropy -375.6556396484375, Learning Rate: 0.01\n",
      "Epoch [65/20000], Loss: 985.0335693359375, Entropy -386.35137939453125, Learning Rate: 0.01\n",
      "Epoch [66/20000], Loss: 1149.6849365234375, Entropy -375.07733154296875, Learning Rate: 0.01\n",
      "Epoch [67/20000], Loss: 1153.858154296875, Entropy -378.9619445800781, Learning Rate: 0.01\n",
      "Epoch [68/20000], Loss: 1020.0030517578125, Entropy -383.6292724609375, Learning Rate: 0.01\n",
      "Epoch [69/20000], Loss: 1023.875, Entropy -408.45556640625, Learning Rate: 0.01\n",
      "Epoch [70/20000], Loss: 1055.8463134765625, Entropy -374.0633850097656, Learning Rate: 0.01\n",
      "Epoch [71/20000], Loss: 1062.4844970703125, Entropy -380.86407470703125, Learning Rate: 0.01\n",
      "Epoch [72/20000], Loss: 1001.0082397460938, Entropy -380.0093688964844, Learning Rate: 0.01\n",
      "Epoch [73/20000], Loss: 944.7272338867188, Entropy -386.4845275878906, Learning Rate: 0.01\n",
      "Epoch [74/20000], Loss: 990.43310546875, Entropy -380.5997314453125, Learning Rate: 0.01\n",
      "Epoch [75/20000], Loss: 1055.55029296875, Entropy -396.74676513671875, Learning Rate: 0.01\n",
      "Epoch [76/20000], Loss: 1106.030517578125, Entropy -392.5927429199219, Learning Rate: 0.01\n",
      "Epoch [77/20000], Loss: 906.8223876953125, Entropy -382.4698181152344, Learning Rate: 0.01\n",
      "Epoch [78/20000], Loss: 1001.2554321289062, Entropy -381.78143310546875, Learning Rate: 0.01\n",
      "Epoch [79/20000], Loss: 927.248779296875, Entropy -385.1673889160156, Learning Rate: 0.01\n",
      "Epoch [80/20000], Loss: 930.8258666992188, Entropy -386.21832275390625, Learning Rate: 0.01\n",
      "Epoch [81/20000], Loss: 865.9725341796875, Entropy -384.47784423828125, Learning Rate: 0.01\n",
      "Epoch [82/20000], Loss: 877.209228515625, Entropy -389.64404296875, Learning Rate: 0.01\n",
      "Epoch [83/20000], Loss: 920.34814453125, Entropy -391.97283935546875, Learning Rate: 0.01\n",
      "Epoch [84/20000], Loss: 869.9642333984375, Entropy -375.5318908691406, Learning Rate: 0.01\n",
      "Epoch [85/20000], Loss: 900.2401733398438, Entropy -385.7626647949219, Learning Rate: 0.01\n",
      "Epoch [86/20000], Loss: 802.122314453125, Entropy -367.06317138671875, Learning Rate: 0.01\n",
      "Epoch [87/20000], Loss: 827.3866577148438, Entropy -375.0320129394531, Learning Rate: 0.01\n",
      "Epoch [88/20000], Loss: 861.600830078125, Entropy -391.7222900390625, Learning Rate: 0.01\n",
      "Epoch [89/20000], Loss: 833.4219970703125, Entropy -374.7691955566406, Learning Rate: 0.01\n",
      "Epoch [90/20000], Loss: 867.4325561523438, Entropy -392.1995849609375, Learning Rate: 0.01\n",
      "Epoch [91/20000], Loss: 890.2430419921875, Entropy -389.3446960449219, Learning Rate: 0.01\n",
      "Epoch [92/20000], Loss: 795.528564453125, Entropy -380.66357421875, Learning Rate: 0.01\n",
      "Epoch [93/20000], Loss: 785.463134765625, Entropy -388.75311279296875, Learning Rate: 0.01\n",
      "Epoch [94/20000], Loss: 754.7662963867188, Entropy -374.9551696777344, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/20000], Loss: 803.808349609375, Entropy -388.0908508300781, Learning Rate: 0.01\n",
      "Epoch [96/20000], Loss: 849.56201171875, Entropy -413.0462646484375, Learning Rate: 0.01\n",
      "Epoch [97/20000], Loss: 862.9053955078125, Entropy -401.08453369140625, Learning Rate: 0.01\n",
      "Epoch [98/20000], Loss: 789.2213134765625, Entropy -383.78778076171875, Learning Rate: 0.01\n",
      "Epoch [99/20000], Loss: 804.6533203125, Entropy -378.8913879394531, Learning Rate: 0.01\n",
      "Epoch [100/20000], Loss: 772.73291015625, Entropy -371.4435119628906, Learning Rate: 0.01\n",
      "Epoch [101/20000], Loss: 802.4400024414062, Entropy -387.85107421875, Learning Rate: 0.01\n",
      "Epoch [102/20000], Loss: 733.3218383789062, Entropy -370.7584533691406, Learning Rate: 0.01\n",
      "Epoch [103/20000], Loss: 750.5535278320312, Entropy -384.23876953125, Learning Rate: 0.01\n",
      "Epoch [104/20000], Loss: 727.3173828125, Entropy -388.91241455078125, Learning Rate: 0.01\n",
      "Epoch [105/20000], Loss: 776.6300048828125, Entropy -391.8217468261719, Learning Rate: 0.01\n",
      "Epoch [106/20000], Loss: 700.295166015625, Entropy -385.76593017578125, Learning Rate: 0.01\n",
      "Epoch [107/20000], Loss: 728.8568115234375, Entropy -389.5735778808594, Learning Rate: 0.01\n",
      "Epoch [108/20000], Loss: 730.1273193359375, Entropy -386.9421081542969, Learning Rate: 0.01\n",
      "Epoch [109/20000], Loss: 778.3782958984375, Entropy -379.2356262207031, Learning Rate: 0.01\n",
      "Epoch [110/20000], Loss: 719.9089965820312, Entropy -388.139404296875, Learning Rate: 0.01\n",
      "Epoch [111/20000], Loss: 759.132080078125, Entropy -392.1846008300781, Learning Rate: 0.01\n",
      "Epoch [112/20000], Loss: 724.559326171875, Entropy -388.2733154296875, Learning Rate: 0.01\n",
      "Epoch [113/20000], Loss: 764.0234375, Entropy -380.1291198730469, Learning Rate: 0.01\n",
      "Epoch [114/20000], Loss: 748.1847534179688, Entropy -366.5919494628906, Learning Rate: 0.01\n",
      "Epoch [115/20000], Loss: 678.6536865234375, Entropy -373.4320068359375, Learning Rate: 0.01\n",
      "Epoch [116/20000], Loss: 689.75, Entropy -380.71820068359375, Learning Rate: 0.01\n",
      "Epoch [117/20000], Loss: 766.9465942382812, Entropy -392.4678649902344, Learning Rate: 0.01\n",
      "Epoch [118/20000], Loss: 691.4598388671875, Entropy -374.8323974609375, Learning Rate: 0.01\n",
      "Epoch [119/20000], Loss: 682.5020751953125, Entropy -371.9173583984375, Learning Rate: 0.01\n",
      "Epoch [120/20000], Loss: 714.4645385742188, Entropy -364.9680480957031, Learning Rate: 0.01\n",
      "Epoch [121/20000], Loss: 721.7398071289062, Entropy -394.1309814453125, Learning Rate: 0.01\n",
      "Epoch [122/20000], Loss: 669.3187255859375, Entropy -364.6186828613281, Learning Rate: 0.01\n",
      "Epoch [123/20000], Loss: 704.6236572265625, Entropy -364.7532043457031, Learning Rate: 0.01\n",
      "Epoch [124/20000], Loss: 666.6485595703125, Entropy -384.1900939941406, Learning Rate: 0.01\n",
      "Epoch [125/20000], Loss: 673.3392944335938, Entropy -366.455322265625, Learning Rate: 0.01\n",
      "Epoch [126/20000], Loss: 698.4192504882812, Entropy -386.02166748046875, Learning Rate: 0.01\n",
      "Epoch [127/20000], Loss: 686.8164672851562, Entropy -376.1339111328125, Learning Rate: 0.01\n",
      "Epoch [128/20000], Loss: 699.0047607421875, Entropy -377.7846374511719, Learning Rate: 0.01\n",
      "Epoch [129/20000], Loss: 661.2523803710938, Entropy -378.009765625, Learning Rate: 0.01\n",
      "Epoch [130/20000], Loss: 655.643798828125, Entropy -392.2771301269531, Learning Rate: 0.01\n",
      "Epoch [131/20000], Loss: 626.1690063476562, Entropy -356.34600830078125, Learning Rate: 0.01\n",
      "Epoch [132/20000], Loss: 640.3894653320312, Entropy -370.4971618652344, Learning Rate: 0.01\n",
      "Epoch [133/20000], Loss: 636.7794189453125, Entropy -385.21893310546875, Learning Rate: 0.01\n",
      "Epoch [134/20000], Loss: 627.7666625976562, Entropy -360.9682922363281, Learning Rate: 0.01\n",
      "Epoch [135/20000], Loss: 655.6978759765625, Entropy -383.5596923828125, Learning Rate: 0.01\n",
      "Epoch [136/20000], Loss: 599.6807861328125, Entropy -368.58660888671875, Learning Rate: 0.01\n",
      "Epoch [137/20000], Loss: 690.57568359375, Entropy -369.5679626464844, Learning Rate: 0.01\n",
      "Epoch [138/20000], Loss: 644.8049926757812, Entropy -373.96661376953125, Learning Rate: 0.01\n",
      "Epoch [139/20000], Loss: 630.5697021484375, Entropy -365.9771423339844, Learning Rate: 0.01\n",
      "Epoch [140/20000], Loss: 646.1361083984375, Entropy -388.12249755859375, Learning Rate: 0.01\n",
      "Epoch [141/20000], Loss: 641.6087646484375, Entropy -378.8780517578125, Learning Rate: 0.01\n",
      "Epoch [142/20000], Loss: 624.7384033203125, Entropy -376.4580078125, Learning Rate: 0.01\n",
      "Epoch [143/20000], Loss: 607.3353881835938, Entropy -379.5390319824219, Learning Rate: 0.01\n",
      "Epoch [144/20000], Loss: 636.658203125, Entropy -393.35614013671875, Learning Rate: 0.01\n",
      "Epoch [145/20000], Loss: 613.911865234375, Entropy -379.4112548828125, Learning Rate: 0.01\n",
      "Epoch [146/20000], Loss: 636.4156494140625, Entropy -369.0868835449219, Learning Rate: 0.01\n",
      "Epoch [147/20000], Loss: 660.6121826171875, Entropy -383.8357238769531, Learning Rate: 0.01\n",
      "Epoch [148/20000], Loss: 624.7000122070312, Entropy -382.6434326171875, Learning Rate: 0.01\n",
      "Epoch [149/20000], Loss: 609.2930908203125, Entropy -393.0994873046875, Learning Rate: 0.01\n",
      "Epoch [150/20000], Loss: 608.673828125, Entropy -375.0440673828125, Learning Rate: 0.01\n",
      "Epoch [151/20000], Loss: 594.4649047851562, Entropy -379.0359191894531, Learning Rate: 0.01\n",
      "Epoch [152/20000], Loss: 587.5621948242188, Entropy -369.5240478515625, Learning Rate: 0.01\n",
      "Epoch [153/20000], Loss: 613.3306274414062, Entropy -374.011962890625, Learning Rate: 0.01\n",
      "Epoch [154/20000], Loss: 647.1123657226562, Entropy -364.193115234375, Learning Rate: 0.01\n",
      "Epoch [155/20000], Loss: 584.4205932617188, Entropy -368.9239807128906, Learning Rate: 0.01\n",
      "Epoch [156/20000], Loss: 597.3602294921875, Entropy -377.1741943359375, Learning Rate: 0.01\n",
      "Epoch [157/20000], Loss: 586.4943237304688, Entropy -364.1910705566406, Learning Rate: 0.01\n",
      "Epoch [158/20000], Loss: 596.8407592773438, Entropy -380.5973205566406, Learning Rate: 0.01\n",
      "Epoch [159/20000], Loss: 563.879150390625, Entropy -373.84625244140625, Learning Rate: 0.01\n",
      "Epoch [160/20000], Loss: 610.9710693359375, Entropy -400.6159362792969, Learning Rate: 0.01\n",
      "Epoch [161/20000], Loss: 579.3168334960938, Entropy -365.2265625, Learning Rate: 0.01\n",
      "Epoch [162/20000], Loss: 582.5171508789062, Entropy -375.3002014160156, Learning Rate: 0.01\n",
      "Epoch [163/20000], Loss: 554.8574829101562, Entropy -374.025390625, Learning Rate: 0.01\n",
      "Epoch [164/20000], Loss: 588.9788208007812, Entropy -376.5218505859375, Learning Rate: 0.01\n",
      "Epoch [165/20000], Loss: 570.0120849609375, Entropy -376.6343994140625, Learning Rate: 0.01\n",
      "Epoch [166/20000], Loss: 557.2969970703125, Entropy -380.8056945800781, Learning Rate: 0.01\n",
      "Epoch [167/20000], Loss: 582.9352416992188, Entropy -367.58087158203125, Learning Rate: 0.01\n",
      "Epoch [168/20000], Loss: 566.8489990234375, Entropy -355.6058654785156, Learning Rate: 0.01\n",
      "Epoch [169/20000], Loss: 559.321044921875, Entropy -372.85382080078125, Learning Rate: 0.01\n",
      "Epoch [170/20000], Loss: 558.1810302734375, Entropy -388.5896911621094, Learning Rate: 0.01\n",
      "Epoch [171/20000], Loss: 538.97705078125, Entropy -369.3304748535156, Learning Rate: 0.01\n",
      "Epoch [172/20000], Loss: 558.43212890625, Entropy -378.7369384765625, Learning Rate: 0.01\n",
      "Epoch [173/20000], Loss: 542.4713745117188, Entropy -362.5935974121094, Learning Rate: 0.01\n",
      "Epoch [174/20000], Loss: 593.4992065429688, Entropy -376.87225341796875, Learning Rate: 0.01\n",
      "Epoch [175/20000], Loss: 548.4566040039062, Entropy -376.759521484375, Learning Rate: 0.01\n",
      "Epoch [176/20000], Loss: 621.3900756835938, Entropy -374.7457275390625, Learning Rate: 0.01\n",
      "Epoch [177/20000], Loss: 560.8648071289062, Entropy -374.7154541015625, Learning Rate: 0.01\n",
      "Epoch [178/20000], Loss: 568.3115234375, Entropy -359.4237060546875, Learning Rate: 0.01\n",
      "Epoch [179/20000], Loss: 560.6060791015625, Entropy -371.938232421875, Learning Rate: 0.01\n",
      "Epoch [180/20000], Loss: 569.0982666015625, Entropy -379.5048522949219, Learning Rate: 0.01\n",
      "Epoch [181/20000], Loss: 644.29638671875, Entropy -386.7689514160156, Learning Rate: 0.01\n",
      "Epoch [182/20000], Loss: 563.19970703125, Entropy -362.3898620605469, Learning Rate: 0.01\n",
      "Epoch [183/20000], Loss: 553.7752075195312, Entropy -382.85955810546875, Learning Rate: 0.01\n",
      "Epoch [184/20000], Loss: 581.7987670898438, Entropy -373.4312438964844, Learning Rate: 0.01\n",
      "Epoch [185/20000], Loss: 543.9649658203125, Entropy -354.7676696777344, Learning Rate: 0.01\n",
      "Epoch [186/20000], Loss: 591.4991455078125, Entropy -375.6517639160156, Learning Rate: 0.01\n",
      "Epoch [187/20000], Loss: 599.0692749023438, Entropy -375.84930419921875, Learning Rate: 0.01\n",
      "Epoch [188/20000], Loss: 561.2138671875, Entropy -381.97064208984375, Learning Rate: 0.01\n",
      "Epoch [189/20000], Loss: 519.7400512695312, Entropy -355.76702880859375, Learning Rate: 0.01\n",
      "Epoch [190/20000], Loss: 532.1878051757812, Entropy -365.1528015136719, Learning Rate: 0.01\n",
      "Epoch [191/20000], Loss: 549.2286376953125, Entropy -366.8349914550781, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/20000], Loss: 540.3986206054688, Entropy -367.5853576660156, Learning Rate: 0.01\n",
      "Epoch [193/20000], Loss: 544.6293334960938, Entropy -383.26898193359375, Learning Rate: 0.01\n",
      "Epoch [194/20000], Loss: 536.4766845703125, Entropy -374.0699462890625, Learning Rate: 0.01\n",
      "Epoch [195/20000], Loss: 534.8342895507812, Entropy -379.7639465332031, Learning Rate: 0.01\n",
      "Epoch [196/20000], Loss: 563.4005126953125, Entropy -380.0486755371094, Learning Rate: 0.01\n",
      "Epoch [197/20000], Loss: 580.5282592773438, Entropy -378.20538330078125, Learning Rate: 0.01\n",
      "Epoch [198/20000], Loss: 582.7572021484375, Entropy -376.33233642578125, Learning Rate: 0.01\n",
      "Epoch [199/20000], Loss: 552.9940185546875, Entropy -383.818603515625, Learning Rate: 0.01\n",
      "Epoch [200/20000], Loss: 538.3097534179688, Entropy -357.41705322265625, Learning Rate: 0.01\n",
      "Epoch [201/20000], Loss: 548.0376586914062, Entropy -370.9162292480469, Learning Rate: 0.01\n",
      "Epoch [202/20000], Loss: 533.232421875, Entropy -367.51495361328125, Learning Rate: 0.01\n",
      "Epoch [203/20000], Loss: 542.5781860351562, Entropy -358.94879150390625, Learning Rate: 0.01\n",
      "Epoch [204/20000], Loss: 563.5907592773438, Entropy -370.90594482421875, Learning Rate: 0.01\n",
      "Epoch [205/20000], Loss: 606.2160034179688, Entropy -372.09112548828125, Learning Rate: 0.01\n",
      "Epoch [206/20000], Loss: 541.6589965820312, Entropy -378.61297607421875, Learning Rate: 0.01\n",
      "Epoch [207/20000], Loss: 532.0443725585938, Entropy -383.2291564941406, Learning Rate: 0.01\n",
      "Epoch [208/20000], Loss: 596.9304809570312, Entropy -363.4387512207031, Learning Rate: 0.01\n",
      "Epoch [209/20000], Loss: 521.072998046875, Entropy -363.21923828125, Learning Rate: 0.01\n",
      "Epoch [210/20000], Loss: 533.3670654296875, Entropy -375.956298828125, Learning Rate: 0.01\n",
      "Epoch [211/20000], Loss: 535.6487426757812, Entropy -374.6200866699219, Learning Rate: 0.01\n",
      "Epoch [212/20000], Loss: 552.2931518554688, Entropy -369.45068359375, Learning Rate: 0.01\n",
      "Epoch [213/20000], Loss: 542.355224609375, Entropy -366.8123474121094, Learning Rate: 0.01\n",
      "Epoch [214/20000], Loss: 543.2559814453125, Entropy -375.5915832519531, Learning Rate: 0.01\n",
      "Epoch [215/20000], Loss: 552.1201782226562, Entropy -382.4374694824219, Learning Rate: 0.01\n",
      "Epoch [216/20000], Loss: 529.8883056640625, Entropy -368.19512939453125, Learning Rate: 0.01\n",
      "Epoch [217/20000], Loss: 526.601318359375, Entropy -373.3267822265625, Learning Rate: 0.01\n",
      "Epoch [218/20000], Loss: 542.5904541015625, Entropy -371.752197265625, Learning Rate: 0.01\n",
      "Epoch [219/20000], Loss: 531.968505859375, Entropy -368.9138488769531, Learning Rate: 0.01\n",
      "Epoch [220/20000], Loss: 519.521240234375, Entropy -378.2594909667969, Learning Rate: 0.01\n",
      "Epoch [221/20000], Loss: 584.5584106445312, Entropy -361.9966735839844, Learning Rate: 0.01\n",
      "Epoch [222/20000], Loss: 517.7924194335938, Entropy -367.10333251953125, Learning Rate: 0.01\n",
      "Epoch [223/20000], Loss: 564.080322265625, Entropy -374.1614685058594, Learning Rate: 0.01\n",
      "Epoch [224/20000], Loss: 565.5924682617188, Entropy -354.2567138671875, Learning Rate: 0.01\n",
      "Epoch [225/20000], Loss: 538.874755859375, Entropy -373.8669128417969, Learning Rate: 0.01\n",
      "Epoch [226/20000], Loss: 568.71337890625, Entropy -375.189453125, Learning Rate: 0.01\n",
      "Epoch [227/20000], Loss: 528.544189453125, Entropy -371.83392333984375, Learning Rate: 0.01\n",
      "Epoch [228/20000], Loss: 530.59326171875, Entropy -349.6038513183594, Learning Rate: 0.01\n",
      "Epoch [229/20000], Loss: 548.2947998046875, Entropy -367.83404541015625, Learning Rate: 0.01\n",
      "Epoch [230/20000], Loss: 552.479248046875, Entropy -361.71820068359375, Learning Rate: 0.01\n",
      "Epoch [231/20000], Loss: 527.7947998046875, Entropy -373.6612854003906, Learning Rate: 0.01\n",
      "Epoch [232/20000], Loss: 525.814453125, Entropy -374.9625549316406, Learning Rate: 0.01\n",
      "Epoch [233/20000], Loss: 555.2020874023438, Entropy -367.582763671875, Learning Rate: 0.01\n",
      "Epoch [234/20000], Loss: 503.18798828125, Entropy -364.480224609375, Learning Rate: 0.01\n",
      "Epoch [235/20000], Loss: 518.2908325195312, Entropy -364.61151123046875, Learning Rate: 0.01\n",
      "Epoch [236/20000], Loss: 509.40350341796875, Entropy -356.6620788574219, Learning Rate: 0.01\n",
      "Epoch [237/20000], Loss: 515.5087890625, Entropy -359.16082763671875, Learning Rate: 0.01\n",
      "Epoch [238/20000], Loss: 535.6200561523438, Entropy -381.0098876953125, Learning Rate: 0.01\n",
      "Epoch [239/20000], Loss: 535.9791870117188, Entropy -357.3963317871094, Learning Rate: 0.01\n",
      "Epoch [240/20000], Loss: 556.8258666992188, Entropy -370.99267578125, Learning Rate: 0.01\n",
      "Epoch [241/20000], Loss: 520.4935302734375, Entropy -358.9438781738281, Learning Rate: 0.01\n",
      "Epoch [242/20000], Loss: 535.9882202148438, Entropy -355.8860168457031, Learning Rate: 0.01\n",
      "Epoch [243/20000], Loss: 567.1103515625, Entropy -353.93597412109375, Learning Rate: 0.01\n",
      "Epoch [244/20000], Loss: 580.5494995117188, Entropy -354.385986328125, Learning Rate: 0.01\n",
      "Epoch [245/20000], Loss: 566.85546875, Entropy -374.4736633300781, Learning Rate: 0.01\n",
      "Epoch [246/20000], Loss: 583.8831787109375, Entropy -371.79693603515625, Learning Rate: 0.01\n",
      "Epoch [247/20000], Loss: 546.8108520507812, Entropy -362.10760498046875, Learning Rate: 0.01\n",
      "Epoch [248/20000], Loss: 566.8684692382812, Entropy -367.0486145019531, Learning Rate: 0.01\n",
      "Epoch [249/20000], Loss: 528.0408325195312, Entropy -381.248291015625, Learning Rate: 0.01\n",
      "Epoch [250/20000], Loss: 602.4456176757812, Entropy -376.1189270019531, Learning Rate: 0.01\n",
      "Epoch [251/20000], Loss: 546.5806884765625, Entropy -369.1221008300781, Learning Rate: 0.01\n",
      "Epoch [252/20000], Loss: 552.5318603515625, Entropy -383.19757080078125, Learning Rate: 0.01\n",
      "Epoch [253/20000], Loss: 608.8812866210938, Entropy -358.94744873046875, Learning Rate: 0.01\n",
      "Epoch [254/20000], Loss: 546.2994995117188, Entropy -388.135986328125, Learning Rate: 0.01\n",
      "Epoch [255/20000], Loss: 537.8336181640625, Entropy -363.7800598144531, Learning Rate: 0.01\n",
      "Epoch [256/20000], Loss: 623.63671875, Entropy -347.7842102050781, Learning Rate: 0.01\n",
      "Epoch [257/20000], Loss: 506.8910827636719, Entropy -359.66094970703125, Learning Rate: 0.01\n",
      "Epoch [258/20000], Loss: 525.1502075195312, Entropy -360.7076721191406, Learning Rate: 0.01\n",
      "Epoch [259/20000], Loss: 640.8828125, Entropy -375.8922119140625, Learning Rate: 0.01\n",
      "Epoch [260/20000], Loss: 599.2606811523438, Entropy -388.32012939453125, Learning Rate: 0.01\n",
      "Epoch [261/20000], Loss: 568.1524047851562, Entropy -371.7587890625, Learning Rate: 0.01\n",
      "Epoch [262/20000], Loss: 623.6737060546875, Entropy -352.9818420410156, Learning Rate: 0.01\n",
      "Epoch [263/20000], Loss: 536.4334716796875, Entropy -370.1151428222656, Learning Rate: 0.01\n",
      "Epoch [264/20000], Loss: 555.1051635742188, Entropy -369.60003662109375, Learning Rate: 0.01\n",
      "Epoch [265/20000], Loss: 609.4136962890625, Entropy -365.2677917480469, Learning Rate: 0.01\n",
      "Epoch [266/20000], Loss: 526.9322509765625, Entropy -355.2494201660156, Learning Rate: 0.01\n",
      "Epoch [267/20000], Loss: 539.486572265625, Entropy -356.8111572265625, Learning Rate: 0.01\n",
      "Epoch [268/20000], Loss: 537.42529296875, Entropy -375.8872985839844, Learning Rate: 0.01\n",
      "Epoch [269/20000], Loss: 662.3006591796875, Entropy -361.8897399902344, Learning Rate: 0.01\n",
      "Epoch [270/20000], Loss: 532.66357421875, Entropy -359.9796447753906, Learning Rate: 0.01\n",
      "Epoch [271/20000], Loss: 571.7646484375, Entropy -359.44927978515625, Learning Rate: 0.01\n",
      "Epoch [272/20000], Loss: 582.938232421875, Entropy -367.234375, Learning Rate: 0.01\n",
      "Epoch [273/20000], Loss: 665.976318359375, Entropy -359.65606689453125, Learning Rate: 0.01\n",
      "Epoch [274/20000], Loss: 542.9205932617188, Entropy -364.7366943359375, Learning Rate: 0.01\n",
      "Epoch [275/20000], Loss: 581.5779418945312, Entropy -363.6820373535156, Learning Rate: 0.01\n",
      "Epoch [276/20000], Loss: 576.2033081054688, Entropy -374.3268737792969, Learning Rate: 0.01\n",
      "Epoch [277/20000], Loss: 574.0184936523438, Entropy -369.2122497558594, Learning Rate: 0.01\n",
      "Epoch [278/20000], Loss: 651.4193115234375, Entropy -349.39959716796875, Learning Rate: 0.01\n",
      "Epoch [279/20000], Loss: 552.5752563476562, Entropy -370.3473815917969, Learning Rate: 0.01\n",
      "Epoch [280/20000], Loss: 630.4024658203125, Entropy -382.06201171875, Learning Rate: 0.01\n",
      "Epoch [281/20000], Loss: 500.1226806640625, Entropy -371.5294494628906, Learning Rate: 0.01\n",
      "Epoch [282/20000], Loss: 558.4354248046875, Entropy -358.2401428222656, Learning Rate: 0.01\n",
      "Epoch [283/20000], Loss: 520.6715087890625, Entropy -373.80078125, Learning Rate: 0.01\n",
      "Epoch [284/20000], Loss: 543.0932006835938, Entropy -369.1086730957031, Learning Rate: 0.01\n",
      "Epoch [285/20000], Loss: 524.5236206054688, Entropy -374.7104797363281, Learning Rate: 0.01\n",
      "Epoch [286/20000], Loss: 560.8632202148438, Entropy -372.2932434082031, Learning Rate: 0.01\n",
      "Epoch [287/20000], Loss: 530.170166015625, Entropy -365.2324523925781, Learning Rate: 0.01\n",
      "Epoch [288/20000], Loss: 495.1259765625, Entropy -351.7901611328125, Learning Rate: 0.01\n",
      "Epoch [289/20000], Loss: 587.8989868164062, Entropy -366.77325439453125, Learning Rate: 0.01\n",
      "Epoch [290/20000], Loss: 488.6680908203125, Entropy -352.37640380859375, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [291/20000], Loss: 592.5709228515625, Entropy -376.559326171875, Learning Rate: 0.01\n",
      "Epoch [292/20000], Loss: 564.989990234375, Entropy -373.66961669921875, Learning Rate: 0.01\n",
      "Epoch [293/20000], Loss: 545.7911987304688, Entropy -356.1357727050781, Learning Rate: 0.01\n",
      "Epoch [294/20000], Loss: 541.9639892578125, Entropy -362.0071105957031, Learning Rate: 0.01\n",
      "Epoch [295/20000], Loss: 650.1040649414062, Entropy -367.925537109375, Learning Rate: 0.01\n",
      "Epoch [296/20000], Loss: 621.9099731445312, Entropy -373.6332702636719, Learning Rate: 0.01\n",
      "Epoch [297/20000], Loss: 657.8092651367188, Entropy -378.2715148925781, Learning Rate: 0.01\n",
      "Epoch [298/20000], Loss: 578.5465087890625, Entropy -357.54034423828125, Learning Rate: 0.01\n",
      "Epoch [299/20000], Loss: 673.9984130859375, Entropy -349.9703369140625, Learning Rate: 0.01\n",
      "Epoch [300/20000], Loss: 532.8716430664062, Entropy -360.08697509765625, Learning Rate: 0.01\n",
      "Epoch [301/20000], Loss: 504.6739807128906, Entropy -372.8829040527344, Learning Rate: 0.01\n",
      "Epoch [302/20000], Loss: 601.5314331054688, Entropy -348.5688781738281, Learning Rate: 0.01\n",
      "Epoch [303/20000], Loss: 518.8187255859375, Entropy -380.29278564453125, Learning Rate: 0.01\n",
      "Epoch [304/20000], Loss: 518.6104125976562, Entropy -368.566650390625, Learning Rate: 0.01\n",
      "Epoch [305/20000], Loss: 613.966064453125, Entropy -372.462158203125, Learning Rate: 0.01\n",
      "Epoch [306/20000], Loss: 530.0201416015625, Entropy -365.62884521484375, Learning Rate: 0.01\n",
      "Epoch [307/20000], Loss: 526.3577270507812, Entropy -367.9291687011719, Learning Rate: 0.01\n",
      "Epoch [308/20000], Loss: 551.9111328125, Entropy -361.57635498046875, Learning Rate: 0.01\n",
      "Epoch [309/20000], Loss: 512.3236083984375, Entropy -361.7065734863281, Learning Rate: 0.01\n",
      "Epoch [310/20000], Loss: 514.6986083984375, Entropy -384.96856689453125, Learning Rate: 0.01\n",
      "Epoch [311/20000], Loss: 608.641845703125, Entropy -364.3017578125, Learning Rate: 0.01\n",
      "Epoch [312/20000], Loss: 527.185791015625, Entropy -352.72918701171875, Learning Rate: 0.01\n",
      "Epoch [313/20000], Loss: 548.2948608398438, Entropy -370.2459716796875, Learning Rate: 0.01\n",
      "Epoch [314/20000], Loss: 634.7844848632812, Entropy -354.6725769042969, Learning Rate: 0.01\n",
      "Epoch [315/20000], Loss: 576.1012573242188, Entropy -368.4822998046875, Learning Rate: 0.01\n",
      "Epoch [316/20000], Loss: 512.6931762695312, Entropy -350.091796875, Learning Rate: 0.01\n",
      "Epoch [317/20000], Loss: 650.2744140625, Entropy -367.7522888183594, Learning Rate: 0.01\n",
      "Epoch [318/20000], Loss: 500.8405456542969, Entropy -348.3854675292969, Learning Rate: 0.01\n",
      "Epoch [319/20000], Loss: 598.3548583984375, Entropy -370.0687255859375, Learning Rate: 0.01\n",
      "Epoch [320/20000], Loss: 594.5809326171875, Entropy -360.8046875, Learning Rate: 0.01\n",
      "Epoch [321/20000], Loss: 523.0576782226562, Entropy -364.20452880859375, Learning Rate: 0.01\n",
      "Epoch [322/20000], Loss: 709.0244750976562, Entropy -388.1874694824219, Learning Rate: 0.01\n",
      "Epoch [323/20000], Loss: 579.9901123046875, Entropy -380.250244140625, Learning Rate: 0.01\n",
      "Epoch [324/20000], Loss: 606.8560180664062, Entropy -358.7047119140625, Learning Rate: 0.01\n",
      "Epoch [325/20000], Loss: 674.0667724609375, Entropy -356.25537109375, Learning Rate: 0.01\n",
      "Epoch [326/20000], Loss: 555.1513061523438, Entropy -359.572021484375, Learning Rate: 0.01\n",
      "Epoch [327/20000], Loss: 651.4127197265625, Entropy -358.28277587890625, Learning Rate: 0.01\n",
      "Epoch [328/20000], Loss: 711.1375122070312, Entropy -354.5957946777344, Learning Rate: 0.01\n",
      "Epoch [329/20000], Loss: 610.3375244140625, Entropy -353.4568176269531, Learning Rate: 0.01\n",
      "Epoch [330/20000], Loss: 856.123046875, Entropy -354.0918273925781, Learning Rate: 0.01\n",
      "Epoch [331/20000], Loss: 579.4721069335938, Entropy -347.3940124511719, Learning Rate: 0.01\n",
      "Epoch [332/20000], Loss: 606.933349609375, Entropy -362.4529724121094, Learning Rate: 0.01\n",
      "Epoch [333/20000], Loss: 600.6502075195312, Entropy -357.9261169433594, Learning Rate: 0.01\n",
      "Epoch [334/20000], Loss: 788.505859375, Entropy -361.12286376953125, Learning Rate: 0.01\n",
      "Epoch [335/20000], Loss: 531.6121826171875, Entropy -371.1018981933594, Learning Rate: 0.01\n",
      "Epoch [336/20000], Loss: 740.7238159179688, Entropy -368.2646789550781, Learning Rate: 0.01\n",
      "Epoch [337/20000], Loss: 611.5972290039062, Entropy -369.1033020019531, Learning Rate: 0.01\n",
      "Epoch [338/20000], Loss: 735.6607666015625, Entropy -365.35137939453125, Learning Rate: 0.01\n",
      "Epoch [339/20000], Loss: 659.3775024414062, Entropy -357.0016174316406, Learning Rate: 0.01\n",
      "Epoch [340/20000], Loss: 576.4780883789062, Entropy -372.9770202636719, Learning Rate: 0.01\n",
      "Epoch [341/20000], Loss: 542.3865356445312, Entropy -376.2889099121094, Learning Rate: 0.01\n",
      "Epoch [342/20000], Loss: 531.8612060546875, Entropy -360.769775390625, Learning Rate: 0.01\n",
      "Epoch [343/20000], Loss: 610.5845336914062, Entropy -372.2175598144531, Learning Rate: 0.01\n",
      "Epoch [344/20000], Loss: 606.5750122070312, Entropy -367.62353515625, Learning Rate: 0.01\n",
      "Epoch [345/20000], Loss: 521.189453125, Entropy -361.8559875488281, Learning Rate: 0.01\n",
      "Epoch [346/20000], Loss: 781.8960571289062, Entropy -365.9098205566406, Learning Rate: 0.01\n",
      "Epoch [347/20000], Loss: 474.05145263671875, Entropy -367.3650817871094, Learning Rate: 0.01\n",
      "Epoch [348/20000], Loss: 665.8311767578125, Entropy -367.9985656738281, Learning Rate: 0.01\n",
      "Epoch [349/20000], Loss: 472.2963562011719, Entropy -343.28173828125, Learning Rate: 0.01\n",
      "Epoch [350/20000], Loss: 532.7106323242188, Entropy -370.57916259765625, Learning Rate: 0.01\n",
      "Epoch [351/20000], Loss: 540.0618896484375, Entropy -366.01495361328125, Learning Rate: 0.01\n",
      "Epoch [352/20000], Loss: 487.4352722167969, Entropy -348.3220520019531, Learning Rate: 0.01\n",
      "Epoch [353/20000], Loss: 523.9806518554688, Entropy -360.6654968261719, Learning Rate: 0.01\n",
      "Epoch [354/20000], Loss: 544.9959106445312, Entropy -359.91888427734375, Learning Rate: 0.01\n",
      "Epoch [355/20000], Loss: 537.5538330078125, Entropy -365.72418212890625, Learning Rate: 0.01\n",
      "Epoch [356/20000], Loss: 499.338134765625, Entropy -368.4696044921875, Learning Rate: 0.01\n",
      "Epoch [357/20000], Loss: 535.8402709960938, Entropy -369.11981201171875, Learning Rate: 0.01\n",
      "Epoch [358/20000], Loss: 534.9965209960938, Entropy -348.1921691894531, Learning Rate: 0.01\n",
      "Epoch [359/20000], Loss: 461.43780517578125, Entropy -358.83233642578125, Learning Rate: 0.01\n",
      "Epoch [360/20000], Loss: 500.2458801269531, Entropy -369.433837890625, Learning Rate: 0.01\n",
      "Epoch [361/20000], Loss: 479.78204345703125, Entropy -367.87591552734375, Learning Rate: 0.01\n",
      "Epoch [362/20000], Loss: 482.62408447265625, Entropy -343.99566650390625, Learning Rate: 0.01\n",
      "Epoch [363/20000], Loss: 469.6174621582031, Entropy -360.354248046875, Learning Rate: 0.01\n",
      "Epoch [364/20000], Loss: 452.14013671875, Entropy -360.2406921386719, Learning Rate: 0.01\n",
      "Epoch [365/20000], Loss: 480.10821533203125, Entropy -360.87548828125, Learning Rate: 0.01\n",
      "Epoch [366/20000], Loss: 504.7862243652344, Entropy -361.4288330078125, Learning Rate: 0.01\n",
      "Epoch [367/20000], Loss: 488.72039794921875, Entropy -380.97235107421875, Learning Rate: 0.01\n",
      "Epoch [368/20000], Loss: 481.6683654785156, Entropy -356.9163818359375, Learning Rate: 0.01\n",
      "Epoch [369/20000], Loss: 461.852294921875, Entropy -370.20660400390625, Learning Rate: 0.01\n",
      "Epoch [370/20000], Loss: 501.87188720703125, Entropy -359.1217956542969, Learning Rate: 0.01\n",
      "Epoch [371/20000], Loss: 450.9593505859375, Entropy -343.6736145019531, Learning Rate: 0.01\n",
      "Epoch [372/20000], Loss: 465.6147155761719, Entropy -358.3324890136719, Learning Rate: 0.01\n",
      "Epoch [373/20000], Loss: 454.91998291015625, Entropy -356.9322204589844, Learning Rate: 0.01\n",
      "Epoch [374/20000], Loss: 431.0338134765625, Entropy -344.55859375, Learning Rate: 0.01\n",
      "Epoch [375/20000], Loss: 472.7942199707031, Entropy -371.9149169921875, Learning Rate: 0.01\n",
      "Epoch [376/20000], Loss: 495.44915771484375, Entropy -353.9844665527344, Learning Rate: 0.01\n",
      "Epoch [377/20000], Loss: 461.79302978515625, Entropy -346.2667541503906, Learning Rate: 0.01\n",
      "Epoch [378/20000], Loss: 455.9217529296875, Entropy -350.49810791015625, Learning Rate: 0.01\n",
      "Epoch [379/20000], Loss: 561.890869140625, Entropy -359.93408203125, Learning Rate: 0.01\n",
      "Epoch [380/20000], Loss: 455.4384765625, Entropy -359.29766845703125, Learning Rate: 0.01\n",
      "Epoch [381/20000], Loss: 511.9892578125, Entropy -349.9559326171875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [382/20000], Loss: 489.369873046875, Entropy -361.8737487792969, Learning Rate: 0.01\n",
      "Epoch [383/20000], Loss: 592.6002197265625, Entropy -349.8948974609375, Learning Rate: 0.01\n",
      "Epoch [384/20000], Loss: 579.52099609375, Entropy -358.152587890625, Learning Rate: 0.01\n",
      "Epoch [385/20000], Loss: 497.0813903808594, Entropy -362.5528564453125, Learning Rate: 0.01\n",
      "Epoch [386/20000], Loss: 553.5355224609375, Entropy -360.730712890625, Learning Rate: 0.01\n",
      "Epoch [387/20000], Loss: 585.5059814453125, Entropy -351.4158020019531, Learning Rate: 0.01\n",
      "Epoch [388/20000], Loss: 468.6366882324219, Entropy -349.0965881347656, Learning Rate: 0.01\n",
      "Epoch [389/20000], Loss: 598.5775756835938, Entropy -346.9518127441406, Learning Rate: 0.01\n",
      "Epoch [390/20000], Loss: 517.272705078125, Entropy -359.4665832519531, Learning Rate: 0.01\n",
      "Epoch [391/20000], Loss: 680.5238647460938, Entropy -363.23748779296875, Learning Rate: 0.01\n",
      "Epoch [392/20000], Loss: 476.25537109375, Entropy -360.85772705078125, Learning Rate: 0.01\n",
      "Epoch [393/20000], Loss: 660.6500854492188, Entropy -353.97686767578125, Learning Rate: 0.01\n",
      "Epoch [394/20000], Loss: 528.9931640625, Entropy -364.10137939453125, Learning Rate: 0.01\n",
      "Epoch [395/20000], Loss: 554.4251708984375, Entropy -351.47784423828125, Learning Rate: 0.01\n",
      "Epoch [396/20000], Loss: 566.181396484375, Entropy -344.849853515625, Learning Rate: 0.01\n",
      "Epoch [397/20000], Loss: 520.760009765625, Entropy -353.6816101074219, Learning Rate: 0.01\n",
      "Epoch [398/20000], Loss: 550.5166625976562, Entropy -354.3931579589844, Learning Rate: 0.01\n",
      "Epoch [399/20000], Loss: 668.2673950195312, Entropy -354.60809326171875, Learning Rate: 0.01\n",
      "Epoch [400/20000], Loss: 586.4229125976562, Entropy -360.5526123046875, Learning Rate: 0.01\n",
      "Epoch [401/20000], Loss: 637.5985717773438, Entropy -368.4906005859375, Learning Rate: 0.01\n",
      "Epoch [402/20000], Loss: 704.3113403320312, Entropy -356.93963623046875, Learning Rate: 0.01\n",
      "Epoch [403/20000], Loss: 515.8056030273438, Entropy -356.81524658203125, Learning Rate: 0.01\n",
      "Epoch [404/20000], Loss: 594.7656860351562, Entropy -349.0255126953125, Learning Rate: 0.01\n",
      "Epoch [405/20000], Loss: 631.216064453125, Entropy -368.78729248046875, Learning Rate: 0.01\n",
      "Epoch [406/20000], Loss: 617.1664428710938, Entropy -354.3365478515625, Learning Rate: 0.01\n",
      "Epoch [407/20000], Loss: 503.7289123535156, Entropy -362.5267333984375, Learning Rate: 0.01\n",
      "Epoch [408/20000], Loss: 561.6170654296875, Entropy -356.33251953125, Learning Rate: 0.01\n",
      "Epoch [409/20000], Loss: 537.581298828125, Entropy -363.39837646484375, Learning Rate: 0.01\n",
      "Epoch [410/20000], Loss: 487.5151672363281, Entropy -358.19158935546875, Learning Rate: 0.01\n",
      "Epoch [411/20000], Loss: 455.0917663574219, Entropy -355.53790283203125, Learning Rate: 0.01\n",
      "Epoch [412/20000], Loss: 484.2839660644531, Entropy -356.2256774902344, Learning Rate: 0.01\n",
      "Epoch [413/20000], Loss: 550.1826782226562, Entropy -368.8112487792969, Learning Rate: 0.01\n",
      "Epoch [414/20000], Loss: 560.2496337890625, Entropy -357.4615478515625, Learning Rate: 0.01\n",
      "Epoch [415/20000], Loss: 471.5253601074219, Entropy -351.79071044921875, Learning Rate: 0.01\n",
      "Epoch [416/20000], Loss: 467.81146240234375, Entropy -353.0021057128906, Learning Rate: 0.01\n",
      "Epoch [417/20000], Loss: 502.8070983886719, Entropy -374.8177185058594, Learning Rate: 0.01\n",
      "Epoch [418/20000], Loss: 505.9927062988281, Entropy -354.3703308105469, Learning Rate: 0.01\n",
      "Epoch [419/20000], Loss: 586.8382568359375, Entropy -349.5357971191406, Learning Rate: 0.01\n",
      "Epoch [420/20000], Loss: 552.5486450195312, Entropy -351.3182067871094, Learning Rate: 0.01\n",
      "Epoch [421/20000], Loss: 603.1843872070312, Entropy -349.3970947265625, Learning Rate: 0.01\n",
      "Epoch [422/20000], Loss: 507.32122802734375, Entropy -341.7062072753906, Learning Rate: 0.01\n",
      "Epoch [423/20000], Loss: 594.6244506835938, Entropy -349.7435302734375, Learning Rate: 0.01\n",
      "Epoch [424/20000], Loss: 530.2193603515625, Entropy -356.3476867675781, Learning Rate: 0.01\n",
      "Epoch [425/20000], Loss: 555.2749633789062, Entropy -354.8775329589844, Learning Rate: 0.01\n",
      "Epoch [426/20000], Loss: 499.67547607421875, Entropy -371.7994384765625, Learning Rate: 0.01\n",
      "Epoch [427/20000], Loss: 480.1780700683594, Entropy -355.56549072265625, Learning Rate: 0.01\n",
      "Epoch [428/20000], Loss: 530.7802734375, Entropy -358.33746337890625, Learning Rate: 0.01\n",
      "Epoch [429/20000], Loss: 472.83056640625, Entropy -371.8682861328125, Learning Rate: 0.01\n",
      "Epoch [430/20000], Loss: 522.1503295898438, Entropy -360.03460693359375, Learning Rate: 0.01\n",
      "Epoch [431/20000], Loss: 551.710205078125, Entropy -361.1491394042969, Learning Rate: 0.01\n",
      "Epoch [432/20000], Loss: 565.5291748046875, Entropy -355.1343078613281, Learning Rate: 0.01\n",
      "Epoch [433/20000], Loss: 507.1422119140625, Entropy -336.40521240234375, Learning Rate: 0.01\n",
      "Epoch [434/20000], Loss: 484.6785888671875, Entropy -345.5502014160156, Learning Rate: 0.01\n",
      "Epoch [435/20000], Loss: 512.1150512695312, Entropy -350.75299072265625, Learning Rate: 0.01\n",
      "Epoch [436/20000], Loss: 559.446044921875, Entropy -349.12213134765625, Learning Rate: 0.01\n",
      "Epoch [437/20000], Loss: 491.70343017578125, Entropy -353.2821044921875, Learning Rate: 0.01\n",
      "Epoch [438/20000], Loss: 492.4654235839844, Entropy -348.00048828125, Learning Rate: 0.01\n",
      "Epoch [439/20000], Loss: 511.123046875, Entropy -348.49407958984375, Learning Rate: 0.01\n",
      "Epoch [440/20000], Loss: 626.674560546875, Entropy -347.80218505859375, Learning Rate: 0.01\n",
      "Epoch [441/20000], Loss: 463.0135192871094, Entropy -355.3607177734375, Learning Rate: 0.01\n",
      "Epoch [442/20000], Loss: 584.0396118164062, Entropy -354.4292907714844, Learning Rate: 0.01\n",
      "Epoch [443/20000], Loss: 493.1524353027344, Entropy -351.8974304199219, Learning Rate: 0.01\n",
      "Epoch [444/20000], Loss: 591.8247680664062, Entropy -350.273193359375, Learning Rate: 0.01\n",
      "Epoch [445/20000], Loss: 554.425048828125, Entropy -359.88555908203125, Learning Rate: 0.01\n",
      "Epoch [446/20000], Loss: 576.0716552734375, Entropy -341.99346923828125, Learning Rate: 0.01\n",
      "Epoch [447/20000], Loss: 513.899658203125, Entropy -355.6959533691406, Learning Rate: 0.01\n",
      "Epoch [448/20000], Loss: 441.81451416015625, Entropy -349.78021240234375, Learning Rate: 0.01\n",
      "Epoch [449/20000], Loss: 535.390625, Entropy -376.0429992675781, Learning Rate: 0.01\n",
      "Epoch [450/20000], Loss: 654.0020751953125, Entropy -368.7899475097656, Learning Rate: 0.01\n",
      "Epoch [451/20000], Loss: 510.31768798828125, Entropy -349.6382141113281, Learning Rate: 0.01\n",
      "Epoch [452/20000], Loss: 478.95587158203125, Entropy -352.6340026855469, Learning Rate: 0.01\n",
      "Epoch [453/20000], Loss: 622.3150634765625, Entropy -352.43121337890625, Learning Rate: 0.01\n",
      "Epoch [454/20000], Loss: 480.74981689453125, Entropy -356.32977294921875, Learning Rate: 0.01\n",
      "Epoch [455/20000], Loss: 580.78515625, Entropy -353.5290832519531, Learning Rate: 0.01\n",
      "Epoch [456/20000], Loss: 589.0308227539062, Entropy -355.4382629394531, Learning Rate: 0.01\n",
      "Epoch [457/20000], Loss: 488.1060485839844, Entropy -344.54217529296875, Learning Rate: 0.01\n",
      "Epoch [458/20000], Loss: 582.15869140625, Entropy -360.8847961425781, Learning Rate: 0.01\n",
      "Epoch [459/20000], Loss: 506.6800231933594, Entropy -336.84161376953125, Learning Rate: 0.01\n",
      "Epoch [460/20000], Loss: 533.5635986328125, Entropy -360.44354248046875, Learning Rate: 0.01\n",
      "Epoch [461/20000], Loss: 525.474365234375, Entropy -370.54443359375, Learning Rate: 0.01\n",
      "Epoch [462/20000], Loss: 443.14898681640625, Entropy -359.84881591796875, Learning Rate: 0.01\n",
      "Epoch [463/20000], Loss: 482.90625, Entropy -348.5599670410156, Learning Rate: 0.01\n",
      "Epoch [464/20000], Loss: 509.4713134765625, Entropy -360.5303649902344, Learning Rate: 0.01\n",
      "Epoch [465/20000], Loss: 521.5791625976562, Entropy -368.97454833984375, Learning Rate: 0.01\n",
      "Epoch [466/20000], Loss: 492.0675964355469, Entropy -349.89178466796875, Learning Rate: 0.01\n",
      "Epoch [467/20000], Loss: 544.431396484375, Entropy -352.84942626953125, Learning Rate: 0.01\n",
      "Epoch [468/20000], Loss: 482.58447265625, Entropy -351.650390625, Learning Rate: 0.01\n",
      "Epoch [469/20000], Loss: 464.1597595214844, Entropy -332.32568359375, Learning Rate: 0.01\n",
      "Epoch [470/20000], Loss: 592.2897338867188, Entropy -359.9225769042969, Learning Rate: 0.01\n",
      "Epoch [471/20000], Loss: 522.1973266601562, Entropy -339.68975830078125, Learning Rate: 0.01\n",
      "Epoch [472/20000], Loss: 568.526611328125, Entropy -355.1615295410156, Learning Rate: 0.01\n",
      "Epoch [473/20000], Loss: 466.2593688964844, Entropy -330.48468017578125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [474/20000], Loss: 580.170166015625, Entropy -359.17401123046875, Learning Rate: 0.01\n",
      "Epoch [475/20000], Loss: 566.5322265625, Entropy -359.4931640625, Learning Rate: 0.01\n",
      "Epoch [476/20000], Loss: 549.943603515625, Entropy -359.25396728515625, Learning Rate: 0.01\n",
      "Epoch [477/20000], Loss: 520.8865966796875, Entropy -362.27020263671875, Learning Rate: 0.01\n",
      "Epoch [478/20000], Loss: 679.7669067382812, Entropy -341.8319091796875, Learning Rate: 0.01\n",
      "Epoch [479/20000], Loss: 664.7068481445312, Entropy -353.595458984375, Learning Rate: 0.01\n",
      "Epoch [480/20000], Loss: 593.154541015625, Entropy -345.8104553222656, Learning Rate: 0.01\n",
      "Epoch [481/20000], Loss: 593.81494140625, Entropy -355.18365478515625, Learning Rate: 0.01\n",
      "Epoch [482/20000], Loss: 601.5914306640625, Entropy -367.50311279296875, Learning Rate: 0.01\n",
      "Epoch [483/20000], Loss: 886.17041015625, Entropy -354.68450927734375, Learning Rate: 0.01\n",
      "Epoch [484/20000], Loss: 604.3218383789062, Entropy -361.69146728515625, Learning Rate: 0.01\n",
      "Epoch [485/20000], Loss: 687.0159912109375, Entropy -350.2323303222656, Learning Rate: 0.01\n",
      "Epoch [486/20000], Loss: 569.6922607421875, Entropy -351.9373474121094, Learning Rate: 0.01\n",
      "Epoch [487/20000], Loss: 656.977294921875, Entropy -359.9128723144531, Learning Rate: 0.01\n",
      "Epoch [488/20000], Loss: 640.6110229492188, Entropy -337.34136962890625, Learning Rate: 0.01\n",
      "Epoch [489/20000], Loss: 604.1318969726562, Entropy -343.673583984375, Learning Rate: 0.01\n",
      "Epoch [490/20000], Loss: 491.4310302734375, Entropy -340.74755859375, Learning Rate: 0.01\n",
      "Epoch [491/20000], Loss: 681.1220703125, Entropy -353.5989990234375, Learning Rate: 0.01\n",
      "Epoch [492/20000], Loss: 652.7344970703125, Entropy -358.55230712890625, Learning Rate: 0.01\n",
      "Epoch [493/20000], Loss: 579.026123046875, Entropy -355.6409912109375, Learning Rate: 0.01\n",
      "Epoch [494/20000], Loss: 588.6284790039062, Entropy -351.5254821777344, Learning Rate: 0.01\n",
      "Epoch [495/20000], Loss: 621.6771240234375, Entropy -347.2890319824219, Learning Rate: 0.01\n",
      "Epoch [496/20000], Loss: 678.3194580078125, Entropy -338.47833251953125, Learning Rate: 0.01\n",
      "Epoch [497/20000], Loss: 734.8016357421875, Entropy -333.5098571777344, Learning Rate: 0.01\n",
      "Epoch [498/20000], Loss: 454.9773864746094, Entropy -340.2889404296875, Learning Rate: 0.01\n",
      "Epoch [499/20000], Loss: 523.154296875, Entropy -342.6055908203125, Learning Rate: 0.01\n",
      "Epoch [500/20000], Loss: 499.55462646484375, Entropy -354.9482727050781, Learning Rate: 0.01\n",
      "Epoch [501/20000], Loss: 567.93017578125, Entropy -361.72430419921875, Learning Rate: 0.01\n",
      "Epoch [502/20000], Loss: 505.92974853515625, Entropy -373.32733154296875, Learning Rate: 0.01\n",
      "Epoch [503/20000], Loss: 481.48236083984375, Entropy -356.742919921875, Learning Rate: 0.01\n",
      "Epoch [504/20000], Loss: 576.7036743164062, Entropy -344.8702697753906, Learning Rate: 0.01\n",
      "Epoch [505/20000], Loss: 496.2297058105469, Entropy -344.8734436035156, Learning Rate: 0.01\n",
      "Epoch [506/20000], Loss: 505.1665344238281, Entropy -359.80615234375, Learning Rate: 0.01\n",
      "Epoch [507/20000], Loss: 465.1415100097656, Entropy -349.9368591308594, Learning Rate: 0.01\n",
      "Epoch [508/20000], Loss: 464.1531066894531, Entropy -342.4519348144531, Learning Rate: 0.01\n",
      "Epoch [509/20000], Loss: 478.7572937011719, Entropy -340.676025390625, Learning Rate: 0.01\n",
      "Epoch [510/20000], Loss: 435.508056640625, Entropy -360.5358581542969, Learning Rate: 0.01\n",
      "Epoch [511/20000], Loss: 524.56982421875, Entropy -356.53179931640625, Learning Rate: 0.01\n",
      "Epoch [512/20000], Loss: 453.4505310058594, Entropy -356.48297119140625, Learning Rate: 0.01\n",
      "Epoch [513/20000], Loss: 446.43359375, Entropy -348.1080322265625, Learning Rate: 0.01\n",
      "Epoch [514/20000], Loss: 488.7855224609375, Entropy -358.7014465332031, Learning Rate: 0.01\n",
      "Epoch [515/20000], Loss: 448.4375, Entropy -349.72076416015625, Learning Rate: 0.01\n",
      "Epoch [516/20000], Loss: 534.3411865234375, Entropy -345.4116516113281, Learning Rate: 0.01\n",
      "Epoch [517/20000], Loss: 481.7978515625, Entropy -350.4351501464844, Learning Rate: 0.01\n",
      "Epoch [518/20000], Loss: 533.452392578125, Entropy -357.5577087402344, Learning Rate: 0.01\n",
      "Epoch [519/20000], Loss: 554.995361328125, Entropy -349.448974609375, Learning Rate: 0.01\n",
      "Epoch [520/20000], Loss: 537.673095703125, Entropy -353.9014892578125, Learning Rate: 0.01\n",
      "Epoch [521/20000], Loss: 468.1195068359375, Entropy -358.21044921875, Learning Rate: 0.01\n",
      "Epoch [522/20000], Loss: 534.4379272460938, Entropy -337.4711608886719, Learning Rate: 0.01\n",
      "Epoch [523/20000], Loss: 585.4205932617188, Entropy -342.0685119628906, Learning Rate: 0.01\n",
      "Epoch [524/20000], Loss: 597.1982421875, Entropy -368.29290771484375, Learning Rate: 0.01\n",
      "Epoch [525/20000], Loss: 532.0647583007812, Entropy -348.62841796875, Learning Rate: 0.01\n",
      "Epoch [526/20000], Loss: 651.17919921875, Entropy -336.6260986328125, Learning Rate: 0.01\n",
      "Epoch [527/20000], Loss: 517.3837280273438, Entropy -351.7744445800781, Learning Rate: 0.01\n",
      "Epoch [528/20000], Loss: 579.7517700195312, Entropy -343.0666809082031, Learning Rate: 0.01\n",
      "Epoch [529/20000], Loss: 624.4234619140625, Entropy -331.3387451171875, Learning Rate: 0.01\n",
      "Epoch [530/20000], Loss: 679.7049560546875, Entropy -343.6755676269531, Learning Rate: 0.01\n",
      "Epoch [531/20000], Loss: 493.2822570800781, Entropy -341.6028747558594, Learning Rate: 0.01\n",
      "Epoch [532/20000], Loss: 747.767578125, Entropy -353.5458679199219, Learning Rate: 0.01\n",
      "Epoch [533/20000], Loss: 623.2228393554688, Entropy -340.9576416015625, Learning Rate: 0.01\n",
      "Epoch [534/20000], Loss: 662.9000244140625, Entropy -366.3873596191406, Learning Rate: 0.01\n",
      "Epoch [535/20000], Loss: 516.4334106445312, Entropy -343.75360107421875, Learning Rate: 0.01\n",
      "Epoch [536/20000], Loss: 531.7267456054688, Entropy -343.4308166503906, Learning Rate: 0.01\n",
      "Epoch [537/20000], Loss: 815.2025146484375, Entropy -347.8517150878906, Learning Rate: 0.01\n",
      "Epoch [538/20000], Loss: 705.0960693359375, Entropy -352.93408203125, Learning Rate: 0.01\n",
      "Epoch [539/20000], Loss: 661.6425170898438, Entropy -357.70355224609375, Learning Rate: 0.01\n",
      "Epoch [540/20000], Loss: 607.4330444335938, Entropy -347.7472839355469, Learning Rate: 0.01\n",
      "Epoch [541/20000], Loss: 735.9669189453125, Entropy -351.2369384765625, Learning Rate: 0.01\n",
      "Epoch [542/20000], Loss: 852.294189453125, Entropy -344.9964904785156, Learning Rate: 0.01\n",
      "Epoch [543/20000], Loss: 537.0675659179688, Entropy -337.8447570800781, Learning Rate: 0.01\n",
      "Epoch [544/20000], Loss: 932.9910278320312, Entropy -338.8355407714844, Learning Rate: 0.01\n",
      "Epoch [545/20000], Loss: 686.1510620117188, Entropy -351.4439697265625, Learning Rate: 0.01\n",
      "Epoch [546/20000], Loss: 537.5366821289062, Entropy -346.6534729003906, Learning Rate: 0.01\n",
      "Epoch [547/20000], Loss: 663.7990112304688, Entropy -365.61724853515625, Learning Rate: 0.01\n",
      "Epoch [548/20000], Loss: 668.0843505859375, Entropy -339.2497863769531, Learning Rate: 0.01\n",
      "Epoch [549/20000], Loss: 554.8284912109375, Entropy -330.6435852050781, Learning Rate: 0.01\n",
      "Epoch [550/20000], Loss: 559.537841796875, Entropy -339.9679260253906, Learning Rate: 0.01\n",
      "Epoch [551/20000], Loss: 559.8580322265625, Entropy -332.9264831542969, Learning Rate: 0.01\n",
      "Epoch [552/20000], Loss: 714.6932373046875, Entropy -359.75201416015625, Learning Rate: 0.01\n",
      "Epoch [553/20000], Loss: 701.8319091796875, Entropy -339.3734130859375, Learning Rate: 0.01\n",
      "Epoch [554/20000], Loss: 668.096435546875, Entropy -339.091552734375, Learning Rate: 0.01\n",
      "Epoch [555/20000], Loss: 722.7872314453125, Entropy -338.0444030761719, Learning Rate: 0.01\n",
      "Epoch [556/20000], Loss: 567.9732666015625, Entropy -356.4981689453125, Learning Rate: 0.01\n",
      "Epoch [557/20000], Loss: 513.8515014648438, Entropy -345.3108825683594, Learning Rate: 0.01\n",
      "Epoch [558/20000], Loss: 652.6976318359375, Entropy -344.9170227050781, Learning Rate: 0.01\n",
      "Epoch [559/20000], Loss: 586.2150268554688, Entropy -341.29046630859375, Learning Rate: 0.01\n",
      "Epoch [560/20000], Loss: 491.08111572265625, Entropy -355.54498291015625, Learning Rate: 0.01\n",
      "Epoch [561/20000], Loss: 548.4518432617188, Entropy -367.8014221191406, Learning Rate: 0.01\n",
      "Epoch [562/20000], Loss: 567.2484130859375, Entropy -330.4017639160156, Learning Rate: 0.01\n",
      "Epoch [563/20000], Loss: 643.66796875, Entropy -345.4822692871094, Learning Rate: 0.01\n",
      "Epoch [564/20000], Loss: 487.97210693359375, Entropy -352.2587890625, Learning Rate: 0.01\n",
      "Epoch [565/20000], Loss: 650.1691284179688, Entropy -343.61865234375, Learning Rate: 0.01\n",
      "Epoch [566/20000], Loss: 669.306640625, Entropy -341.38177490234375, Learning Rate: 0.01\n",
      "Epoch [567/20000], Loss: 518.0140380859375, Entropy -338.7491455078125, Learning Rate: 0.01\n",
      "Epoch [568/20000], Loss: 675.9586791992188, Entropy -354.289794921875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [569/20000], Loss: 587.033203125, Entropy -363.7353820800781, Learning Rate: 0.01\n",
      "Epoch [570/20000], Loss: 693.3341064453125, Entropy -340.85003662109375, Learning Rate: 0.01\n",
      "Epoch [571/20000], Loss: 656.8638916015625, Entropy -353.7293395996094, Learning Rate: 0.01\n",
      "Epoch [572/20000], Loss: 785.7559814453125, Entropy -343.0461120605469, Learning Rate: 0.01\n",
      "Epoch [573/20000], Loss: 832.4130859375, Entropy -355.19818115234375, Learning Rate: 0.01\n",
      "Epoch [574/20000], Loss: 662.0859985351562, Entropy -348.6024475097656, Learning Rate: 0.01\n",
      "Epoch [575/20000], Loss: 773.9044799804688, Entropy -336.3245849609375, Learning Rate: 0.01\n",
      "Epoch [576/20000], Loss: 503.891845703125, Entropy -343.89202880859375, Learning Rate: 0.005\n",
      "Epoch [577/20000], Loss: 545.6812133789062, Entropy -338.82257080078125, Learning Rate: 0.005\n",
      "Epoch [578/20000], Loss: 749.437744140625, Entropy -350.19403076171875, Learning Rate: 0.005\n",
      "Epoch [579/20000], Loss: 524.9837036132812, Entropy -354.3335266113281, Learning Rate: 0.005\n",
      "Epoch [580/20000], Loss: 544.6433715820312, Entropy -348.3907165527344, Learning Rate: 0.005\n",
      "Epoch [581/20000], Loss: 563.1015014648438, Entropy -351.3977355957031, Learning Rate: 0.005\n",
      "Epoch [582/20000], Loss: 536.5708618164062, Entropy -349.9439392089844, Learning Rate: 0.005\n",
      "Epoch [583/20000], Loss: 558.4589233398438, Entropy -333.5619201660156, Learning Rate: 0.005\n",
      "Epoch [584/20000], Loss: 469.4073486328125, Entropy -344.1194763183594, Learning Rate: 0.005\n",
      "Epoch [585/20000], Loss: 521.508056640625, Entropy -357.2593994140625, Learning Rate: 0.005\n",
      "Epoch [586/20000], Loss: 506.0989685058594, Entropy -361.88995361328125, Learning Rate: 0.005\n",
      "Epoch [587/20000], Loss: 527.6365966796875, Entropy -343.3697814941406, Learning Rate: 0.005\n",
      "Epoch [588/20000], Loss: 479.458984375, Entropy -358.1045837402344, Learning Rate: 0.005\n",
      "Epoch [589/20000], Loss: 521.9229125976562, Entropy -358.5272521972656, Learning Rate: 0.005\n",
      "Epoch [590/20000], Loss: 473.9685363769531, Entropy -336.1330871582031, Learning Rate: 0.005\n",
      "Epoch [591/20000], Loss: 469.0788269042969, Entropy -344.2373352050781, Learning Rate: 0.005\n",
      "Epoch [592/20000], Loss: 472.94659423828125, Entropy -346.6515808105469, Learning Rate: 0.005\n",
      "Epoch [593/20000], Loss: 493.7742919921875, Entropy -351.5716247558594, Learning Rate: 0.005\n",
      "Epoch [594/20000], Loss: 440.76611328125, Entropy -357.40936279296875, Learning Rate: 0.005\n",
      "Epoch [595/20000], Loss: 445.21728515625, Entropy -340.5924072265625, Learning Rate: 0.005\n",
      "Epoch [596/20000], Loss: 471.1786804199219, Entropy -346.9848327636719, Learning Rate: 0.005\n",
      "Epoch [597/20000], Loss: 471.5131530761719, Entropy -337.50921630859375, Learning Rate: 0.005\n",
      "Epoch [598/20000], Loss: 451.20074462890625, Entropy -347.6383056640625, Learning Rate: 0.005\n",
      "Epoch [599/20000], Loss: 436.0584411621094, Entropy -369.621826171875, Learning Rate: 0.005\n",
      "Epoch [600/20000], Loss: 452.884765625, Entropy -371.85174560546875, Learning Rate: 0.005\n",
      "Epoch [601/20000], Loss: 434.53662109375, Entropy -344.5875244140625, Learning Rate: 0.005\n",
      "Epoch [602/20000], Loss: 435.5294189453125, Entropy -340.53900146484375, Learning Rate: 0.005\n",
      "Epoch [603/20000], Loss: 432.3213195800781, Entropy -341.591064453125, Learning Rate: 0.005\n",
      "Epoch [604/20000], Loss: 417.9615478515625, Entropy -328.16070556640625, Learning Rate: 0.005\n",
      "Epoch [605/20000], Loss: 405.3059997558594, Entropy -341.4484558105469, Learning Rate: 0.005\n",
      "Epoch [606/20000], Loss: 418.8370361328125, Entropy -345.9750061035156, Learning Rate: 0.005\n",
      "Epoch [607/20000], Loss: 427.34228515625, Entropy -336.3351745605469, Learning Rate: 0.005\n",
      "Epoch [608/20000], Loss: 443.7760925292969, Entropy -364.1644592285156, Learning Rate: 0.005\n",
      "Epoch [609/20000], Loss: 420.4701843261719, Entropy -354.20037841796875, Learning Rate: 0.005\n",
      "Epoch [610/20000], Loss: 431.16998291015625, Entropy -360.1497802734375, Learning Rate: 0.005\n",
      "Epoch [611/20000], Loss: 406.9382019042969, Entropy -335.9491882324219, Learning Rate: 0.005\n",
      "Epoch [612/20000], Loss: 412.9346008300781, Entropy -356.0693359375, Learning Rate: 0.005\n",
      "Epoch [613/20000], Loss: 414.887939453125, Entropy -354.0486145019531, Learning Rate: 0.005\n",
      "Epoch [614/20000], Loss: 425.6069641113281, Entropy -350.1136779785156, Learning Rate: 0.005\n",
      "Epoch [615/20000], Loss: 426.7419128417969, Entropy -346.51800537109375, Learning Rate: 0.005\n",
      "Epoch [616/20000], Loss: 411.8443603515625, Entropy -356.2381286621094, Learning Rate: 0.005\n",
      "Epoch [617/20000], Loss: 407.01007080078125, Entropy -354.2015380859375, Learning Rate: 0.005\n",
      "Epoch [618/20000], Loss: 420.5922546386719, Entropy -341.53033447265625, Learning Rate: 0.005\n",
      "Epoch [619/20000], Loss: 433.7819519042969, Entropy -367.920166015625, Learning Rate: 0.005\n",
      "Epoch [620/20000], Loss: 406.382568359375, Entropy -359.7659912109375, Learning Rate: 0.005\n",
      "Epoch [621/20000], Loss: 421.3094177246094, Entropy -345.8473815917969, Learning Rate: 0.005\n",
      "Epoch [622/20000], Loss: 415.8521423339844, Entropy -356.7789611816406, Learning Rate: 0.005\n",
      "Epoch [623/20000], Loss: 421.9017028808594, Entropy -357.7615966796875, Learning Rate: 0.005\n",
      "Epoch [624/20000], Loss: 386.7567138671875, Entropy -322.66265869140625, Learning Rate: 0.005\n",
      "Epoch [625/20000], Loss: 437.3836364746094, Entropy -360.2784118652344, Learning Rate: 0.005\n",
      "Epoch [626/20000], Loss: 401.22723388671875, Entropy -346.1822204589844, Learning Rate: 0.005\n",
      "Epoch [627/20000], Loss: 420.5250244140625, Entropy -351.7879638671875, Learning Rate: 0.005\n",
      "Epoch [628/20000], Loss: 420.5396728515625, Entropy -357.7662353515625, Learning Rate: 0.005\n",
      "Epoch [629/20000], Loss: 452.94036865234375, Entropy -359.9587097167969, Learning Rate: 0.005\n",
      "Epoch [630/20000], Loss: 420.17645263671875, Entropy -366.3216857910156, Learning Rate: 0.005\n",
      "Epoch [631/20000], Loss: 422.1084289550781, Entropy -360.4552307128906, Learning Rate: 0.005\n",
      "Epoch [632/20000], Loss: 420.1248474121094, Entropy -357.15887451171875, Learning Rate: 0.005\n",
      "Epoch [633/20000], Loss: 414.0546569824219, Entropy -351.5425720214844, Learning Rate: 0.005\n",
      "Epoch [634/20000], Loss: 409.3306579589844, Entropy -335.9856262207031, Learning Rate: 0.005\n",
      "Epoch [635/20000], Loss: 426.28375244140625, Entropy -353.17169189453125, Learning Rate: 0.005\n",
      "Epoch [636/20000], Loss: 406.21405029296875, Entropy -350.6382751464844, Learning Rate: 0.005\n",
      "Epoch [637/20000], Loss: 406.70343017578125, Entropy -355.5687561035156, Learning Rate: 0.005\n",
      "Epoch [638/20000], Loss: 401.2206115722656, Entropy -352.1413269042969, Learning Rate: 0.005\n",
      "Epoch [639/20000], Loss: 391.18365478515625, Entropy -338.4650573730469, Learning Rate: 0.005\n",
      "Epoch [640/20000], Loss: 418.1497497558594, Entropy -365.7469482421875, Learning Rate: 0.005\n",
      "Epoch [641/20000], Loss: 403.3236999511719, Entropy -349.1876525878906, Learning Rate: 0.005\n",
      "Epoch [642/20000], Loss: 410.09832763671875, Entropy -337.20904541015625, Learning Rate: 0.005\n",
      "Epoch [643/20000], Loss: 417.47283935546875, Entropy -364.50311279296875, Learning Rate: 0.005\n",
      "Epoch [644/20000], Loss: 422.82470703125, Entropy -357.9686279296875, Learning Rate: 0.005\n",
      "Epoch [645/20000], Loss: 418.2561340332031, Entropy -352.7635192871094, Learning Rate: 0.005\n",
      "Epoch [646/20000], Loss: 402.462890625, Entropy -340.2334899902344, Learning Rate: 0.005\n",
      "Epoch [647/20000], Loss: 422.7810363769531, Entropy -359.9957580566406, Learning Rate: 0.005\n",
      "Epoch [648/20000], Loss: 391.3237609863281, Entropy -339.3623046875, Learning Rate: 0.005\n",
      "Epoch [649/20000], Loss: 412.82720947265625, Entropy -350.1704406738281, Learning Rate: 0.005\n",
      "Epoch [650/20000], Loss: 411.9867248535156, Entropy -342.64398193359375, Learning Rate: 0.005\n",
      "Epoch [651/20000], Loss: 389.9984436035156, Entropy -338.4540100097656, Learning Rate: 0.005\n",
      "Epoch [652/20000], Loss: 431.19537353515625, Entropy -359.7982482910156, Learning Rate: 0.005\n",
      "Epoch [653/20000], Loss: 396.052978515625, Entropy -338.956298828125, Learning Rate: 0.005\n",
      "Epoch [654/20000], Loss: 404.8748474121094, Entropy -351.48236083984375, Learning Rate: 0.005\n",
      "Epoch [655/20000], Loss: 419.4115295410156, Entropy -357.9451599121094, Learning Rate: 0.005\n",
      "Epoch [656/20000], Loss: 393.934326171875, Entropy -338.9175720214844, Learning Rate: 0.005\n",
      "Epoch [657/20000], Loss: 408.14886474609375, Entropy -348.8231506347656, Learning Rate: 0.005\n",
      "Epoch [658/20000], Loss: 398.836669921875, Entropy -358.0187072753906, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [659/20000], Loss: 422.77215576171875, Entropy -368.25457763671875, Learning Rate: 0.005\n",
      "Epoch [660/20000], Loss: 416.28778076171875, Entropy -342.7257385253906, Learning Rate: 0.005\n",
      "Epoch [661/20000], Loss: 391.7543029785156, Entropy -341.22943115234375, Learning Rate: 0.005\n",
      "Epoch [662/20000], Loss: 414.58758544921875, Entropy -335.4898986816406, Learning Rate: 0.005\n",
      "Epoch [663/20000], Loss: 418.6226501464844, Entropy -354.9050598144531, Learning Rate: 0.005\n",
      "Epoch [664/20000], Loss: 427.0172119140625, Entropy -357.84600830078125, Learning Rate: 0.005\n",
      "Epoch [665/20000], Loss: 408.4069519042969, Entropy -357.98675537109375, Learning Rate: 0.005\n",
      "Epoch [666/20000], Loss: 392.54791259765625, Entropy -341.28094482421875, Learning Rate: 0.005\n",
      "Epoch [667/20000], Loss: 432.08123779296875, Entropy -372.82794189453125, Learning Rate: 0.005\n",
      "Epoch [668/20000], Loss: 403.2450866699219, Entropy -365.2178955078125, Learning Rate: 0.005\n",
      "Epoch [669/20000], Loss: 413.3759460449219, Entropy -349.986083984375, Learning Rate: 0.005\n",
      "Epoch [670/20000], Loss: 407.77392578125, Entropy -341.6788330078125, Learning Rate: 0.005\n",
      "Epoch [671/20000], Loss: 415.33575439453125, Entropy -348.3486633300781, Learning Rate: 0.005\n",
      "Epoch [672/20000], Loss: 423.2434387207031, Entropy -338.82818603515625, Learning Rate: 0.005\n",
      "Epoch [673/20000], Loss: 390.24713134765625, Entropy -339.53350830078125, Learning Rate: 0.005\n",
      "Epoch [674/20000], Loss: 412.271240234375, Entropy -337.94537353515625, Learning Rate: 0.005\n",
      "Epoch [675/20000], Loss: 412.7761535644531, Entropy -352.1038818359375, Learning Rate: 0.005\n",
      "Epoch [676/20000], Loss: 407.0805969238281, Entropy -352.74072265625, Learning Rate: 0.005\n",
      "Epoch [677/20000], Loss: 407.52734375, Entropy -352.1647033691406, Learning Rate: 0.005\n",
      "Epoch [678/20000], Loss: 418.358154296875, Entropy -347.6213684082031, Learning Rate: 0.005\n",
      "Epoch [679/20000], Loss: 397.6527099609375, Entropy -351.3238830566406, Learning Rate: 0.005\n",
      "Epoch [680/20000], Loss: 403.6219482421875, Entropy -345.89935302734375, Learning Rate: 0.005\n",
      "Epoch [681/20000], Loss: 405.0989990234375, Entropy -339.8388977050781, Learning Rate: 0.005\n",
      "Epoch [682/20000], Loss: 406.716796875, Entropy -334.6650695800781, Learning Rate: 0.005\n",
      "Epoch [683/20000], Loss: 412.76318359375, Entropy -334.8421936035156, Learning Rate: 0.005\n",
      "Epoch [684/20000], Loss: 386.127197265625, Entropy -341.5185241699219, Learning Rate: 0.005\n",
      "Epoch [685/20000], Loss: 433.8528137207031, Entropy -369.4170227050781, Learning Rate: 0.005\n",
      "Epoch [686/20000], Loss: 400.3259582519531, Entropy -348.447265625, Learning Rate: 0.005\n",
      "Epoch [687/20000], Loss: 417.77972412109375, Entropy -355.8695068359375, Learning Rate: 0.005\n",
      "Epoch [688/20000], Loss: 411.44818115234375, Entropy -352.75537109375, Learning Rate: 0.005\n",
      "Epoch [689/20000], Loss: 389.9249267578125, Entropy -336.1084899902344, Learning Rate: 0.005\n",
      "Epoch [690/20000], Loss: 404.1808166503906, Entropy -347.1889953613281, Learning Rate: 0.005\n",
      "Epoch [691/20000], Loss: 410.48651123046875, Entropy -349.4676513671875, Learning Rate: 0.005\n",
      "Epoch [692/20000], Loss: 404.43121337890625, Entropy -354.4273986816406, Learning Rate: 0.005\n",
      "Epoch [693/20000], Loss: 385.59527587890625, Entropy -335.6376037597656, Learning Rate: 0.005\n",
      "Epoch [694/20000], Loss: 417.3658447265625, Entropy -347.115966796875, Learning Rate: 0.005\n",
      "Epoch [695/20000], Loss: 402.68341064453125, Entropy -343.46954345703125, Learning Rate: 0.005\n",
      "Epoch [696/20000], Loss: 414.60491943359375, Entropy -360.93817138671875, Learning Rate: 0.005\n",
      "Epoch [697/20000], Loss: 419.96337890625, Entropy -362.9229431152344, Learning Rate: 0.005\n",
      "Epoch [698/20000], Loss: 399.8365173339844, Entropy -345.35076904296875, Learning Rate: 0.005\n",
      "Epoch [699/20000], Loss: 391.7354431152344, Entropy -347.814208984375, Learning Rate: 0.005\n",
      "Epoch [700/20000], Loss: 417.9010314941406, Entropy -356.3363952636719, Learning Rate: 0.005\n",
      "Epoch [701/20000], Loss: 408.8468933105469, Entropy -360.8098449707031, Learning Rate: 0.005\n",
      "Epoch [702/20000], Loss: 405.8365478515625, Entropy -348.6360778808594, Learning Rate: 0.005\n",
      "Epoch [703/20000], Loss: 411.5662841796875, Entropy -372.0286560058594, Learning Rate: 0.005\n",
      "Epoch [704/20000], Loss: 427.6098327636719, Entropy -348.4861755371094, Learning Rate: 0.005\n",
      "Epoch [705/20000], Loss: 403.4519348144531, Entropy -344.151123046875, Learning Rate: 0.005\n",
      "Epoch [706/20000], Loss: 408.29315185546875, Entropy -358.4666748046875, Learning Rate: 0.005\n",
      "Epoch [707/20000], Loss: 390.47235107421875, Entropy -349.98187255859375, Learning Rate: 0.005\n",
      "Epoch [708/20000], Loss: 411.9867858886719, Entropy -358.8133544921875, Learning Rate: 0.005\n",
      "Epoch [709/20000], Loss: 395.5165710449219, Entropy -345.029541015625, Learning Rate: 0.005\n",
      "Epoch [710/20000], Loss: 394.6105651855469, Entropy -352.1026916503906, Learning Rate: 0.005\n",
      "Epoch [711/20000], Loss: 410.9410400390625, Entropy -356.29876708984375, Learning Rate: 0.005\n",
      "Epoch [712/20000], Loss: 398.16131591796875, Entropy -359.94329833984375, Learning Rate: 0.005\n",
      "Epoch [713/20000], Loss: 381.5195617675781, Entropy -339.19549560546875, Learning Rate: 0.005\n",
      "Epoch [714/20000], Loss: 399.2574462890625, Entropy -330.69427490234375, Learning Rate: 0.005\n",
      "Epoch [715/20000], Loss: 389.887939453125, Entropy -338.71734619140625, Learning Rate: 0.005\n",
      "Epoch [716/20000], Loss: 396.27081298828125, Entropy -339.7437438964844, Learning Rate: 0.005\n",
      "Epoch [717/20000], Loss: 405.95721435546875, Entropy -353.36285400390625, Learning Rate: 0.005\n",
      "Epoch [718/20000], Loss: 398.3026428222656, Entropy -348.9608154296875, Learning Rate: 0.005\n",
      "Epoch [719/20000], Loss: 386.38824462890625, Entropy -329.4999694824219, Learning Rate: 0.005\n",
      "Epoch [720/20000], Loss: 392.58111572265625, Entropy -348.8649597167969, Learning Rate: 0.005\n",
      "Epoch [721/20000], Loss: 402.6898498535156, Entropy -351.95233154296875, Learning Rate: 0.005\n",
      "Epoch [722/20000], Loss: 388.41595458984375, Entropy -341.6219482421875, Learning Rate: 0.005\n",
      "Epoch [723/20000], Loss: 400.3392639160156, Entropy -354.2277526855469, Learning Rate: 0.005\n",
      "Epoch [724/20000], Loss: 387.57464599609375, Entropy -347.9870300292969, Learning Rate: 0.005\n",
      "Epoch [725/20000], Loss: 401.3558349609375, Entropy -339.1217346191406, Learning Rate: 0.005\n",
      "Epoch [726/20000], Loss: 407.7615661621094, Entropy -353.0942077636719, Learning Rate: 0.005\n",
      "Epoch [727/20000], Loss: 396.4708251953125, Entropy -344.971435546875, Learning Rate: 0.005\n",
      "Epoch [728/20000], Loss: 381.66986083984375, Entropy -326.1656494140625, Learning Rate: 0.005\n",
      "Epoch [729/20000], Loss: 378.60125732421875, Entropy -337.3827819824219, Learning Rate: 0.005\n",
      "Epoch [730/20000], Loss: 386.8662109375, Entropy -341.10614013671875, Learning Rate: 0.005\n",
      "Epoch [731/20000], Loss: 403.0658264160156, Entropy -351.03656005859375, Learning Rate: 0.005\n",
      "Epoch [732/20000], Loss: 385.54803466796875, Entropy -352.63153076171875, Learning Rate: 0.005\n",
      "Epoch [733/20000], Loss: 413.65704345703125, Entropy -360.893798828125, Learning Rate: 0.005\n",
      "Epoch [734/20000], Loss: 383.8359375, Entropy -336.69091796875, Learning Rate: 0.005\n",
      "Epoch [735/20000], Loss: 391.1939697265625, Entropy -342.2036437988281, Learning Rate: 0.005\n",
      "Epoch [736/20000], Loss: 406.0086669921875, Entropy -346.489013671875, Learning Rate: 0.005\n",
      "Epoch [737/20000], Loss: 399.51666259765625, Entropy -352.74139404296875, Learning Rate: 0.005\n",
      "Epoch [738/20000], Loss: 388.34002685546875, Entropy -339.22705078125, Learning Rate: 0.005\n",
      "Epoch [739/20000], Loss: 403.9349060058594, Entropy -360.4111328125, Learning Rate: 0.005\n",
      "Epoch [740/20000], Loss: 418.31109619140625, Entropy -343.7151794433594, Learning Rate: 0.005\n",
      "Epoch [741/20000], Loss: 386.199951171875, Entropy -348.3325500488281, Learning Rate: 0.005\n",
      "Epoch [742/20000], Loss: 432.4352111816406, Entropy -356.90618896484375, Learning Rate: 0.005\n",
      "Epoch [743/20000], Loss: 411.18487548828125, Entropy -336.1973571777344, Learning Rate: 0.005\n",
      "Epoch [744/20000], Loss: 398.74200439453125, Entropy -342.1109619140625, Learning Rate: 0.005\n",
      "Epoch [745/20000], Loss: 396.9776306152344, Entropy -352.60247802734375, Learning Rate: 0.005\n",
      "Epoch [746/20000], Loss: 386.57000732421875, Entropy -333.9498291015625, Learning Rate: 0.005\n",
      "Epoch [747/20000], Loss: 418.49755859375, Entropy -350.46630859375, Learning Rate: 0.005\n",
      "Epoch [748/20000], Loss: 424.28857421875, Entropy -363.70440673828125, Learning Rate: 0.005\n",
      "Epoch [749/20000], Loss: 403.6701965332031, Entropy -365.37017822265625, Learning Rate: 0.005\n",
      "Epoch [750/20000], Loss: 398.5765380859375, Entropy -336.6305236816406, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [751/20000], Loss: 406.0428771972656, Entropy -341.8398742675781, Learning Rate: 0.005\n",
      "Epoch [752/20000], Loss: 412.35943603515625, Entropy -353.6228942871094, Learning Rate: 0.005\n",
      "Epoch [753/20000], Loss: 418.724609375, Entropy -349.50946044921875, Learning Rate: 0.005\n",
      "Epoch [754/20000], Loss: 408.0875549316406, Entropy -342.5723571777344, Learning Rate: 0.005\n",
      "Epoch [755/20000], Loss: 392.07012939453125, Entropy -338.856689453125, Learning Rate: 0.005\n",
      "Epoch [756/20000], Loss: 398.1558837890625, Entropy -340.8504638671875, Learning Rate: 0.005\n",
      "Epoch [757/20000], Loss: 377.871337890625, Entropy -327.73291015625, Learning Rate: 0.005\n",
      "Epoch [758/20000], Loss: 404.40765380859375, Entropy -360.11602783203125, Learning Rate: 0.005\n",
      "Epoch [759/20000], Loss: 384.239013671875, Entropy -327.19146728515625, Learning Rate: 0.005\n",
      "Epoch [760/20000], Loss: 389.8533935546875, Entropy -341.53204345703125, Learning Rate: 0.005\n",
      "Epoch [761/20000], Loss: 396.7643737792969, Entropy -348.0161437988281, Learning Rate: 0.005\n",
      "Epoch [762/20000], Loss: 411.8263244628906, Entropy -350.42352294921875, Learning Rate: 0.005\n",
      "Epoch [763/20000], Loss: 398.14764404296875, Entropy -346.0601806640625, Learning Rate: 0.005\n",
      "Epoch [764/20000], Loss: 406.5581359863281, Entropy -352.0611267089844, Learning Rate: 0.005\n",
      "Epoch [765/20000], Loss: 395.85308837890625, Entropy -343.016845703125, Learning Rate: 0.005\n",
      "Epoch [766/20000], Loss: 384.1212463378906, Entropy -332.2265319824219, Learning Rate: 0.005\n",
      "Epoch [767/20000], Loss: 403.1495361328125, Entropy -338.82745361328125, Learning Rate: 0.005\n",
      "Epoch [768/20000], Loss: 394.3301696777344, Entropy -349.716064453125, Learning Rate: 0.005\n",
      "Epoch [769/20000], Loss: 412.9386291503906, Entropy -359.46087646484375, Learning Rate: 0.005\n",
      "Epoch [770/20000], Loss: 382.09100341796875, Entropy -325.6759338378906, Learning Rate: 0.005\n",
      "Epoch [771/20000], Loss: 384.3128662109375, Entropy -330.59332275390625, Learning Rate: 0.005\n",
      "Epoch [772/20000], Loss: 390.260009765625, Entropy -343.74627685546875, Learning Rate: 0.005\n",
      "Epoch [773/20000], Loss: 402.1889343261719, Entropy -338.14459228515625, Learning Rate: 0.005\n",
      "Epoch [774/20000], Loss: 385.6282958984375, Entropy -344.3910827636719, Learning Rate: 0.005\n",
      "Epoch [775/20000], Loss: 390.2998352050781, Entropy -328.61993408203125, Learning Rate: 0.005\n",
      "Epoch [776/20000], Loss: 384.2676696777344, Entropy -333.9610595703125, Learning Rate: 0.005\n",
      "Epoch [777/20000], Loss: 408.5096130371094, Entropy -339.7265930175781, Learning Rate: 0.005\n",
      "Epoch [778/20000], Loss: 424.9022521972656, Entropy -351.76239013671875, Learning Rate: 0.005\n",
      "Epoch [779/20000], Loss: 391.40362548828125, Entropy -340.1206970214844, Learning Rate: 0.005\n",
      "Epoch [780/20000], Loss: 401.54571533203125, Entropy -342.6932678222656, Learning Rate: 0.005\n",
      "Epoch [781/20000], Loss: 384.5261535644531, Entropy -342.0938720703125, Learning Rate: 0.005\n",
      "Epoch [782/20000], Loss: 405.1927185058594, Entropy -360.2530517578125, Learning Rate: 0.005\n",
      "Epoch [783/20000], Loss: 410.148681640625, Entropy -344.2140808105469, Learning Rate: 0.005\n",
      "Epoch [784/20000], Loss: 382.8934020996094, Entropy -336.2640380859375, Learning Rate: 0.005\n",
      "Epoch [785/20000], Loss: 387.2147216796875, Entropy -352.4500732421875, Learning Rate: 0.005\n",
      "Epoch [786/20000], Loss: 376.6978759765625, Entropy -334.9576721191406, Learning Rate: 0.005\n",
      "Epoch [787/20000], Loss: 396.2592468261719, Entropy -344.3634338378906, Learning Rate: 0.005\n",
      "Epoch [788/20000], Loss: 398.66729736328125, Entropy -338.1281433105469, Learning Rate: 0.005\n",
      "Epoch [789/20000], Loss: 388.3343200683594, Entropy -348.0980529785156, Learning Rate: 0.005\n",
      "Epoch [790/20000], Loss: 397.4945068359375, Entropy -357.5579528808594, Learning Rate: 0.005\n",
      "Epoch [791/20000], Loss: 389.8204040527344, Entropy -356.6593017578125, Learning Rate: 0.005\n",
      "Epoch [792/20000], Loss: 386.641845703125, Entropy -336.6462707519531, Learning Rate: 0.005\n",
      "Epoch [793/20000], Loss: 406.8170166015625, Entropy -339.7257995605469, Learning Rate: 0.005\n",
      "Epoch [794/20000], Loss: 387.34893798828125, Entropy -329.5209045410156, Learning Rate: 0.005\n",
      "Epoch [795/20000], Loss: 388.9899597167969, Entropy -350.9715881347656, Learning Rate: 0.005\n",
      "Epoch [796/20000], Loss: 383.5567321777344, Entropy -321.3995056152344, Learning Rate: 0.005\n",
      "Epoch [797/20000], Loss: 377.1316833496094, Entropy -337.903076171875, Learning Rate: 0.005\n",
      "Epoch [798/20000], Loss: 391.0287780761719, Entropy -337.2674255371094, Learning Rate: 0.005\n",
      "Epoch [799/20000], Loss: 389.3232421875, Entropy -345.2770080566406, Learning Rate: 0.005\n",
      "Epoch [800/20000], Loss: 382.49725341796875, Entropy -346.1407470703125, Learning Rate: 0.005\n",
      "Epoch [801/20000], Loss: 391.62872314453125, Entropy -337.9383239746094, Learning Rate: 0.005\n",
      "Epoch [802/20000], Loss: 409.94146728515625, Entropy -346.7256774902344, Learning Rate: 0.005\n",
      "Epoch [803/20000], Loss: 420.5021667480469, Entropy -359.40045166015625, Learning Rate: 0.005\n",
      "Epoch [804/20000], Loss: 407.5612487792969, Entropy -345.77191162109375, Learning Rate: 0.005\n",
      "Epoch [805/20000], Loss: 405.03826904296875, Entropy -358.3267517089844, Learning Rate: 0.005\n",
      "Epoch [806/20000], Loss: 395.51507568359375, Entropy -337.7062072753906, Learning Rate: 0.005\n",
      "Epoch [807/20000], Loss: 384.0611877441406, Entropy -344.2525329589844, Learning Rate: 0.005\n",
      "Epoch [808/20000], Loss: 398.24530029296875, Entropy -335.7469482421875, Learning Rate: 0.005\n",
      "Epoch [809/20000], Loss: 396.0010986328125, Entropy -343.365966796875, Learning Rate: 0.005\n",
      "Epoch [810/20000], Loss: 403.91607666015625, Entropy -343.7259826660156, Learning Rate: 0.005\n",
      "Epoch [811/20000], Loss: 376.23516845703125, Entropy -324.8381042480469, Learning Rate: 0.005\n",
      "Epoch [812/20000], Loss: 383.4366149902344, Entropy -332.0846252441406, Learning Rate: 0.005\n",
      "Epoch [813/20000], Loss: 397.9338684082031, Entropy -340.4815368652344, Learning Rate: 0.005\n",
      "Epoch [814/20000], Loss: 404.88470458984375, Entropy -352.9467468261719, Learning Rate: 0.005\n",
      "Epoch [815/20000], Loss: 370.5237121582031, Entropy -333.10162353515625, Learning Rate: 0.005\n",
      "Epoch [816/20000], Loss: 391.5386657714844, Entropy -343.2537841796875, Learning Rate: 0.005\n",
      "Epoch [817/20000], Loss: 398.29888916015625, Entropy -332.6839599609375, Learning Rate: 0.005\n",
      "Epoch [818/20000], Loss: 390.15185546875, Entropy -330.5904235839844, Learning Rate: 0.005\n",
      "Epoch [819/20000], Loss: 402.5964050292969, Entropy -352.9020080566406, Learning Rate: 0.005\n",
      "Epoch [820/20000], Loss: 377.85528564453125, Entropy -323.781005859375, Learning Rate: 0.005\n",
      "Epoch [821/20000], Loss: 409.99066162109375, Entropy -349.3578796386719, Learning Rate: 0.005\n",
      "Epoch [822/20000], Loss: 394.5646057128906, Entropy -335.67303466796875, Learning Rate: 0.005\n",
      "Epoch [823/20000], Loss: 399.7887878417969, Entropy -337.99591064453125, Learning Rate: 0.005\n",
      "Epoch [824/20000], Loss: 401.6007995605469, Entropy -323.5523986816406, Learning Rate: 0.005\n",
      "Epoch [825/20000], Loss: 431.9220275878906, Entropy -346.737548828125, Learning Rate: 0.005\n",
      "Epoch [826/20000], Loss: 380.4388427734375, Entropy -334.57220458984375, Learning Rate: 0.005\n",
      "Epoch [827/20000], Loss: 394.625244140625, Entropy -337.9604187011719, Learning Rate: 0.005\n",
      "Epoch [828/20000], Loss: 407.35186767578125, Entropy -354.9916076660156, Learning Rate: 0.005\n",
      "Epoch [829/20000], Loss: 401.00628662109375, Entropy -338.3609924316406, Learning Rate: 0.005\n",
      "Epoch [830/20000], Loss: 423.2890930175781, Entropy -343.75726318359375, Learning Rate: 0.005\n",
      "Epoch [831/20000], Loss: 397.37384033203125, Entropy -340.04852294921875, Learning Rate: 0.005\n",
      "Epoch [832/20000], Loss: 395.1298522949219, Entropy -339.0130615234375, Learning Rate: 0.005\n",
      "Epoch [833/20000], Loss: 398.2174072265625, Entropy -341.0229797363281, Learning Rate: 0.005\n",
      "Epoch [834/20000], Loss: 393.7553405761719, Entropy -331.5843200683594, Learning Rate: 0.005\n",
      "Epoch [835/20000], Loss: 389.0494384765625, Entropy -340.2238464355469, Learning Rate: 0.005\n",
      "Epoch [836/20000], Loss: 393.00689697265625, Entropy -342.2720031738281, Learning Rate: 0.005\n",
      "Epoch [837/20000], Loss: 405.2119445800781, Entropy -346.3695068359375, Learning Rate: 0.005\n",
      "Epoch [838/20000], Loss: 374.62835693359375, Entropy -333.5018005371094, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [839/20000], Loss: 391.1774597167969, Entropy -333.2308044433594, Learning Rate: 0.005\n",
      "Epoch [840/20000], Loss: 379.238525390625, Entropy -341.9611511230469, Learning Rate: 0.005\n",
      "Epoch [841/20000], Loss: 381.8182678222656, Entropy -347.14007568359375, Learning Rate: 0.005\n",
      "Epoch [842/20000], Loss: 415.3355407714844, Entropy -355.66790771484375, Learning Rate: 0.005\n",
      "Epoch [843/20000], Loss: 415.78179931640625, Entropy -350.35137939453125, Learning Rate: 0.005\n",
      "Epoch [844/20000], Loss: 400.64630126953125, Entropy -346.8260192871094, Learning Rate: 0.005\n",
      "Epoch [845/20000], Loss: 392.2890625, Entropy -341.40057373046875, Learning Rate: 0.005\n",
      "Epoch [846/20000], Loss: 400.6083984375, Entropy -342.0027770996094, Learning Rate: 0.005\n",
      "Epoch [847/20000], Loss: 404.47076416015625, Entropy -339.6611022949219, Learning Rate: 0.005\n",
      "Epoch [848/20000], Loss: 397.99615478515625, Entropy -344.7917785644531, Learning Rate: 0.005\n",
      "Epoch [849/20000], Loss: 403.5169372558594, Entropy -349.0501708984375, Learning Rate: 0.005\n",
      "Epoch [850/20000], Loss: 392.31646728515625, Entropy -351.5020446777344, Learning Rate: 0.005\n",
      "Epoch [851/20000], Loss: 426.146240234375, Entropy -351.2354736328125, Learning Rate: 0.005\n",
      "Epoch [852/20000], Loss: 388.93719482421875, Entropy -334.16253662109375, Learning Rate: 0.005\n",
      "Epoch [853/20000], Loss: 383.10589599609375, Entropy -341.26910400390625, Learning Rate: 0.005\n",
      "Epoch [854/20000], Loss: 377.25189208984375, Entropy -319.8811340332031, Learning Rate: 0.005\n",
      "Epoch [855/20000], Loss: 381.2835998535156, Entropy -334.07049560546875, Learning Rate: 0.005\n",
      "Epoch [856/20000], Loss: 388.22296142578125, Entropy -330.6624450683594, Learning Rate: 0.005\n",
      "Epoch [857/20000], Loss: 375.9435729980469, Entropy -336.4577331542969, Learning Rate: 0.005\n",
      "Epoch [858/20000], Loss: 398.73504638671875, Entropy -344.8911437988281, Learning Rate: 0.005\n",
      "Epoch [859/20000], Loss: 392.9450988769531, Entropy -350.05462646484375, Learning Rate: 0.005\n",
      "Epoch [860/20000], Loss: 382.77490234375, Entropy -337.2771911621094, Learning Rate: 0.005\n",
      "Epoch [861/20000], Loss: 405.07281494140625, Entropy -351.56103515625, Learning Rate: 0.005\n",
      "Epoch [862/20000], Loss: 378.46441650390625, Entropy -330.2955627441406, Learning Rate: 0.005\n",
      "Epoch [863/20000], Loss: 370.23748779296875, Entropy -333.9388427734375, Learning Rate: 0.005\n",
      "Epoch [864/20000], Loss: 401.6141662597656, Entropy -355.7251892089844, Learning Rate: 0.005\n",
      "Epoch [865/20000], Loss: 405.47576904296875, Entropy -349.9851989746094, Learning Rate: 0.005\n",
      "Epoch [866/20000], Loss: 383.4141845703125, Entropy -337.6907043457031, Learning Rate: 0.005\n",
      "Epoch [867/20000], Loss: 389.1342468261719, Entropy -338.1622314453125, Learning Rate: 0.005\n",
      "Epoch [868/20000], Loss: 397.857666015625, Entropy -339.3846740722656, Learning Rate: 0.005\n",
      "Epoch [869/20000], Loss: 410.6280822753906, Entropy -358.0953063964844, Learning Rate: 0.005\n",
      "Epoch [870/20000], Loss: 393.3238830566406, Entropy -350.2452697753906, Learning Rate: 0.005\n",
      "Epoch [871/20000], Loss: 400.8930969238281, Entropy -353.63873291015625, Learning Rate: 0.005\n",
      "Epoch [872/20000], Loss: 394.83123779296875, Entropy -335.62139892578125, Learning Rate: 0.005\n",
      "Epoch [873/20000], Loss: 393.1610412597656, Entropy -348.80523681640625, Learning Rate: 0.005\n",
      "Epoch [874/20000], Loss: 381.69305419921875, Entropy -345.2684020996094, Learning Rate: 0.005\n",
      "Epoch [875/20000], Loss: 382.5116271972656, Entropy -343.30413818359375, Learning Rate: 0.005\n",
      "Epoch [876/20000], Loss: 402.501220703125, Entropy -335.32745361328125, Learning Rate: 0.005\n",
      "Epoch [877/20000], Loss: 375.9619445800781, Entropy -324.9651794433594, Learning Rate: 0.005\n",
      "Epoch [878/20000], Loss: 398.6878662109375, Entropy -355.8246765136719, Learning Rate: 0.005\n",
      "Epoch [879/20000], Loss: 368.521484375, Entropy -320.9862365722656, Learning Rate: 0.005\n",
      "Epoch [880/20000], Loss: 378.6651916503906, Entropy -332.8990783691406, Learning Rate: 0.005\n",
      "Epoch [881/20000], Loss: 407.4520263671875, Entropy -344.1822509765625, Learning Rate: 0.005\n",
      "Epoch [882/20000], Loss: 385.58837890625, Entropy -336.66693115234375, Learning Rate: 0.005\n",
      "Epoch [883/20000], Loss: 377.9956359863281, Entropy -336.50067138671875, Learning Rate: 0.005\n",
      "Epoch [884/20000], Loss: 368.2074279785156, Entropy -324.2650451660156, Learning Rate: 0.005\n",
      "Epoch [885/20000], Loss: 372.55023193359375, Entropy -340.6412048339844, Learning Rate: 0.005\n",
      "Epoch [886/20000], Loss: 394.8413391113281, Entropy -342.90185546875, Learning Rate: 0.005\n",
      "Epoch [887/20000], Loss: 372.8583679199219, Entropy -328.172119140625, Learning Rate: 0.005\n",
      "Epoch [888/20000], Loss: 398.2557678222656, Entropy -335.8177490234375, Learning Rate: 0.005\n",
      "Epoch [889/20000], Loss: 398.52783203125, Entropy -340.0898742675781, Learning Rate: 0.005\n",
      "Epoch [890/20000], Loss: 405.0269775390625, Entropy -349.5104064941406, Learning Rate: 0.005\n",
      "Epoch [891/20000], Loss: 367.0232849121094, Entropy -334.8680725097656, Learning Rate: 0.005\n",
      "Epoch [892/20000], Loss: 398.5304870605469, Entropy -342.2519836425781, Learning Rate: 0.005\n",
      "Epoch [893/20000], Loss: 394.2568664550781, Entropy -335.725830078125, Learning Rate: 0.005\n",
      "Epoch [894/20000], Loss: 388.65863037109375, Entropy -343.6949768066406, Learning Rate: 0.005\n",
      "Epoch [895/20000], Loss: 381.1117858886719, Entropy -336.9211120605469, Learning Rate: 0.005\n",
      "Epoch [896/20000], Loss: 382.2772521972656, Entropy -344.9042663574219, Learning Rate: 0.005\n",
      "Epoch [897/20000], Loss: 382.1675720214844, Entropy -327.97955322265625, Learning Rate: 0.005\n",
      "Epoch [898/20000], Loss: 389.0513916015625, Entropy -339.0676574707031, Learning Rate: 0.005\n",
      "Epoch [899/20000], Loss: 394.3900146484375, Entropy -323.14874267578125, Learning Rate: 0.005\n",
      "Epoch [900/20000], Loss: 395.98101806640625, Entropy -356.5758056640625, Learning Rate: 0.005\n",
      "Epoch [901/20000], Loss: 406.65936279296875, Entropy -351.1606140136719, Learning Rate: 0.005\n",
      "Epoch [902/20000], Loss: 393.03955078125, Entropy -348.26385498046875, Learning Rate: 0.005\n",
      "Epoch [903/20000], Loss: 392.35479736328125, Entropy -351.6059265136719, Learning Rate: 0.005\n",
      "Epoch [904/20000], Loss: 386.1655578613281, Entropy -338.1336669921875, Learning Rate: 0.005\n",
      "Epoch [905/20000], Loss: 375.997314453125, Entropy -339.79144287109375, Learning Rate: 0.005\n",
      "Epoch [906/20000], Loss: 381.4635314941406, Entropy -336.3667907714844, Learning Rate: 0.005\n",
      "Epoch [907/20000], Loss: 376.99041748046875, Entropy -328.4588623046875, Learning Rate: 0.005\n",
      "Epoch [908/20000], Loss: 392.50665283203125, Entropy -334.80328369140625, Learning Rate: 0.005\n",
      "Epoch [909/20000], Loss: 401.4371337890625, Entropy -353.51763916015625, Learning Rate: 0.005\n",
      "Epoch [910/20000], Loss: 377.19561767578125, Entropy -328.37188720703125, Learning Rate: 0.005\n",
      "Epoch [911/20000], Loss: 393.5541076660156, Entropy -331.81500244140625, Learning Rate: 0.005\n",
      "Epoch [912/20000], Loss: 405.86810302734375, Entropy -339.903076171875, Learning Rate: 0.005\n",
      "Epoch [913/20000], Loss: 367.1748046875, Entropy -309.9263000488281, Learning Rate: 0.005\n",
      "Epoch [914/20000], Loss: 395.58258056640625, Entropy -356.442626953125, Learning Rate: 0.005\n",
      "Epoch [915/20000], Loss: 398.6993713378906, Entropy -335.60711669921875, Learning Rate: 0.005\n",
      "Epoch [916/20000], Loss: 374.5589904785156, Entropy -332.97686767578125, Learning Rate: 0.005\n",
      "Epoch [917/20000], Loss: 395.96270751953125, Entropy -336.6470642089844, Learning Rate: 0.005\n",
      "Epoch [918/20000], Loss: 388.5967102050781, Entropy -338.15521240234375, Learning Rate: 0.005\n",
      "Epoch [919/20000], Loss: 406.174560546875, Entropy -343.6246032714844, Learning Rate: 0.005\n",
      "Epoch [920/20000], Loss: 400.4910888671875, Entropy -332.19415283203125, Learning Rate: 0.005\n",
      "Epoch [921/20000], Loss: 392.8261413574219, Entropy -348.2525634765625, Learning Rate: 0.005\n",
      "Epoch [922/20000], Loss: 370.61444091796875, Entropy -326.57196044921875, Learning Rate: 0.005\n",
      "Epoch [923/20000], Loss: 385.8939208984375, Entropy -317.38873291015625, Learning Rate: 0.005\n",
      "Epoch [924/20000], Loss: 398.2967224121094, Entropy -334.9747314453125, Learning Rate: 0.005\n",
      "Epoch [925/20000], Loss: 423.234130859375, Entropy -333.8585510253906, Learning Rate: 0.005\n",
      "Epoch [926/20000], Loss: 372.667236328125, Entropy -327.45556640625, Learning Rate: 0.005\n",
      "Epoch [927/20000], Loss: 410.9530334472656, Entropy -344.6055908203125, Learning Rate: 0.005\n",
      "Epoch [928/20000], Loss: 381.3232116699219, Entropy -340.7274475097656, Learning Rate: 0.005\n",
      "Epoch [929/20000], Loss: 384.6325988769531, Entropy -329.5433349609375, Learning Rate: 0.005\n",
      "Epoch [930/20000], Loss: 380.2824401855469, Entropy -328.85552978515625, Learning Rate: 0.005\n",
      "Epoch [931/20000], Loss: 401.34332275390625, Entropy -341.78143310546875, Learning Rate: 0.005\n",
      "Epoch [932/20000], Loss: 381.6921081542969, Entropy -339.955322265625, Learning Rate: 0.005\n",
      "Epoch [933/20000], Loss: 382.2837219238281, Entropy -343.1979064941406, Learning Rate: 0.005\n",
      "Epoch [934/20000], Loss: 412.9630126953125, Entropy -354.4972839355469, Learning Rate: 0.005\n",
      "Epoch [935/20000], Loss: 375.88031005859375, Entropy -339.9105224609375, Learning Rate: 0.005\n",
      "Epoch [936/20000], Loss: 399.69036865234375, Entropy -347.1398620605469, Learning Rate: 0.005\n",
      "Epoch [937/20000], Loss: 426.7682189941406, Entropy -342.40655517578125, Learning Rate: 0.005\n",
      "Epoch [938/20000], Loss: 388.1544494628906, Entropy -328.32781982421875, Learning Rate: 0.005\n",
      "Epoch [939/20000], Loss: 385.6047058105469, Entropy -322.7672119140625, Learning Rate: 0.005\n",
      "Epoch [940/20000], Loss: 386.24700927734375, Entropy -338.8643493652344, Learning Rate: 0.005\n",
      "Epoch [941/20000], Loss: 394.75372314453125, Entropy -339.0009460449219, Learning Rate: 0.005\n",
      "Epoch [942/20000], Loss: 371.9643859863281, Entropy -327.7099914550781, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [943/20000], Loss: 408.25299072265625, Entropy -339.0697937011719, Learning Rate: 0.005\n",
      "Epoch [944/20000], Loss: 361.46185302734375, Entropy -324.569091796875, Learning Rate: 0.005\n",
      "Epoch [945/20000], Loss: 375.86004638671875, Entropy -332.77862548828125, Learning Rate: 0.005\n",
      "Epoch [946/20000], Loss: 433.0777587890625, Entropy -342.22479248046875, Learning Rate: 0.005\n",
      "Epoch [947/20000], Loss: 381.5659484863281, Entropy -328.8453063964844, Learning Rate: 0.005\n",
      "Epoch [948/20000], Loss: 407.886474609375, Entropy -337.0423278808594, Learning Rate: 0.005\n",
      "Epoch [949/20000], Loss: 378.2451171875, Entropy -328.0675354003906, Learning Rate: 0.005\n",
      "Epoch [950/20000], Loss: 364.0341491699219, Entropy -325.9725036621094, Learning Rate: 0.005\n",
      "Epoch [951/20000], Loss: 380.521484375, Entropy -337.1693420410156, Learning Rate: 0.005\n",
      "Epoch [952/20000], Loss: 385.2992858886719, Entropy -321.0751953125, Learning Rate: 0.005\n",
      "Epoch [953/20000], Loss: 377.7171630859375, Entropy -326.20281982421875, Learning Rate: 0.005\n",
      "Epoch [954/20000], Loss: 395.4000244140625, Entropy -333.43621826171875, Learning Rate: 0.005\n",
      "Epoch [955/20000], Loss: 380.62982177734375, Entropy -327.63763427734375, Learning Rate: 0.005\n",
      "Epoch [956/20000], Loss: 383.98291015625, Entropy -340.2727355957031, Learning Rate: 0.005\n",
      "Epoch [957/20000], Loss: 368.60302734375, Entropy -335.24114990234375, Learning Rate: 0.005\n",
      "Epoch [958/20000], Loss: 388.14288330078125, Entropy -347.76898193359375, Learning Rate: 0.005\n",
      "Epoch [959/20000], Loss: 382.1264953613281, Entropy -330.81866455078125, Learning Rate: 0.005\n",
      "Epoch [960/20000], Loss: 376.1126403808594, Entropy -339.5981140136719, Learning Rate: 0.005\n",
      "Epoch [961/20000], Loss: 380.2342834472656, Entropy -346.8331604003906, Learning Rate: 0.005\n",
      "Epoch [962/20000], Loss: 390.21795654296875, Entropy -333.91033935546875, Learning Rate: 0.005\n",
      "Epoch [963/20000], Loss: 378.66748046875, Entropy -343.0809326171875, Learning Rate: 0.005\n",
      "Epoch [964/20000], Loss: 381.14093017578125, Entropy -342.3180236816406, Learning Rate: 0.005\n",
      "Epoch [965/20000], Loss: 374.9840087890625, Entropy -336.5756530761719, Learning Rate: 0.005\n",
      "Epoch [966/20000], Loss: 381.0209045410156, Entropy -339.2068786621094, Learning Rate: 0.005\n",
      "Epoch [967/20000], Loss: 390.28155517578125, Entropy -315.5152893066406, Learning Rate: 0.005\n",
      "Epoch [968/20000], Loss: 382.75518798828125, Entropy -327.41241455078125, Learning Rate: 0.005\n",
      "Epoch [969/20000], Loss: 381.5695495605469, Entropy -340.9615783691406, Learning Rate: 0.005\n",
      "Epoch [970/20000], Loss: 377.4912109375, Entropy -326.5419921875, Learning Rate: 0.005\n",
      "Epoch [971/20000], Loss: 384.3641357421875, Entropy -332.7556457519531, Learning Rate: 0.005\n",
      "Epoch [972/20000], Loss: 372.86346435546875, Entropy -337.2254333496094, Learning Rate: 0.005\n",
      "Epoch [973/20000], Loss: 422.5329284667969, Entropy -354.412109375, Learning Rate: 0.005\n",
      "Epoch [974/20000], Loss: 401.4605407714844, Entropy -350.9180603027344, Learning Rate: 0.005\n",
      "Epoch [975/20000], Loss: 403.1421203613281, Entropy -331.90887451171875, Learning Rate: 0.005\n",
      "Epoch [976/20000], Loss: 401.216064453125, Entropy -352.68621826171875, Learning Rate: 0.005\n",
      "Epoch [977/20000], Loss: 393.0709533691406, Entropy -338.91070556640625, Learning Rate: 0.005\n",
      "Epoch [978/20000], Loss: 392.06317138671875, Entropy -344.3323974609375, Learning Rate: 0.005\n",
      "Epoch [979/20000], Loss: 416.70245361328125, Entropy -359.2899169921875, Learning Rate: 0.005\n",
      "Epoch [980/20000], Loss: 396.5814514160156, Entropy -349.86822509765625, Learning Rate: 0.005\n",
      "Epoch [981/20000], Loss: 396.19842529296875, Entropy -331.17681884765625, Learning Rate: 0.005\n",
      "Epoch [982/20000], Loss: 417.2180480957031, Entropy -345.43096923828125, Learning Rate: 0.005\n",
      "Epoch [983/20000], Loss: 393.1293029785156, Entropy -330.9507751464844, Learning Rate: 0.005\n",
      "Epoch [984/20000], Loss: 409.1556396484375, Entropy -338.14581298828125, Learning Rate: 0.005\n",
      "Epoch [985/20000], Loss: 401.3141784667969, Entropy -348.77105712890625, Learning Rate: 0.005\n",
      "Epoch [986/20000], Loss: 385.5706481933594, Entropy -336.0338134765625, Learning Rate: 0.005\n",
      "Epoch [987/20000], Loss: 396.7731018066406, Entropy -330.46209716796875, Learning Rate: 0.005\n",
      "Epoch [988/20000], Loss: 413.09100341796875, Entropy -351.42523193359375, Learning Rate: 0.005\n",
      "Epoch [989/20000], Loss: 378.45037841796875, Entropy -327.9434814453125, Learning Rate: 0.005\n",
      "Epoch [990/20000], Loss: 387.95513916015625, Entropy -343.10791015625, Learning Rate: 0.005\n",
      "Epoch [991/20000], Loss: 388.1521911621094, Entropy -325.9927673339844, Learning Rate: 0.005\n",
      "Epoch [992/20000], Loss: 395.1585388183594, Entropy -348.1920166015625, Learning Rate: 0.005\n",
      "Epoch [993/20000], Loss: 382.74566650390625, Entropy -338.5113830566406, Learning Rate: 0.005\n",
      "Epoch [994/20000], Loss: 414.121337890625, Entropy -355.25274658203125, Learning Rate: 0.005\n",
      "Epoch [995/20000], Loss: 361.34930419921875, Entropy -317.7843933105469, Learning Rate: 0.005\n",
      "Epoch [996/20000], Loss: 379.9034118652344, Entropy -325.1631774902344, Learning Rate: 0.005\n",
      "Epoch [997/20000], Loss: 431.3730773925781, Entropy -332.02294921875, Learning Rate: 0.005\n",
      "Epoch [998/20000], Loss: 390.2603454589844, Entropy -344.3845520019531, Learning Rate: 0.005\n",
      "Epoch [999/20000], Loss: 411.894287109375, Entropy -348.1490783691406, Learning Rate: 0.005\n",
      "Epoch [1000/20000], Loss: 392.19061279296875, Entropy -319.6424560546875, Learning Rate: 0.005\n",
      "Epoch [1001/20000], Loss: 395.70806884765625, Entropy -316.49517822265625, Learning Rate: 0.005\n",
      "Epoch [1002/20000], Loss: 390.32525634765625, Entropy -329.8885803222656, Learning Rate: 0.005\n",
      "Epoch [1003/20000], Loss: 378.0201416015625, Entropy -314.54608154296875, Learning Rate: 0.005\n",
      "Epoch [1004/20000], Loss: 377.4241638183594, Entropy -324.80224609375, Learning Rate: 0.005\n",
      "Epoch [1005/20000], Loss: 417.4815979003906, Entropy -320.6195068359375, Learning Rate: 0.005\n",
      "Epoch [1006/20000], Loss: 372.72259521484375, Entropy -335.0964660644531, Learning Rate: 0.005\n",
      "Epoch [1007/20000], Loss: 392.615478515625, Entropy -336.66802978515625, Learning Rate: 0.005\n",
      "Epoch [1008/20000], Loss: 385.44708251953125, Entropy -324.6101989746094, Learning Rate: 0.005\n",
      "Epoch [1009/20000], Loss: 367.1378479003906, Entropy -327.58941650390625, Learning Rate: 0.005\n",
      "Epoch [1010/20000], Loss: 382.25537109375, Entropy -335.9320373535156, Learning Rate: 0.005\n",
      "Epoch [1011/20000], Loss: 377.3580322265625, Entropy -330.3154296875, Learning Rate: 0.005\n",
      "Epoch [1012/20000], Loss: 394.29559326171875, Entropy -325.2634582519531, Learning Rate: 0.005\n",
      "Epoch [1013/20000], Loss: 386.78472900390625, Entropy -338.9949645996094, Learning Rate: 0.005\n",
      "Epoch [1014/20000], Loss: 396.1760559082031, Entropy -328.9319152832031, Learning Rate: 0.005\n",
      "Epoch [1015/20000], Loss: 378.1655578613281, Entropy -327.8236083984375, Learning Rate: 0.005\n",
      "Epoch [1016/20000], Loss: 395.6468200683594, Entropy -324.9757995605469, Learning Rate: 0.005\n",
      "Epoch [1017/20000], Loss: 379.2530517578125, Entropy -322.3954772949219, Learning Rate: 0.005\n",
      "Epoch [1018/20000], Loss: 384.2718811035156, Entropy -328.3034973144531, Learning Rate: 0.005\n",
      "Epoch [1019/20000], Loss: 404.834716796875, Entropy -337.20831298828125, Learning Rate: 0.005\n",
      "Epoch [1020/20000], Loss: 367.87445068359375, Entropy -326.67779541015625, Learning Rate: 0.005\n",
      "Epoch [1021/20000], Loss: 410.63214111328125, Entropy -349.361083984375, Learning Rate: 0.005\n",
      "Epoch [1022/20000], Loss: 403.18731689453125, Entropy -329.7063903808594, Learning Rate: 0.005\n",
      "Epoch [1023/20000], Loss: 387.910888671875, Entropy -339.4814758300781, Learning Rate: 0.005\n",
      "Epoch [1024/20000], Loss: 383.9842834472656, Entropy -335.8656921386719, Learning Rate: 0.005\n",
      "Epoch [1025/20000], Loss: 413.3728942871094, Entropy -324.4363708496094, Learning Rate: 0.005\n",
      "Epoch [1026/20000], Loss: 392.4337158203125, Entropy -335.5754699707031, Learning Rate: 0.005\n",
      "Epoch [1027/20000], Loss: 389.93927001953125, Entropy -324.96954345703125, Learning Rate: 0.005\n",
      "Epoch [1028/20000], Loss: 410.06329345703125, Entropy -334.80487060546875, Learning Rate: 0.005\n",
      "Epoch [1029/20000], Loss: 372.64776611328125, Entropy -325.3851013183594, Learning Rate: 0.005\n",
      "Epoch [1030/20000], Loss: 369.3165283203125, Entropy -331.4305725097656, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1031/20000], Loss: 367.3968811035156, Entropy -317.4471130371094, Learning Rate: 0.005\n",
      "Epoch [1032/20000], Loss: 413.7561340332031, Entropy -353.2386169433594, Learning Rate: 0.005\n",
      "Epoch [1033/20000], Loss: 340.60003662109375, Entropy -314.04449462890625, Learning Rate: 0.005\n",
      "Epoch [1034/20000], Loss: 374.19500732421875, Entropy -338.7429504394531, Learning Rate: 0.005\n",
      "Epoch [1035/20000], Loss: 378.66644287109375, Entropy -351.2445068359375, Learning Rate: 0.005\n",
      "Epoch [1036/20000], Loss: 364.5469970703125, Entropy -324.9622497558594, Learning Rate: 0.005\n",
      "Epoch [1037/20000], Loss: 371.93170166015625, Entropy -337.7580261230469, Learning Rate: 0.005\n",
      "Epoch [1038/20000], Loss: 376.78155517578125, Entropy -341.53656005859375, Learning Rate: 0.005\n",
      "Epoch [1039/20000], Loss: 375.93499755859375, Entropy -334.4075927734375, Learning Rate: 0.005\n",
      "Epoch [1040/20000], Loss: 388.87451171875, Entropy -351.7333068847656, Learning Rate: 0.005\n",
      "Epoch [1041/20000], Loss: 380.8432922363281, Entropy -336.3349914550781, Learning Rate: 0.005\n",
      "Epoch [1042/20000], Loss: 365.9927978515625, Entropy -322.8503723144531, Learning Rate: 0.005\n",
      "Epoch [1043/20000], Loss: 373.3778076171875, Entropy -324.0058898925781, Learning Rate: 0.005\n",
      "Epoch [1044/20000], Loss: 396.3217468261719, Entropy -340.54595947265625, Learning Rate: 0.005\n",
      "Epoch [1045/20000], Loss: 370.2613525390625, Entropy -329.8504638671875, Learning Rate: 0.005\n",
      "Epoch [1046/20000], Loss: 384.1448974609375, Entropy -331.9690246582031, Learning Rate: 0.005\n",
      "Epoch [1047/20000], Loss: 387.1826171875, Entropy -340.71942138671875, Learning Rate: 0.005\n",
      "Epoch [1048/20000], Loss: 396.46142578125, Entropy -348.91973876953125, Learning Rate: 0.005\n",
      "Epoch [1049/20000], Loss: 374.49432373046875, Entropy -332.0877685546875, Learning Rate: 0.005\n",
      "Epoch [1050/20000], Loss: 389.19622802734375, Entropy -333.0955810546875, Learning Rate: 0.005\n",
      "Epoch [1051/20000], Loss: 357.6352844238281, Entropy -324.4094543457031, Learning Rate: 0.005\n",
      "Epoch [1052/20000], Loss: 385.78729248046875, Entropy -335.4593811035156, Learning Rate: 0.005\n",
      "Epoch [1053/20000], Loss: 373.4308166503906, Entropy -333.5107116699219, Learning Rate: 0.005\n",
      "Epoch [1054/20000], Loss: 376.7440185546875, Entropy -318.9234924316406, Learning Rate: 0.005\n",
      "Epoch [1055/20000], Loss: 371.5065002441406, Entropy -318.7535705566406, Learning Rate: 0.005\n",
      "Epoch [1056/20000], Loss: 367.14501953125, Entropy -328.91192626953125, Learning Rate: 0.005\n",
      "Epoch [1057/20000], Loss: 376.92901611328125, Entropy -344.2138977050781, Learning Rate: 0.005\n",
      "Epoch [1058/20000], Loss: 403.0368957519531, Entropy -350.8435974121094, Learning Rate: 0.005\n",
      "Epoch [1059/20000], Loss: 376.11871337890625, Entropy -326.0633239746094, Learning Rate: 0.005\n",
      "Epoch [1060/20000], Loss: 375.51416015625, Entropy -333.4558410644531, Learning Rate: 0.005\n",
      "Epoch [1061/20000], Loss: 366.2074890136719, Entropy -319.2879333496094, Learning Rate: 0.005\n",
      "Epoch [1062/20000], Loss: 367.07568359375, Entropy -314.33685302734375, Learning Rate: 0.005\n",
      "Epoch [1063/20000], Loss: 377.87548828125, Entropy -327.0185546875, Learning Rate: 0.005\n",
      "Epoch [1064/20000], Loss: 386.64892578125, Entropy -346.39727783203125, Learning Rate: 0.005\n",
      "Epoch [1065/20000], Loss: 360.00396728515625, Entropy -323.7783203125, Learning Rate: 0.005\n",
      "Epoch [1066/20000], Loss: 385.7002868652344, Entropy -352.6021728515625, Learning Rate: 0.005\n",
      "Epoch [1067/20000], Loss: 387.2713623046875, Entropy -334.6525573730469, Learning Rate: 0.005\n",
      "Epoch [1068/20000], Loss: 388.7409362792969, Entropy -327.44366455078125, Learning Rate: 0.005\n",
      "Epoch [1069/20000], Loss: 359.884765625, Entropy -329.1393127441406, Learning Rate: 0.005\n",
      "Epoch [1070/20000], Loss: 396.1165771484375, Entropy -327.7652282714844, Learning Rate: 0.005\n",
      "Epoch [1071/20000], Loss: 364.8995361328125, Entropy -328.72528076171875, Learning Rate: 0.005\n",
      "Epoch [1072/20000], Loss: 385.4234313964844, Entropy -318.03179931640625, Learning Rate: 0.005\n",
      "Epoch [1073/20000], Loss: 370.4232482910156, Entropy -327.0886535644531, Learning Rate: 0.005\n",
      "Epoch [1074/20000], Loss: 365.7923278808594, Entropy -317.8746643066406, Learning Rate: 0.005\n",
      "Epoch [1075/20000], Loss: 368.264892578125, Entropy -336.14434814453125, Learning Rate: 0.005\n",
      "Epoch [1076/20000], Loss: 378.16864013671875, Entropy -336.6319885253906, Learning Rate: 0.005\n",
      "Epoch [1077/20000], Loss: 365.03717041015625, Entropy -333.28509521484375, Learning Rate: 0.005\n",
      "Epoch [1078/20000], Loss: 363.26947021484375, Entropy -321.8789367675781, Learning Rate: 0.005\n",
      "Epoch [1079/20000], Loss: 372.705322265625, Entropy -337.39263916015625, Learning Rate: 0.005\n",
      "Epoch [1080/20000], Loss: 369.3468017578125, Entropy -336.72418212890625, Learning Rate: 0.005\n",
      "Epoch [1081/20000], Loss: 379.27239990234375, Entropy -334.48486328125, Learning Rate: 0.005\n",
      "Epoch [1082/20000], Loss: 375.5875549316406, Entropy -339.219482421875, Learning Rate: 0.005\n",
      "Epoch [1083/20000], Loss: 358.0658264160156, Entropy -321.3761901855469, Learning Rate: 0.005\n",
      "Epoch [1084/20000], Loss: 359.17572021484375, Entropy -329.04547119140625, Learning Rate: 0.005\n",
      "Epoch [1085/20000], Loss: 384.84857177734375, Entropy -349.4701232910156, Learning Rate: 0.005\n",
      "Epoch [1086/20000], Loss: 374.123779296875, Entropy -341.4592590332031, Learning Rate: 0.005\n",
      "Epoch [1087/20000], Loss: 373.3799743652344, Entropy -324.1673583984375, Learning Rate: 0.005\n",
      "Epoch [1088/20000], Loss: 380.6668701171875, Entropy -338.0894775390625, Learning Rate: 0.005\n",
      "Epoch [1089/20000], Loss: 375.4730224609375, Entropy -322.20733642578125, Learning Rate: 0.005\n",
      "Epoch [1090/20000], Loss: 388.47918701171875, Entropy -344.7372131347656, Learning Rate: 0.005\n",
      "Epoch [1091/20000], Loss: 377.3871154785156, Entropy -341.42010498046875, Learning Rate: 0.005\n",
      "Epoch [1092/20000], Loss: 353.80859375, Entropy -321.1556091308594, Learning Rate: 0.005\n",
      "Epoch [1093/20000], Loss: 350.70916748046875, Entropy -316.5137634277344, Learning Rate: 0.005\n",
      "Epoch [1094/20000], Loss: 364.3057861328125, Entropy -320.3315124511719, Learning Rate: 0.005\n",
      "Epoch [1095/20000], Loss: 374.6749267578125, Entropy -325.5929260253906, Learning Rate: 0.005\n",
      "Epoch [1096/20000], Loss: 344.2867736816406, Entropy -322.3157653808594, Learning Rate: 0.005\n",
      "Epoch [1097/20000], Loss: 375.9400634765625, Entropy -327.2844543457031, Learning Rate: 0.005\n",
      "Epoch [1098/20000], Loss: 353.5464172363281, Entropy -320.6632080078125, Learning Rate: 0.005\n",
      "Epoch [1099/20000], Loss: 369.16497802734375, Entropy -313.59521484375, Learning Rate: 0.005\n",
      "Epoch [1100/20000], Loss: 346.357421875, Entropy -306.7104797363281, Learning Rate: 0.005\n",
      "Epoch [1101/20000], Loss: 373.5394592285156, Entropy -335.6602783203125, Learning Rate: 0.005\n",
      "Epoch [1102/20000], Loss: 363.4958801269531, Entropy -325.7862548828125, Learning Rate: 0.005\n",
      "Epoch [1103/20000], Loss: 365.87921142578125, Entropy -321.82733154296875, Learning Rate: 0.005\n",
      "Epoch [1104/20000], Loss: 365.9808654785156, Entropy -333.6551513671875, Learning Rate: 0.005\n",
      "Epoch [1105/20000], Loss: 385.0609130859375, Entropy -333.8472595214844, Learning Rate: 0.005\n",
      "Epoch [1106/20000], Loss: 373.04486083984375, Entropy -317.9503173828125, Learning Rate: 0.005\n",
      "Epoch [1107/20000], Loss: 368.28125, Entropy -325.4079284667969, Learning Rate: 0.005\n",
      "Epoch [1108/20000], Loss: 362.5843811035156, Entropy -321.78790283203125, Learning Rate: 0.005\n",
      "Epoch [1109/20000], Loss: 369.5556640625, Entropy -322.8623962402344, Learning Rate: 0.005\n",
      "Epoch [1110/20000], Loss: 361.3728332519531, Entropy -313.7037048339844, Learning Rate: 0.005\n",
      "Epoch [1111/20000], Loss: 348.83056640625, Entropy -326.7668151855469, Learning Rate: 0.005\n",
      "Epoch [1112/20000], Loss: 368.3446044921875, Entropy -336.4742736816406, Learning Rate: 0.005\n",
      "Epoch [1113/20000], Loss: 389.690673828125, Entropy -324.37152099609375, Learning Rate: 0.005\n",
      "Epoch [1114/20000], Loss: 382.9541015625, Entropy -348.465576171875, Learning Rate: 0.005\n",
      "Epoch [1115/20000], Loss: 404.056640625, Entropy -324.35595703125, Learning Rate: 0.005\n",
      "Epoch [1116/20000], Loss: 387.281005859375, Entropy -323.55487060546875, Learning Rate: 0.005\n",
      "Epoch [1117/20000], Loss: 367.5789489746094, Entropy -320.7303161621094, Learning Rate: 0.005\n",
      "Epoch [1118/20000], Loss: 389.0375671386719, Entropy -328.22698974609375, Learning Rate: 0.005\n",
      "Epoch [1119/20000], Loss: 397.90447998046875, Entropy -327.142333984375, Learning Rate: 0.005\n",
      "Epoch [1120/20000], Loss: 384.0505065917969, Entropy -340.22821044921875, Learning Rate: 0.005\n",
      "Epoch [1121/20000], Loss: 373.0330505371094, Entropy -330.1957092285156, Learning Rate: 0.005\n",
      "Epoch [1122/20000], Loss: 358.75628662109375, Entropy -324.1484680175781, Learning Rate: 0.005\n",
      "Epoch [1123/20000], Loss: 385.52239990234375, Entropy -336.91998291015625, Learning Rate: 0.005\n",
      "Epoch [1124/20000], Loss: 389.5754089355469, Entropy -328.2811279296875, Learning Rate: 0.005\n",
      "Epoch [1125/20000], Loss: 368.7838134765625, Entropy -324.47882080078125, Learning Rate: 0.005\n",
      "Epoch [1126/20000], Loss: 385.6671447753906, Entropy -334.3310852050781, Learning Rate: 0.005\n",
      "Epoch [1127/20000], Loss: 366.5366516113281, Entropy -317.70111083984375, Learning Rate: 0.005\n",
      "Epoch [1128/20000], Loss: 394.83056640625, Entropy -349.1946105957031, Learning Rate: 0.005\n",
      "Epoch [1129/20000], Loss: 383.02569580078125, Entropy -337.2709045410156, Learning Rate: 0.005\n",
      "Epoch [1130/20000], Loss: 383.7679443359375, Entropy -323.3825988769531, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1131/20000], Loss: 369.4884338378906, Entropy -319.66241455078125, Learning Rate: 0.005\n",
      "Epoch [1132/20000], Loss: 410.6691589355469, Entropy -345.38623046875, Learning Rate: 0.005\n",
      "Epoch [1133/20000], Loss: 409.7584228515625, Entropy -333.0131530761719, Learning Rate: 0.005\n",
      "Epoch [1134/20000], Loss: 402.78900146484375, Entropy -345.5732116699219, Learning Rate: 0.005\n",
      "Epoch [1135/20000], Loss: 405.57464599609375, Entropy -325.5608825683594, Learning Rate: 0.005\n",
      "Epoch [1136/20000], Loss: 392.0805358886719, Entropy -326.0885925292969, Learning Rate: 0.005\n",
      "Epoch [1137/20000], Loss: 348.86041259765625, Entropy -306.7069091796875, Learning Rate: 0.005\n",
      "Epoch [1138/20000], Loss: 375.6923828125, Entropy -325.4947814941406, Learning Rate: 0.005\n",
      "Epoch [1139/20000], Loss: 385.82708740234375, Entropy -317.8846130371094, Learning Rate: 0.005\n",
      "Epoch [1140/20000], Loss: 385.62542724609375, Entropy -329.7179870605469, Learning Rate: 0.005\n",
      "Epoch [1141/20000], Loss: 379.48004150390625, Entropy -325.34783935546875, Learning Rate: 0.005\n",
      "Epoch [1142/20000], Loss: 383.94329833984375, Entropy -310.77301025390625, Learning Rate: 0.005\n",
      "Epoch [1143/20000], Loss: 362.4095458984375, Entropy -315.9060363769531, Learning Rate: 0.005\n",
      "Epoch [1144/20000], Loss: 373.2433776855469, Entropy -326.8667907714844, Learning Rate: 0.005\n",
      "Epoch [1145/20000], Loss: 384.614990234375, Entropy -340.10211181640625, Learning Rate: 0.005\n",
      "Epoch [1146/20000], Loss: 381.0419921875, Entropy -332.6551513671875, Learning Rate: 0.005\n",
      "Epoch [1147/20000], Loss: 355.53411865234375, Entropy -316.707763671875, Learning Rate: 0.005\n",
      "Epoch [1148/20000], Loss: 357.3709411621094, Entropy -326.0248718261719, Learning Rate: 0.005\n",
      "Epoch [1149/20000], Loss: 386.592041015625, Entropy -340.7323303222656, Learning Rate: 0.005\n",
      "Epoch [1150/20000], Loss: 344.72454833984375, Entropy -305.6150817871094, Learning Rate: 0.005\n",
      "Epoch [1151/20000], Loss: 385.5325012207031, Entropy -328.0023193359375, Learning Rate: 0.005\n",
      "Epoch [1152/20000], Loss: 362.0398864746094, Entropy -332.1458740234375, Learning Rate: 0.005\n",
      "Epoch [1153/20000], Loss: 382.17755126953125, Entropy -334.6465759277344, Learning Rate: 0.005\n",
      "Epoch [1154/20000], Loss: 373.07611083984375, Entropy -339.6246337890625, Learning Rate: 0.005\n",
      "Epoch [1155/20000], Loss: 357.776611328125, Entropy -319.1019287109375, Learning Rate: 0.005\n",
      "Epoch [1156/20000], Loss: 365.47314453125, Entropy -335.46527099609375, Learning Rate: 0.005\n",
      "Epoch [1157/20000], Loss: 373.64471435546875, Entropy -320.29547119140625, Learning Rate: 0.005\n",
      "Epoch [1158/20000], Loss: 356.64251708984375, Entropy -326.2418212890625, Learning Rate: 0.005\n",
      "Epoch [1159/20000], Loss: 354.1803894042969, Entropy -316.48992919921875, Learning Rate: 0.005\n",
      "Epoch [1160/20000], Loss: 365.3292236328125, Entropy -333.44244384765625, Learning Rate: 0.005\n",
      "Epoch [1161/20000], Loss: 366.0130920410156, Entropy -316.7236022949219, Learning Rate: 0.005\n",
      "Epoch [1162/20000], Loss: 379.2830810546875, Entropy -340.816650390625, Learning Rate: 0.005\n",
      "Epoch [1163/20000], Loss: 360.07073974609375, Entropy -319.56591796875, Learning Rate: 0.005\n",
      "Epoch [1164/20000], Loss: 367.9790344238281, Entropy -335.78643798828125, Learning Rate: 0.005\n",
      "Epoch [1165/20000], Loss: 382.2438659667969, Entropy -335.83367919921875, Learning Rate: 0.005\n",
      "Epoch [1166/20000], Loss: 366.54193115234375, Entropy -337.6685791015625, Learning Rate: 0.005\n",
      "Epoch [1167/20000], Loss: 372.01788330078125, Entropy -331.6520690917969, Learning Rate: 0.005\n",
      "Epoch [1168/20000], Loss: 370.84027099609375, Entropy -341.63134765625, Learning Rate: 0.005\n",
      "Epoch [1169/20000], Loss: 359.678466796875, Entropy -325.0380859375, Learning Rate: 0.005\n",
      "Epoch [1170/20000], Loss: 364.5290222167969, Entropy -325.0152587890625, Learning Rate: 0.005\n",
      "Epoch [1171/20000], Loss: 355.6370849609375, Entropy -325.4798889160156, Learning Rate: 0.005\n",
      "Epoch [1172/20000], Loss: 370.2213439941406, Entropy -333.86370849609375, Learning Rate: 0.005\n",
      "Epoch [1173/20000], Loss: 362.4906311035156, Entropy -323.0397033691406, Learning Rate: 0.005\n",
      "Epoch [1174/20000], Loss: 359.4232177734375, Entropy -339.0762939453125, Learning Rate: 0.005\n",
      "Epoch [1175/20000], Loss: 346.17193603515625, Entropy -312.5523681640625, Learning Rate: 0.005\n",
      "Epoch [1176/20000], Loss: 361.0142822265625, Entropy -328.6839599609375, Learning Rate: 0.005\n",
      "Epoch [1177/20000], Loss: 373.3433837890625, Entropy -335.85369873046875, Learning Rate: 0.005\n",
      "Epoch [1178/20000], Loss: 361.985107421875, Entropy -335.2515563964844, Learning Rate: 0.005\n",
      "Epoch [1179/20000], Loss: 375.0624084472656, Entropy -315.9140930175781, Learning Rate: 0.005\n",
      "Epoch [1180/20000], Loss: 365.92523193359375, Entropy -336.810546875, Learning Rate: 0.005\n",
      "Epoch [1181/20000], Loss: 355.2671203613281, Entropy -326.5881042480469, Learning Rate: 0.005\n",
      "Epoch [1182/20000], Loss: 356.5419921875, Entropy -320.6128845214844, Learning Rate: 0.005\n",
      "Epoch [1183/20000], Loss: 377.8853759765625, Entropy -347.78399658203125, Learning Rate: 0.005\n",
      "Epoch [1184/20000], Loss: 352.7376708984375, Entropy -322.63995361328125, Learning Rate: 0.005\n",
      "Epoch [1185/20000], Loss: 381.0203552246094, Entropy -327.90069580078125, Learning Rate: 0.005\n",
      "Epoch [1186/20000], Loss: 374.3493957519531, Entropy -337.7558898925781, Learning Rate: 0.005\n",
      "Epoch [1187/20000], Loss: 363.76324462890625, Entropy -322.1011962890625, Learning Rate: 0.005\n",
      "Epoch [1188/20000], Loss: 362.6605224609375, Entropy -325.76153564453125, Learning Rate: 0.005\n",
      "Epoch [1189/20000], Loss: 358.50567626953125, Entropy -329.6424560546875, Learning Rate: 0.005\n",
      "Epoch [1190/20000], Loss: 362.4385986328125, Entropy -326.86712646484375, Learning Rate: 0.005\n",
      "Epoch [1191/20000], Loss: 354.66448974609375, Entropy -320.8061828613281, Learning Rate: 0.005\n",
      "Epoch [1192/20000], Loss: 388.6490478515625, Entropy -331.074462890625, Learning Rate: 0.005\n",
      "Epoch [1193/20000], Loss: 369.0689392089844, Entropy -326.1690368652344, Learning Rate: 0.005\n",
      "Epoch [1194/20000], Loss: 395.05523681640625, Entropy -340.85137939453125, Learning Rate: 0.005\n",
      "Epoch [1195/20000], Loss: 363.068603515625, Entropy -321.0331726074219, Learning Rate: 0.005\n",
      "Epoch [1196/20000], Loss: 386.26678466796875, Entropy -332.9469909667969, Learning Rate: 0.005\n",
      "Epoch [1197/20000], Loss: 372.9851379394531, Entropy -320.4226989746094, Learning Rate: 0.005\n",
      "Epoch [1198/20000], Loss: 380.9320373535156, Entropy -332.9707946777344, Learning Rate: 0.005\n",
      "Epoch [1199/20000], Loss: 377.7640075683594, Entropy -323.2580261230469, Learning Rate: 0.005\n",
      "Epoch [1200/20000], Loss: 361.1606750488281, Entropy -335.0709533691406, Learning Rate: 0.005\n",
      "Epoch [1201/20000], Loss: 368.83062744140625, Entropy -324.7351379394531, Learning Rate: 0.005\n",
      "Epoch [1202/20000], Loss: 394.1291198730469, Entropy -332.23016357421875, Learning Rate: 0.005\n",
      "Epoch [1203/20000], Loss: 353.2526550292969, Entropy -305.5834045410156, Learning Rate: 0.005\n",
      "Epoch [1204/20000], Loss: 399.71038818359375, Entropy -338.8370056152344, Learning Rate: 0.005\n",
      "Epoch [1205/20000], Loss: 375.4585876464844, Entropy -320.4933776855469, Learning Rate: 0.005\n",
      "Epoch [1206/20000], Loss: 403.5404357910156, Entropy -330.6701354980469, Learning Rate: 0.005\n",
      "Epoch [1207/20000], Loss: 381.6358337402344, Entropy -328.6037902832031, Learning Rate: 0.005\n",
      "Epoch [1208/20000], Loss: 382.1612548828125, Entropy -325.1726989746094, Learning Rate: 0.005\n",
      "Epoch [1209/20000], Loss: 363.5409240722656, Entropy -330.2563171386719, Learning Rate: 0.005\n",
      "Epoch [1210/20000], Loss: 424.3724060058594, Entropy -319.9989318847656, Learning Rate: 0.005\n",
      "Epoch [1211/20000], Loss: 414.456298828125, Entropy -346.74609375, Learning Rate: 0.005\n",
      "Epoch [1212/20000], Loss: 377.37054443359375, Entropy -301.0973815917969, Learning Rate: 0.005\n",
      "Epoch [1213/20000], Loss: 397.6903991699219, Entropy -317.12249755859375, Learning Rate: 0.005\n",
      "Epoch [1214/20000], Loss: 393.56951904296875, Entropy -334.8976745605469, Learning Rate: 0.005\n",
      "Epoch [1215/20000], Loss: 404.4618835449219, Entropy -319.33636474609375, Learning Rate: 0.005\n",
      "Epoch [1216/20000], Loss: 381.0631103515625, Entropy -333.25714111328125, Learning Rate: 0.005\n",
      "Epoch [1217/20000], Loss: 434.87847900390625, Entropy -319.5144348144531, Learning Rate: 0.005\n",
      "Epoch [1218/20000], Loss: 373.82965087890625, Entropy -324.8791198730469, Learning Rate: 0.005\n",
      "Epoch [1219/20000], Loss: 439.6228942871094, Entropy -309.07513427734375, Learning Rate: 0.005\n",
      "Epoch [1220/20000], Loss: 454.3116455078125, Entropy -328.4403991699219, Learning Rate: 0.005\n",
      "Epoch [1221/20000], Loss: 570.109619140625, Entropy -343.847412109375, Learning Rate: 0.005\n",
      "Epoch [1222/20000], Loss: 356.3640441894531, Entropy -326.11590576171875, Learning Rate: 0.005\n",
      "Epoch [1223/20000], Loss: 530.13818359375, Entropy -329.5141296386719, Learning Rate: 0.005\n",
      "Epoch [1224/20000], Loss: 392.8109130859375, Entropy -323.38677978515625, Learning Rate: 0.005\n",
      "Epoch [1225/20000], Loss: 551.9661254882812, Entropy -323.2337951660156, Learning Rate: 0.005\n",
      "Epoch [1226/20000], Loss: 451.83306884765625, Entropy -355.9287109375, Learning Rate: 0.005\n",
      "Epoch [1227/20000], Loss: 524.3803100585938, Entropy -307.52301025390625, Learning Rate: 0.005\n",
      "Epoch [1228/20000], Loss: 421.7014465332031, Entropy -337.7046203613281, Learning Rate: 0.005\n",
      "Epoch [1229/20000], Loss: 554.572021484375, Entropy -308.7247314453125, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1230/20000], Loss: 485.10986328125, Entropy -315.33837890625, Learning Rate: 0.005\n",
      "Epoch [1231/20000], Loss: 375.5213928222656, Entropy -331.50860595703125, Learning Rate: 0.005\n",
      "Epoch [1232/20000], Loss: 449.1798400878906, Entropy -304.98333740234375, Learning Rate: 0.005\n",
      "Epoch [1233/20000], Loss: 395.636962890625, Entropy -325.8890380859375, Learning Rate: 0.005\n",
      "Epoch [1234/20000], Loss: 429.9407958984375, Entropy -329.7010498046875, Learning Rate: 0.005\n",
      "Epoch [1235/20000], Loss: 402.3985595703125, Entropy -310.35455322265625, Learning Rate: 0.0025\n",
      "Epoch [1236/20000], Loss: 359.4824523925781, Entropy -315.0851135253906, Learning Rate: 0.0025\n",
      "Epoch [1237/20000], Loss: 399.2940979003906, Entropy -323.89776611328125, Learning Rate: 0.0025\n",
      "Epoch [1238/20000], Loss: 390.4342041015625, Entropy -328.9603271484375, Learning Rate: 0.0025\n",
      "Epoch [1239/20000], Loss: 374.5140380859375, Entropy -327.69512939453125, Learning Rate: 0.0025\n",
      "Epoch [1240/20000], Loss: 417.833740234375, Entropy -341.4452209472656, Learning Rate: 0.0025\n",
      "Epoch [1241/20000], Loss: 392.68377685546875, Entropy -339.6885070800781, Learning Rate: 0.0025\n",
      "Epoch [1242/20000], Loss: 365.583984375, Entropy -324.5784912109375, Learning Rate: 0.0025\n",
      "Epoch [1243/20000], Loss: 418.35736083984375, Entropy -332.77325439453125, Learning Rate: 0.0025\n",
      "Epoch [1244/20000], Loss: 384.78131103515625, Entropy -316.41278076171875, Learning Rate: 0.0025\n",
      "Epoch [1245/20000], Loss: 375.482666015625, Entropy -332.1541748046875, Learning Rate: 0.0025\n",
      "Epoch [1246/20000], Loss: 386.15887451171875, Entropy -337.6702575683594, Learning Rate: 0.0025\n",
      "Epoch [1247/20000], Loss: 371.8877258300781, Entropy -323.6155700683594, Learning Rate: 0.0025\n",
      "Epoch [1248/20000], Loss: 377.9146423339844, Entropy -320.3074951171875, Learning Rate: 0.0025\n",
      "Epoch [1249/20000], Loss: 405.2025451660156, Entropy -339.7414245605469, Learning Rate: 0.0025\n",
      "Epoch [1250/20000], Loss: 380.5109558105469, Entropy -327.5186462402344, Learning Rate: 0.0025\n",
      "Epoch [1251/20000], Loss: 356.68975830078125, Entropy -323.3878173828125, Learning Rate: 0.0025\n",
      "Epoch [1252/20000], Loss: 377.2643737792969, Entropy -324.59088134765625, Learning Rate: 0.0025\n",
      "Epoch [1253/20000], Loss: 377.98126220703125, Entropy -335.8447265625, Learning Rate: 0.0025\n",
      "Epoch [1254/20000], Loss: 381.8770751953125, Entropy -333.2025451660156, Learning Rate: 0.0025\n",
      "Epoch [1255/20000], Loss: 383.9223327636719, Entropy -322.6047058105469, Learning Rate: 0.0025\n",
      "Epoch [1256/20000], Loss: 375.6851806640625, Entropy -313.08135986328125, Learning Rate: 0.0025\n",
      "Epoch [1257/20000], Loss: 376.70880126953125, Entropy -326.7212829589844, Learning Rate: 0.0025\n",
      "Epoch [1258/20000], Loss: 371.4625244140625, Entropy -342.3367614746094, Learning Rate: 0.0025\n",
      "Epoch [1259/20000], Loss: 378.5235290527344, Entropy -337.54241943359375, Learning Rate: 0.0025\n",
      "Epoch [1260/20000], Loss: 379.2396240234375, Entropy -333.975341796875, Learning Rate: 0.0025\n",
      "Epoch [1261/20000], Loss: 382.36663818359375, Entropy -330.5481872558594, Learning Rate: 0.0025\n",
      "Epoch [1262/20000], Loss: 383.8832092285156, Entropy -330.5967102050781, Learning Rate: 0.0025\n",
      "Epoch [1263/20000], Loss: 376.468017578125, Entropy -332.6585388183594, Learning Rate: 0.0025\n",
      "Epoch [1264/20000], Loss: 365.62530517578125, Entropy -333.3526611328125, Learning Rate: 0.0025\n",
      "Epoch [1265/20000], Loss: 363.8076477050781, Entropy -320.77099609375, Learning Rate: 0.0025\n",
      "Epoch [1266/20000], Loss: 346.74102783203125, Entropy -312.0926513671875, Learning Rate: 0.0025\n",
      "Epoch [1267/20000], Loss: 348.81866455078125, Entropy -328.137451171875, Learning Rate: 0.0025\n",
      "Epoch [1268/20000], Loss: 362.2251892089844, Entropy -317.0179748535156, Learning Rate: 0.0025\n",
      "Epoch [1269/20000], Loss: 369.7310485839844, Entropy -334.67230224609375, Learning Rate: 0.0025\n",
      "Epoch [1270/20000], Loss: 369.0513610839844, Entropy -331.39813232421875, Learning Rate: 0.0025\n",
      "Epoch [1271/20000], Loss: 377.86187744140625, Entropy -329.7286376953125, Learning Rate: 0.0025\n",
      "Epoch [1272/20000], Loss: 352.5350341796875, Entropy -332.395263671875, Learning Rate: 0.0025\n",
      "Epoch [1273/20000], Loss: 349.561279296875, Entropy -317.4228820800781, Learning Rate: 0.0025\n",
      "Epoch [1274/20000], Loss: 352.8819580078125, Entropy -316.4813232421875, Learning Rate: 0.0025\n",
      "Epoch [1275/20000], Loss: 366.8807373046875, Entropy -336.6369323730469, Learning Rate: 0.0025\n",
      "Epoch [1276/20000], Loss: 361.993896484375, Entropy -328.1738586425781, Learning Rate: 0.0025\n",
      "Epoch [1277/20000], Loss: 378.1555480957031, Entropy -338.486572265625, Learning Rate: 0.0025\n",
      "Epoch [1278/20000], Loss: 333.80914306640625, Entropy -316.0225524902344, Learning Rate: 0.0025\n",
      "Epoch [1279/20000], Loss: 360.05426025390625, Entropy -328.2859802246094, Learning Rate: 0.0025\n",
      "Epoch [1280/20000], Loss: 383.585205078125, Entropy -363.0234069824219, Learning Rate: 0.0025\n",
      "Epoch [1281/20000], Loss: 384.70709228515625, Entropy -354.2745056152344, Learning Rate: 0.0025\n",
      "Epoch [1282/20000], Loss: 364.63592529296875, Entropy -331.3619079589844, Learning Rate: 0.0025\n",
      "Epoch [1283/20000], Loss: 361.2237548828125, Entropy -326.93487548828125, Learning Rate: 0.0025\n",
      "Epoch [1284/20000], Loss: 388.6131591796875, Entropy -338.57965087890625, Learning Rate: 0.0025\n",
      "Epoch [1285/20000], Loss: 348.6025390625, Entropy -318.9337463378906, Learning Rate: 0.0025\n",
      "Epoch [1286/20000], Loss: 361.2564392089844, Entropy -315.8931579589844, Learning Rate: 0.0025\n",
      "Epoch [1287/20000], Loss: 364.79705810546875, Entropy -332.7405700683594, Learning Rate: 0.0025\n",
      "Epoch [1288/20000], Loss: 358.87615966796875, Entropy -332.81805419921875, Learning Rate: 0.0025\n",
      "Epoch [1289/20000], Loss: 368.79669189453125, Entropy -325.65594482421875, Learning Rate: 0.0025\n",
      "Epoch [1290/20000], Loss: 356.90863037109375, Entropy -324.0685729980469, Learning Rate: 0.0025\n",
      "Epoch [1291/20000], Loss: 365.21136474609375, Entropy -336.5374755859375, Learning Rate: 0.0025\n",
      "Epoch [1292/20000], Loss: 362.2559814453125, Entropy -324.86163330078125, Learning Rate: 0.0025\n",
      "Epoch [1293/20000], Loss: 370.4268798828125, Entropy -327.66217041015625, Learning Rate: 0.0025\n",
      "Epoch [1294/20000], Loss: 349.5411376953125, Entropy -321.4644775390625, Learning Rate: 0.0025\n",
      "Epoch [1295/20000], Loss: 358.98040771484375, Entropy -331.008544921875, Learning Rate: 0.0025\n",
      "Epoch [1296/20000], Loss: 354.0750427246094, Entropy -312.9560546875, Learning Rate: 0.0025\n",
      "Epoch [1297/20000], Loss: 348.7261047363281, Entropy -331.37322998046875, Learning Rate: 0.0025\n",
      "Epoch [1298/20000], Loss: 348.950439453125, Entropy -326.0215759277344, Learning Rate: 0.0025\n",
      "Epoch [1299/20000], Loss: 352.6102600097656, Entropy -327.76300048828125, Learning Rate: 0.0025\n",
      "Epoch [1300/20000], Loss: 362.859130859375, Entropy -325.5850524902344, Learning Rate: 0.0025\n",
      "Epoch [1301/20000], Loss: 338.9775695800781, Entropy -305.7148132324219, Learning Rate: 0.0025\n",
      "Epoch [1302/20000], Loss: 364.65411376953125, Entropy -327.04052734375, Learning Rate: 0.0025\n",
      "Epoch [1303/20000], Loss: 364.4410400390625, Entropy -328.96990966796875, Learning Rate: 0.0025\n",
      "Epoch [1304/20000], Loss: 348.39703369140625, Entropy -318.7779846191406, Learning Rate: 0.0025\n",
      "Epoch [1305/20000], Loss: 347.327880859375, Entropy -327.8624267578125, Learning Rate: 0.0025\n",
      "Epoch [1306/20000], Loss: 358.1774597167969, Entropy -322.2654724121094, Learning Rate: 0.0025\n",
      "Epoch [1307/20000], Loss: 354.15594482421875, Entropy -319.46417236328125, Learning Rate: 0.0025\n",
      "Epoch [1308/20000], Loss: 358.1049499511719, Entropy -335.60235595703125, Learning Rate: 0.0025\n",
      "Epoch [1309/20000], Loss: 360.23187255859375, Entropy -331.2393798828125, Learning Rate: 0.0025\n",
      "Epoch [1310/20000], Loss: 372.5451354980469, Entropy -326.5866394042969, Learning Rate: 0.0025\n",
      "Epoch [1311/20000], Loss: 367.71759033203125, Entropy -336.18963623046875, Learning Rate: 0.0025\n",
      "Epoch [1312/20000], Loss: 361.05474853515625, Entropy -336.8744201660156, Learning Rate: 0.0025\n",
      "Epoch [1313/20000], Loss: 358.8323669433594, Entropy -327.2994384765625, Learning Rate: 0.0025\n",
      "Epoch [1314/20000], Loss: 360.09783935546875, Entropy -323.9919738769531, Learning Rate: 0.0025\n",
      "Epoch [1315/20000], Loss: 353.5447082519531, Entropy -320.586669921875, Learning Rate: 0.0025\n",
      "Epoch [1316/20000], Loss: 357.1084289550781, Entropy -316.3899230957031, Learning Rate: 0.0025\n",
      "Epoch [1317/20000], Loss: 383.45843505859375, Entropy -362.42474365234375, Learning Rate: 0.0025\n",
      "Epoch [1318/20000], Loss: 363.9974365234375, Entropy -338.6514892578125, Learning Rate: 0.0025\n",
      "Epoch [1319/20000], Loss: 365.7965087890625, Entropy -322.52490234375, Learning Rate: 0.0025\n",
      "Epoch [1320/20000], Loss: 346.32769775390625, Entropy -324.9835510253906, Learning Rate: 0.0025\n",
      "Epoch [1321/20000], Loss: 364.31439208984375, Entropy -327.2759704589844, Learning Rate: 0.0025\n",
      "Epoch [1322/20000], Loss: 370.1787109375, Entropy -327.2287292480469, Learning Rate: 0.0025\n",
      "Epoch [1323/20000], Loss: 350.0543212890625, Entropy -326.49554443359375, Learning Rate: 0.0025\n",
      "Epoch [1324/20000], Loss: 343.04022216796875, Entropy -310.95074462890625, Learning Rate: 0.0025\n",
      "Epoch [1325/20000], Loss: 369.22607421875, Entropy -317.62835693359375, Learning Rate: 0.0025\n",
      "Epoch [1326/20000], Loss: 352.6053466796875, Entropy -309.7452697753906, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1327/20000], Loss: 360.7669982910156, Entropy -330.690673828125, Learning Rate: 0.0025\n",
      "Epoch [1328/20000], Loss: 347.63104248046875, Entropy -325.8607482910156, Learning Rate: 0.0025\n",
      "Epoch [1329/20000], Loss: 382.6119079589844, Entropy -342.0009765625, Learning Rate: 0.0025\n",
      "Epoch [1330/20000], Loss: 350.53887939453125, Entropy -323.6231994628906, Learning Rate: 0.0025\n",
      "Epoch [1331/20000], Loss: 332.35455322265625, Entropy -315.1360168457031, Learning Rate: 0.0025\n",
      "Epoch [1332/20000], Loss: 376.9481201171875, Entropy -323.8226623535156, Learning Rate: 0.0025\n",
      "Epoch [1333/20000], Loss: 361.4646301269531, Entropy -322.1670837402344, Learning Rate: 0.0025\n",
      "Epoch [1334/20000], Loss: 348.70538330078125, Entropy -326.9163818359375, Learning Rate: 0.0025\n",
      "Epoch [1335/20000], Loss: 367.0755920410156, Entropy -318.1275329589844, Learning Rate: 0.0025\n",
      "Epoch [1336/20000], Loss: 361.7672424316406, Entropy -329.2937316894531, Learning Rate: 0.0025\n",
      "Epoch [1337/20000], Loss: 396.24774169921875, Entropy -330.4298095703125, Learning Rate: 0.0025\n",
      "Epoch [1338/20000], Loss: 372.46954345703125, Entropy -321.9295349121094, Learning Rate: 0.0025\n",
      "Epoch [1339/20000], Loss: 353.0537414550781, Entropy -325.17529296875, Learning Rate: 0.0025\n",
      "Epoch [1340/20000], Loss: 361.5952453613281, Entropy -325.5963134765625, Learning Rate: 0.0025\n",
      "Epoch [1341/20000], Loss: 378.5050964355469, Entropy -335.8863525390625, Learning Rate: 0.0025\n",
      "Epoch [1342/20000], Loss: 383.3859558105469, Entropy -319.678955078125, Learning Rate: 0.0025\n",
      "Epoch [1343/20000], Loss: 345.1250305175781, Entropy -316.86279296875, Learning Rate: 0.0025\n",
      "Epoch [1344/20000], Loss: 375.94134521484375, Entropy -336.0130615234375, Learning Rate: 0.0025\n",
      "Epoch [1345/20000], Loss: 391.782958984375, Entropy -329.17401123046875, Learning Rate: 0.0025\n",
      "Epoch [1346/20000], Loss: 368.3319396972656, Entropy -335.96307373046875, Learning Rate: 0.0025\n",
      "Epoch [1347/20000], Loss: 377.1907043457031, Entropy -335.1722412109375, Learning Rate: 0.0025\n",
      "Epoch [1348/20000], Loss: 367.66644287109375, Entropy -317.2073669433594, Learning Rate: 0.0025\n",
      "Epoch [1349/20000], Loss: 353.6289367675781, Entropy -308.3507080078125, Learning Rate: 0.0025\n",
      "Epoch [1350/20000], Loss: 374.7503967285156, Entropy -329.91619873046875, Learning Rate: 0.0025\n",
      "Epoch [1351/20000], Loss: 377.503173828125, Entropy -337.09808349609375, Learning Rate: 0.0025\n",
      "Epoch [1352/20000], Loss: 355.79547119140625, Entropy -316.9453125, Learning Rate: 0.0025\n",
      "Epoch [1353/20000], Loss: 387.69134521484375, Entropy -335.33123779296875, Learning Rate: 0.0025\n",
      "Epoch [1354/20000], Loss: 362.0469970703125, Entropy -323.1302490234375, Learning Rate: 0.0025\n",
      "Epoch [1355/20000], Loss: 379.9029846191406, Entropy -339.5537109375, Learning Rate: 0.0025\n",
      "Epoch [1356/20000], Loss: 393.0783996582031, Entropy -334.9478759765625, Learning Rate: 0.0025\n",
      "Epoch [1357/20000], Loss: 355.3238220214844, Entropy -328.00732421875, Learning Rate: 0.0025\n",
      "Epoch [1358/20000], Loss: 355.7413024902344, Entropy -318.8883361816406, Learning Rate: 0.0025\n",
      "Epoch [1359/20000], Loss: 370.3328552246094, Entropy -324.357177734375, Learning Rate: 0.0025\n",
      "Epoch [1360/20000], Loss: 343.760498046875, Entropy -315.2970275878906, Learning Rate: 0.0025\n",
      "Epoch [1361/20000], Loss: 360.99072265625, Entropy -319.8190002441406, Learning Rate: 0.0025\n",
      "Epoch [1362/20000], Loss: 353.6595153808594, Entropy -305.37774658203125, Learning Rate: 0.0025\n",
      "Epoch [1363/20000], Loss: 362.6849365234375, Entropy -328.141357421875, Learning Rate: 0.0025\n",
      "Epoch [1364/20000], Loss: 345.3471984863281, Entropy -325.1104431152344, Learning Rate: 0.0025\n",
      "Epoch [1365/20000], Loss: 347.9552001953125, Entropy -333.7932434082031, Learning Rate: 0.0025\n",
      "Epoch [1366/20000], Loss: 332.794677734375, Entropy -316.925048828125, Learning Rate: 0.0025\n",
      "Epoch [1367/20000], Loss: 353.90985107421875, Entropy -335.81842041015625, Learning Rate: 0.0025\n",
      "Epoch [1368/20000], Loss: 343.41754150390625, Entropy -322.25640869140625, Learning Rate: 0.0025\n",
      "Epoch [1369/20000], Loss: 352.2031555175781, Entropy -322.923583984375, Learning Rate: 0.0025\n",
      "Epoch [1370/20000], Loss: 388.1545104980469, Entropy -334.28570556640625, Learning Rate: 0.0025\n",
      "Epoch [1371/20000], Loss: 340.1745300292969, Entropy -331.3119812011719, Learning Rate: 0.0025\n",
      "Epoch [1372/20000], Loss: 366.13800048828125, Entropy -335.1487121582031, Learning Rate: 0.0025\n",
      "Epoch [1373/20000], Loss: 371.18670654296875, Entropy -336.1094665527344, Learning Rate: 0.0025\n",
      "Epoch [1374/20000], Loss: 345.2652893066406, Entropy -331.9153137207031, Learning Rate: 0.0025\n",
      "Epoch [1375/20000], Loss: 386.2787170410156, Entropy -338.0558166503906, Learning Rate: 0.0025\n",
      "Epoch [1376/20000], Loss: 363.7516784667969, Entropy -327.2000732421875, Learning Rate: 0.0025\n",
      "Epoch [1377/20000], Loss: 366.92303466796875, Entropy -328.6642150878906, Learning Rate: 0.0025\n",
      "Epoch [1378/20000], Loss: 350.0321350097656, Entropy -324.28924560546875, Learning Rate: 0.0025\n",
      "Epoch [1379/20000], Loss: 341.6424560546875, Entropy -301.4756774902344, Learning Rate: 0.0025\n",
      "Epoch [1380/20000], Loss: 372.9067687988281, Entropy -336.90643310546875, Learning Rate: 0.0025\n",
      "Epoch [1381/20000], Loss: 381.70050048828125, Entropy -325.8772277832031, Learning Rate: 0.0025\n",
      "Epoch [1382/20000], Loss: 358.38006591796875, Entropy -329.055419921875, Learning Rate: 0.0025\n",
      "Epoch [1383/20000], Loss: 388.77752685546875, Entropy -334.44140625, Learning Rate: 0.0025\n",
      "Epoch [1384/20000], Loss: 361.36566162109375, Entropy -324.4923095703125, Learning Rate: 0.0025\n",
      "Epoch [1385/20000], Loss: 368.0190734863281, Entropy -338.0146179199219, Learning Rate: 0.0025\n",
      "Epoch [1386/20000], Loss: 353.86846923828125, Entropy -313.5813293457031, Learning Rate: 0.0025\n",
      "Epoch [1387/20000], Loss: 357.2093811035156, Entropy -320.39288330078125, Learning Rate: 0.0025\n",
      "Epoch [1388/20000], Loss: 383.1354064941406, Entropy -350.19744873046875, Learning Rate: 0.0025\n",
      "Epoch [1389/20000], Loss: 353.54351806640625, Entropy -329.8173522949219, Learning Rate: 0.0025\n",
      "Epoch [1390/20000], Loss: 373.466064453125, Entropy -343.12579345703125, Learning Rate: 0.0025\n",
      "Epoch [1391/20000], Loss: 382.09942626953125, Entropy -330.5645446777344, Learning Rate: 0.0025\n",
      "Epoch [1392/20000], Loss: 348.38079833984375, Entropy -317.7447814941406, Learning Rate: 0.0025\n",
      "Epoch [1393/20000], Loss: 344.93560791015625, Entropy -324.2769775390625, Learning Rate: 0.0025\n",
      "Epoch [1394/20000], Loss: 355.7257080078125, Entropy -309.8301086425781, Learning Rate: 0.0025\n",
      "Epoch [1395/20000], Loss: 375.92974853515625, Entropy -326.0316162109375, Learning Rate: 0.0025\n",
      "Epoch [1396/20000], Loss: 367.49444580078125, Entropy -335.240234375, Learning Rate: 0.0025\n",
      "Epoch [1397/20000], Loss: 355.3676452636719, Entropy -322.44915771484375, Learning Rate: 0.0025\n",
      "Epoch [1398/20000], Loss: 372.70037841796875, Entropy -326.45098876953125, Learning Rate: 0.0025\n",
      "Epoch [1399/20000], Loss: 342.20538330078125, Entropy -320.459716796875, Learning Rate: 0.0025\n",
      "Epoch [1400/20000], Loss: 334.8780517578125, Entropy -311.3158264160156, Learning Rate: 0.0025\n",
      "Epoch [1401/20000], Loss: 353.404541015625, Entropy -329.7135314941406, Learning Rate: 0.0025\n",
      "Epoch [1402/20000], Loss: 352.7049560546875, Entropy -329.69061279296875, Learning Rate: 0.0025\n",
      "Epoch [1403/20000], Loss: 370.8180847167969, Entropy -328.2607727050781, Learning Rate: 0.0025\n",
      "Epoch [1404/20000], Loss: 346.64727783203125, Entropy -315.5325622558594, Learning Rate: 0.0025\n",
      "Epoch [1405/20000], Loss: 342.02923583984375, Entropy -333.9900207519531, Learning Rate: 0.0025\n",
      "Epoch [1406/20000], Loss: 345.48828125, Entropy -325.0457458496094, Learning Rate: 0.0025\n",
      "Epoch [1407/20000], Loss: 332.1817321777344, Entropy -306.4924011230469, Learning Rate: 0.0025\n",
      "Epoch [1408/20000], Loss: 335.6019287109375, Entropy -328.09088134765625, Learning Rate: 0.0025\n",
      "Epoch [1409/20000], Loss: 345.602294921875, Entropy -319.8509216308594, Learning Rate: 0.0025\n",
      "Epoch [1410/20000], Loss: 342.21612548828125, Entropy -330.9494934082031, Learning Rate: 0.0025\n",
      "Epoch [1411/20000], Loss: 344.3963623046875, Entropy -314.3828125, Learning Rate: 0.0025\n",
      "Epoch [1412/20000], Loss: 341.0455322265625, Entropy -328.8124694824219, Learning Rate: 0.0025\n",
      "Epoch [1413/20000], Loss: 356.0742492675781, Entropy -329.87359619140625, Learning Rate: 0.0025\n",
      "Epoch [1414/20000], Loss: 356.49102783203125, Entropy -323.9607849121094, Learning Rate: 0.0025\n",
      "Epoch [1415/20000], Loss: 334.22088623046875, Entropy -312.2970275878906, Learning Rate: 0.0025\n",
      "Epoch [1416/20000], Loss: 342.56439208984375, Entropy -323.296630859375, Learning Rate: 0.0025\n",
      "Epoch [1417/20000], Loss: 339.2398681640625, Entropy -318.32379150390625, Learning Rate: 0.0025\n",
      "Epoch [1418/20000], Loss: 339.6287536621094, Entropy -323.2314453125, Learning Rate: 0.0025\n",
      "Epoch [1419/20000], Loss: 334.46771240234375, Entropy -309.5511779785156, Learning Rate: 0.0025\n",
      "Epoch [1420/20000], Loss: 341.33935546875, Entropy -315.92864990234375, Learning Rate: 0.0025\n",
      "Epoch [1421/20000], Loss: 347.5772705078125, Entropy -319.8298645019531, Learning Rate: 0.0025\n",
      "Epoch [1422/20000], Loss: 351.39501953125, Entropy -318.96722412109375, Learning Rate: 0.0025\n",
      "Epoch [1423/20000], Loss: 331.17108154296875, Entropy -315.4047546386719, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1424/20000], Loss: 346.50299072265625, Entropy -312.41986083984375, Learning Rate: 0.0025\n",
      "Epoch [1425/20000], Loss: 345.0167236328125, Entropy -328.9991149902344, Learning Rate: 0.0025\n",
      "Epoch [1426/20000], Loss: 335.78076171875, Entropy -311.3630676269531, Learning Rate: 0.0025\n",
      "Epoch [1427/20000], Loss: 343.1336669921875, Entropy -325.3157043457031, Learning Rate: 0.0025\n",
      "Epoch [1428/20000], Loss: 357.55963134765625, Entropy -331.4097595214844, Learning Rate: 0.0025\n",
      "Epoch [1429/20000], Loss: 336.0929260253906, Entropy -315.85174560546875, Learning Rate: 0.0025\n",
      "Epoch [1430/20000], Loss: 344.6307373046875, Entropy -338.80560302734375, Learning Rate: 0.0025\n",
      "Epoch [1431/20000], Loss: 359.58209228515625, Entropy -338.182373046875, Learning Rate: 0.0025\n",
      "Epoch [1432/20000], Loss: 338.76934814453125, Entropy -321.9943542480469, Learning Rate: 0.0025\n",
      "Epoch [1433/20000], Loss: 348.6514892578125, Entropy -318.3639831542969, Learning Rate: 0.0025\n",
      "Epoch [1434/20000], Loss: 348.6404724121094, Entropy -333.18609619140625, Learning Rate: 0.0025\n",
      "Epoch [1435/20000], Loss: 345.5980529785156, Entropy -319.9679870605469, Learning Rate: 0.0025\n",
      "Epoch [1436/20000], Loss: 332.9906005859375, Entropy -306.8647155761719, Learning Rate: 0.0025\n",
      "Epoch [1437/20000], Loss: 325.2802734375, Entropy -319.41571044921875, Learning Rate: 0.0025\n",
      "Epoch [1438/20000], Loss: 343.8961181640625, Entropy -315.5126647949219, Learning Rate: 0.0025\n",
      "Epoch [1439/20000], Loss: 355.97637939453125, Entropy -333.468505859375, Learning Rate: 0.0025\n",
      "Epoch [1440/20000], Loss: 354.8402099609375, Entropy -327.2076416015625, Learning Rate: 0.0025\n",
      "Epoch [1441/20000], Loss: 336.2134094238281, Entropy -322.9972839355469, Learning Rate: 0.0025\n",
      "Epoch [1442/20000], Loss: 346.80108642578125, Entropy -315.9560241699219, Learning Rate: 0.0025\n",
      "Epoch [1443/20000], Loss: 336.15802001953125, Entropy -328.8540344238281, Learning Rate: 0.0025\n",
      "Epoch [1444/20000], Loss: 350.83612060546875, Entropy -331.6424865722656, Learning Rate: 0.0025\n",
      "Epoch [1445/20000], Loss: 343.0528869628906, Entropy -322.1819152832031, Learning Rate: 0.0025\n",
      "Epoch [1446/20000], Loss: 339.28076171875, Entropy -312.78204345703125, Learning Rate: 0.0025\n",
      "Epoch [1447/20000], Loss: 352.7033996582031, Entropy -329.8643798828125, Learning Rate: 0.0025\n",
      "Epoch [1448/20000], Loss: 339.1574401855469, Entropy -316.866455078125, Learning Rate: 0.0025\n",
      "Epoch [1449/20000], Loss: 334.1307373046875, Entropy -310.6443786621094, Learning Rate: 0.0025\n",
      "Epoch [1450/20000], Loss: 338.58966064453125, Entropy -321.1715393066406, Learning Rate: 0.0025\n",
      "Epoch [1451/20000], Loss: 325.35992431640625, Entropy -296.57171630859375, Learning Rate: 0.0025\n",
      "Epoch [1452/20000], Loss: 341.5908203125, Entropy -321.693359375, Learning Rate: 0.0025\n",
      "Epoch [1453/20000], Loss: 360.32635498046875, Entropy -334.7037353515625, Learning Rate: 0.0025\n",
      "Epoch [1454/20000], Loss: 341.56072998046875, Entropy -322.2911682128906, Learning Rate: 0.0025\n",
      "Epoch [1455/20000], Loss: 355.0754089355469, Entropy -331.24481201171875, Learning Rate: 0.0025\n",
      "Epoch [1456/20000], Loss: 337.0301513671875, Entropy -315.3343200683594, Learning Rate: 0.0025\n",
      "Epoch [1457/20000], Loss: 328.6861572265625, Entropy -321.7247009277344, Learning Rate: 0.0025\n",
      "Epoch [1458/20000], Loss: 338.09271240234375, Entropy -322.3665771484375, Learning Rate: 0.0025\n",
      "Epoch [1459/20000], Loss: 337.9805908203125, Entropy -316.4347839355469, Learning Rate: 0.0025\n",
      "Epoch [1460/20000], Loss: 366.50628662109375, Entropy -338.0404052734375, Learning Rate: 0.0025\n",
      "Epoch [1461/20000], Loss: 340.28900146484375, Entropy -316.9732360839844, Learning Rate: 0.0025\n",
      "Epoch [1462/20000], Loss: 350.9571533203125, Entropy -337.996826171875, Learning Rate: 0.0025\n",
      "Epoch [1463/20000], Loss: 335.4221496582031, Entropy -316.59521484375, Learning Rate: 0.0025\n",
      "Epoch [1464/20000], Loss: 352.4823303222656, Entropy -336.8565368652344, Learning Rate: 0.0025\n",
      "Epoch [1465/20000], Loss: 331.470947265625, Entropy -300.9698486328125, Learning Rate: 0.0025\n",
      "Epoch [1466/20000], Loss: 329.3912658691406, Entropy -319.33526611328125, Learning Rate: 0.0025\n",
      "Epoch [1467/20000], Loss: 336.7677001953125, Entropy -306.9548034667969, Learning Rate: 0.0025\n",
      "Epoch [1468/20000], Loss: 354.21527099609375, Entropy -314.19281005859375, Learning Rate: 0.0025\n",
      "Epoch [1469/20000], Loss: 410.8599853515625, Entropy -329.3634033203125, Learning Rate: 0.0025\n",
      "Epoch [1470/20000], Loss: 354.5556640625, Entropy -327.3473815917969, Learning Rate: 0.0025\n",
      "Epoch [1471/20000], Loss: 345.25811767578125, Entropy -320.6776428222656, Learning Rate: 0.0025\n",
      "Epoch [1472/20000], Loss: 353.6474609375, Entropy -320.5489807128906, Learning Rate: 0.0025\n",
      "Epoch [1473/20000], Loss: 370.5331115722656, Entropy -334.6899719238281, Learning Rate: 0.0025\n",
      "Epoch [1474/20000], Loss: 336.81903076171875, Entropy -321.25677490234375, Learning Rate: 0.0025\n",
      "Epoch [1475/20000], Loss: 321.99420166015625, Entropy -316.22674560546875, Learning Rate: 0.0025\n",
      "Epoch [1476/20000], Loss: 343.8934326171875, Entropy -321.2450256347656, Learning Rate: 0.0025\n",
      "Epoch [1477/20000], Loss: 355.81329345703125, Entropy -329.8471984863281, Learning Rate: 0.0025\n",
      "Epoch [1478/20000], Loss: 336.52862548828125, Entropy -325.6274719238281, Learning Rate: 0.0025\n",
      "Epoch [1479/20000], Loss: 346.875244140625, Entropy -320.3056945800781, Learning Rate: 0.0025\n",
      "Epoch [1480/20000], Loss: 363.13861083984375, Entropy -333.85076904296875, Learning Rate: 0.0025\n",
      "Epoch [1481/20000], Loss: 354.8951416015625, Entropy -330.8372497558594, Learning Rate: 0.0025\n",
      "Epoch [1482/20000], Loss: 343.51910400390625, Entropy -322.48565673828125, Learning Rate: 0.0025\n",
      "Epoch [1483/20000], Loss: 339.78741455078125, Entropy -314.0019836425781, Learning Rate: 0.0025\n",
      "Epoch [1484/20000], Loss: 324.0194091796875, Entropy -300.5602722167969, Learning Rate: 0.0025\n",
      "Epoch [1485/20000], Loss: 354.76434326171875, Entropy -326.6973876953125, Learning Rate: 0.0025\n",
      "Epoch [1486/20000], Loss: 326.4371337890625, Entropy -311.88446044921875, Learning Rate: 0.0025\n",
      "Epoch [1487/20000], Loss: 340.619873046875, Entropy -322.7452392578125, Learning Rate: 0.0025\n",
      "Epoch [1488/20000], Loss: 348.2882080078125, Entropy -323.83721923828125, Learning Rate: 0.0025\n",
      "Epoch [1489/20000], Loss: 357.2694091796875, Entropy -331.6072998046875, Learning Rate: 0.0025\n",
      "Epoch [1490/20000], Loss: 335.040771484375, Entropy -311.8705749511719, Learning Rate: 0.0025\n",
      "Epoch [1491/20000], Loss: 344.8497009277344, Entropy -322.31524658203125, Learning Rate: 0.0025\n",
      "Epoch [1492/20000], Loss: 346.91961669921875, Entropy -327.9280090332031, Learning Rate: 0.0025\n",
      "Epoch [1493/20000], Loss: 353.96209716796875, Entropy -333.9984130859375, Learning Rate: 0.0025\n",
      "Epoch [1494/20000], Loss: 343.6188049316406, Entropy -335.6677551269531, Learning Rate: 0.0025\n",
      "Epoch [1495/20000], Loss: 348.56475830078125, Entropy -329.1980285644531, Learning Rate: 0.0025\n",
      "Epoch [1496/20000], Loss: 374.0619201660156, Entropy -336.51373291015625, Learning Rate: 0.0025\n",
      "Epoch [1497/20000], Loss: 360.0642395019531, Entropy -338.91082763671875, Learning Rate: 0.0025\n",
      "Epoch [1498/20000], Loss: 332.0479736328125, Entropy -318.5984802246094, Learning Rate: 0.0025\n",
      "Epoch [1499/20000], Loss: 355.368408203125, Entropy -329.2235412597656, Learning Rate: 0.0025\n",
      "Epoch [1500/20000], Loss: 331.654296875, Entropy -312.0953369140625, Learning Rate: 0.0025\n",
      "Epoch [1501/20000], Loss: 338.1640625, Entropy -315.42291259765625, Learning Rate: 0.0025\n",
      "Epoch [1502/20000], Loss: 345.84027099609375, Entropy -325.1694030761719, Learning Rate: 0.0025\n",
      "Epoch [1503/20000], Loss: 346.97265625, Entropy -335.0870056152344, Learning Rate: 0.0025\n",
      "Epoch [1504/20000], Loss: 357.913330078125, Entropy -329.8804626464844, Learning Rate: 0.0025\n",
      "Epoch [1505/20000], Loss: 345.1476745605469, Entropy -336.0693664550781, Learning Rate: 0.0025\n",
      "Epoch [1506/20000], Loss: 342.55352783203125, Entropy -328.6754150390625, Learning Rate: 0.0025\n",
      "Epoch [1507/20000], Loss: 343.41778564453125, Entropy -297.2825622558594, Learning Rate: 0.0025\n",
      "Epoch [1508/20000], Loss: 334.3284912109375, Entropy -321.6481628417969, Learning Rate: 0.0025\n",
      "Epoch [1509/20000], Loss: 333.3341064453125, Entropy -323.1149597167969, Learning Rate: 0.0025\n",
      "Epoch [1510/20000], Loss: 359.17999267578125, Entropy -340.0974426269531, Learning Rate: 0.0025\n",
      "Epoch [1511/20000], Loss: 341.958984375, Entropy -321.33685302734375, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1512/20000], Loss: 362.15185546875, Entropy -348.715576171875, Learning Rate: 0.0025\n",
      "Epoch [1513/20000], Loss: 347.673828125, Entropy -321.37384033203125, Learning Rate: 0.0025\n",
      "Epoch [1514/20000], Loss: 348.71630859375, Entropy -320.70648193359375, Learning Rate: 0.0025\n",
      "Epoch [1515/20000], Loss: 328.2257385253906, Entropy -303.759521484375, Learning Rate: 0.0025\n",
      "Epoch [1516/20000], Loss: 346.21588134765625, Entropy -320.339599609375, Learning Rate: 0.0025\n",
      "Epoch [1517/20000], Loss: 344.15325927734375, Entropy -323.7312316894531, Learning Rate: 0.0025\n",
      "Epoch [1518/20000], Loss: 350.9358215332031, Entropy -331.3348388671875, Learning Rate: 0.0025\n",
      "Epoch [1519/20000], Loss: 351.42535400390625, Entropy -328.5552673339844, Learning Rate: 0.0025\n",
      "Epoch [1520/20000], Loss: 349.82244873046875, Entropy -329.87261962890625, Learning Rate: 0.0025\n",
      "Epoch [1521/20000], Loss: 336.0498352050781, Entropy -326.5588684082031, Learning Rate: 0.0025\n",
      "Epoch [1522/20000], Loss: 369.921142578125, Entropy -347.07684326171875, Learning Rate: 0.0025\n",
      "Epoch [1523/20000], Loss: 337.1930236816406, Entropy -309.5234069824219, Learning Rate: 0.0025\n",
      "Epoch [1524/20000], Loss: 339.7452392578125, Entropy -314.152099609375, Learning Rate: 0.0025\n",
      "Epoch [1525/20000], Loss: 323.91436767578125, Entropy -299.7410888671875, Learning Rate: 0.0025\n",
      "Epoch [1526/20000], Loss: 345.364990234375, Entropy -341.092041015625, Learning Rate: 0.0025\n",
      "Epoch [1527/20000], Loss: 365.2916564941406, Entropy -339.1324768066406, Learning Rate: 0.0025\n",
      "Epoch [1528/20000], Loss: 345.0897216796875, Entropy -321.3489990234375, Learning Rate: 0.0025\n",
      "Epoch [1529/20000], Loss: 331.28167724609375, Entropy -318.3221740722656, Learning Rate: 0.0025\n",
      "Epoch [1530/20000], Loss: 339.55450439453125, Entropy -312.7171936035156, Learning Rate: 0.0025\n",
      "Epoch [1531/20000], Loss: 343.3612060546875, Entropy -325.1796569824219, Learning Rate: 0.0025\n",
      "Epoch [1532/20000], Loss: 345.3209533691406, Entropy -325.842041015625, Learning Rate: 0.0025\n",
      "Epoch [1533/20000], Loss: 353.3594970703125, Entropy -334.2344665527344, Learning Rate: 0.0025\n",
      "Epoch [1534/20000], Loss: 368.39697265625, Entropy -336.0897216796875, Learning Rate: 0.0025\n",
      "Epoch [1535/20000], Loss: 343.0177001953125, Entropy -320.03765869140625, Learning Rate: 0.0025\n",
      "Epoch [1536/20000], Loss: 324.592041015625, Entropy -315.4194030761719, Learning Rate: 0.0025\n",
      "Epoch [1537/20000], Loss: 346.5738525390625, Entropy -319.7693176269531, Learning Rate: 0.0025\n",
      "Epoch [1538/20000], Loss: 363.1432189941406, Entropy -332.8149108886719, Learning Rate: 0.0025\n",
      "Epoch [1539/20000], Loss: 352.7076110839844, Entropy -324.6774597167969, Learning Rate: 0.0025\n",
      "Epoch [1540/20000], Loss: 337.13250732421875, Entropy -316.3402404785156, Learning Rate: 0.0025\n",
      "Epoch [1541/20000], Loss: 345.820068359375, Entropy -321.4732666015625, Learning Rate: 0.0025\n",
      "Epoch [1542/20000], Loss: 331.3771057128906, Entropy -310.1913146972656, Learning Rate: 0.0025\n",
      "Epoch [1543/20000], Loss: 345.66839599609375, Entropy -324.8014221191406, Learning Rate: 0.0025\n",
      "Epoch [1544/20000], Loss: 345.0496520996094, Entropy -331.00042724609375, Learning Rate: 0.0025\n",
      "Epoch [1545/20000], Loss: 356.12286376953125, Entropy -335.7765808105469, Learning Rate: 0.0025\n",
      "Epoch [1546/20000], Loss: 339.258544921875, Entropy -323.6949462890625, Learning Rate: 0.0025\n",
      "Epoch [1547/20000], Loss: 349.37603759765625, Entropy -321.9365234375, Learning Rate: 0.0025\n",
      "Epoch [1548/20000], Loss: 350.5, Entropy -328.2334899902344, Learning Rate: 0.0025\n",
      "Epoch [1549/20000], Loss: 342.10455322265625, Entropy -323.856201171875, Learning Rate: 0.0025\n",
      "Epoch [1550/20000], Loss: 349.8701171875, Entropy -329.28277587890625, Learning Rate: 0.0025\n",
      "Epoch [1551/20000], Loss: 343.28497314453125, Entropy -316.67706298828125, Learning Rate: 0.0025\n",
      "Epoch [1552/20000], Loss: 339.1845397949219, Entropy -328.61883544921875, Learning Rate: 0.0025\n",
      "Epoch [1553/20000], Loss: 338.968017578125, Entropy -313.1246032714844, Learning Rate: 0.0025\n",
      "Epoch [1554/20000], Loss: 330.48907470703125, Entropy -305.2727966308594, Learning Rate: 0.0025\n",
      "Epoch [1555/20000], Loss: 313.03631591796875, Entropy -306.62109375, Learning Rate: 0.0025\n",
      "Epoch [1556/20000], Loss: 343.91571044921875, Entropy -317.1422119140625, Learning Rate: 0.0025\n",
      "Epoch [1557/20000], Loss: 341.3937683105469, Entropy -311.52032470703125, Learning Rate: 0.0025\n",
      "Epoch [1558/20000], Loss: 341.8701477050781, Entropy -322.15216064453125, Learning Rate: 0.0025\n",
      "Epoch [1559/20000], Loss: 338.96002197265625, Entropy -327.685302734375, Learning Rate: 0.0025\n",
      "Epoch [1560/20000], Loss: 335.1575622558594, Entropy -320.3004150390625, Learning Rate: 0.0025\n",
      "Epoch [1561/20000], Loss: 327.1134338378906, Entropy -306.8969421386719, Learning Rate: 0.0025\n",
      "Epoch [1562/20000], Loss: 345.3194580078125, Entropy -329.3900146484375, Learning Rate: 0.0025\n",
      "Epoch [1563/20000], Loss: 352.4949645996094, Entropy -335.7130432128906, Learning Rate: 0.0025\n",
      "Epoch [1564/20000], Loss: 341.39202880859375, Entropy -315.2317810058594, Learning Rate: 0.0025\n",
      "Epoch [1565/20000], Loss: 338.496337890625, Entropy -315.6770935058594, Learning Rate: 0.0025\n",
      "Epoch [1566/20000], Loss: 336.47308349609375, Entropy -308.5758972167969, Learning Rate: 0.0025\n",
      "Epoch [1567/20000], Loss: 341.02593994140625, Entropy -304.0490417480469, Learning Rate: 0.0025\n",
      "Epoch [1568/20000], Loss: 352.3740234375, Entropy -327.5728454589844, Learning Rate: 0.0025\n",
      "Epoch [1569/20000], Loss: 347.14691162109375, Entropy -330.65606689453125, Learning Rate: 0.0025\n",
      "Epoch [1570/20000], Loss: 373.4865417480469, Entropy -329.21905517578125, Learning Rate: 0.0025\n",
      "Epoch [1571/20000], Loss: 335.76422119140625, Entropy -320.02984619140625, Learning Rate: 0.0025\n",
      "Epoch [1572/20000], Loss: 362.85626220703125, Entropy -335.37945556640625, Learning Rate: 0.0025\n",
      "Epoch [1573/20000], Loss: 329.81201171875, Entropy -312.5202941894531, Learning Rate: 0.0025\n",
      "Epoch [1574/20000], Loss: 348.1173400878906, Entropy -333.5707702636719, Learning Rate: 0.0025\n",
      "Epoch [1575/20000], Loss: 339.45880126953125, Entropy -319.8056335449219, Learning Rate: 0.0025\n",
      "Epoch [1576/20000], Loss: 331.94952392578125, Entropy -326.7378234863281, Learning Rate: 0.0025\n",
      "Epoch [1577/20000], Loss: 375.0101318359375, Entropy -351.9832458496094, Learning Rate: 0.0025\n",
      "Epoch [1578/20000], Loss: 360.4771728515625, Entropy -330.7559509277344, Learning Rate: 0.0025\n",
      "Epoch [1579/20000], Loss: 338.3271789550781, Entropy -317.42425537109375, Learning Rate: 0.0025\n",
      "Epoch [1580/20000], Loss: 357.1385498046875, Entropy -322.5846862792969, Learning Rate: 0.0025\n",
      "Epoch [1581/20000], Loss: 338.35760498046875, Entropy -318.3836975097656, Learning Rate: 0.0025\n",
      "Epoch [1582/20000], Loss: 345.618408203125, Entropy -325.985107421875, Learning Rate: 0.0025\n",
      "Epoch [1583/20000], Loss: 373.4374084472656, Entropy -328.0069274902344, Learning Rate: 0.0025\n",
      "Epoch [1584/20000], Loss: 335.61322021484375, Entropy -306.1855773925781, Learning Rate: 0.0025\n",
      "Epoch [1585/20000], Loss: 330.72601318359375, Entropy -311.659912109375, Learning Rate: 0.0025\n",
      "Epoch [1586/20000], Loss: 341.6177978515625, Entropy -321.92950439453125, Learning Rate: 0.0025\n",
      "Epoch [1587/20000], Loss: 338.55853271484375, Entropy -313.9023742675781, Learning Rate: 0.0025\n",
      "Epoch [1588/20000], Loss: 349.7784423828125, Entropy -330.73834228515625, Learning Rate: 0.0025\n",
      "Epoch [1589/20000], Loss: 339.82342529296875, Entropy -311.71417236328125, Learning Rate: 0.0025\n",
      "Epoch [1590/20000], Loss: 329.0122375488281, Entropy -314.0880126953125, Learning Rate: 0.0025\n",
      "Epoch [1591/20000], Loss: 340.237548828125, Entropy -331.30096435546875, Learning Rate: 0.0025\n",
      "Epoch [1592/20000], Loss: 327.7853088378906, Entropy -306.65032958984375, Learning Rate: 0.0025\n",
      "Epoch [1593/20000], Loss: 326.0677490234375, Entropy -316.6913146972656, Learning Rate: 0.0025\n",
      "Epoch [1594/20000], Loss: 335.60028076171875, Entropy -309.86004638671875, Learning Rate: 0.0025\n",
      "Epoch [1595/20000], Loss: 339.9520568847656, Entropy -325.52703857421875, Learning Rate: 0.0025\n",
      "Epoch [1596/20000], Loss: 349.1050109863281, Entropy -329.04083251953125, Learning Rate: 0.0025\n",
      "Epoch [1597/20000], Loss: 388.08721923828125, Entropy -332.91741943359375, Learning Rate: 0.0025\n",
      "Epoch [1598/20000], Loss: 353.48406982421875, Entropy -328.355712890625, Learning Rate: 0.0025\n",
      "Epoch [1599/20000], Loss: 332.63995361328125, Entropy -311.1565856933594, Learning Rate: 0.0025\n",
      "Epoch [1600/20000], Loss: 370.72027587890625, Entropy -332.5370788574219, Learning Rate: 0.0025\n",
      "Epoch [1601/20000], Loss: 340.9773864746094, Entropy -322.938232421875, Learning Rate: 0.0025\n",
      "Epoch [1602/20000], Loss: 340.76934814453125, Entropy -318.1278381347656, Learning Rate: 0.0025\n",
      "Epoch [1603/20000], Loss: 348.7588806152344, Entropy -338.0404052734375, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1604/20000], Loss: 350.51678466796875, Entropy -333.5097961425781, Learning Rate: 0.0025\n",
      "Epoch [1605/20000], Loss: 330.98712158203125, Entropy -317.0921325683594, Learning Rate: 0.0025\n",
      "Epoch [1606/20000], Loss: 329.59710693359375, Entropy -310.8451843261719, Learning Rate: 0.0025\n",
      "Epoch [1607/20000], Loss: 353.86676025390625, Entropy -326.10198974609375, Learning Rate: 0.0025\n",
      "Epoch [1608/20000], Loss: 322.76904296875, Entropy -304.6676330566406, Learning Rate: 0.0025\n",
      "Epoch [1609/20000], Loss: 361.47735595703125, Entropy -321.97998046875, Learning Rate: 0.0025\n",
      "Epoch [1610/20000], Loss: 352.3451843261719, Entropy -343.1618957519531, Learning Rate: 0.0025\n",
      "Epoch [1611/20000], Loss: 352.3868713378906, Entropy -329.2967529296875, Learning Rate: 0.0025\n",
      "Epoch [1612/20000], Loss: 347.16265869140625, Entropy -316.0926208496094, Learning Rate: 0.0025\n",
      "Epoch [1613/20000], Loss: 340.16326904296875, Entropy -324.6224365234375, Learning Rate: 0.0025\n",
      "Epoch [1614/20000], Loss: 338.07366943359375, Entropy -319.1416320800781, Learning Rate: 0.0025\n",
      "Epoch [1615/20000], Loss: 335.0357666015625, Entropy -321.69842529296875, Learning Rate: 0.0025\n",
      "Epoch [1616/20000], Loss: 382.33270263671875, Entropy -310.3887023925781, Learning Rate: 0.0025\n",
      "Epoch [1617/20000], Loss: 360.0269775390625, Entropy -326.4443054199219, Learning Rate: 0.0025\n",
      "Epoch [1618/20000], Loss: 342.9766845703125, Entropy -313.0321044921875, Learning Rate: 0.0025\n",
      "Epoch [1619/20000], Loss: 329.55743408203125, Entropy -304.9461364746094, Learning Rate: 0.0025\n",
      "Epoch [1620/20000], Loss: 352.9596862792969, Entropy -329.444580078125, Learning Rate: 0.0025\n",
      "Epoch [1621/20000], Loss: 353.6007385253906, Entropy -343.16253662109375, Learning Rate: 0.0025\n",
      "Epoch [1622/20000], Loss: 316.65313720703125, Entropy -294.8643798828125, Learning Rate: 0.0025\n",
      "Epoch [1623/20000], Loss: 341.90728759765625, Entropy -316.46856689453125, Learning Rate: 0.0025\n",
      "Epoch [1624/20000], Loss: 322.7822570800781, Entropy -304.8794860839844, Learning Rate: 0.0025\n",
      "Epoch [1625/20000], Loss: 341.2509765625, Entropy -318.2881164550781, Learning Rate: 0.0025\n",
      "Epoch [1626/20000], Loss: 336.5464782714844, Entropy -316.20379638671875, Learning Rate: 0.0025\n",
      "Epoch [1627/20000], Loss: 344.3997802734375, Entropy -320.01995849609375, Learning Rate: 0.0025\n",
      "Epoch [1628/20000], Loss: 333.63104248046875, Entropy -314.6278076171875, Learning Rate: 0.0025\n",
      "Epoch [1629/20000], Loss: 356.78857421875, Entropy -326.1631164550781, Learning Rate: 0.0025\n",
      "Epoch [1630/20000], Loss: 339.51995849609375, Entropy -323.16534423828125, Learning Rate: 0.0025\n",
      "Epoch [1631/20000], Loss: 342.67938232421875, Entropy -329.27862548828125, Learning Rate: 0.0025\n",
      "Epoch [1632/20000], Loss: 319.184326171875, Entropy -306.4669494628906, Learning Rate: 0.0025\n",
      "Epoch [1633/20000], Loss: 332.3587646484375, Entropy -312.6305236816406, Learning Rate: 0.0025\n",
      "Epoch [1634/20000], Loss: 357.8028564453125, Entropy -337.50689697265625, Learning Rate: 0.0025\n",
      "Epoch [1635/20000], Loss: 333.5329284667969, Entropy -307.5728454589844, Learning Rate: 0.0025\n",
      "Epoch [1636/20000], Loss: 315.98046875, Entropy -299.8988342285156, Learning Rate: 0.0025\n",
      "Epoch [1637/20000], Loss: 340.7542419433594, Entropy -321.060302734375, Learning Rate: 0.0025\n",
      "Epoch [1638/20000], Loss: 350.0320129394531, Entropy -333.138916015625, Learning Rate: 0.0025\n",
      "Epoch [1639/20000], Loss: 327.0169677734375, Entropy -311.36297607421875, Learning Rate: 0.0025\n",
      "Epoch [1640/20000], Loss: 346.2212829589844, Entropy -328.02294921875, Learning Rate: 0.0025\n",
      "Epoch [1641/20000], Loss: 347.295166015625, Entropy -325.6900939941406, Learning Rate: 0.0025\n",
      "Epoch [1642/20000], Loss: 355.2552490234375, Entropy -329.1181945800781, Learning Rate: 0.0025\n",
      "Epoch [1643/20000], Loss: 350.765625, Entropy -334.52593994140625, Learning Rate: 0.0025\n",
      "Epoch [1644/20000], Loss: 332.7470703125, Entropy -315.2621765136719, Learning Rate: 0.0025\n",
      "Epoch [1645/20000], Loss: 337.656005859375, Entropy -320.8994445800781, Learning Rate: 0.0025\n",
      "Epoch [1646/20000], Loss: 337.42584228515625, Entropy -309.06207275390625, Learning Rate: 0.0025\n",
      "Epoch [1647/20000], Loss: 336.2403259277344, Entropy -314.063232421875, Learning Rate: 0.0025\n",
      "Epoch [1648/20000], Loss: 343.4351501464844, Entropy -303.7745056152344, Learning Rate: 0.0025\n",
      "Epoch [1649/20000], Loss: 352.6451721191406, Entropy -331.32232666015625, Learning Rate: 0.0025\n",
      "Epoch [1650/20000], Loss: 337.39599609375, Entropy -318.4549255371094, Learning Rate: 0.0025\n",
      "Epoch [1651/20000], Loss: 332.8829345703125, Entropy -315.7370910644531, Learning Rate: 0.0025\n",
      "Epoch [1652/20000], Loss: 338.3946533203125, Entropy -324.7843017578125, Learning Rate: 0.0025\n",
      "Epoch [1653/20000], Loss: 329.99127197265625, Entropy -319.82464599609375, Learning Rate: 0.0025\n",
      "Epoch [1654/20000], Loss: 336.77203369140625, Entropy -304.1849365234375, Learning Rate: 0.0025\n",
      "Epoch [1655/20000], Loss: 346.09515380859375, Entropy -315.7244567871094, Learning Rate: 0.0025\n",
      "Epoch [1656/20000], Loss: 335.0816650390625, Entropy -316.3349304199219, Learning Rate: 0.0025\n",
      "Epoch [1657/20000], Loss: 346.6337890625, Entropy -332.91632080078125, Learning Rate: 0.0025\n",
      "Epoch [1658/20000], Loss: 328.4884338378906, Entropy -314.2584533691406, Learning Rate: 0.0025\n",
      "Epoch [1659/20000], Loss: 335.80401611328125, Entropy -322.92987060546875, Learning Rate: 0.0025\n",
      "Epoch [1660/20000], Loss: 348.1110534667969, Entropy -313.0167541503906, Learning Rate: 0.0025\n",
      "Epoch [1661/20000], Loss: 323.136474609375, Entropy -302.4918212890625, Learning Rate: 0.0025\n",
      "Epoch [1662/20000], Loss: 320.82086181640625, Entropy -311.85394287109375, Learning Rate: 0.0025\n",
      "Epoch [1663/20000], Loss: 328.6883544921875, Entropy -313.37408447265625, Learning Rate: 0.0025\n",
      "Epoch [1664/20000], Loss: 365.16693115234375, Entropy -328.15692138671875, Learning Rate: 0.0025\n",
      "Epoch [1665/20000], Loss: 343.59521484375, Entropy -316.7053527832031, Learning Rate: 0.0025\n",
      "Epoch [1666/20000], Loss: 345.4321594238281, Entropy -307.3656921386719, Learning Rate: 0.0025\n",
      "Epoch [1667/20000], Loss: 339.6759948730469, Entropy -315.8647155761719, Learning Rate: 0.0025\n",
      "Epoch [1668/20000], Loss: 341.2992858886719, Entropy -315.30096435546875, Learning Rate: 0.0025\n",
      "Epoch [1669/20000], Loss: 356.2732849121094, Entropy -330.18377685546875, Learning Rate: 0.0025\n",
      "Epoch [1670/20000], Loss: 357.62884521484375, Entropy -321.6636962890625, Learning Rate: 0.0025\n",
      "Epoch [1671/20000], Loss: 337.97705078125, Entropy -323.66845703125, Learning Rate: 0.0025\n",
      "Epoch [1672/20000], Loss: 354.3523254394531, Entropy -315.4526672363281, Learning Rate: 0.0025\n",
      "Epoch [1673/20000], Loss: 368.64459228515625, Entropy -333.6353454589844, Learning Rate: 0.0025\n",
      "Epoch [1674/20000], Loss: 338.40411376953125, Entropy -324.982666015625, Learning Rate: 0.0025\n",
      "Epoch [1675/20000], Loss: 346.371337890625, Entropy -330.8201599121094, Learning Rate: 0.0025\n",
      "Epoch [1676/20000], Loss: 334.87408447265625, Entropy -316.2083740234375, Learning Rate: 0.0025\n",
      "Epoch [1677/20000], Loss: 339.79486083984375, Entropy -311.919921875, Learning Rate: 0.0025\n",
      "Epoch [1678/20000], Loss: 332.02587890625, Entropy -309.6562805175781, Learning Rate: 0.0025\n",
      "Epoch [1679/20000], Loss: 353.2906494140625, Entropy -328.3769836425781, Learning Rate: 0.0025\n",
      "Epoch [1680/20000], Loss: 342.1912841796875, Entropy -314.9569396972656, Learning Rate: 0.0025\n",
      "Epoch [1681/20000], Loss: 347.37335205078125, Entropy -313.9895935058594, Learning Rate: 0.0025\n",
      "Epoch [1682/20000], Loss: 337.70806884765625, Entropy -314.8041687011719, Learning Rate: 0.0025\n",
      "Epoch [1683/20000], Loss: 338.5262451171875, Entropy -324.01837158203125, Learning Rate: 0.0025\n",
      "Epoch [1684/20000], Loss: 351.238525390625, Entropy -330.35479736328125, Learning Rate: 0.0025\n",
      "Epoch [1685/20000], Loss: 344.7298278808594, Entropy -316.5617980957031, Learning Rate: 0.0025\n",
      "Epoch [1686/20000], Loss: 328.55145263671875, Entropy -322.3414001464844, Learning Rate: 0.0025\n",
      "Epoch [1687/20000], Loss: 327.2337341308594, Entropy -315.5743408203125, Learning Rate: 0.0025\n",
      "Epoch [1688/20000], Loss: 344.0596923828125, Entropy -329.2823791503906, Learning Rate: 0.0025\n",
      "Epoch [1689/20000], Loss: 318.76214599609375, Entropy -303.1829833984375, Learning Rate: 0.0025\n",
      "Epoch [1690/20000], Loss: 331.90924072265625, Entropy -308.89776611328125, Learning Rate: 0.0025\n",
      "Epoch [1691/20000], Loss: 317.1710510253906, Entropy -308.9948425292969, Learning Rate: 0.0025\n",
      "Epoch [1692/20000], Loss: 321.5359191894531, Entropy -310.6123352050781, Learning Rate: 0.0025\n",
      "Epoch [1693/20000], Loss: 317.287353515625, Entropy -302.7362365722656, Learning Rate: 0.0025\n",
      "Epoch [1694/20000], Loss: 333.5036926269531, Entropy -317.7817687988281, Learning Rate: 0.0025\n",
      "Epoch [1695/20000], Loss: 355.267822265625, Entropy -311.0243835449219, Learning Rate: 0.0025\n",
      "Epoch [1696/20000], Loss: 346.53448486328125, Entropy -333.51190185546875, Learning Rate: 0.0025\n",
      "Epoch [1697/20000], Loss: 346.7827453613281, Entropy -326.8056640625, Learning Rate: 0.0025\n",
      "Epoch [1698/20000], Loss: 352.804443359375, Entropy -328.0177001953125, Learning Rate: 0.0025\n",
      "Epoch [1699/20000], Loss: 345.87127685546875, Entropy -332.6488342285156, Learning Rate: 0.0025\n",
      "Epoch [1700/20000], Loss: 338.3129577636719, Entropy -324.7279052734375, Learning Rate: 0.0025\n",
      "Epoch [1701/20000], Loss: 345.0954284667969, Entropy -324.44158935546875, Learning Rate: 0.0025\n",
      "Epoch [1702/20000], Loss: 337.1815185546875, Entropy -313.4610595703125, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1703/20000], Loss: 352.3448486328125, Entropy -340.9520568847656, Learning Rate: 0.0025\n",
      "Epoch [1704/20000], Loss: 340.2536315917969, Entropy -320.24951171875, Learning Rate: 0.0025\n",
      "Epoch [1705/20000], Loss: 318.30975341796875, Entropy -304.8125915527344, Learning Rate: 0.0025\n",
      "Epoch [1706/20000], Loss: 336.6661071777344, Entropy -322.2755126953125, Learning Rate: 0.0025\n",
      "Epoch [1707/20000], Loss: 341.3355712890625, Entropy -328.71295166015625, Learning Rate: 0.0025\n",
      "Epoch [1708/20000], Loss: 329.112548828125, Entropy -303.2027587890625, Learning Rate: 0.0025\n",
      "Epoch [1709/20000], Loss: 316.53594970703125, Entropy -311.3992004394531, Learning Rate: 0.0025\n",
      "Epoch [1710/20000], Loss: 333.4774169921875, Entropy -332.58453369140625, Learning Rate: 0.0025\n",
      "Epoch [1711/20000], Loss: 350.2139587402344, Entropy -329.58642578125, Learning Rate: 0.0025\n",
      "Epoch [1712/20000], Loss: 325.245361328125, Entropy -315.57080078125, Learning Rate: 0.0025\n",
      "Epoch [1713/20000], Loss: 337.671142578125, Entropy -321.4250793457031, Learning Rate: 0.0025\n",
      "Epoch [1714/20000], Loss: 327.73333740234375, Entropy -314.7534484863281, Learning Rate: 0.0025\n",
      "Epoch [1715/20000], Loss: 348.8714599609375, Entropy -321.4702453613281, Learning Rate: 0.0025\n",
      "Epoch [1716/20000], Loss: 342.2789306640625, Entropy -312.4488525390625, Learning Rate: 0.0025\n",
      "Epoch [1717/20000], Loss: 337.48846435546875, Entropy -309.8335876464844, Learning Rate: 0.0025\n",
      "Epoch [1718/20000], Loss: 355.2237548828125, Entropy -318.6819763183594, Learning Rate: 0.0025\n",
      "Epoch [1719/20000], Loss: 348.12921142578125, Entropy -327.132568359375, Learning Rate: 0.0025\n",
      "Epoch [1720/20000], Loss: 345.4180908203125, Entropy -311.22369384765625, Learning Rate: 0.0025\n",
      "Epoch [1721/20000], Loss: 370.03271484375, Entropy -308.70904541015625, Learning Rate: 0.0025\n",
      "Epoch [1722/20000], Loss: 335.30218505859375, Entropy -294.3060302734375, Learning Rate: 0.0025\n",
      "Epoch [1723/20000], Loss: 353.54620361328125, Entropy -322.25958251953125, Learning Rate: 0.0025\n",
      "Epoch [1724/20000], Loss: 365.4224548339844, Entropy -315.50244140625, Learning Rate: 0.0025\n",
      "Epoch [1725/20000], Loss: 361.38702392578125, Entropy -321.281494140625, Learning Rate: 0.0025\n",
      "Epoch [1726/20000], Loss: 335.64569091796875, Entropy -322.6788635253906, Learning Rate: 0.0025\n",
      "Epoch [1727/20000], Loss: 377.9223327636719, Entropy -322.0384826660156, Learning Rate: 0.0025\n",
      "Epoch [1728/20000], Loss: 381.5605163574219, Entropy -341.59417724609375, Learning Rate: 0.0025\n",
      "Epoch [1729/20000], Loss: 366.648681640625, Entropy -333.2740173339844, Learning Rate: 0.0025\n",
      "Epoch [1730/20000], Loss: 335.65435791015625, Entropy -307.773681640625, Learning Rate: 0.0025\n",
      "Epoch [1731/20000], Loss: 390.8222351074219, Entropy -328.2033996582031, Learning Rate: 0.0025\n",
      "Epoch [1732/20000], Loss: 366.65545654296875, Entropy -317.1964416503906, Learning Rate: 0.0025\n",
      "Epoch [1733/20000], Loss: 363.062744140625, Entropy -331.26409912109375, Learning Rate: 0.0025\n",
      "Epoch [1734/20000], Loss: 370.3525085449219, Entropy -325.9289855957031, Learning Rate: 0.0025\n",
      "Epoch [1735/20000], Loss: 337.3550720214844, Entropy -298.2518615722656, Learning Rate: 0.0025\n",
      "Epoch [1736/20000], Loss: 347.8073425292969, Entropy -316.6182556152344, Learning Rate: 0.0025\n",
      "Epoch [1737/20000], Loss: 380.60516357421875, Entropy -326.0863342285156, Learning Rate: 0.0025\n",
      "Epoch [1738/20000], Loss: 341.73309326171875, Entropy -325.5534362792969, Learning Rate: 0.0025\n",
      "Epoch [1739/20000], Loss: 325.2846984863281, Entropy -313.0004577636719, Learning Rate: 0.0025\n",
      "Epoch [1740/20000], Loss: 347.85833740234375, Entropy -324.17791748046875, Learning Rate: 0.0025\n",
      "Epoch [1741/20000], Loss: 333.8554382324219, Entropy -312.84808349609375, Learning Rate: 0.0025\n",
      "Epoch [1742/20000], Loss: 345.0810852050781, Entropy -323.85089111328125, Learning Rate: 0.0025\n",
      "Epoch [1743/20000], Loss: 320.6754150390625, Entropy -311.7073059082031, Learning Rate: 0.0025\n",
      "Epoch [1744/20000], Loss: 348.6661682128906, Entropy -316.03900146484375, Learning Rate: 0.0025\n",
      "Epoch [1745/20000], Loss: 326.4864501953125, Entropy -302.0418395996094, Learning Rate: 0.0025\n",
      "Epoch [1746/20000], Loss: 335.8837890625, Entropy -309.22003173828125, Learning Rate: 0.0025\n",
      "Epoch [1747/20000], Loss: 352.9145202636719, Entropy -329.1448059082031, Learning Rate: 0.0025\n",
      "Epoch [1748/20000], Loss: 349.8238525390625, Entropy -316.6429748535156, Learning Rate: 0.0025\n",
      "Epoch [1749/20000], Loss: 338.6287841796875, Entropy -321.64508056640625, Learning Rate: 0.0025\n",
      "Epoch [1750/20000], Loss: 348.02239990234375, Entropy -326.78900146484375, Learning Rate: 0.0025\n",
      "Epoch [1751/20000], Loss: 346.62939453125, Entropy -320.7937316894531, Learning Rate: 0.0025\n",
      "Epoch [1752/20000], Loss: 332.20721435546875, Entropy -313.8721618652344, Learning Rate: 0.0025\n",
      "Epoch [1753/20000], Loss: 302.9685974121094, Entropy -279.52294921875, Learning Rate: 0.0025\n",
      "Epoch [1754/20000], Loss: 340.4193115234375, Entropy -324.70428466796875, Learning Rate: 0.0025\n",
      "Epoch [1755/20000], Loss: 337.7444763183594, Entropy -319.4479675292969, Learning Rate: 0.0025\n",
      "Epoch [1756/20000], Loss: 369.7763977050781, Entropy -331.02838134765625, Learning Rate: 0.0025\n",
      "Epoch [1757/20000], Loss: 340.48406982421875, Entropy -315.8450622558594, Learning Rate: 0.0025\n",
      "Epoch [1758/20000], Loss: 351.31982421875, Entropy -321.5566711425781, Learning Rate: 0.0025\n",
      "Epoch [1759/20000], Loss: 342.7452392578125, Entropy -305.64312744140625, Learning Rate: 0.0025\n",
      "Epoch [1760/20000], Loss: 372.97442626953125, Entropy -314.0256042480469, Learning Rate: 0.0025\n",
      "Epoch [1761/20000], Loss: 346.0234375, Entropy -311.7145080566406, Learning Rate: 0.0025\n",
      "Epoch [1762/20000], Loss: 341.69024658203125, Entropy -309.86700439453125, Learning Rate: 0.0025\n",
      "Epoch [1763/20000], Loss: 371.07781982421875, Entropy -338.0368957519531, Learning Rate: 0.0025\n",
      "Epoch [1764/20000], Loss: 321.6593322753906, Entropy -301.6987609863281, Learning Rate: 0.0025\n",
      "Epoch [1765/20000], Loss: 340.3709716796875, Entropy -318.9579162597656, Learning Rate: 0.0025\n",
      "Epoch [1766/20000], Loss: 354.6298522949219, Entropy -335.8857727050781, Learning Rate: 0.0025\n",
      "Epoch [1767/20000], Loss: 369.4544982910156, Entropy -327.80133056640625, Learning Rate: 0.0025\n",
      "Epoch [1768/20000], Loss: 327.0218505859375, Entropy -307.09521484375, Learning Rate: 0.0025\n",
      "Epoch [1769/20000], Loss: 366.1544189453125, Entropy -328.6658630371094, Learning Rate: 0.0025\n",
      "Epoch [1770/20000], Loss: 353.4856262207031, Entropy -322.4464416503906, Learning Rate: 0.0025\n",
      "Epoch [1771/20000], Loss: 331.452392578125, Entropy -315.30877685546875, Learning Rate: 0.0025\n",
      "Epoch [1772/20000], Loss: 353.9738464355469, Entropy -313.3878479003906, Learning Rate: 0.0025\n",
      "Epoch [1773/20000], Loss: 342.8567199707031, Entropy -314.2274475097656, Learning Rate: 0.0025\n",
      "Epoch [1774/20000], Loss: 353.5880126953125, Entropy -313.8983154296875, Learning Rate: 0.0025\n",
      "Epoch [1775/20000], Loss: 326.4585876464844, Entropy -310.27490234375, Learning Rate: 0.0025\n",
      "Epoch [1776/20000], Loss: 361.7326965332031, Entropy -335.06549072265625, Learning Rate: 0.0025\n",
      "Epoch [1777/20000], Loss: 339.5264892578125, Entropy -322.8072204589844, Learning Rate: 0.0025\n",
      "Epoch [1778/20000], Loss: 371.61199951171875, Entropy -335.44915771484375, Learning Rate: 0.0025\n",
      "Epoch [1779/20000], Loss: 354.374267578125, Entropy -326.8434753417969, Learning Rate: 0.0025\n",
      "Epoch [1780/20000], Loss: 358.65771484375, Entropy -315.0076599121094, Learning Rate: 0.0025\n",
      "Epoch [1781/20000], Loss: 406.36737060546875, Entropy -321.9270324707031, Learning Rate: 0.0025\n",
      "Epoch [1782/20000], Loss: 351.53350830078125, Entropy -309.9980163574219, Learning Rate: 0.0025\n",
      "Epoch [1783/20000], Loss: 368.2437744140625, Entropy -322.7087707519531, Learning Rate: 0.0025\n",
      "Epoch [1784/20000], Loss: 342.5968933105469, Entropy -311.5765380859375, Learning Rate: 0.0025\n",
      "Epoch [1785/20000], Loss: 359.63909912109375, Entropy -311.46722412109375, Learning Rate: 0.0025\n",
      "Epoch [1786/20000], Loss: 371.71087646484375, Entropy -327.4919738769531, Learning Rate: 0.0025\n",
      "Epoch [1787/20000], Loss: 338.49102783203125, Entropy -296.9145812988281, Learning Rate: 0.0025\n",
      "Epoch [1788/20000], Loss: 343.65960693359375, Entropy -314.0603942871094, Learning Rate: 0.0025\n",
      "Epoch [1789/20000], Loss: 359.0147705078125, Entropy -321.8026123046875, Learning Rate: 0.0025\n",
      "Epoch [1790/20000], Loss: 344.65203857421875, Entropy -308.6655578613281, Learning Rate: 0.0025\n",
      "Epoch [1791/20000], Loss: 323.3768310546875, Entropy -308.0305480957031, Learning Rate: 0.0025\n",
      "Epoch [1792/20000], Loss: 340.27618408203125, Entropy -306.9394836425781, Learning Rate: 0.0025\n",
      "Epoch [1793/20000], Loss: 341.33319091796875, Entropy -309.1502990722656, Learning Rate: 0.0025\n",
      "Epoch [1794/20000], Loss: 334.68096923828125, Entropy -320.5369567871094, Learning Rate: 0.0025\n",
      "Epoch [1795/20000], Loss: 362.88616943359375, Entropy -332.0469665527344, Learning Rate: 0.0025\n",
      "Epoch [1796/20000], Loss: 365.7445373535156, Entropy -328.0897521972656, Learning Rate: 0.0025\n",
      "Epoch [1797/20000], Loss: 353.41094970703125, Entropy -321.3138732910156, Learning Rate: 0.0025\n",
      "Epoch [1798/20000], Loss: 330.60015869140625, Entropy -317.1502990722656, Learning Rate: 0.0025\n",
      "Epoch [1799/20000], Loss: 366.3555603027344, Entropy -316.9288024902344, Learning Rate: 0.0025\n",
      "Epoch [1800/20000], Loss: 333.32415771484375, Entropy -303.9359436035156, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1801/20000], Loss: 344.74713134765625, Entropy -340.039794921875, Learning Rate: 0.0025\n",
      "Epoch [1802/20000], Loss: 389.04766845703125, Entropy -331.1475830078125, Learning Rate: 0.0025\n",
      "Epoch [1803/20000], Loss: 345.2406311035156, Entropy -314.23193359375, Learning Rate: 0.0025\n",
      "Epoch [1804/20000], Loss: 325.05670166015625, Entropy -300.46624755859375, Learning Rate: 0.0025\n",
      "Epoch [1805/20000], Loss: 345.0970764160156, Entropy -305.1849365234375, Learning Rate: 0.0025\n",
      "Epoch [1806/20000], Loss: 334.39459228515625, Entropy -311.023193359375, Learning Rate: 0.0025\n",
      "Epoch [1807/20000], Loss: 331.3558654785156, Entropy -311.1385803222656, Learning Rate: 0.0025\n",
      "Epoch [1808/20000], Loss: 357.2630615234375, Entropy -311.5842590332031, Learning Rate: 0.0025\n",
      "Epoch [1809/20000], Loss: 321.8341064453125, Entropy -305.1048583984375, Learning Rate: 0.0025\n",
      "Epoch [1810/20000], Loss: 339.1889953613281, Entropy -325.9087219238281, Learning Rate: 0.0025\n",
      "Epoch [1811/20000], Loss: 347.11181640625, Entropy -307.8378601074219, Learning Rate: 0.0025\n",
      "Epoch [1812/20000], Loss: 329.72418212890625, Entropy -326.2582702636719, Learning Rate: 0.0025\n",
      "Epoch [1813/20000], Loss: 341.7010803222656, Entropy -314.63873291015625, Learning Rate: 0.0025\n",
      "Epoch [1814/20000], Loss: 346.81329345703125, Entropy -315.7540588378906, Learning Rate: 0.0025\n",
      "Epoch [1815/20000], Loss: 345.886474609375, Entropy -328.33514404296875, Learning Rate: 0.0025\n",
      "Epoch [1816/20000], Loss: 347.4073791503906, Entropy -314.6525573730469, Learning Rate: 0.0025\n",
      "Epoch [1817/20000], Loss: 334.4752502441406, Entropy -315.6857604980469, Learning Rate: 0.0025\n",
      "Epoch [1818/20000], Loss: 344.2542419433594, Entropy -313.82379150390625, Learning Rate: 0.0025\n",
      "Epoch [1819/20000], Loss: 324.7136535644531, Entropy -317.32135009765625, Learning Rate: 0.0025\n",
      "Epoch [1820/20000], Loss: 347.42816162109375, Entropy -323.2811279296875, Learning Rate: 0.0025\n",
      "Epoch [1821/20000], Loss: 335.8052978515625, Entropy -323.2136535644531, Learning Rate: 0.0025\n",
      "Epoch [1822/20000], Loss: 361.5606689453125, Entropy -321.25909423828125, Learning Rate: 0.0025\n",
      "Epoch [1823/20000], Loss: 346.7762451171875, Entropy -318.859130859375, Learning Rate: 0.0025\n",
      "Epoch [1824/20000], Loss: 316.8658447265625, Entropy -302.0312194824219, Learning Rate: 0.0025\n",
      "Epoch [1825/20000], Loss: 347.55413818359375, Entropy -312.26251220703125, Learning Rate: 0.0025\n",
      "Epoch [1826/20000], Loss: 336.5992736816406, Entropy -313.5252380371094, Learning Rate: 0.0025\n",
      "Epoch [1827/20000], Loss: 357.957275390625, Entropy -335.1729736328125, Learning Rate: 0.0025\n",
      "Epoch [1828/20000], Loss: 330.427001953125, Entropy -315.1778564453125, Learning Rate: 0.0025\n",
      "Epoch [1829/20000], Loss: 322.92156982421875, Entropy -324.63116455078125, Learning Rate: 0.0025\n",
      "Epoch [1830/20000], Loss: 335.50177001953125, Entropy -313.9051208496094, Learning Rate: 0.0025\n",
      "Epoch [1831/20000], Loss: 329.92724609375, Entropy -315.25360107421875, Learning Rate: 0.0025\n",
      "Epoch [1832/20000], Loss: 333.2037048339844, Entropy -318.54388427734375, Learning Rate: 0.0025\n",
      "Epoch [1833/20000], Loss: 323.21099853515625, Entropy -311.2084655761719, Learning Rate: 0.0025\n",
      "Epoch [1834/20000], Loss: 319.4591369628906, Entropy -306.2326965332031, Learning Rate: 0.0025\n",
      "Epoch [1835/20000], Loss: 311.7100830078125, Entropy -305.9207458496094, Learning Rate: 0.0025\n",
      "Epoch [1836/20000], Loss: 314.00775146484375, Entropy -298.5301208496094, Learning Rate: 0.0025\n",
      "Epoch [1837/20000], Loss: 338.82110595703125, Entropy -322.24005126953125, Learning Rate: 0.0025\n",
      "Epoch [1838/20000], Loss: 332.392578125, Entropy -322.8355712890625, Learning Rate: 0.0025\n",
      "Epoch [1839/20000], Loss: 334.74395751953125, Entropy -315.2507019042969, Learning Rate: 0.0025\n",
      "Epoch [1840/20000], Loss: 334.4973449707031, Entropy -311.11865234375, Learning Rate: 0.0025\n",
      "Epoch [1841/20000], Loss: 323.7154846191406, Entropy -310.05133056640625, Learning Rate: 0.0025\n",
      "Epoch [1842/20000], Loss: 345.6619873046875, Entropy -328.54486083984375, Learning Rate: 0.0025\n",
      "Epoch [1843/20000], Loss: 332.5029296875, Entropy -320.6828308105469, Learning Rate: 0.0025\n",
      "Epoch [1844/20000], Loss: 332.479248046875, Entropy -322.35125732421875, Learning Rate: 0.0025\n",
      "Epoch [1845/20000], Loss: 321.871337890625, Entropy -305.8330993652344, Learning Rate: 0.0025\n",
      "Epoch [1846/20000], Loss: 321.635986328125, Entropy -309.78472900390625, Learning Rate: 0.0025\n",
      "Epoch [1847/20000], Loss: 329.427001953125, Entropy -303.2333984375, Learning Rate: 0.0025\n",
      "Epoch [1848/20000], Loss: 300.87042236328125, Entropy -297.0940246582031, Learning Rate: 0.0025\n",
      "Epoch [1849/20000], Loss: 319.6253662109375, Entropy -311.8523254394531, Learning Rate: 0.0025\n",
      "Epoch [1850/20000], Loss: 333.8924255371094, Entropy -315.0309143066406, Learning Rate: 0.0025\n",
      "Epoch [1851/20000], Loss: 323.32666015625, Entropy -315.55023193359375, Learning Rate: 0.0025\n",
      "Epoch [1852/20000], Loss: 321.12652587890625, Entropy -322.2037048339844, Learning Rate: 0.0025\n",
      "Epoch [1853/20000], Loss: 330.8185729980469, Entropy -313.4125061035156, Learning Rate: 0.0025\n",
      "Epoch [1854/20000], Loss: 319.5531005859375, Entropy -316.13763427734375, Learning Rate: 0.0025\n",
      "Epoch [1855/20000], Loss: 315.15106201171875, Entropy -305.5568542480469, Learning Rate: 0.0025\n",
      "Epoch [1856/20000], Loss: 336.43939208984375, Entropy -326.34405517578125, Learning Rate: 0.0025\n",
      "Epoch [1857/20000], Loss: 311.4935607910156, Entropy -307.481689453125, Learning Rate: 0.0025\n",
      "Epoch [1858/20000], Loss: 328.11566162109375, Entropy -315.6417541503906, Learning Rate: 0.0025\n",
      "Epoch [1859/20000], Loss: 352.73052978515625, Entropy -302.7916564941406, Learning Rate: 0.0025\n",
      "Epoch [1860/20000], Loss: 319.362548828125, Entropy -310.6086120605469, Learning Rate: 0.0025\n",
      "Epoch [1861/20000], Loss: 340.38018798828125, Entropy -325.6648254394531, Learning Rate: 0.0025\n",
      "Epoch [1862/20000], Loss: 341.5158996582031, Entropy -316.6836242675781, Learning Rate: 0.0025\n",
      "Epoch [1863/20000], Loss: 338.6923828125, Entropy -319.0450439453125, Learning Rate: 0.0025\n",
      "Epoch [1864/20000], Loss: 336.25811767578125, Entropy -321.2155456542969, Learning Rate: 0.0025\n",
      "Epoch [1865/20000], Loss: 319.87506103515625, Entropy -309.94757080078125, Learning Rate: 0.0025\n",
      "Epoch [1866/20000], Loss: 335.8310546875, Entropy -311.6231689453125, Learning Rate: 0.0025\n",
      "Epoch [1867/20000], Loss: 371.9652099609375, Entropy -316.00830078125, Learning Rate: 0.0025\n",
      "Epoch [1868/20000], Loss: 360.4913330078125, Entropy -305.34466552734375, Learning Rate: 0.0025\n",
      "Epoch [1869/20000], Loss: 331.9664306640625, Entropy -309.33447265625, Learning Rate: 0.0025\n",
      "Epoch [1870/20000], Loss: 337.5191345214844, Entropy -302.814208984375, Learning Rate: 0.0025\n",
      "Epoch [1871/20000], Loss: 366.9013977050781, Entropy -315.2683410644531, Learning Rate: 0.0025\n",
      "Epoch [1872/20000], Loss: 339.5274658203125, Entropy -309.9635314941406, Learning Rate: 0.0025\n",
      "Epoch [1873/20000], Loss: 335.2618408203125, Entropy -324.5959167480469, Learning Rate: 0.0025\n",
      "Epoch [1874/20000], Loss: 352.6180419921875, Entropy -306.64044189453125, Learning Rate: 0.0025\n",
      "Epoch [1875/20000], Loss: 339.1573181152344, Entropy -304.7885437011719, Learning Rate: 0.0025\n",
      "Epoch [1876/20000], Loss: 341.6985168457031, Entropy -302.88232421875, Learning Rate: 0.0025\n",
      "Epoch [1877/20000], Loss: 338.19378662109375, Entropy -316.170166015625, Learning Rate: 0.0025\n",
      "Epoch [1878/20000], Loss: 370.26513671875, Entropy -329.6959533691406, Learning Rate: 0.0025\n",
      "Epoch [1879/20000], Loss: 337.4560546875, Entropy -323.08837890625, Learning Rate: 0.0025\n",
      "Epoch [1880/20000], Loss: 369.98406982421875, Entropy -316.5325927734375, Learning Rate: 0.0025\n",
      "Epoch [1881/20000], Loss: 338.6693115234375, Entropy -331.31622314453125, Learning Rate: 0.0025\n",
      "Epoch [1882/20000], Loss: 358.3788757324219, Entropy -329.57806396484375, Learning Rate: 0.0025\n",
      "Epoch [1883/20000], Loss: 332.53631591796875, Entropy -311.453125, Learning Rate: 0.0025\n",
      "Epoch [1884/20000], Loss: 338.1437683105469, Entropy -312.7457580566406, Learning Rate: 0.0025\n",
      "Epoch [1885/20000], Loss: 322.2142333984375, Entropy -306.9360656738281, Learning Rate: 0.0025\n",
      "Epoch [1886/20000], Loss: 314.9053649902344, Entropy -310.1474304199219, Learning Rate: 0.0025\n",
      "Epoch [1887/20000], Loss: 330.7918701171875, Entropy -315.0780944824219, Learning Rate: 0.0025\n",
      "Epoch [1888/20000], Loss: 322.4862976074219, Entropy -312.9593200683594, Learning Rate: 0.0025\n",
      "Epoch [1889/20000], Loss: 350.55255126953125, Entropy -323.2926940917969, Learning Rate: 0.0025\n",
      "Epoch [1890/20000], Loss: 330.874267578125, Entropy -314.9233093261719, Learning Rate: 0.0025\n",
      "Epoch [1891/20000], Loss: 342.8859558105469, Entropy -331.3357849121094, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1892/20000], Loss: 303.3482666015625, Entropy -299.4762878417969, Learning Rate: 0.0025\n",
      "Epoch [1893/20000], Loss: 335.84228515625, Entropy -316.1731262207031, Learning Rate: 0.0025\n",
      "Epoch [1894/20000], Loss: 335.96673583984375, Entropy -310.2232666015625, Learning Rate: 0.0025\n",
      "Epoch [1895/20000], Loss: 316.8741455078125, Entropy -311.42266845703125, Learning Rate: 0.0025\n",
      "Epoch [1896/20000], Loss: 333.0922546386719, Entropy -306.43743896484375, Learning Rate: 0.0025\n",
      "Epoch [1897/20000], Loss: 320.93603515625, Entropy -306.3847351074219, Learning Rate: 0.0025\n",
      "Epoch [1898/20000], Loss: 337.63232421875, Entropy -318.8169250488281, Learning Rate: 0.0025\n",
      "Epoch [1899/20000], Loss: 324.47576904296875, Entropy -315.2286682128906, Learning Rate: 0.0025\n",
      "Epoch [1900/20000], Loss: 316.5523986816406, Entropy -322.0758972167969, Learning Rate: 0.0025\n",
      "Epoch [1901/20000], Loss: 331.12774658203125, Entropy -318.0009460449219, Learning Rate: 0.0025\n",
      "Epoch [1902/20000], Loss: 318.4774475097656, Entropy -308.29461669921875, Learning Rate: 0.0025\n",
      "Epoch [1903/20000], Loss: 323.99835205078125, Entropy -315.1156311035156, Learning Rate: 0.0025\n",
      "Epoch [1904/20000], Loss: 321.0372009277344, Entropy -305.4078063964844, Learning Rate: 0.0025\n",
      "Epoch [1905/20000], Loss: 313.9908447265625, Entropy -290.2095642089844, Learning Rate: 0.0025\n",
      "Epoch [1906/20000], Loss: 328.00543212890625, Entropy -315.8343505859375, Learning Rate: 0.0025\n",
      "Epoch [1907/20000], Loss: 330.9949645996094, Entropy -317.726318359375, Learning Rate: 0.0025\n",
      "Epoch [1908/20000], Loss: 333.5852966308594, Entropy -325.4049377441406, Learning Rate: 0.0025\n",
      "Epoch [1909/20000], Loss: 311.8135986328125, Entropy -296.9576721191406, Learning Rate: 0.0025\n",
      "Epoch [1910/20000], Loss: 313.8838806152344, Entropy -309.5505676269531, Learning Rate: 0.0025\n",
      "Epoch [1911/20000], Loss: 311.8114013671875, Entropy -302.65057373046875, Learning Rate: 0.0025\n",
      "Epoch [1912/20000], Loss: 308.02447509765625, Entropy -310.6201477050781, Learning Rate: 0.0025\n",
      "Epoch [1913/20000], Loss: 334.33270263671875, Entropy -326.93341064453125, Learning Rate: 0.0025\n",
      "Epoch [1914/20000], Loss: 311.3520202636719, Entropy -307.98529052734375, Learning Rate: 0.0025\n",
      "Epoch [1915/20000], Loss: 333.64093017578125, Entropy -327.89874267578125, Learning Rate: 0.0025\n",
      "Epoch [1916/20000], Loss: 318.23590087890625, Entropy -305.111572265625, Learning Rate: 0.0025\n",
      "Epoch [1917/20000], Loss: 330.81561279296875, Entropy -327.701171875, Learning Rate: 0.0025\n",
      "Epoch [1918/20000], Loss: 331.119873046875, Entropy -315.1728210449219, Learning Rate: 0.0025\n",
      "Epoch [1919/20000], Loss: 310.9566650390625, Entropy -306.9529113769531, Learning Rate: 0.0025\n",
      "Epoch [1920/20000], Loss: 315.15887451171875, Entropy -312.6631774902344, Learning Rate: 0.0025\n",
      "Epoch [1921/20000], Loss: 318.14666748046875, Entropy -298.81890869140625, Learning Rate: 0.0025\n",
      "Epoch [1922/20000], Loss: 323.75384521484375, Entropy -303.3829345703125, Learning Rate: 0.0025\n",
      "Epoch [1923/20000], Loss: 326.32208251953125, Entropy -317.9360046386719, Learning Rate: 0.0025\n",
      "Epoch [1924/20000], Loss: 317.98809814453125, Entropy -317.7483825683594, Learning Rate: 0.0025\n",
      "Epoch [1925/20000], Loss: 313.711181640625, Entropy -305.5574645996094, Learning Rate: 0.0025\n",
      "Epoch [1926/20000], Loss: 314.8424987792969, Entropy -312.6964111328125, Learning Rate: 0.0025\n",
      "Epoch [1927/20000], Loss: 338.1540222167969, Entropy -331.9564208984375, Learning Rate: 0.0025\n",
      "Epoch [1928/20000], Loss: 332.9138488769531, Entropy -319.6358947753906, Learning Rate: 0.0025\n",
      "Epoch [1929/20000], Loss: 328.935791015625, Entropy -320.89141845703125, Learning Rate: 0.0025\n",
      "Epoch [1930/20000], Loss: 327.58953857421875, Entropy -325.5860595703125, Learning Rate: 0.0025\n",
      "Epoch [1931/20000], Loss: 327.9908447265625, Entropy -309.32489013671875, Learning Rate: 0.0025\n",
      "Epoch [1932/20000], Loss: 319.6855773925781, Entropy -309.86334228515625, Learning Rate: 0.0025\n",
      "Epoch [1933/20000], Loss: 319.3609619140625, Entropy -314.4984130859375, Learning Rate: 0.0025\n",
      "Epoch [1934/20000], Loss: 313.4867248535156, Entropy -304.19873046875, Learning Rate: 0.0025\n",
      "Epoch [1935/20000], Loss: 323.5390625, Entropy -310.59075927734375, Learning Rate: 0.0025\n",
      "Epoch [1936/20000], Loss: 313.1380615234375, Entropy -299.4764404296875, Learning Rate: 0.0025\n",
      "Epoch [1937/20000], Loss: 315.47320556640625, Entropy -307.54498291015625, Learning Rate: 0.0025\n",
      "Epoch [1938/20000], Loss: 319.4345703125, Entropy -311.220703125, Learning Rate: 0.0025\n",
      "Epoch [1939/20000], Loss: 313.9656066894531, Entropy -301.8803405761719, Learning Rate: 0.0025\n",
      "Epoch [1940/20000], Loss: 336.57586669921875, Entropy -321.0133361816406, Learning Rate: 0.0025\n",
      "Epoch [1941/20000], Loss: 316.66827392578125, Entropy -301.45318603515625, Learning Rate: 0.0025\n",
      "Epoch [1942/20000], Loss: 321.83648681640625, Entropy -312.064697265625, Learning Rate: 0.0025\n",
      "Epoch [1943/20000], Loss: 302.2845458984375, Entropy -296.5188293457031, Learning Rate: 0.0025\n",
      "Epoch [1944/20000], Loss: 336.56982421875, Entropy -323.6197509765625, Learning Rate: 0.0025\n",
      "Epoch [1945/20000], Loss: 345.7279052734375, Entropy -329.41766357421875, Learning Rate: 0.0025\n",
      "Epoch [1946/20000], Loss: 313.81976318359375, Entropy -302.38665771484375, Learning Rate: 0.0025\n",
      "Epoch [1947/20000], Loss: 327.40533447265625, Entropy -315.6615905761719, Learning Rate: 0.0025\n",
      "Epoch [1948/20000], Loss: 312.47991943359375, Entropy -303.923095703125, Learning Rate: 0.0025\n",
      "Epoch [1949/20000], Loss: 323.29071044921875, Entropy -312.09478759765625, Learning Rate: 0.0025\n",
      "Epoch [1950/20000], Loss: 314.8939208984375, Entropy -307.654052734375, Learning Rate: 0.0025\n",
      "Epoch [1951/20000], Loss: 309.0518493652344, Entropy -297.0357971191406, Learning Rate: 0.0025\n",
      "Epoch [1952/20000], Loss: 324.371337890625, Entropy -302.0181884765625, Learning Rate: 0.0025\n",
      "Epoch [1953/20000], Loss: 317.24951171875, Entropy -320.8011169433594, Learning Rate: 0.0025\n",
      "Epoch [1954/20000], Loss: 308.4760437011719, Entropy -315.23431396484375, Learning Rate: 0.0025\n",
      "Epoch [1955/20000], Loss: 323.9106750488281, Entropy -322.19866943359375, Learning Rate: 0.0025\n",
      "Epoch [1956/20000], Loss: 328.48101806640625, Entropy -306.818115234375, Learning Rate: 0.0025\n",
      "Epoch [1957/20000], Loss: 325.6491394042969, Entropy -320.84588623046875, Learning Rate: 0.0025\n",
      "Epoch [1958/20000], Loss: 302.3604431152344, Entropy -299.0679626464844, Learning Rate: 0.0025\n",
      "Epoch [1959/20000], Loss: 340.9515380859375, Entropy -326.07672119140625, Learning Rate: 0.0025\n",
      "Epoch [1960/20000], Loss: 313.7845764160156, Entropy -306.88604736328125, Learning Rate: 0.0025\n",
      "Epoch [1961/20000], Loss: 317.31451416015625, Entropy -313.2593994140625, Learning Rate: 0.0025\n",
      "Epoch [1962/20000], Loss: 337.69134521484375, Entropy -330.6889953613281, Learning Rate: 0.0025\n",
      "Epoch [1963/20000], Loss: 334.3287048339844, Entropy -323.6669006347656, Learning Rate: 0.0025\n",
      "Epoch [1964/20000], Loss: 306.06951904296875, Entropy -309.0593566894531, Learning Rate: 0.0025\n",
      "Epoch [1965/20000], Loss: 305.0458984375, Entropy -302.1250915527344, Learning Rate: 0.0025\n",
      "Epoch [1966/20000], Loss: 323.2295837402344, Entropy -318.9091491699219, Learning Rate: 0.0025\n",
      "Epoch [1967/20000], Loss: 328.9290771484375, Entropy -321.053955078125, Learning Rate: 0.0025\n",
      "Epoch [1968/20000], Loss: 318.2375183105469, Entropy -310.7120666503906, Learning Rate: 0.0025\n",
      "Epoch [1969/20000], Loss: 321.1375427246094, Entropy -312.1078186035156, Learning Rate: 0.0025\n",
      "Epoch [1970/20000], Loss: 292.491943359375, Entropy -299.26885986328125, Learning Rate: 0.0025\n",
      "Epoch [1971/20000], Loss: 310.2992858886719, Entropy -318.7459411621094, Learning Rate: 0.0025\n",
      "Epoch [1972/20000], Loss: 317.419921875, Entropy -307.45361328125, Learning Rate: 0.0025\n",
      "Epoch [1973/20000], Loss: 322.5888671875, Entropy -322.2602233886719, Learning Rate: 0.0025\n",
      "Epoch [1974/20000], Loss: 310.92864990234375, Entropy -315.69232177734375, Learning Rate: 0.0025\n",
      "Epoch [1975/20000], Loss: 303.8975830078125, Entropy -302.7535400390625, Learning Rate: 0.0025\n",
      "Epoch [1976/20000], Loss: 328.04376220703125, Entropy -322.35467529296875, Learning Rate: 0.0025\n",
      "Epoch [1977/20000], Loss: 314.01983642578125, Entropy -315.4482421875, Learning Rate: 0.0025\n",
      "Epoch [1978/20000], Loss: 318.31182861328125, Entropy -320.1667175292969, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1979/20000], Loss: 330.4892578125, Entropy -323.4659423828125, Learning Rate: 0.0025\n",
      "Epoch [1980/20000], Loss: 317.99542236328125, Entropy -308.70281982421875, Learning Rate: 0.0025\n",
      "Epoch [1981/20000], Loss: 315.75225830078125, Entropy -311.68597412109375, Learning Rate: 0.0025\n",
      "Epoch [1982/20000], Loss: 327.3299255371094, Entropy -329.5356140136719, Learning Rate: 0.0025\n",
      "Epoch [1983/20000], Loss: 342.3174743652344, Entropy -323.5154724121094, Learning Rate: 0.0025\n",
      "Epoch [1984/20000], Loss: 323.60662841796875, Entropy -319.2896728515625, Learning Rate: 0.0025\n",
      "Epoch [1985/20000], Loss: 316.7093505859375, Entropy -311.2900085449219, Learning Rate: 0.0025\n",
      "Epoch [1986/20000], Loss: 340.4071044921875, Entropy -315.22393798828125, Learning Rate: 0.0025\n",
      "Epoch [1987/20000], Loss: 314.53314208984375, Entropy -301.48712158203125, Learning Rate: 0.0025\n",
      "Epoch [1988/20000], Loss: 317.82525634765625, Entropy -315.0899353027344, Learning Rate: 0.0025\n",
      "Epoch [1989/20000], Loss: 319.58367919921875, Entropy -312.58648681640625, Learning Rate: 0.0025\n",
      "Epoch [1990/20000], Loss: 322.6466369628906, Entropy -303.6568298339844, Learning Rate: 0.0025\n",
      "Epoch [1991/20000], Loss: 298.35345458984375, Entropy -294.93408203125, Learning Rate: 0.0025\n",
      "Epoch [1992/20000], Loss: 340.65643310546875, Entropy -329.1716613769531, Learning Rate: 0.0025\n",
      "Epoch [1993/20000], Loss: 319.7647705078125, Entropy -305.16986083984375, Learning Rate: 0.0025\n",
      "Epoch [1994/20000], Loss: 319.0533142089844, Entropy -308.07855224609375, Learning Rate: 0.0025\n",
      "Epoch [1995/20000], Loss: 316.89990234375, Entropy -306.2698974609375, Learning Rate: 0.0025\n",
      "Epoch [1996/20000], Loss: 313.94793701171875, Entropy -292.0583190917969, Learning Rate: 0.0025\n",
      "Epoch [1997/20000], Loss: 326.3514099121094, Entropy -320.0477294921875, Learning Rate: 0.0025\n",
      "Epoch [1998/20000], Loss: 334.005859375, Entropy -312.8470153808594, Learning Rate: 0.0025\n",
      "Epoch [1999/20000], Loss: 317.720947265625, Entropy -311.42779541015625, Learning Rate: 0.0025\n",
      "Epoch [2000/20000], Loss: 330.17340087890625, Entropy -321.735595703125, Learning Rate: 0.0025\n",
      "Epoch [2001/20000], Loss: 322.90484619140625, Entropy -316.0179138183594, Learning Rate: 0.0025\n",
      "Epoch [2002/20000], Loss: 342.7369079589844, Entropy -304.70379638671875, Learning Rate: 0.0025\n",
      "Epoch [2003/20000], Loss: 315.7652282714844, Entropy -315.5116271972656, Learning Rate: 0.0025\n",
      "Epoch [2004/20000], Loss: 355.7233581542969, Entropy -327.6551513671875, Learning Rate: 0.0025\n",
      "Epoch [2005/20000], Loss: 318.9522705078125, Entropy -315.5840759277344, Learning Rate: 0.0025\n",
      "Epoch [2006/20000], Loss: 328.24664306640625, Entropy -330.61962890625, Learning Rate: 0.0025\n",
      "Epoch [2007/20000], Loss: 328.4449157714844, Entropy -321.8852844238281, Learning Rate: 0.0025\n",
      "Epoch [2008/20000], Loss: 312.3568115234375, Entropy -313.7123107910156, Learning Rate: 0.0025\n",
      "Epoch [2009/20000], Loss: 315.9897155761719, Entropy -315.3399963378906, Learning Rate: 0.0025\n",
      "Epoch [2010/20000], Loss: 331.12921142578125, Entropy -314.68988037109375, Learning Rate: 0.0025\n",
      "Epoch [2011/20000], Loss: 359.1517028808594, Entropy -336.3116760253906, Learning Rate: 0.0025\n",
      "Epoch [2012/20000], Loss: 323.0427551269531, Entropy -309.14727783203125, Learning Rate: 0.0025\n",
      "Epoch [2013/20000], Loss: 318.1741943359375, Entropy -306.97247314453125, Learning Rate: 0.0025\n",
      "Epoch [2014/20000], Loss: 337.55889892578125, Entropy -325.4429626464844, Learning Rate: 0.0025\n",
      "Epoch [2015/20000], Loss: 326.9319763183594, Entropy -303.9176025390625, Learning Rate: 0.0025\n",
      "Epoch [2016/20000], Loss: 332.87518310546875, Entropy -321.7986755371094, Learning Rate: 0.0025\n",
      "Epoch [2017/20000], Loss: 328.43951416015625, Entropy -325.6153564453125, Learning Rate: 0.0025\n",
      "Epoch [2018/20000], Loss: 305.50146484375, Entropy -299.3192138671875, Learning Rate: 0.0025\n",
      "Epoch [2019/20000], Loss: 316.02593994140625, Entropy -296.8165283203125, Learning Rate: 0.0025\n",
      "Epoch [2020/20000], Loss: 319.5896301269531, Entropy -315.79290771484375, Learning Rate: 0.0025\n",
      "Epoch [2021/20000], Loss: 327.7972412109375, Entropy -312.3707580566406, Learning Rate: 0.0025\n",
      "Epoch [2022/20000], Loss: 316.4964599609375, Entropy -319.0863342285156, Learning Rate: 0.0025\n",
      "Epoch [2023/20000], Loss: 334.29376220703125, Entropy -316.7600402832031, Learning Rate: 0.0025\n",
      "Epoch [2024/20000], Loss: 329.80438232421875, Entropy -326.4453125, Learning Rate: 0.0025\n",
      "Epoch [2025/20000], Loss: 318.6950378417969, Entropy -313.172607421875, Learning Rate: 0.0025\n",
      "Epoch [2026/20000], Loss: 327.0535583496094, Entropy -325.00994873046875, Learning Rate: 0.0025\n",
      "Epoch [2027/20000], Loss: 309.88812255859375, Entropy -313.77532958984375, Learning Rate: 0.0025\n",
      "Epoch [2028/20000], Loss: 317.2000732421875, Entropy -319.22174072265625, Learning Rate: 0.0025\n",
      "Epoch [2029/20000], Loss: 322.6972351074219, Entropy -316.2447509765625, Learning Rate: 0.0025\n",
      "Epoch [2030/20000], Loss: 318.5806884765625, Entropy -321.8443603515625, Learning Rate: 0.0025\n",
      "Epoch [2031/20000], Loss: 345.2845458984375, Entropy -333.09954833984375, Learning Rate: 0.0025\n",
      "Epoch [2032/20000], Loss: 327.47369384765625, Entropy -322.8047180175781, Learning Rate: 0.0025\n",
      "Epoch [2033/20000], Loss: 302.665771484375, Entropy -303.6595458984375, Learning Rate: 0.0025\n",
      "Epoch [2034/20000], Loss: 303.05584716796875, Entropy -306.3111267089844, Learning Rate: 0.0025\n",
      "Epoch [2035/20000], Loss: 319.0883483886719, Entropy -318.3331604003906, Learning Rate: 0.0025\n",
      "Epoch [2036/20000], Loss: 330.18817138671875, Entropy -307.76312255859375, Learning Rate: 0.0025\n",
      "Epoch [2037/20000], Loss: 312.85760498046875, Entropy -304.8008117675781, Learning Rate: 0.0025\n",
      "Epoch [2038/20000], Loss: 318.10662841796875, Entropy -302.2440185546875, Learning Rate: 0.0025\n",
      "Epoch [2039/20000], Loss: 338.15863037109375, Entropy -333.77923583984375, Learning Rate: 0.0025\n",
      "Epoch [2040/20000], Loss: 313.2548828125, Entropy -306.58905029296875, Learning Rate: 0.0025\n",
      "Epoch [2041/20000], Loss: 343.47650146484375, Entropy -323.335205078125, Learning Rate: 0.0025\n",
      "Epoch [2042/20000], Loss: 328.49041748046875, Entropy -321.3294982910156, Learning Rate: 0.0025\n",
      "Epoch [2043/20000], Loss: 341.7523193359375, Entropy -299.1045227050781, Learning Rate: 0.0025\n",
      "Epoch [2044/20000], Loss: 309.70770263671875, Entropy -298.724365234375, Learning Rate: 0.0025\n",
      "Epoch [2045/20000], Loss: 364.64349365234375, Entropy -308.5135498046875, Learning Rate: 0.0025\n",
      "Epoch [2046/20000], Loss: 328.99005126953125, Entropy -314.8405456542969, Learning Rate: 0.0025\n",
      "Epoch [2047/20000], Loss: 352.126708984375, Entropy -313.69769287109375, Learning Rate: 0.0025\n",
      "Epoch [2048/20000], Loss: 331.8281555175781, Entropy -311.8116455078125, Learning Rate: 0.0025\n",
      "Epoch [2049/20000], Loss: 334.0191955566406, Entropy -314.6974792480469, Learning Rate: 0.0025\n",
      "Epoch [2050/20000], Loss: 341.47283935546875, Entropy -321.2326354980469, Learning Rate: 0.0025\n",
      "Epoch [2051/20000], Loss: 310.7187194824219, Entropy -301.6850280761719, Learning Rate: 0.0025\n",
      "Epoch [2052/20000], Loss: 365.40191650390625, Entropy -330.9199523925781, Learning Rate: 0.0025\n",
      "Epoch [2053/20000], Loss: 329.56298828125, Entropy -312.61224365234375, Learning Rate: 0.0025\n",
      "Epoch [2054/20000], Loss: 364.6080322265625, Entropy -326.50726318359375, Learning Rate: 0.0025\n",
      "Epoch [2055/20000], Loss: 358.8061218261719, Entropy -317.194580078125, Learning Rate: 0.0025\n",
      "Epoch [2056/20000], Loss: 378.9666442871094, Entropy -306.6296081542969, Learning Rate: 0.0025\n",
      "Epoch [2057/20000], Loss: 365.2528076171875, Entropy -311.287841796875, Learning Rate: 0.0025\n",
      "Epoch [2058/20000], Loss: 399.2979431152344, Entropy -293.5195617675781, Learning Rate: 0.0025\n",
      "Epoch [2059/20000], Loss: 370.0478515625, Entropy -319.65386962890625, Learning Rate: 0.0025\n",
      "Epoch [2060/20000], Loss: 393.08782958984375, Entropy -331.7702941894531, Learning Rate: 0.0025\n",
      "Epoch [2061/20000], Loss: 351.7110290527344, Entropy -313.6272888183594, Learning Rate: 0.0025\n",
      "Epoch [2062/20000], Loss: 368.47723388671875, Entropy -304.5761413574219, Learning Rate: 0.0025\n",
      "Epoch [2063/20000], Loss: 323.88494873046875, Entropy -303.98004150390625, Learning Rate: 0.0025\n",
      "Epoch [2064/20000], Loss: 363.67474365234375, Entropy -311.6957092285156, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2065/20000], Loss: 367.75946044921875, Entropy -328.20489501953125, Learning Rate: 0.0025\n",
      "Epoch [2066/20000], Loss: 341.30450439453125, Entropy -306.9973449707031, Learning Rate: 0.0025\n",
      "Epoch [2067/20000], Loss: 347.9304504394531, Entropy -317.9698486328125, Learning Rate: 0.0025\n",
      "Epoch [2068/20000], Loss: 335.5205078125, Entropy -307.95428466796875, Learning Rate: 0.0025\n",
      "Epoch [2069/20000], Loss: 338.5130920410156, Entropy -314.71014404296875, Learning Rate: 0.0025\n",
      "Epoch [2070/20000], Loss: 334.4537658691406, Entropy -313.5615234375, Learning Rate: 0.0025\n",
      "Epoch [2071/20000], Loss: 336.9841003417969, Entropy -307.75225830078125, Learning Rate: 0.0025\n",
      "Epoch [2072/20000], Loss: 320.31427001953125, Entropy -313.925537109375, Learning Rate: 0.0025\n",
      "Epoch [2073/20000], Loss: 419.0303955078125, Entropy -311.3577880859375, Learning Rate: 0.0025\n",
      "Epoch [2074/20000], Loss: 336.06201171875, Entropy -303.23162841796875, Learning Rate: 0.0025\n",
      "Epoch [2075/20000], Loss: 368.48504638671875, Entropy -309.3663635253906, Learning Rate: 0.0025\n",
      "Epoch [2076/20000], Loss: 325.59326171875, Entropy -284.7394714355469, Learning Rate: 0.0025\n",
      "Epoch [2077/20000], Loss: 348.1336975097656, Entropy -304.1678466796875, Learning Rate: 0.0025\n",
      "Epoch [2078/20000], Loss: 362.09002685546875, Entropy -314.6394958496094, Learning Rate: 0.0025\n",
      "Epoch [2079/20000], Loss: 374.5126647949219, Entropy -329.3585205078125, Learning Rate: 0.0025\n",
      "Epoch [2080/20000], Loss: 370.9011535644531, Entropy -319.1922912597656, Learning Rate: 0.0025\n",
      "Epoch [2081/20000], Loss: 390.48529052734375, Entropy -308.3474426269531, Learning Rate: 0.0025\n",
      "Epoch [2082/20000], Loss: 347.0169677734375, Entropy -294.01495361328125, Learning Rate: 0.0025\n",
      "Epoch [2083/20000], Loss: 441.0630798339844, Entropy -326.0845947265625, Learning Rate: 0.0025\n",
      "Epoch [2084/20000], Loss: 335.3434143066406, Entropy -300.88580322265625, Learning Rate: 0.0025\n",
      "Epoch [2085/20000], Loss: 478.2269287109375, Entropy -313.42913818359375, Learning Rate: 0.0025\n",
      "Epoch [2086/20000], Loss: 336.498291015625, Entropy -314.5481872558594, Learning Rate: 0.0025\n",
      "Epoch [2087/20000], Loss: 385.81060791015625, Entropy -308.5598449707031, Learning Rate: 0.0025\n",
      "Epoch [2088/20000], Loss: 377.74322509765625, Entropy -319.3717346191406, Learning Rate: 0.0025\n",
      "Epoch [2089/20000], Loss: 328.3927307128906, Entropy -295.62567138671875, Learning Rate: 0.0025\n",
      "Epoch [2090/20000], Loss: 365.1548156738281, Entropy -328.0877990722656, Learning Rate: 0.0025\n",
      "Epoch [2091/20000], Loss: 370.0630798339844, Entropy -321.5370178222656, Learning Rate: 0.0025\n",
      "Epoch [2092/20000], Loss: 340.5367736816406, Entropy -305.0834045410156, Learning Rate: 0.0025\n",
      "Epoch [2093/20000], Loss: 341.6850280761719, Entropy -305.54840087890625, Learning Rate: 0.0025\n",
      "Epoch [2094/20000], Loss: 368.589599609375, Entropy -306.97186279296875, Learning Rate: 0.0025\n",
      "Epoch [2095/20000], Loss: 326.6492919921875, Entropy -296.9296875, Learning Rate: 0.0025\n",
      "Epoch [2096/20000], Loss: 378.096435546875, Entropy -329.5688171386719, Learning Rate: 0.0025\n",
      "Epoch [2097/20000], Loss: 374.70098876953125, Entropy -318.7626953125, Learning Rate: 0.0025\n",
      "Epoch [2098/20000], Loss: 340.30621337890625, Entropy -311.5748291015625, Learning Rate: 0.0025\n",
      "Epoch [2099/20000], Loss: 362.892578125, Entropy -299.49261474609375, Learning Rate: 0.0025\n",
      "Epoch [2100/20000], Loss: 331.45135498046875, Entropy -324.5014343261719, Learning Rate: 0.0025\n",
      "Epoch [2101/20000], Loss: 354.7855224609375, Entropy -323.3932189941406, Learning Rate: 0.0025\n",
      "Epoch [2102/20000], Loss: 388.9792785644531, Entropy -325.2054138183594, Learning Rate: 0.0025\n",
      "Epoch [2103/20000], Loss: 326.9583740234375, Entropy -314.87347412109375, Learning Rate: 0.0025\n",
      "Epoch [2104/20000], Loss: 344.9471435546875, Entropy -307.02044677734375, Learning Rate: 0.0025\n",
      "Epoch [2105/20000], Loss: 354.66357421875, Entropy -320.72021484375, Learning Rate: 0.0025\n",
      "Epoch [2106/20000], Loss: 336.9206848144531, Entropy -317.3968811035156, Learning Rate: 0.0025\n",
      "Epoch [2107/20000], Loss: 386.41009521484375, Entropy -318.968994140625, Learning Rate: 0.0025\n",
      "Epoch [2108/20000], Loss: 337.3775634765625, Entropy -322.6278381347656, Learning Rate: 0.0025\n",
      "Epoch [2109/20000], Loss: 365.1523132324219, Entropy -319.4716491699219, Learning Rate: 0.0025\n",
      "Epoch [2110/20000], Loss: 345.6236267089844, Entropy -296.79071044921875, Learning Rate: 0.0025\n",
      "Epoch [2111/20000], Loss: 343.2421875, Entropy -301.0635681152344, Learning Rate: 0.0025\n",
      "Epoch [2112/20000], Loss: 349.81292724609375, Entropy -310.1913146972656, Learning Rate: 0.0025\n",
      "Epoch [2113/20000], Loss: 353.3639831542969, Entropy -320.8493347167969, Learning Rate: 0.0025\n",
      "Epoch [2114/20000], Loss: 337.1667785644531, Entropy -313.3916320800781, Learning Rate: 0.0025\n",
      "Epoch [2115/20000], Loss: 377.1705322265625, Entropy -310.3872375488281, Learning Rate: 0.0025\n",
      "Epoch [2116/20000], Loss: 351.42498779296875, Entropy -317.8038330078125, Learning Rate: 0.0025\n",
      "Epoch [2117/20000], Loss: 372.4056396484375, Entropy -297.4404296875, Learning Rate: 0.0025\n",
      "Epoch [2118/20000], Loss: 321.2287902832031, Entropy -305.74456787109375, Learning Rate: 0.0025\n",
      "Epoch [2119/20000], Loss: 338.1220397949219, Entropy -310.33599853515625, Learning Rate: 0.0025\n",
      "Epoch [2120/20000], Loss: 358.6123962402344, Entropy -316.32696533203125, Learning Rate: 0.0025\n",
      "Epoch [2121/20000], Loss: 349.9693908691406, Entropy -327.4163513183594, Learning Rate: 0.0025\n",
      "Epoch [2122/20000], Loss: 341.8268737792969, Entropy -320.2818298339844, Learning Rate: 0.0025\n",
      "Epoch [2123/20000], Loss: 326.3415832519531, Entropy -309.1388854980469, Learning Rate: 0.0025\n",
      "Epoch [2124/20000], Loss: 324.9725646972656, Entropy -304.73919677734375, Learning Rate: 0.0025\n",
      "Epoch [2125/20000], Loss: 345.7494812011719, Entropy -320.42083740234375, Learning Rate: 0.0025\n",
      "Epoch [2126/20000], Loss: 318.49053955078125, Entropy -310.691650390625, Learning Rate: 0.0025\n",
      "Epoch [2127/20000], Loss: 343.6109313964844, Entropy -310.47247314453125, Learning Rate: 0.0025\n",
      "Epoch [2128/20000], Loss: 317.88250732421875, Entropy -319.7881164550781, Learning Rate: 0.0025\n",
      "Epoch [2129/20000], Loss: 322.77996826171875, Entropy -310.84857177734375, Learning Rate: 0.0025\n",
      "Epoch [2130/20000], Loss: 335.63323974609375, Entropy -322.4215393066406, Learning Rate: 0.0025\n",
      "Epoch [2131/20000], Loss: 335.19744873046875, Entropy -319.71881103515625, Learning Rate: 0.0025\n",
      "Epoch [2132/20000], Loss: 329.9811096191406, Entropy -301.3324890136719, Learning Rate: 0.0025\n",
      "Epoch [2133/20000], Loss: 351.0444030761719, Entropy -311.9960021972656, Learning Rate: 0.0025\n",
      "Epoch [2134/20000], Loss: 342.9410095214844, Entropy -314.1786804199219, Learning Rate: 0.0025\n",
      "Epoch [2135/20000], Loss: 351.92547607421875, Entropy -313.09375, Learning Rate: 0.0025\n",
      "Epoch [2136/20000], Loss: 317.4068908691406, Entropy -296.6274719238281, Learning Rate: 0.0025\n",
      "Epoch [2137/20000], Loss: 335.2303466796875, Entropy -297.1584777832031, Learning Rate: 0.0025\n",
      "Epoch [2138/20000], Loss: 358.473876953125, Entropy -311.9494934082031, Learning Rate: 0.0025\n",
      "Epoch [2139/20000], Loss: 344.4097900390625, Entropy -326.60906982421875, Learning Rate: 0.0025\n",
      "Epoch [2140/20000], Loss: 329.7747802734375, Entropy -313.4530334472656, Learning Rate: 0.0025\n",
      "Epoch [2141/20000], Loss: 324.76080322265625, Entropy -301.091796875, Learning Rate: 0.0025\n",
      "Epoch [2142/20000], Loss: 316.923828125, Entropy -315.944091796875, Learning Rate: 0.0025\n",
      "Epoch [2143/20000], Loss: 329.54022216796875, Entropy -313.3244323730469, Learning Rate: 0.0025\n",
      "Epoch [2144/20000], Loss: 352.468017578125, Entropy -326.17486572265625, Learning Rate: 0.0025\n",
      "Epoch [2145/20000], Loss: 327.17596435546875, Entropy -325.0810852050781, Learning Rate: 0.0025\n",
      "Epoch [2146/20000], Loss: 324.0264892578125, Entropy -305.82586669921875, Learning Rate: 0.0025\n",
      "Epoch [2147/20000], Loss: 327.59002685546875, Entropy -310.85235595703125, Learning Rate: 0.0025\n",
      "Epoch [2148/20000], Loss: 316.18194580078125, Entropy -312.2629699707031, Learning Rate: 0.0025\n",
      "Epoch [2149/20000], Loss: 327.83642578125, Entropy -311.0400695800781, Learning Rate: 0.0025\n",
      "Epoch [2150/20000], Loss: 311.3507080078125, Entropy -309.6038513183594, Learning Rate: 0.0025\n",
      "Epoch [2151/20000], Loss: 317.24249267578125, Entropy -308.1906433105469, Learning Rate: 0.0025\n",
      "Epoch [2152/20000], Loss: 312.87200927734375, Entropy -311.30352783203125, Learning Rate: 0.0025\n",
      "Epoch [2153/20000], Loss: 309.0623474121094, Entropy -308.4447326660156, Learning Rate: 0.0025\n",
      "Epoch [2154/20000], Loss: 314.91357421875, Entropy -303.77471923828125, Learning Rate: 0.0025\n",
      "Epoch [2155/20000], Loss: 316.85223388671875, Entropy -301.87481689453125, Learning Rate: 0.0025\n",
      "Epoch [2156/20000], Loss: 318.1334533691406, Entropy -313.5615234375, Learning Rate: 0.0025\n",
      "Epoch [2157/20000], Loss: 316.101806640625, Entropy -311.34149169921875, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2158/20000], Loss: 317.4461975097656, Entropy -303.9710388183594, Learning Rate: 0.0025\n",
      "Epoch [2159/20000], Loss: 326.7611389160156, Entropy -318.248779296875, Learning Rate: 0.0025\n",
      "Epoch [2160/20000], Loss: 311.79376220703125, Entropy -298.684326171875, Learning Rate: 0.0025\n",
      "Epoch [2161/20000], Loss: 327.13946533203125, Entropy -317.15313720703125, Learning Rate: 0.0025\n",
      "Epoch [2162/20000], Loss: 328.3899841308594, Entropy -321.350341796875, Learning Rate: 0.0025\n",
      "Epoch [2163/20000], Loss: 317.109375, Entropy -308.2705383300781, Learning Rate: 0.0025\n",
      "Epoch [2164/20000], Loss: 314.643798828125, Entropy -321.7269287109375, Learning Rate: 0.0025\n",
      "Epoch [2165/20000], Loss: 319.36541748046875, Entropy -300.84033203125, Learning Rate: 0.0025\n",
      "Epoch [2166/20000], Loss: 322.35650634765625, Entropy -308.4372863769531, Learning Rate: 0.0025\n",
      "Epoch [2167/20000], Loss: 314.42352294921875, Entropy -303.50909423828125, Learning Rate: 0.0025\n",
      "Epoch [2168/20000], Loss: 347.5546569824219, Entropy -306.3142395019531, Learning Rate: 0.0025\n",
      "Epoch [2169/20000], Loss: 303.7344970703125, Entropy -294.06964111328125, Learning Rate: 0.0025\n",
      "Epoch [2170/20000], Loss: 314.1697998046875, Entropy -303.26348876953125, Learning Rate: 0.0025\n",
      "Epoch [2171/20000], Loss: 336.1681213378906, Entropy -305.10107421875, Learning Rate: 0.0025\n",
      "Epoch [2172/20000], Loss: 305.6007995605469, Entropy -306.5511779785156, Learning Rate: 0.00125\n",
      "Epoch [2173/20000], Loss: 324.4830627441406, Entropy -307.87115478515625, Learning Rate: 0.00125\n",
      "Epoch [2174/20000], Loss: 306.2635498046875, Entropy -302.9158630371094, Learning Rate: 0.00125\n",
      "Epoch [2175/20000], Loss: 314.4466857910156, Entropy -315.8739013671875, Learning Rate: 0.00125\n",
      "Epoch [2176/20000], Loss: 306.84942626953125, Entropy -309.0457763671875, Learning Rate: 0.00125\n",
      "Epoch [2177/20000], Loss: 313.57537841796875, Entropy -312.4777526855469, Learning Rate: 0.00125\n",
      "Epoch [2178/20000], Loss: 305.98992919921875, Entropy -312.63140869140625, Learning Rate: 0.00125\n",
      "Epoch [2179/20000], Loss: 298.38763427734375, Entropy -295.75067138671875, Learning Rate: 0.00125\n",
      "Epoch [2180/20000], Loss: 298.96527099609375, Entropy -301.4610290527344, Learning Rate: 0.00125\n",
      "Epoch [2181/20000], Loss: 321.13336181640625, Entropy -316.2266845703125, Learning Rate: 0.00125\n",
      "Epoch [2182/20000], Loss: 315.548583984375, Entropy -303.1064758300781, Learning Rate: 0.00125\n",
      "Epoch [2183/20000], Loss: 331.00421142578125, Entropy -321.6246032714844, Learning Rate: 0.00125\n",
      "Epoch [2184/20000], Loss: 330.76214599609375, Entropy -321.58587646484375, Learning Rate: 0.00125\n",
      "Epoch [2185/20000], Loss: 334.4480895996094, Entropy -320.9156188964844, Learning Rate: 0.00125\n",
      "Epoch [2186/20000], Loss: 308.3039245605469, Entropy -304.45880126953125, Learning Rate: 0.00125\n",
      "Epoch [2187/20000], Loss: 312.86883544921875, Entropy -300.500244140625, Learning Rate: 0.00125\n",
      "Epoch [2188/20000], Loss: 310.68853759765625, Entropy -315.0661315917969, Learning Rate: 0.00125\n",
      "Epoch [2189/20000], Loss: 312.3310546875, Entropy -312.94317626953125, Learning Rate: 0.00125\n",
      "Epoch [2190/20000], Loss: 316.2926025390625, Entropy -321.52569580078125, Learning Rate: 0.00125\n",
      "Epoch [2191/20000], Loss: 285.05487060546875, Entropy -294.6047668457031, Learning Rate: 0.00125\n",
      "Epoch [2192/20000], Loss: 318.233642578125, Entropy -313.1326599121094, Learning Rate: 0.00125\n",
      "Epoch [2193/20000], Loss: 302.6742248535156, Entropy -308.1017761230469, Learning Rate: 0.00125\n",
      "Epoch [2194/20000], Loss: 314.09765625, Entropy -311.2552490234375, Learning Rate: 0.00125\n",
      "Epoch [2195/20000], Loss: 315.6268310546875, Entropy -323.2875061035156, Learning Rate: 0.00125\n",
      "Epoch [2196/20000], Loss: 302.2875061035156, Entropy -305.3915710449219, Learning Rate: 0.00125\n",
      "Epoch [2197/20000], Loss: 316.7933044433594, Entropy -327.5614929199219, Learning Rate: 0.00125\n",
      "Epoch [2198/20000], Loss: 314.245361328125, Entropy -315.7909240722656, Learning Rate: 0.00125\n",
      "Epoch [2199/20000], Loss: 290.80853271484375, Entropy -299.2760925292969, Learning Rate: 0.00125\n",
      "Epoch [2200/20000], Loss: 307.42547607421875, Entropy -310.1892395019531, Learning Rate: 0.00125\n",
      "Epoch [2201/20000], Loss: 302.991943359375, Entropy -306.15087890625, Learning Rate: 0.00125\n",
      "Epoch [2202/20000], Loss: 297.2958984375, Entropy -310.3759460449219, Learning Rate: 0.00125\n",
      "Epoch [2203/20000], Loss: 315.66912841796875, Entropy -310.2463073730469, Learning Rate: 0.00125\n",
      "Epoch [2204/20000], Loss: 302.58428955078125, Entropy -299.1796569824219, Learning Rate: 0.00125\n",
      "Epoch [2205/20000], Loss: 306.5782775878906, Entropy -316.09930419921875, Learning Rate: 0.00125\n",
      "Epoch [2206/20000], Loss: 316.907470703125, Entropy -315.64373779296875, Learning Rate: 0.00125\n",
      "Epoch [2207/20000], Loss: 304.290771484375, Entropy -305.4349365234375, Learning Rate: 0.00125\n",
      "Epoch [2208/20000], Loss: 311.3728942871094, Entropy -319.6171875, Learning Rate: 0.00125\n",
      "Epoch [2209/20000], Loss: 311.03594970703125, Entropy -311.9924011230469, Learning Rate: 0.00125\n",
      "Epoch [2210/20000], Loss: 304.18060302734375, Entropy -311.3575439453125, Learning Rate: 0.00125\n",
      "Epoch [2211/20000], Loss: 302.74310302734375, Entropy -298.85723876953125, Learning Rate: 0.00125\n",
      "Epoch [2212/20000], Loss: 294.8291931152344, Entropy -308.0955505371094, Learning Rate: 0.00125\n",
      "Epoch [2213/20000], Loss: 316.9134521484375, Entropy -322.4692687988281, Learning Rate: 0.00125\n",
      "Epoch [2214/20000], Loss: 314.86785888671875, Entropy -316.50146484375, Learning Rate: 0.00125\n",
      "Epoch [2215/20000], Loss: 301.82708740234375, Entropy -312.47967529296875, Learning Rate: 0.00125\n",
      "Epoch [2216/20000], Loss: 306.02313232421875, Entropy -312.88446044921875, Learning Rate: 0.00125\n",
      "Epoch [2217/20000], Loss: 301.3662414550781, Entropy -303.4613037109375, Learning Rate: 0.00125\n",
      "Epoch [2218/20000], Loss: 306.39788818359375, Entropy -317.8384094238281, Learning Rate: 0.00125\n",
      "Epoch [2219/20000], Loss: 310.2603759765625, Entropy -306.2768249511719, Learning Rate: 0.00125\n",
      "Epoch [2220/20000], Loss: 350.9427490234375, Entropy -313.1570739746094, Learning Rate: 0.00125\n",
      "Epoch [2221/20000], Loss: 320.7506103515625, Entropy -313.48028564453125, Learning Rate: 0.00125\n",
      "Epoch [2222/20000], Loss: 312.78326416015625, Entropy -301.15142822265625, Learning Rate: 0.00125\n",
      "Epoch [2223/20000], Loss: 308.4249267578125, Entropy -297.96868896484375, Learning Rate: 0.00125\n",
      "Epoch [2224/20000], Loss: 304.084716796875, Entropy -301.3475341796875, Learning Rate: 0.00125\n",
      "Epoch [2225/20000], Loss: 322.395751953125, Entropy -328.1042785644531, Learning Rate: 0.00125\n",
      "Epoch [2226/20000], Loss: 303.72314453125, Entropy -310.7333679199219, Learning Rate: 0.00125\n",
      "Epoch [2227/20000], Loss: 318.24505615234375, Entropy -312.67034912109375, Learning Rate: 0.00125\n",
      "Epoch [2228/20000], Loss: 324.0313720703125, Entropy -311.3184814453125, Learning Rate: 0.00125\n",
      "Epoch [2229/20000], Loss: 289.212158203125, Entropy -300.8414001464844, Learning Rate: 0.00125\n",
      "Epoch [2230/20000], Loss: 308.37957763671875, Entropy -307.1324768066406, Learning Rate: 0.00125\n",
      "Epoch [2231/20000], Loss: 299.7352294921875, Entropy -302.0374755859375, Learning Rate: 0.00125\n",
      "Epoch [2232/20000], Loss: 309.1561584472656, Entropy -301.75433349609375, Learning Rate: 0.00125\n",
      "Epoch [2233/20000], Loss: 311.0982666015625, Entropy -307.6802062988281, Learning Rate: 0.00125\n",
      "Epoch [2234/20000], Loss: 316.613037109375, Entropy -306.6717834472656, Learning Rate: 0.00125\n",
      "Epoch [2235/20000], Loss: 306.64312744140625, Entropy -301.23602294921875, Learning Rate: 0.00125\n",
      "Epoch [2236/20000], Loss: 298.241455078125, Entropy -300.8006286621094, Learning Rate: 0.00125\n",
      "Epoch [2237/20000], Loss: 304.92498779296875, Entropy -314.60711669921875, Learning Rate: 0.00125\n",
      "Epoch [2238/20000], Loss: 307.13092041015625, Entropy -318.1936340332031, Learning Rate: 0.00125\n",
      "Epoch [2239/20000], Loss: 305.82720947265625, Entropy -314.59033203125, Learning Rate: 0.00125\n",
      "Epoch [2240/20000], Loss: 309.338623046875, Entropy -307.6875305175781, Learning Rate: 0.00125\n",
      "Epoch [2241/20000], Loss: 294.0125732421875, Entropy -297.0392761230469, Learning Rate: 0.00125\n",
      "Epoch [2242/20000], Loss: 308.72723388671875, Entropy -313.0835876464844, Learning Rate: 0.00125\n",
      "Epoch [2243/20000], Loss: 305.96160888671875, Entropy -315.332763671875, Learning Rate: 0.00125\n",
      "Epoch [2244/20000], Loss: 288.5412902832031, Entropy -303.8252868652344, Learning Rate: 0.00125\n",
      "Epoch [2245/20000], Loss: 301.8539733886719, Entropy -305.82208251953125, Learning Rate: 0.00125\n",
      "Epoch [2246/20000], Loss: 307.82147216796875, Entropy -311.34991455078125, Learning Rate: 0.00125\n",
      "Epoch [2247/20000], Loss: 304.99798583984375, Entropy -318.5299987792969, Learning Rate: 0.00125\n",
      "Epoch [2248/20000], Loss: 315.03900146484375, Entropy -318.4817199707031, Learning Rate: 0.00125\n",
      "Epoch [2249/20000], Loss: 289.5669250488281, Entropy -299.43743896484375, Learning Rate: 0.00125\n",
      "Epoch [2250/20000], Loss: 302.603515625, Entropy -298.3495178222656, Learning Rate: 0.00125\n",
      "Epoch [2251/20000], Loss: 299.9907531738281, Entropy -307.69317626953125, Learning Rate: 0.00125\n",
      "Epoch [2252/20000], Loss: 316.77703857421875, Entropy -309.3869934082031, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2253/20000], Loss: 306.19720458984375, Entropy -311.8902282714844, Learning Rate: 0.00125\n",
      "Epoch [2254/20000], Loss: 310.88238525390625, Entropy -318.33880615234375, Learning Rate: 0.00125\n",
      "Epoch [2255/20000], Loss: 326.96881103515625, Entropy -327.28265380859375, Learning Rate: 0.00125\n",
      "Epoch [2256/20000], Loss: 307.96148681640625, Entropy -310.77447509765625, Learning Rate: 0.00125\n",
      "Epoch [2257/20000], Loss: 322.95440673828125, Entropy -314.0995788574219, Learning Rate: 0.00125\n",
      "Epoch [2258/20000], Loss: 308.09991455078125, Entropy -321.2315979003906, Learning Rate: 0.00125\n",
      "Epoch [2259/20000], Loss: 293.989501953125, Entropy -303.0668029785156, Learning Rate: 0.00125\n",
      "Epoch [2260/20000], Loss: 302.450927734375, Entropy -310.98046875, Learning Rate: 0.00125\n",
      "Epoch [2261/20000], Loss: 298.2807922363281, Entropy -306.0348815917969, Learning Rate: 0.00125\n",
      "Epoch [2262/20000], Loss: 300.5792236328125, Entropy -311.7095947265625, Learning Rate: 0.00125\n",
      "Epoch [2263/20000], Loss: 304.90972900390625, Entropy -317.29180908203125, Learning Rate: 0.00125\n",
      "Epoch [2264/20000], Loss: 314.093994140625, Entropy -311.9320068359375, Learning Rate: 0.00125\n",
      "Epoch [2265/20000], Loss: 318.5791320800781, Entropy -315.1430969238281, Learning Rate: 0.00125\n",
      "Epoch [2266/20000], Loss: 300.12957763671875, Entropy -302.8763732910156, Learning Rate: 0.00125\n",
      "Epoch [2267/20000], Loss: 315.0387878417969, Entropy -323.3030700683594, Learning Rate: 0.00125\n",
      "Epoch [2268/20000], Loss: 313.1024475097656, Entropy -297.16607666015625, Learning Rate: 0.00125\n",
      "Epoch [2269/20000], Loss: 290.4852294921875, Entropy -297.8896179199219, Learning Rate: 0.00125\n",
      "Epoch [2270/20000], Loss: 314.22412109375, Entropy -313.11614990234375, Learning Rate: 0.00125\n",
      "Epoch [2271/20000], Loss: 301.946044921875, Entropy -301.1770324707031, Learning Rate: 0.00125\n",
      "Epoch [2272/20000], Loss: 308.13043212890625, Entropy -299.3782653808594, Learning Rate: 0.00125\n",
      "Epoch [2273/20000], Loss: 308.27294921875, Entropy -315.0777587890625, Learning Rate: 0.00125\n",
      "Epoch [2274/20000], Loss: 314.3138732910156, Entropy -326.14825439453125, Learning Rate: 0.00125\n",
      "Epoch [2275/20000], Loss: 320.5301513671875, Entropy -314.7468566894531, Learning Rate: 0.00125\n",
      "Epoch [2276/20000], Loss: 292.33233642578125, Entropy -303.7398681640625, Learning Rate: 0.00125\n",
      "Epoch [2277/20000], Loss: 303.5701599121094, Entropy -314.5081481933594, Learning Rate: 0.00125\n",
      "Epoch [2278/20000], Loss: 302.028564453125, Entropy -305.5162048339844, Learning Rate: 0.00125\n",
      "Epoch [2279/20000], Loss: 302.30706787109375, Entropy -305.4857177734375, Learning Rate: 0.00125\n",
      "Epoch [2280/20000], Loss: 293.06707763671875, Entropy -294.54010009765625, Learning Rate: 0.00125\n",
      "Epoch [2281/20000], Loss: 305.87457275390625, Entropy -313.5229797363281, Learning Rate: 0.00125\n",
      "Epoch [2282/20000], Loss: 300.36822509765625, Entropy -307.8416442871094, Learning Rate: 0.00125\n",
      "Epoch [2283/20000], Loss: 300.51324462890625, Entropy -313.5224304199219, Learning Rate: 0.00125\n",
      "Epoch [2284/20000], Loss: 303.03045654296875, Entropy -310.4305725097656, Learning Rate: 0.00125\n",
      "Epoch [2285/20000], Loss: 317.0381774902344, Entropy -333.65606689453125, Learning Rate: 0.00125\n",
      "Epoch [2286/20000], Loss: 306.32415771484375, Entropy -317.3174743652344, Learning Rate: 0.00125\n",
      "Epoch [2287/20000], Loss: 288.0741882324219, Entropy -296.43914794921875, Learning Rate: 0.00125\n",
      "Epoch [2288/20000], Loss: 306.5589904785156, Entropy -310.2035217285156, Learning Rate: 0.00125\n",
      "Epoch [2289/20000], Loss: 301.33465576171875, Entropy -311.8983459472656, Learning Rate: 0.00125\n",
      "Epoch [2290/20000], Loss: 312.63494873046875, Entropy -314.58953857421875, Learning Rate: 0.00125\n",
      "Epoch [2291/20000], Loss: 296.4356384277344, Entropy -299.51434326171875, Learning Rate: 0.00125\n",
      "Epoch [2292/20000], Loss: 304.467529296875, Entropy -307.9787292480469, Learning Rate: 0.00125\n",
      "Epoch [2293/20000], Loss: 291.38751220703125, Entropy -296.42364501953125, Learning Rate: 0.00125\n",
      "Epoch [2294/20000], Loss: 305.83447265625, Entropy -313.38446044921875, Learning Rate: 0.00125\n",
      "Epoch [2295/20000], Loss: 299.3460998535156, Entropy -307.6107177734375, Learning Rate: 0.00125\n",
      "Epoch [2296/20000], Loss: 288.06524658203125, Entropy -289.47247314453125, Learning Rate: 0.00125\n",
      "Epoch [2297/20000], Loss: 284.11444091796875, Entropy -290.02496337890625, Learning Rate: 0.00125\n",
      "Epoch [2298/20000], Loss: 321.3343505859375, Entropy -327.8395690917969, Learning Rate: 0.00125\n",
      "Epoch [2299/20000], Loss: 314.3162536621094, Entropy -316.05584716796875, Learning Rate: 0.00125\n",
      "Epoch [2300/20000], Loss: 294.224365234375, Entropy -289.1907958984375, Learning Rate: 0.00125\n",
      "Epoch [2301/20000], Loss: 303.468505859375, Entropy -310.21502685546875, Learning Rate: 0.00125\n",
      "Epoch [2302/20000], Loss: 305.187744140625, Entropy -309.2833251953125, Learning Rate: 0.00125\n",
      "Epoch [2303/20000], Loss: 314.95782470703125, Entropy -319.7103576660156, Learning Rate: 0.00125\n",
      "Epoch [2304/20000], Loss: 310.25140380859375, Entropy -313.1630859375, Learning Rate: 0.00125\n",
      "Epoch [2305/20000], Loss: 291.3786926269531, Entropy -300.23175048828125, Learning Rate: 0.00125\n",
      "Epoch [2306/20000], Loss: 298.3348693847656, Entropy -300.6732482910156, Learning Rate: 0.00125\n",
      "Epoch [2307/20000], Loss: 291.7528991699219, Entropy -297.10400390625, Learning Rate: 0.00125\n",
      "Epoch [2308/20000], Loss: 295.25445556640625, Entropy -299.4824523925781, Learning Rate: 0.00125\n",
      "Epoch [2309/20000], Loss: 277.9075927734375, Entropy -292.916748046875, Learning Rate: 0.00125\n",
      "Epoch [2310/20000], Loss: 312.2503967285156, Entropy -317.9967956542969, Learning Rate: 0.00125\n",
      "Epoch [2311/20000], Loss: 296.3218994140625, Entropy -302.1036376953125, Learning Rate: 0.00125\n",
      "Epoch [2312/20000], Loss: 312.01983642578125, Entropy -311.5616760253906, Learning Rate: 0.00125\n",
      "Epoch [2313/20000], Loss: 286.96807861328125, Entropy -301.5252685546875, Learning Rate: 0.00125\n",
      "Epoch [2314/20000], Loss: 296.34661865234375, Entropy -308.4706726074219, Learning Rate: 0.00125\n",
      "Epoch [2315/20000], Loss: 302.55450439453125, Entropy -304.3494873046875, Learning Rate: 0.00125\n",
      "Epoch [2316/20000], Loss: 292.5596618652344, Entropy -302.9404296875, Learning Rate: 0.00125\n",
      "Epoch [2317/20000], Loss: 320.01275634765625, Entropy -327.29833984375, Learning Rate: 0.00125\n",
      "Epoch [2318/20000], Loss: 303.4700012207031, Entropy -307.4434509277344, Learning Rate: 0.00125\n",
      "Epoch [2319/20000], Loss: 317.4578857421875, Entropy -321.9254150390625, Learning Rate: 0.00125\n",
      "Epoch [2320/20000], Loss: 305.6819152832031, Entropy -317.49578857421875, Learning Rate: 0.00125\n",
      "Epoch [2321/20000], Loss: 304.7093200683594, Entropy -306.7357177734375, Learning Rate: 0.00125\n",
      "Epoch [2322/20000], Loss: 309.6871337890625, Entropy -306.51837158203125, Learning Rate: 0.00125\n",
      "Epoch [2323/20000], Loss: 311.9848937988281, Entropy -319.3799743652344, Learning Rate: 0.00125\n",
      "Epoch [2324/20000], Loss: 293.27227783203125, Entropy -306.80035400390625, Learning Rate: 0.00125\n",
      "Epoch [2325/20000], Loss: 306.41766357421875, Entropy -311.3432922363281, Learning Rate: 0.00125\n",
      "Epoch [2326/20000], Loss: 316.97613525390625, Entropy -332.3398132324219, Learning Rate: 0.00125\n",
      "Epoch [2327/20000], Loss: 308.13543701171875, Entropy -297.2900085449219, Learning Rate: 0.00125\n",
      "Epoch [2328/20000], Loss: 299.91412353515625, Entropy -302.4464111328125, Learning Rate: 0.00125\n",
      "Epoch [2329/20000], Loss: 293.19268798828125, Entropy -306.21881103515625, Learning Rate: 0.00125\n",
      "Epoch [2330/20000], Loss: 288.3572998046875, Entropy -298.12164306640625, Learning Rate: 0.00125\n",
      "Epoch [2331/20000], Loss: 289.721435546875, Entropy -303.9773864746094, Learning Rate: 0.00125\n",
      "Epoch [2332/20000], Loss: 306.9185791015625, Entropy -308.9226379394531, Learning Rate: 0.00125\n",
      "Epoch [2333/20000], Loss: 293.9137268066406, Entropy -305.69586181640625, Learning Rate: 0.00125\n",
      "Epoch [2334/20000], Loss: 300.18023681640625, Entropy -315.3476867675781, Learning Rate: 0.00125\n",
      "Epoch [2335/20000], Loss: 294.6868896484375, Entropy -299.6048583984375, Learning Rate: 0.00125\n",
      "Epoch [2336/20000], Loss: 298.3394470214844, Entropy -310.7765808105469, Learning Rate: 0.00125\n",
      "Epoch [2337/20000], Loss: 303.69024658203125, Entropy -315.7450256347656, Learning Rate: 0.00125\n",
      "Epoch [2338/20000], Loss: 293.296142578125, Entropy -291.65142822265625, Learning Rate: 0.00125\n",
      "Epoch [2339/20000], Loss: 325.9726867675781, Entropy -328.1336669921875, Learning Rate: 0.00125\n",
      "Epoch [2340/20000], Loss: 303.3450927734375, Entropy -309.3985290527344, Learning Rate: 0.00125\n",
      "Epoch [2341/20000], Loss: 289.67901611328125, Entropy -296.7677001953125, Learning Rate: 0.00125\n",
      "Epoch [2342/20000], Loss: 307.37896728515625, Entropy -309.35675048828125, Learning Rate: 0.00125\n",
      "Epoch [2343/20000], Loss: 316.9827575683594, Entropy -304.0016174316406, Learning Rate: 0.00125\n",
      "Epoch [2344/20000], Loss: 294.772705078125, Entropy -311.9344787597656, Learning Rate: 0.00125\n",
      "Epoch [2345/20000], Loss: 300.83758544921875, Entropy -304.65484619140625, Learning Rate: 0.00125\n",
      "Epoch [2346/20000], Loss: 299.16168212890625, Entropy -305.5932312011719, Learning Rate: 0.00125\n",
      "Epoch [2347/20000], Loss: 306.74114990234375, Entropy -309.3668518066406, Learning Rate: 0.00125\n",
      "Epoch [2348/20000], Loss: 311.0715026855469, Entropy -308.04217529296875, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2349/20000], Loss: 293.0801696777344, Entropy -301.5754699707031, Learning Rate: 0.00125\n",
      "Epoch [2350/20000], Loss: 290.608154296875, Entropy -303.3417663574219, Learning Rate: 0.00125\n",
      "Epoch [2351/20000], Loss: 280.37353515625, Entropy -292.73333740234375, Learning Rate: 0.00125\n",
      "Epoch [2352/20000], Loss: 303.7388916015625, Entropy -306.7078552246094, Learning Rate: 0.00125\n",
      "Epoch [2353/20000], Loss: 301.8327941894531, Entropy -292.9042053222656, Learning Rate: 0.00125\n",
      "Epoch [2354/20000], Loss: 311.9913330078125, Entropy -312.9353942871094, Learning Rate: 0.00125\n",
      "Epoch [2355/20000], Loss: 300.5423583984375, Entropy -309.2160949707031, Learning Rate: 0.00125\n",
      "Epoch [2356/20000], Loss: 310.013916015625, Entropy -315.97601318359375, Learning Rate: 0.00125\n",
      "Epoch [2357/20000], Loss: 315.44403076171875, Entropy -314.7916259765625, Learning Rate: 0.00125\n",
      "Epoch [2358/20000], Loss: 311.55963134765625, Entropy -305.9688720703125, Learning Rate: 0.00125\n",
      "Epoch [2359/20000], Loss: 284.7701416015625, Entropy -293.5990905761719, Learning Rate: 0.00125\n",
      "Epoch [2360/20000], Loss: 307.78485107421875, Entropy -310.7892761230469, Learning Rate: 0.00125\n",
      "Epoch [2361/20000], Loss: 311.961669921875, Entropy -312.4159851074219, Learning Rate: 0.00125\n",
      "Epoch [2362/20000], Loss: 305.46966552734375, Entropy -305.05126953125, Learning Rate: 0.00125\n",
      "Epoch [2363/20000], Loss: 325.498779296875, Entropy -327.48883056640625, Learning Rate: 0.00125\n",
      "Epoch [2364/20000], Loss: 285.1588134765625, Entropy -282.028076171875, Learning Rate: 0.00125\n",
      "Epoch [2365/20000], Loss: 311.3302001953125, Entropy -317.0450744628906, Learning Rate: 0.00125\n",
      "Epoch [2366/20000], Loss: 330.3501281738281, Entropy -316.65960693359375, Learning Rate: 0.00125\n",
      "Epoch [2367/20000], Loss: 328.1885986328125, Entropy -311.7373962402344, Learning Rate: 0.00125\n",
      "Epoch [2368/20000], Loss: 286.86669921875, Entropy -287.0899658203125, Learning Rate: 0.00125\n",
      "Epoch [2369/20000], Loss: 316.39971923828125, Entropy -304.57525634765625, Learning Rate: 0.00125\n",
      "Epoch [2370/20000], Loss: 298.43060302734375, Entropy -293.8448486328125, Learning Rate: 0.00125\n",
      "Epoch [2371/20000], Loss: 306.0166015625, Entropy -307.5514221191406, Learning Rate: 0.00125\n",
      "Epoch [2372/20000], Loss: 309.8089599609375, Entropy -307.02392578125, Learning Rate: 0.00125\n",
      "Epoch [2373/20000], Loss: 332.6145324707031, Entropy -321.7566833496094, Learning Rate: 0.00125\n",
      "Epoch [2374/20000], Loss: 302.50335693359375, Entropy -305.7069091796875, Learning Rate: 0.00125\n",
      "Epoch [2375/20000], Loss: 304.3410949707031, Entropy -315.7008972167969, Learning Rate: 0.00125\n",
      "Epoch [2376/20000], Loss: 301.5096130371094, Entropy -308.0859069824219, Learning Rate: 0.00125\n",
      "Epoch [2377/20000], Loss: 305.3114013671875, Entropy -310.93768310546875, Learning Rate: 0.00125\n",
      "Epoch [2378/20000], Loss: 321.2250671386719, Entropy -312.0408630371094, Learning Rate: 0.00125\n",
      "Epoch [2379/20000], Loss: 306.3260498046875, Entropy -306.88714599609375, Learning Rate: 0.00125\n",
      "Epoch [2380/20000], Loss: 294.7334899902344, Entropy -305.0885925292969, Learning Rate: 0.00125\n",
      "Epoch [2381/20000], Loss: 294.94708251953125, Entropy -304.705078125, Learning Rate: 0.00125\n",
      "Epoch [2382/20000], Loss: 300.70233154296875, Entropy -313.2648620605469, Learning Rate: 0.00125\n",
      "Epoch [2383/20000], Loss: 323.3257751464844, Entropy -303.1881103515625, Learning Rate: 0.00125\n",
      "Epoch [2384/20000], Loss: 299.78594970703125, Entropy -303.43719482421875, Learning Rate: 0.00125\n",
      "Epoch [2385/20000], Loss: 302.30682373046875, Entropy -303.4544372558594, Learning Rate: 0.00125\n",
      "Epoch [2386/20000], Loss: 299.020263671875, Entropy -301.8024597167969, Learning Rate: 0.00125\n",
      "Epoch [2387/20000], Loss: 309.295654296875, Entropy -302.394775390625, Learning Rate: 0.00125\n",
      "Epoch [2388/20000], Loss: 303.058837890625, Entropy -303.11199951171875, Learning Rate: 0.00125\n",
      "Epoch [2389/20000], Loss: 315.211181640625, Entropy -314.3238830566406, Learning Rate: 0.00125\n",
      "Epoch [2390/20000], Loss: 302.5639953613281, Entropy -305.913818359375, Learning Rate: 0.00125\n",
      "Epoch [2391/20000], Loss: 312.6710510253906, Entropy -308.57049560546875, Learning Rate: 0.00125\n",
      "Epoch [2392/20000], Loss: 306.3795166015625, Entropy -316.5628356933594, Learning Rate: 0.00125\n",
      "Epoch [2393/20000], Loss: 299.0335693359375, Entropy -301.100341796875, Learning Rate: 0.00125\n",
      "Epoch [2394/20000], Loss: 297.4988708496094, Entropy -304.2286071777344, Learning Rate: 0.00125\n",
      "Epoch [2395/20000], Loss: 310.226806640625, Entropy -300.4187316894531, Learning Rate: 0.00125\n",
      "Epoch [2396/20000], Loss: 296.072021484375, Entropy -298.0337829589844, Learning Rate: 0.00125\n",
      "Epoch [2397/20000], Loss: 306.8380126953125, Entropy -307.03802490234375, Learning Rate: 0.00125\n",
      "Epoch [2398/20000], Loss: 301.925537109375, Entropy -294.1474609375, Learning Rate: 0.00125\n",
      "Epoch [2399/20000], Loss: 309.1109619140625, Entropy -306.8991394042969, Learning Rate: 0.00125\n",
      "Epoch [2400/20000], Loss: 304.99432373046875, Entropy -309.9493103027344, Learning Rate: 0.00125\n",
      "Epoch [2401/20000], Loss: 284.39410400390625, Entropy -291.4472351074219, Learning Rate: 0.00125\n",
      "Epoch [2402/20000], Loss: 300.608154296875, Entropy -292.34881591796875, Learning Rate: 0.00125\n",
      "Epoch [2403/20000], Loss: 326.2447509765625, Entropy -324.2202453613281, Learning Rate: 0.00125\n",
      "Epoch [2404/20000], Loss: 320.3565979003906, Entropy -304.46783447265625, Learning Rate: 0.00125\n",
      "Epoch [2405/20000], Loss: 309.82305908203125, Entropy -312.0748291015625, Learning Rate: 0.00125\n",
      "Epoch [2406/20000], Loss: 313.8877868652344, Entropy -304.19720458984375, Learning Rate: 0.00125\n",
      "Epoch [2407/20000], Loss: 304.8538818359375, Entropy -307.16290283203125, Learning Rate: 0.00125\n",
      "Epoch [2408/20000], Loss: 305.80816650390625, Entropy -297.0549621582031, Learning Rate: 0.00125\n",
      "Epoch [2409/20000], Loss: 293.32720947265625, Entropy -305.7364501953125, Learning Rate: 0.00125\n",
      "Epoch [2410/20000], Loss: 298.18743896484375, Entropy -307.2329406738281, Learning Rate: 0.00125\n",
      "Epoch [2411/20000], Loss: 307.49005126953125, Entropy -308.72314453125, Learning Rate: 0.00125\n",
      "Epoch [2412/20000], Loss: 308.60406494140625, Entropy -322.20904541015625, Learning Rate: 0.00125\n",
      "Epoch [2413/20000], Loss: 313.2867126464844, Entropy -321.0433044433594, Learning Rate: 0.00125\n",
      "Epoch [2414/20000], Loss: 296.052490234375, Entropy -300.6972351074219, Learning Rate: 0.00125\n",
      "Epoch [2415/20000], Loss: 302.49774169921875, Entropy -309.134033203125, Learning Rate: 0.00125\n",
      "Epoch [2416/20000], Loss: 306.52008056640625, Entropy -306.69647216796875, Learning Rate: 0.00125\n",
      "Epoch [2417/20000], Loss: 314.9369201660156, Entropy -324.89385986328125, Learning Rate: 0.00125\n",
      "Epoch [2418/20000], Loss: 304.5304870605469, Entropy -311.29095458984375, Learning Rate: 0.00125\n",
      "Epoch [2419/20000], Loss: 293.68597412109375, Entropy -300.38671875, Learning Rate: 0.00125\n",
      "Epoch [2420/20000], Loss: 305.54608154296875, Entropy -309.9010314941406, Learning Rate: 0.00125\n",
      "Epoch [2421/20000], Loss: 312.15118408203125, Entropy -310.44757080078125, Learning Rate: 0.00125\n",
      "Epoch [2422/20000], Loss: 312.38079833984375, Entropy -324.82147216796875, Learning Rate: 0.00125\n",
      "Epoch [2423/20000], Loss: 293.33001708984375, Entropy -304.0831298828125, Learning Rate: 0.00125\n",
      "Epoch [2424/20000], Loss: 292.22918701171875, Entropy -310.4423522949219, Learning Rate: 0.00125\n",
      "Epoch [2425/20000], Loss: 304.672607421875, Entropy -312.24139404296875, Learning Rate: 0.00125\n",
      "Epoch [2426/20000], Loss: 295.5295104980469, Entropy -305.3336181640625, Learning Rate: 0.00125\n",
      "Epoch [2427/20000], Loss: 295.70013427734375, Entropy -307.0048828125, Learning Rate: 0.00125\n",
      "Epoch [2428/20000], Loss: 294.59716796875, Entropy -308.367431640625, Learning Rate: 0.00125\n",
      "Epoch [2429/20000], Loss: 300.0053405761719, Entropy -310.5682067871094, Learning Rate: 0.00125\n",
      "Epoch [2430/20000], Loss: 301.1425476074219, Entropy -310.5627136230469, Learning Rate: 0.00125\n",
      "Epoch [2431/20000], Loss: 320.2235107421875, Entropy -314.76849365234375, Learning Rate: 0.00125\n",
      "Epoch [2432/20000], Loss: 293.273681640625, Entropy -307.266845703125, Learning Rate: 0.00125\n",
      "Epoch [2433/20000], Loss: 312.0401611328125, Entropy -318.8075866699219, Learning Rate: 0.00125\n",
      "Epoch [2434/20000], Loss: 299.88116455078125, Entropy -309.20050048828125, Learning Rate: 0.00125\n",
      "Epoch [2435/20000], Loss: 271.48779296875, Entropy -284.9827880859375, Learning Rate: 0.00125\n",
      "Epoch [2436/20000], Loss: 292.08990478515625, Entropy -296.01837158203125, Learning Rate: 0.00125\n",
      "Epoch [2437/20000], Loss: 308.09710693359375, Entropy -309.77972412109375, Learning Rate: 0.00125\n",
      "Epoch [2438/20000], Loss: 299.06591796875, Entropy -302.73797607421875, Learning Rate: 0.00125\n",
      "Epoch [2439/20000], Loss: 292.3973388671875, Entropy -299.51739501953125, Learning Rate: 0.00125\n",
      "Epoch [2440/20000], Loss: 320.63604736328125, Entropy -316.7122802734375, Learning Rate: 0.00125\n",
      "Epoch [2441/20000], Loss: 306.3630065917969, Entropy -315.2684326171875, Learning Rate: 0.00125\n",
      "Epoch [2442/20000], Loss: 295.57025146484375, Entropy -304.2308654785156, Learning Rate: 0.00125\n",
      "Epoch [2443/20000], Loss: 297.14044189453125, Entropy -305.1017761230469, Learning Rate: 0.00125\n",
      "Epoch [2444/20000], Loss: 315.56439208984375, Entropy -320.91107177734375, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2445/20000], Loss: 324.16839599609375, Entropy -324.55157470703125, Learning Rate: 0.00125\n",
      "Epoch [2446/20000], Loss: 293.32012939453125, Entropy -302.4797668457031, Learning Rate: 0.00125\n",
      "Epoch [2447/20000], Loss: 294.20269775390625, Entropy -303.7881164550781, Learning Rate: 0.00125\n",
      "Epoch [2448/20000], Loss: 329.4952697753906, Entropy -331.2673034667969, Learning Rate: 0.00125\n",
      "Epoch [2449/20000], Loss: 304.7728271484375, Entropy -314.11993408203125, Learning Rate: 0.00125\n",
      "Epoch [2450/20000], Loss: 299.1180419921875, Entropy -310.2042541503906, Learning Rate: 0.00125\n",
      "Epoch [2451/20000], Loss: 305.6778564453125, Entropy -301.8406677246094, Learning Rate: 0.00125\n",
      "Epoch [2452/20000], Loss: 292.4940185546875, Entropy -299.2081604003906, Learning Rate: 0.00125\n",
      "Epoch [2453/20000], Loss: 304.73870849609375, Entropy -315.29925537109375, Learning Rate: 0.00125\n",
      "Epoch [2454/20000], Loss: 292.29864501953125, Entropy -308.1383972167969, Learning Rate: 0.00125\n",
      "Epoch [2455/20000], Loss: 300.32763671875, Entropy -310.9443054199219, Learning Rate: 0.00125\n",
      "Epoch [2456/20000], Loss: 294.492919921875, Entropy -300.3741455078125, Learning Rate: 0.00125\n",
      "Epoch [2457/20000], Loss: 300.6646728515625, Entropy -302.5075988769531, Learning Rate: 0.00125\n",
      "Epoch [2458/20000], Loss: 314.0938720703125, Entropy -324.1308288574219, Learning Rate: 0.00125\n",
      "Epoch [2459/20000], Loss: 305.567138671875, Entropy -321.032958984375, Learning Rate: 0.00125\n",
      "Epoch [2460/20000], Loss: 284.0633850097656, Entropy -287.1879577636719, Learning Rate: 0.00125\n",
      "Epoch [2461/20000], Loss: 307.9417724609375, Entropy -310.7340393066406, Learning Rate: 0.00125\n",
      "Epoch [2462/20000], Loss: 304.5377502441406, Entropy -319.41534423828125, Learning Rate: 0.00125\n",
      "Epoch [2463/20000], Loss: 296.76739501953125, Entropy -309.7547607421875, Learning Rate: 0.00125\n",
      "Epoch [2464/20000], Loss: 295.0568542480469, Entropy -308.2168273925781, Learning Rate: 0.00125\n",
      "Epoch [2465/20000], Loss: 290.2815246582031, Entropy -297.58251953125, Learning Rate: 0.00125\n",
      "Epoch [2466/20000], Loss: 305.2362060546875, Entropy -302.3692626953125, Learning Rate: 0.00125\n",
      "Epoch [2467/20000], Loss: 297.2335205078125, Entropy -302.17425537109375, Learning Rate: 0.00125\n",
      "Epoch [2468/20000], Loss: 296.26434326171875, Entropy -303.3093566894531, Learning Rate: 0.00125\n",
      "Epoch [2469/20000], Loss: 305.31976318359375, Entropy -318.56597900390625, Learning Rate: 0.00125\n",
      "Epoch [2470/20000], Loss: 304.7402648925781, Entropy -311.0782470703125, Learning Rate: 0.00125\n",
      "Epoch [2471/20000], Loss: 309.38232421875, Entropy -315.13470458984375, Learning Rate: 0.00125\n",
      "Epoch [2472/20000], Loss: 297.21258544921875, Entropy -298.6758728027344, Learning Rate: 0.00125\n",
      "Epoch [2473/20000], Loss: 316.3861083984375, Entropy -308.4668273925781, Learning Rate: 0.00125\n",
      "Epoch [2474/20000], Loss: 292.5757141113281, Entropy -306.5957946777344, Learning Rate: 0.00125\n",
      "Epoch [2475/20000], Loss: 298.5545959472656, Entropy -306.7237548828125, Learning Rate: 0.00125\n",
      "Epoch [2476/20000], Loss: 294.56817626953125, Entropy -307.32525634765625, Learning Rate: 0.00125\n",
      "Epoch [2477/20000], Loss: 293.9513244628906, Entropy -301.7120361328125, Learning Rate: 0.00125\n",
      "Epoch [2478/20000], Loss: 313.912109375, Entropy -320.04388427734375, Learning Rate: 0.00125\n",
      "Epoch [2479/20000], Loss: 324.29290771484375, Entropy -321.139404296875, Learning Rate: 0.00125\n",
      "Epoch [2480/20000], Loss: 308.16815185546875, Entropy -309.8653869628906, Learning Rate: 0.00125\n",
      "Epoch [2481/20000], Loss: 295.21832275390625, Entropy -303.8798828125, Learning Rate: 0.00125\n",
      "Epoch [2482/20000], Loss: 300.977783203125, Entropy -313.9242248535156, Learning Rate: 0.00125\n",
      "Epoch [2483/20000], Loss: 301.91015625, Entropy -309.0664978027344, Learning Rate: 0.00125\n",
      "Epoch [2484/20000], Loss: 309.65570068359375, Entropy -315.8443603515625, Learning Rate: 0.00125\n",
      "Epoch [2485/20000], Loss: 303.0103759765625, Entropy -316.6806335449219, Learning Rate: 0.00125\n",
      "Epoch [2486/20000], Loss: 294.4864807128906, Entropy -308.2720947265625, Learning Rate: 0.00125\n",
      "Epoch [2487/20000], Loss: 286.04473876953125, Entropy -295.65850830078125, Learning Rate: 0.00125\n",
      "Epoch [2488/20000], Loss: 308.5877380371094, Entropy -301.55792236328125, Learning Rate: 0.00125\n",
      "Epoch [2489/20000], Loss: 300.5220947265625, Entropy -313.0238342285156, Learning Rate: 0.00125\n",
      "Epoch [2490/20000], Loss: 283.4541320800781, Entropy -291.4924621582031, Learning Rate: 0.00125\n",
      "Epoch [2491/20000], Loss: 309.75787353515625, Entropy -324.7677307128906, Learning Rate: 0.00125\n",
      "Epoch [2492/20000], Loss: 297.29156494140625, Entropy -309.2309265136719, Learning Rate: 0.00125\n",
      "Epoch [2493/20000], Loss: 296.5680236816406, Entropy -305.55841064453125, Learning Rate: 0.00125\n",
      "Epoch [2494/20000], Loss: 311.0487365722656, Entropy -309.27459716796875, Learning Rate: 0.00125\n",
      "Epoch [2495/20000], Loss: 315.236328125, Entropy -320.66900634765625, Learning Rate: 0.00125\n",
      "Epoch [2496/20000], Loss: 310.42730712890625, Entropy -311.3444519042969, Learning Rate: 0.00125\n",
      "Epoch [2497/20000], Loss: 300.2330322265625, Entropy -312.30767822265625, Learning Rate: 0.00125\n",
      "Epoch [2498/20000], Loss: 294.14971923828125, Entropy -302.7545471191406, Learning Rate: 0.00125\n",
      "Epoch [2499/20000], Loss: 296.6824951171875, Entropy -297.875244140625, Learning Rate: 0.00125\n",
      "Epoch [2500/20000], Loss: 311.9331359863281, Entropy -317.1967468261719, Learning Rate: 0.00125\n",
      "Epoch [2501/20000], Loss: 298.18603515625, Entropy -305.8789367675781, Learning Rate: 0.00125\n",
      "Epoch [2502/20000], Loss: 282.7921142578125, Entropy -299.82659912109375, Learning Rate: 0.00125\n",
      "Epoch [2503/20000], Loss: 301.4288635253906, Entropy -307.9794616699219, Learning Rate: 0.00125\n",
      "Epoch [2504/20000], Loss: 301.19757080078125, Entropy -307.9580993652344, Learning Rate: 0.00125\n",
      "Epoch [2505/20000], Loss: 295.3331298828125, Entropy -293.7682800292969, Learning Rate: 0.00125\n",
      "Epoch [2506/20000], Loss: 290.024658203125, Entropy -300.6175537109375, Learning Rate: 0.00125\n",
      "Epoch [2507/20000], Loss: 278.369384765625, Entropy -294.76898193359375, Learning Rate: 0.00125\n",
      "Epoch [2508/20000], Loss: 293.754638671875, Entropy -310.8157043457031, Learning Rate: 0.00125\n",
      "Epoch [2509/20000], Loss: 304.134521484375, Entropy -321.2175598144531, Learning Rate: 0.00125\n",
      "Epoch [2510/20000], Loss: 293.76837158203125, Entropy -300.8063659667969, Learning Rate: 0.00125\n",
      "Epoch [2511/20000], Loss: 304.54913330078125, Entropy -322.8108215332031, Learning Rate: 0.00125\n",
      "Epoch [2512/20000], Loss: 313.93756103515625, Entropy -314.177001953125, Learning Rate: 0.00125\n",
      "Epoch [2513/20000], Loss: 282.1656188964844, Entropy -296.9938049316406, Learning Rate: 0.00125\n",
      "Epoch [2514/20000], Loss: 289.9154052734375, Entropy -305.5459289550781, Learning Rate: 0.00125\n",
      "Epoch [2515/20000], Loss: 288.5412902832031, Entropy -299.6829528808594, Learning Rate: 0.00125\n",
      "Epoch [2516/20000], Loss: 303.0693359375, Entropy -307.7637023925781, Learning Rate: 0.00125\n",
      "Epoch [2517/20000], Loss: 291.3529052734375, Entropy -304.4781188964844, Learning Rate: 0.00125\n",
      "Epoch [2518/20000], Loss: 285.417236328125, Entropy -293.46087646484375, Learning Rate: 0.00125\n",
      "Epoch [2519/20000], Loss: 284.0006103515625, Entropy -298.247314453125, Learning Rate: 0.00125\n",
      "Epoch [2520/20000], Loss: 291.1808776855469, Entropy -306.1374206542969, Learning Rate: 0.00125\n",
      "Epoch [2521/20000], Loss: 291.13507080078125, Entropy -297.10693359375, Learning Rate: 0.00125\n",
      "Epoch [2522/20000], Loss: 309.055419921875, Entropy -313.08282470703125, Learning Rate: 0.00125\n",
      "Epoch [2523/20000], Loss: 297.00323486328125, Entropy -315.38873291015625, Learning Rate: 0.00125\n",
      "Epoch [2524/20000], Loss: 311.96026611328125, Entropy -325.9964294433594, Learning Rate: 0.00125\n",
      "Epoch [2525/20000], Loss: 297.4743347167969, Entropy -311.8934020996094, Learning Rate: 0.00125\n",
      "Epoch [2526/20000], Loss: 297.81781005859375, Entropy -310.474609375, Learning Rate: 0.00125\n",
      "Epoch [2527/20000], Loss: 303.0610656738281, Entropy -312.2283935546875, Learning Rate: 0.00125\n",
      "Epoch [2528/20000], Loss: 289.6181640625, Entropy -299.7493591308594, Learning Rate: 0.00125\n",
      "Epoch [2529/20000], Loss: 300.04833984375, Entropy -317.1364440917969, Learning Rate: 0.00125\n",
      "Epoch [2530/20000], Loss: 297.78582763671875, Entropy -305.0052795410156, Learning Rate: 0.00125\n",
      "Epoch [2531/20000], Loss: 307.8715515136719, Entropy -317.23480224609375, Learning Rate: 0.00125\n",
      "Epoch [2532/20000], Loss: 282.8873291015625, Entropy -298.137939453125, Learning Rate: 0.00125\n",
      "Epoch [2533/20000], Loss: 282.9292907714844, Entropy -293.56884765625, Learning Rate: 0.00125\n",
      "Epoch [2534/20000], Loss: 291.0701599121094, Entropy -306.46258544921875, Learning Rate: 0.00125\n",
      "Epoch [2535/20000], Loss: 290.2421875, Entropy -310.18463134765625, Learning Rate: 0.00125\n",
      "Epoch [2536/20000], Loss: 309.71942138671875, Entropy -324.61932373046875, Learning Rate: 0.00125\n",
      "Epoch [2537/20000], Loss: 296.72906494140625, Entropy -293.7706298828125, Learning Rate: 0.00125\n",
      "Epoch [2538/20000], Loss: 293.1881103515625, Entropy -295.88214111328125, Learning Rate: 0.00125\n",
      "Epoch [2539/20000], Loss: 300.8894958496094, Entropy -308.8516540527344, Learning Rate: 0.00125\n",
      "Epoch [2540/20000], Loss: 296.9403076171875, Entropy -313.7830810546875, Learning Rate: 0.00125\n",
      "Epoch [2541/20000], Loss: 295.6590270996094, Entropy -299.1388244628906, Learning Rate: 0.00125\n",
      "Epoch [2542/20000], Loss: 277.10821533203125, Entropy -299.76324462890625, Learning Rate: 0.00125\n",
      "Epoch [2543/20000], Loss: 298.08319091796875, Entropy -310.1045227050781, Learning Rate: 0.00125\n",
      "Epoch [2544/20000], Loss: 344.0345153808594, Entropy -311.63201904296875, Learning Rate: 0.00125\n",
      "Epoch [2545/20000], Loss: 311.1085205078125, Entropy -306.3598327636719, Learning Rate: 0.00125\n",
      "Epoch [2546/20000], Loss: 324.86126708984375, Entropy -299.3775939941406, Learning Rate: 0.00125\n",
      "Epoch [2547/20000], Loss: 305.80059814453125, Entropy -310.5681457519531, Learning Rate: 0.00125\n",
      "Epoch [2548/20000], Loss: 349.126953125, Entropy -325.63104248046875, Learning Rate: 0.00125\n",
      "Epoch [2549/20000], Loss: 290.6712341308594, Entropy -296.9215393066406, Learning Rate: 0.00125\n",
      "Epoch [2550/20000], Loss: 287.88531494140625, Entropy -290.99932861328125, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2551/20000], Loss: 309.29107666015625, Entropy -309.45806884765625, Learning Rate: 0.00125\n",
      "Epoch [2552/20000], Loss: 301.58441162109375, Entropy -306.3540344238281, Learning Rate: 0.00125\n",
      "Epoch [2553/20000], Loss: 307.07470703125, Entropy -306.955810546875, Learning Rate: 0.00125\n",
      "Epoch [2554/20000], Loss: 295.4604797363281, Entropy -306.56768798828125, Learning Rate: 0.00125\n",
      "Epoch [2555/20000], Loss: 313.283203125, Entropy -313.0853576660156, Learning Rate: 0.00125\n",
      "Epoch [2556/20000], Loss: 317.41943359375, Entropy -321.14337158203125, Learning Rate: 0.00125\n",
      "Epoch [2557/20000], Loss: 304.05517578125, Entropy -309.2187805175781, Learning Rate: 0.00125\n",
      "Epoch [2558/20000], Loss: 311.54052734375, Entropy -318.3354797363281, Learning Rate: 0.00125\n",
      "Epoch [2559/20000], Loss: 310.00146484375, Entropy -310.2330017089844, Learning Rate: 0.00125\n",
      "Epoch [2560/20000], Loss: 310.12188720703125, Entropy -306.3913879394531, Learning Rate: 0.00125\n",
      "Epoch [2561/20000], Loss: 305.25579833984375, Entropy -319.12225341796875, Learning Rate: 0.00125\n",
      "Epoch [2562/20000], Loss: 318.2918701171875, Entropy -322.946533203125, Learning Rate: 0.00125\n",
      "Epoch [2563/20000], Loss: 320.335693359375, Entropy -329.8319091796875, Learning Rate: 0.00125\n",
      "Epoch [2564/20000], Loss: 292.57073974609375, Entropy -298.3274841308594, Learning Rate: 0.00125\n",
      "Epoch [2565/20000], Loss: 284.50933837890625, Entropy -296.9791564941406, Learning Rate: 0.00125\n",
      "Epoch [2566/20000], Loss: 307.8433532714844, Entropy -310.91961669921875, Learning Rate: 0.00125\n",
      "Epoch [2567/20000], Loss: 287.76824951171875, Entropy -290.6566162109375, Learning Rate: 0.00125\n",
      "Epoch [2568/20000], Loss: 295.390869140625, Entropy -302.2996826171875, Learning Rate: 0.00125\n",
      "Epoch [2569/20000], Loss: 317.7772216796875, Entropy -308.639404296875, Learning Rate: 0.00125\n",
      "Epoch [2570/20000], Loss: 275.44390869140625, Entropy -282.87371826171875, Learning Rate: 0.00125\n",
      "Epoch [2571/20000], Loss: 300.59661865234375, Entropy -299.4137268066406, Learning Rate: 0.00125\n",
      "Epoch [2572/20000], Loss: 287.86553955078125, Entropy -295.0460510253906, Learning Rate: 0.00125\n",
      "Epoch [2573/20000], Loss: 309.2840576171875, Entropy -309.173828125, Learning Rate: 0.00125\n",
      "Epoch [2574/20000], Loss: 299.7308654785156, Entropy -299.8561706542969, Learning Rate: 0.00125\n",
      "Epoch [2575/20000], Loss: 288.9319763183594, Entropy -291.26007080078125, Learning Rate: 0.00125\n",
      "Epoch [2576/20000], Loss: 309.435302734375, Entropy -309.8878173828125, Learning Rate: 0.00125\n",
      "Epoch [2577/20000], Loss: 300.3023681640625, Entropy -306.2384338378906, Learning Rate: 0.00125\n",
      "Epoch [2578/20000], Loss: 304.6893310546875, Entropy -296.8412170410156, Learning Rate: 0.00125\n",
      "Epoch [2579/20000], Loss: 319.2729797363281, Entropy -326.8604431152344, Learning Rate: 0.00125\n",
      "Epoch [2580/20000], Loss: 297.5840148925781, Entropy -301.3673095703125, Learning Rate: 0.00125\n",
      "Epoch [2581/20000], Loss: 289.90533447265625, Entropy -294.3412780761719, Learning Rate: 0.00125\n",
      "Epoch [2582/20000], Loss: 292.01422119140625, Entropy -289.585205078125, Learning Rate: 0.00125\n",
      "Epoch [2583/20000], Loss: 291.7389221191406, Entropy -301.2497253417969, Learning Rate: 0.00125\n",
      "Epoch [2584/20000], Loss: 295.3663330078125, Entropy -310.1764221191406, Learning Rate: 0.00125\n",
      "Epoch [2585/20000], Loss: 299.9158935546875, Entropy -307.0679016113281, Learning Rate: 0.00125\n",
      "Epoch [2586/20000], Loss: 310.09661865234375, Entropy -315.9140319824219, Learning Rate: 0.00125\n",
      "Epoch [2587/20000], Loss: 292.36822509765625, Entropy -304.750732421875, Learning Rate: 0.00125\n",
      "Epoch [2588/20000], Loss: 300.1258544921875, Entropy -310.9446105957031, Learning Rate: 0.00125\n",
      "Epoch [2589/20000], Loss: 306.16558837890625, Entropy -310.47833251953125, Learning Rate: 0.00125\n",
      "Epoch [2590/20000], Loss: 306.7781677246094, Entropy -311.4859619140625, Learning Rate: 0.00125\n",
      "Epoch [2591/20000], Loss: 317.71221923828125, Entropy -321.6607360839844, Learning Rate: 0.00125\n",
      "Epoch [2592/20000], Loss: 314.344970703125, Entropy -313.72906494140625, Learning Rate: 0.00125\n",
      "Epoch [2593/20000], Loss: 290.07781982421875, Entropy -293.4945068359375, Learning Rate: 0.00125\n",
      "Epoch [2594/20000], Loss: 281.33935546875, Entropy -284.2916564941406, Learning Rate: 0.00125\n",
      "Epoch [2595/20000], Loss: 295.7713317871094, Entropy -293.13616943359375, Learning Rate: 0.00125\n",
      "Epoch [2596/20000], Loss: 299.7438049316406, Entropy -306.6950378417969, Learning Rate: 0.00125\n",
      "Epoch [2597/20000], Loss: 316.5907897949219, Entropy -314.7054138183594, Learning Rate: 0.00125\n",
      "Epoch [2598/20000], Loss: 295.2173156738281, Entropy -305.3527526855469, Learning Rate: 0.00125\n",
      "Epoch [2599/20000], Loss: 303.4892883300781, Entropy -313.62957763671875, Learning Rate: 0.00125\n",
      "Epoch [2600/20000], Loss: 327.3827819824219, Entropy -315.1061706542969, Learning Rate: 0.00125\n",
      "Epoch [2601/20000], Loss: 279.10797119140625, Entropy -297.7748718261719, Learning Rate: 0.00125\n",
      "Epoch [2602/20000], Loss: 292.6310119628906, Entropy -304.9338684082031, Learning Rate: 0.00125\n",
      "Epoch [2603/20000], Loss: 290.804931640625, Entropy -308.0217590332031, Learning Rate: 0.00125\n",
      "Epoch [2604/20000], Loss: 284.75543212890625, Entropy -296.9480895996094, Learning Rate: 0.00125\n",
      "Epoch [2605/20000], Loss: 295.9867248535156, Entropy -315.19293212890625, Learning Rate: 0.00125\n",
      "Epoch [2606/20000], Loss: 308.0948791503906, Entropy -304.322998046875, Learning Rate: 0.00125\n",
      "Epoch [2607/20000], Loss: 304.52667236328125, Entropy -311.5009765625, Learning Rate: 0.00125\n",
      "Epoch [2608/20000], Loss: 304.289794921875, Entropy -313.13623046875, Learning Rate: 0.00125\n",
      "Epoch [2609/20000], Loss: 318.26715087890625, Entropy -320.7544250488281, Learning Rate: 0.00125\n",
      "Epoch [2610/20000], Loss: 303.82427978515625, Entropy -306.1895446777344, Learning Rate: 0.00125\n",
      "Epoch [2611/20000], Loss: 279.9940185546875, Entropy -290.169189453125, Learning Rate: 0.00125\n",
      "Epoch [2612/20000], Loss: 309.1497497558594, Entropy -320.96551513671875, Learning Rate: 0.00125\n",
      "Epoch [2613/20000], Loss: 296.6754455566406, Entropy -306.8733215332031, Learning Rate: 0.00125\n",
      "Epoch [2614/20000], Loss: 315.17205810546875, Entropy -324.3294982910156, Learning Rate: 0.00125\n",
      "Epoch [2615/20000], Loss: 301.03155517578125, Entropy -323.1346740722656, Learning Rate: 0.00125\n",
      "Epoch [2616/20000], Loss: 294.4068298339844, Entropy -300.7716369628906, Learning Rate: 0.00125\n",
      "Epoch [2617/20000], Loss: 307.07818603515625, Entropy -319.5647888183594, Learning Rate: 0.00125\n",
      "Epoch [2618/20000], Loss: 303.599609375, Entropy -306.8235168457031, Learning Rate: 0.00125\n",
      "Epoch [2619/20000], Loss: 283.4530029296875, Entropy -295.96173095703125, Learning Rate: 0.00125\n",
      "Epoch [2620/20000], Loss: 304.2439270019531, Entropy -318.2751770019531, Learning Rate: 0.00125\n",
      "Epoch [2621/20000], Loss: 303.3749084472656, Entropy -304.4165344238281, Learning Rate: 0.00125\n",
      "Epoch [2622/20000], Loss: 294.2777099609375, Entropy -298.5533447265625, Learning Rate: 0.00125\n",
      "Epoch [2623/20000], Loss: 308.6068115234375, Entropy -325.2007141113281, Learning Rate: 0.00125\n",
      "Epoch [2624/20000], Loss: 291.2359924316406, Entropy -306.3822021484375, Learning Rate: 0.00125\n",
      "Epoch [2625/20000], Loss: 283.7017822265625, Entropy -299.6761779785156, Learning Rate: 0.00125\n",
      "Epoch [2626/20000], Loss: 304.92071533203125, Entropy -308.9638366699219, Learning Rate: 0.00125\n",
      "Epoch [2627/20000], Loss: 290.6347961425781, Entropy -305.09503173828125, Learning Rate: 0.00125\n",
      "Epoch [2628/20000], Loss: 303.3984375, Entropy -305.82684326171875, Learning Rate: 0.00125\n",
      "Epoch [2629/20000], Loss: 302.9742431640625, Entropy -303.0465393066406, Learning Rate: 0.00125\n",
      "Epoch [2630/20000], Loss: 299.84576416015625, Entropy -302.3983154296875, Learning Rate: 0.00125\n",
      "Epoch [2631/20000], Loss: 299.29864501953125, Entropy -315.00018310546875, Learning Rate: 0.00125\n",
      "Epoch [2632/20000], Loss: 297.1312255859375, Entropy -312.9845275878906, Learning Rate: 0.00125\n",
      "Epoch [2633/20000], Loss: 291.7620849609375, Entropy -302.8598937988281, Learning Rate: 0.00125\n",
      "Epoch [2634/20000], Loss: 297.75701904296875, Entropy -314.777587890625, Learning Rate: 0.00125\n",
      "Epoch [2635/20000], Loss: 282.3974609375, Entropy -299.42938232421875, Learning Rate: 0.00125\n",
      "Epoch [2636/20000], Loss: 308.29296875, Entropy -320.2435607910156, Learning Rate: 0.00125\n",
      "Epoch [2637/20000], Loss: 286.98553466796875, Entropy -294.3189392089844, Learning Rate: 0.000625\n",
      "Epoch [2638/20000], Loss: 294.4357604980469, Entropy -302.67431640625, Learning Rate: 0.000625\n",
      "Epoch [2639/20000], Loss: 293.95318603515625, Entropy -301.36614990234375, Learning Rate: 0.000625\n",
      "Epoch [2640/20000], Loss: 290.1876220703125, Entropy -299.916748046875, Learning Rate: 0.000625\n",
      "Epoch [2641/20000], Loss: 309.5953063964844, Entropy -312.5396728515625, Learning Rate: 0.000625\n",
      "Epoch [2642/20000], Loss: 316.781005859375, Entropy -322.0273742675781, Learning Rate: 0.000625\n",
      "Epoch [2643/20000], Loss: 290.79156494140625, Entropy -304.84747314453125, Learning Rate: 0.000625\n",
      "Epoch [2644/20000], Loss: 298.15435791015625, Entropy -310.5886535644531, Learning Rate: 0.000625\n",
      "Epoch [2645/20000], Loss: 306.1781005859375, Entropy -309.4515075683594, Learning Rate: 0.000625\n",
      "Epoch [2646/20000], Loss: 294.93768310546875, Entropy -308.59918212890625, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2647/20000], Loss: 305.82000732421875, Entropy -317.64495849609375, Learning Rate: 0.000625\n",
      "Epoch [2648/20000], Loss: 290.18212890625, Entropy -309.9734191894531, Learning Rate: 0.000625\n",
      "Epoch [2649/20000], Loss: 303.0567626953125, Entropy -311.759521484375, Learning Rate: 0.000625\n",
      "Epoch [2650/20000], Loss: 289.3582458496094, Entropy -301.2852783203125, Learning Rate: 0.000625\n",
      "Epoch [2651/20000], Loss: 295.2856750488281, Entropy -309.79876708984375, Learning Rate: 0.000625\n",
      "Epoch [2652/20000], Loss: 289.93499755859375, Entropy -302.0994567871094, Learning Rate: 0.000625\n",
      "Epoch [2653/20000], Loss: 264.48138427734375, Entropy -282.4432373046875, Learning Rate: 0.000625\n",
      "Epoch [2654/20000], Loss: 293.9276123046875, Entropy -311.99700927734375, Learning Rate: 0.000625\n",
      "Epoch [2655/20000], Loss: 290.3887939453125, Entropy -299.7779846191406, Learning Rate: 0.000625\n",
      "Epoch [2656/20000], Loss: 320.7100830078125, Entropy -338.7390441894531, Learning Rate: 0.000625\n",
      "Epoch [2657/20000], Loss: 290.57989501953125, Entropy -305.2225341796875, Learning Rate: 0.000625\n",
      "Epoch [2658/20000], Loss: 277.719482421875, Entropy -282.8485107421875, Learning Rate: 0.000625\n",
      "Epoch [2659/20000], Loss: 292.0440673828125, Entropy -307.7349548339844, Learning Rate: 0.000625\n",
      "Epoch [2660/20000], Loss: 295.2477111816406, Entropy -314.7034606933594, Learning Rate: 0.000625\n",
      "Epoch [2661/20000], Loss: 286.271240234375, Entropy -293.9954833984375, Learning Rate: 0.000625\n",
      "Epoch [2662/20000], Loss: 301.29168701171875, Entropy -316.6309814453125, Learning Rate: 0.000625\n",
      "Epoch [2663/20000], Loss: 277.40887451171875, Entropy -293.2499084472656, Learning Rate: 0.000625\n",
      "Epoch [2664/20000], Loss: 294.62176513671875, Entropy -308.54986572265625, Learning Rate: 0.000625\n",
      "Epoch [2665/20000], Loss: 281.9668273925781, Entropy -302.6133728027344, Learning Rate: 0.000625\n",
      "Epoch [2666/20000], Loss: 302.1019287109375, Entropy -311.8086242675781, Learning Rate: 0.000625\n",
      "Epoch [2667/20000], Loss: 290.2265625, Entropy -305.0038757324219, Learning Rate: 0.000625\n",
      "Epoch [2668/20000], Loss: 307.4080810546875, Entropy -320.3468933105469, Learning Rate: 0.000625\n",
      "Epoch [2669/20000], Loss: 278.34698486328125, Entropy -292.6532897949219, Learning Rate: 0.000625\n",
      "Epoch [2670/20000], Loss: 282.7241516113281, Entropy -292.351318359375, Learning Rate: 0.000625\n",
      "Epoch [2671/20000], Loss: 298.41705322265625, Entropy -307.066650390625, Learning Rate: 0.000625\n",
      "Epoch [2672/20000], Loss: 300.7625732421875, Entropy -301.3692932128906, Learning Rate: 0.000625\n",
      "Epoch [2673/20000], Loss: 287.7985534667969, Entropy -310.62353515625, Learning Rate: 0.000625\n",
      "Epoch [2674/20000], Loss: 302.832763671875, Entropy -294.0159912109375, Learning Rate: 0.000625\n",
      "Epoch [2675/20000], Loss: 287.21392822265625, Entropy -296.70733642578125, Learning Rate: 0.000625\n",
      "Epoch [2676/20000], Loss: 293.8260498046875, Entropy -305.94866943359375, Learning Rate: 0.000625\n",
      "Epoch [2677/20000], Loss: 297.3974609375, Entropy -317.9414367675781, Learning Rate: 0.000625\n",
      "Epoch [2678/20000], Loss: 283.8243408203125, Entropy -296.42919921875, Learning Rate: 0.000625\n",
      "Epoch [2679/20000], Loss: 287.6228332519531, Entropy -304.95599365234375, Learning Rate: 0.000625\n",
      "Epoch [2680/20000], Loss: 281.6002197265625, Entropy -297.5761413574219, Learning Rate: 0.000625\n",
      "Epoch [2681/20000], Loss: 280.03515625, Entropy -300.3327331542969, Learning Rate: 0.000625\n",
      "Epoch [2682/20000], Loss: 286.3287353515625, Entropy -305.5325622558594, Learning Rate: 0.000625\n",
      "Epoch [2683/20000], Loss: 289.73504638671875, Entropy -299.271728515625, Learning Rate: 0.000625\n",
      "Epoch [2684/20000], Loss: 288.3837890625, Entropy -312.4603576660156, Learning Rate: 0.000625\n",
      "Epoch [2685/20000], Loss: 292.6849365234375, Entropy -302.2073059082031, Learning Rate: 0.000625\n",
      "Epoch [2686/20000], Loss: 299.7353515625, Entropy -299.43701171875, Learning Rate: 0.000625\n",
      "Epoch [2687/20000], Loss: 311.78887939453125, Entropy -305.81854248046875, Learning Rate: 0.000625\n",
      "Epoch [2688/20000], Loss: 296.1351013183594, Entropy -311.7709655761719, Learning Rate: 0.000625\n",
      "Epoch [2689/20000], Loss: 291.672119140625, Entropy -300.8680114746094, Learning Rate: 0.000625\n",
      "Epoch [2690/20000], Loss: 289.70880126953125, Entropy -309.916259765625, Learning Rate: 0.000625\n",
      "Epoch [2691/20000], Loss: 307.67474365234375, Entropy -323.9605712890625, Learning Rate: 0.000625\n",
      "Epoch [2692/20000], Loss: 299.7359619140625, Entropy -308.1217041015625, Learning Rate: 0.000625\n",
      "Epoch [2693/20000], Loss: 301.56805419921875, Entropy -320.179443359375, Learning Rate: 0.000625\n",
      "Epoch [2694/20000], Loss: 287.58209228515625, Entropy -297.7756042480469, Learning Rate: 0.000625\n",
      "Epoch [2695/20000], Loss: 302.64453125, Entropy -320.743896484375, Learning Rate: 0.000625\n",
      "Epoch [2696/20000], Loss: 272.4324035644531, Entropy -295.55718994140625, Learning Rate: 0.000625\n",
      "Epoch [2697/20000], Loss: 284.9945373535156, Entropy -293.0504455566406, Learning Rate: 0.000625\n",
      "Epoch [2698/20000], Loss: 303.3158264160156, Entropy -320.5076599121094, Learning Rate: 0.000625\n",
      "Epoch [2699/20000], Loss: 286.0995178222656, Entropy -302.1839599609375, Learning Rate: 0.000625\n",
      "Epoch [2700/20000], Loss: 288.2356262207031, Entropy -297.8121032714844, Learning Rate: 0.000625\n",
      "Epoch [2701/20000], Loss: 286.9312744140625, Entropy -309.98687744140625, Learning Rate: 0.000625\n",
      "Epoch [2702/20000], Loss: 306.1142578125, Entropy -316.3502197265625, Learning Rate: 0.000625\n",
      "Epoch [2703/20000], Loss: 279.7198791503906, Entropy -290.5939636230469, Learning Rate: 0.000625\n",
      "Epoch [2704/20000], Loss: 286.19329833984375, Entropy -298.2748718261719, Learning Rate: 0.000625\n",
      "Epoch [2705/20000], Loss: 300.2701416015625, Entropy -315.2558288574219, Learning Rate: 0.000625\n",
      "Epoch [2706/20000], Loss: 288.16827392578125, Entropy -304.1399841308594, Learning Rate: 0.000625\n",
      "Epoch [2707/20000], Loss: 311.96307373046875, Entropy -327.15667724609375, Learning Rate: 0.000625\n",
      "Epoch [2708/20000], Loss: 272.63671875, Entropy -292.2030334472656, Learning Rate: 0.000625\n",
      "Epoch [2709/20000], Loss: 297.0164794921875, Entropy -303.9283447265625, Learning Rate: 0.000625\n",
      "Epoch [2710/20000], Loss: 280.767822265625, Entropy -299.2074890136719, Learning Rate: 0.000625\n",
      "Epoch [2711/20000], Loss: 287.51531982421875, Entropy -300.18829345703125, Learning Rate: 0.000625\n",
      "Epoch [2712/20000], Loss: 308.6304016113281, Entropy -311.0271911621094, Learning Rate: 0.000625\n",
      "Epoch [2713/20000], Loss: 294.1849670410156, Entropy -311.1660461425781, Learning Rate: 0.000625\n",
      "Epoch [2714/20000], Loss: 282.919189453125, Entropy -292.7306213378906, Learning Rate: 0.000625\n",
      "Epoch [2715/20000], Loss: 306.2763366699219, Entropy -310.713134765625, Learning Rate: 0.000625\n",
      "Epoch [2716/20000], Loss: 281.5775451660156, Entropy -290.525390625, Learning Rate: 0.000625\n",
      "Epoch [2717/20000], Loss: 291.3970031738281, Entropy -305.0862731933594, Learning Rate: 0.000625\n",
      "Epoch [2718/20000], Loss: 317.46099853515625, Entropy -321.421875, Learning Rate: 0.000625\n",
      "Epoch [2719/20000], Loss: 298.5650939941406, Entropy -307.4853515625, Learning Rate: 0.000625\n",
      "Epoch [2720/20000], Loss: 276.71990966796875, Entropy -298.5299072265625, Learning Rate: 0.000625\n",
      "Epoch [2721/20000], Loss: 303.04571533203125, Entropy -313.9477233886719, Learning Rate: 0.000625\n",
      "Epoch [2722/20000], Loss: 302.4297790527344, Entropy -318.4537048339844, Learning Rate: 0.000625\n",
      "Epoch [2723/20000], Loss: 292.7626953125, Entropy -302.910888671875, Learning Rate: 0.000625\n",
      "Epoch [2724/20000], Loss: 299.6168212890625, Entropy -320.5501708984375, Learning Rate: 0.000625\n",
      "Epoch [2725/20000], Loss: 284.393310546875, Entropy -299.550048828125, Learning Rate: 0.000625\n",
      "Epoch [2726/20000], Loss: 283.8594970703125, Entropy -295.35308837890625, Learning Rate: 0.000625\n",
      "Epoch [2727/20000], Loss: 280.2493896484375, Entropy -301.3228759765625, Learning Rate: 0.000625\n",
      "Epoch [2728/20000], Loss: 279.9652404785156, Entropy -302.8009338378906, Learning Rate: 0.000625\n",
      "Epoch [2729/20000], Loss: 294.56793212890625, Entropy -309.7148132324219, Learning Rate: 0.000625\n",
      "Epoch [2730/20000], Loss: 301.9478759765625, Entropy -313.87945556640625, Learning Rate: 0.000625\n",
      "Epoch [2731/20000], Loss: 290.96942138671875, Entropy -302.463134765625, Learning Rate: 0.000625\n",
      "Epoch [2732/20000], Loss: 291.61541748046875, Entropy -297.89385986328125, Learning Rate: 0.000625\n",
      "Epoch [2733/20000], Loss: 279.7438659667969, Entropy -284.32598876953125, Learning Rate: 0.000625\n",
      "Epoch [2734/20000], Loss: 294.11773681640625, Entropy -310.0498352050781, Learning Rate: 0.000625\n",
      "Epoch [2735/20000], Loss: 289.41748046875, Entropy -302.43011474609375, Learning Rate: 0.000625\n",
      "Epoch [2736/20000], Loss: 284.57080078125, Entropy -300.6664123535156, Learning Rate: 0.000625\n",
      "Epoch [2737/20000], Loss: 308.77838134765625, Entropy -318.75555419921875, Learning Rate: 0.000625\n",
      "Epoch [2738/20000], Loss: 294.0372619628906, Entropy -301.06488037109375, Learning Rate: 0.000625\n",
      "Epoch [2739/20000], Loss: 299.3275451660156, Entropy -319.8723449707031, Learning Rate: 0.000625\n",
      "Epoch [2740/20000], Loss: 307.40570068359375, Entropy -323.8174743652344, Learning Rate: 0.000625\n",
      "Epoch [2741/20000], Loss: 310.15911865234375, Entropy -326.9694519042969, Learning Rate: 0.000625\n",
      "Epoch [2742/20000], Loss: 272.9059143066406, Entropy -287.12066650390625, Learning Rate: 0.000625\n",
      "Epoch [2743/20000], Loss: 288.7789306640625, Entropy -310.3407287597656, Learning Rate: 0.000625\n",
      "Epoch [2744/20000], Loss: 300.3546142578125, Entropy -307.49615478515625, Learning Rate: 0.000625\n",
      "Epoch [2745/20000], Loss: 289.6892395019531, Entropy -306.43060302734375, Learning Rate: 0.000625\n",
      "Epoch [2746/20000], Loss: 292.33428955078125, Entropy -308.113525390625, Learning Rate: 0.000625\n",
      "Epoch [2747/20000], Loss: 285.575439453125, Entropy -303.90869140625, Learning Rate: 0.000625\n",
      "Epoch [2748/20000], Loss: 304.37841796875, Entropy -305.4715270996094, Learning Rate: 0.000625\n",
      "Epoch [2749/20000], Loss: 295.8920593261719, Entropy -311.5684814453125, Learning Rate: 0.000625\n",
      "Epoch [2750/20000], Loss: 299.3302001953125, Entropy -315.9834899902344, Learning Rate: 0.000625\n",
      "Epoch [2751/20000], Loss: 296.6288146972656, Entropy -307.06060791015625, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2752/20000], Loss: 294.5311279296875, Entropy -307.0021057128906, Learning Rate: 0.000625\n",
      "Epoch [2753/20000], Loss: 290.18548583984375, Entropy -308.0378112792969, Learning Rate: 0.000625\n",
      "Epoch [2754/20000], Loss: 312.3677062988281, Entropy -331.72039794921875, Learning Rate: 0.000625\n",
      "Epoch [2755/20000], Loss: 284.02349853515625, Entropy -295.59906005859375, Learning Rate: 0.000625\n",
      "Epoch [2756/20000], Loss: 304.00408935546875, Entropy -315.2176818847656, Learning Rate: 0.000625\n",
      "Epoch [2757/20000], Loss: 296.3979797363281, Entropy -306.97528076171875, Learning Rate: 0.000625\n",
      "Epoch [2758/20000], Loss: 290.253173828125, Entropy -307.9443359375, Learning Rate: 0.000625\n",
      "Epoch [2759/20000], Loss: 301.1868896484375, Entropy -307.82171630859375, Learning Rate: 0.000625\n",
      "Epoch [2760/20000], Loss: 291.43621826171875, Entropy -306.2264404296875, Learning Rate: 0.000625\n",
      "Epoch [2761/20000], Loss: 316.05975341796875, Entropy -334.5899963378906, Learning Rate: 0.000625\n",
      "Epoch [2762/20000], Loss: 282.471923828125, Entropy -300.1433410644531, Learning Rate: 0.000625\n",
      "Epoch [2763/20000], Loss: 292.2393493652344, Entropy -306.75128173828125, Learning Rate: 0.000625\n",
      "Epoch [2764/20000], Loss: 293.9990234375, Entropy -308.57952880859375, Learning Rate: 0.000625\n",
      "Epoch [2765/20000], Loss: 301.0171203613281, Entropy -317.8861999511719, Learning Rate: 0.000625\n",
      "Epoch [2766/20000], Loss: 290.80169677734375, Entropy -298.0484924316406, Learning Rate: 0.000625\n",
      "Epoch [2767/20000], Loss: 286.4418640136719, Entropy -300.2273254394531, Learning Rate: 0.000625\n",
      "Epoch [2768/20000], Loss: 288.6859130859375, Entropy -303.0336608886719, Learning Rate: 0.000625\n",
      "Epoch [2769/20000], Loss: 276.72991943359375, Entropy -290.9985656738281, Learning Rate: 0.000625\n",
      "Epoch [2770/20000], Loss: 303.43377685546875, Entropy -314.9298095703125, Learning Rate: 0.000625\n",
      "Epoch [2771/20000], Loss: 294.4305725097656, Entropy -317.2914733886719, Learning Rate: 0.000625\n",
      "Epoch [2772/20000], Loss: 292.0788879394531, Entropy -308.2560729980469, Learning Rate: 0.000625\n",
      "Epoch [2773/20000], Loss: 289.2750244140625, Entropy -303.0248718261719, Learning Rate: 0.000625\n",
      "Epoch [2774/20000], Loss: 292.6295471191406, Entropy -311.8568420410156, Learning Rate: 0.000625\n",
      "Epoch [2775/20000], Loss: 302.30206298828125, Entropy -300.3808898925781, Learning Rate: 0.000625\n",
      "Epoch [2776/20000], Loss: 300.2080993652344, Entropy -305.1692810058594, Learning Rate: 0.000625\n",
      "Epoch [2777/20000], Loss: 288.09088134765625, Entropy -308.336669921875, Learning Rate: 0.000625\n",
      "Epoch [2778/20000], Loss: 301.75042724609375, Entropy -308.9748229980469, Learning Rate: 0.000625\n",
      "Epoch [2779/20000], Loss: 288.4490661621094, Entropy -296.7366943359375, Learning Rate: 0.000625\n",
      "Epoch [2780/20000], Loss: 308.457275390625, Entropy -317.9563903808594, Learning Rate: 0.000625\n",
      "Epoch [2781/20000], Loss: 285.38763427734375, Entropy -297.96893310546875, Learning Rate: 0.000625\n",
      "Epoch [2782/20000], Loss: 298.67578125, Entropy -304.8435363769531, Learning Rate: 0.000625\n",
      "Epoch [2783/20000], Loss: 290.71533203125, Entropy -300.1983337402344, Learning Rate: 0.000625\n",
      "Epoch [2784/20000], Loss: 295.506591796875, Entropy -307.5766296386719, Learning Rate: 0.000625\n",
      "Epoch [2785/20000], Loss: 286.53619384765625, Entropy -302.0021057128906, Learning Rate: 0.000625\n",
      "Epoch [2786/20000], Loss: 293.171630859375, Entropy -302.4941101074219, Learning Rate: 0.000625\n",
      "Epoch [2787/20000], Loss: 280.363037109375, Entropy -298.74664306640625, Learning Rate: 0.000625\n",
      "Epoch [2788/20000], Loss: 297.7205810546875, Entropy -313.16448974609375, Learning Rate: 0.000625\n",
      "Epoch [2789/20000], Loss: 275.291748046875, Entropy -290.70965576171875, Learning Rate: 0.000625\n",
      "Epoch [2790/20000], Loss: 300.20428466796875, Entropy -318.6114196777344, Learning Rate: 0.000625\n",
      "Epoch [2791/20000], Loss: 310.9778137207031, Entropy -325.2030944824219, Learning Rate: 0.000625\n",
      "Epoch [2792/20000], Loss: 304.8490295410156, Entropy -319.6454162597656, Learning Rate: 0.000625\n",
      "Epoch [2793/20000], Loss: 282.96319580078125, Entropy -299.2156677246094, Learning Rate: 0.000625\n",
      "Epoch [2794/20000], Loss: 301.0198669433594, Entropy -315.2489318847656, Learning Rate: 0.000625\n",
      "Epoch [2795/20000], Loss: 291.67578125, Entropy -304.52386474609375, Learning Rate: 0.000625\n",
      "Epoch [2796/20000], Loss: 283.1237487792969, Entropy -295.01605224609375, Learning Rate: 0.000625\n",
      "Epoch [2797/20000], Loss: 294.4802551269531, Entropy -312.0891418457031, Learning Rate: 0.000625\n",
      "Epoch [2798/20000], Loss: 289.1763916015625, Entropy -311.5962219238281, Learning Rate: 0.000625\n",
      "Epoch [2799/20000], Loss: 289.157470703125, Entropy -310.0105895996094, Learning Rate: 0.000625\n",
      "Epoch [2800/20000], Loss: 295.02496337890625, Entropy -308.9880676269531, Learning Rate: 0.000625\n",
      "Epoch [2801/20000], Loss: 290.4444885253906, Entropy -305.99798583984375, Learning Rate: 0.000625\n",
      "Epoch [2802/20000], Loss: 283.73876953125, Entropy -296.52789306640625, Learning Rate: 0.000625\n",
      "Epoch [2803/20000], Loss: 294.8142395019531, Entropy -311.655517578125, Learning Rate: 0.000625\n",
      "Epoch [2804/20000], Loss: 295.1654357910156, Entropy -307.9126892089844, Learning Rate: 0.000625\n",
      "Epoch [2805/20000], Loss: 309.0772705078125, Entropy -324.7593078613281, Learning Rate: 0.000625\n",
      "Epoch [2806/20000], Loss: 299.63043212890625, Entropy -320.5974426269531, Learning Rate: 0.000625\n",
      "Epoch [2807/20000], Loss: 293.77032470703125, Entropy -305.6690979003906, Learning Rate: 0.000625\n",
      "Epoch [2808/20000], Loss: 290.9325256347656, Entropy -302.44586181640625, Learning Rate: 0.000625\n",
      "Epoch [2809/20000], Loss: 331.86358642578125, Entropy -315.5618591308594, Learning Rate: 0.000625\n",
      "Epoch [2810/20000], Loss: 291.5281982421875, Entropy -307.90625, Learning Rate: 0.000625\n",
      "Epoch [2811/20000], Loss: 287.192626953125, Entropy -299.3451232910156, Learning Rate: 0.000625\n",
      "Epoch [2812/20000], Loss: 280.0457763671875, Entropy -298.4278259277344, Learning Rate: 0.000625\n",
      "Epoch [2813/20000], Loss: 313.239501953125, Entropy -314.7138366699219, Learning Rate: 0.000625\n",
      "Epoch [2814/20000], Loss: 271.8905334472656, Entropy -289.2919921875, Learning Rate: 0.000625\n",
      "Epoch [2815/20000], Loss: 284.29937744140625, Entropy -298.3629455566406, Learning Rate: 0.000625\n",
      "Epoch [2816/20000], Loss: 297.64056396484375, Entropy -319.5079040527344, Learning Rate: 0.000625\n",
      "Epoch [2817/20000], Loss: 282.62457275390625, Entropy -302.2897644042969, Learning Rate: 0.000625\n",
      "Epoch [2818/20000], Loss: 300.56683349609375, Entropy -318.8383483886719, Learning Rate: 0.000625\n",
      "Epoch [2819/20000], Loss: 289.811279296875, Entropy -305.53564453125, Learning Rate: 0.000625\n",
      "Epoch [2820/20000], Loss: 284.3826599121094, Entropy -301.3994445800781, Learning Rate: 0.000625\n",
      "Epoch [2821/20000], Loss: 290.59075927734375, Entropy -305.8221740722656, Learning Rate: 0.000625\n",
      "Epoch [2822/20000], Loss: 300.47705078125, Entropy -318.8517150878906, Learning Rate: 0.000625\n",
      "Epoch [2823/20000], Loss: 277.4314880371094, Entropy -291.9685974121094, Learning Rate: 0.000625\n",
      "Epoch [2824/20000], Loss: 288.2642517089844, Entropy -305.875, Learning Rate: 0.000625\n",
      "Epoch [2825/20000], Loss: 300.73992919921875, Entropy -315.5976257324219, Learning Rate: 0.000625\n",
      "Epoch [2826/20000], Loss: 299.26080322265625, Entropy -307.79473876953125, Learning Rate: 0.000625\n",
      "Epoch [2827/20000], Loss: 295.56329345703125, Entropy -296.42730712890625, Learning Rate: 0.000625\n",
      "Epoch [2828/20000], Loss: 273.2481689453125, Entropy -290.2711181640625, Learning Rate: 0.000625\n",
      "Epoch [2829/20000], Loss: 268.1528625488281, Entropy -289.9937744140625, Learning Rate: 0.000625\n",
      "Epoch [2830/20000], Loss: 299.743896484375, Entropy -312.2842102050781, Learning Rate: 0.000625\n",
      "Epoch [2831/20000], Loss: 291.117431640625, Entropy -309.62841796875, Learning Rate: 0.000625\n",
      "Epoch [2832/20000], Loss: 271.83331298828125, Entropy -295.9113464355469, Learning Rate: 0.000625\n",
      "Epoch [2833/20000], Loss: 305.4036865234375, Entropy -322.02032470703125, Learning Rate: 0.000625\n",
      "Epoch [2834/20000], Loss: 285.8276062011719, Entropy -300.9794006347656, Learning Rate: 0.000625\n",
      "Epoch [2835/20000], Loss: 290.03302001953125, Entropy -309.6513366699219, Learning Rate: 0.000625\n",
      "Epoch [2836/20000], Loss: 293.1307373046875, Entropy -301.0932312011719, Learning Rate: 0.000625\n",
      "Epoch [2837/20000], Loss: 282.2264404296875, Entropy -298.7843322753906, Learning Rate: 0.000625\n",
      "Epoch [2838/20000], Loss: 298.9298400878906, Entropy -321.002685546875, Learning Rate: 0.000625\n",
      "Epoch [2839/20000], Loss: 301.5611572265625, Entropy -315.94549560546875, Learning Rate: 0.000625\n",
      "Epoch [2840/20000], Loss: 308.79754638671875, Entropy -323.65032958984375, Learning Rate: 0.000625\n",
      "Epoch [2841/20000], Loss: 293.1169738769531, Entropy -307.55084228515625, Learning Rate: 0.000625\n",
      "Epoch [2842/20000], Loss: 278.45892333984375, Entropy -294.060791015625, Learning Rate: 0.000625\n",
      "Epoch [2843/20000], Loss: 284.59161376953125, Entropy -298.8304748535156, Learning Rate: 0.000625\n",
      "Epoch [2844/20000], Loss: 286.4446105957031, Entropy -303.29449462890625, Learning Rate: 0.000625\n",
      "Epoch [2845/20000], Loss: 284.4063720703125, Entropy -296.2613525390625, Learning Rate: 0.000625\n",
      "Epoch [2846/20000], Loss: 295.06024169921875, Entropy -301.0648193359375, Learning Rate: 0.000625\n",
      "Epoch [2847/20000], Loss: 284.9111328125, Entropy -303.3456115722656, Learning Rate: 0.000625\n",
      "Epoch [2848/20000], Loss: 280.84832763671875, Entropy -299.1941223144531, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2849/20000], Loss: 295.92156982421875, Entropy -307.8533935546875, Learning Rate: 0.000625\n",
      "Epoch [2850/20000], Loss: 285.20562744140625, Entropy -298.76129150390625, Learning Rate: 0.000625\n",
      "Epoch [2851/20000], Loss: 284.32733154296875, Entropy -304.2319030761719, Learning Rate: 0.000625\n",
      "Epoch [2852/20000], Loss: 284.40911865234375, Entropy -298.0751037597656, Learning Rate: 0.000625\n",
      "Epoch [2853/20000], Loss: 282.9464416503906, Entropy -294.855712890625, Learning Rate: 0.000625\n",
      "Epoch [2854/20000], Loss: 293.98760986328125, Entropy -305.40167236328125, Learning Rate: 0.000625\n",
      "Epoch [2855/20000], Loss: 290.7998046875, Entropy -309.04901123046875, Learning Rate: 0.0003125\n",
      "Epoch [2856/20000], Loss: 304.79559326171875, Entropy -312.3408203125, Learning Rate: 0.0003125\n",
      "Epoch [2857/20000], Loss: 291.0757141113281, Entropy -303.52935791015625, Learning Rate: 0.0003125\n",
      "Epoch [2858/20000], Loss: 288.51971435546875, Entropy -301.24114990234375, Learning Rate: 0.0003125\n",
      "Epoch [2859/20000], Loss: 287.5553894042969, Entropy -299.0027770996094, Learning Rate: 0.0003125\n",
      "Epoch [2860/20000], Loss: 300.8047790527344, Entropy -329.5874938964844, Learning Rate: 0.0003125\n",
      "Epoch [2861/20000], Loss: 298.7588195800781, Entropy -320.08172607421875, Learning Rate: 0.0003125\n",
      "Epoch [2862/20000], Loss: 307.134765625, Entropy -308.1105041503906, Learning Rate: 0.0003125\n",
      "Epoch [2863/20000], Loss: 286.5910339355469, Entropy -300.6542053222656, Learning Rate: 0.0003125\n",
      "Epoch [2864/20000], Loss: 281.14642333984375, Entropy -297.6787109375, Learning Rate: 0.0003125\n",
      "Epoch [2865/20000], Loss: 299.31805419921875, Entropy -308.9798889160156, Learning Rate: 0.0003125\n",
      "Epoch [2866/20000], Loss: 297.0763244628906, Entropy -311.3900451660156, Learning Rate: 0.0003125\n",
      "Epoch [2867/20000], Loss: 284.8826599121094, Entropy -294.59625244140625, Learning Rate: 0.0003125\n",
      "Epoch [2868/20000], Loss: 266.33636474609375, Entropy -281.0166015625, Learning Rate: 0.0003125\n",
      "Epoch [2869/20000], Loss: 290.2986755371094, Entropy -305.7778015136719, Learning Rate: 0.0003125\n",
      "Epoch [2870/20000], Loss: 271.0232849121094, Entropy -299.1950378417969, Learning Rate: 0.0003125\n",
      "Epoch [2871/20000], Loss: 288.2843322753906, Entropy -295.71038818359375, Learning Rate: 0.0003125\n",
      "Epoch [2872/20000], Loss: 291.4528503417969, Entropy -306.45977783203125, Learning Rate: 0.0003125\n",
      "Epoch [2873/20000], Loss: 281.0713806152344, Entropy -300.03289794921875, Learning Rate: 0.0003125\n",
      "Epoch [2874/20000], Loss: 293.01849365234375, Entropy -309.2755126953125, Learning Rate: 0.0003125\n",
      "Epoch [2875/20000], Loss: 299.22857666015625, Entropy -314.6613464355469, Learning Rate: 0.0003125\n",
      "Epoch [2876/20000], Loss: 275.032958984375, Entropy -294.86328125, Learning Rate: 0.0003125\n",
      "Epoch [2877/20000], Loss: 290.0019836425781, Entropy -306.3558044433594, Learning Rate: 0.0003125\n",
      "Epoch [2878/20000], Loss: 288.5936279296875, Entropy -302.59429931640625, Learning Rate: 0.0003125\n",
      "Epoch [2879/20000], Loss: 265.607421875, Entropy -278.07928466796875, Learning Rate: 0.0003125\n",
      "Epoch [2880/20000], Loss: 282.66583251953125, Entropy -301.9936218261719, Learning Rate: 0.0003125\n",
      "Epoch [2881/20000], Loss: 306.36248779296875, Entropy -303.9358825683594, Learning Rate: 0.0003125\n",
      "Epoch [2882/20000], Loss: 283.8289489746094, Entropy -291.33587646484375, Learning Rate: 0.0003125\n",
      "Epoch [2883/20000], Loss: 292.0299072265625, Entropy -310.6259460449219, Learning Rate: 0.0003125\n",
      "Epoch [2884/20000], Loss: 296.59197998046875, Entropy -314.28997802734375, Learning Rate: 0.0003125\n",
      "Epoch [2885/20000], Loss: 301.9542236328125, Entropy -311.13800048828125, Learning Rate: 0.0003125\n",
      "Epoch [2886/20000], Loss: 282.64788818359375, Entropy -302.9952392578125, Learning Rate: 0.0003125\n",
      "Epoch [2887/20000], Loss: 305.51239013671875, Entropy -320.8084411621094, Learning Rate: 0.0003125\n",
      "Epoch [2888/20000], Loss: 295.6201171875, Entropy -315.7948913574219, Learning Rate: 0.0003125\n",
      "Epoch [2889/20000], Loss: 275.37884521484375, Entropy -297.2926330566406, Learning Rate: 0.0003125\n",
      "Epoch [2890/20000], Loss: 289.32757568359375, Entropy -306.0563049316406, Learning Rate: 0.0003125\n",
      "Epoch [2891/20000], Loss: 298.64447021484375, Entropy -309.7133483886719, Learning Rate: 0.0003125\n",
      "Epoch [2892/20000], Loss: 297.8940124511719, Entropy -315.41192626953125, Learning Rate: 0.0003125\n",
      "Epoch [2893/20000], Loss: 288.58123779296875, Entropy -312.3485107421875, Learning Rate: 0.0003125\n",
      "Epoch [2894/20000], Loss: 286.9727783203125, Entropy -301.1107177734375, Learning Rate: 0.0003125\n",
      "Epoch [2895/20000], Loss: 271.44195556640625, Entropy -289.9480285644531, Learning Rate: 0.0003125\n",
      "Epoch [2896/20000], Loss: 302.81756591796875, Entropy -315.9031677246094, Learning Rate: 0.0003125\n",
      "Epoch [2897/20000], Loss: 282.10467529296875, Entropy -305.0057373046875, Learning Rate: 0.0003125\n",
      "Epoch [2898/20000], Loss: 282.546875, Entropy -298.2102966308594, Learning Rate: 0.0003125\n",
      "Epoch [2899/20000], Loss: 273.07611083984375, Entropy -287.80010986328125, Learning Rate: 0.0003125\n",
      "Epoch [2900/20000], Loss: 282.69805908203125, Entropy -298.5153503417969, Learning Rate: 0.0003125\n",
      "Epoch [2901/20000], Loss: 282.0328674316406, Entropy -294.7798767089844, Learning Rate: 0.0003125\n",
      "Epoch [2902/20000], Loss: 291.0072326660156, Entropy -304.0154113769531, Learning Rate: 0.0003125\n",
      "Epoch [2903/20000], Loss: 286.87847900390625, Entropy -304.18768310546875, Learning Rate: 0.0003125\n",
      "Epoch [2904/20000], Loss: 272.7191162109375, Entropy -286.5824279785156, Learning Rate: 0.0003125\n",
      "Epoch [2905/20000], Loss: 282.27105712890625, Entropy -299.19537353515625, Learning Rate: 0.0003125\n",
      "Epoch [2906/20000], Loss: 294.46356201171875, Entropy -318.8349914550781, Learning Rate: 0.0003125\n",
      "Epoch [2907/20000], Loss: 295.2425537109375, Entropy -310.0274658203125, Learning Rate: 0.0003125\n",
      "Epoch [2908/20000], Loss: 285.0797119140625, Entropy -301.287841796875, Learning Rate: 0.0003125\n",
      "Epoch [2909/20000], Loss: 294.744384765625, Entropy -312.56658935546875, Learning Rate: 0.0003125\n",
      "Epoch [2910/20000], Loss: 300.0821533203125, Entropy -323.0417175292969, Learning Rate: 0.0003125\n",
      "Epoch [2911/20000], Loss: 284.89324951171875, Entropy -296.7919616699219, Learning Rate: 0.0003125\n",
      "Epoch [2912/20000], Loss: 282.0606994628906, Entropy -300.6591796875, Learning Rate: 0.0003125\n",
      "Epoch [2913/20000], Loss: 294.89630126953125, Entropy -306.60943603515625, Learning Rate: 0.0003125\n",
      "Epoch [2914/20000], Loss: 279.49285888671875, Entropy -297.2872009277344, Learning Rate: 0.0003125\n",
      "Epoch [2915/20000], Loss: 283.72052001953125, Entropy -302.81640625, Learning Rate: 0.0003125\n",
      "Epoch [2916/20000], Loss: 296.3662414550781, Entropy -315.8756408691406, Learning Rate: 0.0003125\n",
      "Epoch [2917/20000], Loss: 296.12677001953125, Entropy -313.4383850097656, Learning Rate: 0.0003125\n",
      "Epoch [2918/20000], Loss: 271.27386474609375, Entropy -288.8241882324219, Learning Rate: 0.0003125\n",
      "Epoch [2919/20000], Loss: 293.42816162109375, Entropy -309.4579162597656, Learning Rate: 0.0003125\n",
      "Epoch [2920/20000], Loss: 280.127197265625, Entropy -292.2489929199219, Learning Rate: 0.0003125\n",
      "Epoch [2921/20000], Loss: 291.3438720703125, Entropy -301.8790588378906, Learning Rate: 0.0003125\n",
      "Epoch [2922/20000], Loss: 297.775390625, Entropy -315.2330627441406, Learning Rate: 0.0003125\n",
      "Epoch [2923/20000], Loss: 286.6208190917969, Entropy -303.8396911621094, Learning Rate: 0.0003125\n",
      "Epoch [2924/20000], Loss: 283.1742858886719, Entropy -296.2003479003906, Learning Rate: 0.0003125\n",
      "Epoch [2925/20000], Loss: 270.14727783203125, Entropy -291.9163818359375, Learning Rate: 0.0003125\n",
      "Epoch [2926/20000], Loss: 295.9081115722656, Entropy -308.76068115234375, Learning Rate: 0.0003125\n",
      "Epoch [2927/20000], Loss: 280.90081787109375, Entropy -295.90789794921875, Learning Rate: 0.0003125\n",
      "Epoch [2928/20000], Loss: 287.0233154296875, Entropy -302.4627990722656, Learning Rate: 0.0003125\n",
      "Epoch [2929/20000], Loss: 284.5310974121094, Entropy -301.3656311035156, Learning Rate: 0.0003125\n",
      "Epoch [2930/20000], Loss: 284.86151123046875, Entropy -297.4248352050781, Learning Rate: 0.0003125\n",
      "Epoch [2931/20000], Loss: 286.5224609375, Entropy -301.31427001953125, Learning Rate: 0.0003125\n",
      "Epoch [2932/20000], Loss: 281.9417724609375, Entropy -296.82025146484375, Learning Rate: 0.0003125\n",
      "Epoch [2933/20000], Loss: 289.67413330078125, Entropy -310.06622314453125, Learning Rate: 0.0003125\n",
      "Epoch [2934/20000], Loss: 296.4637756347656, Entropy -312.5171813964844, Learning Rate: 0.0003125\n",
      "Epoch [2935/20000], Loss: 289.63665771484375, Entropy -306.7374572753906, Learning Rate: 0.0003125\n",
      "Epoch [2936/20000], Loss: 281.16632080078125, Entropy -292.095947265625, Learning Rate: 0.0003125\n",
      "Epoch [2937/20000], Loss: 281.8576965332031, Entropy -301.17694091796875, Learning Rate: 0.0003125\n",
      "Epoch [2938/20000], Loss: 299.739013671875, Entropy -310.9801025390625, Learning Rate: 0.0003125\n",
      "Epoch [2939/20000], Loss: 291.09918212890625, Entropy -312.2104187011719, Learning Rate: 0.0003125\n",
      "Epoch [2940/20000], Loss: 286.1025695800781, Entropy -301.1570739746094, Learning Rate: 0.0003125\n",
      "Epoch [2941/20000], Loss: 289.453369140625, Entropy -307.270751953125, Learning Rate: 0.0003125\n",
      "Epoch [2942/20000], Loss: 292.334228515625, Entropy -304.0487976074219, Learning Rate: 0.0003125\n",
      "Epoch [2943/20000], Loss: 289.913818359375, Entropy -308.7411804199219, Learning Rate: 0.0003125\n",
      "Epoch [2944/20000], Loss: 297.3509521484375, Entropy -304.75335693359375, Learning Rate: 0.0003125\n",
      "Epoch [2945/20000], Loss: 284.80731201171875, Entropy -302.06695556640625, Learning Rate: 0.0003125\n",
      "Epoch [2946/20000], Loss: 288.0557861328125, Entropy -300.70928955078125, Learning Rate: 0.0003125\n",
      "Epoch [2947/20000], Loss: 289.4632873535156, Entropy -310.23834228515625, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2948/20000], Loss: 297.4792785644531, Entropy -298.4526672363281, Learning Rate: 0.0003125\n",
      "Epoch [2949/20000], Loss: 275.67059326171875, Entropy -297.36151123046875, Learning Rate: 0.0003125\n",
      "Epoch [2950/20000], Loss: 279.706298828125, Entropy -292.2383728027344, Learning Rate: 0.0003125\n",
      "Epoch [2951/20000], Loss: 304.9682312011719, Entropy -316.7559509277344, Learning Rate: 0.0003125\n",
      "Epoch [2952/20000], Loss: 293.9016418457031, Entropy -312.51373291015625, Learning Rate: 0.0003125\n",
      "Epoch [2953/20000], Loss: 293.6617126464844, Entropy -302.7810974121094, Learning Rate: 0.0003125\n",
      "Epoch [2954/20000], Loss: 304.40618896484375, Entropy -324.7122497558594, Learning Rate: 0.0003125\n",
      "Epoch [2955/20000], Loss: 296.44049072265625, Entropy -309.1423645019531, Learning Rate: 0.0003125\n",
      "Epoch [2956/20000], Loss: 279.4033203125, Entropy -293.3424072265625, Learning Rate: 0.0003125\n",
      "Epoch [2957/20000], Loss: 287.8299865722656, Entropy -302.99652099609375, Learning Rate: 0.0003125\n",
      "Epoch [2958/20000], Loss: 287.5871887207031, Entropy -303.4981384277344, Learning Rate: 0.0003125\n",
      "Epoch [2959/20000], Loss: 297.88134765625, Entropy -317.6027526855469, Learning Rate: 0.0003125\n",
      "Epoch [2960/20000], Loss: 312.3457946777344, Entropy -315.5296630859375, Learning Rate: 0.0003125\n",
      "Epoch [2961/20000], Loss: 287.1593017578125, Entropy -310.9851989746094, Learning Rate: 0.0003125\n",
      "Epoch [2962/20000], Loss: 288.36126708984375, Entropy -302.23602294921875, Learning Rate: 0.0003125\n",
      "Epoch [2963/20000], Loss: 272.2463684082031, Entropy -285.6319885253906, Learning Rate: 0.0003125\n",
      "Epoch [2964/20000], Loss: 292.3231506347656, Entropy -308.50054931640625, Learning Rate: 0.0003125\n",
      "Epoch [2965/20000], Loss: 279.1580810546875, Entropy -295.7481384277344, Learning Rate: 0.0003125\n",
      "Epoch [2966/20000], Loss: 283.79852294921875, Entropy -296.3692626953125, Learning Rate: 0.0003125\n",
      "Epoch [2967/20000], Loss: 296.3134460449219, Entropy -321.67486572265625, Learning Rate: 0.0003125\n",
      "Epoch [2968/20000], Loss: 267.7779541015625, Entropy -286.7101135253906, Learning Rate: 0.0003125\n",
      "Epoch [2969/20000], Loss: 307.1221923828125, Entropy -318.7762756347656, Learning Rate: 0.0003125\n",
      "Epoch [2970/20000], Loss: 280.24822998046875, Entropy -297.04302978515625, Learning Rate: 0.0003125\n",
      "Epoch [2971/20000], Loss: 282.7158203125, Entropy -303.0888671875, Learning Rate: 0.0003125\n",
      "Epoch [2972/20000], Loss: 283.3325500488281, Entropy -301.16815185546875, Learning Rate: 0.0003125\n",
      "Epoch [2973/20000], Loss: 292.4481201171875, Entropy -304.6916809082031, Learning Rate: 0.0003125\n",
      "Epoch [2974/20000], Loss: 276.73944091796875, Entropy -301.4167175292969, Learning Rate: 0.0003125\n",
      "Epoch [2975/20000], Loss: 295.0364685058594, Entropy -311.2064514160156, Learning Rate: 0.0003125\n",
      "Epoch [2976/20000], Loss: 301.5407409667969, Entropy -312.9284973144531, Learning Rate: 0.0003125\n",
      "Epoch [2977/20000], Loss: 277.8549499511719, Entropy -292.3459777832031, Learning Rate: 0.0003125\n",
      "Epoch [2978/20000], Loss: 300.05523681640625, Entropy -317.1302795410156, Learning Rate: 0.0003125\n",
      "Epoch [2979/20000], Loss: 297.74658203125, Entropy -320.0616455078125, Learning Rate: 0.0003125\n",
      "Epoch [2980/20000], Loss: 272.3005065917969, Entropy -291.38238525390625, Learning Rate: 0.0003125\n",
      "Epoch [2981/20000], Loss: 266.6909484863281, Entropy -287.487548828125, Learning Rate: 0.0003125\n",
      "Epoch [2982/20000], Loss: 288.93994140625, Entropy -306.0079650878906, Learning Rate: 0.0003125\n",
      "Epoch [2983/20000], Loss: 289.05126953125, Entropy -301.88751220703125, Learning Rate: 0.0003125\n",
      "Epoch [2984/20000], Loss: 289.29205322265625, Entropy -307.00146484375, Learning Rate: 0.0003125\n",
      "Epoch [2985/20000], Loss: 281.39605712890625, Entropy -300.69207763671875, Learning Rate: 0.0003125\n",
      "Epoch [2986/20000], Loss: 290.532470703125, Entropy -308.5345153808594, Learning Rate: 0.0003125\n",
      "Epoch [2987/20000], Loss: 284.8556823730469, Entropy -301.8499755859375, Learning Rate: 0.0003125\n",
      "Epoch [2988/20000], Loss: 282.49102783203125, Entropy -302.4143371582031, Learning Rate: 0.0003125\n",
      "Epoch [2989/20000], Loss: 297.21246337890625, Entropy -317.67572021484375, Learning Rate: 0.0003125\n",
      "Epoch [2990/20000], Loss: 281.633056640625, Entropy -304.2335205078125, Learning Rate: 0.0003125\n",
      "Epoch [2991/20000], Loss: 295.7646789550781, Entropy -320.6756591796875, Learning Rate: 0.0003125\n",
      "Epoch [2992/20000], Loss: 280.2780456542969, Entropy -297.8631286621094, Learning Rate: 0.0003125\n",
      "Epoch [2993/20000], Loss: 267.09857177734375, Entropy -284.9234924316406, Learning Rate: 0.0003125\n",
      "Epoch [2994/20000], Loss: 288.71087646484375, Entropy -303.48272705078125, Learning Rate: 0.0003125\n",
      "Epoch [2995/20000], Loss: 286.0746765136719, Entropy -298.8604736328125, Learning Rate: 0.0003125\n",
      "Epoch [2996/20000], Loss: 287.85675048828125, Entropy -307.702880859375, Learning Rate: 0.0003125\n",
      "Epoch [2997/20000], Loss: 286.66766357421875, Entropy -304.68023681640625, Learning Rate: 0.0003125\n",
      "Epoch [2998/20000], Loss: 285.2398681640625, Entropy -296.55975341796875, Learning Rate: 0.0003125\n",
      "Epoch [2999/20000], Loss: 302.7337646484375, Entropy -317.1188659667969, Learning Rate: 0.0003125\n",
      "Epoch [3000/20000], Loss: 290.28741455078125, Entropy -309.54241943359375, Learning Rate: 0.0003125\n",
      "Epoch [3001/20000], Loss: 289.80523681640625, Entropy -307.63433837890625, Learning Rate: 0.0003125\n",
      "Epoch [3002/20000], Loss: 296.6304626464844, Entropy -312.19427490234375, Learning Rate: 0.0003125\n",
      "Epoch [3003/20000], Loss: 303.44146728515625, Entropy -322.597900390625, Learning Rate: 0.0003125\n",
      "Epoch [3004/20000], Loss: 287.74462890625, Entropy -302.1282653808594, Learning Rate: 0.0003125\n",
      "Epoch [3005/20000], Loss: 290.9947204589844, Entropy -305.8130798339844, Learning Rate: 0.0003125\n",
      "Epoch [3006/20000], Loss: 276.681884765625, Entropy -289.7912292480469, Learning Rate: 0.0003125\n",
      "Epoch [3007/20000], Loss: 277.32415771484375, Entropy -296.63177490234375, Learning Rate: 0.0003125\n",
      "Epoch [3008/20000], Loss: 271.28204345703125, Entropy -283.4886474609375, Learning Rate: 0.0003125\n",
      "Epoch [3009/20000], Loss: 273.3515625, Entropy -292.3356628417969, Learning Rate: 0.0003125\n",
      "Epoch [3010/20000], Loss: 293.9869384765625, Entropy -317.0661926269531, Learning Rate: 0.0003125\n",
      "Epoch [3011/20000], Loss: 295.40130615234375, Entropy -310.7210388183594, Learning Rate: 0.0003125\n",
      "Epoch [3012/20000], Loss: 278.846923828125, Entropy -298.9259948730469, Learning Rate: 0.0003125\n",
      "Epoch [3013/20000], Loss: 291.1563720703125, Entropy -311.46380615234375, Learning Rate: 0.0003125\n",
      "Epoch [3014/20000], Loss: 271.90008544921875, Entropy -285.5546875, Learning Rate: 0.0003125\n",
      "Epoch [3015/20000], Loss: 280.6256103515625, Entropy -293.91571044921875, Learning Rate: 0.0003125\n",
      "Epoch [3016/20000], Loss: 282.63043212890625, Entropy -302.5706481933594, Learning Rate: 0.0003125\n",
      "Epoch [3017/20000], Loss: 294.3798828125, Entropy -317.50634765625, Learning Rate: 0.0003125\n",
      "Epoch [3018/20000], Loss: 278.1088562011719, Entropy -295.271240234375, Learning Rate: 0.0003125\n",
      "Epoch [3019/20000], Loss: 271.1920166015625, Entropy -287.77154541015625, Learning Rate: 0.0003125\n",
      "Epoch [3020/20000], Loss: 280.5233154296875, Entropy -299.8358459472656, Learning Rate: 0.0003125\n",
      "Epoch [3021/20000], Loss: 283.293212890625, Entropy -300.0279541015625, Learning Rate: 0.0003125\n",
      "Epoch [3022/20000], Loss: 300.15802001953125, Entropy -315.5091247558594, Learning Rate: 0.0003125\n",
      "Epoch [3023/20000], Loss: 282.26251220703125, Entropy -293.18817138671875, Learning Rate: 0.0003125\n",
      "Epoch [3024/20000], Loss: 282.9316101074219, Entropy -301.28924560546875, Learning Rate: 0.0003125\n",
      "Epoch [3025/20000], Loss: 289.65625, Entropy -306.71661376953125, Learning Rate: 0.0003125\n",
      "Epoch [3026/20000], Loss: 296.0166015625, Entropy -314.2164001464844, Learning Rate: 0.0003125\n",
      "Epoch [3027/20000], Loss: 303.1265563964844, Entropy -320.0866394042969, Learning Rate: 0.0003125\n",
      "Epoch [3028/20000], Loss: 280.709716796875, Entropy -295.2972106933594, Learning Rate: 0.0003125\n",
      "Epoch [3029/20000], Loss: 273.90289306640625, Entropy -289.3970947265625, Learning Rate: 0.0003125\n",
      "Epoch [3030/20000], Loss: 282.21539306640625, Entropy -301.3447570800781, Learning Rate: 0.0003125\n",
      "Epoch [3031/20000], Loss: 286.0539245605469, Entropy -301.4148254394531, Learning Rate: 0.0003125\n",
      "Epoch [3032/20000], Loss: 298.7196044921875, Entropy -311.3273620605469, Learning Rate: 0.0003125\n",
      "Epoch [3033/20000], Loss: 292.6796875, Entropy -313.28619384765625, Learning Rate: 0.0003125\n",
      "Epoch [3034/20000], Loss: 289.38629150390625, Entropy -300.9349060058594, Learning Rate: 0.0003125\n",
      "Epoch [3035/20000], Loss: 284.10205078125, Entropy -304.8076171875, Learning Rate: 0.0003125\n",
      "Epoch [3036/20000], Loss: 283.3258056640625, Entropy -296.6052551269531, Learning Rate: 0.0003125\n",
      "Epoch [3037/20000], Loss: 291.5001220703125, Entropy -312.2813415527344, Learning Rate: 0.0003125\n",
      "Epoch [3038/20000], Loss: 273.54718017578125, Entropy -297.8116760253906, Learning Rate: 0.0003125\n",
      "Epoch [3039/20000], Loss: 292.1703186035156, Entropy -310.0736999511719, Learning Rate: 0.0003125\n",
      "Epoch [3040/20000], Loss: 283.551513671875, Entropy -299.2695007324219, Learning Rate: 0.0003125\n",
      "Epoch [3041/20000], Loss: 290.465087890625, Entropy -304.31219482421875, Learning Rate: 0.0003125\n",
      "Epoch [3042/20000], Loss: 279.2335205078125, Entropy -297.14947509765625, Learning Rate: 0.0003125\n",
      "Epoch [3043/20000], Loss: 291.222412109375, Entropy -308.4555358886719, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3044/20000], Loss: 285.71160888671875, Entropy -311.74603271484375, Learning Rate: 0.0003125\n",
      "Epoch [3045/20000], Loss: 282.19195556640625, Entropy -298.3777770996094, Learning Rate: 0.0003125\n",
      "Epoch [3046/20000], Loss: 286.62255859375, Entropy -306.6500244140625, Learning Rate: 0.0003125\n",
      "Epoch [3047/20000], Loss: 283.5013732910156, Entropy -308.4196472167969, Learning Rate: 0.0003125\n",
      "Epoch [3048/20000], Loss: 283.0552673339844, Entropy -298.4405822753906, Learning Rate: 0.0003125\n",
      "Epoch [3049/20000], Loss: 284.85552978515625, Entropy -307.0634765625, Learning Rate: 0.0003125\n",
      "Epoch [3050/20000], Loss: 277.2203369140625, Entropy -298.0845642089844, Learning Rate: 0.0003125\n",
      "Epoch [3051/20000], Loss: 269.8869934082031, Entropy -298.4419860839844, Learning Rate: 0.0003125\n",
      "Epoch [3052/20000], Loss: 291.9166259765625, Entropy -309.0201721191406, Learning Rate: 0.0003125\n",
      "Epoch [3053/20000], Loss: 267.8927001953125, Entropy -282.1338806152344, Learning Rate: 0.0003125\n",
      "Epoch [3054/20000], Loss: 278.3638610839844, Entropy -295.49505615234375, Learning Rate: 0.0003125\n",
      "Epoch [3055/20000], Loss: 280.06964111328125, Entropy -300.2429504394531, Learning Rate: 0.0003125\n",
      "Epoch [3056/20000], Loss: 302.41192626953125, Entropy -317.5777282714844, Learning Rate: 0.00015625\n",
      "Epoch [3057/20000], Loss: 265.0, Entropy -284.46234130859375, Learning Rate: 0.00015625\n",
      "Epoch [3058/20000], Loss: 302.58038330078125, Entropy -321.90631103515625, Learning Rate: 0.00015625\n",
      "Epoch [3059/20000], Loss: 296.15582275390625, Entropy -310.8921203613281, Learning Rate: 0.00015625\n",
      "Epoch [3060/20000], Loss: 297.2394714355469, Entropy -312.8992614746094, Learning Rate: 0.00015625\n",
      "Epoch [3061/20000], Loss: 282.62548828125, Entropy -302.06658935546875, Learning Rate: 0.00015625\n",
      "Epoch [3062/20000], Loss: 284.0523986816406, Entropy -297.3697509765625, Learning Rate: 0.00015625\n",
      "Epoch [3063/20000], Loss: 271.50372314453125, Entropy -289.8294982910156, Learning Rate: 0.00015625\n",
      "Epoch [3064/20000], Loss: 296.762451171875, Entropy -306.61212158203125, Learning Rate: 0.00015625\n",
      "Epoch [3065/20000], Loss: 269.8305969238281, Entropy -294.4573669433594, Learning Rate: 0.00015625\n",
      "Epoch [3066/20000], Loss: 291.821044921875, Entropy -307.7366638183594, Learning Rate: 0.00015625\n",
      "Epoch [3067/20000], Loss: 278.57318115234375, Entropy -293.76507568359375, Learning Rate: 0.00015625\n",
      "Epoch [3068/20000], Loss: 289.38128662109375, Entropy -297.3841247558594, Learning Rate: 0.00015625\n",
      "Epoch [3069/20000], Loss: 288.3843994140625, Entropy -307.1282653808594, Learning Rate: 0.00015625\n",
      "Epoch [3070/20000], Loss: 311.65447998046875, Entropy -311.4949645996094, Learning Rate: 0.00015625\n",
      "Epoch [3071/20000], Loss: 282.71612548828125, Entropy -301.9314270019531, Learning Rate: 0.00015625\n",
      "Epoch [3072/20000], Loss: 286.7675476074219, Entropy -305.1607666015625, Learning Rate: 0.00015625\n",
      "Epoch [3073/20000], Loss: 293.3836975097656, Entropy -306.3926086425781, Learning Rate: 0.00015625\n",
      "Epoch [3074/20000], Loss: 296.38140869140625, Entropy -305.20941162109375, Learning Rate: 0.00015625\n",
      "Epoch [3075/20000], Loss: 304.2063903808594, Entropy -318.8843994140625, Learning Rate: 0.00015625\n",
      "Epoch [3076/20000], Loss: 282.84716796875, Entropy -295.48785400390625, Learning Rate: 0.00015625\n",
      "Epoch [3077/20000], Loss: 294.2019348144531, Entropy -311.5987243652344, Learning Rate: 0.00015625\n",
      "Epoch [3078/20000], Loss: 286.4810791015625, Entropy -309.0382080078125, Learning Rate: 0.00015625\n",
      "Epoch [3079/20000], Loss: 294.3638000488281, Entropy -315.2737121582031, Learning Rate: 0.00015625\n",
      "Epoch [3080/20000], Loss: 285.23931884765625, Entropy -309.0628967285156, Learning Rate: 0.00015625\n",
      "Epoch [3081/20000], Loss: 295.4676208496094, Entropy -310.594970703125, Learning Rate: 0.00015625\n",
      "Epoch [3082/20000], Loss: 305.98199462890625, Entropy -317.5104064941406, Learning Rate: 0.00015625\n",
      "Epoch [3083/20000], Loss: 302.35052490234375, Entropy -319.26348876953125, Learning Rate: 0.00015625\n",
      "Epoch [3084/20000], Loss: 291.20123291015625, Entropy -305.7623291015625, Learning Rate: 0.00015625\n",
      "Epoch [3085/20000], Loss: 279.65826416015625, Entropy -300.5370178222656, Learning Rate: 0.00015625\n",
      "Epoch [3086/20000], Loss: 280.06854248046875, Entropy -293.02679443359375, Learning Rate: 0.00015625\n",
      "Epoch [3087/20000], Loss: 297.8142395019531, Entropy -320.391845703125, Learning Rate: 0.00015625\n",
      "Epoch [3088/20000], Loss: 277.674560546875, Entropy -298.2050476074219, Learning Rate: 0.00015625\n",
      "Epoch [3089/20000], Loss: 279.7733154296875, Entropy -295.0168151855469, Learning Rate: 0.00015625\n",
      "Epoch [3090/20000], Loss: 281.3381652832031, Entropy -300.792236328125, Learning Rate: 0.00015625\n",
      "Epoch [3091/20000], Loss: 294.7767639160156, Entropy -301.2662048339844, Learning Rate: 0.00015625\n",
      "Epoch [3092/20000], Loss: 271.32049560546875, Entropy -285.66845703125, Learning Rate: 0.00015625\n",
      "Epoch [3093/20000], Loss: 284.5283203125, Entropy -313.3797302246094, Learning Rate: 0.00015625\n",
      "Epoch [3094/20000], Loss: 294.17364501953125, Entropy -320.3046875, Learning Rate: 0.00015625\n",
      "Epoch [3095/20000], Loss: 306.7178649902344, Entropy -325.74005126953125, Learning Rate: 0.00015625\n",
      "Epoch [3096/20000], Loss: 295.54119873046875, Entropy -310.8773498535156, Learning Rate: 0.00015625\n",
      "Epoch [3097/20000], Loss: 312.68280029296875, Entropy -316.6553955078125, Learning Rate: 0.00015625\n",
      "Epoch [3098/20000], Loss: 285.5816955566406, Entropy -304.02984619140625, Learning Rate: 0.00015625\n",
      "Epoch [3099/20000], Loss: 292.0041198730469, Entropy -308.7449645996094, Learning Rate: 0.00015625\n",
      "Epoch [3100/20000], Loss: 295.1763916015625, Entropy -302.1334228515625, Learning Rate: 0.00015625\n",
      "Epoch [3101/20000], Loss: 288.50408935546875, Entropy -305.40234375, Learning Rate: 0.00015625\n",
      "Epoch [3102/20000], Loss: 294.37554931640625, Entropy -304.059326171875, Learning Rate: 0.00015625\n",
      "Epoch [3103/20000], Loss: 295.478271484375, Entropy -319.04248046875, Learning Rate: 0.00015625\n",
      "Epoch [3104/20000], Loss: 292.65557861328125, Entropy -310.92767333984375, Learning Rate: 0.00015625\n",
      "Epoch [3105/20000], Loss: 266.9896240234375, Entropy -283.9774169921875, Learning Rate: 0.00015625\n",
      "Epoch [3106/20000], Loss: 269.8487243652344, Entropy -290.8813781738281, Learning Rate: 0.00015625\n",
      "Epoch [3107/20000], Loss: 272.825439453125, Entropy -291.6158752441406, Learning Rate: 0.00015625\n",
      "Epoch [3108/20000], Loss: 265.6339111328125, Entropy -292.99017333984375, Learning Rate: 0.00015625\n",
      "Epoch [3109/20000], Loss: 295.3125, Entropy -317.9213562011719, Learning Rate: 0.00015625\n",
      "Epoch [3110/20000], Loss: 295.06671142578125, Entropy -312.1437072753906, Learning Rate: 0.00015625\n",
      "Epoch [3111/20000], Loss: 287.52935791015625, Entropy -303.1907043457031, Learning Rate: 0.00015625\n",
      "Epoch [3112/20000], Loss: 273.99072265625, Entropy -286.87158203125, Learning Rate: 0.00015625\n",
      "Epoch [3113/20000], Loss: 286.9743957519531, Entropy -309.1683654785156, Learning Rate: 0.00015625\n",
      "Epoch [3114/20000], Loss: 277.1833190917969, Entropy -295.4433288574219, Learning Rate: 0.00015625\n",
      "Epoch [3115/20000], Loss: 271.4630126953125, Entropy -293.9915771484375, Learning Rate: 0.00015625\n",
      "Epoch [3116/20000], Loss: 283.04071044921875, Entropy -300.63250732421875, Learning Rate: 0.00015625\n",
      "Epoch [3117/20000], Loss: 282.7213439941406, Entropy -296.34716796875, Learning Rate: 0.00015625\n",
      "Epoch [3118/20000], Loss: 272.8989562988281, Entropy -289.07025146484375, Learning Rate: 0.00015625\n",
      "Epoch [3119/20000], Loss: 292.0249938964844, Entropy -313.35662841796875, Learning Rate: 0.00015625\n",
      "Epoch [3120/20000], Loss: 293.1107177734375, Entropy -303.3315124511719, Learning Rate: 0.00015625\n",
      "Epoch [3121/20000], Loss: 283.5433654785156, Entropy -301.3269348144531, Learning Rate: 0.00015625\n",
      "Epoch [3122/20000], Loss: 284.8354187011719, Entropy -308.18878173828125, Learning Rate: 0.00015625\n",
      "Epoch [3123/20000], Loss: 286.2981262207031, Entropy -304.28326416015625, Learning Rate: 0.00015625\n",
      "Epoch [3124/20000], Loss: 283.42425537109375, Entropy -298.34393310546875, Learning Rate: 0.00015625\n",
      "Epoch [3125/20000], Loss: 282.36712646484375, Entropy -301.39874267578125, Learning Rate: 0.00015625\n",
      "Epoch [3126/20000], Loss: 289.50079345703125, Entropy -301.34271240234375, Learning Rate: 0.00015625\n",
      "Epoch [3127/20000], Loss: 275.630126953125, Entropy -292.5676574707031, Learning Rate: 0.00015625\n",
      "Epoch [3128/20000], Loss: 278.03717041015625, Entropy -299.0246887207031, Learning Rate: 0.00015625\n",
      "Epoch [3129/20000], Loss: 270.72406005859375, Entropy -289.80035400390625, Learning Rate: 0.00015625\n",
      "Epoch [3130/20000], Loss: 304.9925537109375, Entropy -322.1856384277344, Learning Rate: 0.00015625\n",
      "Epoch [3131/20000], Loss: 284.74139404296875, Entropy -300.3655090332031, Learning Rate: 0.00015625\n",
      "Epoch [3132/20000], Loss: 290.89666748046875, Entropy -314.18084716796875, Learning Rate: 0.00015625\n",
      "Epoch [3133/20000], Loss: 292.611328125, Entropy -306.6651611328125, Learning Rate: 0.00015625\n",
      "Epoch [3134/20000], Loss: 283.60931396484375, Entropy -303.375244140625, Learning Rate: 0.00015625\n",
      "Epoch [3135/20000], Loss: 274.0657043457031, Entropy -299.9634094238281, Learning Rate: 0.00015625\n",
      "Epoch [3136/20000], Loss: 290.77593994140625, Entropy -312.29241943359375, Learning Rate: 0.00015625\n",
      "Epoch [3137/20000], Loss: 295.0028076171875, Entropy -305.364013671875, Learning Rate: 0.00015625\n",
      "Epoch [3138/20000], Loss: 271.8863525390625, Entropy -295.6058044433594, Learning Rate: 0.00015625\n",
      "Epoch [3139/20000], Loss: 274.6552734375, Entropy -300.2312927246094, Learning Rate: 0.00015625\n",
      "Epoch [3140/20000], Loss: 286.9385070800781, Entropy -298.5602111816406, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3141/20000], Loss: 278.11639404296875, Entropy -285.78228759765625, Learning Rate: 0.00015625\n",
      "Epoch [3142/20000], Loss: 284.16485595703125, Entropy -297.8761291503906, Learning Rate: 0.00015625\n",
      "Epoch [3143/20000], Loss: 298.0638427734375, Entropy -310.5541687011719, Learning Rate: 0.00015625\n",
      "Epoch [3144/20000], Loss: 292.4136657714844, Entropy -298.734130859375, Learning Rate: 0.00015625\n",
      "Epoch [3145/20000], Loss: 309.8035888671875, Entropy -315.7377624511719, Learning Rate: 0.00015625\n",
      "Epoch [3146/20000], Loss: 277.1031188964844, Entropy -291.5906677246094, Learning Rate: 0.00015625\n",
      "Epoch [3147/20000], Loss: 283.44000244140625, Entropy -306.5143737792969, Learning Rate: 0.00015625\n",
      "Epoch [3148/20000], Loss: 288.64764404296875, Entropy -309.5888977050781, Learning Rate: 0.00015625\n",
      "Epoch [3149/20000], Loss: 283.4076843261719, Entropy -301.99200439453125, Learning Rate: 0.00015625\n",
      "Epoch [3150/20000], Loss: 291.04058837890625, Entropy -307.916015625, Learning Rate: 0.00015625\n",
      "Epoch [3151/20000], Loss: 288.7505187988281, Entropy -299.98858642578125, Learning Rate: 0.00015625\n",
      "Epoch [3152/20000], Loss: 281.1669921875, Entropy -296.2362365722656, Learning Rate: 0.00015625\n",
      "Epoch [3153/20000], Loss: 274.7660217285156, Entropy -293.7675476074219, Learning Rate: 0.00015625\n",
      "Epoch [3154/20000], Loss: 300.78955078125, Entropy -320.364013671875, Learning Rate: 0.00015625\n",
      "Epoch [3155/20000], Loss: 281.0210876464844, Entropy -301.2878112792969, Learning Rate: 0.00015625\n",
      "Epoch [3156/20000], Loss: 304.9870910644531, Entropy -320.8458557128906, Learning Rate: 0.00015625\n",
      "Epoch [3157/20000], Loss: 296.4968566894531, Entropy -314.86865234375, Learning Rate: 0.00015625\n",
      "Epoch [3158/20000], Loss: 281.77044677734375, Entropy -298.05096435546875, Learning Rate: 0.00015625\n",
      "Epoch [3159/20000], Loss: 291.0055847167969, Entropy -308.0911560058594, Learning Rate: 0.00015625\n",
      "Epoch [3160/20000], Loss: 292.2613525390625, Entropy -312.4891052246094, Learning Rate: 0.00015625\n",
      "Epoch [3161/20000], Loss: 285.49847412109375, Entropy -303.6280517578125, Learning Rate: 0.00015625\n",
      "Epoch [3162/20000], Loss: 298.28790283203125, Entropy -314.1650390625, Learning Rate: 0.00015625\n",
      "Epoch [3163/20000], Loss: 289.4803466796875, Entropy -308.3319091796875, Learning Rate: 0.00015625\n",
      "Epoch [3164/20000], Loss: 287.9185791015625, Entropy -304.2574462890625, Learning Rate: 0.00015625\n",
      "Epoch [3165/20000], Loss: 283.56048583984375, Entropy -293.4967346191406, Learning Rate: 0.00015625\n",
      "Epoch [3166/20000], Loss: 282.2415771484375, Entropy -302.4449768066406, Learning Rate: 0.00015625\n",
      "Epoch [3167/20000], Loss: 282.2569885253906, Entropy -306.15313720703125, Learning Rate: 0.00015625\n",
      "Epoch [3168/20000], Loss: 288.53125, Entropy -296.51214599609375, Learning Rate: 0.00015625\n",
      "Epoch [3169/20000], Loss: 294.3453369140625, Entropy -313.2391662597656, Learning Rate: 0.00015625\n",
      "Epoch [3170/20000], Loss: 275.4696044921875, Entropy -291.228759765625, Learning Rate: 0.00015625\n",
      "Epoch [3171/20000], Loss: 291.9250183105469, Entropy -305.74493408203125, Learning Rate: 0.00015625\n",
      "Epoch [3172/20000], Loss: 279.5885009765625, Entropy -293.57513427734375, Learning Rate: 0.00015625\n",
      "Epoch [3173/20000], Loss: 290.49261474609375, Entropy -311.7490539550781, Learning Rate: 0.00015625\n",
      "Epoch [3174/20000], Loss: 287.14141845703125, Entropy -305.1206359863281, Learning Rate: 0.00015625\n",
      "Epoch [3175/20000], Loss: 270.8592834472656, Entropy -287.0562438964844, Learning Rate: 0.00015625\n",
      "Epoch [3176/20000], Loss: 308.44891357421875, Entropy -326.57098388671875, Learning Rate: 0.00015625\n",
      "Epoch [3177/20000], Loss: 287.6097412109375, Entropy -310.6274719238281, Learning Rate: 0.00015625\n",
      "Epoch [3178/20000], Loss: 292.57537841796875, Entropy -312.5599670410156, Learning Rate: 0.00015625\n",
      "Epoch [3179/20000], Loss: 301.74652099609375, Entropy -311.9939880371094, Learning Rate: 0.00015625\n",
      "Epoch [3180/20000], Loss: 294.37908935546875, Entropy -315.5166320800781, Learning Rate: 0.00015625\n",
      "Epoch [3181/20000], Loss: 278.31658935546875, Entropy -299.66253662109375, Learning Rate: 0.00015625\n",
      "Epoch [3182/20000], Loss: 292.3795166015625, Entropy -317.9739685058594, Learning Rate: 0.00015625\n",
      "Epoch [3183/20000], Loss: 280.432373046875, Entropy -297.309326171875, Learning Rate: 0.00015625\n",
      "Epoch [3184/20000], Loss: 287.849609375, Entropy -304.1729431152344, Learning Rate: 0.00015625\n",
      "Epoch [3185/20000], Loss: 277.1387939453125, Entropy -292.15020751953125, Learning Rate: 0.00015625\n",
      "Epoch [3186/20000], Loss: 292.58599853515625, Entropy -310.76263427734375, Learning Rate: 0.00015625\n",
      "Epoch [3187/20000], Loss: 279.3823547363281, Entropy -293.7491149902344, Learning Rate: 0.00015625\n",
      "Epoch [3188/20000], Loss: 285.2190856933594, Entropy -301.3214416503906, Learning Rate: 0.00015625\n",
      "Epoch [3189/20000], Loss: 294.74560546875, Entropy -311.1119384765625, Learning Rate: 0.00015625\n",
      "Epoch [3190/20000], Loss: 288.5462646484375, Entropy -304.901123046875, Learning Rate: 0.00015625\n",
      "Epoch [3191/20000], Loss: 281.4570617675781, Entropy -299.7046203613281, Learning Rate: 0.00015625\n",
      "Epoch [3192/20000], Loss: 266.632080078125, Entropy -280.36407470703125, Learning Rate: 0.00015625\n",
      "Epoch [3193/20000], Loss: 309.1126708984375, Entropy -325.86090087890625, Learning Rate: 0.00015625\n",
      "Epoch [3194/20000], Loss: 267.9431457519531, Entropy -293.91070556640625, Learning Rate: 0.00015625\n",
      "Epoch [3195/20000], Loss: 287.9721374511719, Entropy -308.6890563964844, Learning Rate: 0.00015625\n",
      "Epoch [3196/20000], Loss: 276.6175842285156, Entropy -299.5544738769531, Learning Rate: 0.00015625\n",
      "Epoch [3197/20000], Loss: 298.4818115234375, Entropy -320.5494079589844, Learning Rate: 0.00015625\n",
      "Epoch [3198/20000], Loss: 275.56317138671875, Entropy -288.7485656738281, Learning Rate: 0.00015625\n",
      "Epoch [3199/20000], Loss: 275.16357421875, Entropy -291.0271301269531, Learning Rate: 0.00015625\n",
      "Epoch [3200/20000], Loss: 288.02166748046875, Entropy -305.4037170410156, Learning Rate: 0.00015625\n",
      "Epoch [3201/20000], Loss: 290.5915222167969, Entropy -301.4974365234375, Learning Rate: 0.00015625\n",
      "Epoch [3202/20000], Loss: 289.82977294921875, Entropy -300.02484130859375, Learning Rate: 0.00015625\n",
      "Epoch [3203/20000], Loss: 288.9140319824219, Entropy -308.92950439453125, Learning Rate: 0.00015625\n",
      "Epoch [3204/20000], Loss: 296.1212158203125, Entropy -315.511474609375, Learning Rate: 0.00015625\n",
      "Epoch [3205/20000], Loss: 280.8411865234375, Entropy -293.9795227050781, Learning Rate: 0.00015625\n",
      "Epoch [3206/20000], Loss: 289.4166259765625, Entropy -305.7033996582031, Learning Rate: 0.00015625\n",
      "Epoch [3207/20000], Loss: 279.6658935546875, Entropy -291.9939270019531, Learning Rate: 0.00015625\n",
      "Epoch [3208/20000], Loss: 312.38226318359375, Entropy -328.7804260253906, Learning Rate: 0.00015625\n",
      "Epoch [3209/20000], Loss: 283.8544006347656, Entropy -303.26568603515625, Learning Rate: 0.00015625\n",
      "Epoch [3210/20000], Loss: 287.4854736328125, Entropy -304.6007080078125, Learning Rate: 0.00015625\n",
      "Epoch [3211/20000], Loss: 271.265625, Entropy -291.7930603027344, Learning Rate: 0.00015625\n",
      "Epoch [3212/20000], Loss: 289.0693054199219, Entropy -305.2564697265625, Learning Rate: 0.00015625\n",
      "Epoch [3213/20000], Loss: 296.16796875, Entropy -311.0086364746094, Learning Rate: 0.00015625\n",
      "Epoch [3214/20000], Loss: 294.1123962402344, Entropy -314.6740417480469, Learning Rate: 0.00015625\n",
      "Epoch [3215/20000], Loss: 281.4670104980469, Entropy -291.9185791015625, Learning Rate: 0.00015625\n",
      "Epoch [3216/20000], Loss: 291.6056823730469, Entropy -307.7300720214844, Learning Rate: 0.00015625\n",
      "Epoch [3217/20000], Loss: 291.1280822753906, Entropy -310.8870849609375, Learning Rate: 0.00015625\n",
      "Epoch [3218/20000], Loss: 276.48370361328125, Entropy -295.4483337402344, Learning Rate: 0.00015625\n",
      "Epoch [3219/20000], Loss: 291.1452941894531, Entropy -304.52984619140625, Learning Rate: 0.00015625\n",
      "Epoch [3220/20000], Loss: 296.45135498046875, Entropy -315.8021545410156, Learning Rate: 0.00015625\n",
      "Epoch [3221/20000], Loss: 280.52545166015625, Entropy -298.1567687988281, Learning Rate: 0.00015625\n",
      "Epoch [3222/20000], Loss: 280.85675048828125, Entropy -298.69903564453125, Learning Rate: 0.00015625\n",
      "Epoch [3223/20000], Loss: 292.89080810546875, Entropy -312.8798522949219, Learning Rate: 0.00015625\n",
      "Epoch [3224/20000], Loss: 281.7923583984375, Entropy -299.3056335449219, Learning Rate: 0.00015625\n",
      "Epoch [3225/20000], Loss: 291.0990295410156, Entropy -314.51983642578125, Learning Rate: 0.00015625\n",
      "Epoch [3226/20000], Loss: 288.19195556640625, Entropy -307.3935241699219, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3227/20000], Loss: 299.09136962890625, Entropy -320.22833251953125, Learning Rate: 0.00015625\n",
      "Epoch [3228/20000], Loss: 279.0692138671875, Entropy -297.6261901855469, Learning Rate: 0.00015625\n",
      "Epoch [3229/20000], Loss: 286.6021728515625, Entropy -299.9089050292969, Learning Rate: 0.00015625\n",
      "Epoch [3230/20000], Loss: 289.3576965332031, Entropy -312.6119079589844, Learning Rate: 0.00015625\n",
      "Epoch [3231/20000], Loss: 291.5277099609375, Entropy -308.2462463378906, Learning Rate: 0.00015625\n",
      "Epoch [3232/20000], Loss: 275.674072265625, Entropy -300.33966064453125, Learning Rate: 0.00015625\n",
      "Epoch [3233/20000], Loss: 287.5689697265625, Entropy -306.3456726074219, Learning Rate: 0.00015625\n",
      "Epoch [3234/20000], Loss: 280.02294921875, Entropy -293.9416198730469, Learning Rate: 0.00015625\n",
      "Epoch [3235/20000], Loss: 286.49664306640625, Entropy -302.4929504394531, Learning Rate: 0.00015625\n",
      "Epoch [3236/20000], Loss: 283.7384033203125, Entropy -295.9087219238281, Learning Rate: 0.00015625\n",
      "Epoch [3237/20000], Loss: 288.200927734375, Entropy -305.81536865234375, Learning Rate: 0.00015625\n",
      "Epoch [3238/20000], Loss: 287.8814697265625, Entropy -307.253173828125, Learning Rate: 0.00015625\n",
      "Epoch [3239/20000], Loss: 285.33978271484375, Entropy -302.1378479003906, Learning Rate: 0.00015625\n",
      "Epoch [3240/20000], Loss: 273.42218017578125, Entropy -287.3804016113281, Learning Rate: 0.00015625\n",
      "Epoch [3241/20000], Loss: 296.7902526855469, Entropy -318.6432189941406, Learning Rate: 0.00015625\n",
      "Epoch [3242/20000], Loss: 291.283203125, Entropy -302.7044982910156, Learning Rate: 0.00015625\n",
      "Epoch [3243/20000], Loss: 274.8490295410156, Entropy -298.73724365234375, Learning Rate: 0.00015625\n",
      "Epoch [3244/20000], Loss: 271.4504699707031, Entropy -288.89569091796875, Learning Rate: 0.00015625\n",
      "Epoch [3245/20000], Loss: 285.4148864746094, Entropy -304.1007385253906, Learning Rate: 0.00015625\n",
      "Epoch [3246/20000], Loss: 300.5124816894531, Entropy -321.5496520996094, Learning Rate: 0.00015625\n",
      "Epoch [3247/20000], Loss: 280.40277099609375, Entropy -298.5165710449219, Learning Rate: 0.00015625\n",
      "Epoch [3248/20000], Loss: 297.62713623046875, Entropy -320.4969482421875, Learning Rate: 0.00015625\n",
      "Epoch [3249/20000], Loss: 291.223876953125, Entropy -314.0319519042969, Learning Rate: 0.00015625\n",
      "Epoch [3250/20000], Loss: 268.5476379394531, Entropy -287.0775451660156, Learning Rate: 0.00015625\n",
      "Epoch [3251/20000], Loss: 284.9918212890625, Entropy -297.2284851074219, Learning Rate: 0.00015625\n",
      "Epoch [3252/20000], Loss: 281.01666259765625, Entropy -298.9851989746094, Learning Rate: 0.00015625\n",
      "Epoch [3253/20000], Loss: 280.1951599121094, Entropy -297.1659851074219, Learning Rate: 0.00015625\n",
      "Epoch [3254/20000], Loss: 281.432861328125, Entropy -299.170166015625, Learning Rate: 0.00015625\n",
      "Epoch [3255/20000], Loss: 274.5458984375, Entropy -293.5729064941406, Learning Rate: 0.00015625\n",
      "Epoch [3256/20000], Loss: 283.50543212890625, Entropy -296.10198974609375, Learning Rate: 0.00015625\n",
      "Epoch [3257/20000], Loss: 287.70068359375, Entropy -299.6826171875, Learning Rate: 7.8125e-05\n",
      "Epoch [3258/20000], Loss: 273.3699951171875, Entropy -291.23828125, Learning Rate: 7.8125e-05\n",
      "Epoch [3259/20000], Loss: 274.5723876953125, Entropy -299.47454833984375, Learning Rate: 7.8125e-05\n",
      "Epoch [3260/20000], Loss: 288.7786865234375, Entropy -307.6441955566406, Learning Rate: 7.8125e-05\n",
      "Epoch [3261/20000], Loss: 287.3114318847656, Entropy -304.3763122558594, Learning Rate: 7.8125e-05\n",
      "Epoch [3262/20000], Loss: 288.2133483886719, Entropy -305.4284973144531, Learning Rate: 7.8125e-05\n",
      "Epoch [3263/20000], Loss: 277.8438415527344, Entropy -297.0729064941406, Learning Rate: 7.8125e-05\n",
      "Epoch [3264/20000], Loss: 292.83892822265625, Entropy -307.0318603515625, Learning Rate: 7.8125e-05\n",
      "Epoch [3265/20000], Loss: 286.8204345703125, Entropy -300.94854736328125, Learning Rate: 7.8125e-05\n",
      "Epoch [3266/20000], Loss: 297.08953857421875, Entropy -312.3367614746094, Learning Rate: 7.8125e-05\n",
      "Epoch [3267/20000], Loss: 287.66790771484375, Entropy -304.2052307128906, Learning Rate: 7.8125e-05\n",
      "Epoch [3268/20000], Loss: 283.0079345703125, Entropy -307.0950927734375, Learning Rate: 7.8125e-05\n",
      "Epoch [3269/20000], Loss: 294.7193603515625, Entropy -308.3148193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3270/20000], Loss: 299.34332275390625, Entropy -309.8542175292969, Learning Rate: 7.8125e-05\n",
      "Epoch [3271/20000], Loss: 293.82452392578125, Entropy -312.41912841796875, Learning Rate: 7.8125e-05\n",
      "Epoch [3272/20000], Loss: 306.85552978515625, Entropy -321.0492248535156, Learning Rate: 7.8125e-05\n",
      "Epoch [3273/20000], Loss: 272.1103210449219, Entropy -289.2089538574219, Learning Rate: 7.8125e-05\n",
      "Epoch [3274/20000], Loss: 285.6627197265625, Entropy -303.3979187011719, Learning Rate: 7.8125e-05\n",
      "Epoch [3275/20000], Loss: 281.7002258300781, Entropy -300.2891845703125, Learning Rate: 7.8125e-05\n",
      "Epoch [3276/20000], Loss: 303.08050537109375, Entropy -314.1533203125, Learning Rate: 7.8125e-05\n",
      "Epoch [3277/20000], Loss: 282.62542724609375, Entropy -300.8647155761719, Learning Rate: 7.8125e-05\n",
      "Epoch [3278/20000], Loss: 285.311279296875, Entropy -304.2059326171875, Learning Rate: 7.8125e-05\n",
      "Epoch [3279/20000], Loss: 292.6118469238281, Entropy -312.7679748535156, Learning Rate: 7.8125e-05\n",
      "Epoch [3280/20000], Loss: 284.6927490234375, Entropy -303.44476318359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3281/20000], Loss: 281.9384765625, Entropy -306.83514404296875, Learning Rate: 7.8125e-05\n",
      "Epoch [3282/20000], Loss: 284.232177734375, Entropy -300.0058288574219, Learning Rate: 7.8125e-05\n",
      "Epoch [3283/20000], Loss: 293.6199645996094, Entropy -300.9403381347656, Learning Rate: 7.8125e-05\n",
      "Epoch [3284/20000], Loss: 289.87213134765625, Entropy -312.33245849609375, Learning Rate: 7.8125e-05\n",
      "Epoch [3285/20000], Loss: 276.7063903808594, Entropy -291.9361267089844, Learning Rate: 7.8125e-05\n",
      "Epoch [3286/20000], Loss: 288.4554443359375, Entropy -309.673583984375, Learning Rate: 7.8125e-05\n",
      "Epoch [3287/20000], Loss: 292.80328369140625, Entropy -309.2316589355469, Learning Rate: 7.8125e-05\n",
      "Epoch [3288/20000], Loss: 284.11376953125, Entropy -304.3428649902344, Learning Rate: 7.8125e-05\n",
      "Epoch [3289/20000], Loss: 282.1557312011719, Entropy -307.9331970214844, Learning Rate: 7.8125e-05\n",
      "Epoch [3290/20000], Loss: 307.39434814453125, Entropy -331.94921875, Learning Rate: 7.8125e-05\n",
      "Epoch [3291/20000], Loss: 293.3360595703125, Entropy -314.5211181640625, Learning Rate: 7.8125e-05\n",
      "Epoch [3292/20000], Loss: 284.5110168457031, Entropy -299.01043701171875, Learning Rate: 7.8125e-05\n",
      "Epoch [3293/20000], Loss: 293.2272644042969, Entropy -317.7545471191406, Learning Rate: 7.8125e-05\n",
      "Epoch [3294/20000], Loss: 276.5219421386719, Entropy -291.9911804199219, Learning Rate: 7.8125e-05\n",
      "Epoch [3295/20000], Loss: 299.4457092285156, Entropy -318.63385009765625, Learning Rate: 7.8125e-05\n",
      "Epoch [3296/20000], Loss: 279.28265380859375, Entropy -295.78839111328125, Learning Rate: 7.8125e-05\n",
      "Epoch [3297/20000], Loss: 280.95654296875, Entropy -295.8008117675781, Learning Rate: 7.8125e-05\n",
      "Epoch [3298/20000], Loss: 274.82342529296875, Entropy -294.04278564453125, Learning Rate: 7.8125e-05\n",
      "Epoch [3299/20000], Loss: 269.91168212890625, Entropy -291.98614501953125, Learning Rate: 7.8125e-05\n",
      "Epoch [3300/20000], Loss: 283.6810607910156, Entropy -304.342041015625, Learning Rate: 7.8125e-05\n",
      "Epoch [3301/20000], Loss: 290.07086181640625, Entropy -301.8087158203125, Learning Rate: 7.8125e-05\n",
      "Epoch [3302/20000], Loss: 283.4486389160156, Entropy -298.59759521484375, Learning Rate: 7.8125e-05\n",
      "Epoch [3303/20000], Loss: 283.1850280761719, Entropy -294.4335632324219, Learning Rate: 7.8125e-05\n",
      "Epoch [3304/20000], Loss: 272.6773681640625, Entropy -289.8699035644531, Learning Rate: 7.8125e-05\n",
      "Epoch [3305/20000], Loss: 292.2031555175781, Entropy -306.09259033203125, Learning Rate: 7.8125e-05\n",
      "Epoch [3306/20000], Loss: 283.2594909667969, Entropy -301.3664855957031, Learning Rate: 7.8125e-05\n",
      "Epoch [3307/20000], Loss: 296.3814697265625, Entropy -318.9677734375, Learning Rate: 7.8125e-05\n",
      "Epoch [3308/20000], Loss: 293.0009460449219, Entropy -315.1149597167969, Learning Rate: 7.8125e-05\n",
      "Epoch [3309/20000], Loss: 273.5823974609375, Entropy -294.81256103515625, Learning Rate: 7.8125e-05\n",
      "Epoch [3310/20000], Loss: 298.5128479003906, Entropy -316.4570007324219, Learning Rate: 7.8125e-05\n",
      "Epoch [3311/20000], Loss: 283.76226806640625, Entropy -298.80145263671875, Learning Rate: 7.8125e-05\n",
      "Epoch [3312/20000], Loss: 276.9375, Entropy -304.4723205566406, Learning Rate: 7.8125e-05\n",
      "Epoch [3313/20000], Loss: 296.95562744140625, Entropy -306.36981201171875, Learning Rate: 7.8125e-05\n",
      "Epoch [3314/20000], Loss: 293.1253662109375, Entropy -312.9273986816406, Learning Rate: 7.8125e-05\n",
      "Epoch [3315/20000], Loss: 292.3883056640625, Entropy -317.82763671875, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3316/20000], Loss: 289.62628173828125, Entropy -304.892822265625, Learning Rate: 7.8125e-05\n",
      "Epoch [3317/20000], Loss: 301.83184814453125, Entropy -313.4599304199219, Learning Rate: 7.8125e-05\n",
      "Epoch [3318/20000], Loss: 274.30438232421875, Entropy -295.0609436035156, Learning Rate: 7.8125e-05\n",
      "Epoch [3319/20000], Loss: 274.8098449707031, Entropy -294.40338134765625, Learning Rate: 7.8125e-05\n",
      "Epoch [3320/20000], Loss: 281.36444091796875, Entropy -301.9347229003906, Learning Rate: 7.8125e-05\n",
      "Epoch [3321/20000], Loss: 291.7420654296875, Entropy -296.1798095703125, Learning Rate: 7.8125e-05\n",
      "Epoch [3322/20000], Loss: 300.67913818359375, Entropy -311.5897521972656, Learning Rate: 7.8125e-05\n",
      "Epoch [3323/20000], Loss: 290.06689453125, Entropy -307.9655456542969, Learning Rate: 7.8125e-05\n",
      "Epoch [3324/20000], Loss: 292.2454528808594, Entropy -309.654296875, Learning Rate: 7.8125e-05\n",
      "Epoch [3325/20000], Loss: 290.64849853515625, Entropy -311.64398193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3326/20000], Loss: 281.0033264160156, Entropy -295.588623046875, Learning Rate: 7.8125e-05\n",
      "Epoch [3327/20000], Loss: 309.1229553222656, Entropy -318.0984191894531, Learning Rate: 7.8125e-05\n",
      "Epoch [3328/20000], Loss: 284.984375, Entropy -296.53515625, Learning Rate: 7.8125e-05\n",
      "Epoch [3329/20000], Loss: 273.4255065917969, Entropy -286.0865173339844, Learning Rate: 7.8125e-05\n",
      "Epoch [3330/20000], Loss: 286.47894287109375, Entropy -311.9865417480469, Learning Rate: 7.8125e-05\n",
      "Epoch [3331/20000], Loss: 294.43145751953125, Entropy -311.0946350097656, Learning Rate: 7.8125e-05\n",
      "Epoch [3332/20000], Loss: 281.1716613769531, Entropy -301.57037353515625, Learning Rate: 7.8125e-05\n",
      "Epoch [3333/20000], Loss: 281.87762451171875, Entropy -300.8692626953125, Learning Rate: 7.8125e-05\n",
      "Epoch [3334/20000], Loss: 288.36602783203125, Entropy -304.502685546875, Learning Rate: 7.8125e-05\n",
      "Epoch [3335/20000], Loss: 283.950927734375, Entropy -294.5390625, Learning Rate: 7.8125e-05\n",
      "Epoch [3336/20000], Loss: 282.7989196777344, Entropy -300.3396301269531, Learning Rate: 7.8125e-05\n",
      "Epoch [3337/20000], Loss: 285.4844665527344, Entropy -298.5029602050781, Learning Rate: 7.8125e-05\n",
      "Epoch [3338/20000], Loss: 270.40716552734375, Entropy -290.81634521484375, Learning Rate: 7.8125e-05\n",
      "Epoch [3339/20000], Loss: 296.822265625, Entropy -312.0436706542969, Learning Rate: 7.8125e-05\n",
      "Epoch [3340/20000], Loss: 270.40313720703125, Entropy -290.7867431640625, Learning Rate: 7.8125e-05\n",
      "Epoch [3341/20000], Loss: 290.8718566894531, Entropy -307.08203125, Learning Rate: 7.8125e-05\n",
      "Epoch [3342/20000], Loss: 306.07666015625, Entropy -323.24786376953125, Learning Rate: 7.8125e-05\n",
      "Epoch [3343/20000], Loss: 282.02777099609375, Entropy -296.92547607421875, Learning Rate: 7.8125e-05\n",
      "Epoch [3344/20000], Loss: 286.3980407714844, Entropy -297.9781188964844, Learning Rate: 7.8125e-05\n",
      "Epoch [3345/20000], Loss: 274.2002258300781, Entropy -298.2980041503906, Learning Rate: 7.8125e-05\n",
      "Epoch [3346/20000], Loss: 287.91583251953125, Entropy -306.6708984375, Learning Rate: 7.8125e-05\n",
      "Epoch [3347/20000], Loss: 278.461669921875, Entropy -294.2946472167969, Learning Rate: 7.8125e-05\n",
      "Epoch [3348/20000], Loss: 292.3230895996094, Entropy -308.5000915527344, Learning Rate: 7.8125e-05\n",
      "Epoch [3349/20000], Loss: 268.12152099609375, Entropy -286.8148193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3350/20000], Loss: 280.02581787109375, Entropy -290.2586364746094, Learning Rate: 7.8125e-05\n",
      "Epoch [3351/20000], Loss: 278.3811950683594, Entropy -296.6000061035156, Learning Rate: 7.8125e-05\n",
      "Epoch [3352/20000], Loss: 282.182373046875, Entropy -302.63836669921875, Learning Rate: 7.8125e-05\n",
      "Epoch [3353/20000], Loss: 272.9314880371094, Entropy -293.45892333984375, Learning Rate: 7.8125e-05\n",
      "Epoch [3354/20000], Loss: 278.7613525390625, Entropy -297.7825927734375, Learning Rate: 7.8125e-05\n",
      "Epoch [3355/20000], Loss: 286.2377624511719, Entropy -306.754638671875, Learning Rate: 7.8125e-05\n",
      "Epoch [3356/20000], Loss: 288.00091552734375, Entropy -305.83251953125, Learning Rate: 7.8125e-05\n",
      "Epoch [3357/20000], Loss: 290.02728271484375, Entropy -302.2355041503906, Learning Rate: 7.8125e-05\n",
      "Epoch [3358/20000], Loss: 280.5417785644531, Entropy -300.1324768066406, Learning Rate: 7.8125e-05\n",
      "Epoch [3359/20000], Loss: 287.3818054199219, Entropy -308.3853454589844, Learning Rate: 7.8125e-05\n",
      "Epoch [3360/20000], Loss: 279.1551208496094, Entropy -291.3980712890625, Learning Rate: 7.8125e-05\n",
      "Epoch [3361/20000], Loss: 294.40240478515625, Entropy -311.74261474609375, Learning Rate: 7.8125e-05\n",
      "Epoch [3362/20000], Loss: 283.9886474609375, Entropy -309.59613037109375, Learning Rate: 7.8125e-05\n",
      "Epoch [3363/20000], Loss: 280.8133239746094, Entropy -297.2875061035156, Learning Rate: 7.8125e-05\n",
      "Epoch [3364/20000], Loss: 285.6097412109375, Entropy -300.2140197753906, Learning Rate: 7.8125e-05\n",
      "Epoch [3365/20000], Loss: 294.53948974609375, Entropy -313.51605224609375, Learning Rate: 7.8125e-05\n",
      "Epoch [3366/20000], Loss: 295.03326416015625, Entropy -312.0530090332031, Learning Rate: 7.8125e-05\n",
      "Epoch [3367/20000], Loss: 290.19415283203125, Entropy -300.9880676269531, Learning Rate: 7.8125e-05\n",
      "Epoch [3368/20000], Loss: 288.5353088378906, Entropy -305.9627685546875, Learning Rate: 7.8125e-05\n",
      "Epoch [3369/20000], Loss: 279.29803466796875, Entropy -296.9788818359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3370/20000], Loss: 280.2785339355469, Entropy -298.94757080078125, Learning Rate: 7.8125e-05\n",
      "Epoch [3371/20000], Loss: 311.26812744140625, Entropy -332.4253845214844, Learning Rate: 7.8125e-05\n",
      "Epoch [3372/20000], Loss: 305.74224853515625, Entropy -325.9391784667969, Learning Rate: 7.8125e-05\n",
      "Epoch [3373/20000], Loss: 303.3099060058594, Entropy -319.0984191894531, Learning Rate: 7.8125e-05\n",
      "Epoch [3374/20000], Loss: 278.2642822265625, Entropy -295.4361267089844, Learning Rate: 7.8125e-05\n",
      "Epoch [3375/20000], Loss: 284.0362243652344, Entropy -298.1854248046875, Learning Rate: 7.8125e-05\n",
      "Epoch [3376/20000], Loss: 273.4443054199219, Entropy -297.76727294921875, Learning Rate: 7.8125e-05\n",
      "Epoch [3377/20000], Loss: 282.31854248046875, Entropy -294.3776550292969, Learning Rate: 7.8125e-05\n",
      "Epoch [3378/20000], Loss: 291.5865783691406, Entropy -310.3351745605469, Learning Rate: 7.8125e-05\n",
      "Epoch [3379/20000], Loss: 273.3336181640625, Entropy -292.5869140625, Learning Rate: 7.8125e-05\n",
      "Epoch [3380/20000], Loss: 274.1185302734375, Entropy -298.5585021972656, Learning Rate: 7.8125e-05\n",
      "Epoch [3381/20000], Loss: 284.4583740234375, Entropy -298.5740966796875, Learning Rate: 7.8125e-05\n",
      "Epoch [3382/20000], Loss: 287.5050354003906, Entropy -304.926025390625, Learning Rate: 7.8125e-05\n",
      "Epoch [3383/20000], Loss: 293.1016540527344, Entropy -316.2486267089844, Learning Rate: 7.8125e-05\n",
      "Epoch [3384/20000], Loss: 277.5352783203125, Entropy -294.7970886230469, Learning Rate: 7.8125e-05\n",
      "Epoch [3385/20000], Loss: 279.8126220703125, Entropy -298.4766540527344, Learning Rate: 7.8125e-05\n",
      "Epoch [3386/20000], Loss: 294.32330322265625, Entropy -310.4032897949219, Learning Rate: 7.8125e-05\n",
      "Epoch [3387/20000], Loss: 287.0218505859375, Entropy -305.144287109375, Learning Rate: 7.8125e-05\n",
      "Epoch [3388/20000], Loss: 286.328369140625, Entropy -306.2455139160156, Learning Rate: 7.8125e-05\n",
      "Epoch [3389/20000], Loss: 272.61370849609375, Entropy -292.9115295410156, Learning Rate: 7.8125e-05\n",
      "Epoch [3390/20000], Loss: 279.218505859375, Entropy -302.3690185546875, Learning Rate: 7.8125e-05\n",
      "Epoch [3391/20000], Loss: 279.200439453125, Entropy -303.2831115722656, Learning Rate: 7.8125e-05\n",
      "Epoch [3392/20000], Loss: 269.84405517578125, Entropy -281.97515869140625, Learning Rate: 7.8125e-05\n",
      "Epoch [3393/20000], Loss: 301.41082763671875, Entropy -318.4369201660156, Learning Rate: 7.8125e-05\n",
      "Epoch [3394/20000], Loss: 298.10101318359375, Entropy -307.5047607421875, Learning Rate: 7.8125e-05\n",
      "Epoch [3395/20000], Loss: 276.0889587402344, Entropy -293.2683410644531, Learning Rate: 7.8125e-05\n",
      "Epoch [3396/20000], Loss: 280.87176513671875, Entropy -306.1747131347656, Learning Rate: 7.8125e-05\n",
      "Epoch [3397/20000], Loss: 287.7825927734375, Entropy -309.5637512207031, Learning Rate: 7.8125e-05\n",
      "Epoch [3398/20000], Loss: 284.1739807128906, Entropy -304.6424255371094, Learning Rate: 7.8125e-05\n",
      "Epoch [3399/20000], Loss: 300.92547607421875, Entropy -314.8741760253906, Learning Rate: 7.8125e-05\n",
      "Epoch [3400/20000], Loss: 293.596435546875, Entropy -312.9441223144531, Learning Rate: 7.8125e-05\n",
      "Epoch [3401/20000], Loss: 290.5724792480469, Entropy -305.75732421875, Learning Rate: 7.8125e-05\n",
      "Epoch [3402/20000], Loss: 284.4185791015625, Entropy -300.6761779785156, Learning Rate: 7.8125e-05\n",
      "Epoch [3403/20000], Loss: 272.22882080078125, Entropy -292.75897216796875, Learning Rate: 7.8125e-05\n",
      "Epoch [3404/20000], Loss: 285.39923095703125, Entropy -299.154052734375, Learning Rate: 7.8125e-05\n",
      "Epoch [3405/20000], Loss: 289.5525817871094, Entropy -303.3434143066406, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3406/20000], Loss: 285.15570068359375, Entropy -301.38385009765625, Learning Rate: 7.8125e-05\n",
      "Epoch [3407/20000], Loss: 297.167724609375, Entropy -323.0108642578125, Learning Rate: 7.8125e-05\n",
      "Epoch [3408/20000], Loss: 289.82891845703125, Entropy -300.090087890625, Learning Rate: 7.8125e-05\n",
      "Epoch [3409/20000], Loss: 273.39678955078125, Entropy -294.6669921875, Learning Rate: 7.8125e-05\n",
      "Epoch [3410/20000], Loss: 296.09625244140625, Entropy -319.47845458984375, Learning Rate: 7.8125e-05\n",
      "Epoch [3411/20000], Loss: 288.87200927734375, Entropy -306.6466369628906, Learning Rate: 7.8125e-05\n",
      "Epoch [3412/20000], Loss: 291.3848876953125, Entropy -310.6557922363281, Learning Rate: 7.8125e-05\n",
      "Epoch [3413/20000], Loss: 273.0513916015625, Entropy -296.9213562011719, Learning Rate: 7.8125e-05\n",
      "Epoch [3414/20000], Loss: 305.8426208496094, Entropy -317.1820068359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3415/20000], Loss: 281.997314453125, Entropy -299.74554443359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3416/20000], Loss: 280.93536376953125, Entropy -300.43719482421875, Learning Rate: 7.8125e-05\n",
      "Epoch [3417/20000], Loss: 272.20013427734375, Entropy -289.2566223144531, Learning Rate: 7.8125e-05\n",
      "Epoch [3418/20000], Loss: 290.34539794921875, Entropy -306.1634521484375, Learning Rate: 7.8125e-05\n",
      "Epoch [3419/20000], Loss: 291.0328063964844, Entropy -300.2073974609375, Learning Rate: 7.8125e-05\n",
      "Epoch [3420/20000], Loss: 294.99676513671875, Entropy -319.57464599609375, Learning Rate: 7.8125e-05\n",
      "Epoch [3421/20000], Loss: 307.676025390625, Entropy -317.8873291015625, Learning Rate: 7.8125e-05\n",
      "Epoch [3422/20000], Loss: 277.806884765625, Entropy -293.0670166015625, Learning Rate: 7.8125e-05\n",
      "Epoch [3423/20000], Loss: 274.912353515625, Entropy -297.19366455078125, Learning Rate: 7.8125e-05\n",
      "Epoch [3424/20000], Loss: 294.010009765625, Entropy -304.7065124511719, Learning Rate: 7.8125e-05\n",
      "Epoch [3425/20000], Loss: 273.06439208984375, Entropy -294.1065673828125, Learning Rate: 7.8125e-05\n",
      "Epoch [3426/20000], Loss: 290.82733154296875, Entropy -315.03082275390625, Learning Rate: 7.8125e-05\n",
      "Epoch [3427/20000], Loss: 285.32861328125, Entropy -300.2024841308594, Learning Rate: 7.8125e-05\n",
      "Epoch [3428/20000], Loss: 284.95135498046875, Entropy -297.5315246582031, Learning Rate: 7.8125e-05\n",
      "Epoch [3429/20000], Loss: 281.82781982421875, Entropy -298.1526794433594, Learning Rate: 7.8125e-05\n",
      "Epoch [3430/20000], Loss: 299.5475769042969, Entropy -318.67718505859375, Learning Rate: 7.8125e-05\n",
      "Epoch [3431/20000], Loss: 288.3195495605469, Entropy -299.8695983886719, Learning Rate: 7.8125e-05\n",
      "Epoch [3432/20000], Loss: 293.5032958984375, Entropy -314.82611083984375, Learning Rate: 7.8125e-05\n",
      "Epoch [3433/20000], Loss: 294.3341369628906, Entropy -313.796142578125, Learning Rate: 7.8125e-05\n",
      "Epoch [3434/20000], Loss: 302.3551940917969, Entropy -311.2900390625, Learning Rate: 7.8125e-05\n",
      "Epoch [3435/20000], Loss: 283.832275390625, Entropy -302.4231262207031, Learning Rate: 7.8125e-05\n",
      "Epoch [3436/20000], Loss: 284.11517333984375, Entropy -300.1302185058594, Learning Rate: 7.8125e-05\n",
      "Epoch [3437/20000], Loss: 279.75103759765625, Entropy -295.865966796875, Learning Rate: 7.8125e-05\n",
      "Epoch [3438/20000], Loss: 288.88397216796875, Entropy -302.9374694824219, Learning Rate: 7.8125e-05\n",
      "Epoch [3439/20000], Loss: 294.95001220703125, Entropy -310.818359375, Learning Rate: 7.8125e-05\n",
      "Epoch [3440/20000], Loss: 291.4486999511719, Entropy -311.54193115234375, Learning Rate: 7.8125e-05\n",
      "Epoch [3441/20000], Loss: 298.53289794921875, Entropy -308.48260498046875, Learning Rate: 7.8125e-05\n",
      "Epoch [3442/20000], Loss: 278.6261291503906, Entropy -295.1521301269531, Learning Rate: 7.8125e-05\n",
      "Epoch [3443/20000], Loss: 283.87860107421875, Entropy -294.2987365722656, Learning Rate: 7.8125e-05\n",
      "Epoch [3444/20000], Loss: 291.005859375, Entropy -309.0951232910156, Learning Rate: 7.8125e-05\n",
      "Epoch [3445/20000], Loss: 286.57232666015625, Entropy -298.2978515625, Learning Rate: 7.8125e-05\n",
      "Epoch [3446/20000], Loss: 297.0999755859375, Entropy -320.62799072265625, Learning Rate: 7.8125e-05\n",
      "Epoch [3447/20000], Loss: 291.3095703125, Entropy -311.4502258300781, Learning Rate: 7.8125e-05\n",
      "Epoch [3448/20000], Loss: 293.2113342285156, Entropy -311.5625, Learning Rate: 7.8125e-05\n",
      "Epoch [3449/20000], Loss: 290.40216064453125, Entropy -304.0546875, Learning Rate: 7.8125e-05\n",
      "Epoch [3450/20000], Loss: 274.13140869140625, Entropy -287.124755859375, Learning Rate: 7.8125e-05\n",
      "Epoch [3451/20000], Loss: 296.57366943359375, Entropy -308.14410400390625, Learning Rate: 7.8125e-05\n",
      "Epoch [3452/20000], Loss: 281.12176513671875, Entropy -294.39520263671875, Learning Rate: 7.8125e-05\n",
      "Epoch [3453/20000], Loss: 285.9803466796875, Entropy -304.6219482421875, Learning Rate: 7.8125e-05\n",
      "Epoch [3454/20000], Loss: 285.9224853515625, Entropy -299.946533203125, Learning Rate: 7.8125e-05\n",
      "Epoch [3455/20000], Loss: 300.0819091796875, Entropy -317.254150390625, Learning Rate: 7.8125e-05\n",
      "Epoch [3456/20000], Loss: 279.68096923828125, Entropy -302.2558898925781, Learning Rate: 7.8125e-05\n",
      "Epoch [3457/20000], Loss: 278.7131652832031, Entropy -296.891357421875, Learning Rate: 7.8125e-05\n",
      "Epoch [3458/20000], Loss: 282.9065856933594, Entropy -302.4373779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3459/20000], Loss: 291.1592102050781, Entropy -306.51251220703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3460/20000], Loss: 281.0199279785156, Entropy -295.97821044921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3461/20000], Loss: 281.8577575683594, Entropy -294.83892822265625, Learning Rate: 3.90625e-05\n",
      "Epoch [3462/20000], Loss: 285.64093017578125, Entropy -297.7299499511719, Learning Rate: 3.90625e-05\n",
      "Epoch [3463/20000], Loss: 285.44415283203125, Entropy -301.80645751953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3464/20000], Loss: 278.78887939453125, Entropy -298.5381774902344, Learning Rate: 3.90625e-05\n",
      "Epoch [3465/20000], Loss: 293.6680603027344, Entropy -312.6166076660156, Learning Rate: 3.90625e-05\n",
      "Epoch [3466/20000], Loss: 293.5833435058594, Entropy -312.47607421875, Learning Rate: 3.90625e-05\n",
      "Epoch [3467/20000], Loss: 268.9197692871094, Entropy -286.2531433105469, Learning Rate: 3.90625e-05\n",
      "Epoch [3468/20000], Loss: 281.333251953125, Entropy -290.2688293457031, Learning Rate: 3.90625e-05\n",
      "Epoch [3469/20000], Loss: 276.0218505859375, Entropy -286.697265625, Learning Rate: 3.90625e-05\n",
      "Epoch [3470/20000], Loss: 277.04742431640625, Entropy -293.4411315917969, Learning Rate: 3.90625e-05\n",
      "Epoch [3471/20000], Loss: 294.5399169921875, Entropy -310.0329895019531, Learning Rate: 3.90625e-05\n",
      "Epoch [3472/20000], Loss: 286.2236328125, Entropy -301.11566162109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3473/20000], Loss: 293.1826477050781, Entropy -308.2667541503906, Learning Rate: 3.90625e-05\n",
      "Epoch [3474/20000], Loss: 289.8540344238281, Entropy -305.4263916015625, Learning Rate: 3.90625e-05\n",
      "Epoch [3475/20000], Loss: 309.7052307128906, Entropy -334.2663879394531, Learning Rate: 3.90625e-05\n",
      "Epoch [3476/20000], Loss: 287.70721435546875, Entropy -298.401611328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3477/20000], Loss: 272.66015625, Entropy -294.4493713378906, Learning Rate: 3.90625e-05\n",
      "Epoch [3478/20000], Loss: 290.1520690917969, Entropy -307.2756042480469, Learning Rate: 3.90625e-05\n",
      "Epoch [3479/20000], Loss: 285.06146240234375, Entropy -300.34588623046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3480/20000], Loss: 290.71295166015625, Entropy -303.3401794433594, Learning Rate: 3.90625e-05\n",
      "Epoch [3481/20000], Loss: 292.2132263183594, Entropy -311.5179443359375, Learning Rate: 3.90625e-05\n",
      "Epoch [3482/20000], Loss: 276.4932861328125, Entropy -291.7967224121094, Learning Rate: 3.90625e-05\n",
      "Epoch [3483/20000], Loss: 293.79510498046875, Entropy -313.396240234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3484/20000], Loss: 283.8388671875, Entropy -300.9352111816406, Learning Rate: 3.90625e-05\n",
      "Epoch [3485/20000], Loss: 281.9066467285156, Entropy -301.6104431152344, Learning Rate: 3.90625e-05\n",
      "Epoch [3486/20000], Loss: 276.58251953125, Entropy -298.9213562011719, Learning Rate: 3.90625e-05\n",
      "Epoch [3487/20000], Loss: 295.30657958984375, Entropy -311.0001220703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3488/20000], Loss: 272.24151611328125, Entropy -293.42816162109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3489/20000], Loss: 283.43682861328125, Entropy -309.1777648925781, Learning Rate: 3.90625e-05\n",
      "Epoch [3490/20000], Loss: 287.0794372558594, Entropy -308.7545166015625, Learning Rate: 3.90625e-05\n",
      "Epoch [3491/20000], Loss: 280.9167175292969, Entropy -299.8643798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3492/20000], Loss: 284.79510498046875, Entropy -306.7793884277344, Learning Rate: 3.90625e-05\n",
      "Epoch [3493/20000], Loss: 288.5548095703125, Entropy -302.764404296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3494/20000], Loss: 286.073486328125, Entropy -313.667236328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3495/20000], Loss: 291.755859375, Entropy -312.8227844238281, Learning Rate: 3.90625e-05\n",
      "Epoch [3496/20000], Loss: 291.0323486328125, Entropy -311.37371826171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3497/20000], Loss: 271.2783203125, Entropy -291.58843994140625, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3498/20000], Loss: 280.16485595703125, Entropy -298.72119140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3499/20000], Loss: 298.087890625, Entropy -311.0530090332031, Learning Rate: 3.90625e-05\n",
      "Epoch [3500/20000], Loss: 281.03948974609375, Entropy -295.9320068359375, Learning Rate: 3.90625e-05\n",
      "Epoch [3501/20000], Loss: 269.68121337890625, Entropy -291.1058349609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3502/20000], Loss: 292.03216552734375, Entropy -309.93756103515625, Learning Rate: 3.90625e-05\n",
      "Epoch [3503/20000], Loss: 271.27349853515625, Entropy -287.2779235839844, Learning Rate: 3.90625e-05\n",
      "Epoch [3504/20000], Loss: 263.72186279296875, Entropy -284.9700622558594, Learning Rate: 3.90625e-05\n",
      "Epoch [3505/20000], Loss: 287.546630859375, Entropy -300.067138671875, Learning Rate: 3.90625e-05\n",
      "Epoch [3506/20000], Loss: 299.4027099609375, Entropy -317.24383544921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3507/20000], Loss: 271.54180908203125, Entropy -288.73321533203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3508/20000], Loss: 267.4654541015625, Entropy -290.2333679199219, Learning Rate: 3.90625e-05\n",
      "Epoch [3509/20000], Loss: 294.64300537109375, Entropy -312.5162658691406, Learning Rate: 3.90625e-05\n",
      "Epoch [3510/20000], Loss: 272.70806884765625, Entropy -294.3409118652344, Learning Rate: 3.90625e-05\n",
      "Epoch [3511/20000], Loss: 277.7511901855469, Entropy -290.6666564941406, Learning Rate: 3.90625e-05\n",
      "Epoch [3512/20000], Loss: 288.3738098144531, Entropy -309.9510498046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3513/20000], Loss: 283.47125244140625, Entropy -301.2042236328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3514/20000], Loss: 311.6547546386719, Entropy -319.0035705566406, Learning Rate: 3.90625e-05\n",
      "Epoch [3515/20000], Loss: 273.5428466796875, Entropy -304.2931213378906, Learning Rate: 3.90625e-05\n",
      "Epoch [3516/20000], Loss: 284.7994689941406, Entropy -305.2420959472656, Learning Rate: 3.90625e-05\n",
      "Epoch [3517/20000], Loss: 287.1793212890625, Entropy -303.4307861328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3518/20000], Loss: 290.294921875, Entropy -309.9621887207031, Learning Rate: 3.90625e-05\n",
      "Epoch [3519/20000], Loss: 289.79901123046875, Entropy -300.0555114746094, Learning Rate: 3.90625e-05\n",
      "Epoch [3520/20000], Loss: 287.1882019042969, Entropy -301.806640625, Learning Rate: 3.90625e-05\n",
      "Epoch [3521/20000], Loss: 293.251953125, Entropy -310.841064453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3522/20000], Loss: 278.39410400390625, Entropy -298.5924377441406, Learning Rate: 3.90625e-05\n",
      "Epoch [3523/20000], Loss: 279.8661804199219, Entropy -303.52545166015625, Learning Rate: 3.90625e-05\n",
      "Epoch [3524/20000], Loss: 290.8520812988281, Entropy -314.55242919921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3525/20000], Loss: 274.5950927734375, Entropy -292.9906311035156, Learning Rate: 3.90625e-05\n",
      "Epoch [3526/20000], Loss: 277.78509521484375, Entropy -289.3335876464844, Learning Rate: 3.90625e-05\n",
      "Epoch [3527/20000], Loss: 289.4330139160156, Entropy -307.0994873046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3528/20000], Loss: 290.924072265625, Entropy -309.7240295410156, Learning Rate: 3.90625e-05\n",
      "Epoch [3529/20000], Loss: 285.52838134765625, Entropy -298.13330078125, Learning Rate: 3.90625e-05\n",
      "Epoch [3530/20000], Loss: 304.3699951171875, Entropy -311.1644592285156, Learning Rate: 3.90625e-05\n",
      "Epoch [3531/20000], Loss: 292.79541015625, Entropy -313.25372314453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3532/20000], Loss: 278.94647216796875, Entropy -300.5859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3533/20000], Loss: 293.66778564453125, Entropy -304.4388122558594, Learning Rate: 3.90625e-05\n",
      "Epoch [3534/20000], Loss: 288.50054931640625, Entropy -310.29736328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3535/20000], Loss: 289.8031311035156, Entropy -303.97283935546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3536/20000], Loss: 286.9725341796875, Entropy -304.0150146484375, Learning Rate: 3.90625e-05\n",
      "Epoch [3537/20000], Loss: 285.99169921875, Entropy -297.0665283203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3538/20000], Loss: 277.2355651855469, Entropy -299.14312744140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3539/20000], Loss: 296.165283203125, Entropy -314.1732482910156, Learning Rate: 3.90625e-05\n",
      "Epoch [3540/20000], Loss: 288.70855712890625, Entropy -311.9255065917969, Learning Rate: 3.90625e-05\n",
      "Epoch [3541/20000], Loss: 286.28936767578125, Entropy -299.1732177734375, Learning Rate: 3.90625e-05\n",
      "Epoch [3542/20000], Loss: 279.8873596191406, Entropy -301.14349365234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3543/20000], Loss: 265.62957763671875, Entropy -283.5326843261719, Learning Rate: 3.90625e-05\n",
      "Epoch [3544/20000], Loss: 282.0167236328125, Entropy -306.13470458984375, Learning Rate: 3.90625e-05\n",
      "Epoch [3545/20000], Loss: 288.844970703125, Entropy -297.5965881347656, Learning Rate: 3.90625e-05\n",
      "Epoch [3546/20000], Loss: 306.761962890625, Entropy -311.0545959472656, Learning Rate: 3.90625e-05\n",
      "Epoch [3547/20000], Loss: 282.8900451660156, Entropy -304.0063171386719, Learning Rate: 3.90625e-05\n",
      "Epoch [3548/20000], Loss: 290.8526611328125, Entropy -313.6870422363281, Learning Rate: 3.90625e-05\n",
      "Epoch [3549/20000], Loss: 287.28497314453125, Entropy -302.80108642578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3550/20000], Loss: 288.633544921875, Entropy -312.74114990234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3551/20000], Loss: 285.34527587890625, Entropy -312.9211730957031, Learning Rate: 3.90625e-05\n",
      "Epoch [3552/20000], Loss: 295.5669250488281, Entropy -311.80108642578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3553/20000], Loss: 270.32977294921875, Entropy -292.5307922363281, Learning Rate: 3.90625e-05\n",
      "Epoch [3554/20000], Loss: 290.80889892578125, Entropy -309.4576721191406, Learning Rate: 3.90625e-05\n",
      "Epoch [3555/20000], Loss: 283.8140563964844, Entropy -302.62158203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3556/20000], Loss: 277.1286926269531, Entropy -296.8115234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3557/20000], Loss: 278.9520263671875, Entropy -295.9986267089844, Learning Rate: 3.90625e-05\n",
      "Epoch [3558/20000], Loss: 275.1565246582031, Entropy -291.6247863769531, Learning Rate: 3.90625e-05\n",
      "Epoch [3559/20000], Loss: 288.07794189453125, Entropy -306.86669921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3560/20000], Loss: 270.185302734375, Entropy -290.6824035644531, Learning Rate: 3.90625e-05\n",
      "Epoch [3561/20000], Loss: 277.27020263671875, Entropy -300.06298828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3562/20000], Loss: 298.1914367675781, Entropy -312.3193664550781, Learning Rate: 3.90625e-05\n",
      "Epoch [3563/20000], Loss: 278.85205078125, Entropy -303.3221435546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3564/20000], Loss: 284.2377624511719, Entropy -303.8797607421875, Learning Rate: 3.90625e-05\n",
      "Epoch [3565/20000], Loss: 296.06890869140625, Entropy -312.5384216308594, Learning Rate: 3.90625e-05\n",
      "Epoch [3566/20000], Loss: 274.98016357421875, Entropy -304.795654296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3567/20000], Loss: 274.86761474609375, Entropy -292.2563781738281, Learning Rate: 3.90625e-05\n",
      "Epoch [3568/20000], Loss: 279.57293701171875, Entropy -305.98443603515625, Learning Rate: 3.90625e-05\n",
      "Epoch [3569/20000], Loss: 304.9954528808594, Entropy -321.2877502441406, Learning Rate: 3.90625e-05\n",
      "Epoch [3570/20000], Loss: 275.96923828125, Entropy -290.1566467285156, Learning Rate: 3.90625e-05\n",
      "Epoch [3571/20000], Loss: 287.7707824707031, Entropy -308.1968078613281, Learning Rate: 3.90625e-05\n",
      "Epoch [3572/20000], Loss: 276.2322998046875, Entropy -285.1427917480469, Learning Rate: 3.90625e-05\n",
      "Epoch [3573/20000], Loss: 284.79168701171875, Entropy -302.846435546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3574/20000], Loss: 281.2447204589844, Entropy -301.3089294433594, Learning Rate: 3.90625e-05\n",
      "Epoch [3575/20000], Loss: 279.08984375, Entropy -295.9569396972656, Learning Rate: 3.90625e-05\n",
      "Epoch [3576/20000], Loss: 289.41400146484375, Entropy -307.6266174316406, Learning Rate: 3.90625e-05\n",
      "Epoch [3577/20000], Loss: 292.80938720703125, Entropy -309.60809326171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3578/20000], Loss: 272.4759521484375, Entropy -294.3174133300781, Learning Rate: 3.90625e-05\n",
      "Epoch [3579/20000], Loss: 280.933349609375, Entropy -300.3771057128906, Learning Rate: 3.90625e-05\n",
      "Epoch [3580/20000], Loss: 277.91851806640625, Entropy -294.7572021484375, Learning Rate: 3.90625e-05\n",
      "Epoch [3581/20000], Loss: 289.08056640625, Entropy -311.2800598144531, Learning Rate: 3.90625e-05\n",
      "Epoch [3582/20000], Loss: 287.2080078125, Entropy -308.3086242675781, Learning Rate: 3.90625e-05\n",
      "Epoch [3583/20000], Loss: 263.501708984375, Entropy -284.6567077636719, Learning Rate: 3.90625e-05\n",
      "Epoch [3584/20000], Loss: 268.55023193359375, Entropy -283.9739074707031, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3585/20000], Loss: 283.85693359375, Entropy -308.6624755859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3586/20000], Loss: 283.43719482421875, Entropy -299.8774108886719, Learning Rate: 3.90625e-05\n",
      "Epoch [3587/20000], Loss: 305.46905517578125, Entropy -313.6212158203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3588/20000], Loss: 308.52630615234375, Entropy -318.40789794921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3589/20000], Loss: 280.6488037109375, Entropy -299.69140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3590/20000], Loss: 271.9765930175781, Entropy -291.9421081542969, Learning Rate: 3.90625e-05\n",
      "Epoch [3591/20000], Loss: 294.03070068359375, Entropy -306.4405517578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3592/20000], Loss: 272.46368408203125, Entropy -288.42449951171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3593/20000], Loss: 277.2124328613281, Entropy -294.9698181152344, Learning Rate: 3.90625e-05\n",
      "Epoch [3594/20000], Loss: 295.2935791015625, Entropy -310.1065979003906, Learning Rate: 3.90625e-05\n",
      "Epoch [3595/20000], Loss: 294.8306884765625, Entropy -314.00360107421875, Learning Rate: 3.90625e-05\n",
      "Epoch [3596/20000], Loss: 284.16107177734375, Entropy -306.5873718261719, Learning Rate: 3.90625e-05\n",
      "Epoch [3597/20000], Loss: 299.80377197265625, Entropy -307.4364929199219, Learning Rate: 3.90625e-05\n",
      "Epoch [3598/20000], Loss: 297.87957763671875, Entropy -317.13739013671875, Learning Rate: 3.90625e-05\n",
      "Epoch [3599/20000], Loss: 291.8916015625, Entropy -309.3127136230469, Learning Rate: 3.90625e-05\n",
      "Epoch [3600/20000], Loss: 291.4969177246094, Entropy -313.0732116699219, Learning Rate: 3.90625e-05\n",
      "Epoch [3601/20000], Loss: 277.2481689453125, Entropy -300.8096923828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3602/20000], Loss: 300.6167907714844, Entropy -319.3112487792969, Learning Rate: 3.90625e-05\n",
      "Epoch [3603/20000], Loss: 285.9744873046875, Entropy -301.8439636230469, Learning Rate: 3.90625e-05\n",
      "Epoch [3604/20000], Loss: 282.6875, Entropy -298.8641662597656, Learning Rate: 3.90625e-05\n",
      "Epoch [3605/20000], Loss: 279.8643493652344, Entropy -299.8692321777344, Learning Rate: 3.90625e-05\n",
      "Epoch [3606/20000], Loss: 285.6202087402344, Entropy -303.3973388671875, Learning Rate: 3.90625e-05\n",
      "Epoch [3607/20000], Loss: 292.6518859863281, Entropy -311.2260437011719, Learning Rate: 3.90625e-05\n",
      "Epoch [3608/20000], Loss: 288.80828857421875, Entropy -307.1801452636719, Learning Rate: 3.90625e-05\n",
      "Epoch [3609/20000], Loss: 295.21319580078125, Entropy -310.13153076171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3610/20000], Loss: 283.4589538574219, Entropy -303.02886962890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3611/20000], Loss: 283.985107421875, Entropy -305.8167724609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3612/20000], Loss: 282.36260986328125, Entropy -290.8475646972656, Learning Rate: 3.90625e-05\n",
      "Epoch [3613/20000], Loss: 284.041259765625, Entropy -306.51123046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3614/20000], Loss: 279.2332763671875, Entropy -295.70819091796875, Learning Rate: 3.90625e-05\n",
      "Epoch [3615/20000], Loss: 283.79315185546875, Entropy -295.63427734375, Learning Rate: 3.90625e-05\n",
      "Epoch [3616/20000], Loss: 265.3663330078125, Entropy -284.8240966796875, Learning Rate: 3.90625e-05\n",
      "Epoch [3617/20000], Loss: 286.532958984375, Entropy -304.5484313964844, Learning Rate: 3.90625e-05\n",
      "Epoch [3618/20000], Loss: 288.8856201171875, Entropy -304.33978271484375, Learning Rate: 3.90625e-05\n",
      "Epoch [3619/20000], Loss: 283.0478515625, Entropy -297.058837890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3620/20000], Loss: 287.08746337890625, Entropy -306.1900939941406, Learning Rate: 3.90625e-05\n",
      "Epoch [3621/20000], Loss: 278.42950439453125, Entropy -296.17523193359375, Learning Rate: 3.90625e-05\n",
      "Epoch [3622/20000], Loss: 275.2769775390625, Entropy -297.8642883300781, Learning Rate: 3.90625e-05\n",
      "Epoch [3623/20000], Loss: 279.91949462890625, Entropy -293.4543762207031, Learning Rate: 3.90625e-05\n",
      "Epoch [3624/20000], Loss: 277.25701904296875, Entropy -297.768798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3625/20000], Loss: 287.9644775390625, Entropy -302.87762451171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3626/20000], Loss: 280.68798828125, Entropy -306.453369140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3627/20000], Loss: 283.523681640625, Entropy -300.53692626953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3628/20000], Loss: 278.65997314453125, Entropy -294.2726745605469, Learning Rate: 3.90625e-05\n",
      "Epoch [3629/20000], Loss: 306.544921875, Entropy -321.0592956542969, Learning Rate: 3.90625e-05\n",
      "Epoch [3630/20000], Loss: 285.45428466796875, Entropy -305.72686767578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3631/20000], Loss: 282.04083251953125, Entropy -289.05401611328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3632/20000], Loss: 286.9031677246094, Entropy -305.7535095214844, Learning Rate: 3.90625e-05\n",
      "Epoch [3633/20000], Loss: 280.1165771484375, Entropy -293.4573974609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3634/20000], Loss: 297.724365234375, Entropy -320.99267578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3635/20000], Loss: 289.94696044921875, Entropy -302.3788146972656, Learning Rate: 3.90625e-05\n",
      "Epoch [3636/20000], Loss: 287.25433349609375, Entropy -305.7291564941406, Learning Rate: 3.90625e-05\n",
      "Epoch [3637/20000], Loss: 273.37774658203125, Entropy -292.6805725097656, Learning Rate: 3.90625e-05\n",
      "Epoch [3638/20000], Loss: 292.16302490234375, Entropy -301.5176696777344, Learning Rate: 3.90625e-05\n",
      "Epoch [3639/20000], Loss: 292.5200500488281, Entropy -312.1567077636719, Learning Rate: 3.90625e-05\n",
      "Epoch [3640/20000], Loss: 288.02130126953125, Entropy -305.0943603515625, Learning Rate: 3.90625e-05\n",
      "Epoch [3641/20000], Loss: 307.5540771484375, Entropy -286.3171691894531, Learning Rate: 3.90625e-05\n",
      "Epoch [3642/20000], Loss: 279.098388671875, Entropy -302.23614501953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3643/20000], Loss: 271.3093566894531, Entropy -291.0666198730469, Learning Rate: 3.90625e-05\n",
      "Epoch [3644/20000], Loss: 282.3695068359375, Entropy -306.9712829589844, Learning Rate: 3.90625e-05\n",
      "Epoch [3645/20000], Loss: 294.2153015136719, Entropy -312.6101989746094, Learning Rate: 3.90625e-05\n",
      "Epoch [3646/20000], Loss: 285.7435607910156, Entropy -300.08831787109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3647/20000], Loss: 296.9423828125, Entropy -316.08868408203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3648/20000], Loss: 276.69122314453125, Entropy -288.6523742675781, Learning Rate: 3.90625e-05\n",
      "Epoch [3649/20000], Loss: 293.0343017578125, Entropy -310.5001525878906, Learning Rate: 3.90625e-05\n",
      "Epoch [3650/20000], Loss: 297.3636474609375, Entropy -322.480224609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3651/20000], Loss: 292.15032958984375, Entropy -294.69842529296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3652/20000], Loss: 288.1578369140625, Entropy -313.07952880859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3653/20000], Loss: 291.85321044921875, Entropy -301.6033935546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3654/20000], Loss: 291.41558837890625, Entropy -313.705322265625, Learning Rate: 3.90625e-05\n",
      "Epoch [3655/20000], Loss: 275.370361328125, Entropy -296.88494873046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3656/20000], Loss: 294.1632080078125, Entropy -309.8207092285156, Learning Rate: 3.90625e-05\n",
      "Epoch [3657/20000], Loss: 282.03460693359375, Entropy -298.8672180175781, Learning Rate: 3.90625e-05\n",
      "Epoch [3658/20000], Loss: 275.81500244140625, Entropy -297.45684814453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3659/20000], Loss: 267.48309326171875, Entropy -290.52099609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3660/20000], Loss: 271.196533203125, Entropy -290.0528869628906, Learning Rate: 3.90625e-05\n",
      "Epoch [3661/20000], Loss: 288.2168884277344, Entropy -306.8375549316406, Learning Rate: 3.90625e-05\n",
      "Epoch [3662/20000], Loss: 283.614501953125, Entropy -303.11907958984375, Learning Rate: 3.90625e-05\n",
      "Epoch [3663/20000], Loss: 266.590087890625, Entropy -284.037841796875, Learning Rate: 3.90625e-05\n",
      "Epoch [3664/20000], Loss: 272.2681884765625, Entropy -288.1575622558594, Learning Rate: 3.90625e-05\n",
      "Epoch [3665/20000], Loss: 279.2814025878906, Entropy -302.1539611816406, Learning Rate: 3.90625e-05\n",
      "Epoch [3666/20000], Loss: 283.4945068359375, Entropy -293.5752868652344, Learning Rate: 3.90625e-05\n",
      "Epoch [3667/20000], Loss: 273.7073059082031, Entropy -289.13238525390625, Learning Rate: 3.90625e-05\n",
      "Epoch [3668/20000], Loss: 280.3575439453125, Entropy -291.7399597167969, Learning Rate: 3.90625e-05\n",
      "Epoch [3669/20000], Loss: 291.16796875, Entropy -304.5487365722656, Learning Rate: 3.90625e-05\n",
      "Epoch [3670/20000], Loss: 293.861083984375, Entropy -316.3199462890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3671/20000], Loss: 297.22119140625, Entropy -318.3951416015625, Learning Rate: 3.90625e-05\n",
      "Epoch [3672/20000], Loss: 300.91387939453125, Entropy -321.1160888671875, Learning Rate: 3.90625e-05\n",
      "Epoch [3673/20000], Loss: 280.2535400390625, Entropy -298.10345458984375, Learning Rate: 3.90625e-05\n",
      "Epoch [3674/20000], Loss: 303.9576110839844, Entropy -322.49517822265625, Learning Rate: 3.90625e-05\n",
      "Epoch [3675/20000], Loss: 279.33392333984375, Entropy -302.7945251464844, Learning Rate: 3.90625e-05\n",
      "Epoch [3676/20000], Loss: 280.26171875, Entropy -300.46343994140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3677/20000], Loss: 274.95947265625, Entropy -291.9586181640625, Learning Rate: 3.90625e-05\n",
      "Epoch [3678/20000], Loss: 286.48779296875, Entropy -310.2507629394531, Learning Rate: 3.90625e-05\n",
      "Epoch [3679/20000], Loss: 284.23651123046875, Entropy -307.423095703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3680/20000], Loss: 285.2499084472656, Entropy -303.2791442871094, Learning Rate: 3.90625e-05\n",
      "Epoch [3681/20000], Loss: 285.798583984375, Entropy -295.0915222167969, Learning Rate: 3.90625e-05\n",
      "Epoch [3682/20000], Loss: 298.051025390625, Entropy -316.32513427734375, Learning Rate: 3.90625e-05\n",
      "Epoch [3683/20000], Loss: 293.19873046875, Entropy -306.4104309082031, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3684/20000], Loss: 275.5650329589844, Entropy -296.0839538574219, Learning Rate: 3.90625e-05\n",
      "Epoch [3685/20000], Loss: 292.9639587402344, Entropy -315.1099853515625, Learning Rate: 3.90625e-05\n",
      "Epoch [3686/20000], Loss: 277.53594970703125, Entropy -288.03961181640625, Learning Rate: 3.90625e-05\n",
      "Epoch [3687/20000], Loss: 273.90435791015625, Entropy -289.5904235839844, Learning Rate: 3.90625e-05\n",
      "Epoch [3688/20000], Loss: 282.227783203125, Entropy -304.08245849609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3689/20000], Loss: 286.046875, Entropy -304.9678039550781, Learning Rate: 3.90625e-05\n",
      "Epoch [3690/20000], Loss: 279.74493408203125, Entropy -304.8734436035156, Learning Rate: 3.90625e-05\n",
      "Epoch [3691/20000], Loss: 286.7001647949219, Entropy -297.4292907714844, Learning Rate: 3.90625e-05\n",
      "Epoch [3692/20000], Loss: 272.71685791015625, Entropy -292.9039001464844, Learning Rate: 3.90625e-05\n",
      "Epoch [3693/20000], Loss: 276.9268798828125, Entropy -297.1014099121094, Learning Rate: 3.90625e-05\n",
      "Epoch [3694/20000], Loss: 282.8372497558594, Entropy -295.46026611328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3695/20000], Loss: 286.99237060546875, Entropy -300.290283203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3696/20000], Loss: 305.300537109375, Entropy -324.6385498046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3697/20000], Loss: 296.41363525390625, Entropy -307.82354736328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3698/20000], Loss: 285.08416748046875, Entropy -301.64251708984375, Learning Rate: 3.90625e-05\n",
      "Epoch [3699/20000], Loss: 303.96893310546875, Entropy -325.0700378417969, Learning Rate: 3.90625e-05\n",
      "Epoch [3700/20000], Loss: 289.85198974609375, Entropy -312.7235412597656, Learning Rate: 3.90625e-05\n",
      "Epoch [3701/20000], Loss: 268.6333923339844, Entropy -286.0097351074219, Learning Rate: 3.90625e-05\n",
      "Epoch [3702/20000], Loss: 286.573486328125, Entropy -308.0855712890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3703/20000], Loss: 279.7951965332031, Entropy -298.7678527832031, Learning Rate: 3.90625e-05\n",
      "Epoch [3704/20000], Loss: 273.984619140625, Entropy -300.636962890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3705/20000], Loss: 292.30645751953125, Entropy -291.3592529296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3706/20000], Loss: 285.34674072265625, Entropy -305.7770080566406, Learning Rate: 3.90625e-05\n",
      "Epoch [3707/20000], Loss: 270.03680419921875, Entropy -286.5670166015625, Learning Rate: 3.90625e-05\n",
      "Epoch [3708/20000], Loss: 296.2822570800781, Entropy -303.7662353515625, Learning Rate: 3.90625e-05\n",
      "Epoch [3709/20000], Loss: 277.513671875, Entropy -292.0330505371094, Learning Rate: 3.90625e-05\n",
      "Epoch [3710/20000], Loss: 285.0010681152344, Entropy -305.34893798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3711/20000], Loss: 252.40769958496094, Entropy -271.0292053222656, Learning Rate: 3.90625e-05\n",
      "Epoch [3712/20000], Loss: 292.31317138671875, Entropy -312.8425598144531, Learning Rate: 3.90625e-05\n",
      "Epoch [3713/20000], Loss: 282.5898132324219, Entropy -300.01019287109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3714/20000], Loss: 297.6935119628906, Entropy -314.21832275390625, Learning Rate: 3.90625e-05\n",
      "Epoch [3715/20000], Loss: 259.4368896484375, Entropy -283.7688903808594, Learning Rate: 3.90625e-05\n",
      "Epoch [3716/20000], Loss: 279.7139892578125, Entropy -303.4032897949219, Learning Rate: 3.90625e-05\n",
      "Epoch [3717/20000], Loss: 298.824462890625, Entropy -320.38751220703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3718/20000], Loss: 294.1111145019531, Entropy -300.366943359375, Learning Rate: 3.90625e-05\n",
      "Epoch [3719/20000], Loss: 271.79718017578125, Entropy -290.99249267578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3720/20000], Loss: 310.15643310546875, Entropy -323.0644836425781, Learning Rate: 3.90625e-05\n",
      "Epoch [3721/20000], Loss: 291.8864440917969, Entropy -311.7204284667969, Learning Rate: 3.90625e-05\n",
      "Epoch [3722/20000], Loss: 293.42938232421875, Entropy -309.755126953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3723/20000], Loss: 287.105712890625, Entropy -306.3957824707031, Learning Rate: 3.90625e-05\n",
      "Epoch [3724/20000], Loss: 282.7604675292969, Entropy -298.94866943359375, Learning Rate: 3.90625e-05\n",
      "Epoch [3725/20000], Loss: 282.1533508300781, Entropy -301.9508361816406, Learning Rate: 3.90625e-05\n",
      "Epoch [3726/20000], Loss: 286.990234375, Entropy -304.0927429199219, Learning Rate: 3.90625e-05\n",
      "Epoch [3727/20000], Loss: 273.75262451171875, Entropy -289.1709899902344, Learning Rate: 3.90625e-05\n",
      "Epoch [3728/20000], Loss: 288.87548828125, Entropy -309.7359313964844, Learning Rate: 3.90625e-05\n",
      "Epoch [3729/20000], Loss: 280.6163024902344, Entropy -306.9615173339844, Learning Rate: 3.90625e-05\n",
      "Epoch [3730/20000], Loss: 280.006103515625, Entropy -296.5180358886719, Learning Rate: 3.90625e-05\n",
      "Epoch [3731/20000], Loss: 280.4656982421875, Entropy -297.9534912109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3732/20000], Loss: 306.1044921875, Entropy -329.8614501953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3733/20000], Loss: 276.9460754394531, Entropy -303.2001037597656, Learning Rate: 3.90625e-05\n",
      "Epoch [3734/20000], Loss: 287.94390869140625, Entropy -303.8551330566406, Learning Rate: 3.90625e-05\n",
      "Epoch [3735/20000], Loss: 306.2095947265625, Entropy -324.6745300292969, Learning Rate: 3.90625e-05\n",
      "Epoch [3736/20000], Loss: 282.4364013671875, Entropy -301.050048828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3737/20000], Loss: 299.2655029296875, Entropy -313.8387145996094, Learning Rate: 3.90625e-05\n",
      "Epoch [3738/20000], Loss: 269.8050537109375, Entropy -284.43585205078125, Learning Rate: 3.90625e-05\n",
      "Epoch [3739/20000], Loss: 300.9202880859375, Entropy -317.75518798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [3740/20000], Loss: 284.93896484375, Entropy -301.06219482421875, Learning Rate: 3.90625e-05\n",
      "Epoch [3741/20000], Loss: 288.5508117675781, Entropy -305.08544921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3742/20000], Loss: 273.07464599609375, Entropy -298.1630554199219, Learning Rate: 3.90625e-05\n",
      "Epoch [3743/20000], Loss: 268.0147705078125, Entropy -286.0103759765625, Learning Rate: 3.90625e-05\n",
      "Epoch [3744/20000], Loss: 306.57855224609375, Entropy -329.34942626953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3745/20000], Loss: 272.08526611328125, Entropy -292.1839599609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3746/20000], Loss: 280.20263671875, Entropy -297.1659240722656, Learning Rate: 3.90625e-05\n",
      "Epoch [3747/20000], Loss: 301.1323547363281, Entropy -315.4937744140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3748/20000], Loss: 274.59075927734375, Entropy -288.0402526855469, Learning Rate: 3.90625e-05\n",
      "Epoch [3749/20000], Loss: 269.972900390625, Entropy -285.62371826171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3750/20000], Loss: 279.9281311035156, Entropy -299.19403076171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3751/20000], Loss: 272.6462707519531, Entropy -288.00799560546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3752/20000], Loss: 305.5470886230469, Entropy -307.93890380859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3753/20000], Loss: 280.2762451171875, Entropy -300.9883117675781, Learning Rate: 3.90625e-05\n",
      "Epoch [3754/20000], Loss: 276.05535888671875, Entropy -299.32080078125, Learning Rate: 3.90625e-05\n",
      "Epoch [3755/20000], Loss: 267.95660400390625, Entropy -284.8682556152344, Learning Rate: 3.90625e-05\n",
      "Epoch [3756/20000], Loss: 286.4193115234375, Entropy -302.9454040527344, Learning Rate: 3.90625e-05\n",
      "Epoch [3757/20000], Loss: 291.7364501953125, Entropy -306.1531066894531, Learning Rate: 3.90625e-05\n",
      "Epoch [3758/20000], Loss: 281.2347106933594, Entropy -300.77972412109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3759/20000], Loss: 287.54815673828125, Entropy -304.6045837402344, Learning Rate: 3.90625e-05\n",
      "Epoch [3760/20000], Loss: 293.54425048828125, Entropy -311.8154296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3761/20000], Loss: 279.4600830078125, Entropy -297.92816162109375, Learning Rate: 3.90625e-05\n",
      "Epoch [3762/20000], Loss: 289.8852844238281, Entropy -313.17578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3763/20000], Loss: 286.0947570800781, Entropy -299.8060607910156, Learning Rate: 3.90625e-05\n",
      "Epoch [3764/20000], Loss: 278.6217956542969, Entropy -292.6614990234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3765/20000], Loss: 279.43206787109375, Entropy -299.2126770019531, Learning Rate: 3.90625e-05\n",
      "Epoch [3766/20000], Loss: 296.3079833984375, Entropy -314.4974365234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3767/20000], Loss: 282.7267150878906, Entropy -295.19976806640625, Learning Rate: 3.90625e-05\n",
      "Epoch [3768/20000], Loss: 278.9550476074219, Entropy -297.4365234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3769/20000], Loss: 279.782958984375, Entropy -295.37567138671875, Learning Rate: 3.90625e-05\n",
      "Epoch [3770/20000], Loss: 289.103759765625, Entropy -302.63043212890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3771/20000], Loss: 290.382080078125, Entropy -306.9541931152344, Learning Rate: 3.90625e-05\n",
      "Epoch [3772/20000], Loss: 269.2452697753906, Entropy -289.7983703613281, Learning Rate: 3.90625e-05\n",
      "Epoch [3773/20000], Loss: 269.5960693359375, Entropy -292.6498107910156, Learning Rate: 3.90625e-05\n",
      "Epoch [3774/20000], Loss: 271.0194091796875, Entropy -289.4505615234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3775/20000], Loss: 285.2271728515625, Entropy -301.4264221191406, Learning Rate: 3.90625e-05\n",
      "Epoch [3776/20000], Loss: 302.0140380859375, Entropy -319.7706298828125, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3777/20000], Loss: 279.326904296875, Entropy -298.5465087890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3778/20000], Loss: 291.59808349609375, Entropy -308.81646728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [3779/20000], Loss: 285.77239990234375, Entropy -306.090087890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3780/20000], Loss: 290.11505126953125, Entropy -301.3878479003906, Learning Rate: 3.90625e-05\n",
      "Epoch [3781/20000], Loss: 278.6858825683594, Entropy -305.15057373046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3782/20000], Loss: 285.229736328125, Entropy -305.1075439453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3783/20000], Loss: 286.3414306640625, Entropy -304.9422607421875, Learning Rate: 3.90625e-05\n",
      "Epoch [3784/20000], Loss: 281.0595703125, Entropy -304.7787780761719, Learning Rate: 3.90625e-05\n",
      "Epoch [3785/20000], Loss: 291.95526123046875, Entropy -308.2352294921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3786/20000], Loss: 279.63507080078125, Entropy -292.4889221191406, Learning Rate: 3.90625e-05\n",
      "Epoch [3787/20000], Loss: 271.33526611328125, Entropy -287.4938049316406, Learning Rate: 3.90625e-05\n",
      "Epoch [3788/20000], Loss: 282.90252685546875, Entropy -302.0369873046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3789/20000], Loss: 286.8463134765625, Entropy -314.42218017578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3790/20000], Loss: 298.1343078613281, Entropy -312.8941345214844, Learning Rate: 3.90625e-05\n",
      "Epoch [3791/20000], Loss: 288.004150390625, Entropy -305.087646484375, Learning Rate: 3.90625e-05\n",
      "Epoch [3792/20000], Loss: 289.917724609375, Entropy -314.2298583984375, Learning Rate: 3.90625e-05\n",
      "Epoch [3793/20000], Loss: 283.8047790527344, Entropy -294.921142578125, Learning Rate: 3.90625e-05\n",
      "Epoch [3794/20000], Loss: 288.332275390625, Entropy -303.6247253417969, Learning Rate: 3.90625e-05\n",
      "Epoch [3795/20000], Loss: 290.63177490234375, Entropy -303.8023376464844, Learning Rate: 3.90625e-05\n",
      "Epoch [3796/20000], Loss: 283.21099853515625, Entropy -308.1410217285156, Learning Rate: 3.90625e-05\n",
      "Epoch [3797/20000], Loss: 266.5503234863281, Entropy -284.9242858886719, Learning Rate: 3.90625e-05\n",
      "Epoch [3798/20000], Loss: 289.0176086425781, Entropy -307.1441955566406, Learning Rate: 3.90625e-05\n",
      "Epoch [3799/20000], Loss: 289.7506408691406, Entropy -309.62384033203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3800/20000], Loss: 289.5010986328125, Entropy -311.0596008300781, Learning Rate: 3.90625e-05\n",
      "Epoch [3801/20000], Loss: 287.84527587890625, Entropy -305.2032470703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3802/20000], Loss: 291.509521484375, Entropy -308.7596435546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3803/20000], Loss: 271.24749755859375, Entropy -292.76129150390625, Learning Rate: 3.90625e-05\n",
      "Epoch [3804/20000], Loss: 292.65960693359375, Entropy -308.0340270996094, Learning Rate: 3.90625e-05\n",
      "Epoch [3805/20000], Loss: 272.2218017578125, Entropy -291.3371276855469, Learning Rate: 3.90625e-05\n",
      "Epoch [3806/20000], Loss: 278.475341796875, Entropy -297.67681884765625, Learning Rate: 3.90625e-05\n",
      "Epoch [3807/20000], Loss: 278.8990783691406, Entropy -294.3275451660156, Learning Rate: 3.90625e-05\n",
      "Epoch [3808/20000], Loss: 276.37982177734375, Entropy -294.66461181640625, Learning Rate: 3.90625e-05\n",
      "Epoch [3809/20000], Loss: 292.6770935058594, Entropy -311.1225891113281, Learning Rate: 3.90625e-05\n",
      "Epoch [3810/20000], Loss: 264.7313537597656, Entropy -287.9129333496094, Learning Rate: 3.90625e-05\n",
      "Epoch [3811/20000], Loss: 295.87603759765625, Entropy -311.81756591796875, Learning Rate: 3.90625e-05\n",
      "Epoch [3812/20000], Loss: 278.0909118652344, Entropy -278.5805969238281, Learning Rate: 3.90625e-05\n",
      "Epoch [3813/20000], Loss: 282.0196533203125, Entropy -302.38092041015625, Learning Rate: 3.90625e-05\n",
      "Epoch [3814/20000], Loss: 298.6236572265625, Entropy -318.4205627441406, Learning Rate: 3.90625e-05\n",
      "Epoch [3815/20000], Loss: 287.7969970703125, Entropy -309.9591979980469, Learning Rate: 3.90625e-05\n",
      "Epoch [3816/20000], Loss: 284.5802001953125, Entropy -306.2383117675781, Learning Rate: 3.90625e-05\n",
      "Epoch [3817/20000], Loss: 288.01458740234375, Entropy -312.9267272949219, Learning Rate: 3.90625e-05\n",
      "Epoch [3818/20000], Loss: 264.9085693359375, Entropy -282.4107971191406, Learning Rate: 3.90625e-05\n",
      "Epoch [3819/20000], Loss: 320.90911865234375, Entropy -334.4479675292969, Learning Rate: 3.90625e-05\n",
      "Epoch [3820/20000], Loss: 274.9532165527344, Entropy -297.6012268066406, Learning Rate: 3.90625e-05\n",
      "Epoch [3821/20000], Loss: 285.7216796875, Entropy -310.1658935546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3822/20000], Loss: 282.33544921875, Entropy -299.45587158203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3823/20000], Loss: 289.64349365234375, Entropy -310.3161926269531, Learning Rate: 3.90625e-05\n",
      "Epoch [3824/20000], Loss: 289.70367431640625, Entropy -305.025146484375, Learning Rate: 3.90625e-05\n",
      "Epoch [3825/20000], Loss: 286.43017578125, Entropy -302.7488098144531, Learning Rate: 3.90625e-05\n",
      "Epoch [3826/20000], Loss: 270.3499450683594, Entropy -289.9423522949219, Learning Rate: 3.90625e-05\n",
      "Epoch [3827/20000], Loss: 298.4700927734375, Entropy -319.0823974609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3828/20000], Loss: 291.6190185546875, Entropy -311.3377990722656, Learning Rate: 3.90625e-05\n",
      "Epoch [3829/20000], Loss: 281.171630859375, Entropy -303.04962158203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3830/20000], Loss: 277.3132019042969, Entropy -301.32281494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [3831/20000], Loss: 284.7520751953125, Entropy -303.3880920410156, Learning Rate: 3.90625e-05\n",
      "Epoch [3832/20000], Loss: 296.6199645996094, Entropy -314.9576721191406, Learning Rate: 3.90625e-05\n",
      "Epoch [3833/20000], Loss: 271.72808837890625, Entropy -285.1974792480469, Learning Rate: 3.90625e-05\n",
      "Epoch [3834/20000], Loss: 287.0500793457031, Entropy -300.7918701171875, Learning Rate: 3.90625e-05\n",
      "Epoch [3835/20000], Loss: 273.0648498535156, Entropy -287.9637756347656, Learning Rate: 3.90625e-05\n",
      "Epoch [3836/20000], Loss: 293.22296142578125, Entropy -307.70623779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3837/20000], Loss: 291.81689453125, Entropy -296.41900634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [3838/20000], Loss: 288.25018310546875, Entropy -305.6047668457031, Learning Rate: 3.90625e-05\n",
      "Epoch [3839/20000], Loss: 288.0832824707031, Entropy -305.0456848144531, Learning Rate: 3.90625e-05\n",
      "Epoch [3840/20000], Loss: 279.71038818359375, Entropy -287.8555908203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3841/20000], Loss: 266.7254638671875, Entropy -291.4593505859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3842/20000], Loss: 275.689453125, Entropy -292.3019714355469, Learning Rate: 3.90625e-05\n",
      "Epoch [3843/20000], Loss: 281.91583251953125, Entropy -308.2508544921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3844/20000], Loss: 272.501953125, Entropy -301.73089599609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3845/20000], Loss: 282.22845458984375, Entropy -296.1102294921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3846/20000], Loss: 273.3963623046875, Entropy -292.00860595703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3847/20000], Loss: 278.1522216796875, Entropy -290.4015808105469, Learning Rate: 3.90625e-05\n",
      "Epoch [3848/20000], Loss: 282.3194885253906, Entropy -290.58935546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3849/20000], Loss: 279.096923828125, Entropy -305.85699462890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3850/20000], Loss: 284.0338439941406, Entropy -308.9502258300781, Learning Rate: 3.90625e-05\n",
      "Epoch [3851/20000], Loss: 308.50775146484375, Entropy -321.4924011230469, Learning Rate: 3.90625e-05\n",
      "Epoch [3852/20000], Loss: 285.48712158203125, Entropy -298.76708984375, Learning Rate: 3.90625e-05\n",
      "Epoch [3853/20000], Loss: 271.376708984375, Entropy -293.09661865234375, Learning Rate: 3.90625e-05\n",
      "Epoch [3854/20000], Loss: 293.89251708984375, Entropy -316.01953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3855/20000], Loss: 298.3836364746094, Entropy -313.8558349609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3856/20000], Loss: 280.9029541015625, Entropy -295.3360290527344, Learning Rate: 3.90625e-05\n",
      "Epoch [3857/20000], Loss: 287.02117919921875, Entropy -299.67626953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3858/20000], Loss: 275.9439392089844, Entropy -303.4326477050781, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3859/20000], Loss: 279.3757019042969, Entropy -301.5368347167969, Learning Rate: 3.90625e-05\n",
      "Epoch [3860/20000], Loss: 307.06781005859375, Entropy -315.1163635253906, Learning Rate: 3.90625e-05\n",
      "Epoch [3861/20000], Loss: 278.4093322753906, Entropy -296.3896179199219, Learning Rate: 3.90625e-05\n",
      "Epoch [3862/20000], Loss: 283.218505859375, Entropy -299.3406066894531, Learning Rate: 3.90625e-05\n",
      "Epoch [3863/20000], Loss: 296.2894287109375, Entropy -314.0552062988281, Learning Rate: 3.90625e-05\n",
      "Epoch [3864/20000], Loss: 285.94830322265625, Entropy -309.29638671875, Learning Rate: 3.90625e-05\n",
      "Epoch [3865/20000], Loss: 326.7894287109375, Entropy -319.6430969238281, Learning Rate: 3.90625e-05\n",
      "Epoch [3866/20000], Loss: 296.92437744140625, Entropy -316.2389221191406, Learning Rate: 3.90625e-05\n",
      "Epoch [3867/20000], Loss: 286.3274230957031, Entropy -293.50555419921875, Learning Rate: 3.90625e-05\n",
      "Epoch [3868/20000], Loss: 262.8772277832031, Entropy -286.65252685546875, Learning Rate: 3.90625e-05\n",
      "Epoch [3869/20000], Loss: 281.98809814453125, Entropy -296.87091064453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3870/20000], Loss: 291.13653564453125, Entropy -300.93853759765625, Learning Rate: 3.90625e-05\n",
      "Epoch [3871/20000], Loss: 276.1961669921875, Entropy -300.2469177246094, Learning Rate: 3.90625e-05\n",
      "Epoch [3872/20000], Loss: 281.6567077636719, Entropy -302.12713623046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3873/20000], Loss: 308.39373779296875, Entropy -322.505859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3874/20000], Loss: 273.36932373046875, Entropy -291.203125, Learning Rate: 3.90625e-05\n",
      "Epoch [3875/20000], Loss: 281.7682800292969, Entropy -305.6082458496094, Learning Rate: 3.90625e-05\n",
      "Epoch [3876/20000], Loss: 285.5251770019531, Entropy -307.2674255371094, Learning Rate: 3.90625e-05\n",
      "Epoch [3877/20000], Loss: 288.97607421875, Entropy -313.98046875, Learning Rate: 3.90625e-05\n",
      "Epoch [3878/20000], Loss: 292.85101318359375, Entropy -314.3122863769531, Learning Rate: 3.90625e-05\n",
      "Epoch [3879/20000], Loss: 302.16680908203125, Entropy -323.18731689453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3880/20000], Loss: 296.47528076171875, Entropy -310.4958190917969, Learning Rate: 3.90625e-05\n",
      "Epoch [3881/20000], Loss: 301.4009094238281, Entropy -325.3838195800781, Learning Rate: 3.90625e-05\n",
      "Epoch [3882/20000], Loss: 277.07684326171875, Entropy -294.1622314453125, Learning Rate: 3.90625e-05\n",
      "Epoch [3883/20000], Loss: 283.91668701171875, Entropy -305.52777099609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3884/20000], Loss: 299.3654479980469, Entropy -316.1692199707031, Learning Rate: 3.90625e-05\n",
      "Epoch [3885/20000], Loss: 284.1375427246094, Entropy -299.3121643066406, Learning Rate: 3.90625e-05\n",
      "Epoch [3886/20000], Loss: 265.3831787109375, Entropy -284.4197082519531, Learning Rate: 3.90625e-05\n",
      "Epoch [3887/20000], Loss: 281.678955078125, Entropy -292.05218505859375, Learning Rate: 3.90625e-05\n",
      "Epoch [3888/20000], Loss: 263.7633056640625, Entropy -281.1326904296875, Learning Rate: 3.90625e-05\n",
      "Epoch [3889/20000], Loss: 282.75323486328125, Entropy -302.4172058105469, Learning Rate: 3.90625e-05\n",
      "Epoch [3890/20000], Loss: 259.98626708984375, Entropy -279.0589599609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3891/20000], Loss: 279.57830810546875, Entropy -303.31207275390625, Learning Rate: 3.90625e-05\n",
      "Epoch [3892/20000], Loss: 269.1303405761719, Entropy -290.7769775390625, Learning Rate: 3.90625e-05\n",
      "Epoch [3893/20000], Loss: 272.246826171875, Entropy -289.895751953125, Learning Rate: 3.90625e-05\n",
      "Epoch [3894/20000], Loss: 260.36663818359375, Entropy -277.1350402832031, Learning Rate: 3.90625e-05\n",
      "Epoch [3895/20000], Loss: 280.32244873046875, Entropy -309.480712890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3896/20000], Loss: 280.368408203125, Entropy -292.7643737792969, Learning Rate: 3.90625e-05\n",
      "Epoch [3897/20000], Loss: 294.185302734375, Entropy -306.71917724609375, Learning Rate: 3.90625e-05\n",
      "Epoch [3898/20000], Loss: 292.49395751953125, Entropy -307.7637023925781, Learning Rate: 3.90625e-05\n",
      "Epoch [3899/20000], Loss: 279.7413635253906, Entropy -302.3300476074219, Learning Rate: 3.90625e-05\n",
      "Epoch [3900/20000], Loss: 270.4690856933594, Entropy -290.2105712890625, Learning Rate: 3.90625e-05\n",
      "Epoch [3901/20000], Loss: 312.5853271484375, Entropy -322.7604064941406, Learning Rate: 3.90625e-05\n",
      "Epoch [3902/20000], Loss: 284.103271484375, Entropy -303.1358947753906, Learning Rate: 3.90625e-05\n",
      "Epoch [3903/20000], Loss: 283.4122314453125, Entropy -302.68975830078125, Learning Rate: 3.90625e-05\n",
      "Epoch [3904/20000], Loss: 289.17315673828125, Entropy -316.0968322753906, Learning Rate: 3.90625e-05\n",
      "Epoch [3905/20000], Loss: 278.3099365234375, Entropy -297.7657470703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3906/20000], Loss: 296.902099609375, Entropy -310.9409484863281, Learning Rate: 3.90625e-05\n",
      "Epoch [3907/20000], Loss: 297.8094787597656, Entropy -314.46807861328125, Learning Rate: 3.90625e-05\n",
      "Epoch [3908/20000], Loss: 276.6900329589844, Entropy -301.09063720703125, Learning Rate: 3.90625e-05\n",
      "Epoch [3909/20000], Loss: 288.90252685546875, Entropy -302.5082702636719, Learning Rate: 3.90625e-05\n",
      "Epoch [3910/20000], Loss: 274.11669921875, Entropy -295.76116943359375, Learning Rate: 3.90625e-05\n",
      "Epoch [3911/20000], Loss: 294.05242919921875, Entropy -304.4122619628906, Learning Rate: 3.90625e-05\n",
      "Epoch [3912/20000], Loss: 282.283203125, Entropy -304.4569091796875, Learning Rate: 3.90625e-05\n",
      "Epoch [3913/20000], Loss: 275.4811706542969, Entropy -296.45855712890625, Learning Rate: 1.953125e-05\n",
      "Epoch [3914/20000], Loss: 303.29461669921875, Entropy -322.17755126953125, Learning Rate: 1.953125e-05\n",
      "Epoch [3915/20000], Loss: 283.9352722167969, Entropy -307.75445556640625, Learning Rate: 1.953125e-05\n",
      "Epoch [3916/20000], Loss: 278.1703796386719, Entropy -297.43316650390625, Learning Rate: 1.953125e-05\n",
      "Epoch [3917/20000], Loss: 269.69635009765625, Entropy -285.3244323730469, Learning Rate: 1.953125e-05\n",
      "Epoch [3918/20000], Loss: 278.718505859375, Entropy -294.8017272949219, Learning Rate: 1.953125e-05\n",
      "Epoch [3919/20000], Loss: 267.9908142089844, Entropy -288.9830627441406, Learning Rate: 1.953125e-05\n",
      "Epoch [3920/20000], Loss: 277.78662109375, Entropy -298.7055358886719, Learning Rate: 1.953125e-05\n",
      "Epoch [3921/20000], Loss: 276.34698486328125, Entropy -295.95135498046875, Learning Rate: 1.953125e-05\n",
      "Epoch [3922/20000], Loss: 281.62701416015625, Entropy -293.948974609375, Learning Rate: 1.953125e-05\n",
      "Epoch [3923/20000], Loss: 273.1556091308594, Entropy -290.1727600097656, Learning Rate: 1.953125e-05\n",
      "Epoch [3924/20000], Loss: 291.5792236328125, Entropy -303.18121337890625, Learning Rate: 1.953125e-05\n",
      "Epoch [3925/20000], Loss: 283.2615966796875, Entropy -306.0661315917969, Learning Rate: 1.953125e-05\n",
      "Epoch [3926/20000], Loss: 289.21728515625, Entropy -305.5285339355469, Learning Rate: 1.953125e-05\n",
      "Epoch [3927/20000], Loss: 280.8780517578125, Entropy -295.5647888183594, Learning Rate: 1.953125e-05\n",
      "Epoch [3928/20000], Loss: 278.0350341796875, Entropy -301.6512145996094, Learning Rate: 1.953125e-05\n",
      "Epoch [3929/20000], Loss: 290.0295715332031, Entropy -308.8181457519531, Learning Rate: 1.953125e-05\n",
      "Epoch [3930/20000], Loss: 283.32086181640625, Entropy -300.16998291015625, Learning Rate: 1.953125e-05\n",
      "Epoch [3931/20000], Loss: 293.24322509765625, Entropy -312.1402893066406, Learning Rate: 1.953125e-05\n",
      "Epoch [3932/20000], Loss: 278.285888671875, Entropy -298.9383544921875, Learning Rate: 1.953125e-05\n",
      "Epoch [3933/20000], Loss: 278.0316162109375, Entropy -291.41845703125, Learning Rate: 1.953125e-05\n",
      "Epoch [3934/20000], Loss: 289.57928466796875, Entropy -302.0836181640625, Learning Rate: 1.953125e-05\n",
      "Epoch [3935/20000], Loss: 280.5799255371094, Entropy -302.944091796875, Learning Rate: 1.953125e-05\n",
      "Epoch [3936/20000], Loss: 282.96380615234375, Entropy -300.662353515625, Learning Rate: 1.953125e-05\n",
      "Epoch [3937/20000], Loss: 274.18011474609375, Entropy -291.8659973144531, Learning Rate: 1.953125e-05\n",
      "Epoch [3938/20000], Loss: 276.1966552734375, Entropy -292.5576171875, Learning Rate: 1.953125e-05\n",
      "Epoch [3939/20000], Loss: 294.0897216796875, Entropy -306.7134704589844, Learning Rate: 1.953125e-05\n",
      "Epoch [3940/20000], Loss: 281.1454772949219, Entropy -304.6376037597656, Learning Rate: 1.953125e-05\n",
      "Epoch [3941/20000], Loss: 283.03125, Entropy -296.1405944824219, Learning Rate: 1.953125e-05\n",
      "Epoch [3942/20000], Loss: 289.6811828613281, Entropy -304.95355224609375, Learning Rate: 1.953125e-05\n",
      "Epoch [3943/20000], Loss: 284.5504150390625, Entropy -303.37567138671875, Learning Rate: 1.953125e-05\n",
      "Epoch [3944/20000], Loss: 280.733642578125, Entropy -303.28631591796875, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3945/20000], Loss: 274.363037109375, Entropy -296.8343811035156, Learning Rate: 1.953125e-05\n",
      "Epoch [3946/20000], Loss: 275.5167236328125, Entropy -302.0845031738281, Learning Rate: 1.953125e-05\n",
      "Epoch [3947/20000], Loss: 286.0126953125, Entropy -304.47796630859375, Learning Rate: 1.953125e-05\n",
      "Epoch [3948/20000], Loss: 275.3718566894531, Entropy -295.6117858886719, Learning Rate: 1.953125e-05\n",
      "Epoch [3949/20000], Loss: 268.9403076171875, Entropy -294.838623046875, Learning Rate: 1.953125e-05\n",
      "Epoch [3950/20000], Loss: 293.20819091796875, Entropy -309.9419860839844, Learning Rate: 1.953125e-05\n",
      "Epoch [3951/20000], Loss: 278.86669921875, Entropy -304.4051513671875, Learning Rate: 1.953125e-05\n",
      "Epoch [3952/20000], Loss: 279.3760986328125, Entropy -298.2596740722656, Learning Rate: 1.953125e-05\n",
      "Epoch [3953/20000], Loss: 291.48748779296875, Entropy -306.6299743652344, Learning Rate: 1.953125e-05\n",
      "Epoch [3954/20000], Loss: 274.15185546875, Entropy -295.2012634277344, Learning Rate: 1.953125e-05\n",
      "Epoch [3955/20000], Loss: 299.5986328125, Entropy -306.39324951171875, Learning Rate: 1.953125e-05\n",
      "Epoch [3956/20000], Loss: 277.8512268066406, Entropy -287.8011474609375, Learning Rate: 1.953125e-05\n",
      "Epoch [3957/20000], Loss: 288.7962341308594, Entropy -301.1571044921875, Learning Rate: 1.953125e-05\n",
      "Epoch [3958/20000], Loss: 304.25665283203125, Entropy -320.83892822265625, Learning Rate: 1.953125e-05\n",
      "Epoch [3959/20000], Loss: 282.1607666015625, Entropy -290.9400634765625, Learning Rate: 1.953125e-05\n",
      "Epoch [3960/20000], Loss: 283.31756591796875, Entropy -282.6506652832031, Learning Rate: 1.953125e-05\n",
      "Epoch [3961/20000], Loss: 276.06500244140625, Entropy -289.5867919921875, Learning Rate: 1.953125e-05\n",
      "Epoch [3962/20000], Loss: 279.36517333984375, Entropy -290.20001220703125, Learning Rate: 1.953125e-05\n",
      "Epoch [3963/20000], Loss: 297.2464904785156, Entropy -314.0349426269531, Learning Rate: 1.953125e-05\n",
      "Epoch [3964/20000], Loss: 288.35302734375, Entropy -302.9129638671875, Learning Rate: 1.953125e-05\n",
      "Epoch [3965/20000], Loss: 280.1396179199219, Entropy -295.8722229003906, Learning Rate: 1.953125e-05\n",
      "Epoch [3966/20000], Loss: 289.713623046875, Entropy -313.8448791503906, Learning Rate: 1.953125e-05\n",
      "Epoch [3967/20000], Loss: 291.1795349121094, Entropy -307.25238037109375, Learning Rate: 1.953125e-05\n",
      "Epoch [3968/20000], Loss: 293.6939697265625, Entropy -300.1014709472656, Learning Rate: 1.953125e-05\n",
      "Epoch [3969/20000], Loss: 293.05621337890625, Entropy -315.6859130859375, Learning Rate: 1.953125e-05\n",
      "Epoch [3970/20000], Loss: 287.09283447265625, Entropy -302.1722412109375, Learning Rate: 1.953125e-05\n",
      "Epoch [3971/20000], Loss: 287.61260986328125, Entropy -309.2126770019531, Learning Rate: 1.953125e-05\n",
      "Epoch [3972/20000], Loss: 266.29437255859375, Entropy -285.00885009765625, Learning Rate: 1.953125e-05\n",
      "Epoch [3973/20000], Loss: 272.46484375, Entropy -292.41375732421875, Learning Rate: 1.953125e-05\n",
      "Epoch [3974/20000], Loss: 311.24822998046875, Entropy -327.6465148925781, Learning Rate: 1.953125e-05\n",
      "Epoch [3975/20000], Loss: 290.36151123046875, Entropy -311.21832275390625, Learning Rate: 1.953125e-05\n",
      "Epoch [3976/20000], Loss: 280.5652770996094, Entropy -286.3150634765625, Learning Rate: 1.953125e-05\n",
      "Epoch [3977/20000], Loss: 301.6478271484375, Entropy -324.08856201171875, Learning Rate: 1.953125e-05\n",
      "Epoch [3978/20000], Loss: 284.22125244140625, Entropy -298.7102355957031, Learning Rate: 1.953125e-05\n",
      "Epoch [3979/20000], Loss: 294.3108825683594, Entropy -305.696533203125, Learning Rate: 1.953125e-05\n",
      "Epoch [3980/20000], Loss: 289.62841796875, Entropy -313.2780456542969, Learning Rate: 1.953125e-05\n",
      "Epoch [3981/20000], Loss: 287.126220703125, Entropy -306.375, Learning Rate: 1.953125e-05\n",
      "Epoch [3982/20000], Loss: 285.7186279296875, Entropy -302.3506774902344, Learning Rate: 1.953125e-05\n",
      "Epoch [3983/20000], Loss: 280.8016357421875, Entropy -293.1058654785156, Learning Rate: 1.953125e-05\n",
      "Epoch [3984/20000], Loss: 277.1197509765625, Entropy -298.09393310546875, Learning Rate: 1.953125e-05\n",
      "Epoch [3985/20000], Loss: 292.5765075683594, Entropy -314.6236572265625, Learning Rate: 1.953125e-05\n",
      "Epoch [3986/20000], Loss: 278.7249755859375, Entropy -294.4610290527344, Learning Rate: 1.953125e-05\n",
      "Epoch [3987/20000], Loss: 295.7030029296875, Entropy -312.8033752441406, Learning Rate: 1.953125e-05\n",
      "Epoch [3988/20000], Loss: 291.98028564453125, Entropy -312.2205505371094, Learning Rate: 1.953125e-05\n",
      "Epoch [3989/20000], Loss: 302.70428466796875, Entropy -314.49871826171875, Learning Rate: 1.953125e-05\n",
      "Epoch [3990/20000], Loss: 269.56695556640625, Entropy -294.62603759765625, Learning Rate: 1.953125e-05\n",
      "Epoch [3991/20000], Loss: 273.05450439453125, Entropy -290.9915771484375, Learning Rate: 1.953125e-05\n",
      "Epoch [3992/20000], Loss: 280.70068359375, Entropy -289.9532470703125, Learning Rate: 1.953125e-05\n",
      "Epoch [3993/20000], Loss: 294.4263000488281, Entropy -316.2845153808594, Learning Rate: 1.953125e-05\n",
      "Epoch [3994/20000], Loss: 287.85211181640625, Entropy -307.77294921875, Learning Rate: 1.953125e-05\n",
      "Epoch [3995/20000], Loss: 279.5899353027344, Entropy -294.5292053222656, Learning Rate: 1.953125e-05\n",
      "Epoch [3996/20000], Loss: 284.636962890625, Entropy -302.92913818359375, Learning Rate: 1.953125e-05\n",
      "Epoch [3997/20000], Loss: 289.2543029785156, Entropy -309.58575439453125, Learning Rate: 1.953125e-05\n",
      "Epoch [3998/20000], Loss: 278.7615966796875, Entropy -303.25518798828125, Learning Rate: 1.953125e-05\n",
      "Epoch [3999/20000], Loss: 284.55401611328125, Entropy -304.2618408203125, Learning Rate: 1.953125e-05\n",
      "Epoch [4000/20000], Loss: 268.58856201171875, Entropy -287.2780456542969, Learning Rate: 1.953125e-05\n",
      "Epoch [4001/20000], Loss: 300.7619934082031, Entropy -324.3578186035156, Learning Rate: 1.953125e-05\n",
      "Epoch [4002/20000], Loss: 272.8448791503906, Entropy -292.3539733886719, Learning Rate: 1.953125e-05\n",
      "Epoch [4003/20000], Loss: 293.92938232421875, Entropy -312.9286804199219, Learning Rate: 1.953125e-05\n",
      "Epoch [4004/20000], Loss: 280.59930419921875, Entropy -299.19586181640625, Learning Rate: 1.953125e-05\n",
      "Epoch [4005/20000], Loss: 268.10931396484375, Entropy -281.2663269042969, Learning Rate: 1.953125e-05\n",
      "Epoch [4006/20000], Loss: 296.76556396484375, Entropy -299.4521484375, Learning Rate: 1.953125e-05\n",
      "Epoch [4007/20000], Loss: 289.80657958984375, Entropy -302.4217834472656, Learning Rate: 1.953125e-05\n",
      "Epoch [4008/20000], Loss: 282.3980712890625, Entropy -295.58184814453125, Learning Rate: 1.953125e-05\n",
      "Epoch [4009/20000], Loss: 277.47235107421875, Entropy -294.5828857421875, Learning Rate: 1.953125e-05\n",
      "Epoch [4010/20000], Loss: 284.76763916015625, Entropy -295.2470703125, Learning Rate: 1.953125e-05\n",
      "Epoch [4011/20000], Loss: 288.125732421875, Entropy -307.5080871582031, Learning Rate: 1.953125e-05\n",
      "Epoch [4012/20000], Loss: 281.8437805175781, Entropy -301.3099060058594, Learning Rate: 1.953125e-05\n",
      "Epoch [4013/20000], Loss: 299.32989501953125, Entropy -317.703125, Learning Rate: 1.953125e-05\n",
      "Epoch [4014/20000], Loss: 295.50848388671875, Entropy -313.0007629394531, Learning Rate: 1.953125e-05\n",
      "Epoch [4015/20000], Loss: 289.2493896484375, Entropy -310.364990234375, Learning Rate: 1.953125e-05\n",
      "Epoch [4016/20000], Loss: 284.0497741699219, Entropy -306.642578125, Learning Rate: 1.953125e-05\n",
      "Epoch [4017/20000], Loss: 267.32989501953125, Entropy -290.6726989746094, Learning Rate: 1.953125e-05\n",
      "Epoch [4018/20000], Loss: 283.16552734375, Entropy -300.25927734375, Learning Rate: 1.953125e-05\n",
      "Epoch [4019/20000], Loss: 281.4854736328125, Entropy -301.89251708984375, Learning Rate: 1.953125e-05\n",
      "Epoch [4020/20000], Loss: 282.2520751953125, Entropy -295.86358642578125, Learning Rate: 1.953125e-05\n",
      "Epoch [4021/20000], Loss: 281.8155517578125, Entropy -309.3385314941406, Learning Rate: 1.953125e-05\n",
      "Epoch [4022/20000], Loss: 275.9612731933594, Entropy -294.1802673339844, Learning Rate: 1.953125e-05\n",
      "Epoch [4023/20000], Loss: 278.11395263671875, Entropy -300.0302429199219, Learning Rate: 1.953125e-05\n",
      "Epoch [4024/20000], Loss: 285.61895751953125, Entropy -308.96600341796875, Learning Rate: 1.953125e-05\n",
      "Epoch [4025/20000], Loss: 281.571044921875, Entropy -299.52203369140625, Learning Rate: 1.953125e-05\n",
      "Epoch [4026/20000], Loss: 272.3428039550781, Entropy -296.65411376953125, Learning Rate: 1.953125e-05\n",
      "Epoch [4027/20000], Loss: 283.12774658203125, Entropy -295.6875915527344, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4028/20000], Loss: 287.20880126953125, Entropy -310.2978820800781, Learning Rate: 1.953125e-05\n",
      "Epoch [4029/20000], Loss: 286.215576171875, Entropy -309.416259765625, Learning Rate: 1.953125e-05\n",
      "Epoch [4030/20000], Loss: 260.9263916015625, Entropy -278.604736328125, Learning Rate: 1.953125e-05\n",
      "Epoch [4031/20000], Loss: 279.862060546875, Entropy -301.48223876953125, Learning Rate: 1.953125e-05\n",
      "Epoch [4032/20000], Loss: 289.77764892578125, Entropy -308.7651062011719, Learning Rate: 1.953125e-05\n",
      "Epoch [4033/20000], Loss: 288.24261474609375, Entropy -307.82525634765625, Learning Rate: 1.953125e-05\n",
      "Epoch [4034/20000], Loss: 289.40301513671875, Entropy -304.1168212890625, Learning Rate: 1.953125e-05\n",
      "Epoch [4035/20000], Loss: 285.58587646484375, Entropy -304.50933837890625, Learning Rate: 1.953125e-05\n",
      "Epoch [4036/20000], Loss: 286.9146728515625, Entropy -303.27276611328125, Learning Rate: 1.953125e-05\n",
      "Epoch [4037/20000], Loss: 291.61248779296875, Entropy -317.1028137207031, Learning Rate: 1.953125e-05\n",
      "Epoch [4038/20000], Loss: 284.37481689453125, Entropy -310.239990234375, Learning Rate: 1.953125e-05\n",
      "Epoch [4039/20000], Loss: 269.177734375, Entropy -293.4314880371094, Learning Rate: 1.953125e-05\n",
      "Epoch [4040/20000], Loss: 285.8858642578125, Entropy -302.16748046875, Learning Rate: 1.953125e-05\n",
      "Epoch [4041/20000], Loss: 283.75421142578125, Entropy -302.9222412109375, Learning Rate: 1.953125e-05\n",
      "Epoch [4042/20000], Loss: 296.6282958984375, Entropy -321.1234130859375, Learning Rate: 1.953125e-05\n",
      "Epoch [4043/20000], Loss: 279.9193115234375, Entropy -297.547607421875, Learning Rate: 1.953125e-05\n",
      "Epoch [4044/20000], Loss: 299.8971252441406, Entropy -318.24505615234375, Learning Rate: 1.953125e-05\n",
      "Epoch [4045/20000], Loss: 288.06964111328125, Entropy -304.6865539550781, Learning Rate: 1.953125e-05\n",
      "Epoch [4046/20000], Loss: 264.7900695800781, Entropy -287.8047180175781, Learning Rate: 1.953125e-05\n",
      "Epoch [4047/20000], Loss: 301.25006103515625, Entropy -315.1695861816406, Learning Rate: 1.953125e-05\n",
      "Epoch [4048/20000], Loss: 292.8045654296875, Entropy -309.7642822265625, Learning Rate: 1.953125e-05\n",
      "Epoch [4049/20000], Loss: 289.3430480957031, Entropy -311.2384338378906, Learning Rate: 1.953125e-05\n",
      "Epoch [4050/20000], Loss: 278.1848449707031, Entropy -289.9977111816406, Learning Rate: 1.953125e-05\n",
      "Epoch [4051/20000], Loss: 274.17608642578125, Entropy -293.0110778808594, Learning Rate: 1.953125e-05\n",
      "Epoch [4052/20000], Loss: 285.23260498046875, Entropy -307.6007080078125, Learning Rate: 1.953125e-05\n",
      "Epoch [4053/20000], Loss: 277.960205078125, Entropy -297.80780029296875, Learning Rate: 1.953125e-05\n",
      "Epoch [4054/20000], Loss: 289.53338623046875, Entropy -316.8014831542969, Learning Rate: 1.953125e-05\n",
      "Epoch [4055/20000], Loss: 292.6568908691406, Entropy -306.6601257324219, Learning Rate: 1.953125e-05\n",
      "Epoch [4056/20000], Loss: 297.21038818359375, Entropy -319.88800048828125, Learning Rate: 1.953125e-05\n",
      "Epoch [4057/20000], Loss: 295.17071533203125, Entropy -309.91314697265625, Learning Rate: 1.953125e-05\n",
      "Epoch [4058/20000], Loss: 296.17657470703125, Entropy -315.17279052734375, Learning Rate: 1.953125e-05\n",
      "Epoch [4059/20000], Loss: 297.6521911621094, Entropy -317.6430358886719, Learning Rate: 1.953125e-05\n",
      "Epoch [4060/20000], Loss: 283.2894287109375, Entropy -297.70294189453125, Learning Rate: 1.953125e-05\n",
      "Epoch [4061/20000], Loss: 297.57073974609375, Entropy -314.5652770996094, Learning Rate: 1.953125e-05\n",
      "Epoch [4062/20000], Loss: 285.0929260253906, Entropy -301.38726806640625, Learning Rate: 1.953125e-05\n",
      "Epoch [4063/20000], Loss: 288.2831115722656, Entropy -308.7724609375, Learning Rate: 1.953125e-05\n",
      "Epoch [4064/20000], Loss: 269.66082763671875, Entropy -286.7460021972656, Learning Rate: 1.953125e-05\n",
      "Epoch [4065/20000], Loss: 288.3477783203125, Entropy -305.67291259765625, Learning Rate: 1.953125e-05\n",
      "Epoch [4066/20000], Loss: 275.6202697753906, Entropy -296.0533447265625, Learning Rate: 1.953125e-05\n",
      "Epoch [4067/20000], Loss: 296.10211181640625, Entropy -319.282958984375, Learning Rate: 1.953125e-05\n",
      "Epoch [4068/20000], Loss: 309.612060546875, Entropy -317.61163330078125, Learning Rate: 1.953125e-05\n",
      "Epoch [4069/20000], Loss: 278.5108947753906, Entropy -295.4796142578125, Learning Rate: 1.953125e-05\n",
      "Epoch [4070/20000], Loss: 281.2738037109375, Entropy -299.2444763183594, Learning Rate: 1.953125e-05\n",
      "Epoch [4071/20000], Loss: 271.4486083984375, Entropy -299.33868408203125, Learning Rate: 1.953125e-05\n",
      "Epoch [4072/20000], Loss: 283.09576416015625, Entropy -303.3529052734375, Learning Rate: 1.953125e-05\n",
      "Epoch [4073/20000], Loss: 287.15380859375, Entropy -295.1379089355469, Learning Rate: 1.953125e-05\n",
      "Epoch [4074/20000], Loss: 275.89068603515625, Entropy -296.6767578125, Learning Rate: 1.953125e-05\n",
      "Epoch [4075/20000], Loss: 298.7457580566406, Entropy -314.2822570800781, Learning Rate: 1.953125e-05\n",
      "Epoch [4076/20000], Loss: 284.7758483886719, Entropy -309.1172180175781, Learning Rate: 1.953125e-05\n",
      "Epoch [4077/20000], Loss: 291.787841796875, Entropy -306.07147216796875, Learning Rate: 1.953125e-05\n",
      "Epoch [4078/20000], Loss: 299.28839111328125, Entropy -319.0641784667969, Learning Rate: 1.953125e-05\n",
      "Epoch [4079/20000], Loss: 282.0089111328125, Entropy -305.18121337890625, Learning Rate: 1.953125e-05\n",
      "Epoch [4080/20000], Loss: 288.24267578125, Entropy -312.1131896972656, Learning Rate: 1.953125e-05\n",
      "Epoch [4081/20000], Loss: 289.2319030761719, Entropy -309.0258483886719, Learning Rate: 1.953125e-05\n",
      "Epoch [4082/20000], Loss: 303.64385986328125, Entropy -321.8127746582031, Learning Rate: 1.953125e-05\n",
      "Epoch [4083/20000], Loss: 286.1864013671875, Entropy -312.8246154785156, Learning Rate: 1.953125e-05\n",
      "Epoch [4084/20000], Loss: 291.150634765625, Entropy -302.112548828125, Learning Rate: 1.953125e-05\n",
      "Epoch [4085/20000], Loss: 292.0024108886719, Entropy -298.4662170410156, Learning Rate: 1.953125e-05\n",
      "Epoch [4086/20000], Loss: 285.5948486328125, Entropy -306.5133972167969, Learning Rate: 1.953125e-05\n",
      "Epoch [4087/20000], Loss: 300.04644775390625, Entropy -314.06011962890625, Learning Rate: 1.953125e-05\n",
      "Epoch [4088/20000], Loss: 271.74786376953125, Entropy -298.4339904785156, Learning Rate: 1.953125e-05\n",
      "Epoch [4089/20000], Loss: 285.696044921875, Entropy -292.7891845703125, Learning Rate: 1.953125e-05\n",
      "Epoch [4090/20000], Loss: 285.6367492675781, Entropy -298.18524169921875, Learning Rate: 1.953125e-05\n",
      "Epoch [4091/20000], Loss: 270.5634765625, Entropy -295.4064636230469, Learning Rate: 1.953125e-05\n",
      "Epoch [4092/20000], Loss: 281.11334228515625, Entropy -295.9029541015625, Learning Rate: 1.953125e-05\n",
      "Epoch [4093/20000], Loss: 289.0665283203125, Entropy -309.12884521484375, Learning Rate: 1.953125e-05\n",
      "Epoch [4094/20000], Loss: 285.9256591796875, Entropy -306.05157470703125, Learning Rate: 1.953125e-05\n",
      "Epoch [4095/20000], Loss: 281.6059265136719, Entropy -298.346435546875, Learning Rate: 1.953125e-05\n",
      "Epoch [4096/20000], Loss: 285.4958801269531, Entropy -302.016357421875, Learning Rate: 1.953125e-05\n",
      "Epoch [4097/20000], Loss: 307.46746826171875, Entropy -330.409423828125, Learning Rate: 1.953125e-05\n",
      "Epoch [4098/20000], Loss: 277.93609619140625, Entropy -299.0957336425781, Learning Rate: 1.953125e-05\n",
      "Epoch [4099/20000], Loss: 284.422119140625, Entropy -300.2112121582031, Learning Rate: 1.953125e-05\n",
      "Epoch [4100/20000], Loss: 269.2216796875, Entropy -290.9548645019531, Learning Rate: 1.953125e-05\n",
      "Epoch [4101/20000], Loss: 270.8834228515625, Entropy -286.853515625, Learning Rate: 1.953125e-05\n",
      "Epoch [4102/20000], Loss: 285.4598388671875, Entropy -305.298828125, Learning Rate: 1.953125e-05\n",
      "Epoch [4103/20000], Loss: 282.906494140625, Entropy -298.92779541015625, Learning Rate: 1.953125e-05\n",
      "Epoch [4104/20000], Loss: 289.81561279296875, Entropy -313.8986511230469, Learning Rate: 1.953125e-05\n",
      "Epoch [4105/20000], Loss: 276.9402770996094, Entropy -299.51275634765625, Learning Rate: 1.953125e-05\n",
      "Epoch [4106/20000], Loss: 287.391845703125, Entropy -303.4292907714844, Learning Rate: 1.953125e-05\n",
      "Epoch [4107/20000], Loss: 280.5829772949219, Entropy -296.7159729003906, Learning Rate: 1.953125e-05\n",
      "Epoch [4108/20000], Loss: 274.853759765625, Entropy -288.8796081542969, Learning Rate: 1.953125e-05\n",
      "Epoch [4109/20000], Loss: 284.390869140625, Entropy -302.8503112792969, Learning Rate: 1.953125e-05\n",
      "Epoch [4110/20000], Loss: 274.5617980957031, Entropy -287.1818542480469, Learning Rate: 1.953125e-05\n",
      "Epoch [4111/20000], Loss: 286.5694580078125, Entropy -310.6491394042969, Learning Rate: 1.953125e-05\n",
      "Epoch [4112/20000], Loss: 302.5028381347656, Entropy -328.06317138671875, Learning Rate: 1.953125e-05\n",
      "Epoch [4113/20000], Loss: 295.9913330078125, Entropy -315.60333251953125, Learning Rate: 1.953125e-05\n",
      "Epoch [4114/20000], Loss: 278.0035400390625, Entropy -296.668212890625, Learning Rate: 9.765625e-06\n",
      "3711 [tensor(252.4077, device='cuda:0'), tensor(-271.0292, device='cuda:0'), tensor(-137.5822, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "k_MC=100#size_sample\n",
    "\n",
    "#sample, = ax.scatter([],[],color='red',alpha=0.07)\n",
    "#fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "'''\n",
    "def show(GeN,n,alpha=0.07):\n",
    "    Z=GeN(n).detach().clone().cpu()\n",
    "    plt.pcolormesh(grid_x.numpy(),grid_y.numpy(),p.exp().numpy())\n",
    "    plt.scatter(Z[:,0],Z[:,1],color='red',alpha=alpha) \n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "''' \n",
    "\n",
    "def show(GeN,n):\n",
    "    #Z=GeN(200).detach()\n",
    "    #fig=setup.makePlot(Z,device)\n",
    "    #plt.show()\n",
    "    return\n",
    "    \n",
    "#lr =.03 for lat_dim 5\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    optimizer = GeNPredVI(loglikelihood, logprior, projection, k_MC,\n",
    "                                                1, 100, 1000, 50, 50,\n",
    "                                                20000, .01, .00001, 200, .5,\n",
    "                                                device, True, temp_dir, save_best=True)\n",
    "    best_epoch, scores=optimizer.run(GeN,show)\n",
    "print(best_epoch,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f582c71d790>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_entropy\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('KL divergence')\n",
    "plt.plot(time, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f582c71d610>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=torch.as_tensor(optimizer.score_elbo)\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('ELBO')\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5834b8b400>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_lr\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAJOCAYAAABvHKlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde5Rk+1XY9+/+/X7nnKrqnrkj6QqJRxARLxkrIQlgDCwwtsEhGLzIshcPG8uYlbBsTAJOMBhsMAnGj5j3ItjBxBhingaThxdgSFjCCMtWEDYPIQExICQQoPuY6a6q8/g9dv74na6p6emeO3em697han+0Zt3urqpTp06XunfvvX/7J6qKMcYYY4y5eu75PgFjjDHGmBcqC7SMMcYYYw7EAi1jjDHGmAOxQMsYY4wx5kAs0DLGGGOMORALtIwxxhhjDsQCLWOMMcaYA7FAyzxyRORvi8gXHPg53iQiH3uP218rIv/VIc/hqonIe4vIWkT8Azz2a0XkLxzivO7z+T9LRF639/laRF75AMf5MyLyo1d7du+aROTXReTjnoPnURF5v/njfyAiX3bo5zTmuWSBlnmkiMhLgdcA/8v8eSsi3z//0Nd7BUfPhqr+flV97fwcXyEi/+Qhzvl95nNb7/37sr3bOxH5RyJyIiK/LSL/3RW8hLuo6m+o6rGq5vl5n02w+PeAvyYi7UU3XvAaf11E/upVnft58+v41XvdZ++cwt7jvlNV/9hVnouIfImI/MsLvv64iEwi8urzgeJ9HFNE5PNE5OdEZDu/L14rIp9+n4//rPm1/5VzX3+7iHysiHzG/D2Sc7cHEfldEfmk+X5vv99zfobz2QVLD0NV/4KqfuVVnNNlROTPicgb5/8/vl1E/qf995AxV80CLfOo+Szgh1S13/va64DPBH77eTmj+3djDhCOz/2y+Arg/YFXAH8Y+CIR+YTn4wQvo6rvAN4C/IlnuOsNVT0GPgP48otexwvwl9b/BnykiPyH577+6cDPq+ovPMAxvxH4AuC/B14CvCfw14Fn8754CvhiEbl+wW0/CNwA/tC5r38CoMCPPNsTfgFZUa/948CHA38U+MLn9YzMC5oFWuZR818AP3H2iapOqvr1qvo6IN/rgSLyh0Xk5/c+/79F5A17n79ORD5l/vjXReTj5kDhS4FPmzM1P7t3yFeIyE+JyKmI/KiIPP6Ar+k1wFeq6tOq+mbgH1IDyotewx3ZtfNZmznr8ZUXndf+fUXkq4CPBr5pfl3fNGdRvm7OaNyasymv3nv61wJ//H5ekKq+HngT8Or5uVVE/pKI/ArwK/PXXiUiPyYiT4nIL4nIp+69rpeIyP85ZxXeALzvueuwX05aisjXiMhb5/N+nYgsgbMs0835NX7EfmZJahnqq88d9/84yyiKyHuIyA+IyDtF5NdE5L+95LW+Hfhx4M+eu+k1wLffz/U6dw4fAHwu8Omq+mOq2qtqVtXXqepn7d3vMRH5X0XkHSLymyLyN+XOsvCbgdcDf/mCcx6A75vP8fw5f6eqpmd5zn9ARF4vIjfn8/kmmbOfcjvb97Pz9+HTnuFYf2U+xm+JyGefu+0fi8jfnD/+2Dnj9EXze/YdIvIpIvKJIvLL8/vqS5/N6wBQ1b+vqj85/2z5TeA7gY96tscx5n5ZoGUeNf8R8EsP+NjXA+8ntaQTqEHAe4nItfkX84cAP7n/AFX9EeBvAd87Z6I+eO/mPw38eeDdgJZn/qv3rfMvhm/bC35eBLwHsB/A/Szw+x/wNd7XeanqX6O+1s+bX9fnAX8M+BjgA6jZjk8Dntx72JuBDz5/rPPmgO2j5tfwb/du+hRqhuCDROQI+DHgu+bz/Azgm0Xk7HX/z8AAvDvw2fO/y3w19Xv3kcCLgS8Cyvxa4HYm8fXnHvdd1ABa5vN+0XwNvkdEHPB/Ub8X70nNanyBiPznl5zDt7MXaInIBwL/CfDdF91ZRL5ZRL75kmP9EeBtqvrTl7/k3XMm4P2A/3Q+9/Ol4C8D/rKIvPiSx/+p+b2PiDwGfDLwHc/wvBfJ1IDuceAjqNfrcwFU9ez78MHz9+F7LzvI/IfNFwIfT83yPlMP2MuBBfV79OXUP1I+k/p++GhqVvWV87H/9BwIXvbvvS95jo+h/tFgzEFYoGUeNTeA0wd54PxX/E9Tf3B+KPBz1LLjRwF/EPgVVX3y8iPc5dtU9ZfnMub3UX+xXuQJ4MOopcEPAa5R/0oGOJ7/e2vv/rfm+zyo+z2v8+L8vK8CRFXfPJcMz5xSr/+9PEEtWX0r8FdV9f/Zu+1vq+pT83l9EvDrqvptqppU9WeAH6D+4vfAnwS+XFU3c+ntwszQHBB9NvD5qvqbc+bnX6nqeB+v9yepZbKPnj//U8DrVfW3qN+vl6rq/zhnNn6V+kv8sh6pHwReJiIfOX/+GuCHVfWdF91ZVT9XVT/3kmM9zrky+Byg3xSRQUReISIvo2Z3v2C+Rr8LfN3581PVfwf8KPDFF5zDTwG/A/yX85c+Ffjl+THPiqq+UVX/9fy9/HVqD+X5suT9+FTq+/cXVHVDLavfSwS+SlUj8D3Ua/cNqnqqqm+iBkj/8XyO36WqN+7x7zfOH1xE/jz1Z8VXn7/NmKvyQuulML/3Pc3DBSE/AXws8Pb546epvxBG9kqS92n/l+GW20HTHVR1TQ3wAH5HRD4PeIfU3pn1/PXr1AzO2ccPFEw+m/O64Dx/XES+iZpNem8R+UHgC1X1ZL7LNeDmMxzm8XuUnd629/ErgA8Xkf3jBWq/00vnj/fv/9bLno+a0fj3z3Bed1FVFZHvoWbT/iU1E3hWln0F8B7nzs9zLuO5d6ytiPxT4DUi8nrgzwAPuqjhSWomb//47zVnYSMg8/k11PfR2d0cd16zM18OvEFEvu6C276DGhR+FzUj96xLnbArd34tNShZUb9/b3yAQ73Hucdd9n0/8+TZ4g7grG/zd/Zu77nP9/95UtsI/g7wcar6xIMcw5j7YRkt86j5OWpp60GdBVofM3/8E9RA6w9xeaClD/F89zqeqOrTwDu4syT3wVxeqthQf5GdefkVnMftL6h+o6p+CLXs9wHA/qq138edJc6Heb63AT9xLqNwrKp/EXgntST2H+zd/7KyzhPUAPV9L7jtfr5v303Nor2CWtb8gb3z+7Vz53dNVT/xHsf6dmpG5uOpQek/v4/nv8iPU0vaH3qP+7yN+sfB43vnd11V7yo5q+pbgH9G7TU87zuAPyoiH0HN6n7XA57z36culnh/Vb0+P5fc+yEXegf3931/1qSO9ljf49977933E6gZzE9W1Z+//KjGPDwLtMyj5oc4V5KQOh5hMX/aishCRC77If+vgA8E/gDwhrm8cPZL9q4l+rPfAd5nLlM9ayLy4SLygSLiROQl1BVlr1XVs3LhdwB/XUReJCKvAv5r4B9fcrh/B3yM1JlYjwFf8iDnNPsdYDeLSkQ+bD7XhhrQDdy5wOAPAT/8EM+3758DHyAif1ZEmvnfh4nI75szFP8M+AoRWYnIBwF/7qKDqGoB/hHwtVKb173UpveOGrCV/dd4weP/7Xy/bwX+haqeZbDeAJyIyBdLbbb3Usc0fNg9XtNPUjN+3wJ8j6pOz+aC7J3TL1FLb98jIh9/9vzUHrSz+7yDWhL8GhG5Pr+33ldELivX/Q/Uvr07Sr+q+lZq+fy7gR9T1QdduXsNOAHW83v4L567/Y732j18H/BZIvJBIrIC/sYDns9dtI72OL7Hv98AEJE/Qi3t/0lVfcO9j2rMw7NAyzxqvgP4xLMG3tkvUUsE7wn8i/njV1z04Lnv42eAN+39Inw98Na5z+Ui/3T+75Mi8jMPcM6vpC6XPwV+gZqJ+Iy92/8GtfT1VmpW7e/NTfgXnf+PAd9Lzey9kQfPmgB8AzWb87SIfCO1ZPkPqeXUt1JLWF8NICLvDnwQ8L8/xPPtqOoptXn704HfopY7/y7QzXf5PGrJ57epQee33eNwXwj8PPD/UvvD/i7gVHULfBXwU3N/0x+85PHfTW263mVz5mDvk6n9bb9GzZx9K/DYPV6TUt+fr+AZGsqlrnj8B/e4y1+iBuRfO7+mtwNfSV2gcNZL9BrqYodfpH7Pvp9zJce9c/s1aln26IKbv/1+zvkZfCG19HpKfQ+db3j/CuDb5+/Dp3IJVf1h4OupWb3/b/7vc+3LqN/nH9rLdl3VHxjG3EXqzw5jHh0i8reA31XVr3++z+VdhYh8DfDvVfWylXLGGGMewJUEWiJyg/rX4KupfROffcFSa2OMMcaYdylXVTr8BuBHVPVV1EbfN1/RcY0xxvweIiJfekkzupXnzLukh85ozUvYfxZ4pVod0hhjjDFm5yrmaL2Suqrn20Tkg6kNvJ8/NyXviMjnAJ8DsFwuP+SVr7yfBSrvWnLOeO+f+Y7vQuyaXMyuy8XsulzMrsvd7JpczK7Lxd70pjc9oaovfZDHXkVG60OBfw18lKr+GxH5BuBEVb/ssse8+tWv1l/4hQfZh/WF7S1veQuvetWrnu/TeKTYNbmYXZeL2XW5mF2Xu9k1uZhdl4uJyBtV9V6z7y51FT1abwferqr/Zv78+4H/7AqOa4wxxhjze9pDB1rzALy3zZusQt1s9Bcf9rjGGGOMMb/XXdVeh/8N8J0i0gK/Sp1QbIwxxhjzLu1KAq15N/gHql0aY4wxxrxQ2RY8xhhjjDEHYoGWMcYYY8yBWKBljDHGGHMgFmgZY4wxxhyIBVrGGGOMMQdigZYxxhhjzIFYoGWMMcYYcyAWaBljjDHGHIgFWsYYY4wxB2KBljHGGGPMgVigZYwxxhhzIBZoGWOMMcYciAVaxhhjjDEHYoGWMcYYY8yBWKBljDHGGHMgFmgZY4wxxhyIBVrGGGOMMQdigZYxxhhjzIFYoGWMMcYYcyAWaBljjDHGHIgFWsYYY4wxB2KBljHGGGPMgVigZYwxxhhzIBZoGWOMMcYciAVaxhhjjDEHYoGWMcYYY8yBWKBljDHGGHMgFmgZY4wxxhyIBVrGGGOMMQdigZYxxhhjzIFYoGWMMcYYcyAWaBljjDHGHIgFWsYYY4wxB2KBljHGGGPMgVigZYwxxhhzIBZoGWOMMcYciAVaxhhjjDEHYoGWMcYYY8yBWKBljDHGGHMgFmgZY4wxxhyIBVrGGGOMMQdigZYxxhhjzIFYoGWMMcYYcyAWaBljjDHGHIgFWsYYY4wxB2KBljHGGGPMgVigZYwxxhhzIBZoGWOMMcYciAVaxhhjjDEHYoGWMcYYY8yBWKBljDHGGHMgFmgZY4wxxhyIBVrGGGOMMQdigZYxxhhjzIFYoGWMMcYYcyAWaBljjDHGHIgFWsYYY4wxB2KBljHGGGPMgVigZYwxxhhzIBZoGWOMMcYciAVaxhhjjDEHYoGWMcYYY8yBWKBljDHGGHMgFmgZY4wxxhyIBVrGGGOMMQdigZYxxhhjzIFYoGWMMcYYcyAWaBljjDHGHIgFWsYYY4wxB2KBljHGGGPMgVigZYwxxhhzIOH5PgFjjAHIFBKFgu6+Jrv/1o8cgkdw9jeiMeb3CAu0jDHPK0UZSXcEWLdvu/OjDEQg4GjwuwDMGGMeVfZnoTHmeVMoDJcEWfeSKIwk9Fk+zhhjnmsWaBljnheJzPAQwVKmsCWSyBZwGWMeWVY6NMY85yYSiXLf989z75YCBb0jAzaQWBAIOAu4jDGPHAu0jDHPmXv1YwEULfSxp2hBRMgokQwiCMIiLBCRu445kOjwjJLJFLwl640xjwgLtIwxz4lnCrJSSQxpoPMdjW8YNQEZD6gqqSS2ccuqWV0YbI1k8vwcHcGCLWPMI8ECLWPMcyKSLw2ypjwx5YllWOKdJ5LJorfHOAh455EsbOOWZbPEyZ2BlKJMklGwYMsY88iwQMsYc3BnM7LOU1WGNKAoR80RIkKiEC/p32p9i1CDrUVYAODE7YKusyBrQWAk0eIJ+IO9LmOMeSYWaBljDm4i3/U1VWUbt3jnWYYlUBvdL7ov1KxX0ULRQsqRJ6cNR+0RAIuwILiwO0aiEHC7Y1mwZYx5vligZYw5qHjJ+IUhDQQX6EIH1ABpJF14jDGNZM00rqFxDcuwJGtmSAOtaxnSsMtw1eesgRZgwZYx5nllDQzGmIMplLpq8JxUEkXLLsg6a5Q/C8cEYUFgSYPmTCqJZVjS+Kb2aokQXGARFsQSWYYlQxpIJe6Ot1+qnOYBEcYY81yzQMsYczCXlQzPZ6BG8i7I8jgWBBxCLgnNicea47tWGgIEFxARihZWzYopR2KuwVY813p/WUnSGGMOyQItY8xBpEtWGU55IriAd7WUN+3dL+Do8AiQSy0NLsOSVgLdJZ0One+Y8oQTxyIsdisYz2e1Ckq2rJYx5jlmgZYx5sopeuHKwVwysUQ6f7sv6ywYcgjt3EelqvSpZxEWu4DMIxcGW955nLhdsLVslsQcSSXdNbXr2UyjN8aYq2CBljHmyl3WAD/mkc53uzLgfv/WfpC1jVta3+5WEp7xCG7u31oQOCsmdqFmtVQVJ+725+eyWrVTy4ItY8xzxwItY8yVKpfMzJryBEDjm/l+uuvMCjjcHDaNecQ7T+vbu44hCNfpcHsBl1BnaQUXSKWuWgwuoKo1g7bX/wVcOqPLGGMOwQItY8yVuiiQUVWmPJ0bwVCzWYLQ4FFg0sS2jOADI5mBdMe/syzZ2cR32Qu2Wt8SS0S13qf17S6428+c5d321MYYc3gWaBljroxe0nA+pIHWt7sJ7rU3q2a0HDCQuMXAk3lN9EIvNbDKKGX+tz8Xq5YAa7B0Fqg5cXjnd8FVcIGsuQ44PderddHICWOMOQQLtIwxV+aikmHRQta8KwUmCqeM9EQSmZ7EholJE1OZcM6T5/lbZ8FWwO0CrTNx3kQamIdBQOtuZ7VE5NKsVrKsljHmOWKBljHmylzWm3UWZJ2VA8/Ki/vN6lOeaHx7x7wsRZlI3D1BqzbPj6Td4wMOEaFxDWMeAWhcQyoJVbUViMaY54UFWsaYK5EuWGmoqqSSavAzl/zOskn76/+KFvJ8v/MCjnjBRtOC7PYz3N9yp/XtbvL8WeB1ltXaL2taoGWMeS7YXofGmCtxUeASSyS4QJSya0KPZCbybpwD3JnNGtNI0bnMp0ohMFIDq2vhiMVeMNbgSHOZUXEEvZ3VijnShY7GN3VchLZk0d0PvZpNy7YHojHmoCzQMsY8tLLXnL4v5ogLze3y4BxkOQRBSCWRS2Y7bVk2S25NT5O1sGqOaHxDK54GjyBkzZykNSWsWLk68LQ2wteMV6JQZC4jusCQBjq62iQvnlgi4gWdJ8/D2ebTFmgZYw7HSofGmId20UiHVBJJFHU1rCkUtvMOhIKwjhu2uWed1qjANvdMTmkWK9Y60OtYVymKgNTgadWsWKct69zvnme/Sb5QVzSeTZPPpWbG9pvi98uHl62SNMaYq2IZLWPMQ7ksWNnkAdztIGg7736YKQyxBkpt6BhLIrsCztGGjogiTcM6Dqgqx2GFzDkoJ0LbLNjOt12bb/PIHWNJC7obYOqd323TE3PEebkjOEuU3VwuY4y5avbTxRjzUC5caaiJUeNuCnym0BMZyUxpRFEWzZIxDWxyvwuyzogI15ojphI5TZtdWbKgJFFc09LrxDpuUdU7AiWHkCk0viGWuPv6WVbr/GAHy2gZYw7JAi1jzEM5H2gpsM79HSsI10yMJKY0IAqLsGQskafGWyza5R1BFsxb8ohj2axImjlN6zt7wERwTcsoiSENe11XlcehUvvAzsqHwYW62lHv3iLIgi1jzKFYoGWMeWAXjXQYNZFK2s3OmuaBpDFPUJQuLIhSuDnepA3tXUGWztPiAToJXAvHRE08HW/dFRBpCAwaKaXcEWw5hHRBVuusnHj+OBZoGWMO5cp6tETEAz8N/KaqftJVHdcY8+g6nxkqKEMZCS4gIrsp8GMeSTlxvTlmkkIqiTGNrNojxjTsBpf2JGKKHLmOpWt3KwZdaDiJG8Zyi8fcikXddAeAyddG+pVb3XEuDlDnSHHafS24QMyR4uu2PmcbWecLVkwaY8xVuMqM1ucDb77C4xljHmEXjXSIFGKOdY4VmQ0ToyZijqyaZV2FiLIe1+SSaUOLE08RIQMlJlZ4JGdyyWTNDHmkjwOUQh97bjGyZmQiAeB9YEt9jn0eRxYQcaQy31c8WTOqekdwdTZA1RhjrtqVBFoi8l7AHwe+9SqOZ4x59J3PAhWUsUyICOqEiVyzVGmg8Q0qgqL0sWc7rbmxehF4T/T1vlOZuNaueHzxEpbd8dzQ3rJslizbFUftMSVGxjSyIdYgjoiieN9wmvs7ypg1W6XgbgdaIoITR9Z8QZ+WZbWMMVfvqkqHXw98EXDtsjuIyOcAnwPw8pe/nLe85S1X9NQvHE888YRdl3PsmlzsUbgug6Q7QpNRMn3qEecovk5sH0ic5i1t6OrQ0Bw5GW/hxfHO1ZqE1t4t6qrAY2357fnvv15HUp5Y+RVe6lysKY1s4tvoFkc0LtCqp1NPpw6Jiadu3qLArl+rDjLNlDixCitEpJYOKXS+o1O/Kx86hE5fmMNLH4X3y6PGrsnF7LpcvYcOtETkk4DfVdU3isjHXnY/Vf0W4FsAXv3qV+urXvWqh33qF5y3vOUt2HW5k12Tiz3f16XMQdSZjDJoZBM3+KYjizKSOIlrXu7A+4aSE6fTKTfkxWQPjV8Q00DwDY2vG/Isacgl17KkwlQiOU9ca44J4gkusB5OGYh07Yqla2lwdAQWGii/+Bbe5/3fh4U0dcUhhZFMjCNHfkFwgaKFbdxy3B4TcHdsBbSk2c3seiF5vt8vjyK7Jhez63L1riKj9VHAnxCRTwQWwHUR+Seq+plXcGxjzCPofJktkmt5TgSVuhqx9lgV3Bxk9WkkOhhFaw9XGgm+QbwnkgkEtnnktL+J4FCUiUQphVvDCY81Rxw3x3WVYql7IopXgl8yklCB4iDlRAp1657aMJ/BOcY8EVzASd0AqGghy51BVbljgx5jjHl4Dx1oqeqXAF8CMGe0vtCCLGNe2Pb7mzJ1BV8qieIEpZBR+tyDd5RSSHkiOiUiZE2E4smiiHeAsiKQppHNtOa4u07XLHBA1LwbctrHgZI2LMMCr8Ky6ejTSMCx8B0TiRQcqUyM6glzQOUR1AXG3LNSRUR2Yx6cd+S94CrblHhjzBWznyjGmGelnJutHqmr+Ead8C7UbXZKJmpBvSfnSJK550oKBWHQCR9aBGgLjP2aOG55rL1GEEerQkfgWDqW0rBslrTNEoKnzyMneUOKE4tmyTbX7XgUGFyheM+Uht3+ix6HiIAI8Wz1ofO7Bvl8Lmg0xpirdKWBlqq+1mZoGfPCth+MpDnsiiVS5s2fM8qYB3KQGmRRiCTUeyZNaEk0vqWUxNifcnL6FDEOHLXHHLslR7SM816GAC21DNj4hgy07QInnlvTKVoSznmGPOzOaXJaM2El3lEKDL6hL2P9eO7VsjEPxphDs4yWMeZZ2S8bnmWN+lKzWYl5GKlmRGr2qYij10hykOJI8C1OhBJHROG4u8bLrr0717vrtK7BKbiirMdTVJWAwyMsXH1cFui6Fc55bvY3cQh9mShazyWLgvdMZSKSEQSH4MWTNO0COC81q6V37X1oWS1jzNWxQMsYc9/2y4Z5DlGyFiaNhLlsOKaazerzgHeeSGTyypQmPJ7gG0qcKDmzdAuO2hWaM8O0YZt7soO2WRA18eT2CTZpy1giiUzjG4Y8UpxwtLhO0cImbhBxjHm8fZ5O6MtIRue+K7ldPtRaMjzr06qvZb98aBktY8zVsUDLGHPfzpcNAXqd8OIpokw5MkmhCExzlutW6XGuIY49XbMgpxFRwQFFlG3qSWR809E0C5wPtL7lPZbvxqo5IudEyYnttAFxdTxDmYhe6boV29iz1YnT0jMQGUj0kuglc1p6JvKuwd27wDjvfRhcIGu+63WVu3Jcxhjz4K5sr0NjzAvfWXCl1MxPpjDl203wsUwUL2znafBrHcgilDQSxM8bRs/ZLhyLELjuV7Tzj6Kz/QfrGFHhqFmxjVs6FygibOKa4Bo2uSe6Ba5xTJMy5Q1HYcWYp/ncFHGOk7yp+y4CQi0XTnPmS0TqrK2SEXfnSIdMIfDCHF5qjHluWUbLGHNf7iwb1oBr1ETWXEuEmomaSShZM9k5NmXEO0+OUy0ZqjKVRMoTR90xC9/S4EkUNtSeKqBuyUPGiatZsBw5oqX1HadlYCiRXDIqtcxYirLViY2Ou3Kgc55RE5MmtkQi9TwLhTT3c52VD3UeUXHG+rSMMVfFAi1jzH05XzbMFJLmulGzKClH1AmbPIB3jCSSZkSVkiNFFC+OYdpw1F0jhAaPY0tky4Scbb1DDYx6JkYSkxRcaIlponMtjWsopdCnLUrdVHrhO2KeGINykjb1JEUQcWzLSKGuLhxIOHFMert8eBaY3RloWZ+WMeZqWKBljLkvZ2XDcjaglELKcVc2HMrEQN0+J3qZJ7E3xDiSRQmhZTOeIC4QuiUTmUihp+6Z6FVxuZDjSEojsdTbo2ZOy5Z3xltspjUL37IIHWMcGXVCXZ2TFcSTS2LDxJRrI3zrG4YyzmMoakYuOujLWJ/T1XJm0XJXFsuCLWPMVbBAyxjzjPbLhmezs5IWsmbEOWJJdX/DEsm+bp8TS0RRxjTQNAvSODCWSLNcMZJ3YxlyiqRphBhp1XHDH7GUFmJks73JyXCLrUZ8t6AvE5u4ppAJCJv+lEFrYIXCEHvW04bf3P4227Stg0m1sNWJQp2T5Z1nW0ZGbq8+zCXfFVgVKx8aY66ANcMbY55RPte/lKhB1m61Yar9VROZ4hwxJ5x4pjyRNLNQ5TT1NItV3d8QZZ22NEVoXGARVizcAoCxJMYSmSTTNF3d0kdHCg7vAoSAkiFEbt36XVJJHDUrOgn40FC8kF3LzbShaF0BuS4Djfe0+F1T/lYnGnG7eVqNb3bN+GCBljHmaligZYx5Rmdlw93srLls6OaM0aSJSZTkay9ULoksmZQT3gW2sYc2EJqORGabepYacM2ChXSIOk5KT8wT/XDKIiyhDVSGwI0AACAASURBVKgLBBFWGjjNPUkzoTjEORDh+rXHGcY1Q9ciCItmBVDnu3shiqIpEedp9CsUT6E4YSwTg2/onKPk26/PAi1jzFWyQMsYc0/ny4aJQtG6stC5hlhGJjKjThRX51xFTaiClkzSDA7a0KACN+MpDZ7gO3xRXIms8wCq9HFL4xsmyfRxAoGlX9C4hi60TCWy7k/w7YJls2QbJqQE+mlAg+JEaELLlCKikUW3oJOO0/6E3jcswnHtMBNhW0aWfkEQqeGjKlkKzdxRofP/BLnX5THGmHuyHi1jzD2dZXbOZmedlQ2dOIoofambRU9OUaEOGJW6z2EkM5UJDR71jnWsKwKPwoqUBso41MZ1qSsCm8URy6Mb0C1wITCROUkbNtMGnSJhngw/lhGcq83sTaBIYYwDkUzwDaAUzYxlQr1j0a3YThu2edz1aWXNbKl7MYo4sua7sljWEG+MeVgWaBlj7umsPyvPua2CkkpCnCdpZtDIqAl1NTM0lglF6/yqvEGDB+/r1jwU2tDRxzU5JZbdEYvuGs4HmtDW7Xi04ETowoJle4Q0DZPLDNOWaXvC8dENRo2s0xaPI7gGCQ1JEkPcIs4jIoypZ4wTCcWFUDeVzkMdOTEPK02aGEgUB7lcPCXeGGMehpUOjTH3dJbVOSsbApSS8U3LkLckCiOZ4gLTPDahT1sGjRSkztTKE8F5fGgZpi2L7LjeXkOLso0bSplYhSPiNDJxe+Bo6z3Od4hAn0+REshaaH1HzBEnwsKFun+hbxinLX2/pjgllUw/rhGUo7CiaJ2hNaSR0Hicc+SSiL6pY+NLoaOjoHjr0zLGXBELtIwxlzoLsspZAzyFovNugALbeUaVekeiNr9nMr1GcppwPlAA7xwlBNLUE5Jy3NygpFTLgLHnenONMY91cKn3eN8gGpE4kgSGPNF1CyiJGAeUggueKUca39CqJzoYNSIlcdxdZ6MQ1IGrA1ULMMQBCUpTWhYukHKk+IKKZ6sj1+bXfNanZYGWMeZhWenQGHOp/WzWWUktlYRznqFMRAoTieyEqJmsmVt5QwEyGZk3bi7eM049JUWO/BKvgsMRfOBl19+d5ugYXS6gW5CdsE490TtoOqYS2eSem2lD9g6CYyoT27jGNw0xDoxTD0UJyxWTU1Ka6PyCUjJFC+I8y+4I5hLhmAYQqeMfUBCZG/rjXut/VaxPyxjzECzQMsZcquz6s/SOsiHO0eda5ktOyFIomhjKRCpK0oS4hqwRQsMYB8o0sPQLVtISxBN8wDnPiQ6cxDWbaQ0p0qinVSFvN8Q0UURoV9cYfOGd8SanoRAbz5Qmbg63mEpEvCd7IYQF29wj80pCxEEppJIoAi60ON+wiRui5t2m0pmCd55bpbd9D40xV8oCLWPMhc4CjrOy4S7o0gwIvU4kLagXRjK5ZNalNpujIChZarA29KccdddZ+o7GBRrfcjKdstFp7rlqOW6usWqPaZuOFy9exFFY0a+fZswjQ5lofIM6x5RGYnA4F9hubkHTztPdE8U7ohNOdQAtOO9IGmsvFgUnHpyA99yaTuom0/NqQyeepImeeMdqQysfGmMehgVaxpgLnQUb+9msVBIiUre90YQ66lBQlNPc16Z371EtDJoI7YJ1f5Nle0QngZaA+MDT402SFxbdimXoKE6YpE6WF4SEEgOUrgXvoWTGqafzLV4cOUVoGmgCfeyZHPiSKZpxbcc69TVgEgAh5oiqok6YSmTVXWNIA32ZSKUGWt55cskMZEby7jpYoGWMeRgWaBljLrQ/1mE3Gb5kcJ6+jETNtQGdTCyx7ls4Z7OmHGlDx5QGvArLsMCJw4WGk3jKKIWuO8Ih80bUSsDRZCX2a57ePMmT63eSHcQ4ICkTS6aftjS+hZRQzRyvbjDkkaSJkUJJCfGeAjgRVJUitdyZSkSdzIGT0i2O2IzrXR8Xc7mxaGHLtDc/TM91bRljzP2zQMsYc6GzpvC4l93Jc0brtAwUgeRrIHZaBqYcceKIJYJmnA9s+vWczWoQJ5zEUwpK1y5YSkPAsSRwnQ6dBrbbW8QSKTkRJFByRnDEaaQpkEtks72Fm7fgibEGWdu4hdDSp4GFBBoXyEVRByq1fJjSRAZEHGOZCKHDNYFt3JA11+135sGltcnfslrGmIdn4x2MMXc523ZnP5tVV+gVEolJIwTPRKYnMeaRMY+s2iOmfkPXrdhMa7rQ0fkWRNimgZVfkHOmc20dbkpGU+LWuMEVaJuO4hxtCCyallgSvdbJ85v+FqMvxGkitA3t6jrMmbAhDhQniCpDHvHBE2NEfIdQcOKYSqQpGeeEpAVHoW2XDONNxtjTdW3dJHseX9ETWcw/IutsLWOMefYso2WMucvtsqHe/rhkxHk2ZSCjjC4zkejLyJQTqO5Kb4iQ0sSyXdJIw6b0dUPpkml8w0IaSimMw4bT/gTBcbx4jFVzTEwTyUOSgoTAqjli0a446q7hp8KiW9GEjimNyGKBeM9qeZ08DiRNrPsTijiSzH1lbs5GlUIqIzoPKlWU4hxNt2Q9rskUnPN1VSW1JHp71aWNeDDGPBjLaBlj7nIWYpxNaYdaNlQHJ6mvexo6xykTaR4i6kNLnnqapmU9nLBYXiO4hkEnUhCWQNHMdfcYTmE9nBJz4iis6EJLJNNPa7LUAG+KAwiUogiwbBbI0YspHjZlREtkM5wi3tFoZNkd4fwpU544HW+ycotdT1l2hSYLKUU0LGEOCKMIi6ajHzakkmikm1dV1tlhkUxHsNKhMeaBWUbLGHOHs7EOeW9IKdSxDlGUsUSKdwzMm0bnaZ7QHkg5M+YJ7wOND0wktpJYuA5S4ppf0YhnHdfcjKd4H0i+0FMb1b0PLBZHrMKKRbtCVZnyQM6JkGuwtWyO6MKCTgIlR0qKxBRxoQVRQrsgoWxjX7NU4ohSyBSkKLFE1LnaBE8BHxDxjHFARRFkVz4cSLtGeBtcaox5EBZoGWPusD/WYfdxyajARkcKhezglFhXHqaxzqbKdXXfFAd8tySK0utEE1qaAk6Vpe8Y0sDN/hYLaWnbBTQdrukYSAySKVL3GnQxsZSOx5cvpfUNre9oVMg5cb05pm0WtL5FUyKXQtSI94GcEt4FJjJDjuQSkRAoZFKOUJTslDyPdUgkmm7BEHuS5toQP5cP436PmmW1jDEPwAItY8wdzgKKuJfPSiWhImzyQBYlOmUgkkumn3qa0JHzyDSNtMtjshd6jTS+I4gn58jSL8k5c6u/yZhGcgg8mU/p05Y+9fRxCyEQ1ENMrAjcCEeUONJkan6tKGnYQi6smhXHzTGtNKQ0MeYJnMdpLXNm7+h1ZMwTKsLk636HJUdUHINOCDBR6p6MWrNzMg8xBZjIFmgZYx6KBVrGmDucNcCnvVJZ0cwkhU3uIQROGWs2KE/kkmicJ5dCIiJtx0AEAbxHVfHqCBK41T/NU9sn6LojdBFouhXFC6d5y2nuiXHkZv80m9wzUTid1rSp8JLuRbykexHH3TGda9hunmaVHDfckqP2CFElxZGimbZbEuf+roFUe8hyREJL1EhMEx5Xtw0qNZAqrs7eijmCyC6jVebrcL6Maowx98sCLWPMzv5Yh7OyoaqSNLNhql93yoZI0swwbGhci1PHOKxx7YLsClEzIXQICrnuX3iyfZonNu/k6OglNMdHZFdjMcQjItxYvZhGPP20Zcgjkyskr9Auau8WgWO35GVH78bSLyEVQhEa8RyHFTEOtbfKO4Q6fHQik4NnO20RH0hSSDmhJaPiGUus4ZN3iHNzObFeA51XUaY52LLBpcaYB2GBljFm5yxrM50rGxbRuWwIg1MihVwyMdYerJwjm2lDu3qMrU40vkXEoQg+FaZpS9+fcu3oxXTHx5zqyJAGTqdTbk23GDWBwnZcc/3oBsvuiJgnpCiDL9yiZyKzJNCJ58biMQLQEFiGjjYsCBmmNFByogkLiJFJI6NXEpkxDdA0RE1oKTQuEDXOAVnChQYFhjzixNUxFdQSap6DLCsfGmOeLQu0jDE7Z5tI75cNs2Z6KWxzj3jPCQMFZZpLdcEF+nGLaztSyGRRvK/jPTUnZJro45bcBvxqxUlacxpP6SWxcZmTMlAo/M7Jb9ZSnwcJgZgiRRUvQqbsprVnBOc9rW9wCB0Ni9ASQoNOkZTrNjyaC0EC67RBuo71tAHvKXPQFVwgatlNglfn0HlzbIXdmIe8d00s0DLGPFs2R8sYs3PWi7Q/oDOVyNZPJM2MHgYySQvjuCH4Fodj09+kuX6DjUZ8U78WFGQYmbJSNHO0uMZJWrN2heKUkCfImSYLUxmJDkLX8VQ8BVVWvsVJweWM94GeCWhY0ZCkYSsDS2lJJbNolnTNkjLvd+gaQQScQkwTUyt4B7FkPMqUJlal4OeJ8c57inNkVVpgKgmHgGcuHxY8YoGWMeZZs4yWMQa4PSdqIu3CiaJ1vMG2TCSBXlId5KmJOA20TUM/rutqvs6THLTS4HGs4xbNiZhGmuDpnXIqiVgiXoXGBdqsSMmcDqcohc14Qh97bm6epNeJ1DhintCSyWROGBmIHBEI3rMuPa1vkJx50eoltTcrTaQ04aSps7JKzVqlxjOUEfWeMQ/kkgiumWdmFaJTiiiI1BEWersh/myA6/6+j8YYcz8s0DLGAMx9SHV21O5rJTO4TJ+2dWSD1IxXHHsKuQ76HDboomVwiguBBkeftricaJKQNDF0gbXWjahDaAki+FhwBNqm46XXX8616y8hrI6JTomiPDXc4lb/dB0nkSJePQs8I3XA6cotSICKENQTRDjqjhAcpISIIipA7d3KTmo7v6uZuzHHefPpWjrMoqirqyQRIea4a4g/Kx/G3VUyxpj7Y6VDYwxwO3OT7wi0Ej2RWApDV/f/yxTi2ONdQ0mJsYykxRHqYCWBWDIUpcnCzfFpFovrFB+Q4HCayXFAaCnDSHGQJDCWgTKUOnU+JZaLY8iZaRp4Z6kT3Zup4T2OX4ZSKHgSmaVv2OYtPjSUtGURlnTtkm1/C0ohtA2TJlKeaJslk1OSQiaT0oi0KzyCaiFKpnGOXGpfWJr7t4KE3bVxc/nQ1/WSxhjzjCyjZYwB2DWc7+drJo2sdWSSzCh19V7RwjhtCW3HMGzofSEHEB9Q1VoqdIHN5ibiA361RINnSgPbYY1TIaiwTlvW45p1f8Jpf5MhDQh1G54mdKyaFU1oCa5hsTwmp8gTm6eYNLNhJFFwLlBUEecQASlK23Z07ZKSI5ILKKScKSWTPYxSAGEbe2KJBNfUAacoydW1hTD3ZpV0+2Nur0I0xpj7ZYGWMWavP+t2EFG00JMY8kj0SpI63DPFiZwSDsc290yth9CizpHjSPANw/YmZZpYLq5BaDjpb9JPPV2zoG0W3No8xZgnwnLJtesv5nj1GBI8/XhKngZSHOrxRFgPtxjjyPXjF7OJJ4zTFlVlJJEkgyhaFAltXReosFxcR1RIcaDzgSmP5BwR5+llQoNjyAN5bogvZd5EWwpJ6mt3ztfthWCeosVcPrQ9D40x988CLWPMrgcpn+vP6iUxlMgYZJ4FD+OwhsYTxy1DUJx3SPDkPBGkbl+zvXmL1dENwuqI7XQKTlitrhM1Ma6fJqbEteMbvOjocRZhQSMBp8JRc8SN5YtoCTgRusWKdnmd9fppnj59J83iiHXcMo0DaF0B6V3gtGxxInjfkvKED4GuXZBjJBDQokxzdiqi5NASNTOlHpwgOpdOpc7UEhHEe2KujznL8+W9vQ+NMeZ+WKBljLlwTlTSyEYHRhLZ3S6Z9eOGxjVspg3ZC9q2FCdIrrOotreeovWB1dE1xjQwaEJCy8nwNMSEU89Rd8SqWVFSxGXl2C15sTvi8eYaTYESB05PnmCMA21oefGNlzFpoh82qINJJ9LUo1rIc8lwIuOlqQFTSSyX1wChTBEvjqQTWgpFYPIZBNbTGlXF4ciaUREGMoiAKrHUhvj9a5R3+S1jjHlmFmgZY3b9Wfs2ZWSrkcEXkigZiHliihNZ68bS2QFtx5QnOgmM00Ban3L9sceJWjjJW0K3YDOe0rjAY36JqCJdw0AC78A5+tQzDVva4rneHPOyo5dzrT1m7Dek2DPGofZJaeLp4aQ+dymMU09C6+bQmoiu0ISWPg74pqNrlkzDKUvfkGIml4Q4z0BCm5ZN7Eml4MShWrNXgyu7SfDiXN3/kNvlQ51XHxpj3jWUh8xiW6BlzLu4/flZu69pYUtkzCMpCBMFULbDGhEY4kD0njRvHC05UQTizac4Wj5GkMBp2iJdxzBtkeC5Ho7ZjBticGQtBNcQ48jptOFkuMWiWXC9PeaaX9CElsePX8pLFjdYuQXHy8e4fvwS4jQiAje3N4le8QpD7EEcrihRCq5pSJrIZJara2gp+OLIaSJrRhCiJli0jCkSc484QUsNooooAxmRuhljzNN8ne7MbBljXtjOtuca9n42PggLtIx5F5f35kSdSSWxlcS21Kb0OJcV++0JLjRknchBkbaj5Ih3gTROuKy03YJtHpCu9ktNJHzTMQ1b1HlQpXUtcdgQ44ikyGNuyY3mGC1QcsHHOmh01R4hpZDTxKJdcv34JXX0QkncGk7IAloSSRNtkTr6QUC9Y8qRpm1pm44y9HjnGNMIWmdmpeBJoXA6niIIovUaiDjWpa99WuJ2Kw9v92lZRsuYF7pIpifSE3mS7UMdy+ZoGfMu7vYgzttGndiUnq3LFNdRqBPdpzRSxJFcIUqhbVumkvASyOOW1gWSFtrFkp5En3ra5RHtmBCEMQ8spCGliSY0HDfHtAqPuWMWviGjtRFeQdOarEoIHWMcKf8/e+/a40aaXWs+7zUuZGZKVdVtn5kDDDD//08dYI7dqpLyQjIi3uve8yEolaraPnZb7i63Kx5BgAQpmSQFhlbsd+21TGaeHsg9M7pAqZmLuXJy0368ZzyhOwQwzpFawQ1nhmFm3a7Y7hDbaL1ivWeTTBwn3rYr381/wOi+DBCt50ZGDGAttd19WoYvm4f9nuZlj3vVg4P/VvR7p2qjc6Vwo5CPidbBwcG3sPuzfjmhucrGJo3u7J6dhez+K21UaUiMqHV7AbO12FKwtaMWQohsvrPUFY2esDc0s5WEaR0fIlOcGP2Ecw5zr+MZ8HgshUY2nadwZvITo/FYYEsLAcMcJ7wLBB+p0rjUG6hSemaUPUjUWreHoUrFxxFrHe5eUt2lA4YmBTfMrHWlSdl9WrI7sdQIBcFgEMwvplqff/5Smh4cHPw9IwiJSqJyIfEnFp5ZuZJYKd/02IfQOjj4HfN5z/AXtTu638ktsoHzXzbtbusraizdVKo14Oyelt4F7sXRxnn6ELiVhWYN3g3Y3JCaML0zjg9EP4JC75X1+gK9Y7rQesMLWDX7UR4Oa+EUzjxMjxiBNd0Y4oxIZxrPRB/pvZFq2s36NTETwFiaEbIUbBxxPuDx9FxovaEqNNjreLzduxbvm4aCgnEsZKx1cN9i3N+vn2Mevo7CODg4+Pvksw9ro7JQ+MDCT3eBtVAo/8Ki0F/KIbQODn7H9Ht21tf+rCSFlcaiGZzdc6ekk/KCqKLeIdagBroBWyvSK12UMI9cZKFoYxgmfO9oLjg81gWwhrIu1JJwCoMbmNirfGzv+A5zVeYKozoemQBltANPp3fUvIEKzgVUBO8jIQ6knim6m/e9QjAeA/fexIb1gegCtIJB6NKx1u6REPOJ1/QGWJB+92kZFklYYzDWUO6GeP2FT+sQWgcHf880OonGQuEnVj5w443ESiazBzRnrdzat3m0DqF1cPA7RtBfpMEDbJq5yUZzhmb2DbvUErmX/RjRDYh2sBbtjWA9LW+YGMjOkFohDDNeDS1teBNIeaX2Dckb4zAzzg9gDM46TvHMHCaiCUzqmd3EjCfXDaMw4rDA4Efm4UTZFkY/srYNax1DnDHOIbXQpJPLymA8BocY5dYzbhhQ63ECpRakNzDsR4Zxfyyhwb1E2lpH1ka3BsUgqoj+LEh/Pj48xNbBwd8bn48JVwrPrHxg4ZWNG5lEo6FUGktPXOqNpedv+n6H0Do4+B3za3+WojzLwlU29H40KAhv2xsqu7Aw3tJV6RikVWotCJ0eHFnql+lRTiteoNWN1FbicGaenlBnoAtO4YfwyCBgescaQ7JKlt2ab5xjqwtewO0zMU7xDAoiFWsMW880FDuMZK1sZJaWoXes0f2CaRrZ7o83mIDcze2K0lWxzlEsbDXtvitV1PxctyN3WdWk3dO1/uUC7oODg//afD4mXKlcyHxg5dP9mHCj0dmnXItk3urCpa3c6srz8tM3fd9j6/Dg4HfK5/nM15lQRXevwiYZ6yYSfd82TDfECIS4iy1r6L0w+oG8XHDO47xDEUKIlLJBa/Si9LwyjY88hhMxjnjjCR1CbzjdM7ossLSMSCfisMZiQyB7WNtCdxbr3F5S7RwJRa1haxtzMIQw0mIGgVJWQghE60laadawtswcLNZ7tK703jDd463bxZV3XPOF709/vAute8wDmXfWfymlxu0iy2H+LEn/4ODgvy4dId8zsd7ILGS2+761fv5zrWwtU6RSeuGWrzQEH4dv+t6H0Do4+J3yOQ/qa6mwSuFNE9XsHYaVRmqJUhLFdKKPVG10awGl1UqjY/2EqODjiHSh1MpQKlobzg68P3/PND4gKqh0ako8xndYF/D3o0FPxCpYUZZ0hV4x04gJEWmJpBXjPRoiUhemeGIrK9lkTj7ux5U+UErGjx2HxRlFvKf0SjKKCRHT9vwuGwI4T5WKHUcu640/nP64CyprMcbu39NFpFW67pO/z0Lrs7dNUQzmt/gnPDg4+DfQuz0iU7lSuNwFVrlf+z7H26w9sbVEl85SF1LLWOeJYUKd+6bncAitg4PfKZ8vMJ9RlDe9ce17SGm7Z8ms+UqRDeKMcRaVjqpgXSCnC9EHnLV7urrZN/9sKUhKxOGJ2Y2c4onSC9obUR0hDMzxTFBLMO5ebQMeg3WGB+e4bhfyeoVxIviBW7vRe8P7iN4jHcJ4Yl1fGcNICAMuRJzzpO3COD/tRdNYsI7SO2Pw6Ka0XvHSaOpxanHBs/UrRQsOhyWgZl8MEHv+8i516Ti7Oy6+LuL2fNuF+ODg4D+fRqfQWSm8krmRyV/N8PdjwkJqG7W3XWD1DTWOMAzgPOo9Wes3PY9DaB0c/E7Zg/nkF7+/SmLTggmeQqdqI6UFAXwcqNbQRPaYh1aw3YDfhUfzHteFlhN+S7ybvmN0gXM8k1vGGEOwgV4bsxmIpeGwiBHUgrMBZ+51P9YSxhnNyqUsIB7rLLlnsBDDxFY3pnHial5Z68YpRGwY8NaypBs+DBhvsOrwbu9hFD/gTKT3SusFo4FgDM4GqlVubeXsz0QMai29F5oFNYIqdGmI3S+bX2dqHRwc/Nfh8xRro3yZYq0U2pdlFmHTytoTpRVyT9zqiojgQtgn3z6QtZH7endv/cc5hNbBwe8QuRu5vzZzJ228aaFow/qBSiW1jZRXmrGMwbH1uoeURg95I3i3dwd6CAbauqApcx5OnKYzPW2ogSIFZx1W4UkdfxyeeDInjDGkXsitsMgr/S5m8J7gB6p3lKZYbVjZL1etVbyPUDeoe/3Py/JpP8rTjgsTmm5syxtMEy7uIk2dI/e2X0h7o7eGkUZ1Fq8K3rPkjXM4I9Ixdk+Z32jMxu3TK/1cNw0G7hljh9A6OPivQqOT6SwUXkncyF+OCRUl37cJc8t3H9aNqoL1FhsHbByoKKmvNK1UA91+mzXgEFoHB79D+r9QjLxJ4qrL3hVooNAprbCmG/Z8pmOpklFr6HRs75gw0LoQfEBLpWwL78cn5vBArxXLbrCPcWK0ke965DFOPNoTTTql7oP8TKOrIUvGGof0yiobWI9BeUlXhmGiWSH3zslaDJY1XXkYHshtX8u2ITKf3yO9cksLpnfKtqLjnuPV6oYfAmbN9FrxvdOc7GXTMXLdbvyg7xH1WOwuBLUyu0CT3byvuhdPOwyVzog/6ngODn5jvp5ivZLvm4Q/myMqnUUzqWVKyyx1JfdEx+KHiAkOcW73pEolW0GdRQ04+bbt4kNoHRz8Dtnzs355bPiiK2vP4C2VTtXKul1oRngYZprpdKm0GNFaGEygi2I8GIW2LAzDzGgjYxh4uXzg4eE7wjgz2MBZR7woQxjIvZB6whiHxXJiIAx+3xCksrQFh793D448Gri2FRsCqyS2ZeEcHxn8RPCROZ64tY2l76XScThhS9o7E41BsVgp5JYJ8QQYRIVeGy5ECo0YAnnbyNLwpjO4iBhD1oqxI7UVZjfuUy3jAfNlmtXRQ2YdHPxGdORL8OgriQvpS6CwfP6znsgtsdWNtSaaVEyMuCGCCxQpbGWjmIYEj2KwIoy7c/Sbnt8htA4Ofof82ghf6VxlI2sDN+z+LKlseQXr6Baayj4FswZTFOs8rWTieEbL7sE6hYloBl4uzzjvOJ2fcMYxERgFrHE4EbZeQUC14lxgtBGjBiOCRXAu0lrCO083ilWPUTAi+K5ceyKamcEHSsucw0TWSqlvrBTmOOKdo/aKViVME+osm90oUsEZjBpayziJeBMRZ1H2mIloPQMTxhiaNppTRArWOLo01EZgPzr8vLl0cHDwt2fPxSpcKPdU959vIRONVQulZda6staV3CrqwYwDNs6Aci03kpZdYBmPEyFg8cbRpLLpt5VKH0Lr4OB3htxDSr8WB1krz7IHdqp3VDK5JdZ8w8VhP0pshWYtDsVppRAwFlQUSmUaz7imZJORlnn3w/+kG8M79podesei9NbQ3lFV5vHMHhSxdyxW7fuxZs9YYymt4bxlHGbeypXL+sb79/8D0668rJ94d/oe2zpumIjGodr2Gh47MQ4zmleWmrGtY6MlDAN5W3DWYNUgvdFaJUSP4GjekFsihYFJgxWIkwAAIABJREFUG8YYunSqAWvMboqVX+ZnNQR7xDscHPxN+TypulF4I/PG9mWK1emsNFLPbHXbf7aNKg0ZHGE4Y50j1ZVb3WjBYH3cg5NViVhEOm995aaZao6jw4ODg7+AX9fuKMpNEzfZ9pJlOpVOKolWNob5iaKN1At2jLRewHpcKdhpQrdECGeCcUjZkDAyz0/4MHAm7neGoqxtYTYnmhSMszyMTwiKxbFby5XaO9o7VmHtaQ9LrQ21jilObJLIdeM0ninaeF2eObsTRjLBBhyO1iolRoIP2OrRsiC1oGEg+oHuMioF6YoA2joaQVXQsBviH/QMqmAsIkKhMVu3+7QwdBU+a6tKJ2CPPK2Dg78R7W52v5B5/WqKpSiJTtJKqhtrW1jKSpayl9yfZsY4UnrhZXslO8FNI04U7RU1Du2N176waqdZAaPUdsQ7HBwc/AXIr4zwlc6LrPfRuaOilF5Y00KzhikYNm2I3cuWpXa8iSD75Gr0IzEOtPVKCJ7oDXGc8Lh7grryp/VHolhqONMCWOe4thcQYWA/jitS8SbifCD4kRnHJpW0vvCyvjCfH2EYeFmfeYx/ZBhnqjRellfe+++w1hDFEPBIK4gPhDgQiqOm3QRvncG5QFGllgVjlV4XnEwYAzZE1u1K0kqWxuwD3Ri2uyG+SiXcfVpiFHtPiP/8vrpDaB0c/FXJVG53L9bLV1OsRt+DSKWxlBtLTWxtYesFO417YLJR3tIbF90gDjjjab1iDBhRatvYaDRrMN7SSiKVDevCNz3nQ2gdHPzO+PXGYUV405XWKzpNVCqlZ7Z8JYRx3z6UhrF2PzLTDggNJapjnh6gCj1nwvkEWKwfsPfJ2ZoXWtn4w/l/kqSC7vU9WIOYzqU3xIL3HmMqZ7XklmlWqSgP4yPj9MCn9LJHSRjl4/qJeH7ATTOhbNy2C+fH76imI0YQBbCMPjDEkZSumDrSXKSa/XgUb+i9Y7pSWsKFEWcsxQprS2RXmBgx5p6f5SJbyTz4EyIdsbvQ6l+OK+SecX9wcPCfjSCsVK73KdaFhLDf4GQaWfcWi1u5stTE0heqs0wPjwxh4lavPNcrPQSsGzHS97YHUXrLrNLQEDA+UNKNumyod4ynJ0yI3/TcfxOhddhGDw5+G/Rugv/aY7Rp4aVvFCOoNVSEVjO5LLjxgSJtj3MIAZGOc4G6bDhreBgfMCps2yvjOO9GeecJ1iIYtpbR7cbJDSz1tl+wvKMYZW0r0TjsEPb+w/vl6EJjUI+tlWu54MaZyQ9M5syn9IYZAuvyihkGYhiw04n19Sd82bAGUsuMcaZKQY2DYUDyhV4LEi3Oe7QW3DiRr684Y2itomFCrKFb2LRy6xvveABraSqodxQt9+PEdk/T+jkh/jDEHxz8dWh0bmTeKDyzkO7Wh0rfRdZ9inUtC1tbuUnGTyPn6ZGqjf9v/d9s1hDGAauA1P1mrGSKCj04GEZSvrEtN6y1TI9P4D1bTaTl8k3P/zcRWnJv0I7HQO3g4G/Kr7cNG8JNM6sk1N1rd6Sz5JXSOj5YqpF7TMJer+PtRM9XTt//T4IfSMuNbhQzDUitxPERgyVLpqV190/FgXGa6VZ3v1fbcMbhXARVjAibbqBKlc4rHRHhPI4UbVxKxTnP6COdivWBfHvGPf1wT3IeWfKVbixGOpj7na5mhjigxtBqwrWAOnDW73U6w0hZF2zeYHrAKHgfyT3z5ja+l4I3Fr37tLz1+7Gh/lKsHob4g4O/Dpl692JlXllp95uaQqfQ2Hrmmi/cysq1XcneMp+fcD7yUt54bSsuDgTrUGl7rEspqCg9OGwcSWUhXS6A5XR+j8bAllfScqFtGzUt3/QafqOJlrJQMBjC0RF2cPA3YxdaPx8bFhovulCkItHREKoUtnzFeU+390mNt1QVMBazbhgzMI2P9LJR2ob1noJyMp7Jj2QprPmKLY1gPcM4k7VQ2i6yAKIqa70yuz2I1BiHseCMYcuJYoWtVroRPB7T7pESdOI0sS1XLusLp/k9dhqoy5XWG1UatA3rAy03op8YxxOp3JBS0NFjLIAS4kCvmVrSbnj14EMg5xtzFJIURjfStZDpBGfJvRCN+zNDfMQdwaUHB/9JKHqPbch8YuFGRdk/a5VO1s6t3riUCy/1xrVvDOPM4/zEJoUP258Q5wjjRJdG7R1qobeKiQE7z9S2cn37hFVlmM5I8FzSQl0TrTf6lkCF+fTum17LbzZS6ihXMo8MRyHrwcHfiI78QmhlGq+ykqShbqDS2Woip4wER9M9ilOtQaQTTKCmV06P3+FQUst0CzaOmC6M8UzTzmt5w9TKaD3BeW7pStZOrguiMOCoohjjSCExjScwu3cr5Q0fB2KYqTSaVG59ZRCwbd8ErKOnONCSKPqRGGeyFXpvNO20njmFkW6UIgUzRLR5trIi8Yw1uie8I5Te98cpC4N/j1qLGKWocJPE5EfavRvt7CKpJsbwQJOGuvilige4b1EeHBx8C4LcvViZT9zIyD2WZo+m2aTykl95Kxde+42mwvn8Hh8GPuUXFqn4GLFA7RlpnV4T1kfc+YEqlee3f6KUzDicMWPgUjekVlQNvWR6KZzO7xjGiaZ/x/EOgnIh88SAO8TWwcFfnYp88RZ9zqG59I1m+l43QaOWjdQ2Sow4Y1ErdEBUoDRUKvPpHaUVkja8C1hnCVWJfuA5X2i1MKsjlw0/BtRDF8UPM07BGYc3li6N9fbGp7c/4ZxHnUecYjTg2g0bRwYfUOdZVRiq0FJiedtQb8hlZXSPNKkU7VzbwlAirQluGME5bnVhHh8wm6FtmWo6Gvx+g2csZhjoNXFbLozDmeAHDIauhbWvKO/AGKpWqguYXLHWoSpfNg0/r5YfPq2Dg2+j0ngj8fLVUWGjUxAKnbe28JpfeClXlrYRw8TT6YlC5WP+hFiDi2G/4WoVLRW1EKYzDeH58s9s6415PDG9+wNZC72lfdknN0pamMYnzt9/R6eTW8a7v0Mz/NcIytsx2To4+Ksj7D6jz+zbholb31BvaQippb2GQit2eEAQjN3TkZ0a+rJwOr9D6NSeQBUXHEaEk524tIWtbYxNSHkf5ftxorVCa2XvFBQh4Nn67gdzwTOGJ2pbWevCef6OMJ5pvZDKjSQe7yOlJlQNMXgcgT5Eeq9c65XHGPCnE82/UqMnlQVZXnk4vaOWhvQ9wz2G3QxbfdhXtmslDgM1R2orlF7pvWG8o7TKZhoV2WMtVFntbntH94DVn4WWHgnxBwffSKLyysYnNq7k+4Z0vye875/15/TKc70g0nk4vccMged6JUnBOk9HqT1TS0Z6YRhmsJ6X7ZllvTDEkXd/+B8UlK2ugKW1SluuRD9wevoHjIPcy57NZw25bN/0un5zoQVfT7bGYz364OCvxK9jHTKNN1nIWvdJEkpqhbXcaM4S6GA9YhpGFK0Fr4Y4nikUpAvOe3COQRzZCJftgu9KV4+LkTA/sPaN2/qCGMNgPWOcUQyqnhgcqgaxgtOBh15J20rJK4/v/oEYB27pRrq9YoZIDwFMYLCWpVwZz088v/4zWq4Mw7xvVAaP6wHtjbUnes+EbAnjjMkbvWyoeEy01CL4EDDB0Xqj9Y4dBrRWaqk0t4eknkykSaM7pVvZtxD15+mgove+Qz2CSw8O/kIUZaPyiZVPrHuW1V1gZTqrFl7T234s2Da885wfvqfazlu5IgaM9xRtlJKoacX7yDA9knvmcn3GGcvj+z9SnWWp2z6Blk6+veINDI/vcc5ReyPqvgmda6JpZx5P3/T6fputw38hzn6fbKVDbB0c/JX4ukj6s9H0VVeyVMQNCJ1UVra0oNGAdWCgdkWNRdeMCxM1gO2CGiG4/bNqRbj2K61kQpzBOsR5MpXl9glUeTh/xxgGrBq2uoF3iDcUA7VktFSmMDI/PHG7fOLl7QPTMIMKcZhIeWVthTR0RvajyLotuDjw1lZGD9UoVRs+BGre9s0iFW5t4zG8w4eBkje0diQqagwGizEGtYaUbwzDhJ1mtvRM7ZmtFyY/YHrfnSLWsOjGiUiVRrT7JL4jR0L8wcFfyGc/1guJn7hR6Gy0vW+VziaJH7dnXsuFUhNxODGczrz1jVwbanbfVt42St5wxjA/fI9zjrf1la0sDNMJMwysJSO9Iyq07Yrpew+qi5HWBa8GZwy5bjQV5vHE03D+5rO230ZoBaH2SvhV2urnydYD8ThGPDj4T6buTYbAbt5eaTy3hWo6xjqyJHJe2XqDuydBnUVqQUolqiLRY72nr3vhMxg8hrVs1F7wccKFSGmVEEZutxeKFB7f/yPGBd7yAq2B9+AsTQraMz1lQhhYJGNaJkwzy/JG2SoPwwlRRxxmcr6Stht9nDDBktcLSTLdOda60REu5cq74UwtCV9X4sMT+frGdXll9nEvhU6NFhzGORDFhoFWMl0ayJ6ZZYMnSWKtK+/CA2inqSDWsvTMQ9gT4hV+YYjvhyH+4ODfRUd4I/HMxk8se7I7e99ponKrKx/SJ675gqownd4j0fHSFqp2ilSKFkpKGG08PH5HjDPX9Mbt+ooJgenxHUUaNa+otfS0orVigseMw/48RLAoqSYQ4TQ9MsUJo0poMPVv0yO/idCyzfK8PfPd9N2fia2OcKNwIh7RDwcH/0nI3Uj6mUzjppnUE3iPGkglcas3qiSG+IAxli4dUejbihvP6OBBQI1iHOAsNW/k9Y3x/B5rLZsWwjCwbRfWfOP77/4RUeF1eWEynjidMc6Ty4a0TOuFIU5ggdYpvXB7fUNFsQYGF/GqWOuY/MhSV0rZGKYTmBN2VaxWWtu7C1O+8WogBEetDS1pDx01gHUM4wNle6GkxDhNlJowRsFB7pXaEoM/4byntcalXPnj/Ee8NXsGjwvkWugGzFc+rXZ3ah0+rYODf5tK44XEj1z5xEZBaPftwlULz+WNj9sLW1vBGMaHd2QjbC2T2kqRRusNkUYYRs7zP9B64afLP1F7w53OiDGsdUWMo/dKX7b9JmgawRiU/bKjrSJqmOOJaRgxCqEpQ7doa2Qt3/RafxuhJZaH4YGX7YX30/s/E1sNYWMvcTzE1sHBt/PrIulE5VkXci90v9u5c0vcasJ4hxgD3u1p6q2AgQKcxplSVqx1iBqMKs/PP/Ld4/dosBRtBDdwywttvfHu6Q+7cbwlznH60hNY1ivOWJ7smW4bLVisQrCG1ITx/N0uWkpFSiW8e4c6g9MO3nFbX3krH7HjjPeBlgvDOFG1IFK5XD9xnt5BX5nshB0HjBhSbZxCYJYzKoUYRqyxUBNbv0dH9IZvDRMiIkLSyq2tPBi/T7SM3Psi9auE+P2ifRjiDw7+bTKNH7nxz1y4Ue9tFdBo3LTyIX3iNb1Qa8HHETeOXCWTeyX3jW6h9oqxcDq/J7qBy/bKmq9oiLjxTO0Fkb0bvqcr2gUXBzCgOJwapBcEwxhGpjhjjIEmTN1gulC07FaAb/xI/0YeLWUKEyi8phfejX8utgr9i8/hEFsHB9/G10XSgrJSeZOVQsX6SNHOmq/7lCkOOCxqDKVV2rbiYsR5izOOfj8rEwOvLz/ivUfOMzWveDfQ80ormXl+wOOhFLQWahUKG7Y1Bj8xeE/KV+IwccJRqFzWC/P8yHl+h9ZKE+G2vLC8/Ug8P0IITOMZjZG2vJHSQu97kGHL+4q29yNl+USZGtY6gnZ23ehxVVHrsQLaG701sJ5pOPG2vVJbpsl+l+zdQJOKxsBSbwzhiaaFZgPdKP3+Q+5Brp9reA5D/MHBv86NxJ+48YEbiXaPnNlv/q6y8qftI0u6UqQQpxPNGa5todHI2ulWdy/oOHEeH6mt8PHygaoVO0+ICrUXFENrCa0VawMaoBtw1mJbRTBEPzKGEWscqBKrYDs0FDWgIngg+vGbXvNvVsHzSuIxjijKJb/xMDwSf5VVsYut3bh71PUcHPzHyfeDLYBCZaNykX1uHKwny8JaEk0SfvoO5yxdK6pC10awE26akVZ2A7mx5HWhrFdO//f/y9a2/W6wV3recNYz+QlqQUrBx4FxOIFRJiLGWp7ffsIbS2mZmjekd2KMqIFWE6OfMTXzcHpiNUq93TAxcg03GAamcQIj3NZMb53aGiVXpvAd0/sfdmPsOFF6wajHeUc3oN6Cc5gs+wV7mgGYpkcubx9IZWUKM912UINgKFrJPZGt5cGYPYNMKqPxrFqIxn/ZPPTw5Tjx4OBgp9N5JfGBG59YSfQvx+0rhU/9xsf1IymtlF5w48BqOmIczQmp759Bg2V+eI+3ntt24VauSAjgZ1qvex5Wb0ht+5zZBppVsOAFqA3vA4Mf8TZgjcHWhhdBjaMZRVojGEsIMw/xzPj3mKOlwEpFUc5hN6Mt+YbGE4Mfvvp7Sv4y2Tq6EQ8O/iPor2p3Mp1Pun7Z/FOjLGVlaStiDM568IGaV2pOiDEEP+B8RGpHjZDaQl0uDE/v6QaaCBFPXa+0Xvnjwz9gBVorGG8ozrLlZ7wY3qxj3W4YazmNZ0wvtF4IzhHCQJdKvq1Ed+UUTtA75/GRrCvNKFUaqQtuiMzuiW7g9flHlusLLSmP9g94Y6h5pdSK8YU4Qu0FF8J+vDlO2O1KrxthGFFrCD7iw8RWNs6SsWLAWsQIzUAFbn3jfXhErSX1wslHshaUaQ85RQB3F1oHBwd67zb+xMYnVp5ZyXfDu3w2w7cbz8tH1u1Go2PneY9ycZa13igtk1smjifmYUZb5W29kLUiQ0AUbG+ApecEohizWxm66QxYbFOc9cQQiSFirMOWgmmC8YFqwLSMUc88PvI4npnMANKR3v/N1/l/4jcTWulzRrWBU4gEVVLdQ8F+LbY+T7YOsXVw8Jfz637DjcpVE1kKJnoqwpoXlrRgfMDavXKn1ESuhXEc9w0dkf0eVJV8u+AHj59nuhYQpbdCWhd++OH/whvPLb3t3YnWoXVjcBHjLVJWQgwM8UTXfc4Wz2dinGk9U6UjEdaycNPMP04/8MRImgJLXXB+pNY31FtsGDgNZ7bpSq4TLW1sy4UQB6wLiCotL8RxZmuZYQiU2vDjmeaUnFfcfMa4AJa9SzEopTYcDWNAaiPbgo2Wuu0F3NGPtFIwdjfZFtcZ8Ich/uDgK/ZE984nFj6y8kL6hR/rhY3ncuHj5UfWdMMGTzg9wjCQNLNsLyTJCIb5/J7oAimv3OpCs+yTaWWfYrUGrd0fuyN0DErsBussgw+MfkCsQ3rF5oxxkW4FKQlvPPP0nnfDA6OJ0DvSK1hD/kaT1m9WKl3od/OoIkaYY8AUofTdfDZ+dSbaEcqXr20Mh9g6OPh30+/9YLBfgBYqF91Ishcur1pYy0prCX9+wDhPa5XaCsYIfhhx1iOqVBXaetvLk8OIWkcviWAj6/Ijw2mGprzUT1QLZjphrWGyM944rCguzPtdIgYjgDN4F+hlwxlLcAPFgUwP6LbwcflIDQ+MLu5Hc9byEM88rxf6BKY3hjjz+D6Qrv97r8bpBW0d6x3aZT+adLD1zIkAKNP5ietP/4uhZsYQaMZhgqfXlW47qsJucu9UFapRBudZ6sKTH/YAWN3/XmUXWoch/uDg5y3nSv8S3fD2ZbwCicZHvfGyvvDx+oFSC+PpjD2d6c6wtoVlu5B7xo9npmHEirKsb1wlId5i1WDVoqbTS6FLw2Ao2lADoSvBBmIMDG7AOL+3PuSMtQExSi0b3jgeTu95Gp4YCdAbXRJqDSuNklZ6zd/0fvw2W4eY+9jw8/0fqIEYPLY2unRSS78QWw3B3uda5ZhsHRz8u9nvID/7szoLmVvPYBSs5VY31r7RteNiwIVAur1StGGw+DBgDFRtVClsy5Xz4zusC/eLm7JdX1GjOJS13ygh4MdIiBOuFLxxOCwuOHopeOuxZg9FtcaRayLYQHC7R2vouq9fn96Rw8Y/rS8MxfCH4Qlaw4+RqBNvbz9CjEznR2za8DFijFJa3rsTUYw1aC1041jJRGvpvRGH835UuF6J4xlnHMGNJHNja4lxmjG54Y3ZNyV7YQwTuVSyb0zG7RVFQFehG8FhvxjiBcEeiVoHvyN2m8LuveoIn1j5kRtvlC/LODcSP8nCx9uPXJZnBGF4eocdR5o3XLdXLusb6hzj6YngA70W3tpCUcU4hxEF53ZPlnS6KE0bTQXXldE4fJyY/bBPnVuht4yz+8S+lY3BBc7nH3ganpjwaG+0nqhGyVLJ24q2inOOaXz4pvflN0uGH/Hke/rr58kWNmA8jF0xKn8mtgode8+rOY4RDw7+feRfxTq8kFnbhjpPMZ1cN9a0YKzHO49i2GpCaiOMM1YNai1bK5TbBTsMWGP3GIhWaCnTJeNEycYShpHgPHE8oWkl2omA24VPyYQqQKaUjPZGGE4M44ABqnSC8wRjoEO3hhYHgn9kfXvmn/IzT37m1DyTjVyNpWOoFjR4YpzwzlJropc9n0uNpfeOVqE4IceBLJVTmBnHE6/LJ8a8MM5nrHcY4/fJHYI1Su8FZ6Y9QT/MWGO4aebEQNbGbDxNO/0e+/BZ1MoRXHrwO6Lfp1jK3k/4Eys/snAj71t8KM+68rG98XL9ibUk1FrC6QEzzCRTeb18ZKsJFwem6YyqkMvKrSbUgjH7UEYNe+zMfZpcegUE35RpODGGGWugSr0LrP2LtWW8CTw+/JGH+MhsAvRO6xtJG1kqJW2oVMYwMZ7eM7uJ8I2f5N9GaMWO1EwMkXI/w9X7j9lFFimczIBRZavbHgVxJ9MZ716IQ2wdHPyfEeSLP0tRFipX3cgt4YeBBWFNN3LdMCHgYmAtK7XXPQjwNGFV6dZQtjekFeLDe1QBq7Q1UXqit8Q4PeCGAev3UNKWFibjMQK3/IarnbJc8WbfCnJdieNMVUFzImARo+TemIYH4nymkTAh4G1kfPyB7dOfeFUoCCOO7x/+yEu+7HU7wy7WGALBKnm5IL1g/Yi1Hmtgywur80wu0rQxjY9c84Xt9sp8fsJaS/CeUhO1V05xZL2tuF5JNiNBUaN70jSBJg3rhr0H0eo9bvFnoXVw8N+dr6dYsE/Qf2LlA1du99IvQfhTf+Gl3risr6Sa6KYTzo/oENk08fr6gYoQT2d8GOi9UcpGko6xoAjd7V5Rkf1RSy/01rGtMYaR8fTIYB1FCkUUUcHi0CoMzvE4/4Gn4ZHBeIwouW2U3sg9UXLG6G5bGucnTmbCA8YYuv079GjRYU03goz4ONHM/p/B52PEyQcudePJzTgxvxBb+yZi+yK2DP3I2To4+Ff4uki60lkpXCVTtROcI8nGtdwQqYQ4Y3xkvfxIU4NzjmAjqnArKy0l7DDhd9c4LW3c8hUxSnQeP54JfiCMM6lcIVcWMuVygV5hTYQYMWFiiiPzw3cMYaC3ipaKdiWIUtXy8eWfCNuIPT8ShpEYpz0k9ek92+tHalpJpwee/JlH88DH/Er3Sh1mnDZCGMnmQmkZby1u3BPhl/XKur5xsjO2Cg7FSCeXQqsVaywuRLQmSi2c43m3OvRMDiOVhreWpsJq+p6z5c1e68Nucfg6r+zg4L8zX0+xYD91+sCVDyz3ZAFYJfGhvbFK4povrHWlWyWcHtFx4JIuvF4/YOJEnB+xZt9WTjXtmXaAWotgQep9m3m3MfRaiOp4OH/HECZq2bhpRlGcWrxANIbH0/c8xAcmGzAKpWRyL+S+IaVgBE7DzBBPe3uFCRhnaMbQDZSyftP79JsILaMGaz2tFrp0hvF8DwDcgxTFKHOIvNQb7/0jtv/yGPHzFlXAfjH5HmLr4ODPqXukJrAbUN/Yt+YMUJyQciaVdd/cGSJFK60XVDJ23vv9iovk12es9zgfQAV1lsvlDTEGbzxxmPAh0KyQ0huyLGA9cntjVMt5euT8/f+D85Eg4IeBpkpuDeM943AiYnFNMarMceKn5SPl9RPuNDOMBWs94swetdBWtI9YyZzizFQ33mpCjWCtxWHx8yPL2wdwDi1gfCCEyJJubOPCGN8xuJlpfOIiz6zXT7j5DG4/Ks26t675ONJSog0nFslEM2ExJCl7PpnKbsBH6fzy+PDg4L8rhfblpgJ2W8KPLPzpHkQqqrz2Kx/lRjXCLV25pgviHP78Dhkcr8tHrssLfj7hpzNIJ7dCbgURoRvde0f17u1uQm6VWjZM7zzM7zifH2k5c01XjDVYwHVLNI7H6YFTPDO7Caf3TeqS2NoGbe83nMOZIQ7MdmBwA2otzShbz9RtYdneUP07nGgZDN76vcC1C8v2yjQ+4qy5l0k2ulFOPvLSLrz3j/ArsVXvfi2HOcTWwcG/QqF9+XWi8Epmqyt4Rzb7kV6uGfEeFyLr7QZm39TzpxO9Krnf0JpgPuOMRTGktJHKxvD+BzQlzDjSEVrv1O0KgLsuzOHEw8N3DG4AFFWhWYtIx7GntXsF6Y3uIuN4InZF9f9n7012LEvObL3vt243p3GPJpNk8RZUAu6gpoLe6Y4F6Ek0raEADaUX0BNoIA0lQhfVsZhNZES4+2n23tabBuYelckiWRc3SxVM8iwgkQl4JCJiR7idtX9b/7eE17Xx9flrloczarfn7s0vOi1eN7I2rNePNKVo+4IbRppfabXQ7EjeIsO0Yz1r1rDiakTcgDscEImcwon9fM9AYRhnlL+Sa8FpTckFaiZXwefIfpiIfiGXTKiRrBxVHKlkovTQr6YH5rWY50WfhkJugfib/uT0slH4/ZcJT+IdC99w6YysmvmYnzirQlLweP7ANVzBGszhjmzg8fErtrwxHO5QdqSWxJYjuSQohWKEphWKBhVSDkQfyHFltAPHVz9DKbisZyqgRKOBAcM8TByGPbOZ0ShSjlzDQkgeyRWDMLgJ5yYOZmLQA1VgbRmfF/x6JkaPasIwTAw/RWCpqgqt+sZOrYUBy7I9MQ/HTm9+wT+oxqw1j/nCvTnQSiHk8IkbyVBkAAAgAElEQVSzFSn0spButgQwN7N1003AD0GllcaJyNI8PgeaM6QWWcLaWTHDQLOGdPX4mlDGIqJIKpNOZ2SaaaWgjBBqZjs9oF+9pqWAeob/1VZZlhMqRIwY9rs77u9+huRKTAExDmpEG4ehYrRh1ANGFLopJCeWdGVRghk0k73n5/PAx+2Bx+sj3/7mP3P/xV8wTnc0s5BipPkTSTfGaYdVHR+BaiQpDNWgxonw+J42vqbFFXvc9+LrmnkMDyjzGm0dGCHkwCxg3IDaDCVshOKZzdxLqZMnuomkobZKVcJWPFuLHFTPaTltfvAhdAvE3/SnpBcu1vflSXzLwjecCa3g88ZjW/EGYsm8P3/LGldwFnd3z1YjDw/vaDR2928p9CFKLpGScy+2cgakGxTJjZACYTtDKRwPbxmnHT5s1JoRUVhtccrg0OyGPUd3wKLINbNsC2FbUa2ixeDcyDjuuTMzTvWc+FPxbPFK8CutJDSavdvjtMVog/teTvy/Rp/t6nByMyoHtriSa2HSA1d/Zhp2aNt5OYnKVTemJlzqysHsyDlD7lDTFx7X+PzbeOlH1Lej7aabnvMTL/mszEJgaYHSKtmAz5HNn4GKcZaYfccV5Iy9O9JyJsb+451WaKWotbEtV5pViFXUi8e9eU2hsHpPuZ6Z53v245H94S0lV1Z/opaMKQZtHApDldanTyWSVa+5KaVQW6YhKKvRzWDUyEG9pjnD4+N3PH74ilc//yuG3R2pvCeUTEpXZBgQEWqK5Drgs6dEz7g7sPqV6j15ElL0oG1fDEgBJwsHPePMwHVbiDmC1th5pqQN768wvuobk7USSiKZxNY0To9sMRFa4qBGcsvPz/qHRuumm37qevmsLd+7KoRusr7hyrdc2GpkzSuLykSr2OL6bLIW1Dhi7+65piuPT+/QbsbtdngKoQZaqcToQUM2GiuCEUXwgRSuxLAw2Yn9q7+g1syynChKGPWA1gaLZjaO3XBgUg6pjYs/49cz0hpOD1gzMo5H7uyMEUNsiY/pjI8bMW6QC04bhuHIYBxGGQYzUmn47H/U8/tsZHgRYbITWhRrWEg5sbMj17gwAebZbBUaV13JKaNEMxlHS+mT2arPNT3D8yTrJSh/G9ff9Oeu/L0NuJXEmcRWupmKSlj9Qki9u7CNI3HrdTuVjIwDJRWq9zCMpBjR4x4fPNkvmLc/g+sVM+1pSgjbRjx9ZDcdGXZ7BrfDrxe25YIPV5QIGs1u3KFLQesRZ0a0UdgGLRUUlSsZv0Xi9oCd+nYQIhgU4+7AeXngcnrPXn+JnmeiX/GXM00r5umO2ApsJ0orUBujTIzDxLJcoDX8suF2O2SLZK241n49YIYJ2c7UHBE9ULRCtCXFjE8BYxy5RFJKxKF0U2U0a9uIJZF1L6AFfvACeDNaN/3UVamE7wXeX/Risr5pZ655w7fAaipewTUufHf+Gp88ap5QxwNP2yNP54/MuwNtmNla6iYrZVIOiDFkLQxKo6pwXc+k5UKrlcP9l1jn2OKVVipWOwbb77OcMhzG3XMOS7FtC/56ppXMYCecG5nHHQe7w4jGl8BTvhLjRkoBKQ1nLMN+z6xGtCiq9Jekj+HEklfKj6wt/WxshPgcZndmQCnN1V/wYWU3zKxxxdWCcQNNBETYbKOmBSWKwZreyF36yLD0j4a+DQXPxoub2brpz1rfx6acCSyEnoFQUFRj8Qs5J6oRmoISAkkXsBaUUGOgtIISA61RWmO9PqGmEVKgVcEdD8TlSjifGd2MtiOSC6l0Exf9E2aYGIcD9/u33IlD1b7pV2Pkenpksjt2h1eI0Rxkps6BLVxI4UwbDkjN5NT3ks3+jlISpw9fwdxJ0qZdqCFSD5pxPhLatXcU1kQqCWsdQqVcz2RtcG1Gq17dUaURqqdgaErYcsBZi1KarBVKF3y6cjR7aqw0EWIOZNWvCJ3R+Bp7P1vrH0Xy/OxvJuumn7oKlfC9nOeLNhLfcOGr+sSaPUk1NitsVC5x4cP5G9awoPZH2m7i4fqBbb0w7+7JgyY8v6CUGKgl0wYHWjGKpcTAup6JyxU7TOzevKG2yrataBGGcd+znbUxuZnZzp1C4AOnywO1dNTDPL5mGCYmu8MgpBJ5yp4YN3LOKBqTGXDzhFMdvuyp1JbJJbHlztZCq15K/SP02cjwE4aVhEZhleE43XEVxeKvTNMOXyItVOww0UQQUWwmI/nCa3uHtgqfPCI9WP8CM1UIL2XUI/JcSH3TTX9eepmqQD8srwQWEqkEitGEWlm3E0ih2hHVClVVas2ocSKnSI2eag3EiJknwvJEVQo9TbTrin39BXFdSNuFJg1jHa0U3Hwg5khMG+KGnocYdsz0/GVTCl0aqgn73RtomZBWnNmDEiYsDEcepfEUzgyisMPAuEVi9GzNo51DZU/TE4wTOXiuT+9IoeJejcRWSCePKhnlHOM4c318z1IaWmuUc5QcqW6kGQ2+INbgU2SYoNWGNpqcyqduttpqL9ROG3XcUVoha8WaYi+qRpNbwYr+NI1/OY9u59BNPzWl5wqd35Yn8TVnfl0eCCWSjLCozErmEq/PJmvFHO5gHng6v6ekwLg/shqILVBKpvg+XS+jwSrds9rLE2m5UHLE7e+w044UAq0UBjejhwFTK04M4zwxy4jExNPykRw8s5vZ795gtWG0MwZFSoFL7tOrWjNKFLObGN1IaY1aMmsroBSpei5pI7WCaKE5gzIOLT9BYKlq8ny9B9dngpYTzWE8IiJc1hPjtCe1gvdXhnEHotDKcFGBmk98Ye/JVrOlrW8WKP2DvNYLb2vA3A65m/7sVJ8hgtAnvCcivnpijpTBsqWFEDcQ0MNI9BtJQYkJNd7ButJUnwnX2rNeyW+o454WAmqcqTmRt42aM4OZEK0x84EteeK20HLkePiSvZ0Y9PQcdi20GNCpYOzAqAWrLVvcWMKF4kYwiiqKnTh8vrLowlwrxk0MqpIzlFpRRpEvZ/JLzc5yQes983xH8mcYHWlb0fMO0Qo37slhJVyv2P2xl4Roi08rqiiaaEraiK1Cqxg7kJeFWB1ZKtIatVaS6hUdWfUtRR8DsUQmmT4ZrfpsdO1zJY++nUE3/UT08tn523ks6Cbrq3bm7/MHMoVkFYvE3p8aLnw8fcuSrti712RnOD19i2oN9gcuuhKIlJQgeKpWFGtw2mGLcDq/I28LKM346i1adD9rtGHc36NFULXhhh17O2FTYb28J0XPaEfu73+OVQ5nHFYMJUdOaSMmT6sNpRTOzT1rSuMaF4y2iOn9pUtY+sbwYBE3YrWl1YJPnph+ghkthXBg4IoAwkIkULCiOIxHtNJ8vL5nmo+UVvHblXHag/Srxkva0OXCa30gGoG8Pm8GdbPlnvNaL4fdrYT6pj839a6xPu4+s7ESWGsiSaFox7pdyDGQNWCEumSqArSh0q8R2zjSYgIrcLogw4QqFQU0LQS/UorHaYsdR+rgCHGBVBAa8/4Vk7LQhCWulJIQGkYrxExoZfE5shCpVhFjpawPGDug5x0NOOzvOPszi8kMZkTyxMjI5s/EmDBa0/xGVmDnHdv7jSFs6AabVtSSmFJC7MB8MKwl9clU2GjTSDUKlKWsEWql5UKOHgZHrSBGk0qfXIkIPqwM+5FYAkVlqrIEXfDFs7MjtXVz+zJR3GGfjdZNN/3xq9E+IUt+W4HEP9Un/j6/R5QmGukLNmTO4cyHx29Yisfe3ZOMcD1914ucR9cD8kRySLTgUc7S3MCkLXndeDp/pJQIw8A83WFQtFwY3YwZHC0XxA6M08SYFeXpic2vWDvw6viWQY84ZVGiULlwyQsp9j5XbSxN94lUqpVSCkYbsB2MvvilZyznCWV7B2vOiW1dSTV3Y6Z+3IvSZ+JowZ4BhXCioRi4EolUDI3Z7VAHzbvLN4zPZa9+uzBMB0QUgxl5Sgsiins1E0yj5YW93ZOlG7mXvFbfvLpV9dz056WXIHzHOgRWUichSyXTWJcTFRDraDVTpV8bNmcgbChjqKVCK+Rmeg28tajcwDqy3yAntLGYaU90mqEUaq6QO63ZyHMVhmSS36i1oErDYSg2kZWmNvAlUK6B6jRmmIk50K6BZiy1ZVINMI5cVUZJpMUI2uLmvl2kciadHyhWoURTosc4h3UDaTcDGq01TYMd594ooaCGQBIw04FiFNqO1PVECit2cpRWEGXIKRBqZDfviOcHyr4QWya2zE4pmtKc0sord0+qGXT/wLrBS2/6Kekl9P67/r4GEv9QHvl1+YAylquKrCQWMpdw5sPD11yrx766p4iwXD5QtKGMmlWlDv/1ERUzdXKIcQxi8acHtsuJQsXOe4ZxRleQ1hjmHTwjGqZpz4DGnDdCXFFi2R9ec3QHTJO+0FMbIS19giUgbqCpSqwVqX2qLEBWwpJX1rKQnaUd5w4pbkJIGy0mSsudIN8KYVs78/NH6PN0HaoO+NszIAgnPAcGFgKJRiXj7MAvjr/k68tXTMMeqx1+OzOMB5TSWDPwmC+IVdypkaALklb2dkeU8kzX6rpV9dz056aXAOtLPsuT2fJGMZrUMj6sVFNJRlNDoDhN2lZwd+RlpQ0DLXgqDUkBhhFJnmY7YqV5jxoMdpypzmIatFYp2xUrmnF/DyJkFHXzaG0ZzcROO5ybOyuvJta4IsaiJof2gfXhAxhDSQG3OyCDRYZ/zlIkaUR/xboJGUeaT1ilUPMd3ntym5FUEQPOjqQhkWKh1Uqr0NwI25li+qVeChFTF7S1IA4z7YjbFXs40KRRdEOSPE+sjogxxBDIzhBKACc0qVRliDURnj+jXj6sEvWGm7npj16/L/QOHXr8d/kDX9UnxDquEp5NVuISF94/fM2lrtj7V+RWOnrBaJJTfZLVMnVd0bVQ5xlrLapWLh/eEeKCaIUe9kzTjKmCKIsZRkpNaGNwZkb7RNvOFGWZpuMng1VrI7cKOffspCj0OJLJlLJhq+sLKg2SbvjqOeWNZg3MM013OHMNnrQtlNKrtFLLtFr79Bto+sdZpc825lniMxdDHAp4xLNnYHmebAUKzhj+4tDNlnM7nBk+Tba0MhRVeMpXsHCnRzYykld2ZiZI/pTXgu+T5G+H3k1/2nohNwMsBC4ktta3aJgMa7wQ4kbWCq0NKUZShdoEUwpNKaiFUiutZbSytJYQsUjphfCVih4m1NDBKkqEdD3h7MA47FBKUWOB4lHaIkoYlMHYvj5N65MevduRwkbNEbPbsb874k8nwnYhXk8M9p5hvqPWQLyckMnBm9dcHx5Q0WO1ZpoHZLC0D2eiT1S9g5JR2mDMQEoryjja9UyzmhYUJfhupoCYE6TMqCtudyDFQN5WxFmqKKRVckpEW3qHYl6o445Y+4fIKELREEpkUIrSal8Rf87JDehbIP6mP1r9Lgjpi2LL/Of8jnd0qvvleybrGhfePfyaa91wr95QSmKJC9lqglVsOrGVgF49iFCnHdYYaghcnj4SakBrzTTtmccdqjaUcSijiS3g3IhNYK4njLKM45HJ7RhR1NI7XFsp5BzJNBgsVUHKGwqDEUNumWYUS8ssxVM0yDSCMr1j9fJE9J5cI03pvq0sDWqvh+85CUXJ4Uc9489zdVgVVjvWtDLogVk7NIoPrOxwCIlA6VeJRvMXh1/y1fVrYGI0U59sTYduvNLGuayg4ahHlpaQvLGz8w/yWnBjbN3056Hyg3xWIJDYauy4B+24nK+UVhFtCDVTVaVjmBUtRoq1tHXtP6YXYEDKiHHEHCAm9G5CjKVqaLFSYkC7CSMCqRCXC1UrlBFmt2PUA/NwBBqxJNa04Eugrp1Kr4eBHAM+JGgJsz8Qlwv+9MhmClo72jx17s04wmjJ1xWzf81SMpIDbR4JlytrSwxNKDEgz4TpqivKGXIMNG0oKWFiQnZzf2a5EtaVdjf2HsaUMdPYoaoaWkukVlCq0aIQSyYQKDVTRdEUbDlw0BOpZbS4TyXTDW6B+Jv+KPX7NgsBQkv8bXrHd2qjGs0Zz0JiI3NJV757+CdO6cr4+i05erYaSUrwVrjqSMoBtXhQDpknNMJ2PpGWJ1ItaNOv/yYz00qmOUtqGaThxKCvG0M17MYj1g5MYpECsWakFWKKNAGspWihlojKPT6QSSQlrJTnSb5CJodSihQ20nIhhY2iFMZamnG9HqxkpFVK7lnOUjJF6u+Z9f2X6zMBSxtFC6OaCM8N3aMZ+VJ2vGdhxiKAp5BpKKP4xeEXfHt5B8CgJ8J2YZiOODMQ0sYiEaWEvRk4J4/KismMaNQPDrgb9uGmP3Wl72WDzqQOAS2eKI0mjbA9kqTRlCCtB8Wj731h4gbIiUqB2nNZrfZ6q9YyLSeUVZix5xokRnooqUGrhOVK1QN2GDDO4sY9pXYG12l9pMVAyQloKKVR1lFiZEsF7QaS9z3LZQyyH4l+Jb37GnX3BrPbYbSmXPuEqk6ZlDzK9AodZQ4orvj1jL57S82FkhvY/kYqw4hePVU7kED1K2a3IzmL1EAWkLBgh2cTJ8dPkMaUK6lVjABKiDVRtCUWz6h2JBqxZdJzdmvEffozqM8ss5tu+mPSb5dC/+BrNfJ3+Ts+aE/WwgXPSmYlcU0L3z38E0/pzHD3lpg8sRaCbiyusqhCiR6W5++5YaRR2M6nfj40cG7i+OoLdO09p3XQ5JLR2uBCxebK3XBgP+xRTdC1kUqitkJNqUcanCFbQ60JyQUtmqLBy8uZF4mqoacBqYVyfcKvV1LNiDPYaeih/lxocSOWSCuFUhJVeidz1YJyA1r/uNjR5zFa0qdLTTSjm8k5sqaV0Yx8ofZ84ArPZmt73n8QrXl7eMvD9QEaODPitzPjs9ny2aOtAoHZWJ7SgioK0R0l8WKrXlZXR+zn+K3fdNP/73oBlUYSZ1YSiTV76rNBWMLaNw21IpZIsYqSM9pZihLqulFbQ2hoUZQUEIGiLZIzvDpC7YwoZQfqGmgl0paV3XyPnmbMOCLWUdeAbkKuGULsV4ZKg1ZYbaiqgdKoWDk/fEdVjTZOVL/QrEHoXy9+oSaPVhoz7zDK4ueB+HRiUHtk3lGXK2qcqJsnDQtm3lP9QrUWpIK0vu0UM02EWgstbOjdnqYjZXDUbaHtjmgtJL+ih4mwPVJVIRdP1TM6ZUrJBJXxJXHQQqqNKn1CEFoE5k+w2JdQ/E03/bHo9+EbAGIN/H1+zwcTCarxRCCQWUisaePdx3/iIZzZvf4CnwNJMptOLE5YJVF9RK8bdr5DrCbnSDg94rcVJcJ8uGd3fIWERNWabFXnZjXFEBN3ds/9sW8eUis5RVJrUEqfMlnpL4BU2jNLs1jDpUZCy2wUsvQJtioF//SRLVxpDZQbsOMBaiOEQI4ncgw9JqGlv7A5088uawBNLumnGYaHf14/LzQmY9FV9yZvPfCF3vOe5XnqFNmeL0K0dtzt7zkvJ8iNwYys24l5ukMrzZY96tlsTdbyMZ15K3coJZ8qeoDn2p58wz7c9Cen74NKr3R0wkphKxtYzSVcyCnQxs61qhpKSX3z0E5IDuQcEaXBmp5VCCvqcAfrAvsjVpk+zbKauFwpy5VdVdhpj4wD1arO4Fo9UlVn1UhjPOz7m2nNNNXIuZBCgnGgTgJqollDjhGmCWom3R/R20aNniaKKhV/+oh6/RpaIVpFixvzvCMNhioK6xzr+YndNPUMml9IWpF1RbWMpdBSJVoFy4I93tGUARLiLN4v7MxATQEZjiijaSmypYQdCk6BkkZoia2sFLmn0siqEWomSnkuk26frg9vRuumPxb9IZMVSuArThzsHZtkTkS25+vCJa98+/CPPIYz8+s3bNkTpLISWQ0EyZTN91L53ZFqoMSVeDqRw4pBs3/zJcO4p4VItkKuCUkVW4SDHnizf82sHSknUonUVKmtUHKfQpXB0BB07S+TySq2GtnKSnj+vmtAy5l6PeHDhmiFnWZEG6QV/HLuoOXkEaNBa2Rw6GGgGEVBUWuBnKkkRPqg58foszqNl+lSprJTltnObGlDN81bPfNRNnjObG097obVA/N8wPuFXCKjGj6ZrZgDvgREDyAwGMuHfOJn9hVa/hn5AD3Hkm6biDf9ianXUfVD9AGPp+LrRqgFzMj16SNFAaqzcpRzFN8nWE1r6rJ0g6AUaEN+ekI7R6kJZS3GalpTiBspl5V6uTI6i9IjahoJWjE4R0wJaZnBOhoNnQslrxg94MYBJwo1QSuJ8+k9pQTMbt+5O7p0M4hQWqE4A2uh1AVRUw+8fvMb2O0oJOLqqaZhhplgageVPl1J775m+PJLcvKkontno4YaCloqNCGsZ1S4p4mgFVQstXhCTVgUUgttdGS/MrRIlvI8ay80EbaaiDVjGoieyDkTai/gedl7/v6fyU03fU79QZOVA1/XJx6HhhL/Q5NVNr59+DUP/onp1WvW5Mmq9caJQZElE9cFHTN2dyTTyNtKPD1Rc8KZkfmLX+BQxOgpupFjwlRhpwfupjvejve0UtiCR3KipNRzotZQ9wOi+mJKbIVV9c3Aa9rIqlHrcxFfpYfbc0RrhZknjHaEsJAuj/htobaCshbmCTOONGPIWlFLZ2xRcwcg0zuZjWi0/ISN1osKlQuRUTSznQklEJPnjZ14kH8msq5kBGE0I3mo5LBBy4zKsWxPTOORVCJKaUQElGC15n164kv7ip0MP0hm3TYRb/pT08ukOJF7tyGRtXiyFKrUPkIXRaqJbISKkNeNNuhPnYKiNFZa7zcMgWQtLidkPvbcwmQpywVC7Jt5GNJoyBpEV0oJkAJOGxSJHAMiGmdGEp4QA9JaH8cL2GmEOqCUIuaMaIWMB0pL5NXT0kaZNOnrb6jTiDke+7VfC7T9npRW0sMHhrtXhOWJrBu4kXJ6Tz3OtHmmnh+Io8E4RfQFXRtCoWpFWz1qGvu2YBO0G8glQ9jQdUJEgzGEuOGmQ2f1NYMVRayZrWxMMpMpNNHElvEtYUV/CsL3f+ptEeemz6Y/ZLJ89nzXLryzkU31SZYnsZLwJfLtx9/wsD1gD3csyVOs5lRWwqBIkojnE65qzP5Iqpm0edL5EWph3N8z339By5GtZWqrEBJGO94Me+7HVxzVgI8rKWUkenItNKOQYQRjUKIIFDYSoSWWtFJFQEHNkVYaNQdK6ibJzhO1NYJfuKzf9jNHADcyjAcYOzA11kTNGbZ+CyBK9+woPXPaaqGWQK0/wa7DKvVfHDqNxkYmS+Nghp6BSBt3xnH+3tm0klEoZjux0Po1A4VROVZ/Zhx2xBzQtr9Pita0Bh/zGW3ve4/a9xRvBdQ3/QnpJZ8VKFzw/Y00hz59yYHgN6pWVFVpChrdGMl4TwkeyZk2O5IxyMMDDBZLpUy73lToZiQEatioqeKGsTO3nKa11tetlwWLpk2GtAZMASWRWDJiLE0q2WiKghYDLSacdqRUiX6FuzuaVNK6ErcLRUCspfyHX8LpoRvEX7xFr1d0qZTDHfXhA6lk6nxH1CekZZrSbE/fMf23/5EaFlpcafsjjIYWG7Y2qhLC5ZFp/9+gJFFS6KXagyWvV1oIyDAg2pBDJKaIURZb+hlWgK14iplJNDKN0iqhJXYyfDJZ5fnft1Pmps+hP2SytrTxyMo7EzjJxkUnLKk3ttTMt4+/4cPyDnt3j2+ZbDWPdSGNQpJKOj1ixNB2M7km0roQTicUlf3rv8Dtd8S4UWulxohWhtlM3I/33A9HbC5c1qfefZgTSQtqmtHOIUoRpLGVFV8jPm/9+0kJlNLhoilSSz/PZBygFLbzIyWs5NS3ht3ugJ5m6jQQc6LmBJcztIo2FqxDRFDSt5VLyZgKohXGOkS5H/X8P4vRKrpyKRuz7rCF728AJgqPbBz0wCQTPntmpRDTDVI3ZAWDZjQjS312na0XTfq4Ys1ALBF0fzjOaNaU+Jgv/MzcY3/L4HWzddtEvOmnr/CczzrhWcjPoFIPVnPe3nccgR16uNRZkl/7KN0Y0vkMSmFqpymbGKm7maoUYy20aUetCZ0SMQaM7mvbVWmqD4gIkjPjboebjrjzgioVN+0wuz25VUqO5Jb79CeWXpkxTCQF23mh1kT55iuCqrCfUPsjxUDLCYASBmoOmGhJztDOH1FKk42B80dQbzH7AyV6yqsD5ZtvyOOvGd58Qf3wnjYmEKFIphgFykBIyHLuplEXaopoI1Q7gd8w89gPdtWIYcWOOwakb0BpS67P5Gs1UKT3IfqaKKp+z2jdUlo3fR79aybrQuBbG3hg5UwkSOk8y1b49uk3fHv5Brs/4FuhGOGhXklOyDS2xw84beEZMFqWhXQ6YYxlev0L2uBY/UKrGXLF6YHjtOfo7tjrGYJnCSt+PVMAs99j3EjRilU3QtkI0ROKJ9dE1d0vJB+RFCjPG8rVClIK6fJI8BslR8QOmLs9arenUIglUc8LqgnKOdS8Q7RGSqHkCD7SGhhtUG5EKU3NmZQytVx/1J/BjzZaIvKXwP8M/ByowN+01v6nP/T/tNa4+DPFZSY7o5EfVOQ04EJgVo7Jzvi84VIF05k4LwF5J4biJnxcoTWkNAyQUoDWUKIR1Q2UNYZTWtFF8TN99z1u/K0T8aY/DdXnLFCjccL3UXuLhJpoeuK6nihKUVqmSOsZrGWh7vd9kpU606pai/n4kWQNpjXEWqq2qJqJraFSwWSw93cIirxcsMqgrGU8HHB6RD2dUGKx+1coLfjLCWUsOENpmrxuvfIn9jB8yZGcAwpF0wrxC9U6qiu0NZFqRHKk6EY7ndhyRFeh1W6ccI4ggvGeZnZU71HzSP7Zl/D+Pb5BWxeUEuwwU0tCGqAtOUXKthCdxSIY7cghogZLO5+gvQKnqR5qK8ScyWKpFZJtxNw/lNrLgo9qpJqIFKbvgR1umdCb/r31r5mslcA31vOeK2cinsyqEhOV707f8M35K7yj6XMAACAASURBVPRuT1CVbITHupJHRaKyPT3g9HNzQ42k60I9nxkOR9z9PaFVTNpoIaJE44Ydx/HI3u3ZF0O+nliWEzFH1DQz7PdUo7nqRq4Fv13xZSXXQjEaMYq6bTQf+/TKWoo0cvDUHIgxU3JADw5994ZmXf/d+5UmgjEWu79DlEAVatpQW6aljFIGNwwUBFKmroHYEkZZlDEo+/m7DjPwP7bW/i8ROQD/p4j87621//v3/Q+6aNwwsYSVVBKH4UiWyID5lJdqwEIki2ayIypHSooMViPieDFbgxianXpHkQZTLblGQtoAQbmZ1LursdbyMV2wYnmrdj/4Nd3C8Tf91JUon6o0ViJXPFuJlNZYm2fbVqqSPk2yjpwTOW7w6tgNlwhWKVLOSGsYa6nDgKq187eUQsdI8x69O0CtpOTRaNS8w9RKPV9JdcEgNFXIfiWnhJ5GpFlyFsgZqzVp3FF2jey3503Dfv1GEdT8JSWshKdHWkkIUJ2luoEsQj2d4NUrJDRSzqgQKQL5HFGPgbRekfMTcjySjaH6DasU8ekJvnQYp6m1ouxzTCEH9lpTytr5Ytr0QLtACRtKWYoUImBaN7ADBYshCKQaWWviIANNNL548rPxtei+lXgLxN/076j4r5isQOZbG3jHhcuzyVo6eIkPl+/49eM/IvNE1BCM4lSvFNcziNvTA4NzYAdqKeTzI3mJTHevUccZXzOSKjUlrBsYhh378Y5XZofzmfPlHYs/gzHYV/eocWTRz0QAf2UNV5JkitagDSxXathA697ukAv5cqLV2pddaGg7oV590Su8SoFWEW2xuwkaqAYlJ0qMqJBA05sqdmOv24mZkvvVphiNVRZjLChQ+jNfHbbWvgG+ef7vi4j8P8Avgd9rtACMcRht8f7K4/qR43SPV2BQP5gshWe0w2AscxGuacMZA+rFbIFTGuxISJ6iYGJgLR6fVrTSiB0RKiIKZQzv8iOD1Rxk/MGv6RaOv+mnrBeMwEbiicBKwZdA0+DLRs4bRVmaFppSZL9QtaaJoGLs3YTGIE9PfRMHcMNADYFoTN/MWza0MmhnofTlFDU42uWJcPUMxoEoSi5YYzHGUOeJGFby9akHUscJ2e2REhFlaQ3KPHTqlDTqYCk+kmqg5hfUQ6OtK+JX1DxTl4V0uTCMIzpGsveQM4SZqIU6z7THx565EME8PJC//BKuV9LTE2IcRSusWvuvMUW26pn2E/nUs19tsBSlkeWCef0liKGWTLGO1gqpJEY3klXvbfQl0OwO1YRcC6kVkhQm7CejdaviuenfQ4nye439ljYKhe9s4CvOXAhszy9nkcrT9sA1PFCNBaPxFk7lQnOGtUbi5QlnB7AOciI8PiClMr59QxktORd0TKjaGKYdw3TklTtwaI50ufDV6V0fauwP2P2xV/bQiGljWU99CmcsrWnUupC3FWsdbXDkZSMnD60SqUgT6jRhpgmM7lU/SoEWVKFXhrXSM1w5o2tl0A51PKDQlG0j+0tHRliLGSeU0T0ULwZtdI8tPEcX/mv1b3pXJiJ/Bfx3wP/xO772n4D/BPDqL7/k7/72H4BeJVRi5G/T3zPbHYMdaNIYqv6B4bFNdTxDKaw1dN6FFlYpBMk9lFcSqfYrAVULa/YgisN0j1Ya254p8Tnzj/XX/FLu/gW4VICh6c9yGH748IFf/epX/+4/7x+zbs/kd+t3PZcn5Vkl8xt95u/sE9+YlXfbd6xkvvNPbI+ZpAveNsqgCeeFZkf4KlCWAkrTTh62Cq3C8Y543cAOkBzm/EiOCTVYwhZofkUDJRVsbYzTPdUaSmm48RWlKXJqsAaqO6KNkPyV6BPlq1+Ta6W2RNOKOkyIkr5JZAxVGUrUtGugNI8aJlpMNL+S7QT6Dr67kN++wrrX6LkQLo/AlfyPZ9AOKY4qR4yzZAb4OkAS6jlQdwPUCKaRtEWFQL58JN29wV2hZo/UpT+TsOH8BFuhRo9MiliFpAtpTDhlac2ztQtNrdzXCRUim1uYxXFfHaZpLIpjtZjPMDW/fR/9S/2pPpNMJcnv3y6sVD6Mia/0xkV7vBQ2yUSpnMKZv/3m/0XNEzIORO9ZWiFrTWwbfnnA2olmKile4fqAKI3Md/iHhLSAzqXHdaY9JltkLWzpIx+XRy7bBe0G3PE1YVO0sJJSYItXYsk0qymlQTjR4tb7B0WzhY/EGED1CVeT1ovhnUO8IYWehpRa+wug0mitqU1Qz7U6RhmaWHyKkM60BhiDaI3ShiSC1oJIo7aIaolWumFs5XfXFP2X6t/MaInIHvhfgf+htXb+7a+31v4G+BuAv/rv/2P7+V9+wWRnRPoESUrl4k84MzC5mSIwoH9ghCyqX+21xpJWkmoUI8/9S6mXUSff34xrgVI5xwtGW17vv0CJ4NBohJoSexn4K/PFv+ggU8hnIcf/6le/4q//+q//3X/eP2bdnsnv1m8/l0bjHddn7s133GG4thNP5wt5EtS7D70c2grGCcU1pEbamwOybTQHWAUhwKxAKbgzsEbkix16W9A14PSIfXWkPZwoJaJHhx32HA9vcHpA/II9vkEjmFZ66H54TauF5FekzugcCdmi/Ua8PCH7iXLY06zqYNKSUC0hKOTta/L1TCsR9WZPWQV1PdPu7mllopkF9cWMVIXc7fB/m5AvNcM04reGKSfUq1fYn9/D4yPFHKkPD8jB4qylqQajoL2DkpCfO9QlM8gIrZKvC5oddqzI2yPpfcTcWbTAqBzTtMeheWXumULj1e4Lftb26Fx5a47c2QNv2eHQjBh2WCZ+3DXEv8Xfl5v+NJ/JHyqI3tIGwHsbOPHIkQVDZiMxkDmHC7959w8wOw7/4Q1h0oTiGY1wIcHpyv5wxDrXt4UfL9gvd8jhQBUwVWFKRrRj2r1inu44Nku+nnk8faQcKne//EvksEe0IqXIFq69P9WOmNao1ysqBdQgNCbq9UKsEV7vMG5Pe8ZDaOcYh7HjWWqlls69U8MeRKFa64T61vpkqjRKirTiYacRe8Rqg9IKJaZPsQRo0rOqMUEt5JRpSlDqj4CjJSKWbrL+l9ba//av/fgWhUteiCmwGw+gLVor7qZXXMOFa7gw2Zmo+7p6P6Z6AK8BTjSTnah5peXKzljq87VJMwMhe0R1hs3e7XnyT1z9mcN09yn0rozlmjxf1yd+qe7/RTj+lte66aekF35WID+Xv0ZC7TjgUBo+LORWKMZS9P/H3psnSZadV36/O77Bp4jIzKoioG5rmZahtWgjWoR2oG1oBVqAzGTdZBMECLBQU2aM7m+489Uf1z2i0ESRBAtkgiY/ZmGe7h7+wl94vJvnft/5zoEyt7Yh5TwNVwrk3G5Lgd0OQoDNBpUSTBMiZ+puQ3x8Rh6PqO0e+8WX9HaDRZKeXzC7PbVmlJBEIUhSUZInxrXF+9RKrRWCo0SPuTmw5kh5/ESxFnXYU3db6jwjU6EAZtiwLhNymbCHA+n2BjlPhH5DenkhPDygt1vYblG3EqNn6jgySombJvAepTURqMsCux11XUkxIbZbWFdKP8DsyKdnoh0QIWOMQWpDjYFUCioXUIIcWz6kz55RFGKprDJjqmjO8CQ20hJzIJvLxKE8f07X2cMr/m2QKT9JslxqBYiTKfyOZ56YWUmvX1Na+M39f2dKC9ko1kGyFkdSlYlAeH5Cmw6lNcU5/PEJvRmh35JKxEiNOE/6bXbvGOyICZGH5+8Jywxjj775AH1HSJ4wL4SSKFKRO0M+ncjrjCqitQXXhVQLbEdEtyc7Rw4LwlrU9gBaEHNBpoQyBmMHpJDUEBDRQcqoWhC5Qk5EqZFaoocBLXXzGFCqWTuUTE2FHBwlXGLCBMZ2mP6GznZt4/kz8OeYOhTA/wn8da31//iXvEYi6MY9KiZe1icGM7DpdiAlu37PHGZcXDHFoLTlKBwbLBb92ne2QtHrgSWt1JjZaksVUESk033TZ6l2evtuz9P8gFGG3o4EMlYohNY8pCOd0XwQ239kM3HVa13xHwUXfdaE54gnUvC5LbsuzKTkQQkiteWFeQ9930hVSi0U+qzTwtrmJbWu0Pfkpyd0CKjNAdYF1hkxbDC//J8wyiJywU9H1DAilUYJWHIki0KulVxiK+HLNoKdYwIpUYdbYvGI00QuAaqgTAtymlvsjVRNjC4knZTkQYPSdJ2lCFAxNnd476kxIocBOe6oXaaeTuSuAyCnRA2BcnsLX3/dYoUOB3h5oR5fMPs9xEC1hjxNyFuLr6VVyYaesEz0tqPmTDGG6B2q3+Cjx5eAFJa1Rg6qw5VAlK0N60IAms60Q1Ovgvgr/o1QzkMwfww+eUoteA2/4YH7M8laSHgiSw785uPf8uSO6M2OnD1L8QRVmEskvjwibI+Wirw64npE7/YgFClFjJYQI6YfGbfvsEoTT0dOLw8UKur9ATYbPBCXJ0opoBVJScLpSJyP6Aw1F1IIJAllO1C1obqVeHxEDR365h1VNwd3UUrTiUmNroXkPTUmiAGRMqK0qWppLLrrAYGQbaIYLVFCkmIkTidqjNRaUdog+w5pOrTUIKEWgYsO8ufPOvxfgf8N+H+FEP/P+bH/vdb6f/3UC6pqmqtkNAd1y+wmHqd7tv2eQfds7AYXV0otlOjQyjKrNi49Yv+AbA1mYE4rNUa2xlJEZREJq3tCcihlqMCm2/Lp5Tu+uv1PGN2OoaVEKs338ZnOWg50f/A+A5n+6q91xX8A+DPVemFtHjgk5uTwGuZlIuQMXU+RhVhrm8oRohGtGNvt5f44NvI1DKhloSwLRUpKjMiUwXSIL96hrKU4T15Tm+7pLCl4Am1KURrbMg+p4DyFQpgXtKzIzQa/ruToEHdbrLmD00R6eSKk0kSpXQeltPzSu3eIHCEmsuiRtsekjLQjwrm2WDoHZUAJQc4ZqRR6HEkhNDNCpSjv3sHHjyBls7V4fGyVrs0GO1qq95RaIUe8rHS2R/Y9MTj6bUdFtOmnmqAKgg+YwbBkTzEjLq7Eft9c7kug1koQCehe/bSuDvFX/DlxMSj+Y4g5kkrTPv1a3PP9q7ygkay5BH778Lc8ro+IcYMfNe40IxGsOeOPDwjb00tNWT3JLYjNtlWllUQpgQyZfnOg2x4gZpaH7ynBkYeeutuQrYWwknOimo4kE256JrwcUaWgaqHkRATYdRShCHFBhgXRD+gPX4EUTWSfCsZ0TdydKmJeSNEjQ0SXTFUaZQek7agpISRIbZpmS0pKKWTniTlCLm2asDdIaahCtHWhVkJ01NK0ZlKrtin9GfhzTB3+3/AnMpEKIXmMNqyycDPe4uLK0T0TzcC+OzCYkTUuLZk7R0QRRG04CceIgfMOsUNTdc+SBSF69qYjiUqQYJQl5oiSmqHbELPn0/F7vrz5ZRvZpC2+tRa+TQ8o/Z7tj/QTlyzGz6HXuuKKPwWe1rI6kZgIRCoxBYLK+GUl10SShVjja0WpqUFpuixrG7kypj2XM5hW4cF79HYPqkX2mH6L2B+o8wyhLbhy6KlupaaCHjegDVJJOL2QThNi7JEuYoWgjhvm6aXlGY4D1Zjm42U19Fv0PBFcwOQI3YDY7dF9j8mJkE6o04wcR5QdEX5Fqo4cK3payGJE3N0hQqSuDrPZQIwUKVExIsaRPI7t/FKiHg7w9EQEzDhSYySlgLYKnG/C+95QXjy1glSalBM5RdCGFBfyuMVlRzCVsHqiqCQSSI3PHqXFaxSPAiKF7kq0rvgz4PJ/VP0jLelUUvv7M5b/Lu75lglHbCbGZ7L1D0+/5YeX72GzoYwdK56lZgQQX54QXYdGENeV7B2lHzG5QNc3fXVI2MM7ZNeRphPxdKSUgrjdULuRUnOrgBtDVh3r8ZF4eqbmikIgcsLlBF1HlYKYQiM8w4jcjE2DlQsqC7Q9Tx/7gIwRsXpkihRA9QP0+6bJSokaA9p0CGMRJbc4novjO7IZn2rdboVqDqA1g49UQWtR6gFpNI3e/LxK9Ge52mWRCCFIKaGQTHi0sdyO74g5cT9/wpXAYEYAlGyhjil6UslM57DLdC6XWhS9so1YRcdtbX8cWhnUWcSmhGI/3pFq5nH6SKnNN6vSSoyuRH7IL/+o/HrRa11xxV8qMvmsz8q8sBDIrMWxlkCoERcWhNIULclAiREuafQhNNJx3s2hdSNb0FqH89yS67uOrARKa+r7GzgbB0opkX2PmFZEiNhupBoDVOLLI3GeMR/eIztLMQZx2OHWGR9mSi+hV9SSEDXD6uF0pCDQJVKrgs2ACp6SIsVoRGcoMlPWFZUKHRY5bNBCUvoBeXymGoO6OSBjpqaENqa1C4FiTNudat1+B1rDfg/zjFtXkIIyn6jGkCWksFJtR9GKmD1SCqpUpHUBUcmitkH6UgiqRfCEHPA1NsFvDhSap9HFG/66nlzx50L4icyBXDIuOTrT8TvxwtccWc7ekxeS9fvj7/nu6XfkwZI2HbMILCRijYTnZ2pnUVWQvSfECF2PKpE69EhRUTnR3b1HaEW8v28kqlPkdzdEY5qXZYXSdUzrxMs3v8E/fQIhUAWCn5lrJveaoCpeC8Rmg767Qe+bqF3litEdSmnqNCGenpDPR8R0QpIx2xuGm/dY01GXuVWx+gE9js2ipiZcaZunlBNISKbJEpTUzbAzJWpJrXW43aFubmEYyLLi3cr89In54dPP+pw+kxV6pdPN9ypGjzEdiYqUgs24J4SV+/Wevd2x01t8dkgh6XWPT44kJatuupRLdmGHpqqWtj3HhZ02PMuA1R0uri3qA8lhvOVp+oSWhpvNO4JopqcYwykufJKWL8X2D4TwV73WFX/JCBQyhRcczzSjTJcdWVaWMJGiI1tNLIFcSqtk5dxahI+Pb9UsIZpn1UUUP00QAuLDB+gtIgQ47NFI5Dxh+h1VaeppQqSC3uzxIlHmswFpTnCzZ5mPxMd7UJpwTKTsEXcH6m6HoGJsRVSFShDfW3QMza1ZaUoq1LFHLJ68euTGkoH8ciJ2EqMNolqym8g5U1JA/vADdRzBSLJbQQik94hxJJTSiNayQNdy0bCtil2mibjboaeJujsgjCZEh7YaVGv7WWMRCuK6oLcjRVpKTqRamUtkoyQhebwY6PUGHzw7WsXxslZddVpX/DnwU4akpRbWtNLrnq/Fid/wyHwuTngiC4lvl498/fHXLKpidltmGfE1sdaIn5/Ruy1draQcqTk1y5WcULs9pIAQmu7dB+Lq4HgkS+CwQShDzhGJQnUd3gfcp2/I0SN6CykTTi9UIcnWUDqNtKYRH9M0mEgJpbYpaR9hekGEjBCVmgtIgR1vEEJSvSf4Bd2N6P0tQrXWX6mFUnLLNBSVJCRCSZQQLUVGFjISqQzqLHHItbZUGTeTk0emQhWgtEWa7h9/AH8CPmvmjDUdIXpi9AjTYc8Oytr2bJRh8QsxRW77G2IOpBwZzQafHCE6irYUUchoBgwdCqSl6MqcFgYtWGV9FccbZamqst+842V+RCvDbji0CUOhKEryHE9II/lKbP9gEvGq17riLxUXB/IJx3Su9LrscQTmdSWlRNqPlLw2/VGMjVzkfLZzGMG5NxH86dSemya4uYG+p6aE7DrkZgPPR6xuV0N++IQsmro/sFRP8C1jVAqo40CeT8SnZ5BQjCBWhRrv0Lv965VUaiG+PAKgpUJsDoi+a1NItbZFV0hkiuQpYCj4w54YAzWslOMRLwrq5Zmkd1TnEF1H7nvk6UTNuWnSlGpE0to3bZoQ7avvIWfyRaf2/Ej37gtIufnyWENIAd1vQBqSn8mhkG2FWqhCMqWF93aPC56kmz7En8fRg3irPDTHn6tO64p/PdJPGJLWWlljI1k/yJlfcf/aAXIkJhIf/QO//eFvWUVCHu6YRMSX1ATwxxeSEgxAThVSQihFrRm9vWmect2A3u6Zn5/Arajtlqw15GbLq62hFpge7ynLRDGGKiXx8YFUKtgOsRmpViOEoirRsoyVRIiKKBLpHHU9YqoA0QyYZBWIYdu8+5wDAWq7obMj+dwerCVSC1AiqVaEKMgq0UK042uDpCKkpUrRMhDjQkkJQqSW0oZ2kFQkJQVqjO35n4HPEyptEhLaQnMmWyF6pBF0KBSKoKAbtviwcL/ec7B7AHxy9GZA5oCLnqI1VbbFa8C0SpTsEFpwTDNSQ5XiVRxvdAdU0rjjcblHSs2m2yApKGUI1TPlmQctec/4SqzewqeveYhX/GWh6bPya76hI7JERxCQwtJiLUwlhXOlqtZGqF5eGukIoe0iN5tGuM52DvQ9HA7Ic1vRbLYwr8hUSAbc17/FdANq0xFq04VhNGWdqblQlxfyucUmhz1lM6CMbHqKXKilYgvE04nqHVIaMAq520KtqM2WfDqC94jhgFWWvJ5wQiII5FoonaLe7NDBt8mjaii9ouTcRtE3G8q6NkI5TW/nud+3at67d6/TlZxOlBipw9Aifg43GN10I0prqlspSiCGDpYTJa5Eowgp0Wvb1rFBsLpAqrU1CAWUkslKvU6GCiC/Gj5cccWfhn/KxmFNK1pqTjLydzzwjDtXsgoTkcf0zN//8CumMKHe3+F0aZqt7HHHZ7IWyCJIpVknQOuuyd2O6hb0OCJNz/rwESEK3B0oqVKCh35AIfHzRFpXUk0UISiPHwkposaR0o/IXiOEoUpB1Y1kSQHVZ1Tw4NoQGwhKqdSyYvQI2lBzpOgOfdgjVEctiZDC+XqqzfcqJySiqSGsRUrTql9UhJRtMCjMZB8Qr/Y2mZKahKGgUFIgpEQpi1QKOfwF+Gj9qUiq8O30A18Od/SqQ5zjc1xyKD3QoekQRJGh2xCV58kf2agBLRUurvRmQAnFnBaczFTdkamMZ7LVSwsGapw4qYxSqmm4UsCojqEkks08zvcYqdskFQKpLKfoMMWgpeSW4fV9ZwqJ/Fmcna+44o+hUFrAK4FPODKFtSZc8QQ8bl2onUXk3NSHMTaipRQcj3A4tMf6vj328tJICcB2+1rx0eNIzRkxT2TdUb/5GjlusHd3VG3ISiCo5NPUwqIrCCOpoondy6BJaaUUgSSjM4iQmE5HakiIcUCZjjrYRmhCpJamsRIV4txigUTfo2qixEAZR4SUCClbXmIpMD9Tbrfw/Ewehvb+d7t2PjG2r0u70Nq3cy+l3Z8m6t0dWUrq8xNp3yYIs6yIlPBxZegGqqxkHxFdIpdElT0hOoIUBJFwNZBrbm2LkqjKvBItiSCfMxCvuOJPwWXD/8fgkmtVZi34G+75xHKuZGUmPM955tcff83T/Ih+/55kDY7AGlbcdCRJmtGnlBADuYpmYjyMaBcQw0gB5sdPqGGk9h2sniwlxVpsTOToicETsqfML8TVU/sOsbtD9LZN/ilF1k2ELqVA+ACrQ6aEkKaRrBBbq3IYsOYWISWIirB9qzQJyKUlv5RaqNGTYkYB0hik7UEKSIWaMzE5Ss3UmEFkalFAgZgQZKS0GNshVbN9krUNy5UKkkr+Caf9fyk+C9ESXjGXlZcwUVSmUxahWj7hkhxKj+izC7yiInRHkprFr5gk6JTFRejNwM5sWdLCci6XVgE9FYuiE4a92ZLjCy8EjLKtd1szg2nlxhnBx/kHvtr9AqGgExqhDac0I43ECPUHk4jhrNe6lv2v+EvAJdNsJjCf/bPWvBIoLGEluYVwt21GfEI0YqE1zHOr7pw1C6++WdPUtEtKwW6HzBkxtgU2Pz+hi0C9rDB0qMOB3DVtZMiRMi+UHBBaUrWlxkwxkqoKeVnazzxnkSVpqLkgTicQFV0i6bZDS9lCY7WgnibwgXI6UZwjb0fkF18hxo4yWOrpRLr4fg1DO4/1BGLX2qFKNVJ1aRGua6vWXQgWNGJ5c9OI1jC8Vb60JoTA4BzsdmRAmiYMztueKi0lBoiJ0BVGBDF7ZjwbJYklNqKlBCEHBjOcBfFtLbnqtK741+CnJgxDDpRa0NrwX/nE9xyZiXgyJzxHVn77+BseX75F3NyRO80iIoubWecjSRSE0ChlSOlIrhZhFGIY0NHD0FNiIAeHONw0m5NlpmiDkRIdIy5Fglvw60SanxFmoN4c6LqeagVVtIGcKtownPCtelVTQQqFKAIRXMsm7Ub6u3dtyrAWiqjNPFhKAgWJoNYMPkD0CNk8s4RRlFio6/z6WqggJFUooFJiQdaIUgbRj4hzy7KW2gZmYnjbENWKFDTJxc/AZ+qDCcy448Ed6e2AKolaK6M0LCUw5ZWDGl81Ut25lBf7DSUG5rSiUvvDGu2GjdmgsmeJK0V3VFmpVBSSXhhuzJ4Un5kIaGUI0SGVbGSrZhyFT9MPfLX/BVFkjFRElVnSijIKjaT/0a+q6bWuROuKz49Em559YGUmkUgs2RNqxIeFVBJpsMSXpRGRC6F4eGiE6qLRkrK10i7Th/s91Eo1plWKnp6QKZONJUmBHDpqp1BKtJBXHwglIHVzXM7rRJqnVq7vOnLOqJsDetwgXKA+PlKnE9iObv8edTighCDVQs4ZkRNqu0PqgTKOpHUlrjPl43eUmx21s0TRcktZ1zeSVCt8+tTagzm/kUZr23mF0ITwHz60W+faVwjtezabRgitpcRI8h7Z92AMwVpYZ7rdLYwD8fiETj2xJooSUGDJgax7Jr8SbUbLZjFTaiX+SKeVrwHTV/yJ+PHk6o+RSiLkwGhG/k488g+8nC1eGsk64fjdyzd89+l3sN8htz2rSMx+xc0nUo1UZTDKQPDkXNBWIbsOFVObunWh6Qpvb8B5YooIbTBKUktldieCW0jTkVIqbG9QtkNZDdoQlUDqJnKvboEQKLEAEpsyQmSM6VA3N+iztCDFZt0grKGeJ6ZrrYham9XE6tBKIFQTs9cUIfrWnBcKYdS5LRiJq2+tUAnSWIowCCEg+2aULC4WLJFaWxW/CkFrXyZy/Q9Y0aqi4nRFWss37p7/M9umJgAAIABJREFUPH5Fh6KmRFclPjhOVnCrNkBzsDCoZglhO5CKEB0v4UiumV23p1cd8ixILSpTVEeHQqPoheXWHEjxiRmPNR0xOqzu6fVAThCK537+gQ/br5AUtLIsxWOS40HDl2xbqDVNDxZI2Kte64rPDE/Gk3hiIVOYSbgUWAm400SyqumEfvyiH7fPUvOwYZoa8bi5afeHocXzKAUPD0TADgN6TWQjkbstYtORfSB6R54XpKwUaagvEyUHqpaIw03z1alNWFt++B4KyFJh2DXNx2EHgyHFAC6Qk0MVibKC2muM2CMOB+R8ZHl6gnkiBvNGns5EsJkK+ka8jGkEyvs3XdYwNKH/ujZC9v59I1iXKt+l+nWOJqJWQowY5xBng9N4/JZcA3Icyc/P5JRIfqFsC0JJXFqIeoMn4NLKYDsihVwzVeizL5+m0sjWVYZwxb8EPyV+L7XgkjtPGL6cxe8ef24XHnF84z7x7fe/InUGtR1ZZGJ2K+v0RIwROoNWlhocMWWKVmANIhWqEuAWYmcx/ZY0HSFL1NA2MM6teL/gpyPFO4TtkcOIVhKMJXYGpQSkCMtKcaG5yVeFAjqtUds9ymqk0ZSQCfN8fg+qSXpqoRYoJba4rNUjZUV2G6rRUCWi5OaLVVoUGTngpwkVEhmJMaa9FwEZQZUFLyWIRC2lDWLLZvkiKOdosoLQglol6mw19a/FZ2EKRZZWVTIGmQPfuI/8YviCzhh00YgkOK4vJJv40t6ec9xKGytHkLRgkBoXFp7CCV8i7/o7rGytwlOcWetK1T2WikYxCMOdOZDjCysBow0heQYzEnNA2IE1TDwuD7wb3zU7B205xgVdNA9y4QOb1ypboqAoV8uHKz4rPImFwCPubF4YWPKMzxEfJsp2bGJwIRrpUOq1hUdKTb/kfdNrjWMjHNtte2yzaVWuUjDjiKxQtcAcbhC2I91/xMeIWhyMPVSJnFeSFq090HUkQLh2rVcpyeOIWJqeSkug05QYkKJSxg4EmCVTlCAB1SfqqCgxEEuBwUCk7TZjW3jpure2aNeBe27/3m7fnO6lbORLqUaunp5aVWu/b9W9i2brQtyWBYxBlILIGUJAdh1ZKdbTE+PuHUVByhntA0v27LQhBcdsIjvdMSfPnRWtoVsyRTZ9TaWeJw+vuYdX/PMoPyF+//GE4YsM/A2fOOFZScwEnlj5Pj7x9Td/wyIK5vZdE7+7lWV6aj5XxqC1Be9JJYLtKDohcqu4plBgMyKhBcALid6O5BKJxyNrdOTTESmA/R6FRhpJ6jqKUYgSSUugrI7oIprKoCxm2NAP22bnUBM5JFLwFNtRNx0V2UKm/UKJmexdi9xSCr3dIY0mlwQ5kSqkmmFxJJ+QJZMFaGOImw1aSSKVfLncSoBayFVRtACpUbVSS4HSEiVEZ5DWkAUIZJMB/Ax8npJMFkRRIK4oq3HOofwjH7o7rFQo23GjNJM78kO554O9BSnJ596sRZFkYbCbJogPM2n9yLvhHUZoDmbLMc0ssZGtIsAgGYThndnzQ3wmqIyUgpgDu/7A43LPtr/luDTbh0O3pxOaqvWrXutZOO5+JI6/Wj5c8Tlx0Wed8Mxn0etytkHxKZB8oHxxIL68vHlnCdGIxjkHEGsbmbr4avX9W4Dq2UdL9j1CKUSqyL6nKkm+/45oLbpW6od36Fyoi6Pux6Zdsrp5WR2P1FIoIZBjRIdAzBm1rnC4JQZHSYkaJXKVCKXpbI+IiZIiVWn88wM5Z2qO5JSaBUOtCCGo220jiZvN2ek+w90dPD830hhCO4+LrYM4X6svL20QYLdrpOriG/b+/avVA9NE6XvKOCK9p3QdZbcjHY/k/R2l60kxkHJHcCtsbkjzQhSVIDNTnM/ktzTB7tn8uE0eXonWFf88/ql4HZccWmqczPw3PvKMYzmbkT6z8DEd+ebbXzGHBf3hHdEK1rCwzC94v1I6hdI9IgVKiWRtm9dUqa1dhkRuttQc8b5N7Nehx68zKXqWdULOE3KzQ2iDJpMHTe36ds1PpzZ17COqQN9vGLY3qH5sOnW3Ut1ClYpiDUJZMhXhI7VEojjnlMY2Rch+RzGGECN5WQEQNZJcq/eBPE8xWoSURN3somLJzRRZCopSVKMRtSJqq7SLUlplTCmEambLJSVK8JScqSk3/66fgc9DtHTFKEOWhZgCxcAn/4xUilu9w6AwSjEMe0JYOIYTg+qoSrXpA2g2+rIy2DZ5NLsjH5dP3PQ3jKrnYLZMeWWJC1Z3FGmxKIxQfDAHvo/PZCXINSGr4tAfeHFH9ptbHqZ7jLRIM2CkJkrPklakkWgEe1ru0dXy4YrPiUgmUnhkPls8RObsWEVq2gtZyEo1AnLRZ0Gr7ITQqjnev2qS0LqRDOca2VqW5uI8DMgKIq7UzpCnF+I4op0jnc0/y7RQhSRNbXGShwP1+bm1DK1tDvIpk7VBh4j66hfod+8QtRBDQJyOlMW1eJ+taPoKLVmzI2mJUYJa2rVflwUhZXOgN6aRpaenM9HatEoWtIrd7e2b/urHk4a1tkrWWX9FCO12WeCLLxoxWxZYFvJ+j7AWcTpR9ntiSpQcEZue8hCpNRD9Qt6/p6SIJxGVbXlyNaAuuYcMZ9lBZkCeFTdXndYVP41LBfQfPZ4DlYrUir/mO77j9OqV9cTKQ1359uE3PE336Hd3RKtY4onp+EJIK8lIlOlQuVKTJ6tW7VU1k2ogyw5pLTk6UgrYfkPQlXJ8wpWMPL2gSiYdblE0M9G43yNqIS8TeV0o84wUYLd3jNsb+n4DKRLWZqOCaTmDuWRkiZArWXJu5RVyCKgqYdMjdEdwM9mthOTQpVJFpdAsIqRuRqdZtp6TAmo5a9qURJjmnScRiJKpAqqSCK1ASHJOsHpEbikPtTSdd8tLFFT58/6P/zw+Wjbh1om+2yB1RyiRRQW+XT6iN4ZRWRKVTiq0HXDJ0wkQKRFlRSlzdnoXCCEYzYgAZj9xdEdilxjVwFYNzELikyOrAqrDooki8+Ur2ZIseWFrdnTKEnJiNx74NP+A3v8SKQVKdyzBY7LhpMCiX8XxV8uHKz4X4jlO4yMr5Tx56EtgTZF1mRBDR/a+EY583hVfpu2gkYzvv28Eq+va/XVt7bWUGhkZxyZcnRfYblrH0VrE8wuhNMNT7ROlM4RaUEtA3d6SYnxtGcpSqM7R2QFyhdt36N2O5B3JryjnqMqgb3fYCGWeSUNPrgGRI8JakjEU75v/3nlEHGsbScy5ncM4QqqtajWOraoVQiOYIbQK1mX6ENr5XSpc69oI2zy338U8tyrZ/T1lWajj2EwSc6YaQ1wXzDiQn58JqSK9I5aIkgqXPE5YkrKc4sSdPhByIpaMlfpMtMxrC1FdidYVfwSR/Eed3y/i98GM/IoHfs/pHK+TeMLxyMw3z//Ap/tvUTc3xNEyF8/08kQIM9FqZGfRRZDj0qbxtESWSC6ZLBRSiWbWSYVxaJXbk8NHjzqekONIUBoTHWkzILqeus6kZaHME1JIut0t4+0HrDKQEsvLE4QVbN9sXEolRYfQLWZQAgXRNmolQj8SBMi4sh4fz5OGBaQiWUkWEqSgyub4LitNX1Uhy3ZOJSVUydScmthdSlCq1b9SAJ8p5yD5cq74i5zPXndt2lCW8h/TsLSkyjFMSBRaazpl0L3iYXnkd/PX/C+7/0IWLcPNSoVWlmNe+aAPmJJZYhO4GmVBtOrWaEakkBzXF3zylFLoTU8vDdLIFlpdEzu9ocdwFI4P5zaikIopTmy6HWl9RhqLVpZP0w/81e6v6IVBGsMUZ4zUPIqVL9i8iuPjWat13Zle8e8JR2I+C14zsJJZ/IlQHNGdSF/cUp1rJCSlRjguzu83N41MXPyjzjvC14Bp70FrtJRwPFE728yBU6J4j6gFdXuL9gmxUeQQsE8P1C+/pAqBWlfkdts8tOaZGgIuJaQx6PEGnwO1JPJ5AbO17R6TEoTkqNPSXr/ZtIWvVqpt00Xl4vd1PLbzub19s6fQqvnn5PxGHIfhzR/s7u6NhF0c4Yeh3b9o156eWrXv4pa/rsQQGgFdForWeLdg+2aimIsnZksIjq0xpOhwpiPrjik53plbPLkJ4n/UCiqvROuKK/4Q+TxN/D+i1voqfv9WHPk7Hjji8RSe8Tyw8P3ykW+/+y1i7Ikby1oi8/EJ7yaibiaefVUk78hVIK2Cktq0YWepqk0sKtkyAcWy4GqhzC8tneHmFpJHFU867BAxNc+5dUHUit3fMty8ozc9hEB8fqTEtW2WNhtKaZYMVbVrVSLJpk0kEgNCiiZUd0eKD83f0iiS0mQpkJcKvWhxz6IUAs0DTIpmtkpsG6wqBFXrNlVYCjiH9J6am0cflySIi83Npep/kVmINpH4mv/6r8Tn6XlJWNOCkZq92lNSRArJu/6Oh/meX0//wP+8/U8gNJmEUQpZJU954p3esVeWOS+s57YgUmNQjHpAjJLj+ozUgjWuZN3RSUNvBlxyHNPETm8YsUwicKd3fEpHCrAWx6bbcvIv7MYDz9M9n5YHvtx8aHotJTmlmb3Z8sjKe5oFxbWFeMW/N1qgeuaZlZXESmApHlc8PkVKTaTLNOFF+F7KmzN838PHj2+6Ja0bAdvt3qpfSlHmGXKiqqGJU6VECoF8/x4lRPOecStxmsj7PTIERAiUDx8QUpKnCVEKahgQMbaw5ufnJjSXEmlMC3PNUELAeYeslaA1sjQRuiilmSL2fXvv3rf3mPObNmuzOVtULG3BDuGtHZhzc4B37rUdyn7ffjfr+mbr8PT0RsouWq0LgXMOud2+7npjCMSakJ0lrzMle9ZlaiJ574kWohbMbqaKNh2aS6Yqzgl1V0H8FX8c/5Qp6ZpWrLJMMvDX3POMO08dOz4x8TE+8903f0eRIA47VlmYnx9Z1yNJg9wMWKFJy0KqoLQh14KMCYxuCQbKYoRsLbxzAos6HVtlebNHuoloNegOeTzhY8s11cOG4fYLOmMRzuOPj+BmktXETYeiksOJohWya/9XCm1JojYhewqt4rT4Vnk3BoaepBS6lLYRy5UqRDMRDgFVCvVcjRJStqtJiLYpkvIt5eLiIwiUUt489qR88xH88abzEs11yX0t/wE1WiI3N+eXOKOVolc9SghEgdv+huflgd/P3/Ll+CWdNC0CQENMCZkm7syeXg/IovApEEWz5e+FZVQ9DDe8rE/0ZmwaMJmx2mJNT4grz/HEjd7SC80q4UbveIgvhJQRRtLpAR8WDpt3PJ0+8aQ73nc3zYOreNbsQcERx4HhXGa8thCv+PfDxT/rByYCiZXMWhyuJOblmWLaqPMrsbosKhffrNPpzSH+x4vOuYJzITLFOdhsULsdUUr0PFMOB4TWpOORuiyUnCnn7MQsJfzVX6HOBqUqRvTh0AiKMei+pwI1RnIp6GFoY9nrSgotV82PI2JdyfMMt7eIw4F6OsH9fXuPZzPVV/3V8dgW5gvZWqZ2budWH/BWsbtUuUL4Q0uHS2Xr4sV1aR2ua/uK8c309UxccwzUToLT1CqasP88YJNEwYlMBFz1DEK1SJIzuYpk2iD5lWhd8Yf4KV2WT745vyvBf+UTj8ysJI54fmDiIU98++2vWP2E/PILFlNZj09M7kQRBTkMKNVTTxPpbIcQakKtkdxpRG8pRiJqS1CIQpDXBbGs+HFEUyh+JiuFjYkUEyFntBSYu7/CDgPSRdLLiZRdW3a2bdq4kIhCIIxFS9mueWsJ8wzLQkoJUVssVbIWMQxt/YqRuiwtq/RScSpn7Sm09QbgQrIu651z7bq+VK3O348Qb1PKl2xXY94GgC7rwWUjp1R73tr/8eP4k/CZpg4lpt9wOj3w0WV+sfmSmgNSaozS7PsbntcXjLDc9HuMshgUUiueo0MlwY3eU6WhWknJCRdXkoxs1chWDchR8rw80psBUQVrdFjdoU1HTZ6neGJvNmgBSMPObDjGCZ8cnRlQPpBzYjfc8rI8opXmTrfpijU6rDRMImJQbM5uz4F8bSFe8e+Cixv8E45EZcHj0sJSPHGeSMNZ1H7RJ13sDua5Ea1LluGlDO99e/4igleqPTYMiNvbFho7zy32xlp4eSHPc9t3X3aIF51UCGQhUNaitluIEQWIDx9Q1oJzlBhRqekjcozEdaUYQ+m6NqkIbUFcV+o0tZP+se9XrW9k8SJizxnU9k3wfqnobTbte7Vu73W/b695enptkTLPTcN1f9+O+fjYiNyFnIXQiNil+pcSsRQ6JMUIsg/kEvA50dVKKImoMkkr5uToxEisrX2ohcSfK+D1GjB9xY+Q/gldViqJzvT8Nz7xzdn5/YTnB04815nv73/HdHyk3t2w9pLl9MK0PJNLROy2KDtSj80OCW3IIqOnhbTfojbbZrrrV0rO+FyQ60JFkLZjMyQOHm0MulacAJ0Suu8xh1uML+RPj6zJQ81taGYYEOdhHAFopRq5UqolPXz/PSXGFhitNelShQqhVZUvhAfatazPdOWyDlz0lZfK04+JFbQ16RItdmn/XTZql02W9+3nXTSpF1zsYC7HPp1+1uf6eQxLqyCNHXv1FZ8evuY78ZFf7n8JqeCDozM922HP0/qIAUazoZgeLSRKa75PE2TBjWoZZquq9HIg5sBLPLHTGzayRwx3PLknBjOgpSZE19xntUVlwTFObPUGIWEre5LOnMLUvs8OuLDSmZ6h3/I4PWD2moMcQUlOaeLG7DniMSjsuZLVDAl/Xj/3iiv+OThZWFmZiSQKK4kpLazBUaKnvju0xQreyESMbQG5VK8unlKXhWgcG8G4iOfHEfZ7qtYt2Lnvm0v6ulKmiXxZCLvubWGyFulcE5eeK0MpRsRXX2HOFaOcEiJGUkqkEKluRdzcUA6HVp26uWnHmyb45pu3yULn3namxjRi9PDwFrEzz+ArfHnTzv1M+l6fv/hu5dxI5Xb7RtYuv6dLxSvn9vMuO+BpasTrsvBKSVwW7Ll1WUQh1UQIM73uiGnFyw1RKaY4c+g2r0QLYV71N5cK15VmXfFTflk/NiX9nXji1zwy4ZkI3HPikYVPp+95vv89adOTNpZlfuY0PZBjRB52SNtTjxPJO+jasJmcT6TdAXs4kGqmLjPQKmdm9sSuay7spxOyFPSwoXSWFEPLJby9RSMoT8+swSGkIHeWOu6oWp+nBiv6vIEKSlGWhfTw8DakIgQ159dBkz/Qkl6qSRdvu8u6ddnYlfImI7hcp5vNmx/e5bq+SCdqbdf2RZt6qZJdjqX128btx6Trx0Mz/0p8JlFR24GPXc+HD/+Z7z79jsw3fLX7io20+LiihMT2G07ZUaNkyBHV7whCoLTh+3gkU7lVW0Y0s4hobSmlMKWFQRgG3UN/y7N7ojcDRllCdGht0cqQRWFKM0Z3SKk4qJFgE6tb0NKgpcYnx2BGUvI8LA+YjWZUllwCS14Z1cALjjvG11bAtYV4xb8l2oKceGHBnQ1L1xpZgsO7mSxqE3BedneXibtzht+r/uFSzaq1kY51bUSn79v9vn8T0iuF6Lo2ofPw0I51mfyzthGh3Q5OpyZW9x4RQiv59z3i4QH3+98DbWpQnHUV9ZKt+PjYKkwXkvXy0qpU+30jQ8djIzrj+Ifl/a5r33uZnJxCE7afq26v1a39vi2mFxL19NTe72WxvohiL/qMs5P9q1BWqUa8ttv2voYBpom03zdDxJjQvuCjJ3WWlDxBR5IdCFMgixb+7UtklP1rwPRVp3XFBf9UWLRVlkfp+FseOeKZCTww8YmFh/WJh2//nmw16W7LHCZOL4/kHJGbEWyPnBfieoJxJOWAmBbqhw+Ys10J60o4Xx/FF9LBtIB175HWUne7VnGaJ4S11MMB5pkYQou/6SxlHMnWIlKixojumkVEEoISI/nxsV2TzrUTu0gbLm27C8G6kKwLLsTqgsuadVl3LqTq3OJ/zTSFdv8yeX3ZUF7Wiq57q1pdWoMXAnbpBNT6tib8DHwWopVEJiNwBISxfPH+P/Hp6Vs+rQ/E/sDeDoicySHhsqfTPVoI8vzM0G2oxpKN5lM8UoTgRo5ssUw0zxphO1LO5DhjlOW2v+XZPQMCqzpiCiAFVlucPhu/KYNRlju15aMtTOHItjuQc8Zlx6Y/8LI88eifUf0dvTas0aOFAQmnH+m1ri3EK/4tkShEmblnJpBwRFx2LMWTlpl4Ka3DW8sM2qLz47ba6dQISEqNOHz9dVuMLjE8Kb1VwPq+aZTu7xvpsfaNaG027Wc8Pr6J0J1rhOssIq1StmOeRa1F6+aJ98tftuNfHN4vwdYXEf/l+Be/r4s9xUVPdonXubRJbQ/+HMGz37/psV5e2jkq9SaEvxi3XiYTQ2hE6kKq+v7sNO/a8S7t1QvxSqk541OhM0S3kPKBtbS81JA9wVRcTc1bi645WJ8/wwvJylei9f97/FSOYcih3arKX/OJT8zMBB5Z+cjCU5y4/+7vWbMn3r3DJcfp6Z4YV+Rmi9jtkKeFcDySh47sZkRKqF/8AjUMzRNunpsh8GUwpATKwwPyfA2J8f9j7z2XJEmOLN3P3JwGzSzSBMCMyL7/4+zu3VmCGaABFEkWGcSZ0fvDQss8a9Ezu+hZ6Wl0mkhKVgbx8IgKUz969OjRFU72X9dRAur5GVNVKflqmmROfNVUqaJAdx1OKdw0pf318JCeL+yQ7KGldkpAloAveYwkQQLIrgw7l0titCUxkmMJWJIS4e1tbmxZaLqAnLAJ+BOWSxh/AWI/cf089g6NY7QXQtWhUKzrmpv9e87nRwpd4qvASlW0bUecIw+Xz3y//R2rbsU0DpTO0rZrbKl5cCeoFJ2qWFNxwSZmSRcUhU5lCmBXb7m4HqUUTdky+5loDU1VMVWKyU54PK3uuK02fA6Gy3xkXW9x0WKjZdvuOY/PPOvkMF/pkt4NVPWOHktNyepaNnwtIb6u/1drxnPGcAIckQuWs++ZrcVMZ3hzm4LbNfB9ASrC2EiWJ105m00KWJDsDzabFMS223S/+FVdLhnsxJiBiwAlYxJ4G4asgei6xGh1HUoplHP4EJIOqyzzXML379Ox+z4d882bdBzRZ4kuC/LrxZhAkzBv8wyqSB2G1xE6FEU6h6WmC5Ip6fGYGSoBpvI8YbQk6IpIXuYiLgxOXVmijKOMER89ITp81MzB4RW4IjB6Q9BpALWPAa2Ka6ey5mqN+JqY/UpXaqT633VZPniMN9RVx3/lEx85MWA5MHJHz3MYeLz7E5f+CfvuLZN2nI/3mLlHr1aU+y3xdMEeDszrFsY+aaV++1vKtsU6hzufCSaVAkNZpj3RG+J3LWGzISpFOB7THihLinnGXW1RVF2nTmDZD9e9EYoidSuPY2KXj8cMrpaM1RJILU2VlxMcRJQu4En+LSBotXohkkfr7AkopUARyFub/i3SCPlbQJqwV5Jcik61KDIw+xvXz6PRIvB8fGSz2RPbLY7ArlmxvoraK12hKo33hrZuaLnh4/HPfLv/npv1njDP9MMzXb0hFgVP9sRttcOpJE41BBQFQYGqSkoPwRvaomF2iQ5sqw7jZ6y1VKVGVR2jHXAxsi473ja33IUHBjvSljWWgNLQNmvO45G6qLjRa1TwXFzPtlxzZEKjaChfS4iv6//ZmnA8KcN4ZYUnLL0ZGE1PULw08hT9gjBGAhykDCYB7XTKI2nEP2o5sudySQHzcEjAbbfL/lVKJYAiXlQCcOr6y5zBeD4TpWQZQnZvl9d/ekrHEECz2yWAVFU5IF4uWV/VNFmkKtR+XcPTCBNZ4C+eYNam451OcH+f3oOUDkSXtdm81HQVRWYBpYwoHYrz/EW75d6/p5odjoj1lik4mqgxpWEMBltqjJuZCkdUChsdWtWYq80D8Gpc+itdP2blIH5ZddnwR/XMHzhywnJg4hMnHuPA4fiZ49NfmPc7bKu4PD9i+gu6bdBv32D7Hp6fmLvmi2yg+sd/RDcNszFJK3X9rgfn0h7sOtjuoVXJZ0qAxnXfhq77sm+i1un54kkn7K8w0odDejNNk/ZQ0+TEbOldJfeJTEFiwNIkVBgmAUSi5xJNlWizZO8ak2UCAtKkFChgqywzsBKmTc5L9r+Avl9i6bAkdReezgeMNezWtxyKyLbtCMEy2QkVQbdrhhApa00d1zz1D1hvedu9ofVXLZcuiSRx+qpa4ylpKLDXuYgR8LpAFw2Fszhv8SEBuqZqUd4yWQtVQVutmNzAyV3YlRtse8t9f48KilqV2OAor4Own8dn9EpzU7YYa5ijA1VeGbWCkuK1hPi6/p+sEctJT4yk75vF09seP55T27OAgtMpAxLnciltCSJWqwRwNpusWbI2D5uOMesqzufkL3Vzk+5fapfu7tL9IkiVsuJV//GlI0hA3Pn8he36cp9kqd4nhu3mJoE5ySwFyAlIEs3VNGUA2bbpWGIwKOVB6bqUEuPzc2a6RL8mYLQoss5DSobXbskvcxMly/WeYAwKTygV3ozE9Z7JGlZNYPIGU66wxnCJhqDAREtLfe0wiwuH+Nf1a1s/auXgZ3SheS5m/icPHBg4MPGZMw+MXIYjDx//mb4t8euS8/GRuT+iyhJ1e4sZR+Lnz8lL77rXqt/9DtU0DOOYm15E2yQD5ssSLh5MyOySABwBM/IcYzLzE0LWVYq1QlWl/dR1WfMkoG29TntVqfR4OYclAJPyoYAuiVvSTSgASUp/wn4LmBKQtfTKEgnDklGDl92IXwMvOeZPWD9P6TAGdkXHuSxw88iTNdxs33CuWlRTo4yhig479ZTtCl+UKDpssBg38jg8smu2rJs1xk4EPJN1lGhi1eJQlCRfjUikRoFK845WSnGZzlid5oy1VUenCi42OT7XZcvsRg4udS+a1Q3PwxOxbGh1yxQsTbtmHE6c5hNVq1nrit72VPWOEUtJwZaaAvVqZPq29wkFAAAgAElEQVS6/l2XvZqTPpcGQ8GI4ylcMM5hpQznXKbHhdaXQCK6q2VHDuSsUoCQ2CWcz7nT5927VNJbApEYX4KsrkvgTZgi59J9EvjEEFUy26enXJqTDFZc3ZfATBipGOHz53TbbpeHY4uoPQQIV4sKGSEkjNbjYxbJx5jO5XjMsw2tTUDu/fv0usdj+reUEq7WE1+yYe+/ALBZa+pCEYxJM9iCxUbP7CdctWYOHo/HKI8JDvTXOq1A9Qq1flXLE37UysEHT6hK/jsP3NNzYOaRM4/0DKbn8eM/0+OxNzeM4wlzOQFQvH3DbC3qwwe8dMvudpS//S2xaZiHITG6wuqI/lCSLO+vruo67+OyTPtjaf5pknYMpdL+mue05wR8SflO9rlYvyzj0/19jgWQy3PL2LS0jlmW8ASACesuMW2p75KkCV5qwWSVZT62vNayu1HAHvwyDUspIyFEVkWNLUust5xOD3TdjlW7TkCUCUVHMU3odoWqK8piy/l8ZFeUHOcztjDsmz3BW6KC03xmHyK66TB4ChT66tzeUqLRxLJks9rTj0dMtMSYBlPv1IYndwatqcuO2Y0c7YVN1eHaLZfpDCjasmUOlqbdMI0XTrqmrneUQdH7kY1e0WOoKWipXo1MX9e/65pwPFy7DWcpG9qRYe6x3sLu2j0olL9kn/t9ZnOkpCilObFykOC7fIyALhGdz/NLI9DjMZfvui5nvJCC7jxngb0cS+h4YZAeHjJrJBoo0X/J6Jz1OjNgS2dnyGXCaYLDDKrM3UUy11CsHITVurvLGfrDw8uSxOGQAKUI/3e7BMBk6PbhkADYolkgxogHvFOYYFFEJj9jCottFLMy2OCYtcNG/YXFEgn0a+fhr2v9WyVDXdb8L/XADzzzfJ1f+ImeIRie73/gaXrC3u7ppzPz8YAKjvKbb5hihA8fUiPK+Qxv36K/+47Ypbmc3N2lFxLvqNUql9rg2vnXws06M8zCakvydTUf/sL2nk45JpRl2uuinZJYIAnXsiz/NXsEmXX6WtO1tGBZAiwBRwK8xCtv6e4u7JUYlEJ+rpQUl+VB0a4Kkybv+SesnwVoWRc49g9sN7fgA3XVQq0w04hzhq7ZMM4DodXMPrCfI12zQZc1zeaGYezptGaIM2564qbaUSigbhjsSIyRtu4IRZpDWKHwRLYUaAp8Aatuzzidcd5ymc9smi1vqx339plIQVN1THZksAObaoWrLJOZKIoSpRJDVlQV/Xym1hX7siNYw1xUKFVxxqApqNGvsxBf17/bmnE8MjAUjhnNyMRgR9x4fpkRDkNmcyAFnufnDBRWqxQQpQNR6xQwJZsTM9NhyAOXL5cc8MRBXjr2vv8+67vkPOS5AuSMSaBFGDHpVBSthLUJ4HRdAjbCdm02KSgOQ7r/5iZn1vf3mT0rS6gilAvh6rIZQMYMvXuX3uvhkP5dVRlISZlyGLIzvBi5ShlSRPVywbh2KjmgVBE3T7TNBu8ckx4x0WFUGv3RY9hduw+VUtgrqwW8Gpf+itaPlQwnN1Hpij8VJ35/tXI4MPCJC32ceT584vPTR+Ztx8CMvRyJ3qHevmHUGv74x1yme/8evvkG37aJzRUGSRjZzSZrokRrud8DVZoXqlT6rsteE4ZY9tPTU5YFCCu232fwJQBoyUpJuXBZiluCHwFFy5KhsGQCzJbMkyyJOSJBkNcTE1Q5nnjjLWOldBrK85fmpfLc8qdBpZ8FaBVFwVhr7PMn1utbgndU3YpmtQU3Y+YLEbDDkWLzhic7sZkD+2ZHWdX46HDOoqoW7yxhfmJXbiiLKo0GCY7ZTpS6pNQlswqUwJGJHQ0VGltA065RZsYGw2k8suv2vKv23Nkjc5zpqo7Bjsx2pq07bPAMpmfdbnDBUjUd43jmOJ8o25KdLhncSFlpwNFjKGi+6LVeS4iv66euHsuRkVmFVELEYkzPPFxyNrf0fzkek85JOgXFCfk3v0kB7jpi50u79GaTguk0JfAhrJMELwmcwiDd3KTSmwAvrfOQ5sslPfb2Nr8BKe+JDguyTcPbt+mcTqfMoomQVkDPx4/p/OR8bm9zp6AE+Y172Q0pXl0C4JxLgO3uLl9kpCwoTJqYlzZNes7XTNrplD4r0ZddgVisG7wZsesd+jIytxvmaAhly+wmhtARCzDBUukSj8cRqNH4V+PSX8X6sZKh9ZZI5KQd/4sn7hl5YOAzF47MXPonPt79gXMVsW2ROgbnieLNG0zbwg8/ZIbmN7/J+/LxMX3XhU2Srj8p/0uZT+aG+gDG58kJos8SD7unpwTAxLxX7nMuGQwrlfbR0sldZAsCYPRXFR7ReS3F6MvbxcVdSo0Si4QZk2RrKZgXk2Jh6uU2SSZl30IGWxI3ywUrXhQopX4S5/zzXPmtxrWaWK45HB9Y1Vusm2g2NzR1Rx0izlmsHTid7tlv33L2E3aO3NYbmmrF7M+UwaOblsnOOHdmGzpaneYYlRFUVDhrKMsSUzgsCkfgDavk5F5AKD0qFLjgOPSP7Fe3vK12PLoTg5voqpbRzVhnaeqWy3hmmgfabot1hqZZM08nzvZMU99QhsjoJzZ6xUAa0ZMsH9Lm0q+h9HX9jcviODHyxHz1z4JzmJjMhBcvLLFYEOAD1268pxQQ7+4ym9X3OdAcDi9G6HzJSCHdJq3SAtiEbhfN1TSlgC0luuWoGxlf0bYJgEnWCC9nFy61Zft9Dq53d+lx+316j8tzvbnJ4nbvIeqsSSuKdL9k3cug++ZNes7pdB1e22XvsBAywJILiAR7ybqF6ZJ1ZcVcWaKdJZYFPlpscAx+Zi5aLIo5zBgdMdGxJum0pLX/tXz4979+rGQYYkiWQ1XJ/+QzHzjxyMAdZx6YmMyFz5//wDH0zPstsb/g+wtqu8Ws1/DnP+dy4Hffwbffpu/p/X3SNEpJXgCE2Khst1mfKXvv8ATjtat2WQY8HNJelmkSy9Li42NmrL6eK7icoyqJigCfpRno0gfra6NRiS1Ly4Zl6VHsWyQ+LRmppQkx5PcJ+dzk5+vjX8Ff/CWK4XEK05ToCqriDc/HRzo6zNMn3P4dXb2mbTrKsmK8HDj1J1ZNR4ieaDy7ekfZtEzTxMpr6maN14bjPOKsoys7Yugpix1N2WLcTKXAlQWT8jww8JYVDSWqVIx2oC4riiLNR9x1N9xWOx7skdFOtGVDdBEfHG3T0Y8XtJnQVUUMAV11XOaepmi4KVfMdqYsSjp1NVGloKPE4GlRryXE1/U3rRnPIwM9lh7HGctsRqaxz8JNKQVst9myQRiuaUr//k//6aUrs5QEZWagzDoUGwYBWOOYAql40Gy3WecloOzjxwyYlh2AUroU8CTmhX/NFFTKE8JISTCXTsXdLr234zF3U1bV1f5hlcsNy3ZtCcrHY9ae/fa38Ic/vJxjJqXApTWE/JasvGnyRQ3yiI+yxHuP947gLEFX2HlmqEZctcMqSwgNo7JYn3RaArREs/W6/r7XvzYwutAlf1RH/oUDj0w8cOGBgdmPfLr7I4/9I2a7IpoJ31+gqbG3t4lFEiH6b36TgJZS8OlT+hFAJEBGJhuIvUmMaT/JeBpbwW/f5mTn8TFrJaUkJ8y57C9hgmUAs7BH4lElcUkSlaV56LIjGTJrJbFBNGTDkJ+/7AZcdiPK+1yCNmmGgfz8us7Ac/n4pSeXlCyXMxf/xvXzdB3qkEp83hG2NaW6ZTyfKXVBPNwxdRv26z2rZs1qc8vYnzCxJASNc2d8jOybLaouGecRrSvKqgFdMk4T1p5Z6ZYwHbhtb+nqFcbNeGsoSs1cwAM9t7SsqKHsGNxIrStUu+U0Hlk3a26qLU/u/GXOVHQRGx113TKYC9vyBounLmucNzybI1Wh2eia0U2UVfp4h6uJatJreerXEuLr+huWCOF7RmYcJzzGTczjJWsXluNkxANKtFn39ylDvc4c/CLyFDAkzA3krrrlTLDtNgU+8dJ68yaXGYXlEQPA/T4dZwlQrmNrvnQfLksK4tW136fz/vAhuzofj9koVYTxNzdfHOi/lA2enuA0Q9vl93E6ZcFvWeYB0w8PWe8lAVWyWDE/lQuKfJ5VlZmsyyWzBBL4r5YZUZf4ecA1a+w0MUfLhMfEAuMtIwZHhYuBUukv3Yfq1bj073r9ayXDQOBRu6v7+8ADF+4YGKLhcL7j/viRaVUSi4A798SiwL99m/bJ01Pac7/9bdJKXgXxfP6c9U+QGV3p/pM9KyL3GFP5fn8LnUlJ0/mc97AAJ2HK2zY3qAggEt2mMMgCUITREnZpGPL9S9ZKfiR5kfNqmnTe8BJQSZlR9qgkQHJseV2JNxJz5L0s9V7yXImLAuI2m5ef49+wfpYrvgJmM6KLEuU9Yb/B6UjoB2xRsDIDz95imont+paq7fDzTLXaES1c5hMxOvbtLUOliObMrtmhi5JqtSYYx3ke8arE9fe85z1dvUKHktGNeOUxZcmjGnFEtqpmVXb0tqcuG0K7pp8H2tiyrVac/Xj13eoILuBUmn5+mY6suz2zn2mbNcN45mBONM1bNKmEqHXHiKW6CvEhUL6KXl/X37DOTDwx0mMwWHoC49yngaxCfct8v+u4jBfluBCSbkMCorBHolXoujxfUGYZyvNEuyUDYff79LzDIWuXJLgtrRJWqxx0xVNraRi4FLeWZR4SvV6n87y7S+9HmDPI5y/HeXhIF4h378DOUFx1I/IaYnoqpVIJ1MKwQR6vI0Ot5eIjIn3JeJfePFKilCBfljAM+LomeA9dgRsGZmcYa4vXaTTYHByzCslFXpVfnME1xatx6d/p+rdKhnOl+F88cEfPIz13DPQYjuORv3z6I0MwhHKN7S94ZxNr9fiYQBYkgPWb36Tv6ufPKamSMthS+L20XJDmF9E3SpLz+4/wfMn7ealtEuZbOozh2u17eFmyW7LVS/sESaqW4EnYMNGQCou0FLXLvoX8W44jJX25T2LFUgwv5yYyh6XIXsDeshPyazPTpXnq37B+nlmHladUFS5YvPdUKPR6g1cQppFzjKyLyGgH7Glmt3pD1IrZTmy7qzP81OOcZd/d0iuPN2f2zY5Glei6pNRbxqknFJ4P5w98t/mOdbNhU2/o3YCxybH5uQCHZ69aVuWKwQ2sqo6iVQxmQEdNU1XMCowdrwOmAzZc8ERG01NXHXMwNE3HYEae7In31U1y9i0qWlXRYygp6KiuJcRXoPW6/s+XxfNIzwXDgOOCZ/SGcbxk3xoJGG37xT+H0ykFCmGL1usEOIYh/S0Gg+/e5edIxioAqevSjxiXSiCb5/RYKVkKsBI26Ztv8mOk9CdlBinRSflhKWgtisxgLd3hpZQopQUR285z7qScDOiQhb8CuERAL2XCZTfR01MW7Yt+pevyvEMJtOLptWS1pJQKX8oS3lpmO1MRCUWBc5YpGiblcFQYb7E6seMt9ZcSYoM4xL+uv7dl/5WSodcFf1AH/sCBB3ru6TkzcbZnPj78nsv0jN+s8NOIn+fExJ7PCVAplfRYv/td+n5+/JgSiK/H2SzBiDSpiI2K7Ln7+3Tc5xm2i+RHOn6XIncBaksjUdlPYsmwlDIIM9y2Ke7I471PceVrDaSAQfHJE5ZqKZhfMloCqCRxEx892bvL0TtLvy0517bNTTkCLJfdib9ERstXlv7pE+3+HU6DG4+07NCrDRaPqzxhmulUS4fmuT/QVjXBzGil2az21GXFPFx47h/YdbcYZ3i2Fzb1mo4SrRXtao+bBzyGD6cPfLf9lm27Z12u0MEwuglXzPQ6ElRkV7S0umW2E13VEarkhYM16LIAXTLbgXW1wkbHyZ9x3oO2aKUJKHRRcnYDTVGzLRoGN6CrJJodcWgKmmsJ8dWg8HX9n64JywMjZyYmAmccxo2MY58fJLonEatKkBGdkQjHz+fMQJ3PCRAJgFpmld6n59zcZPfm1So7vgtDJMFtSfvvdhlkWZu0Ikqli4Rk1UtdxrILaemzJRYP4gQvwVpeUxim5+drkKyhcPl9CKCUcxN92PNzet99n8oKnz6lC9BqlbVg8p7fvMkXAxlgLWyhOOzL5319X8FanJ2oKo21M0MYmdQaXwRmPzGXFhs8UUcsAfsqiP+7XT82y9B6iyNwpwf+J/fcM/L5qss6x4mPT3/m8PSAbWui97hpzEzyx4/p+/buXQJZfZ++w0vwI7YkkugolScbCBASCxdJvpSCaMCR9tay+3cJemQvLg1BhUWCDIrEBb7rcjlQOp/lMWWZ9WJLllu6BiEDI5EmSOlPGDtrc9IGmVmT58tajgeTJZ6Dw5D+XgK3pUfXT1g/T+mwAuss8fEDertDdR3D8EzTbamaNWa+YDcddpiwRPZFiwmOAng+3hHxbLtbmvUOPw6cxmfaskWZyEUrnG7oqGmVomxWxEJj48CH80feR89te0tTVFApjDfMdoISYgFrXVHFitlNbKoVkcgYDNF50AqtK6yd2JVbTLT08wXtSlyl8NHT1g3TNPDsLnRVRYiRKhiKov1SQiyupQGNei0hvq7/o5WE8CNnZi5MTFgmOxJFuC6idjEFXa/zsGQJutttAhEybkMABbws3QnbtN9n5kZKA5IVD0MGTMIy7XbpvqpKAEkEtGKF8JvfZIAmDJwEZvHxEXAl5cj1+qXbtGhEBGxJVnq5XN9vBHRmsGR0zzzn+Ym7XXqfAhTFif75OXkPhZDAVFlmI8amyYJjCeyiNZGOLTmXecZOIzEGTKFp5okpBobC4lVkcjOmU1ifeI5AfAVaf8frx4xJZz9zrgL/g0c+cOGOC49MDBg+nz9yePwTvgK0xg6XvFc/fEjfybdv4R//MX1vHx7S99mY9L3d7dJeeX5OzxFNk+icBIAYk/bp8u8pgl6IxkXcvuwUFgPQpRBe2N4YX46pmqZ0fnJ8iVdLt3cBUF+LziXhE0C3tF0QACT3yXzWJWMl9jASt76eiLE8pty+tIOQ53xtR/F/uX4eMfyoMOOFWFaE4zNqmtDbjnm+UNYdum4x80DsGkbr8GFiTc2mbAE4nB9x1rJd3dKs0iBY7xyjm+lCZFoXeB1xlKxVSVU31EXF3Pd8Gu6Z3cy79TvqInUd6qCZ3ETUHjS0ZUm0YNzMtlwndB8sU/S46NBFiXMzN9UNxjlGN7DSW3wBU5gpq5rJzjwUZ74pb67eWiWFqq5diAr9WkJ8Xf8X65ELB3rOWC7MWAL9cMyBSzRQQvXLPMFpSiWxtk2P7fsMaETgLgOSj8ccUMQ1/XjMcwEl6IogXcb7aJ2d5yW4i4OzlOHETqKuE+gSkCPBVqh+8cxaGhIK0xZCOl+tM5hc+gJNE5QdrKuXw6blcQLYnMvvQxzg6/qlwF0AVFmm27/7Lpczlcr6ttMpAUgxhr2+pzjP+BAoqwKHY/ITQ+ExKtLEgI+OAcvNVzqtNDrsVRD/97J+rGQ4uYm5CPyLOvAHnq8zDHtOTNxPBx7ufmCaJ+J6hRn7XCr/9Cl9jwVkPT2lH2FfRW81DOl7WxQJdC01UAJsjsf0/RWmCa6gZeE1JWU82TOy1wTAyPQH2b/yeBlqLwmTgDMp98FLs9Al2JIYBun1NpsUvyQZW3YFip3Dsnwv2ixZcqzl+B7Iz5G4sARh8lrLjsSfsH4WoKV9RfP997jHA84MFNFRTAPFekuhK3xwaF1ivCNWJdEHfDDMzrAtNxRFQ+9H/Nmy625oyo6qKKFwTGakuXjCek8oE227BpqypF1vscOFs+2xZ8u71TvaqiUWJatqzeRGLmEglh11WTLbiSJotuWaaHuCShmnCw5daIKz3LY3fLp8xriJumrxSlGoSCwUgxs5qYpN0TL4kbJMXNaEv/Ja6nU8z+v6N5fFXcuGqXvtxMTgR+b5SnULyyOaiGUAFCG5+EIZk8XqYkAogUiCbQjZ3NPaFLiXPlrilyNaKWGdlvqGts1O7mKIKoFraQYqrJCM+ZBs/OsZZJDLA0L7x5hBmbBrjwaKJutYjMklTxmELUH1cMi6teMxHfN4TIFdLh4y9HoYEli8v88O+NL+bm1mxiR7nmesNVRaE8oSO81MpWFUhk61zN5gVI2NHlRyhReg9SqI//tYgYD9K2yWC445Wu6qif/OPZ8588jIMyNP7sjd4w9MlxO+bVK5UMDHw0P6Ht7epnLh01NuHjmfs/7pcMhGxDJVQZjtENL9l0ve75KgfWGXNazbzCAvLRukuUaSkuU+lWMJ0yS2L/K6Sx3XsqNXlnQlShlR4phYyzw/v+wQlngCL8t9S5D4NcBb/ggrvrR4WDa3yPuR8UQ/Yf08jBaBSUP37XvCMDAeHtFE9MESxp72/fe44CAGfIzEsiAEBbrAuQurUNDojlCvOPfPzNXEulnTVg2VKgmzoRguzF1LKBuCSmLTVVmzXu+YhgsexafhjjftDat6TVAqCd29YbA9oWypypqzG9hXG7bliuAuOBUJOtXXtSrQPnC7vuX+/BldVChdYGKgbmrsOHH0I5WqCDFQhepFCTGVDtXreJ7X9a+uGf9FIHtiZMAzOUcQ0XoImaESluZ4zGM4xENLwI4EWGGG3r1LmbIE0XfvXjovywxCCUabTQ524iklAep8TkBJypJSIry9zR2CMv5DtFVSthSn9b5PF4ylF85SdybgcZqyXkoCeFdn4LNep+M8Pqb3KZ+NiF/FGX+7zVqwZQeSnMvbt7krsW3zGA9ht2QMkZRqr52KfujxdYMrAs6OWGXog+W2aJj8xFR2hBi+2DtYAi2vgvi/l/WvzTI8lo7/zGc+XcXvT/Q8xZ6742f6x0+YAnzwuUQno3BubuAf/iHtm8fHXJrf73NXsOw3sSmBLF4XL70lmFitXvrj2SLHDAFXwlZJTJDOQ2GXIIOupcu6gKYlGyXJjui6lpMnJJkShk6WPE8A2NJkVF57yZYtLRzSB5//XmrLhJ0Wxlx+y2e2fOxPWD8P0Co843DCtWvW6zWbVcfw9Ijpz6iLxU2/Z/Pb36HLEjONaAqirpiBSikuBMx0gUKx2e+x48B5OGLLlnXV0dU12oObDSYEfFkRNYnE1RXrbo0ZB4qy4jCfsN6xajfooqTUNVqlUmIoKmpdcbBnbqot+3KDsc9EXUDZYNxIiaYJBbvuhvN0ZNfdAhHjHbqpGeaBS6HZFSvObqCqSwqWJcTi1Vvrdf2r68zMkYkz81UM7zF2zkOi5UfYJufyWBrp2BOfrKW2wZgUuAWUeZ9A1mbzEtiIDqyuU0CGLGoVY0HRd8nID/HwEpbn7i6fU12nrFrKczLepmkSOLI2XRSE/VIqXTiWYtzl/LLTKV8oJgvr+mWZb7fLpVERwVdVLv1tt+kx4lovS9g2AVKi1ZKyp8w+HIbsEr/Ipt3lgr+9xVca11umGBmUwyjP6Ay+jszeJM8/Iu56YX7Vaf3yl8P/1f9H4w194fnn4sAPPPORM0+MPDPzODxyuv+ANQbftfm7dD6n7+5ul2wcnp/TzzSl+7bb3D27LBUOQ07C+j7vJRGESyLjXDq+gKmyeMlwyWOX+ikBYrL/l+ajS5ZIErul5knAozDw8toCdCAzYPK3SAzkuQLq5DUEyC3PT44jYEk+TwGCS7+spdhd3q90HP87rJ/l6h5DwFQFfjji64mu3lC/e4dtG/zxiJkGnv7l92zef0+3vWEYj1BC3TQYTRpoUyim8R6rPG+379GTZZpmrJ1xzYaNqtlSMweY7EwInlC2oCKxrFi3Ld5YyrJhiDNmMKzbLW3ZURSarloxuxniTKE0R9ezrVa8rfZ8sk9UpYaqY7QDTdR0qmbSNZMdqKuWECNRQSwLTn6kUak9tPcjpU4lxAFLcS0iln+lK+V1va5I5JGeAz0nZi4kw0sz9rlrR7oERZsltgw3N9eDxJy1dV0KzptNAgnW5kDXtnkEj2SmYv/w9m3ORAXEiF5DvHtCyK3jAp7Ea0tMUes6zzIUz5uieFnaOxxyNntzk5knmaUIGZjJcwUEdQ00KntiPT3lc5Vh1E9PidmSzkgBalJCPJ+zTYVSWSS/FOEus3jRx8nnI0HfOZwx0NT4AmY3MeoWoyOTmYko+jixZ0O4+ixFXoHWL33FRXPDcvngOYeRz1XPf+eRz5w5XNmsR/vM88NHzOWEa5ts4ikzSFerZONwOmUXd/meQh7mLvtOHiPGoAJQlpYo0qUnbNBqdR2aXgDmJbMj7NayzCYgR0yIhWFa6qXkOUu7hKLIlg/CMEmsWJYEl2yXADMBU5JYCmO3ZKKWyaToy+S5crtoQJci++U5h8X/3y9VDE8HhXX4VYM3Dj+dqIuG1XqDqmvM8ZlwOjLefcT0Z9p332DmARMMuttCqVAEdFvxNBzwCt6v3tGVFW7ouUxnTFERihXv9BvqInLxM0PoiWVH1BCrmi5qYggUsSQCp+nEXBl2zY5SFXRV0lJE7yDCxY+sdMs31S1/sY/osqKr1oxuoA6aVbniYs547VCFxnuHLhvGuecQRt4XJRc/Uhc1hSqY8TT4a/nwtXT4uv735Qg8MHBg4ohhwDKGAcYevMuu5ELFa52AhDBFwiJZm/6WwCTrdMr6K+ka1DrPOxzHxAAJgDidcrAUX5rjMQdPyahFayGzBLfbVN6Qv3/3u8wOiQ7iw4c8xPrdu/y+JCBKABYhrveZfRPdmSmhvpYyv/02vebDQ2bJJLD3fT5HYfqWLeZSihWR/d1dKtm0bfbikguFGLFKc4AArRjx84zXFbHsMGbEtBvGIrCJAR8tAwoXA0Gl7kNPQFEQXk2Nf7HrxwTwgxt51ob/oh74y3WW4T09D2Hk8HzP+HSPVQsDThnsrnUC+n2fvezO56xxXGqivE/3yXddOu+EgRXgtfSOEgDmfQJNfXypa1oaBgvLvZwYIZMXvgZWsqeWvliSlFwuL8XsSxAmxxF7GHgJfERLBVlKAPk2iVUiAxDG6mtfrKUhqjBxS3Kqz7MAACAASURBVEsHkUR8/fp/w/qZZh1G1OlI4bbEdYuNCq8c/nKibGqaN++YyhJzOaPNQPjLH6nevSM6jxvOqPUWXRYYArFU2PEBWym+1XtW6zVqMlhreLJHvLV8u/+Om2pD73p6NxCCR5VAVVMZqBV4H6irNBfxPjxy29zQFRW1rnHKE+2MMSOq0VRFybtyx707oquGpuyY3UQTS4yqMM7SVIoQAe+o6xUnc6FRBVtWHF1PWekXJUSD+qtZ0Ov6da+eKfnqYDkzMuKZzQzTmL64khlK4JOL/du3OahJMGmaxM5IFiwBfekYLZmllNHevcvgQ8DJEoQsy2dikyCBWYwTJVMW/cj332c9l2SqMhBWAqCch7UJuK3XuSQh71esImQ+Y9fBpQd9LYu+eZOOL95DEuClKUA+Fwnq2232yxI/LWHO7u7S8YQJlI4uyCXG/T6XJK7vwU8Ttm2ZK2jNjOkcAzNWQe8NnSpx0eOV2Dz4L4L4V5j1y1vS1PD1Mt7wrEZ+r5+/GJM+MPDMxKl/oL//jDFTLo/Pc/aYe/s2/Xs5j1CMQSUREJPiwyGzu1IiFDZYdJYyUkbAj+wluDJiGvblS3f15eOWjM8SmEDuTJTbz+dcthQGTcqC8lhJTJazB+W1ZX/KvlrufUl0RKy+nJW4nJYhwvelF5f8SHK4NHSV/btku36RjBaacnOLOx9QxuC2K3xVYTcVcTI4Z9C7LbqscJcjwQbs3Sfo1tRthwuRsNlQliWhiczDyPPwCOuCd2pF19ZUWoGNnMYR//Rnvr39nm29pXcjo5/wwUG1YV014DxlWTK7ibbscNHyMDywX92yK1p0oYl1hzIT43hCdXuKQrHVKy52pKpqqBqsKqhDzTSd8bomqkgMHl1otK54DAOVLiHAKYzoQqEov3QhWuVfW7tf14t1ZOLxWl64XBmtaRzBWah5OVNMgq24GC9F6uIJJcCq63JGCRnwSAeTmCGKtkseJ+J1Mf+UoCZdeGJm+uFDerwE0r5Pv0ULBSngLwdAC6ASpkzAocwzFKGsBOa6zmJ8cW0vSuDKXokGTbQeRZG0XuIQvxzlIZ/H7W0qg0oGLxouY9LtMu9RvMPEGmMc82stShLROWwINCrivWcKngnLXNSMYSZUa+ZgcEVDoPxykX4tH/4y14+N2Tn6gU/VwH/jno+cuefCIwOH+Znj42em4+PLAcqyt25vsw5RvOJizLcLY/3hQ/Z+E7BmbXqOgIm2Tc8TNhhy8iL/DoHkUzT9dU8rkSsIQ/T1zEHxmuv7DIjkNZbdhFIOlN/L8pwwUaJBXTq1f/lQF7cLKBKAt7SPWArc5UdeR4CYvH9h4iReLIX0v0TDUrQl+EB9855wfoanA2Gzxq2STkJbj5/OlG2HLm6I/YVQgJp6hnmgXm1picTVhqKsCF3HOF4I4yNxo3kbIp2uqJSi1WumYeDx6QO3+29ZtyvKQjO4iZO9EHVgU7TE6KnrhmHuWdcbVFHwNDzimx231Q6vArrpqGJkHI90qz1al9SxYnKGsqqJJazZMLiZaT6zXt1g/YyxkbpumeaeQzHyBoVyI3VVUir9pQvRqoDB07wK418XKTt+ZOTAwJGZCc8cDa7vwcyg55e0uIy02WyyFYPQ6sJmiR2DaCtETyW+UhJghUESPyrpwPM+a6Ikm4wxlekk+7xc8muKVYL4Y1mbbhOtlojeBTBJ6VB8vESM/vSUnqd1Pv7STmEYrmXNG9i2GaDJhUEuUNItJR1Zol+RTH2/z2BSsu55ziasj48ZbEkDQV1nfZoANvEtA8I842uDK0pMcIzKYItVSvjqyBjsl2HDr8alv9z1YwL40U0c9Mj/px74C0eeGLmj5+Av9MdHxvvP+SI/z7m8v15nX7rjMZfR3r9P31tJcE6ndLvoHSHtVdFVNU1ixdbrzIgtNYYC0KQTt65hU+TypewTYc2lHCgsk8wOFHAooEiGuEtpUoDQ1yVCsZoQgLT8LYz817qppahfyqOyBChJafBrvdVS17X8LYyYJGUCIJeNAX/j+nmu6A2Y4YAPG+r9nmKciecTajK4XUBtthT1HjuOgKfcrtG2xfc9YR4Ynw84O7ImUnc76rol+sA49vjyEdvt+CZsaChw0bJdrRgng+qfWAVP265YlysmP3HxE6jIKpagC6qm5TSfWddr2m7LcTzhg+NNc0sgUrYrimlkHk9U7QZdVhTWE6xFVyWUFe/Wb/nz8U+Mc0/TrjF2onCGuu4YzEBTlcQQKb2mKjUbGi4YHIEZR/llAPXr+jUvT+QTZ56YeWZKRqXhqp0KLoMBCW6iNYLcYbTwdfpSUlytsnhdbBVEk6V17mISHYgI4qWkJlnk5ZKza8mGRRjbddmdXqksvJfg+/CQGSTIjxM2Tkp4EvzFwXq7zaNFhG2TLPXhAabHZFq6WmVX+G+/zfqTyyWdi4Clec7+RNIIIKJ5ufiJl9g8Jx+t5TmJKHe1Sucnn8/CPNZZi3cOr2uMG7Bqhalgmgw+Bvo447l69BGukvjX9UtaPyaAd8HxEC/8k37m9xx4YOQzJ54ZOZ+fef78Ie8XSWaUSntEmNfjMTePvH37Uj95OuV5hZD2qdiM7HY5qblc0l6QEpqAB9mnm03+rp9OcFroueAlM74s3QlAki69pT9eWeb487VX35IlX1pEyN+SQAoI+lqALyJ3yE07cp7Lkr6c91KTJft3yXQvuxSlRCkM3jz/ModKc9F46/DzM9EayvWWanuLG3vs0yPOGNRug151YD2mv1DogvJ2T3HSxGKkPz1j55Ht2+9YrRPYCsFhLieOqoBOcVus6CL4MHLTbrDWY0yPIlKWNW3dYr1lxhKJtDZQ1CvKpuU8X1jXG9rVjn48E0Lgtr0hKoVqWsoZvBmpqgZTVXg7o5xDlZpK13yz/Z4/Pf0LZd1Q6pLZzayKMs1C9BNFUVD4kUpX1EqjKDF4DJ4Sx4r63/4cX9ff9Toy8czIA2dGDDOeXlifwEtXZAlawqhIB6JzCSR8/pxAgAjSl4JYyMzVapVbxasqz0GDLLCvqqQFUSqX/6RNO4QEnm5vX5YZl87vnz7lUqfcLqJ059K5LMWuNzfpdc7nDJjW6/QcKdfJufzzPZQ6D9cehnQe223WrMmF6OYmPebtW/jhhzxwW85dGAIRvLdt+uwPh3wRk3FBIiZealjkAhMjzky4zQZnLaayGBwjCoPHonDR4VX4wopo1Ksg/he0fkwA/+TO/KW88N+45zMnPnPiiYnzdObw8CF9p0W4LbNKhXE+n9P3UOQA796l7+7ScFS86oRREnZKLE2E6ZXkAtIe3G6zLcM8J6ZWTEifDVQ2s1AyFWIpeJfvtpThBMAIEPq6ZCfgRfbS1x5Xy9LcsgQopb0l8FoyZksx/F/zypLjCoslSdDydYUx+9rUVJYc7yesn8cZ3tS0v/0t7v6RMBtm80jVdui2Rfua+XgmGIva76Gt4WZHOJ9x3qJu9ui+oibizkeOn/9MeP9bunZDU7eYGJiGZ7yK+Faxr2vWFDzOR95WayqnaIlYZ1DeousGr9JGKQpFmE5suxvKpuM0PdM1W5rVjnkeOIwHtu0OXSSkXllHdJ4qRlyZZiBqD14rNtWKt9vveDzfcbP/BrRinC+suh3jdGHWFkKkdCNlpXnLmqnweCITjgr9OnT6V7ySrcOZe3oOTPR4ZixewIYZk0Zr6QUjF3thjiRYSWlBBPIyExHy/SI+VSqBMtFBiV5rs8lzAD99ypooodvFs0cuEn/8Y7r9u+9edg2KuaJ0HEI6/jhmvdYyQ5dOqTdv0usfDrncIQJfOfZqBZsbKMcc3Lfb7IMlQErmNz4/p9tk8K0AOGuz270Mj3YuHb/vE7harTKrJqyWlGPF0FWCfQgE5/B4bFTYYJmDw6AYw8xWVQxhZqMbajSOQPUqiP/FrB8TwI9+4l71/JfigT/xnDoMmTj5C+enT8SHh8zOSFlehqcPQzbaFWB0OuXbiiInArIPvjYIle/9apUTKxHCx5gbSQS0CaCoa3h/m1lf+f6LcbAsYaxEI7UUy0OWM8jfAijlPQqbJGW6JZCCl6wZvCxLft1NKMcS8CWPWwr1l2ap4je4BIWSrH5t0Ao/2bT0ZwFaXicNQ/ndd7jnNOswGIO3hrKpKTc74nQhPD+j1sm1Vq3X+GlO/XmrBl3f4uoK83DP86c/4t59T9usKCpNFRRuPHNUiqLZEZqGBoUdnnhbbtBots0Oby1hmoh1idWaCo8vFKfhkEb7tFvG6UxUkbrpMGbiNJ5YNSvqssGUis4XrKNicj26rDFuolQ1rgi8W90y+4nT5YnNeo9TjskMtPWK3o7U1Y6Tv1AVJaVOgfXCzJ7kHv86dPrXuwKRB2YeGDkwM2Ew0eUOHu9AX0dULNuQRfAuAUTcooX5kXKfaLmW/jYhpNKYzCM8HrM1w/v3ucwmbuwinpdjrlYJEM1zYoWki0/KDQISxQphaVo4TZmhEvDYdek8pJ1d2LSlE7uAHjFKdTGDPymtChMl5yRgaxyzU/Zmk522xZhVvL8EwEogF13MbpfLMqLnGseskZPXVwrjHK2dCWXN6C1DaZl1wcWOvG+2zNERrpyIxdNRvuq0fiHrxwTwn/2Rf6oO/AtPPNLzkYGeif78xHh/n7938h0UUXjfZ0Nf0VReLmnvyfdQDHoF+AhAWnbL7ffpt4CypZmxsF+iWxSAtlpBX0JxLdUvEzkBKm2bGSWRKCx9qCAzXQLqZC11T0vwIgBo6cMl+20Zz5bHWf6WtQRjS5C1PAdh1ZZryZjVi2qSAOFfpBh+Feg/f6J+85bidk/RVzBaVPDEEPFTT1G2KJ+6F5QH7wyxbNJniKZQimK7QVcl7vNHTncfcG/e07UrdFFSUeCmnoOCUK+x7YqV6rg/n7BFRFGw727wzmHtiPWOqW7ZaE3E0c9nVs2Gpt0yTGdCG6ibFldYhvmCj562WtEHw041vGPNR3dC64rZGXRVUSjN29Vb/MUxzD1V1THNI1WR7uvDyIqGg7ugi5IRhyMwkb4Er0Onf73L4K6lhlQ2HLGMUl5wLgEtr7NIVeaSLTMxAVZlmYGWiG3bNo+ekUz4eEy/b2/z7L/VKv1tTAr0z885K5ZSnGTKu10eUtt1udX8/j6dt7BA0ikpmontNuu8xGpiHHPJRDLhpdu9jMQR4LnZXNmrGZqY/YZOp/TeRXe13WZbCcmshZESsbB0GgqokxEoMkdyHNOPsGHLlnHpBBPNzUJ/Mk89zbbDBMccDL5cc3Zj0mZG++WCba/lw1eg9R9//ZgA/smd+WNx4p/UPR/p+ciFCxPP04HT3V1OQERsLntBLBrEdV2mFzw+vtznohtaapCEyRFQJcBEGDLpaPzaM0rYrhCuovsCpgWAk+ML0ywdhF/rqOTx8reU0gWsSIn9a2ZJ2HgpZQpYFMDzNbO0NBqV25di/WV5UhgxAW/ymYhma+kuL2BR3pM8Vtiyn7B+HqA1KEy0+Ls/obc31N0apTXF7CicpWg1wVuUUyhriD5QssX7AV8oXKUomxpdFahCob79Dns4MB4eYLtFd1uKOVA0K6KaOaGgjtB0ON3inp6IKqBMwb69pdQVzD3TPBCqll1RE1xgthOVrmiaNZfpTNtGuqrDUzCZERc9bbni4HrelTu+VTs++CNaFVg7E6qaTjds2h297THeUNQV5/HIfvOWae5p6xrjDCc/cNEWi2fAUqMZryXEV2H8r289MXDPwAM9ZwwTJjWHSBeeugYuYbAgMzliUCgi+NvbFMSenrJD/G6XgBOk+yXgy5xCsS2QjPt4TM8XM1LxoxJtlAA1AXifP6djL19PLg4SXMWNvWnSBUUMU8UDRzJveU9i7bBe58DZdem8+j4F5ttb2F+B29NTKnPKSKCuS1m+lA5l2PV6nXyyRPPS9xlgiYeQOMBvt3m8iTG5pHi55MxXPjvI5Y+qwlqLUx4fHMZP2DIwRsOEo4kac71s++vsw1eg9R97/ZgA3gTLn+Mz/7V65AeO3HHkmYlnf+b09JS+awJGpDQYQvreSWlQQMDplO1Q5Lu4ZIQEvAgYkjLhsklESn7Cfi3BStdlYCN79eJhpzKzK2BEkiRxpV925wmgWXYPLkGUAEk5Z9lbAvKkdLcs/UkcWGq1JHERACjlPjmXZcKz7F6UhGjJpC0fuwRjXz93qev6G9fPA7RUAdsVzhhsfyLMM2W3QpVQtjXV4Kj0Cl9HghmJ4wT+SLFZEesG1w/E1lO1Law6lC5QweGrkXGaKW1AVw2FnWnClqgLLhTEWhHKlni75fPjIyFY/lEpbts3bPSOcb4wmJFLFdjoButN0mMRWdVr+qmHLtJULXXR4szMEC/UZcu9O/Fddcs7FXlwJ1QE5wyxgn29w7iZUhf0biSUcBmPrJstZ9tzU+7pbfJJemLkGzb0WLYoBgwbmldvrV/RisSrz86FRyYMjimGzKp4n/yixFdqu83GpTI6RnRM0hUoHXjOZQ0RpI68voePH3OJQsw8pavvckkXgKrKAEu69G5vE1skAU9e9+YmAyMBSXKfdEQ1zcu29r/8Jbs6N00CRcvxHzGmbH+9Tq8lz3/7Np3f8QiqhPUuHfP779Nj//zndHEQv6Hb25xtC2v17h386U+Z6RvHdE7Cwn3xGPJ5jJGAteX4HchaM+m0vDJhIUai95gyMjmDadL/ayobVkzRYZXHLcqGr4L4/7jrxwTwf3GP/FP5yP/ggU+cuGPkwszl+Ez4+DFr/8TKRLR94pUlgESc4JdMkAAjsXoQcC/drpIALMtwwh4vgZlYLogFCmTQJCAIsnZy6Te1FIyP48su26UXlRxX9IvyGiIXWJbX5T75LSyYnPOSPVt6ZS1/y/kv2aqvmTsBb8vnLu0gfuwcfpGGpdf3orsVXiuccdjxSKlbQijwXU3jFMp7dN0Ri5owj/jnE9W6Q61b7NgTgksC+m5FWdXY+894RqCg8DMhFIyXA6U3FG/eMyuIVSRWLfXtjrvnZ+JYYlTgm+Yt63ZPaXpOtieowJaaab6wbrf4GOjKjmHsoStA17RNizcTkx0pdcln98z7ak+sIg/2hPEGVyjQFZtmzWm+sK7XnKcTvR9pfINSBRNzYrD8yImZBs0NHeYqhm9eh07/qpYncEfPD5wYSIzHJILxLw7PLVwO6QkS1JZZblGkgCv+Vvf32UF6s0mPF93VDz/kQCXsjbR8j+NV++Ry+W6eU8DvuvT69/e5ZHG55NKf0PnixC5eWjK/ULLYpRu7WEuI0FxAl2TGT0+5rHI85hEiAhLdCc4qlxvfvEmP/fgxP/ZwyOOBlpowYfn+4R9edkBKVi8eY6IPu1wyUyf3S6CWMqOs68VongfW9YbZWSwBSzIvflesGMOM12v8VVxdo18F8f9B148J4J/9hd+rA/+teOATFx6YuGA4jUfM3V3uMlwmDwKypFwfY272kPKVWCeIJlIABaR/SyfxshMQvrCpXxIB+U4KM/V1mU4pGMn7fVkGlGRObhemSMqKwuIugdjX5TmJMV+bhy7P82uAJomMlCUFRArIXB5XQNMSwMl7X4IvWfL+l12K8vfyfYb//f/6/2b9PFfvyhOGEdoa1a1RaiZME8bNeK0pR4OrGqq6prKRQgfUaoUyhmAcaj6hV12yiPAD1JbYdOjffI/79AlzGlDrNepywVuPDpYYDOHNbyhQUCl8U1Hvt3w+PhEHTywU39Rv6JoNWlcc5yM9sKJknM6suh0OaHRNP55gdQOFoq4bnJmIPuJwFOrCvlwTK3g0J/p5xLWRrmyozAQoVt2W83jkbnj4/9l7sx7JsuxK77vztdHHGHKqgU1SXWwIgqAHQYAAQW/6AXqWfo3+idACWkBDrQdJEMQWJZJQN9ldbHZV18iszIyMjAgPd7fZ7I7nHj0cW3GOeyVRVRnFisyCn4Qj0t3M7mT37Lv22muvw5PpY/bdgTI/pTcdlWm4TaAgJSYio2RPR3pcfvph/P6PLTVXR+foAz0VDUaA5M2aetYzLmFJTv9WlQsYKgXKjkELN8uH5tkzb3WgIDMee0+pzz7zS37owTCdup/TU18mU/eT2KuwC0/ZojRN0k71vfvbBx/4k1cZpWncfuX7I0bs/fcd2JK+Q2U+lU3XS1jjy4vWunPuewcIBTxXKw+czs7cNmYzByoXC2/YqvKgwKOC7nzurqnKMQrEKoXIrT9sPEgSurqmPXH6y8o0zJIxG7Oji8/orDMsniC2JMNgH1Ksr+H4Us8sa/jU3PK32Q2fsuaKHWsq1mbH/ubG3X8CAbpP1mt3L6rrMOyAEys6dg1hb8TpKtXpnpfHXWgEGq7jJ7sXlbWVjAnk3NdGDRFMU3+vhxYnEuLfZ65CMAT+dQG1EAgpiQI/P5TYhN5a95fjCcX+IXgDv69QXxWK4kN/Le03FPmHmiyBQF0TxZq3GO8IaLV01Y5sKIn6HiYzkiTBVgesHWhjiLoKawZIcqI4JTUDUZ4R2YzI9MR1Q1S7pXiGvsd0W6JRQfbeU0x8Tbfbk02nJFXN0DVstnu67nPso/eZEUEGlAnGFLw6rGEfYRh4lJ8ySUvO43PWzYbK9hgTEdcHRuWEOIrph4HtfgmTM4hTsnxE2x3Ih5hVuyWJY4o45yI/YWgt23pPNZpQFGN21ZpyNMEUU7b9kpvDDZfjSzb9jjhOqdo9SZnyOtrzISkHOiZEHOiYUvzKS/swvvnj5rjY7Gt2VHTU4EXfYk+ag9draAmbkGoXmzUMHhA8euQe+KuVAwqvXjlmZj6/G8zkjfXJJ3cXrw2z1/Nz7zyfJG6bee7+1fGEgncJ2GXpIKCmLqvZzGfyWopHjtR6TZ5YJyde2C5m6o0o9uA0MKenXpCu7akUc3HhrSa6zntmaX3ExcLtQw+jMKvWckBF4XVp6rQMs2wxADI2PTJyfdvStQe6aETT1bT55KjT6hgNCe1RXN0/6LS+tkM6uvvjlVnzo/iGj6Mlr9my4MCWis167TSLYpQ1P5rGzc393gNzlfri2N1f87m7d25u/P2oJEYgQKUyMUK6B0NWWR2+el+4zmCofbIWbA89HqyITVansYCXXlOZ/34XoeZBCFykdRKDpUQoFN3r86EvXShyB6/dDJkrsVXy/BLoFNgKAacAYGgRoe7iEJSG5qVvMd4N0MoHDstb0tmMvClIDjXJ2Sl2NiHZ1RjTY6OImobe9BS4GyPugGEgJSNKEqKug82KaD4nzXLa7Q7btSSPLhjShHZ/oBiNiImI2z37DvqXz+gv3+N8fo7Jcuwox5iO1/0OUw1YC5fFGdM456Q85dDu6WzHvq+IayiKMbNyxrpast0tiKYXEMeuo/AItm6qFWejM/I45TI/gcayODhWLMtzuqZmMppirWW9vWbbbBmlI7poYLADTV8TZxHX7IiZUZDSYCgwD95av+djOJYNP2PJltYZlVrrQEEIPK5f3y0DvNnA4LPB6dTrPsZjBzZWK9+NeHvr/64HgEwOBbIU2LX2nzoMQ+8esWfrtc/EBS5klCjTQzlHh0G5aXwXn9g4lRGbxhuYiu3qe7++oN4jADoauaWJbm4887bd+u2t1+69p6defyZQJIf3NPWmpHqogNek6DjUgagHn4K+WAexi7oWx6y57xuGckrdVwyxpe4Nh6jnBEt9NC41R5Cl/x40ml+f8WV2Dtuh4kfDC36QveYFK26oWHNgWR2B/3J51w6h69zfpbsMu1+lxdJqA+q+1T0mJkraLN2jYsJ0T0rDWJZ+LoqNCsFEuAAzgE08uFJ37n0Nkzp2w+VpwvJbqPu6D240hxU/xMxp+2LWxVyFbFMY61QKDZk8JUO6PrpWRXFXe6b3h95foWYrZAX1d/7qq90wvLOuQ0dp9qsV/WRCnqbkVzXRyakTt3fHDghj6SNDn0SUnSGJc5I4whpLbCDNS6I4ZtgdiMaWPMtpq4ah77CTETaO6HtLNCTEjMibmjYxrG6fY7qG89PH5OWYeDJmt93DcGCoXbfUUJwxiXImxZQmaRiqA+t2z9y6dQtPR2fc7G/Y7G85nV4SxylF7rLUaDCs6hXT0ZxRlHNZntHXhmW9ZFqeUvcr0r5lVEzpTc9yfUMyzziYA1lW0rQHsiRnFTeUpKTEnFCwp+WE8iHo/h6Pho5XbLiiosZQ4ZZvYbfz7u19D1ULo8JrPULmZRjg8WP3mgw+T048IEhTJxDPc8fGyAsqilzwv731XUWyX1A2rK4mdSjJ/0qARct2COhNp+6hMZ/7tnM4nkPlT1yalNAoVe7r0pIpIGaZK/fJyfqjj9wxty2MSiiOgXe7dduVUFgPgsPBi97lRaRzlYWEyp8CU3LRDx+MYsEEvu5n8WL0dH7H69js97TTc5qmox2c/m47VDyNJtS2OzrEO9ZExqXJw5z/WowvE8AbBj4xt/wgueHTaH0EWTUb02FubvxyV+D/vblxzGnIsgicy//q5Uv3r5Idle3ESoVsqZpMrHUJi5bwiSKfkIUaKM1nxYNQM5XHbr3QkAHT0PGrZC6jYjFyYn9CvZTmfAikQt1TCNB0PCGwU8eg2HQxdiqfhnqyULwe2jWovKr5KPZMuk29T+eo5Ev7+WaK4TPSszP6w4FovabNc9rRiPzmFflkSjw/wY5LkqphMIao72jSmMRCHqUkEdgYLIY0KzBE9FVNEmcUeUnTVNhmw1Bk9BnkxSl2vWawQFthbc9mu8QMLRdn71GO5iSTEbt9haXBtNcuo8xPmUQZeZoTTTLq3YrKNNBHxMPA5fQRr7dXLLbXXM4fk0YJSZbT0WLaFuotphwziUqelBf0lWHbbhllYw7tjlEyZzKe0/UNi91rumhg2++YJCVVuyMpT7hlT05CTkJERENPSfYrL/HD+GaOLS0v2XHFlpqWBlxQU6dfWR6X6ughHvkMT1mn7Abk2i4GLM/d55LEBfko8oyNS4HuHwAAIABJREFUtB9iifZ7Xxobj32glW5psfDMlcCJgJCCkhaqDgOzAht4zZYyagV6bVOllc3GlzkUTGU/cX5+dzHo9Rpi49gqlfhkiQEeMGqf2r+6tUI2SgAsZBJ03NKlhWBLpUVpR0IDSgXto06rb1vawVBjaYeezsLBNrRxR2v7N3Nc5SkHtB7Gux72WNK9P14PO/6d/ZyfJgtu2LFgz4aGZr12YEmMqsrLr1+7H5XRwzKgFn/X33X/yGpFnbJ978v0YnRklSKgosWf72ubVGoU8yQmVhKBeIAhmJfST2n+3dc16TjFAIXHrvmmv2s+CeiEXYLaVnhNFAuURIarTIhdD1/XXFR8CgX5Oub7Jdr7wnkdY6hDCx3xv8J4N0BrgKHrSMdjevngbDa0ZYlpG7LlLWk5whbOgXboWuI+wiQDdWLJ04ykd/eDiQx5lrmFKw470vGUeDyhbmrY13SxZSgt48dPGF6/dnlhs8dWFVtrYbjidN4wmV0SjQr2VU1EjOluiKIBsnPGUUYSR4xn5zTbNXVfM0pj6mrHo+ljXu9fc7u55nL2iCRKSLOMxhqqrsK2FptHTKOCp+Uj2uolLS1RlNC0B/JywsnsgrZr2DXXbM2BUTFiaDvavoG04IYDKTE5CXu6B2+t39NhsVyx5Rkr1tRsqZ0+a7PxDJMWew4F1+ABQJJ4ECDtkroMlalJ35QGFhGTiXv/YuEF8Qq8TeMF5auVZ2rGY28sKj2DDE/FRoWLXK9W3sxTeogk8ccncbqydDFjyt6l61A3oLof5RSfJDB0HlCqE0r6NpVCtlt3rloTToyU2u5VqhRYC41Lq8oHawmaFYSlHwmDus5B+x8GrDGYtsKmMxpzoI/n7E1NFQ/MjoJ4+6DT+tqNL2OzGgw/6r/gb9NbrtiyoHZzt64dk7Vc+nsWnCD+6sqDLPBJBPiyF/j5Ppt5xjdJPKsax541ltbKWpfkhIu/h2yMQL9AS2i4K1uIrYExPjESixaCDd3f2mYoRI8iv4rDfbYqHAJI0mKFXltKbsL1XMUa630S4QskqaM6TNTEvuucxfDpGsHdRp+wW1LHGLJjX3G8G6DVuYDZty1pmmLOz7FNA4cDZrnEjMfEcczIDhDF2DgmNpYhtsR9Sx0bsqwkbS0RBptAQs7QdXT1nswUjOcT6jyHzYbmZoE9N5TvPcLe3DIcgLrCHnasrWWIBpqu4+T0gjhP2bY1QxbxrF3QWsvj3JURbQTlbE6739IOHXmc01RbLseX3O5vuNndcDl9RBpl9PlAOxiGvqZjIMpmTOKS98tLnjWv6SPo+47kuBD1+ckTXr14waGtuWXB4/yCqtmRJTn7qOOWAzkpF4w50DKjfCdf3cP4hxs9hudsecGWPT0NgwdMyi61hA25f9iLzQJPhaukdXHhy2V97wHGeOyDtgL57a3bxmTitqFSgDoJtdSM2CodF/gHwtOnfrFmBdDt1meacezXOzw58cchNkxmiHC3NKLtCcxpzcH33vMLRs/nsC8gXvnFqiVcryqf4coB/vbW+WcJMCrYS4PWH5c8UhlG5ykWQcyWAGn4INL7VX5UwD/+vWkq6vGEpm8ZSktje/a0dENHjVvz9AFofX3Gl9k5WOBjc8W/iZ7zabzmigO37FgZ4xirFy/8/JQO8dUrN4809NqXDc2z9fpuyb4ofDleTJAYqlC3KYZIQEjzWclLOEfBg5A8gml8V0elpEjvEwsVNuGExqZiwkK2KJQ3aC6HBqzh/sSGgS8Fir3XsYSgS/IH7U/u9WrckZZM4EwJk7Yfdl2KwRNjJ8D3FuPdAK2LgeGonTBtS3w8SXtywtD3sF4z1DX709OjmN3SW4OtLVGWkgF9s6NPR2QkDH2PTVLiIcEYgzUt8dKQzydkjx7D6pb26hVV31M+eky8XGMjsHGDrbccgCiN6W97TufnJEnEwdTu6pglfWt4L7tgFo9oIks+mjI0DcZ0xHFCW++Zj05Y1ysW+2suxo8o4wJbWtpqTzR0rPodURpRxgVP8nNedgtqBmh2FMmMJMuZjS+o2i2xtWzSMZNjF+K4mLKjYcme8bFsWNA/eGv9no09LS9Z84oNNY1js/Sw3+08YBhcAoI9BilZMcBdDZZKf8ck5g1Yu7i4Kzo/HFyJQ/oOZYMqRYZt2fqRL5d0X6MRfOtbbnvHOfyG8VGgGwYPgMABrsPBARuVKLX48+2t97YK9SMS7hZHfdpnn7ntazHotIAPPnLHt157PytZQcj9XoL8xcL7gYFn78rSn5/OQ+sYXl15z6Cq8v5GoZhWD5Fw8VqZy8YxbVXRTZ2vlokuqG3LjtYtwWU7bGSPOi1L+iCIf+fjy+wcbu2O75tn/Di7ZcWBBQduOSZGr175JKZp7lqlaGie3R8CEWKYNL/L0nvQgddnhr5zAlahdYHYJzFFmtNq6BD79KbLdoDhGFuURIQsD/j9ht3Ib8T09q6oXfsCn+xo/mh+hCXRkAUXYAs9vcLt6PUQ6IVMfBx7VjHUfOkaK3kNr0loeAp3uyW/4ng3T+qb4Y3mxM7nmGM9OZaw7dEjF4BvbmimU7L5nCQviKIOW1eYJMdkMZk5YPIR5Al9b4iLAnvYAQlJbOlXG6LZlOL8EVFW0L18xqFrKS+eQJoRLzdOM3HYsLcGc3qJ3S6YlGOIcuqhhzgCeyDpI2x6zjwu6ZKILE/dc66HmJi+qZlmE/Zdxaq65XR0ThkXmNJSH7ZkacKy33CazJglE+qhAyLWzYqkLUiKgmI0ZTJKqJodq2pBOX2PvqkoshHECSsaMnZ8xCk7Ws4fgNbv1VhS8QkrFtTsaejAr72nTjsBlSgQWytQiDrfbFzAODm5C3oEpEJxaF277FtBSBopbVdLzoBfpufVKw9CksQBt/fe8/YLAnsq5wm0iUmTH5h0WiqNTia+rPj++25b67U7p7J0r+l8BBBXK6c5E0BqS9h3DnwZc9Rtxe4BJQZPdg4qcYht04Op69y1k1BZJcWwBKLrLcZKLEFoWqrsWtdJx5gkDHWNiWMqBmrbMBoSdkODiQydNdRRR3nHIf5BEP+uxpfZOTQYfmhe8FfxK66iA6/Zc4vzg+TlSwfGxSwfDi7xCUEW3AUOd3ZovM4R7nYhwtGYt/ddhGKgNWfFMostUgKj+ah7VTrO++smjko4zTyjdn9dQLFnKs2JIQrX9gxLieA/HwI3nZu6InVNxGyVQdVGQEegLNR6hg02fe91l+qG1o9KoHC3DKl/tU2dg8ChQNxbjHfzpB4XjrKXyPd4MwzTqddQlKUDXMslXd9jZjOSsiQajzFVRVRbmiQhGXryYkyc5KSmgfmEfnfA9pYoK4g2W4auoTg5IfrWd2k+f8ah/YLs9JzkYg5LQxRNGfZb2sVAfHHJ0EAX90ySHso5mIPLMHuDTS85jcd0SUwyGLKiIGo7YpPQm54yKaj7mk29ZlbMGSclw2igqraYcgJmxxlTztIZje3oihnbw4qT9IIhskxm53R9w77Zs4hvOCvO2dUbTsZn1Bg2NFyz5wlTDrSMyX/19X4YX/sxMPAFa56xYkdHwzFIrVa+1CCxZ5JAM0AyeIGsslNw79dcur31wm8F0zDDffXKM1Z17W0chsELTcWqDYP3/AEX+J8+dQyR3NqlzdJ+4G6wLQoPgrRGYRx7rdV+78sa6niUE3bfu98fP3YA6vLS/a5lTa6vITqHduQBoLXeQV4PmtXqru+VSqP6mxoKFGAlbBcLKJuI0DFeSx/peumhFHYf7nYuph2z/LraUadT+r6jT3pq27CNema2f1M+HI5Q60EQ/+5G9yV2Dp8ON/x/w6d8nm2PIOtAbYybb69eeXF4VbkSolzff9UQMFI5WyBHSYJK5/O5T4IkJ1AyBb6rVnEg1CFpPi+PK0sIOOme7SrYVF6UH9okKNm4X7oLLRE098UYhZrGsJx5Xxul8w+X8hHLprkrgCRNp3SdOo9wdQz9aDtKgqT30nuLwoPS0H9L567jf4vxboDWPhCKqlRxOLibVEaGahc/Lng7rNduTcTZDJtlpMZggb5rGQZDnpbYvCSpe+LpxIEx05BkOVHVMgwLsvkM+51v0726ZlgssLMJ8WwOhz29tdh9hX39kuLsKdE4xnQ93dDB+NzdfEXC0N9gkwvOkwkmi9l1FbNySt722N7CYMjilKqvSaOUMhsxSUcM5UDVbInKE1ZmxwkTLtI5XW9os5bdfkXcDxBHTGbnbNbXrOo143xKaqHuDpTZmD0ttxwYHb+6goTkIQR/40dNz2cs+YIVFY3rNpSmStooBdPRCEwDxXH6qjtOQEA6pNXKff7iwoMIBUNtNzQFVAlBpS5pQlSuNObY8XjsaHr0yL1fAndps9RxFPpPSeQe6iEuL937D4e77JmEv9qWOia3W/feszP3INps3H4fP/Zt5i9uYXbir9Plpft/rc2odRa1TwFEBWNdJ8Wm1co/zEJjRJV2VAKROamup65j2M2kYzx+B23b0E+mNKalj8dUtqOOetqho00eFpj+Ooz+aCAbjhU13zef8cPkmtfRntdsWYO7Hz/91CUQWi/z5UsPaH7VCK0UNI/BC9jL0tukgC9Jak6phCcj31DzKH+tEEyI1QrBjjEQ55Dzy2AjLK+Fpqlw1y4iFMCHcwbuAp/wtdAFXsBG5xV2JIulEjt+eenLh2LZww5g8PMw9PdSXINf7poMOw9D0PUW4x05w+NFu6Fuom09lTka+RKHEG3b0u92RHlOm2XkxmCyjKhtqc2etK/J8jFZM5CWBZ0ZsE1NnMXQ9LBYE5/MKC4vqPdbqA4MXU88HhNhsUlCu9/D4grLBaPxCfuuJdrfYian0O6gmGHNAgucJxNskrDt95yUMyZtyr7ZYSJLNkRUXUUSJ6RYZukYYzo27RbyGZE5ME/GnCQThrRj0e1puj3WWrK8pBzNqKstV+sXfHT2bTbNhiwpIHadhzccKMnY0XLC6Fdd8YfxNR8rDnzMigWtLxvKOToU1L7JsAZI8ruC0zx3rI4AynrtwIJAkspyV1d3KXZjfIegglK4lI6YGbFZk4kDOwpOJyde07Tdenf5sPtHQ+zSyYl3lFbJTZnm+bn7XexWnrugKi+xvvf+XxL3axmReQa7rQ/OxrhgrOVPpM2SXkxgKSwhSu82Hrvrr2WA9JCQZkvieVk8hIH5vm9S6Hc0mcDhQFfXNNOBqq/o8xO6wbCxNb0d02AwDHRvwNZDl/G7GPe1WT2GHw+v+Ev7jNdJzWs2LMCX1F+/9iXDmxv3+68zBFg0V8SoNo2//0P9JHg/Oemjwmfmzc3dxaWzzM01lQ3D0h34uWEtDCXMEg90Qld53eOh47vmmcBX6K4elhLD84yD+1kgKUhC7gAlsU8yNBaYknYVfAyQJECJXdhZqWRULPV9uwrwc19d0eEakG8x3pEzfO+zUQEsud+q4+dw8FShtV7TYa3rUBwGurIkNoY+y4iGgdYYTLXFRDX5MCXLC7rRCNt1xERE1jCs1iTTCVleYPIcW1cM+y1RXjJEEUk8pdlX2MU1Qz8wnp2yGzrMfk0/mhE1EfHohK6/xtqBR+mMfjBs+z2zfMo0mrGpNwyxxZiOfbNnVs6gs0yzKX27YtNtifMT6A9M45I6GVMMHb0ZaJs9WTFhNJ7Rm5a+PnC7v+Z8dM623XJantLSs6Xhhj0JM0o6557/ML6x44odn7FgS8UbWLLZuB9lrQIxfQ9R4gOGSm0Sx8oyRQtHqxQ/DO5hcD+YTKfudwUWMT8ShoYB7fzclQsV1MB39M1mjj0D936V3MRUSUMxDO741NGorrzdzscBbV8u87KTKEsHfhYLt6/p1P0eLt1Txr5zEfxDRKWYOPamkForUcaqOu6i8IBqv/dlVDGLsnpQN5T0c3qAaB3K0ABV2wrWfDSRobYd/WBo4p6KjoberXsYmTedhw8O8b/78WV2Dl+w5c/6n/JpuuUVG15wZIOvrx2bZYz7fq+u4IsvfvVOVGoT0xKWxlRCFNARCNFyNwIcKhkuFp6dBt91FwrEpa0KO+60XcWP1Qa6ewJ4ldlCrZJYKPjlcqL0VSErF5bWwZcSdd5h97HYJ+m/VN4MtWLh8kFircOuSl03JVBheVVzOTRHVTlT/x92OoYLxH+F8W6AVml8BquAJD8biUxDL52wJVtBrW0ZhoHhqCeJkoQ0jmmBYegYtgvMeE52vODGDCStxUYD3XZJXM6IBgOTKTQtQ99giWjjiHSc0fUpLG7Zdi3Tswtq02DbGJsO2MMA43M+Nwui3nKRzmi7lt1QMctGnMRnbA5LbGIxbcM+SpiWU6zpmWUzlt2GRbfmIjsl6mvmUUGXTHgRR9hhoO2cAL4cz9gPhnW9ZZJNMVFPZWpGSUlNz5KKMTkxcEn6EIS/oaOl42MWPGfNlo4DeG3RZnO3G0dBOMp8UFIXz2Lhuwy3W8fkqOynNf1CU0ABHQUesTNd5/YLbjsqXU6nbpvTqWeBksSzW/u9e8DIr0qZs4Ci9i3GLAyocq4/HO6uOSaNikTFAlxN44XyYsVWqyNwPAp/BXzuM3TSYc3n7hwPB3e+WlxabJ8eVBILS7+mph09NFQq1Lkp+xc7qH12nbuejx6563M4ULcNVZRTDzXGjjjYhiYaaG1HEwAteBDE/y6Hxf6SNmtLzb82H/PD6JrX8YFfcCw9bbdO7L7buTlxfQ2/+MWvtyN1CIZD5XIBllCQLt2mGJrQgFOAKlxq580JHYFVyH6H5UK9Zq0rHabWe+yJsdI+BKjAs936XcAn7AIM9VChRYT+Fp73fW2nSvNheVPbUFwLAZO1vjKmz+kaas1UgU1pvKRPlU5LYFWg7o2lzlcf7wZoNfjWTQVarakUtouHC0eqRq1ac6iTSFMia+nynLTvsUBTZJjDClNMyHpDUpaYsiTqemgtw8GVIKOqxk4nUCdEfYPF0NuUKGqJ5lPi3Zpd1zN5/NS5yicRve2wlYXxJZ/0CyITc5ZOaPqaKIuZJSUnk3OG/S11OtC0e5IIRvkUjGGajNkOFYt+w0U6J+57JnFOaVOMteQ2ou4OFOmIrChph4Hr/TVPZk/Y1huySUYEVPRHf62EHc2Dt9Y3dGxp+YQF11Q0HNkm+Vop4dDDHo6BLvEBUsJZZXPLpe8yevnS/U0ARroNBTqxRaExp1i0UMA7m7nOQpUvZHyqoKdgprKlgmXoKq2sUOUMBTLpl6QvkXRAmict5yNhvLQf8s2RG/Z8Dld7GAqvddls/ANKrJOAnxI8cHFFzJU0H/ISU8egPLnkhJ/n3qg1FAzrHEN/o7D8q+/NWtq2pS97etPQxC1N2rOPnJ9WE3dvNFoGi2F4MCr+HY37IGvA8jN7w1+YX/A82/Gc49zoezfHXrxw3/V+D3/3d7/5DnU/wi8DlHDOggc9ISiRFEeMrZIFbVv3p+Z5CK7CMre1YIAOD6ogKCsOPsnQ57TP0PdK4Ay8lkzzPSwjhqVIfVYsW7i/N19EAOpC4CYmUCygXleJsO994hUasYZAN7SnCAX8odbyK453A7TawvvgKACrHq0vVDVnoVb9SGOx37uLeCxzDHFM1DT0eU50rM+2eU7fHrCmJY0seZpj8hTSEVFTQd1iE4h2W4bxmLiYEu0PEPVYG9M1Fdn5Gf1yw/7lZ5SX72PrCjuactOtGXYDZ9NH/Lx/zR8Ml5wnI5q+JsliiHNOJ+csDksaO1C1B6IoZpRPGIaWERmHqOem3/AonZP3EZNoRDQYetsTxymNaRgVU4wxtP2eTb1hnk3Yt3um+fRNCXFEilvNMSN9EMZ/48YVW37ODSsq3jSA7/feB0qB8U4Wik9QytJluWXpywJPn7osW0FEJUeVB/TwV0lMSYwWXVYrepK4cuGHH3qqXtvUA0FBPdRBhCBDmWvbevZJnwlBj7LRvneswMmJA0Ladln6cxDw2m49wExTGGKni1FH4nbrtWpF4R8KYbejlgpSkqfYpHPQg2u/d2xUqPHQ/yvzVlBWqVABW9+hyqxHTdlwOFAXUw5Dx8z2dDjj0sZ2dNg3YuwHQfzvbnyZOekL1vzf5if8PF7webTiTQry+rUrGeoe/OlPf/MdqiQuxjacn2GCJYZKrI50SeFC0RKNK5ESYAlLjSGLJfAlBi1NIUthHrBdAjd6T2jx8MZ7K2C0wt8FujRf9LdwXoVaL71XyZmOMQRdoUdYKGQP/w3NU6318z5ks8AzheCTwhAwKr5+I4FWGrlAqKxdZowyZtOXp6xSKFx11jx3AViLxh4DpT1+uVY3RNtikoR915KbFe14ysjkRGkKozE2qqGuMLuWyFiYT0lmM+xhT2fB2oHmsKY8P6Nfralefkr0/reJmgRbjrjp1rCH0/ElvzC3WHvKBROq3pmdTuKck/EZmwr2zY6m3hETUxQjTG9IBzBxwo3Z8jidkxEzTkoW3Y5JcuIW1B4Mo2KCxbI+bCnTEuotWVpAnJHSs+DAiIwFEY+YPpQQv0FjYODvuOE5O3YSwVvr5sV67QNPKMZOErDH94VslroJz86cGDZsDw/NRZWJSrAudkj7C7txTk8dkyUgosw0pPQlsleyFLI2ylbl9aOFsWezu5ooJVHK4rvOlSF3O+8HJl1WFPk1EM/OvFdWUcAMsL0vo6rMKJmCzl2lRT2sxBCErKGE/1r+qK69dYaaA6Qvk++PHrgqaagcIS8udTsFbvItbo3Ddmhp7cCOnsq2tBhqDB2GIvDUehj/sOO+AL6i46/tc/7V8DmfZTuu9Pp+D8+eeUPMf//vf/OdzefuXlku7zZrCJyrVK5yvMpkYUKjjkABDQnCtURXXd8FJGKNBB6GwbPDWQaHFOLEW6IIoIilUhIBfp6IpToc7oK8sEEkBF0qL0qPKbb7/nEJ6OkzGqGGKwSQek3nCXc7HvWazlXXLrSVkFRBMe8trR3gXQEtahcoi8IZE8pEcL93gVRdGzpJnXxZus8oWKtNWwFTOoxhuLueWpbRti3Zfkt9ckpqDGnfExc5ZAnDocJs10TDQHw6g+mEZA8miTG9pVrfUJw+Jlov2X7+KXz4AcQR5COuuw1DFXM+OucXZkVvDZd2TD3ExDFM4oL55AyAVbUiqnbEcUSZlTRtyxBZ4jjmtdlCljJJxjR9y67dMy2d11YcQZ7m9FnOsl1xWZyzrzck4zMO9CQk3HIgeyghfuPGjoZfsOIVW/YqVwhUyJw07CxUwOobKI7BUGyWym/WOqCl/68qXwJTQNZaaApSCpDK9KLIzcUPPvCMj9ieorhbPlCnnuapHgQKztJ8ibkaBvdg0bbU7Sh2S00xWeZZr7Mzt+2XL73oXesdKg70PcwvIMbtT0LWsBNQx6tjrWsf6LVEjsSweoCcnjqGLUncA+n8/K5GRtdRD0k9dFS60fYUsHc7t80jG9YOA3Xc0w6Gduio45qGntq2NFF/T6c1ED+UD//BxpeZk/4d1/xL81M+idd8Fh2/U2McY/z8uft+v/jCf++/7ogiD+LFrsq2QM89uGs/IpZJ95bmpI5JbNB93ZSAWniMAnTa15t795hUyBBYZUwBvXDB+vA4tY1Q8B5qFofh7gLXIbuksl+oRwuBkj4fljqVrGhOK+Gp67sLSoeaMW1b5URtTzot/b9+RPL8fcsk/Zrj3QCtwvqgNgzuxtJirjc3fmFaPQCkjQB3sS4uXCBVpqxMer/3pcfj2mdRkmDrGoqCrm0x6xX5bIbJUvLDnjgviEaleyas1sSDIbq8IJ5MiOoDUX6KWSxp1q+xZ4/JWLH59FPKDz7k5PwpbZ6w6FbYCC6LEz4btnRDz/s91FlCFDlT0enkFOKIxe6GtE6Iooh5NuO2XRAXYyyGBRUf5CXTYcquvqZOUvJiQtvXxHFCWYw57Ncc+prBGOcYn5XUdCRErKkeSojfsPGaHT/lmiU73iwnu9v5rryQJg8ZEtPBeOZLCwo006n7rKhysVj6rBY5VpABX8I/HPyBXV668uN268sGs5l7TUxZGGCt9cFY5TI9QARkqsobfQq8hVoROblrMWhlslqO58kT95qWwJFx6GLhwM9uB/sNfOvsbkaq49HC2HogyV5GTII0VMrEVep7/NjbbOjBoFKg7GcOh7uBvyjc8bzpEj2C2KJwD68PP3zje9a1LYe8ZKCjsz2VNdSRkxD0kaFjOP7nyocPMOsfbtzXZt1y4E/t3/G3w0s+yfagasHNjRO8q9z+63plhUOgR80lYlTVFSywETJDum9V7pLnnBIyJQrhkjgCakqm7nf/heXFOIY6duVDATWBFw3FA/nuiVkTeBFoCkGXAJmYXpkiKy7pWS/dp575YuhC4KV4px8duwChLG0EBkPriNCkNBTpizkLr4cYMLFubzHekUYr9lqF+dzXVE9P3U13c+MyBDnbykFeN5jMCBWIRa3u9z4IRhEsl1hlv8furWEYqNdrB7ZGJUXTkEYp+XhMnUJ7e0syDCRPLiHPSXpDdHmJubmmXV7B2ROyOKb6/Bn0MH/8HnUMi24FUcJFNuFlXDH0lm9FMXU2BhpGFIxHcwZrWW6vuYhS8lHMPJ9xW28oRlOMNVwPOy7KMWdmzk21IU0zkjTHdA02iijKKcvDiifjR2wPK/L5E+qoJyVmTc2YnCU1l4wfSohf82GxfMwtn7Ni7ZaQdkNlQ3lYKfCqLNU0kBW+FJdlvlVamWjYuSvmZb2+a5kihmYY7oKs+dy7yheFXwIndKAXO6bAaa3bhl5TAhRmitKSaMkdBbn53FshCGzJ90ds0uvXnk26vHS/i0WSb9BsBuYYsB89cjHk6Fn1BhCdOXb5TRkx1IQIKNa1ZwCUHT9+7NgLcHFmNrvbASXj1tnMnUNZuvMQkFTw1nUKWYS2pS076qGnNi1tathGDfXQ08SGjv5Bp/U7GCZgDgE6ev6az/nT/mN+kSxpouN3XVUOZKlZ5erqq+1Q1g0C9WLmJ0XaAAAgAElEQVRXw2478FpMdcjJS05ATe/X/SuwJqAgACHAFZb2wm5gAa+DgT7o+g0ZHoEvNc2E3Yf3QRf42COmW4AoBFL3u5Db1p2jtq9GOSVg8/ndZE3JpuKdgFeoC5PGUpUygU4dQxgXQ5ZLIOwb2XUYJd459/bW/b8oujx35cTDwQfY+dx70YgFk+ZBgEu04H5/Z1kflku3/ZMT4v2e4fhFtFVF0vfY8ZjcDCRdS5bktKdnmNWS4dVA8vQSkphoMKSPH9PevKZdvILz94ix1C8+g2Fg9sGH1L1h0S4gtpzHU66SGtNd8d34fUgKYlpyMibjE4YIFqtrLuNHZEXJNB2zrfcUSU5vehbUnExO2Sx37A5bZtMTyArsYIjiiDgvWbUbTpMpu3rNbHTKnpaEmAUHUmLKo8PWw/j6jpqWH3HDF+x4A3OM8aAiLHUpUIFvWZbNgOaGWOH7Goy29SUAaZbS1O1D3jMax7nyxlLl8vKXGSsFN/A6L7hL36tcqXK/AvkwOPAURd5KQbqnJ0/cdmTUKmD1j/6Re5jVtTuP83P33sXirmv9bgc2hbr3pc9Xr/z5CNxpyY1hcOcoE1U1BQg46sGwWjl2TwBxs/GgUecrHZbOUcmggKjKFbp2VeVLRW1LOxgq29Oali4a2NuOmoaOgfoBaP1ORnuPzfqUFf/L8EN+Zl+xDC0FvvjCabO0GPtXGdIFim1VWU5AQaJszT11y+r1sOMvTMbEQAtIhb5T4EFIaPcgAfkb0BdDGXQLh2ak4AFbWIYU26tzE6ALS25hsqF9h0xU2OUoABhqsO539govCAeEejCdZyjKF6AT019V3roGvIwh/Nz9f7/ieDdAq0+8X5YCvr4cGbWJTlVwqyrvlqv6a+jDpQApLdd67YXymw00DcPpqUezVYVJEsx+z1CWZHlKZixlNqKZGobtlugF2MsTojgiSSKyx0/orl7RLK8YnT9iSBMOrz7BDIbTb32Xum5Z1msYJ1xQcJ3EdPVz/qPRt6hiiIlISJiNTjC252b5isfxB0zyknpoqNsDRfqEpq/ZRPB0/pTPVp9RVSnFZEZajGiGHVle0FY7drYlqjYUWUmeluxpyYgpachJKUjJHxae/tqOGw58zC23bL1JqZIPBTZR/cpUJZJNM6h2XucAHjTJcFQ/YqsEsuQFFZYDwAGS83OfNY7H3khU3XU6htHIZ99huzl44CONpFhmZfACWFqnsa4dsNrv3f41/+vaC/Q//NAL/FVekBmr2CkdR2vcti4vvX5L5qc3Nw40hUakigngtqfsWsmaDJXFVlWVA3lPnngWT+BV1hQCUiqz6kEo4KWFsY8xrzKGJm3pTEc/9FRxR2U7OnpnYMpA8QC0/sFGf8+cdEPN/8aP+X7/Oc9TAyrYrlbOvmGz+WogS3MaPPsDd5lhAS3wc1SvC0xIyxRuU2ApZIjglz8XyhH0Hs3jNIX0yDKHDS9im1Tmk/5RxxlqEMUIa98Ccjq/0EQ1LO3fZ960woSul8BWyMSpQU6WT3C3i/K+Tg08oJQ8SavRhNquEPi9ZcchvCugNSQuCIYPBtH7KiWGTtPqTlIwDEsXAltaRBN81rpauYAWuseenfm1FJdLODujaxqGvmcoCjIG0vEYO1hMfYClJTqZ0QNxnJA+ekx/e0O1vKGcnBA9/YD6xXOWxnDy3T+kqis4LGBywfmQs4wtP64+4x+Pvw0RTIGImNPxBcMAN+uXPD3/iJNkygvzgq6tKLKSpm8ZspzH00d8sbsiyTLivCAvxtSHNUlWcGj3FNkJm/2Ss9ljohj2tBQkFKSUJJwSP3jvfE3Hx1zzC65ZyTsLHMjabj17G5pdKmjkObQNRAHlrwAt8CNHdQVqCdiL4u7C0BrvveeAixzS1WUnZksBCXw5cLv9ZaGsyvhh56HKD03jmR4dhwKkypiyblBpQR2YEpCLMVIDzHTqM+6ydPrPeeq2o85DgcTRyJcZHz/25b6zM19miCJ//mIGFMzFzs1mfrFuvR4OPTjCNnixCyr/CKjp2LqOXdrTDx2VqWniERU9le3po4H2aPNgeRDE/7aHMyf1rO6A5S/5lP/D/ISfRWuIj4CmbeHjjx2bdXv7FjsM7Bv0HBNxELJVGtIIqcyle0nVHf1/WA6Eu/qu0DZJpbuQARJoGQbYWNe5qzmmJEn/r3mifaiipGfs4XC3IzC0XLhvNaH4MZ//slYsTDT1PvClQjHQWj4sBKgCftqmAJTOWTFJJUmdj9hmaTXhbjXhK453A7RMe1frIYHfbufKJpOJu/CrlacFFcSViUvUK1Svv2l5AolnJxNXPlCgfP3aBcr53L1vs4HJBBPHDE2DyXOKOCKZT6HvGOqKKI5hPKLPM9IkIT2/pF/ccjisKcsJyUcf0nz+nPXQMvuDfwx1RVQtsJNzzslZDzU/rp/xvdG32WMZk2GJOJues7QDr5bP+eD824ySgq7viaKWLElpupYszzktTljvloxPH5EkCdloRrvfEGU5+6EmtpZDvWU2PqWhZ3NktPIj4JqQP+i1vmajo+eH3PCcPTv90VpvaRBmtmJ7xUYdXcVJg3ZlvU8aDmkRNEIbhxAYJInrLHzyxAMmlblkY3B/KR2xPWHXYhjUosgv9qosUcFSerKicOAOfIegWKzQHV7GpVXl5q5EqRIhn505Fuzq6qijOF6DcI1HlVmHwe3j9tbtcza7u29dG+k+b2/vCoJ1beZz73N2fu7PTcFc2hb5ZYXGruBd7sOOra6jL1tqOmrT0WaGA62zfEicxUNYPnyAWb+90b+BsG58zA3/jB/wg7/813R/8Rz+6+/Cf/GRY7B++lNvSfJVhoDEr9vFJhClUruSEmkvwzmnbtow8Ql978Dfn+G9p+2EIvA5PqGSma+YnpBJ0zmpY1g2TXoGC7goTuj90nxa666nVsDQs16sk85BP3Hs5qr2qYRO1SuRLDq+ELiFpVD5CaobWnFUpUVtQ3qxtxzvBmiddp6K10VoWy+GXyy8NkvoVV+e6FH59ejmE9K+vnbb1XumU/jud51z7xFUvcmcT0/d78fM3SYJnTH0RcEktkRnM5LFBnOoSSLHLvSjkiwvSc7OibZr2kNNFqckH7xHc/WK4Rc/4uQP/oTDfgdRTDQ+Y25TVs2eH8fP+ePiAwBGZEDE6fSCxWB4sfiM6VBSJim16cijiCyK6UxLOp6Qbxua3Zp8dkKapiRFSV8d6GxHTUTUrMmygjJzmfCamoLkaGYaMeLt1mp6GL/dccOen/Ca16x9iBfbEpqKKjDqd5W8Ogu285ki+MRBoEIj9NW5z75cXrp5IP2SthOWz05PvZ4o1GdIWyIAImAoV/micJ+Vv5dKhipfyIJCDJfKiSrVSfehdQ/j2K97JvC5WLjk6qOPHNOwXrpltaZTXypV67w5lhRHI7+MSZK4c9eCtfLKms/9Oop6WAlIgQN4V1fus7q+YgD1wBM7FwJnMQBV5ReYPj4EKmupMLSmprOGXdQ4iwd6DjScMXrQaf2Wx/2ldvY0/FP+hn/1F3/B8r/5n1wZOv9z+F//Wzj81N03b/vgvc9YfdnQ/a17RgAi1F+GZa2wU1ai7zT1Jf77uioxQooLYnmKAkYxjAZvAxPatIjt0TGF1i8SnOt5LAnAbOY/L8AYdiiCO95QYC8WTvNWc0vdwSELBt51QKBQ10ZMm9g+rc8qxkwsYsh8hdYU2tdvat1xb7wjAY9xAXK7dRmhbgR1Tj1+7C6Wgv9k4i7kbObruqrzgntN9vpixtR6qqz4O99x4C1ci+362teiVSOOY6y17IuCIs9JzmawWGKqA3FZMgx7GmtJ85xkNqOzlqZqyQdD+t4HdFdXLH/2A+Z/8D3swaFlW845tTGresnP4og/yp4ClpKMKIo5nT9iYQduXj3jnyT/GV23pDcdaZKRENMNhmI0oap2tNWeYTQhLUqM6TGNobUDiTHs6g1pnBIlGXs6tjSkpJRH5/gHvdbXZ/ycG/6OG3ahZ8/NjZsX4dJTYdlNgWa7hX6ALNB0WOvmTNg9CHcXQ72fRassv1ze9a8R4FLCImCggKQAOJn4IKwuYgE/6cDkMD+Z3GWklR2bYyy4r6kIu4pDvx6V/+TDNx67448i+OM/hu0nUK09aAP/WT2oksQBQSV7KomGXnzbrQOJOl5l5zrGonDnpPZxLfshZk/gTNo1BXWxjzoHNRM0DV3fU+U9bVfRRk4cv7cdPZYG86Yr7gFo/fbGfTuH/52f8//Yz3j2Zz92IMtY9+8//7fwT5ZvVzL8VUP3n6o94f2qRhbNUbEvAgghex1ql9ZrBw61bdkfhN5batAQQ7RPYHpkjsNGHJXNNS/lYanERyBGJIiAlawg1AAQajuVSJalr0bt914ztd36z4SJluLVZOLB5Hx+NxaF5clQsyrQFYry9btYdyWOcJeN/qpf7Vtv4auMQ+HLE1dXPmirTCC9hXxutlsvBpbwXaJ5/Ru2Ymso45Y3z/vvu8+/eOGXzVDmrZvw+KXYrqMuS4rZjPzslHaxwPYxaVRgDgfaYSAtCtLxGJMkdIcGc1hRPHlEf7Ng88mPOfnOHxHv10RRDMWMU5ux2C352TTij7MnQEwBJFHM2fwRV8VLlssvOD976pb4iQaSOHFAO4qIsoyhqTFpCllBWo6wxtC2DXEck3YVWbtnVs7pI8PqyGotSclISB70Wl+LMTDwA17zGWu/5A64ErfWFxQjIg2Q6HZllCY+gq3MsylfVo5QNrff3/37yYlft/DkxGfQCvT6V6BImbNKd6FvnRIX+VApK1RAVCDX+oBhB5TOK2TbQlG9HNzBgxZdB2Wuee7mdNPAh38A/XMH3qQPEZNmjF+8WqDPGAeorq7cQ0SaKa1WMZ16oXtY+tDCvWHpVJ8VyIpjb7WhJX/C1vPl0pVsA43MoWjphpLKtFRxz8E2tBhanE6rOIIti32QA7zlsNg7S+38jNf8c37A981L+K++A/lfOpCVxXB6BOa/7RF23IX2BwJSerbptbAjTvd36DMJdw0/laQpYZAWWkxynnuDVIG1oYW98bHlfsezTFVPTrz/np69YsZCHZqSGpXdw6Y2lTVVeu97d1zyvJPOVPNMoEglQ/luTiY+mZtM7pYXQ4sVnUMoqNf8U0LX934pM1UTvpFdh/uS7KOP6FYrXxpUVjsauYs1m3kd1rFL8I0IVp096grSFxB2W223fkkMAbamcQzaH/4hfP659+YSAla3lR4Y+z2NMTQnJ4xOTzHLJW2WkfYDUVXRW+tE6kOKmSbYnaXZbUgfndMtFqw+/TmTD7+N3S2Bgag8ZW4TlodbfjSxfC99wkDBmIw0TplPLhiymNX6iun8nL2pIeIIkAaytKAfeobWsRtRVpAcma2m70iSiKTdO1YrnxBFAytqMlImOHasJHoI0O94LDnwIz7nNUEJoqq8zkgPdLEnYQBTWSCeQHYELJvNl5cj9MC/z3KNx15wrtKe2GBlyQqsAhFixpQtK+CHQEw+OmJ6BDoU1MNygYCI9qeMVeVC6Z5kNKr2dvCSA3URXly487m+hr6G//hDD5bOz12gFDADJ/p//txf2/ncAzqxCOpunE59khd6FIkZEAug18PyqDQuoWWEvqdh8KbLShiNoRmcWWlrarp4wsG2VENLH49o6JmSPwCt39LoIj9ndlT8j3yfv7LP6IYB/stvw5/+d/B//hxe/Bz+dgnvNfDRb/EAJHIXkNEzTeVksdkCY2Fnb8gICUgJjIXgQEDs4sKzNF13V8cZesilKfQRTIa7Ni6au5qTSjyKwq+UIHZXEoLQ0V0lvdXKSyBEroj5Dc1GdX7qzBXgCpfREpASGSNAJdmA/P8U26RN0zUMGwvy3NvA6Pj1/l+n1PsrxrsBWpklKUvskycMt7cMqhFXlbtgCngyLNVNoG4GtaWG3iP6QoXCT0489ah11vrePcxOTpxu6+VL7+irG7DrfOAWe/D6NdXlJfn5OdFySTedkg4W03X01hKlKZntGOYz7GZDv92Qnp4xbNZsnv0C3v820R4iImw558Qm7A8rfjyO+F76GItlTE6aZJzMLlhvrjlslxSzOZ0dsNFASkxvDXGS0fYHij6hiyDJUpJyRLfb0DKQdHuKrCDpE5JsxJ6IkpaMypUqgZLsnXztD8ONn3PDT1iyCf8oh3MFqNCcVMzOndUPYi9u//sCQehZo5HnTl8k7QR4YKVWawEEicrDtQzDMpiYtlCjEbZgS6sVBkBl26GbvYCY9JeyYgg1X+fnfnuya3j0yJVyXrxwlg0nJ/DJ2oGo01P3vs3GC/Otddd4OnVC/GfPfKD+8EP47DOfUWv5EXUzLxaeZVBJVEy84obKGTo3sYIq++paCdiqfCgT1a5ziV080HQ1Tdazp6eyDT09Nd2b0qF5EMS/1RgYMG+WNbL8C37Ev+QTXprG3+P/+Qfw/e/D//AK13YO/KfAf8LbAS5pl6QdHI89MxyCLwGAsAMvnIN61kk/qJ8vs0C4vfWfDdkoefGBn299BAP+eJSwaW4LZMnqREBGTWya12KTksS9JpZKZU252of+VUqmBDw1b0cjt22V8BWrNJes9YSMAJ0E9qHGTfvRdQ07NiU/ChsOQm3lW4x3A7RGPf1uRyKx7LEldDg58ayV7PhHIwd8zs68zYNMGcM6avhAUWlBQVsswGTiXr+5cf//+LG76V6/9g+rqnIlHLW6CwBeXdFeXBDN5+T7PcNsRlTX2GHAWksN5H3rbuD1CrPbuv/fbtl88Qze+zaWNUQQjeZMqoGhWvGj0cD3Utd9ZRjI0pyT6QW3myua3ZpsOmeIIhgMeZTS09OnOVXfMk5STGSIs5R0PKE+7IiTkqpxrFYSJ8SJc4zPibkh4SlTWvoHvdY7GgMD3+clz1hzR5b+/Ll3g9cDWYFHgVWliySB3vpunr9vhN1G4ObDkye+TC5woGAdukCHrs33fW7USi0NZGgFoaCtkoe6izYb7zSvxEkPCrHU8u1SEqVAH0XuswrWYremU6e9fPbMzek09Z2E4MDZy5cOJJ2d+VLo55/Dn/yJA2effuoF70+euPdXlRe7395636269uDqvuRAwEsl37ADTGy5Og1DAe/h4DPptsV2HbuyoekqWgwVLTvb0GCo6TAPxqW/lRHaOfwNn/Mv+A/8jV34ZB2c+/v//DPQFDPAvwH+HfDf85uDLTV9qNSneycUjoeNJaFJasgCKx6opA0eoAmQqUqjBo7JxK/ZJ5dzPX9VKlMpnRzyzIM0Wc2IZdP8BB8f2tYxykoKVcaDuzYPAjX6fLhEjhItnbM86MJOyTj2FlDhAvYqSyppEUki4BZ6gIGfiwKSoYBfoEy/6xzfYrybp20XEe92tE1DkmUkWYaRCDVN/YrmyjafPXN/m889y7Veu4CqjEAZtGrNEs0a4z4ntkw3uxD1yYkLsHJ81k3z6pW7CeWMfTjA1RV2PqeZTMjUat+22DQlShJaIKn2JGfnDIsFdrslnk5J9jvWLz/BPP0IGwFE2GLCSQfbesuPRxHfS55QRwMmGkjzgrP5I2631wy7FeXsDJtkWNORxxnd0NNFlqpvKCkwcQypy366tmdvD2RZQRTHpHFKHEVsaEhJmJIzoyBheNBrvYOxpeFv+JxrgnJe3ztWRrS72FkBLnXPibpXp5Ct//4d3R9x7BdmFmMm9kWleC1LIRAWaopC+waJXPWa5tSXLWEhndPlpcsyFws/z1WCDDsNZWKsdnJltrJU0ENKQt+2dR2Hn3/uwNb0g2Oys3bHcnnpuxu1n8XCPUT/8A/d71984fVSspWRa7w6ofQdqAsyitzxjMfuM7KJUDYs0a50W/dZx6MAnsXCJXxBd2kdGw5NQ2N7KjqqoaXGUDHQYzCkD0DrLUa4cPQLNvwzfsi/5fnd+bXZwD/9c/jzw5dtAD7l1wdak4m7JwWcQm2U7ucQTAjYqHwVgisBhhDggN+2GGNtV8yp2CN13oX3nxgnkR7Pt76bX/NR+1JpXKBJpTktSaUyoZ6lAlWhHuo+O654pPkViu9Dfy95gWk+CSAp5kiWoDkoM2IlPkpwtB0BLzFsYrR0bqFWTkL/rzjeDdCqStIPPnBrEfY9xhgfNtr2rou0ugxVUhSwEsO1XLrAqE6KYfBtnqr3ypdHAVpfWte5jFUCuixzAVpBXgFX+4rjN5lsN5mQRxFWJc3RCFsUtNaS77dkl5cMtwvsfkc/PSE57Ni9/Bz79EN3nhMgGXESZeyqDT8sLZdATU8epeRpwen4nOXhlu12wcnJY0hg6Adym9JHlsa09FlKMlhskhAXBW23JY1L1oc1RTZm3+1JsimHKGZEyzUHRmREmAe91jsYP+IVP+KadfjHmxuvz1L3rRgUuGsWKnBkf8PV5B898oLRsNVbwV4ls1DnoZ/QaiLM/gQi1Nattm8FKLWaix2bzdxcur72Duz3S/7SjAiI9b1n8qRlAq/t0Hx+7z0HmF6/gvMPHAu+Xvvy53LpQJfE8BK/yzhZcUSSg8PBGynvdu64pZFTo44CvsCimDB9V4plKsnoXEOGYLPx53t8iLSjkSsVmooum7C1DfVxgemanvGDTuuthjoNV9T8GT/i/+UTXuk+l9/S978Pf3UFw5dsIAa+82vsSPolib/lCXl//UCxxWKt4G63XyjKDjtztZ1wnmpNT5X+Q9AhcCUmXNpIJQ3SNY9ncBn7zkKV90YjB8akeRTwCrv1wh+RH9qXjjPsGhS7HTbFSPcoxl1aa7H7YrtDU2QxgQJV+l1YQscRdiKOx/49ArgiZ5SAKsa8paXHO7N3GKUjzEWGaSq6uqIDoqahl/K/aby2Kkncl7zZuBtCgaksfaAU9an6c9O4QKu2z93Oi+skEFYWLiRdFC5AF4VD+spshsHdYMo8djtoGtrJhHQyYQDi44Ky8WRCu1rB8pbk/Jzh5ppov8JO50Rxw/7FM3j/O0RxjC0tNi45yUfs6g0rDI94ypwYkohRXtLbU24Pt6y3t5zMLsjTAtMZ+r6jixMO7YF5eYI1BhvHROMxh/2eUVyy3S+Yzy7Ym4okTdjQkJBww56nzGjoH/Rav8NhGPhrnvN5qM6y1pWrlAGCp7TV3RY6sqsb5jcZH37oAZaCjVgizbfJxGenAkBvNBu9/5weCAr4CuBh11Ko29KDS5qOonAMjnRPTePAic5N5Q51F4Zi+9DdOfQDUynkgw9g9cxdz0ePfODWMh6bjTtn6bc+/hj+6I9cDBFzJfZhufQmiCrxjcf+gTSf+yVYdB0ENrWIvYCntiFwpnNQeUSLUQO0LV3XUaUFdVNTZS0HWmpbY6IJB1pOAz+t5AFo/UZDFhkVLf8he83/xXP+PWtffgL42c/gJz+Bpw0kcM8B4lePNHX3nzRJoR+eGKGQkREIC0tnIdMicKJthyypyAh9bjz2oESAQeV9ASJZNAhc3DPOZV27ConYaJUP93v37NM+JxO/DR2v4lNYYpSQP5RDbLc+Rsj6QQJ2HatAnhhwHaNApMBfCOZ0zRWLFDtk96Rz0TFoO+H+BVr1PQj0vcV4N0Br7AxLk3JEnJfEUULSHOiPLefDbscg912BrWFwIEgXSBdXFKmoVt04MjSrKu8wHzrIhhmpsksFwSxzwXe59CUba932VAve72GzoR8GkosL+igi224x0ynx+Tn/P3tvEqtbdt33/fbep/+6272myOpIFik2tkQFNmXZhqRAUOI0QAZBEiFBEo+cQTLIJJNMwsySQQIERgKYcYBEgJEICOxEsRk7gRUmakoiTYmiSLFIq4pVZNWr19x7v/70e+8M9lnvnFvsxHolEbLeBh7ee/e7X3/22mv91///X+31NdH1JdHpKWq3p99vUMszDHC89030cy+GijRxEMEyyTk2a75q3+bPm2fCQOhIM/c5jhMeHS4xB8VyeQvvPb2z1LYHo9l3BxbxAtu3eG2wSUzfO3btjrQpUEnO0VZoEwL1FZo5KXMSOiwxT+4T8nT94LWj4mW+zRUTNMraQMKeqnukYoTvtGz4YZOsW7fGREgQrJOT0dNGVLaCtkBIEmQfTeXlkqxNibESQEWx2/chQE7J4FJlilO6kFLn87A333or3PfsbExSxJ9HAqdUzhJwp0mPmI42Ddx6BtoHATU7Px/9xabGi1EUks9vfCNwtD7ykRHJurwMn9lyGfa/8EIlUTo/D21KQQI3m/D78p6EczVNPuUQlMN8WtnL3MTF4gaicohaKldR+56WPqBaWKrBI14Shqc794dbHZYex2tc82vpPX6DezfRorffhi99KSCezwF/Hfg94G3greFBHN+7dSjzQp27Ochd9oogTHK4y9kDIwokaM+0NTa1UJDkS9ptgtwK+jPds/K8U684QWTl9Ujh8pjf1YNuRksS8ciSQksSD1HtS5dJ4sI0OZT3JIWjPOfp6fgYMl5vsxnPc3kfgkYJkCIoHYwzDiVJkralxAnhcQlQMx21887nlraheHLJ/eX7ip8MkPjRJFpe0ZRHTNdCHOGjGB2nxE1LEhvaO3foZjPc9XX48KekWq1DsJMLT6pggRflg5FhrwJLivJHKmyBL+XikQtQiHlKhecRCwoZbnt6Oh5YWsPlJbbvUXfu0CmFGQ4EfXFBf3mJ26yJlksiBe6wQS1OUN6ye+Ob+Bc+CCi8t6gk2DUcqz1fzhWfNM8wI8VHhsIVnM7Pud4/wkQxs9kpuXf03rHvSxRQRjWZien7FpPmVO7API7ZHB9xJ3mByjYkOuaoFBkRb3PgA5wAYFBPZ6f9MS+P52s84OtccYP1Iao5qZgk6E45UTBWxD/MurgYW+pSrUnFOIXuYQw2U55DNAkPAqNPiexTebhYJ0igFOKtUiGxi6IRvZEB8XEciOabzdhOPDsb+RCiyhM+i9AHZK+fn4d/i4lkVUHZwJ3JiBzhZcHIs5JY8tJLIdl646M3PwIAACAASURBVA14/vlw2+XlmGwVxdg2kUA8n4+cLBHdSMtwsQjvRXy6xBNNKnL5HkXOLoestCUEQbSWEkfdlDSLnpKOynW0xlJNjEst7mmR9EdcL7/8Mr/6uV/lp37ur/DsT3+c3+B1fv13fpvtL70Gf/VZ+MvPh+/0K18JSZas54Y/3wb+JwK6ZfjurUMBBdbrm4f2YnGTCD9VEMq/5ZwSJEgSGmk/r1YBCZ760sn+k1a3CMUkQZgiOfK4fT9ORZjONZ0WTbEJzwdjgiMFw9ToVOxdJAESHqQYkpblaDouSaW0O6XwOz0NcUoAFJnMMBWzyfkvtkuC0gnKJ0rDqXpZkDV5rvX65hSKJBmLG3lOySmk/SocNPHofIL1IzIsNah5jq1raDzae7QCF2lc1ZJUDfFyTvfiizTX1yEIl+VI9JNZZDJOR3qrkqVPg6n0uSWjhvFwkAtQ/i8XugRmpcaESqTi3ocAL4fR6SlcXQWO2a1bgZjeNCjn4CyQ4tvtFj+fY5zH7a/Ri3PQiv0br+JfDMmWs2silTFLDPt6w5cyzyfN+5irDBVH5KRBjXh4hNEReb6gx9KWNcfO0lFiigWRSei6GuKEY9vhUKwPD7lY3mXfHYmTiAMNBs1DDryPJc1TvtYf++px/Bqv8m0mztLOBaHH1OdqqhScolc/LJJ1ejqiVeITJRxFGK93gdmFIyFwvAQYaTeKpcF6fZOTMTUflIAtyLCgUVLZCydKWnHCFZF23oMHNxMVQZ1FuCIEYAmqXRcSovPz0Sm+7EZOl/ejclkqWwmsEnTf//4QX0SJLEH34cORHCwtTwneJydBLCPJ034/inQ2m/B6V6sxlggyLwKDKZkZxpFgExl9rxS1tzR9yzHqOPpyUB06ajoy4qeE+D/ievnll/n5n/952jbMjv3P/vFn+D/4Kvf+zf8ROguJgc/+Iiy38M1vjqrV6XqOoDT8ve/xJKIYFPGKjHcT3qOcF1MyONz0xYIRuRVECsIeEnGHJDRiCSHJguy7KVIj+0ZQceEpC0lelMDC3cyyMZE5tuNrEPRJCPWSNIn1jJyv4msHIwomXnOSqEgRJS1Dac0lSdjLguZL8iSAiRSM8mc6LUISrqYJ71vQQBiTR8kbRMko8U0S0YuLEYGW8V/CFxPF5BOsH1Hr0OGMRq1O0HWF7VqUNqgoQRcGX5a4y2viPCc5PeVYFLjLy9GzA8Z2oHyhYlIq0OJ+P8J9zo1V8JTwKMFtSrabehaJ8khIutaOLYo7d8LvSVC9HqTBg4LI1zV6t8OdncHVFd1+j5/NiLTC7a7RJ+fg4PDaq/ChD+OTQKZdmDlzIvb1li/nhk/quxQ6RUcJBZ62WHG5f8idKGKWzHDOUZeX0EPVVhTJHGWDnrDTHpfG7Modi3xJEmXs+iM6WpDRc03FgowFyeA6/dTy4Y9r7Sj5Dd5iPf2hc4EnJGjQFMF6knV+Ph70EvwPhxEdFtKoILdSqUq1KXYMUysCQZVkr0n7QMb3SOtM9gmMFginp+FnoiqUyl8SLSlsTk7Gwkm8c5Qa1ZL7/UjcPRxGQuydO+Ggk+o50SOaJlL3OB45WBLY+z4galU1vg9p+0grY7kcn3fqtTObhftLq3O7DZ+5tByFXycCBwnYU68tiUeioLx16wZvpo0jqq6iiubsfUvpG3o1o6RjNXhpOdxTNPoHrM997nO0bRtEV23Lr3zuH/Ey90KSJSN2/sFX4FPtyLv7XutLBFRLLB6eV+OwdaXC9y/WBlP18DSxEjRHEgC5Xa4xuW1qeyCAgSj0BC2dFjzTRO7kZCRyCwF+SvCWfS88TUF8pCjL25vTHAStEtWxJFySnAmHUZR+bTsObJZpLvJ6YEzOBHUT4cxAUVDzOf7WrfAZbLfjmK1pHIKxVQk3uaWSB0zFBpI8yWNKCzdN0XGMT1OUUviiwMtrle/qT6WPlnX0mw06TfGzJSqOoe/ABhKsX66ga+l3W9TbJfl8hr97l+5wCG7yAssKfCoZuvAsJMs+Hsd2x34/kmKnEO206pXg71y44ARGlIt4vx9J9ffvhwNAPHDE3d65x5wNZy16vw/J1mZDX5b4PMcoYHOFOj1Dec/xta/DB36M2Edc7x7A8i4LH7Gpr/m9DH5C3yU3CdoZZsmcru+43j3ibHWXWbagdR2X1RW0UJqaRZrTViVxklE1JbMi48HmLZ67eInO9RxdRaQVMYYHHMgJMHGPJXrainjPVxi58zZf5/Imr/bqKqApst6LJEvUhTC2GGCUcAuXURKBKSF3GoykrSWBUJIyKW5gTB6kChau1lSNKHtm6jElpsCz2diylMSnKEZOlBBuxXZC9mGej23EqgoeZLdvh9e1PkKUjvtV+BmCIgkaJkbGZRlGc735Zgjmt26FZEtQbhkdIp+JeGjJ70grZbO5aT0jhHmJR9ICgptKMfk+pkjjcHgdMxXah0VP7Xv2rqY1lpL+MRnePTUu/YHrZ3/uZ4kHdFQnEd/8uQx+f7AE0h5iDS8Q0OXvt14nJFl++PvNCD65GonYMnxd9oigT3DzsIcxeZL/S6ImCcL035IsCDgg+3LKQ6rrEeESFZ0ADFPfKnkNgnTJeSr77/ISjtHIlxTFv6BM32v6w9QgXFzf5RqfcqukoJuiXPIZyWs8HvEDqqcH0Y5zbixo9vtx/JY815TYL96Asr8mCdTj9/+OsURu4IWp2QyVJERFgSoKfNPQlSXKPRl+/KNJtJSnz3N006CuH6GKgjjPwYPvO1Rbo5TC3boFZYmtalRdE2UZ7vwcv9sFN/k0Hcm3oggUWNH7cLFI0BaoVFoGcpBI5Svmb9IiEIJqmo5tiZOTkVNRlqNyQ8YbCAFSqnClcMaMaqftFns84pIEn8ZEm2vU6QUWz/Gb/5Rk8SIZKX7/EL+8Q4Hhur7myxn8uL5LFiUY71jkKzblNZv9I86Wt1nmK8q+ZN8c8MpTzyKSNKWtjngTU9meLI643L3N3dPnOPYVaRxxUAaN4j4HnmVFiyX85GkL8b1cPY5/wDd4m8msNGuDl9MTyoZvrPPzEXWZzcYkShAnCdZTCbZUapIYye8LJC+8Dq1HtEr4E7KXYAyqkpCIq7MgX1OPLmnDr1Zji0V8e1ar8OfevdC+m8/D+5LPTHhWctiI99ijR2G/K31z4LQgc3IwyPsRor8cdmdnIdHa78fXJQeMJHjH40h0F3sKaYFUVTikzs5GDpccLoLES6tWVIhihdH34bmffXb8LuKYsiio2pLWh5mHpe9oCJytfiDEW/xTHPoHrI/99Cf5pX/8d/nfPvdZ/vDn5nz+938f/qPPgnVgNPwnfx6yR/ClQ0imXuS7E91fZFQhRsBL0TjCScwyRTAlh/zUoHPKzYKRcymJOIzFlij0pn51UzNTOXumFABRBkrCJdYNUyRLkh45ywRpFjW/MdB2AdkzZiT3w3iWyj4SwELa8VKUiSeexBHxrZL4IfcTqo8gbJIoTYZTuyEZ00mCXy7R5+dwOGDFhNy5kRMniZf3ITGSeNY0+CjCzOeYOMYbQyefkSSvxyMcj0GEZwwuz1FFQbpYoOdzVNvyJCytH80eTR1u8KOxQFSW+LpG5TlxFOHTFOc9qm3RUUS3CG+UtiUB7GyGrWusoFmi3pHEa0o4lQtO0C2BOYWgKIFbvjSRpEq2v1qNElJBuiToirustaHHK9yt9Tr8TOasZdk4N21oK3ZJgk1iks0VenVKbx3dm98gvf0TEHn8/iEsbpN6zVVzzZdTz4/rZ0jjhM5bZvmCXbVlX26Yz0+5Nb9Ns2lp6pYyKjHZgjjNaaqKxvckecF2d2RWbSnSOfv+iIkNORE7GjZUnJA/tXx4j5fHs+XIy7zJjZTKOfj6159YNvx4zedjEiQtLCGuw02/G2mZCxIlAVZaWnJAyEEgHJCp6Z8kKeJpJw7TYnEgCchyOcraRTUl7TvhM4mHnVTZRRHI6dttUCRKIiTBfbEYW3K73Yhc7XYwP4c0CveVyltUWdLqt3bkh8TxKAKQn+33o9pJDinhbwlSJQal05FB8nnOZjeJ+3LICbooh4xw8+RzE4+uiYN17SyVbTiajIMrCcN4gkt8+tS49Aeumo4dDRc//RLLn/4ZPv/y/wn/4WehnyQ533wA996+SXb/97mZbH2bkIT9NaACPhzDR4fpIrdujYit8BwF+RFrB6XQShERbLiUUijv8c6Fv+MEvMP2Pb7v8Vrjhha81xqvFEYpXNOgtA6WQkmC0horSZkQ2ts2FClZNo69EoRJBB7Stpek6+RkPNN8GV6l+Eyu1+N4HbFKEmBCEkFJIqWAkVjk/WgBIypkeW5pr8prl0JMrv8hfilrcSJU0RpXFJjBksXXNU4c6GWPtS1+Knwbvgd7eYmNIsxqRWoCvaY3BlcU2KkAZ+By+aqivr5GD0jXk6wfTaIVgy9LrLUoY3BxTG8tarfDzmYYY4i0DpknYLzHDmqN3nuM95gkofMeV9c46S1PfTEE2RJp98nJ2Ke2NgTf7XacayjmbHKoiCJxvR6RLakapv1wMTus67Dhbt8O71EqWlFgSJAXmLRtcUrRKEj2G9TJin5ds3/1q/ChT+ABc7xmNTshaR1X7Zo/SDQf13fIo4zeO/J0RtVW6EqT5UvuLO/y5vZNuuOBMjIs4jmm71A4yuZIvih4sL3HC7c/jMNzsBWRMcREPOJIQUKCeWr58B4ui+O3eYNXeTj+0PsQCIU4+qRLApsxgXMkQUOUd1PJ+FQUIomTkFthbB1K4JQETJIqqTwFGZJ9NJ+P3Cutx6HMgm5NJeXS5pCC5nAYSfWyN4Wg+8IL4xgdSWisDXtNnK5hRAbbdUj8kiTcR57rcBgRJpkZKUXQ+fmIZgkCIAmTtPX6PiSwm81oPSFomiCHkqSJCEEeQ7hrMLZV5YCR700UlvKcAzG3MZaqq6ijJTtfsfcNZ4Of1pJsaCI+NS79bqvHsqbiiiO/zbf5X/kKfO71m+pdpSB7G77Jzbbg64yJ1lRxGAH/QQ4/eRHGP0nSLN+zFAOT8TeJ1sRKoaxFKYPSGq0MKopwcQpRQhSHo9hZj+vCKCbXNbi6wfctnW1DwjUgZMo51NC5MUqhh5/bOMZJsl7X4bouinEcjvALpZAQDpeYmi4W0NeQ7MfiQbjJsk+FizUdoC5CDrE1EQ7W1H5CCip5bimQJBETlE4QwKaB3S6YghcFkTH4rkNVFfp4xA9u9kld46sKD/ihdWplTJega9LtUgr76BE2jjGzGVGWYbRGdx3Kucefnxdj4yHJ05vNE12LP5pES7wG6xqfJHjvUcbglaI/HOjjGDubEQ8VAM6h4hhnTIAShwPAKIVKElRZBnRrsRjbFKIsiOOROFsUI2dCXJ4fPgwXgHBGhCsBY0vg+joET+m7y/gdaRkOFwRtG5Ct27fDZhOVomxsGQskh0/f44HOOeJyC6tzGvb4V78KH/ooHoUv4TRbYXvHw3aNTuCj5g6ZT/B4rLNUbY1WhjSfcVacc7l/SLPfoFcxeZbhXI/tHb3r8VnEw81bvP/8Requ5qAjZipCo3jAgWdZ0mGfWj68R6vH8St8gwdTi2lBs4QE/6RLEiEZFyUJw2wWiOJTgq2IPCTgyesRArsETLipjBN4P8vG9plwPUStIwKV5XJEqGRKg/C3JvD+DTPPwyEUQ8LfEK7HahVc3y8vw+NkWdhXVRV+fnIytmXWa6gt7CZI234/onT7/Wg1Ichb34fHOT8fDxQYEWiJKW07yuHlPU8TJUlM63pUm4kPl7ynqXWHyPzlcSRuSYtluE+VZdT1kSbvKH3H1lf0ynKcDJh+alz6ncvh2NMOI6/u83f5Epcvfxu+tQ1mnP1wPf9bc3h2HxIsaQu+077hdW4mYQ+ygLgKBUW4j6LsNQYTx6RaE5uYSMfhb6XwvUVbULaH1tHVR9zxGAAdE6GzFB9l6PkCqz2273C2J7U9/fFIX+2xZY3VQBzjAaU1vbUYHxT8sQoTS9xigR2oNV6Q4tks2A8R7u9EvSvnojGQF3Cej8o/6QJNkW1By8X6YFrMSfEje30+D/tJCOiCskmBuF6PPxfxjvjwLRaPi5B+iD9xmmKHjlfUdbgoQp2c4PseM/CuzDAX1bctvq7pBVF/LJhJsE2DNQaT54G6FMeoNMU3Da5p8FoHBGz4nJ9k/Yja+24MMkOF6iUDHhKXvq7p05RkuQwQqfdoa0NbccgyVRRhjMEsFrjhovDijzGF4s/OxoxciPPi9i4KhLoePXykooSR3Lheh9cq6JYcHjJXTarWhw/DhTmtkoXXJeRESeaGA8c5F9C56kj87Irm0rN79RX40CdQGmhhmczwfcfb3RpixZ+L7pI4S5sktHVN1dXkWrNKFzS24/p4RXVcEy8u0GmGcY6qLlnNT9nut8wOlyyLU6qu4io2pCrYPlxTcU7x1PLhPVgOx4YDv863bm5Ua+EP//C9eRJBTKVVCCOiI2rDqdRZkCRBYKaolXAphAciEL5Ux+KDJcOhBXWS/SQJl6DAFxdhT0mrQvgdQlQVhZTMWRRLhdPTMchfXob3dnERnrdtw+3HYyCwn5+H5z87C+/rjfVotCjkfeGYiVpxPh9bKNfX4bN5//tDgSTqpykaPp+H9yRcUEGn5HASpExaMcfj+LkIr0xakPK+pe0oVhjWhkRVCMJDUtzOZtRtTU3P0bccXUWle2osPRZHhH06t/TG8niOtBxo+UOu+Bxf4wsvfwV+/peCwjDS8IsfgQ/1YF4LdxL7htf5To7Wi4ST0gKRgp/7QLhWZPauFOBApDWp9xRWk3pD5CDuFd47Em1QJkFFMSaNMPMItMLh6Zuarirpqiqo7m1FkmhUkuKSGS7xdNkc587pm5a23OOqit61uN4GeyRrMVpjdThDVdeRKEW/WOCtJapr3ABusFigkwQN+CjCxTGmqnBNg3MpKorQJydYEYzIOKq6Ho1FRf0nMUhc3KXwgbEIEeHYfj+el+KlJ2anYgMjVhND4aOyDH/nDqptUbsdfV3jtSZJw5xf7T1+UCz6oWWr+h6tw6QUfXJCXNd4a+mbBjtMmPEDdcA2DfZwQCcJSRreu/DbTNtiAT20a9/t+hEhWu/wvhDDUamapS1XVbR1DXlOvFig8xzT92ilgrd239P1PcoYdFFgh2Cn2hY/n4+cj7oeg6tUrHKYSCJ1fR34IHJBTMmIU/PSq6sx8xZl0slJuL+QFdfrcNGJL4i0Ew6HsZ0gh87QSnQDH6QrD8RnS5qrNbvXvob/wEfx2uBRLKIC7zrud2tUDB+Nb5N3Fps4+q6h7RpiBatsSU/P5nDJMTmwyla4NIHecii3FMWSB4dHFOkcrQ2lrbmOIm5j2FAzIyEjosOSPKXavutl8XyWr/PWdOSOc0GxOlUbvtslZOyzs1HxJof7dPSM7Klp21CSELl9SsyVfSiVJ4ycC+FX1HW45oW/Ia0/eS5pKZ6cjK0B4YDJ80z97FarsD+ursJjyz6U5E4Kpvv3w/MKJ0xI9ZIg5hlQjgjUdNyJKBqF2yl+e5JsieJQPr8pp0pa/+LvJciTJE+S5EobUFosUsBNOW8wouKCdonBo8QqObCco3EtZd9w1AlH39IQSPE1PelTP63vWBUdFT33WPMF3uJ/5tXQMmwHOwdcmE5ivnnzjs/x3UnwH8nhP87gQQH/0sfgX/jYd7idK2tZAEuVMyMjVhGJVhhlSE2Cdiq0+5wn6g2qD6Ijr8EbDUmBzs5xp1Dbhro5UB0PdM0RXx1RkSGJEmyUQJbSZTnWerqmpKkOWNtivYOuDyAE4CMTEJmqRuFxWYbyHmUt0WYDUURfFERJgksSdJbRDu3vqKrwUUSS5zCf03cdbrcb949MZRDyvRizCr1GirupcCVNwx47ORnVg1L0CUAi1hECkqQp3rlQcA0j9/TgFOC7LvDYlEINHS4XxyHx8p62bUO+EEWYxYIojkOyWRR4pbG7Hf6wpxvajK6qqGczVBQR1zWRMlgVWrNPun40p2ijiZdL+qoKGaj4dUxlpnCDf9ENpNl4IKPHcYzve9q2xVsbIFJARxFOoHj5gqdtDQm+Yj4oPeWLi3D75eUY6IVLIUFUVIzCIREifVWF2zabUeFUliFxE5RMJO7CMRFIVKqFKAJV0g8thuh0Rb3e4l9/BV78CBQKr2CmQ8vw7W6NTjQvRaek3nKwPZ3v8a3DJAWLdEHXt+w3VxzOI4o4w+eeZr8lcR06i7m3e5PnTz9IZzv2rqbQMQbFI0rexxwA87Rafterx/H3+INpmhUO2y99abzG3/UaFIOCGsk1LZwjaWPBqGzrupFPJAnWFNGSlpYkQev1qGoS4YgkIhJsBfUSFZ5YQYjkWpAg4S1J+0ESMtkDWTaSigW5ktE2U8L++94XklRp54ua+OJiSLQ8+G60YTk7Gzla8j7ltd66FR5LArnMdpOKXMi1ggRKIiT7ebUK95NkUaT2ojQUwrskdoIKyu8KYVdQLjFLFT7p8D3URtN2R+osZ+9KDjT0zDjSPeZpPV1htUMCes2Rr/CIX+bzwVLlZ14IxqStDajU/HIkuL/Id0+wIFyXzz4L//yHAydravUBoDVz4IKMgpzMxRRRQqZijAW8QjUerTTaRGgTAx7lg7OEQqOtwvYOpzw+VizMAlcsKPOWtm+p24q+2dPWNV3T4hNDFMegFTY1dPmMtqzpuyNNbDHeotqOtqlQXY1TChOnqKZDK4/VGjuQweNDiY4abByhkoQkiuiWZ3DeY8oSP1y/6WwGFxe0p6fY/X5U5MrfEg8EjZL4JvQE4UVKYnZ2NnIepdCYOrJPE7UBYfKAf/ttzODF54uCqO+DUK7v8ccj2gNZMGmOs+xx29Du95jZDH16Sjyf48uSaLnArZaYJrz27hjUjN4YbJ4HrptzKKVR5k+jj5YJFWY0n+PqOmwEgd4F5peAL+S4waStOx7h9BSTZSHz1BrbD6HGDWrGKW9CpKRSfYothARwaRHKz597LrQwxCdLDpKht81iMfpyNU0IzCKpF9Sr60ZH3EePxuAtFbJSo6JRqVFSXhSg9iEBTR3mZEG93cHr/xT/4kuoucLj8drjUEMbET5oVmSxo+6qoGZpa0wSM8+XtH3LYfuI5OzZAFnnBYfjhtP5bQ79gevDQy4Wd6j70ELMVERFwxrDOQXt0xbiu1o9lvtc8Xu8Of5Q2nGvv/5kD641YAK3KElC8Do5CYmDENGFsC2oqbQGBVkR0rcIOmD8/zuTsK4LxcXV1SjXFnK7JCISKKtq9K0SkUpZjvtAqlYphITnsl6HJOP27UCAf/AgPJ/sN+EyKRXe5/V1eN8yz/TRo8BHW8RB1uVcuN25kISJGaogXA8fhs/vzp3wPA+G+YjCtRHir5BgBSGUgk3ihxiliu+XHCSSUAmKPiXIt+1ofyGxTVqJ8lgTU9hyNuPYVDS552gbdr6hU44D7TCK56lxKYQ9V9JR0/MKl/zfvMLXGArqf+4W/Mq/Dp/9Wkiy7t37/ipDCN/Rj/3YOAtTWugAxhAZwwUxtzihUDEzlZKqmLgFhcVEMUYbjI5wSqPw+M7hvUOrGK0Vzjm0NhQmJdExXd/QNR0+MuRxDnFBFc2psgXNrKZrW/r6SFWV9NoF+owypPmcLkvJupamquiLBD2b47sGW5W4tg3co0hDnKAjh04yVKwCyNd0RJ2lTyLiLsJ4g1ossNbiyhJXVeg4JhkMiLvFAltV+MMhFDripj6dCyrXM9z0m5QuU5KEfSlJ2lTt/E5HdilKzs+xQxFoooguyzBZRmQtqu8xFmxVoQ/38Ys5fjEnmc3ojke6wwG12dDPZsS3bxPNF+i6CkKCLEMtF/hjTVfuA1rWNOg8RxmDesLC+EeTaOng/q60RsUxOkmCfFNM1gRil8xWEiThndy/jy0KWC5RWRZgw7bFGhMyZZGOS/AT0zfha4hnj6BVknBJ2+XWrRG5EiPT7XZ0AI7jkfcl5DoxUZSDQ/gccTxK20WpAWNlLWMK1mvQg0x+s8F2HUopWMyot3v8699AffCjMDvFu45ceUChhjbiC35J6y1d36JUjOoakjhitTij2zxgu3vI+ckz+CTFdi37cs1ids6D/TVFNic1GVVfcx3HxBh2NGTEzJ+6xr+r1eP4O3yZe+8kwb/6aviun2QtFhAvxjbgs8+OPELZRwLH5/mImghPcPoHbsL3gt4K4gQ355uJ5YEQ+eV6FyNS4SgNweuxxYL3I7o1dZiWZGy1CsnOt74V9sBqNZLexe9LvHqKYhz6Lg7VdR2SJ3U2igLefHPkSJ6chOcRpKrrwvPdvj1aR0iidft2+P3dbmz/SQwxJiR5Z2djyzVJRtd7OUgErRNOpqBeIjaQAk5aKvJ5bLcjkg6Pi7m6PdJg2amOg6uoTUdFN+Fp/dk2LnU4Kno6HK8NBc4v8+qIMjoHHynAz+E3v/ydBPfXuZlonZ2FWZjPPTcmxVKUpykr4C4rbrNgoTMKlTInIlUJcZyglUKrgBo5a3EuTKjUcYKKDK3v6GxL76BxHb3tcaqhiAtm2Qzbd7RVjTYxp0mBMwu2pqGMKpqkYOmhaQ7UdcmxOuLSGIUhjmekcUrd1rRthTUp+rQIiUN9pKsqVHPAmQgft5j5DB0nmEhhvSdqHLZt0E2MajtUHPavbdtAyRl4xlma4uOYZj7HnpwEjtTVVbh+BYGWLlUch9viOOwrQXcFCc/z8dyWdqL4/olARdr3UpycnIQZwwM9qEvTIIzznrjIcGWFOpS47RE1LzCLgvj27cDH2m6pX30VUxREt24Rz+bQd8RJUByaRYGtavryGCymug5fzJ/o+vwRtQ4N6Wr12AtLe4+OInoZB7Dfj0NbRT0k0OMUmm+aYJcvc5+E55Cmgdx6PIbgKV494oYtFadsHiGzTuWpIlWXCydJblazzt0k7QrRXpQby+UoIZcEok+bGAAAIABJREFUSxI3OQyFRyYX0VtXcGtoBV1d0bdtqFhWC5rNju1rX0d96BMwW+B9OChVBHRrdKS463OOzmJ9aPepzmIizdnqFpebt1lH15wUJ0RFQbNZk3YlSVbw5uE+H1y9SE/PzlbkJiJCs6EmRpMSPXWN/yGWG8wk/z6v3HSCtxa++MUne/D5fEh8opBQnJ6Gg//+/ZFXJXwpMeObtuukPS8BUJIHGAngoh56p1EijEFUihPhc4mpofhHCcIFYzJ069bYapcEUAbhzmYhYTw/DwmStO83m9CeOz8PCaa4wUv74epqRLbqGvYbWC1GQ8ZvfSv8jhgLSxyQxFOMTqecrzwfK3BBq6e8t8vLMRkSg8bp31UVfk8qe/HSktghsnNRaE29iER9KPy0gQ9W+5aqqyh1zNpX1HR0BFTrKU8LWiwtlrfZ8DUe8t/zcrhBREt1HfbIb/1W+PmLfG+V4cVFSLLEKkW6K4DJMu5Ec14y5zyvz7hQCxKriDAYDGqYT9nbHq96lI6II4OKU1DQ256+a0iUZp4siJKU3nbU3ZHa99TdHmUMeTpnWZxi+56mKtFaczvJUVHOQffsXUWjM9q8ZdHXlOWesq3oIuh1RB7PiKOUrq1p+2AN0a/OUVmNa6phznBLX9boPMXO5sRFAcbjvCVuHUQa52xA52KDy3K8tfjjMYyrmS8onMUCfZbRnZyEjtLDh+GsE3BElvehuBH1bp6PnCzZ0+IwL0WYUB2Eby3n9+Ao4Gcz+uExTF3TZBk2VkSzHHN6iq4CeV8fSnwxw8wDz6trGrrtFvvGG/R5Tnx2jslzTBIKTl3MMfMZ9njEVhWuejKFuPn0pz/9RA/wbtZ//j/8l5+e/fVPBSOwNMFEEbbr0ICJopA4KTX2dKVqFCn3FP2acBkeS8infJXbt0f3WFmi/psSg6e8MOF2CTdFeFXCJxOfLeGNCFI2sZ54zIeRdtF0XII8jwRfOdAqBe12vBCH3/XeQ5Zi25p+fYVZrNBxjFMKXI8zhta1GBMxI6O1DdpEeNcToei0wkQph+MlOkmJTYyPDOVhQ5HPsS5UV8vsBGtbeq0oVILCo9FkRIP6+U++hXh5ecnFxcWf6HM+6eqw/Cbf4L/jizTyQ7FW+If/8N2N2pEkSuaTzS5gHoegJhwnkZlPZdjCQxQkdjqeQvaJwPTSUhQfINlngmLJdSycwqkbvJiUrlajCzuMyYS0M6cjeqSSlQRnsxkTKGmhSaUr7s9FMaI/8plIgjifw9HBbELKl2JGUCVxnxdivnCoomgUrEx5kyKLlzls8jkdj+NAX/nMJKGUwbYQfl+I9IKYS2tE6A1w8/uS4lJi0myGVYqCmCzNWPiEW9GSBRk5MUtSDOr7Clf+NO6jP+pq6ano2dHwFR7wd/g8v8thRA2dC8n7F784DoxeAR8AToGfY0SzLi6gvQP/pIXlAj76zOMEeb5a8Yn8Wf5S8iE+mbzI+6JzFmbGLC4ooozUJORxTpHOmacLinhOojTaelzb4PqOxMTk2YzYJPS2p6qPaK2Z5UvmyZKZjzAWmuqI6xvSOGGWrtBK0zY1vm+ZmYwTMyfTERGGQqXk2ZI8yzG9g77DKI3WGq0NUZTgvUK1HcZo1GyBiQONwCmFq2rU8YDtOuIso6815ixDWYexHk2IF9p5DAYdxfi2RdUlRMGPSitF5BwqTdGrVfCzMmbkcUrbfzr+RmxmxF9LWuaCoEuRKICL3F8KFRi9Kgd7KF9VuLqm77owQzlNMGcX6KJAVTW6alEW4jglKnJ0kmDrCrfeYKtQUCkPoIiSHD2fYYoCFUX0//XvvP3pT3/6M+/mGn1PEC2l1F8D/htCbfC3vff/xfe9g3ZEZYeNQUUxLknIigI7yE+NtfiiwAqJdb0eCejn54FXUZbhtqnTrPTQBXqUAHt2NlbKEuwlKErQk+xakiWReIqlQ1mOUKgEbZmdJK0JycwliEqyBWMSCGMrVIi/MjQ3TiDzofK6cyf8/PISb0zwS1kuaNY71q9+Ff/hj0O2BK3w3QEVFXzbbVDRiqVPafqGNM5wfU/UO1ycsMzP2Gwecnb2fqIoxuYFm+Oa09kZ23pP0Ww5iRdDC7EkYs6ehozocQsx+zPdoPjBy+PpcXyGL7Kd3mAt/O7vju2HH3YJF3C5DP/e1fBoM7bmBJGVhE4I74JOSbIl6K0kZHDzkJ8mXcaMRYbcVxIGGRQr3nMSAO/fH5Ml2Q9RFPaQtPSlIt1sQkJ1djbOCNxuw+u9cyfs+4cPR7sKQZJExSh+ViJE2e/BzG6O00rTgJS98cY4ZkQsIi4uRr87Ic/fuRNELOt1uF3ENFJMCbohRaAgHhLwxetLyPKSjEp8EbqCxAAp6iThEk8xSVSHmObmc6ruQMs5W1ex9Q2tshwHnlYf2Jt/5riUFkeLpcHyGlf8Jq/yD7k/FgAQUJR798L3Ol3vVBnevRuSrP/0K9A5+MzX4R/9O/CpZ7gVx/wF/Tw/ybOcMCNFkxARo4kGFzONCmo31+FcT68szqTYzOO8p+4qymZPdziijKZIcvI8p3MN+8MarSPybM5pvmTRVhzrPe1mi0pqitkJ+ayg7o401YHIJCyTnHmUcfRVIM1rw8lqyaE/si/X7NojnYroDURK08cxTV+jyxYXKdTylLjo6KojtiyxVUVz/z62yeEwx+U5LouIGxuUfIC3lthqEpVjsfT7I9Q1arEgXixQTYPre9TJCSrPaRcLvMwolDNTQAnpNAmBfqpalK6QeFRKnBO1sBRXIvIRq4goCp5hfU/fB++xKFoTz+ZEdy+Img6OJaptUFFMFBckt+Z07RG739Nvdri0CciWNigMpshhcfJE1+kTJ1pKKQP8t8AvAG8CX1BK/Yr3/g++550sxE7hjy0qsejI4GODKYogN21b2gmSZfM8fNhlORJ/xadH2nZyOEzHYYjtv3xRzz8f/v3w4UgCFmNTSaJWq7FFKdBnHI9jP4QnIhm5VO/ilyPVuyAJ4hQsiJa0F0Uun6Yh2To7A5KR+Hv/fkDjxD9IhU3cL2ew2bF57RXUSx/HpUHS7/oKG3uUUzxn5mQupu9bIpMQW0/XN2RpQWFrNvuH3Fo9Q5rPKPsNVVtSxDmPqivyKCUjYtuXZFFEhGJHS4QmJ37qGv8DVo9jy55f51vjDwVh+p3feXcPKjwoQbSqCqyGZT46tcu1PPAXHk+5l2tSUCy59iThExRLBkXL6xUl8DQxlPYZjNWntO2lHSl8qUePbipzxchTqRE1OjkZuVKnpyOSJf5WUumu1+PtgkiId5H4c83nQzuwBLLw+NJ2uHMnfH6vvTZWyWLLIiiPtPlnw1iV+/dHLuZuNyZHklSlafid558f37NY1AgvUxI+UWPJfhdEXOKMxATx1drvx8eT4m+5pKlLat9zoGPtD7TqjJqehp5k8NP6s9Te9/jHLcP77HiFe/wtvjQinhC+u+treHloJX4vpeGtW/Dxj8P/VYYky/qgUPx/X+f5v/wSf1W/xCe4y4qUGQkRioSYZJgOCwRLBeXpTII34RVaZ+lcR+07iiTmJF3Q2JZDc6BsSiyeNM0pinOqvqGsdpRAni84Wd6hbysO1Z7d9UOW6ZyTYombLTi2R6rqQBQlnCQFNp5Ruoqmb8jNktVqyb7dcyg3HOyRGqgxxHFMFzma+oAqW3waoU5OcVlOX+7pD0fscUe39+iuRceGfh5MftPOhvFAvQMajFIYFeMbh+22UBSoxQyfOExdY7OMuCjQsxn1MOv38Vl8chKu+c3mpuO8oFdS9AkCLQ7z0q6X/SNFnsSixQI1n6PKMiR9XUfvHHa7wayvMbMFqsjJnIauxXtFrA1KZ/iTlK5tcE2Ftw4bZxgT4asKtbtRNv/Q671AtD4F/KH3/jUApdT/AvxrwPdOtDKPNZokn+PKCtt19E3IYnVi0HGMPj+nb1tcWYbRA0URpKbC6djtQvKzWIwV7VRmLjwVgfwFPcrzQHAUGwcZJzIdqSNznaRKlvlVghwIQdfa8SLxfuRgidIKRj6ItCOmgzcliIqtRL+E8/n4eA8fhgBwcTESdbWmXy1gvWH92tc5/dDH8EmGU6C6EhWBU5b3RwvyTgepr4mI+56ya5kXZzT7B2zLa5bZimQ2Z7+9Jp4lKAWPyivuzu6Ca1m7I7mOiWlI0I9tHp66xn/v1eP4Jb7APd6RoAhK8sMuSRZkysFjK4GhtS5+PkIol+REkonNZkSuBJUSxFbI73KNTtEsIdILqiWJlRxiAumLJYEQ32FsCYhcOxsSn+12HIclydhqFZIoQZQEuZOiRu6/2YTbZNiz7Fd5fTK+ZnMYEyKxfei6MaH61rdGQYqIbVar8H9xwJY9/ODB2NoQJFwUwtIqfPgw8EGlEBMjWGmPTv32BEUUdFHoBxJ/JGaU5RjHJvSIo4KqK6mimLWrOeiWE3KOdMxI/8zxtBp6WizXVHyTDX+LL3CEm+jsw4fw+c+HO0xH6UyVhrdvw0/8BPzkT4J/G/6rfxKSrMTwws9+gl8wH+PPcYe7zCkIhWhGREo0QRDDZz9VgfY4Ou1pdUeDo3cdne1IlWZWFHS+Z9Ns2NcHWlWTZTNm+TmNb9lVeyoOzGcrzla3aZuKQ7On2T5kkS45y+e0eUHVlbTVgSTJWEYFJAWlrTjYiixesTpZsqs3HNoDR1tytBW1AzNbYr2jLXf0+4Y+TUlPbxEXCw77R9i6ou9b9GxOsl5DktIWwZVdRR76DnqH6noSo8Fq2n2Jb8EvM0wxx3YNum2xy+Xj4czNfI7bbELsiuNxfwpVQGKFcLikMyQxS9AwrUde5uEwnuWHA36xQJ2dhdbp8Rg4ZW1LD/TVkag8UGUZKk2JbYOtWnSW4R0kJqHPFL5usJsryOfEyxUsV090rb4Xidb7CZewrDeBn3rnLyml/gbwNwD4qQXtG4+G+UcrtMlQbU1Ph+/rYLUfRegoQcXLMEKmKvF9EcxOseBqeFjBgwayHJJFGKtQ76EvQTeQFZDPwfXg9qBiiIY2SHIGtoLjDtoe9FCJqgSuyzCmoTgPj3N5HR4zm0GSQ6ehqaBT4C2sd5AuQGdwtYc4hbQIv0MCeChdOATSHIwGCiiP4X2UQXJLt4U3HMwWoOfh9vUlrM7ALGF7BOXAQ++X9G9d022/yur9HyKOc2qv2PuSQzznwJ4zl5B3kEczvO85thUuNjg064f32GcVSZxQ1y2bq29ylp1w3XdszJaTKJA8L9WMM58z8zEnLqXwMRGK1Js/kTbF5eUlr7zyyh/787wXy+JoleNvz36LG8BC5+BXf+PdPWiUg82hzwiniAPVgI7A55DPwnWuDewUXA0TDBzhWlFR8A1ChSpdq3Cbd+HfkQl/dBb8Z4oFRGk4jI4l2HZQZ6VADM6Di8Oe8T3Ec0BDaaE5gjJhTygV/q16UG3Ye5iwB6IOTs4gncObj0ANfKd9D/oQXoM10LfQ9eH1dsN7S2fhM9mVUAwGrW7gi11tw2vfuXBfLFwD57fDv6PbsNSwfwOqGqojzE+ha6EeHqMGqhaiGfgGXr8PZ+8bEl4DdQfloIxKzuD6begewZ33QZdDY6FPw/uuqmA10bsQa1QGXRniQ2ugM9AOqKGJCbFi4J882IMZksOqAd1hjWa7vSKdGd7U9/iGUlR2xd495P39nMLH5P67h/Q/Tfvoj7JabLC4UC1vRDv+9/grfDnag7PQDS30Rw/hy98YZ4q+zjj+rR/+//Fz+OAn4ZmfhEsDH3wBfvnfg994jef+0of4mZf+Ah9+PWPhO7TfYV1E6zWRi9AYHA6vQprlgFb19MrTqiCIcXicCrGhwdJpT+NbOtfT+Q50mDV77Hdct5f4SJPGM0wUUXUl1w8uUSaiSJZo5Wmbist+T+IhjzKSZEZJz9pfo7wmiTOcMSjv6VxJ43tiY8h9HsCMLgHbcOxrvAaVLAJydb2h8x6VZ6QXd3BVSXd9CVfXuGyOSQHV0McJOooxOsE7h7aOzvaY3gYndr+jMzuYL9B5hlY59C3OOXqzxJBjihWd28N2Ddc7iDKIL8J5ua+C/ZPpIGknA7ozsH3Yqy4KMeZqB1EC+S2oDnA97Mu3a1y8wS2WMD9HxXOUa1D1ARpD7x39tgfV0UQZJo6I+u0w9zBGWY2yMX1jaR5cU/lL1GzxRNfre5FofbfT9jtKK+/9Z4DPAKifOfHZs2dB9lqHcRnqzow0SsOHQBcGa7oKpTtiE+EuZvQ4bNPQliXUDlQ6VuHaDuqo5QgpsgUqmBcjadYPv+sbOC1An42SajX4CEUDWsUOFik8czdkzZsNqCqgTno59pk94IaKOh5aJXYLd5fD42o4mw+KqeOIuC1SaBgqcA8uB70Nr215Cucz2Flww0iTs9k4IBMFZ6e4zY6qeYvomQ9CXKCsxilHb1J6UjKbkPcpi2RG27Xs+yPEEUs3Z1/vWC3mnLHgeNySqZRFfIGylmV+ykpnJCrmPDrhlIwVOWcDATfG/Im4xr/yyit89KMf/WN/nvdiNfT8P3x12jQcUM8K3nz1h3/AooA8gXkeKkhpQc9m4Ao4GZCu6ji2+BIDmR6RMEFPIOwzpYKtitZhPqggus0GKgsVYytxPofbp2M7W5As8cGq6/F1ZRnE58MH0dxEi40BPwRNHUN5CEXEyQl87Jmw/w4bWM7A+LAH5nMgH6vZroODGoZLF7BKoN6OPltdFxKwhx1cDMRap0KB1bSBf2OAO7dhZQNadTwCa7h7DiWwG1C7REFiYbYMz+euweShoHt2MfiJWShiYBGKO3OE983hYRlO3KMBryFqYTa0AFMHNg6FX5HCpgrIpOoH98pujJztBmbDeJ7IwrIOs9v6DnOe4X1Mlq+4wx3uMOclbpMTsyD9rgXQn6Z99INWSFp6Kjq+xZY9JX+PqwHF6sNnuNlBdx/ufWW8Y/6OBzqbw1/5i/DJT06QXgPPvI9P/Ysf51+NP8lPqed5hjnnzAYECzKix/SJwIwLfwuiaPE3XmM1mKj2WOzA4azpKX1DZVt6F9DOxnc8qi/ZVjtMHHOruIXyBDSqPRLHKbfz2/R9Q9+1KDyZT7gwMSq5S+V7WtcQ6wgTpSijaV3HoT9Sa0+j79C4mmO9o+wrtv2RXb2ji3Pc/Ixuu6M5bKg2DflzZyR+idtc4fZ7etMRzZfo2OLTAFgYnRCRh3E3zqFaR+IdM2+xvsbHYOdzXD6n811QQKJBL4htgauW9JsN/WYDtoRlDHo1kt11D7mc6wM6HBcTLvXwhdY7OJmFL1hUyQmg1lDvUOmK6M4SFZ/gBwd40zQ4a7F9g9YdfRShfYWOHGZ1ikkSst7TNkfsdku/vqZ+gmv2vTgp3+Rmt/tZ4N73vYeHtjqEoJ9E6NbSX25wsYY0I8ly+mwR+t0uBD/Te2IFUZyiC2gGhcFjU0AhqDsXgnSWjXwPIdStViO3Y2rUOFUmTYfriixYlBDPPDP2/EX9JTJ6aWsKZ6XrhkMhHz14ZB7d9XV47MWQJRszGL35kEyVZXjM27fHOXBC8pf3Oiid7Lygvn4UvMmefwHiWcj8XYXXDqc9Z9oRWUMWp6Q+4dgdidKCLE3ZHTesilPifMHxsCMyMZmKuW63RJkBp7h2BzJtSDAcMWjC+IinrvHj8kNw/Zv8Nu30BucCCf6HXcINlCHGMF5bsxnsCcFIYHRxbpfZfLMZcVGQZxmxiTEqtDkipdAYlFd41+NtT9vW2K6lbxraw46+PNDtdwEJePRobDPKYHXhZIlZqFg2SOtMbhO7FWk7Hg7hNil6hpljjz2uxCLFmFH8Iko/ed+LRWjDCqdyvQ73Fb8rUQDKvhE+5b17o5Lv1q1RnHJ9PcYGmQ0p3DSxedjtwnchI4WmPzs5gbffDnytF18cW6aitpQ2onAyhUMqgh1p2U5fM4yfzWIRfmd4jVVfU/ua2sc8cjsqfUaNpaIjIfpnfsC08LJ6HI8oeZMtf5P/LyizpzMoNxv4tV+7eeeKgUg1/F3chR//8THWD3//lD3l34g/yS+oj3LOjBkJyZBYxZjvy1EN1i4hFiQY5qRYHBUde1pqusGX0DBTCVXUsnc1lW3IveGF4v2U2Tn3jw/Zbx+R5UuW+YoiKdhXO9b7R8yyBUla0HU1jQa8I24acq1JTBbGjXcNyhryKCaLTyltxbFvaKKcdJZTtHvyJmNmCtbthvJyQ7RckKyWuOM9zD7wEvXFXZrZEn99idtc0hQzEhTWxbjc4L1HZzFR0+HjADRFVpEohTm2tIeHuNWSeLGgzxLitqZxLU4p1HyOns3Cbes13eEwttbFPUAmOojwTGKBTHiRlr7sIZm/KMPkAXd5SbvZYIaWYiw2UnVNNMxV1m1LF8d0tiO5921smqHOb5Esl2TLU+z7XqDm77/r6/a9SLS+AHxYKfUB4C3gF4F/+/veo4owqxW+6bD0kKTovsfVR9R2R7ff49OEbLEMXhlJBDi8D6ML0nxOlOW06ZF2vR7nImk9IlxJMqoThb/14EH4+Wo1DsOEMUDLoSbqLbF6kKAuTtDipXN5OSohtB4TIiHlS5AXPx3pO19cjHMTT0/D7y0WcDyMXJOuC8FbRgNV1YhMTGfGRRF2llM9uhfOmOeewyeLMPMKQIM3Oa7bcludkic5bdPRtBV5usC6Lcdmxyxb4LKUfXskTk/xtmXXHYjiJbqv2cQpRgWFTRwcY1Cop67xw+qwvMU1n5/WGCKEEO+sP8rIDxiTLOH5iKu7/KxpoPUwS4KaVkQTyyXzOCZDkw6oY0ZCPHDqgjf1TQjaAeQM1bij9z1119B0JW1ZUu0uaXY7+u3msSjjMRlV5ieKcmjqdSd8MCHE13W4TQKi3L9tR+K7qPUkYMpzyXvu+7AXXnopJDeSlFxejiM9tkewbiyOpBiD0RlePLrEMHS9fkw4f8ynFH+fLButVoS3uVqNcSHLxp9vNiNXS75DQQFlD8OoZBRO23TMkfj4WTvyUEXl2DQ0xlDXDYc0Y+drtrScY9lTsyAbEq1/dleHxeHZUfOQHb/Mb/N1upsTPtZr+MIXRgsAWS8yemclGv6VT40H+sBr/On+jH83+ov8y+rjFMSkBE9BAIP+gUIgPbBXY8zj4qtHEaGZkdAN7vVb6v+fvXcPti27yvt+87We+3HOuY++/VI/QBKgyMKASjIYWRhbYMTDlB0nGD8qTuykUnGSSrmSVCpld9kVEydVtklsQkKZcmyI48R/2BTBAaMKyBhhXDYIDBiwhKSWWrfvPc/9XK85Z/6Ya5y1b6tbtNQKfQWZXbv6nn32Xnuftdacc4xvfOP7aPFYNJXOaPSQ7JWGhkplfMH8KVb9ik9uX2TVbpnVx9yY3WLXbdg0Kxqt05odPG0cUC5908wHVAwMWiePvn7AaMPS1lQ6Zzvs2emBLFvibEHZNcxNwbnbcrk7o9tGyvlN3E3D7vI+cbUlzyzZnUfp93v683P69gyqmmIYGBZzjIrE0mGiJu5b9m2yxXPK4HSOudzTrPbkxzOK+ZLO9Ox9Qxd7YozEo6MUdJ2fw3pNNwxJGFUaUCTRkEqQ7MvGTN3MMpdFhPnkJM0ZERuGZB10dQXLJXo+T5IPRYGua/RuR9glNNqXBUOMuI9/hC4vUUc3sUX2yhf9VYzXHGjFGAel1H8E/DDpNv7eGOMvfNo3zQbUdoeyWXLv8A2mrGGxRPc9bK/wuy3d3R0hc+iyIuYZujAMGnQcsEqjl0fY42Pa83P8vXtTgHPYPj2fp4VQzGr7fiKW13VaNMV8t2kmNOqwvdqYafGEdFEliLt3bwqU6jod47AjUToa5SFu76JsfXaWXqc11BWE3fXNAKQN5ebNyWtNUDApI41iqqEY2J5+kqAi4YmnIJ8l7RYgqkB0JaG/4PH8JjM3o28vGPqGspix2V2xa3YUWUnT91z1a45szbbf4oxD65KrYUPhHA59/dAoOtT/rxpPKhd8Dz/F6eGTIcDzz6cN/pWIuC8dgn6IC4JoX0nXat+PHXiPwVvuwNER1jkKoCZjhqPEXQfEdlz4BYe0qLGtIYVbAcnCE0owqIjPSny2JNSB9uaT7IYd+/WK/eqM/fl9+u1mQouEpCpI1PHxJLopGnIwtV9L53DbPtiVuF5PZHfpJBZS7PHxhPbIpigNLUKMvxi5adlJKjOI3p0EOII0ieK0KFLL+RSUWpAteNBFAqb3C/Imc1oaFU5P4dlnp7/zUIJCNgdB9ZpmVPh3U+lTyqQyzs8Tii4o3dg40/RXdMWCK79nZXa0LNgwEAi/qbuC/Ugwbxh4kQ3/nOf5fj7yYDftep3Qyw9/eHrjYYLz7znoHoNveyd8yRem0vfYWPGV/ZI/Yr6Cb9ZvJR/njgRZ+rNY5xRJyNRirr+7HGdGxoaOKxq6MeAqtWWeVVz4Nfuh48gumC1nnO7PuL8+JWYZs/qIMqtZ7y7Z7C7JXIXVmn2/pzeWmaupyOn7ln3TgNG4rIK+IzMG55bMfMOmb9jYkqbMyV2GazIWtuCsuaK/d4/s6Ah7+3H63Zb96pw4DGhdoB+5k0qJ60uatkHLnraYp5R7OUP3SVah3+xxQ0teFCxcwXC+ZVg3MC/RdUWpM5qx3KmUQt25Q1gucWdn+LG65EVnUva/i4upslPX6URLEip6f0Kgl71f1oYxUR1G1NqUJTbPcdYSyhJTlkkBf7cjDp6hnqFCxLz4yeR7+BrG52SHjDH+EPBDr/oNg2IIHva7tIYoRXt6itIWfbQgu3kn6ZLstnB+RlhdEPIcvXUJ1ClzQuaIMZArQ3ZyQnPjBs3paVqcdrtpc7q8TCf+5s2pC0s0fyQLXS7TRTk6mrLvQy0byYykdiyqz84lX7b799PFFH0g6SDq+3RM6c6SbEt8z0R7S1AsRoHF3W56rqom5KssUxAm9h8S/I3CpzFGdvfvElHw5FPJK6vbE7MkLzBoh+3OeSQwYQUPAAAgAElEQVS/SR1qLrsVTmvKckbT7JNicVnR7TbsQ0alHNt+j8mSzMOZX1MYy5YOh0Wj0CjMuKD8Vh0Dni07/i4fnJ6MEX7yY/BXfwB64JeYiLgvZ/kBUwlDuuEOLXRiTPfp00+nx6rG3IIKqHDMKa6DrHzU9inJqTBUuOtAK9nYQk+kx18TdmX0eHo8HQM7Il555q6gOVnQH99h+9iG7dUl+8tT2qtzhmY/IS6SlIit1OHCJ+4KUg69upqsNWTeSFBSVVP7tnQUSUelCKyK/2iepzklSNQQEvldug7l8wWVPj9PKKB0W4oUw2KRAqU7d9L8Oj2dpDSkPCuosgROs1n6bNEAurpKKLRoiB1ajch6JNdX5q8EcSIBIskTTJI2s9mEcM1m7No9zcKzCjvus+NZenZ0DGOw/JtRT0tKhoHIPbY8zyX/LT82ddeKwPVmAz/6oym4+iCwAX6VlFEY4M8/CX/y96Vr9PH+Gnl957DgD/NlfJNJQZZBX5cL1ecgmTRjeiPdiADHlNRkrOlYsacf5TkKY9jqjothhQIerR9hUSy4u/kk28t7VLMTjmY3Kfodq+05rVI4m9EPPeu4pbeOZTGnCBW7Zp34t8WMShm87zE2I9cZ9bBnowMba3F1TtntyFVGnEX6oWN/foWeV5hbT9BvV7TbNS5AqBJfUV+d41cr+r6Bdo9fLsmKCjKLLW4RZw395SX91RXbuOakXlKZnLDuaXaXdKWlKnOcrmj0QGz3hDwnPPFE4kWdnxO7jqgUyhiCaNitVmneiY7dcjl1IYsosCgC2NFBw/s0P0UcvOvwfY8vCrz4JcaIcw61OML3HXG7STzyskZ/NiLTB+P1gSI8+HlFFmDoOhgiuiyJTUv/iY/jrUUfpVKAfeYZ/H6LOTvH9z190Jhug3IGnGXIMnRvyI0jPzmhWyzotonAlgh1epJKmM1SmUV4JVU1lRavrtIifHSUFmIpY6zXkx6WCAyKjIMsio88ko794osTaiXolgRy0iIufmZlec2lQal083TF2EVRTgFYlqXXnJ1N9irn5+nmqevJMkUy6xjZn98jGkV87AnIKkLX4EdFgBA2qF5zKzumDgObbocrCmyW03YtRbCoLAVYyijU0LI3FmMV2jdc6h1aqWvJBzX+p38LSz70BP4Bv8jHDntA/snH4Ov/Duxfxoz0pZYfMkRBuaomErts6M88k9CSEdG0K7iBZUHNDMOcjAUVx+Qcjf8/oaCmYEaBQWQ5JChW7GhY0bGhZUPLipZLevrU/8vx2CmVBCE7GjUwzwp2t45obtxh1Vyxv3+P/vKMtm8JgmBtt1OiICXEQxkVQZ27bjKTFm0qKYuXQnRtJr6jiA+LaKoEJ4KC7fdwb5Pm4Y0b6bWbzZQo7ffp3F5cTI4Rx8dcm7wXRUKQH388vV/mnAR2wgmReSfzXBZ0WU9OTiYzaUG3Du1EpLQqa5DIPgjKd3g/rNcPStXESBMje79npyxnYctaN5xQsaOjIPtNydPq8EQilzScseGv8ePcgynIEhL0j/1YCrL+JjzofzX+/MMd/K4dvH15XX76Ml/zh+LbeK99K8Uo2ZAdJI45n7sOa40mQ2MJ9AQy4AYlczKuaFjRpsRVGSqXcek3rPodpcl4evkMZ/szzlf38XlBOVuSHz3OanfJvtvgrKP3Y7kyeBauZjG/QdE1rLcXrPSeRbEgHxSt8pS2IveeuuvYOMMmt+SuYO/22Mpx1q3Z7da0ekAXFS4r6HYbum6PiQG/vEnf7YnbNb67Qu9auuMlZj6ny8AWGfbRx4hHDeH8lIvLc7LdFYvZCfNsydB17No92ipskdHlyaXE9z3m6Bi7WODPzxmuruiHASX8rTt3Ej/70NB6Nktz9lBhXtD01WrSyBSQRSRwui4Jm3YdMc+xxmCMxTpHmB+jhx7f7vGfrdD0OF6fQMsA6ys661BVhQZi06OyAr2cEVdbhtO7DGf3MXWNXR7D7TvYvkVt1ww+EIKHpkU1LUOeYbIc0ylyo9HOMdy6Rdf3RCHFiR3AxdjBJ8RhWRBlQf/kJydvtZs30wU8O5t4XyJGKmUM2TCqKqFbp6fpM4SPJeiUQJ2iSSTlRRFpMwb2K9gNU8eXlCE3m/SdhWMym6XA8aXBlnit7XY0d19IC9DjT4HLCEPDyhp8bGFIKsTHWU0Xetpmhy0rBqNpuh25K+hVS0OPBXbdDqcsO625HDbkLuFZ2Vie6vFo1G9J1fiEIni+m5968Bc/9mvQvoLj+zt4+bKhUg8GJ2UJb35zeiwW1y87BhzwOAtuMWNJwWPUPMkxz3DCY8w4omJJzoLiJXo/KUMPB4hWN5Kpr9jzSVbcZ8cnWHGfLSuSeXFDxp6eFs+MnkY7FlXJ7qljVo9s2Z6/SHN6ly54gpTVpLlEiN+CbAkZXPwPpUzY92muCbp182ZaHEXPbrMZT8DxJFQopUcJ4EoH3ShKLAmOoFBZNiVOd++mslzbpuPFOAVrzz8/aWOt1+kzhT91eTmVSyWjFtKuLMYvvpiOLQGk2BgdKvO/tNQhSZug6DJOT+GxxyYz7BHF3rcrmqJiHfdcsadhYEXHcvTZ/M3UpDKM9+megVM2/Ci/yvu4P51v79P98yu/ksqGH+FTgyxIJPh//An4PX8bfvgPwxc+wxeFkm/xb+Fb3NuYqXxEr6YwNRuxYOAa+z3sNHy5IazVKQ391CBNo8nR+LHcm2G4Sc2MjHP27EaRaGeW1LrkfFjRhZ7b5U1mWc0L60+yvbhLNbvBSX2DfVay2V4QGfAx0OiBIQSGEJi5ipvHj7Hbr7naXVLakjqr8DEyGJPUwfqWmXFcGMeuOMGVBZkuuLI5V90VbdfTGk05P8K1Bc1+h+4bbFbQ2gy12+DbPf2LDW6/Ix4f48sa58AVOe7xJ4nHO9rTU87WZ5SbK+r6iEU9Z4gDu22LaTVD4Risott1mExjbj+Cni3h9EXibscQI2oEFbwAEof6mvP55CQh64/QLiRBE+Dk0CGj7+mGgZDnxCxSZDnKRDJrICsI+z3dp17qVz1en0BrsOh6wTAMqKtVas7JM5RJG4g/mhOP5vj1hmG/w999AVPV2LpGmQIXe7xS9EWG8h7VpkW3sw6d52TaoH2H9QPtYsEgpQ3hvRxGwdKlcGif07Zpsbx/Py32t29PF1PKF4KKSXYuNh2PPZb+f+/eZN9zaFYrZD4R1BMl6bKE+hj0aiLPC4lXCMNirn1xkTaRs7O0UR1m1YIG7Pc0d18gKgWPPUlhDdFvGUyyHfrocB8ywyyf0e87hnZPlhf0tPR9i8scTdOgjUbFgZ1vMNpgouJsWJNbwwp9UEJMwdZvhOTDwzR6PD/BLz9ouOM9/M4nk4ZSeJk33X2FgwlXz9p0z73jHWnDH3k7BbDEcIM5MwJfwh2e5YQ3cpM3c5NnucFibE/49UYyl0gbSE0K3h5jyZu5TTO2pF+y56Nc8iHOucsVZzRs6NnQsCfZv5RYZkXO7rEFq1tPsD57ge7sRRqlEq9Bkor1ehLrlU5CEUoV3qIguNJUst+n+1yI7mdnCQ3eblOJT+xz6vqABxWn4OfycgqkJLERcdS+T5Zcjz6ajiecSGPS53ziExM3Uqw+siw9d3o6LdRiLwTpu4jAaNOkufnJT07oNqTvJj6TUj6UwBLS84c/SxAqqvPbJA/TtA1NFbjyG140W57Cs6Uf78mElPxmGIclw1M2/GtO+Uv8ZLr2/+Sj8P7n4ctO4IkIP/ET6U1PM5HeXzrCqPj+jz/OjS94mvcOX8gftF/KYpQKEKX3MJZfPZGe/hWDqlc7JOgSVFmCNykpDnh6AiWOR7GsabgYBQUWqqBwjiu/5arfUtuCZ46e5v7ujPOr+5TljMX8mGJZcrm/SP6JJtLHjovo6ULHcbakKucUecV2t2K9v6TKZhTRETRoU6BDTxY0Tcgo3JzaZuRdRqUyLvya7dDQhgFcTmUMfefw7S4FsIsTuv0ukcovVgy7Her4GLU8wpc1OSRO1ONPwGZDc36G31xQ7DdU9RHLvKAJnmbTMuQWW+T0XUff7nBlgXviKYbNhv70Rfq2JTYNVmv8YpFoM9J01jQpURLutQAQMt8kSZJuX0ianaPNne97Ygi0XYdyjjByuEz+2ix4Xh9T6e/+754r/tTbMRpcNUtO4F2H2rd4Hwl4VBhQ1hDrGVidaqa9J1qLzTLwEdvsIUSGIiNkY9DV7OmjR9scbRymbTA+BR/Xe55wO6SFWkizWTZ19on57mqVAi4p4UlgJKRaWcAPvbXm88mFfLWaVKAFDRMES0otkpl1Co5G0p1k6cLh0HrqvIBpgZZFWOw6YIrivcevVwStUFWdbCFiwOtkx9KGjspVFBi6PhHnvUkE5zgk/kIkoLUhDh5jHFEpNBGtDJlKujJuXJz0uHnrV7HRv9rxMJvhegI7ev4sP8y/YjX9Yhjgx/5F2sgVSYrhcHwV8NhLnhMOT1UlK5B3vStt6mOQNQduUfE0x7yZm3zR5YI/snw7v4838RU8yWMsKXCvucShUDgsFRknVDzBgjdyk6c45hYVC3LmZGRoNJZsdHpzpPJ9MVtgT26htUG3Ld4aovxt8GCHkJRKpQwoCYhzk/OCWNIIR22xSM+fn09SE0J2Vwp8BnmcdL9EoiXPJ1RIEi5BpsVTTXhbwq0S1wbR8ZLmBGmYkTKgZMZSIhUNsdu3J3ukQ9P6Qy9VybIl+JJyqHBCBPWezabnj48Z+p5yfkQWFLWreJw5NRknI8PopSjmwzyPPt1oGYjAOQ2fYM2f5//iI3TwEx9Jpfn3/Rr8vV8B/69hNq6jS+BZkljtoXOK02k+Zobsz76Lr6+/kH//6F08bm4QiWg0kalMadGvOcCSIQiY6GhJ92Ti04EZyffyaQWOOolB0Y1JbKVzCpX8ChWKqphR5BXr3SX7Zk2d1cyKOcoZ2m7kBirowsA+tDhtyIwjcwXKWPqhu95/MgyFcQQi+8sVjyyOsdqR2QzrHCYaTASlIoSBqDXKOJRxaEARcC5H2bQyhL7Fb3fQ9vg4QJY4VloplMvQdU10hq5v0r4+DMkkW2lU79GtT5QWm0HTwtBhiwpzdITWCjUMeB9Q+2S1FWczjNZEY6Zy/aEDhIAWsv4IB3ZEs6K1aGtRw4ABgjHoEAhd0jkLQ0f/V37m9TWV/oxH4QmX5yiXMyiP1gqzPIYIar8l7PcoFIOKmG6HVxqfZ0mzY3cJZY2azTFmTtjvyJs9vlnhs4zeGFSIDJtL1Kj343zybbLG4IFeFniR/99s0kWZz6cFWRZSCWZeeCH97saNqdtKrEQO9bfW66mk8eSTCX168cUHfeC6Li3u4n92XU400KipfiwbhCBmy2XaYIQsfH6ejjOSZJO+0npCDMZ6dfvxjyW+1a3HCcozhAjaMgweeng6e4Tc5+y7BlNkBKMJQaFDpCfQKE8EbLfB5oaNipjBUDiHVnrUltG0eDT6t4zkQ8vAz/MxfuTQGOGffAz+15+B7/3ZhGallr8pu34r8BUvc7A8T2jLV35lki+QgB84AR5nzhfyCG/mhHfxLMfbHe/k2f+v/rTr4bAcYTmi5FmOuaLlY1zyES54gTV3WXOfLRe0XLGnwFBYR3UnZ3PjNtnpXdrzU/ZaEw8teqSz71AjTAxnLy/Tc4LuSZee6FCJzZDwlwQ5y/OkCF/X6XUXF2nuej/JPRTF1LkoHqVCFZBAqusmjpZoYkmDi/cTl0yu26G9liDe6/UkOyGEeMmiJcs+7DgUUj5MQZaM8/MJ2RRdMqXYdlc0xnIZGi70jtvMWNFTjNpNn+8NKsMYjOwZOGPD3+dn+CnW6Rr8+McSMuVjUoP/AQ+PAm9jMov+d4CrL4D3b+GJBbznWbhs4Wue4Ru/4nfyDR96hMfNTVqGa56pHwOf7Dfg3HlC2o/gGu1ySeWOnoDDcIuaGsc9tvR4al1QuIzzYc26a1i6mvzkGe5tX+Ts4gXmsxvcKJfMlxWnuzOaZoO1Of3Qca+/z3F5zDKbk2clWhuGoaeMiqFviR5qm1NGhxkCS20praM0OfWs5LTNKXZXrGPDlp6Gnj53eK3oWiB4irImZBlmn9FvNwybK3zbYPY9YZmUBWzmMCYHrQjO0Wx2hK4l9pbcOCqjGCLs710Sypx6ViVksRvwOqLnNzDVHH15xjDKMti2xR8fY/Kc0DRprREpFynbS3ORlJpF0slaVNcRQyAWBRHQXZfkpPIcBfSvkQz/+iBa3/8Xn1O//0uIMWAI0HuGdkuIPnUzVDOMtmifss6owAwDoW0J1hD6AXYbooqoqsLVFbGuUVqju57oB0JIx41Dx6ABY7ABlHM4Ywjep7KaZLAwdU4J4iXlCOGTDENavA+5AcI/kWxUiOltm14jWbiUHuWzpD1efA37Pln7ZGHig1k7dTzJjSNlQpg84aQlXPSH+n7ipYxowXB5iXcaN5vj8XilCTEQ/ECrPXO3RHmf7BSsI2qSxQIkc2qbEYNHaY3TjqAGIopaC/nWPNClI23Rr3U8rJm4x7Oh48/xPn6W8/TkB55P/I+ffmEqGUbgBkksEVKW/Qwp65ZRVfDGN8LXfm0yKdbp3CngFppnOOEreZJv5S38Yb6U38ZjbE6vfsPPi8FQk/EYC57iiCNyanJuUrGkOPDDTBuGM458voTlLBWYhwFf5pMRtix+IhQq82mxmLhcslCKr+khUiVaVtIw0HXQWYijvpbo24kmngQ8gqjBpGnVHdp9HCBV4sQgQaCUPGWeixjxoSSEBGvb7UR2324f7Dh8aRAp81uQNkG8IR3r5s0pgapryDKiUtRZTa40N8ycR5iTYTihGqUJpmDhYZ1HrzQikXbsobzHlp/hE/wXvH+ScbAG/rd/mTTTIgk1fgH4ORKatSRxG9/2ZfA//HP4pVN430fgz72bd739bfxJ3sGtVcHJjZNRD3DCHIqRDvEbPcKIdkl+JuNQ+LTHo5SiNgUZhm5osMpQFzOczThf36MbGqp8xiJboK1l120xIaKMYd2uGfCUtsAZi9KankDtKjIMu27H7nzFreObSXMvBAptKVVOZUtsnqpJKni01Wgf8JlN5ssBou9Q2uKKCm0dOkZi2+GbHUM3gE+2QzHLkqexsZBn9Erhux3oSF7OEyqbuYSIbTbE4LHaYYzDaEVmLKpMnxEVeO/Rq6uESolck/CxZJ8P4eCkZpPOpSQ6Y0OKjhFbVfgR4VLDgFYK/50f/KwRrdcn0Pqb/81z5mveMMKKEJxOkOIQ8O2OGHrILKosE0E+gjIajEW1Dar3DChisyfsd3gNyhisy1HzGSbPiEYTrUH1A3rfMOz3eAXRe4y16LLEhEA0Sd32mpDaNCkIEu6FlDBErVYyWImIJTsXlWdRrpUuIWnzXi6nFmQZh3pb1ia/uIJJURqmz4dpMV4uJ+XbQ80wuVkkKJTjiIr85SVD7sjqBUF5vFF4n4xOg1PUtkJ1A4MfwFiiAu2HUYsrYrWBoce4ER6OHqcNhcqIhLGMpEco/HPThfiwbhAbOj7Ei/wZ/p8UU33geXjux+CXzz71xbuDf0cSIeqp8eeqSma27353QkjHYYDHcbyFR/gG3sSf4h38Dp6hHNk3r/d5ybDcZs7THLGgpMRyTMmMnNkokWoYSb82xy0WxLrAdh5lFIOU3wQxWi4nUrkEE1IOFxV54XNJiV+SCVFzL8uECN+eT0bOoksGB+XFAzsheV5Ei8Wo+tC+aL2eDK9lo5dgTeadmF+L/IQEdt5P81E4mdJxCBMx1/sHdccOM2gJ7I6OHhBk9H1PMVtSoJnZgjvMKcm4Rf0puk+v9/3ymY52FEG4oOHXOOM5fpC7DFMSeWKhVvC+5x98YyRBwL9tCd/4jfCDH4Mf/bWEfMXI8dO3+DNf+Yd4u3uWzfmKGzdujJ2GaYi0w0tHjKnM56NnCMOnffjg054yDqU+86BN3u3HcqNFMycnw9COSF+mHTNdMAzJuinPKqp8xrZZsd5dYl3OLJ9Ru5p+6OmGFudydu2G/dBQuopMO5TWNL7FGstRdsTF1SVZDnlUGO2IwWOUoVCWQmXkeZX2gm4A41A+VaVUlhOVInYNoJJkQl7hjCV2DarrCH2Pb/bEGFDGYIo8lR+NITpH3+4Ztlt0kXwcM+PIXQa9JzQtoWtQfcBZizM5eVWjqwqt0jVi08BukwRQxy78KOdfuFnCj1Yq7c2yr47ASvQ+BW4xJoTMpfKo/6s/+3lWOuwNuq6IbUtsdsS+A5uhMoMKEJqG0KUFzGYZqiowsUL1e2JREHZ7zG6D8p4ueNxZT3AOX5ToIkeXBWaRY/ZbfJYRlMK2LXGzoe9ThGxGErxTiqA1A+OFWiwmjS0RDpXnZJEUAVMRXxS7EeFeSIYqWbCU+w4teORYopa9WCRDXNVOejqyGYh+iGTL+32SlDg/n2x/pI39zp30PaS0ITyQcRPpf+3X2CjF7OZtuugJThHbBtWeQ6E5KTJ0s08+UCa13Jumpev3mCJZfOj9GlfdYB967g1X5C5DK82KBjd27Ahn6zej5EM/Sh78Nf5Zksb6wPPwtX/r5aUcXjoOpR3mc/iqr4K3vW1COkkNIW+g4LfxBN/OW3kvX0KB+5z/HZ+LkeN4Ezd5lmM+yiUf5px7bLjDmruseIENp2zIMJT1I6yfPmJ7dYa5/wKtMQwyh2QOSKef6NIdH6cgq2km7Zw7d1IgNgzp9bNZmqunp9DVcDnqbsmCakx6r8wlCbaGYULEiiK95ubNiQslgZ3WaT2QEv16PaFkQn6v62v+1HUgJ52JUrKQsr5k2UJ8L8t0fGlNf7lxeTn6NZr0PQC8Zxs2bHGcxj0r1dITWLHHjYbHn4/zT0qGDT33WPF3+Bd8kGZKGvs+ndcP/sqnvlnm13vfm8q/73oq+X92HjLDv/3VX8c73RspVEpYDjsM3TUiCyEGfEhBlY8pcNJKXz+UeuW1LcSAj54+9IQYrt9rtMEog9EGrV7ddRFhCSlv1mSUOF5ky44Wowy33BHrYce6b9C2Ij9+mrub+5xf3mUxO6EuF9xePMLV7oxtu6HIZgx9y0cvP8qd2R0WWY1yBfuhZYiBeTbj5vwOq2ZF3G/JjMUHRbQKawsqHFWeUZqSs90ppVZsTM+2b9BFTWcz2vUVcUjfT8/m2LJmf3oP37T42OCHM9rtjrA8xs3HRjeXMRjNfruj357RdQ3z2U1ycrSx9CHQDC1t7wnnlwSXoauS2mWUj7yBzXyNvzxnf3GG+uQ9Yl3iFnOGLMMLNwsmFF34m8Lhkjk93l/eGHwIOK0J9rWFSq8PovW3v+M5/a1fghKH7xCIQ0/0IznQOnwI6K7FNw0xBIIKKJehtEUZha5rPArTD+AH/DAQ+57Q9ig/oOOAystk7+OHa69BXdfEGOl3O+JmgwoB4xwqBJSQ1CXSFR0bkU0Qkq4gVnLBBF2SMoIsoqK7JXVhWXyraiLBH9aSg4X5uKEKyiYEWwnkpPyw26UMVwi9oj+03abNQL6HcH2k3BJCEoMrcmxZgAKvNX3bJL5cZsmiRfserdVo42NR3uOHHpuX+BFKdTYjRM8QPTOTunYkk47jv18rT+Rhy8QjkQ0tn+Ae/wH/KD35fT8H/+hDUxr6ckORuFlfR+KPHB/De94Db3nL1HhB8kJ9E3Pewxv5z/hqvoY3vuw5fNjOi0ZzQsUbWFLhKLEsKUcBVYPDoogYZXFFiV4epc3GDwyZm0RPxd1hzEavkSqZW9LBOAwTLwqm96z2kMVJlkF4UCIELMKlomYPD5YERWtLiLIiGCoWXE0zcSul9CldidK8slhMNATJnMWYW+zCBPG6PoF6oh8cljhkHPI6RX+rLGmVYm4KcltwoipuUZNjOKK8Rpjh4btfXmlIyVC8DN/Hr/Id/LMJ9ZOmoL/yfvjBjyZBUkjz64uAbwb+xO+FN70pnfNHa/g9XwDPHPPN/9W385/+zj/CsZ6lHpWzS27fSOfEoNABOt/RDi196FFKYbWlsAW5zclMhjMOq20Kml7hYbXFaoszjsxk5DbHapsQseDpfEfnO3xI6KUEbq80hIoRxg7MCGORWKdmAQW5ySgw+KFFaUtd1BhjOV/fp/ctuSspsxlWGYZuT55XBKW42p8TlKKwOc5kDAROL865eXzCMl+Q2ZxhaOjbhuCT64AzjkJZMu0osiqFp51H24wQPFqBrlLj2NB3iSKkDdnRMUopwnqTRB21IrQ7wm5IRkVFhslKjHMEbRj6hn63QjlLXsyxSmEUWGNQWZG4eWPpT7c9uSlwiwVmvkjI2maL2uxQRuHKkmBtQrdEUkX2e0GbJRGTyhXAZkMIIVkC/fVf+DwrHX7vX3jO/+4niLttqkfP51AWWGuIIaBixLiMmBcEo4kxJLJcs0u8K2cx2qI06Dwj6HSjKjyx71HdkAK0tkUBtiwJSqO7lhgCdjbDzOcM1uL3e3zbpsCg79FKESWoErVZ4VuIAKqUEWezCTmS9lK5iFJOEBkIOZ4EShJBy88hwGaf4IxDhWjZYIS/AVPwJIrWkjlLULZeT+VIIfiKLcGYrYfLS0KRY+qSqFLjQd/tGbRCZxnZoIhDgneDAqsNoU9tzlle0HUtzjicdsl9XilqXRBGEmc2en1JJ+JnOx62DaJhoGHgv+Qf8gsf+PkUZF228BPPv/KbNPBe4N0k7sjt2/AH/gA88cR0fUmX/os44o/xZfxpvpIv4NYrHvJhOy8yDJob1DzGnApLhWNJeU30zTCppKgttp6h5nNMgBg9XhY9Kcu9VApCAhnRlhNESLoWvQfvoDbTvBUkGhIxXRZVOaYstoclQTGylRLl1dWUXElJUnTtBA3b7Sb0TDiewjuT+Z9lExol3YxCjoepLDa8DDIqf/9yOaHhN25A11FUcwplmJmcJznCYblNnXSYxiD9Yb1fXjpaBvwoTPpzfJy/yI9wzkDkPyQAACAASURBVIFY9G4H3/VT8Bd+NvGyIinA+hZSN+/bnk5leKkmWAtPLnn3O/8N/uun/hB3zNGYAGpWZ5ecnJzgw0AcEvpktCG3+XVwZLT5rEp/Lx1KKYw218GX1akrdAgDrW9fVdAlHd1+NK52WArcNZfN6FTaU0P6ucpqZnnNVXPJttmQuZwyr7HG0uzXlK4mdyVX23O60JGbnMLmXG3W2MqhiBS2ZJbXZLbA9w1Nsyf4nsLm1DojUxrrCgqX/IqdMkRN4s5lGWQWBo/3A/QeW89xsyVxlC1RWQ42wH4g7PdEpbBVAS7HZA7vA8N+S+hbTFElyyHABI/JKnSWgx8SKhl6bOexSmPLGl2VoCFsNsnzUWmcswStiTIvpeFNEiEp98sefahv9z//8udZoPV3/tJzvOdZotaE7ZZhdYX3HlUUxGIMuPr0xymtUM4RnUsiZRpU30LfocebNfXORoIPichtDEFFVNcT11tC16G1RuVJeV03e7T32DxHz2YEpQijWFkYBoz4pAmCddiavt8/YEJ67Y8mKJXwOaQWLAuqPK/1g8cVpEtr8Dno7kFiPUwZ+KEUhPBJ+n6yABGpiq6b9IUEdRORxJcgW6GqMGWOMprgI32/JzgDTlP0pJZeoxmUwihF1+wS4dBofN+S5QUaRRs6Mu3IlSMQrhWWgdFv77NbrB6mDaLH0zDwce7zpz/wt1K58Ec/DP/040mf56Xjq4A3AV8DfPH43KOPwrd9W7pnpAxNQrK+lBv8J7yDP87bOab+1OMdjIfpvLzccBhuMuOR0QDoiIIFqaPHjghXjsJYh53PCWWFGTxd9FOZXObQoaacZJwwaWoJzyLLYBeSvIMEUYc8SrHPOpSUkG5FGS81gpd14FDd/dACSEp90j0ogd2NG5NOlnyOEHA3m5QgSWIkJTFBoV9qhnw4jo+nEuPt29D3DLlhRkblKh5jyWK0YyrGBzz89wuI+G8SJv0YF/wNfpr3czYFniLr8R//MFweoH5L4KtJa+23fusUUI/z69lB8xf1e3nK3saO5UETInfv3WV2VFMqR2lLMpN9zgKrX28cBl5Op2t0GHQppV62vKgP0C1JZAvcKBvh0cqQ6wwzpLnjbE6dL2l8w9XuAtCUeU2elTTNGodmXi3Z7TdsupSs95uW+ckR3dDhYyDTKThc5HOUMbTtnu1uhcUwtxVOJeDD2eSFm0eLMYbIgEERiwylNJFA6PZYpcluPkIg4q8uUENA5wVKpyaUsNtjnEHlJSbP8UbRtw2+adJWmBUY7bBDEnVVZUFAp2Y3pQmkPcfaHGUytLbEvid2TWLgFQXKJRAiShBl7dStLIbyIUBRoPM8FSu+6xc/zwKt7/zvn+NPfPkUsCgFmw1+vcY3DSEEdFngTaqCq75PhHjvUcYQq4pY5GAUQSvIHNZlxBigbQhdByFpbkVnU2mxTVmsDh4yR3AO0/foYUCPi3Qcu/1ink+dgBKgCJIli6YIMB66v4v1hgguSvas1CT/L2UGrSdJBilZbHqYjRuKZM4SUEmpUjYCIcKLorVz6XjSst62aSMSDohE6YcR+jAQViuGqkqkRGeJ/cAwdIQ8AxNxvcIqRVRq1BaBvtlh8yS86IeeMqsJwdOHgdoUWGUIREpc6lwZF4fPRvLhYdkgwmhH09DzXr6L0+/7uRRk+THA0nxq6fBNpA1AOgxv3YJv//ZJtHYM4Evgy7nNn+XdfCNvpXwVelgPy3n59UaG4w4LjsgpcBxTjN2pYVThdjilsXmGWi7QLqNvdwmqFxRH4H4JRCRQEv7hapXmmbXADKrx3AnBXRBgCWpmsymZETRLkDGZr+KdKImSJDAw2XMJsn0YKMmcH4bE9zr0ZhR0WWQiDj9Tgm7ppnw5VEs6IxeL9LeNaPZgDDOTkbuSm6rkFjXZWLotRpbPw36/SMmww3OfLT/Av+J/5GcnpFKS1b/3T+HvvvDgXBNdum/4hmRTJefQWirveS5+Db/dPZMCkuATITt4Vpcrnr39BjKT/YYEV680Xi7o6kNP69trftfh95P1NJI6FTWKCjfy2tK9mOsMEwIhDBjjUpCkFRe7M4bQk2cVZT6j6Xf4oeeougF4ds2GzXbD0XKJMY4+9PShv+aXLWxNnc/RSrPZXrFrNixsMojOtEWbJPmTKYcLClREBYhKo5xFGUPfdYT9lrxe4OZL4naH360JCkyWJ6Bksyd2HTiDzUp0mTP4gaHZp05Al2F0hiZiPDijUFlBVDoRz71PyjpZQVbVOGdRbU9o98SmSVy5WY1xSTU+StPNoW7dKDQeRR3g867r8G9/x3Pm33prasOULFGg+WFIRo5NQxjd7Adj0DEQvU+lxb5Hx0gwJqFdCrAas5ijF8cJhhk8dAO67Qgq4PuB0DUMY6eh9QGlHV6nl1siPsaknxHCdRat9SgiJzL+EvBIt9Nqlf6GopgWwpOTBzPfvp880oQrIma5WZaI7XkO5y2wf3Dh3+2mz4UHuwolGxfOljGJtyWLtwRbh2KrhwHjGGzF1Yp+NsPmGdEZwr6lZ2DIM0LsyAYwKnWGYjVh6Im+IytnDH2HVpC7Ah96OjwLk0RXFZoCe70YfDZ8rYdhg0ibQFJufh8/y//Eh8Bq+P6fH+VBDPyuAj58YJ+iSUiWBFm3b8Mf+2NpwgrCqBQF8NU8wV/hG/gKnhpby3/9UuvDcF4+k1GT8+goqlmTsaQc/8qIwlBgybXD1TV6cUQMA33bTHNKOJOHQY3oVkHahNsWdj3Uox2PBEESPEkg07ZpHsI0r8ROZz7n2qi4bSfOY55P81mCpKtRDVOSRUGYYSLZiySFlCTkex8KnUpQJZ1q8vkvN5SaEBtJ7voeU1gqXVFpx6MsyMfyoRtlHh72+6Ub0awr9vw0H+Uv8yNcQDqfSsGPfwi+56fhB38+yTjI+CLgPcCXfzm8853T9RypGX/cv4k/6N5OFZPQpwlQ2oLCFmzOVjxy85XL8y8d0txjrx/m4N96RMvSa0QJ/jMdh0GX1ZYQA61vGcLwKSiXGT/Fj1FngSPHsqOnV57MZGRRE/2AMpaZm5HZglV7SdvtcTajKuZ4P9D2O+p8hjWOi7NzyrrAx4HMJjpI6zuU1iilKZRNchBFRQgDl9szbIwsVIUzGUanvbJwKbkiKpROemdRW0xVoqJi2G8xUZEdJYmN/uoKRnkhlecQQyonhgSGuKwkWsvgR0oAAesqrFKoEMmUARVHUfMiBajtHvyArebY5QlOG3znifsderMlGINbLNBEgqDcEnTV9XUJWq3Xn4elw+//jufU736CMIxGkcK9EE7EMKSgyrnE4Qqjx1SMhHGh82P0qcLIIyLpPikCZjZDzReo3BEyg45gUUnzY7smXF3RaYXPLFYbdFREk5AbPZbX4igeGMfARI2SEFHEBiU4lK5CkXGQEl9ZpoxTFtIQUufQMKTFUYKjzSYt5sfHUN+BfLTrkQVbrDekc1BuBuGvXF0dlE12k5aWBFbb7YS+yeYiaIpki6NBZ79YYIscbyHu9nQq0Bc5IXTkg0Ypk76Cc3SjvIXNcrq2wY2cht4PBA1zXRCIo5ipGbW29GfM13oYNogOjydyjxVfzf+ennxyCe96Azy1gP/wLfAjv/DgBgDw25k4WX/0j07l5XFjzoDfx7P8Nd7LU9wc+UuvLhh9GM7LZzoUiiUld6jJscxHlCuOomMKjUXhXEZ2dAx1Rdc1ic8RY7p/D5MECZ5Ec67rUqClxyDp0PFBOFgS5AoRXZpVRDNLrLSEu7XdTsmK2GkJV1IkXGTOCxIu80qaaAQFPwwUXxowStJ02M34ciKJfT8h4X1/HWgNZclS52S24lFqjihZkFPiyLAP9f0i9jNbOj7EKX+Dn+IDrCbJi5/8GLz3/4CffBFehOv4xQLfBLz5Dnzd18EHzxNnMnfw+Jx3DEf85/b3svAZfeiYmYralWiVgqKrswuOb9641q8aRikFecTxoyS4kgDqpS4YDz709TonHLlD5wyFetVq80LGz0yikPShp/MJVZ06H9P38OMcsmhmZAzAnh6lE7qkhp6gIpWtqF3Btm/YNxuUhqpIPqptv8eZjHbfUlU5GZbetwmN0jp9tgJUMsaudE6Rz3AuZ7tfs+8b5jgKnaQXYvAo66hsjvGBqEcO9tCjipyY5/i+IfQd2uWY+Zy4bRi2W7zR2NwRjUb5yNAmUQtnLMpkeO0xQRH7Hg9Yk8HgyZQjU5o4DGjncOUsASptg+p7XDUjq2donbjHardHbbaELMMZjR5BligSLLLX1jW8BmX41yfQ+l++4zn+wJekUqBEj0KCFTJpjNcLXwCCtSnYyfMkw9B1DLsdsW0ZvEcbg1aKoNLJjzGgsgxrHSrPiHWJyosk62At8fKScHZGaBoaDSbPU8QeI2ZEsq65Il2X6rlCfF0sJpFQ4Y80TVqQD0UMhU8iQZF0GknZQYTVdrvUWr738MYnJvuew4VfNgcpZ8oiLdws6cKSzq08n7zz1usU5MU4tavLAyal3M2Gfj4nK0u81cTdlsHCkGWEvkm6KsqgtEFbQ79dkY2aZUPXkBczFJHWd2NnSoKz87FwKLYWnwlf6/XeICbeSMcX852TsWgI8GgFv+Mx+M6/Cf+QTy0dngDvuJM4WRL4jveGAb6ZL+C7+RZOmI+L8qtvIX69z8trGXY00D2hpMZRkWGxQMSOOkZOGbKiwh3fwFtFf3GR5oOUwqXLVhpQxMS98RDbaX5KcCUBmZTeJYgR1FhQX+FyyXukHC+SDpL4SDAkCvWCZkkwLQGXEOeFeyUlS6Wm4EqI+fKdpeT5ct2HIrAsxtpjVSA4R24Mlas4IuNRFhRY5hSUuIf2fhEvw4aBF1nzD/iXfA+/NJ07peB7/zn8+PPT/PoyEufx3aQO3q//engeeM/3JVHS7/95jr76SZ578lt5OhyRmYy5qzHa0I/W0ArFi+enHN04xhMPOE8coFMT3SGMr0lBWLi20Rmu35m+3CuhWBIQSfAlohKvLuTiGuUyylxzuWKMST5BHfK2GEuJiSPb4vFjM5MaAj4O5LZiltX0Q8e+2+Gjp8hrlFL0Q8t2s+X4+AZ96KhshQqBwadu3SGkpFPp9DdkGEqTk+czQhzYtFtciBQxPa8jCbnPaorxnHobiF2PMTk6T53vcWjR3mNmc5RR+NUFcQiJT2VTYhp7T+97lEn6XiGEJJoKqMFjjE2NWSGSGYPxnhACWZaTFRXKWkLfje/LcMZiywLlDKx2KB/wZYndbVExEoQX6n0ChF5D6fD10dHKImrMLIP3KMkSJbjp+1QSvHVrQn12O4ZRhd3VNaauk5L5boder+m3W4Y8x5UlfkQMdEgWB8padD8QnEHljmw2Izu5Sb/f0l5eou/fpz89xc/n6Koicy5FwyNJfhg5HkHQp6pKi6fY34hOztXVpK81m02m1YJ05Xl63WYz2f5Iy3bXwb378AsXqRvti784GdJ+4hNJH0jqxkLIP+SHiVGucLVk85nPU8ardfJrfP75tKg/8cRU7pTFfLeD83PiL/4imze/mfLoiL7IiNs167kiliX97opHPZQUaJuhyorV1TnL40fYe8/l/pyb1Q26zvNCd06RpXr9OckepAMMA9XnwJPvN2IEwnU79b/L9153khNj8lp7/8egvg8f5FPNow3QFvCFX5Ou20GQpYBv5hm+m28hLT+/9cy4FYoT6hHhmnODihMKPsIVL7LhPlsyNLmzVI9/EWfLm1x+5FcI9++nubBcThytq6sJdSpqmMcHrbEOgyNjJmRKJBgEXRYHCOF0Cdq7XE7zCybOliBlomMn/qmCHEsCKX6KonUnEg7GTDZbMJU0Px0ZHhKC/uij6XtcXqb37Pess4xdbPm4uuKSPcdUY1DgP/3xXsfRjZp0V7S8nw/xffx0+oWUTnc7eFZPHEjDZLMDcPRW+Pun8NF/PVnydJ4v/fGet37V4xSmQik1yp8yzrUHUWPFFFx9putSJI5ujHKsCd36dMfTJFQI0jojHoi/HtpltKHUJSEGOt+x7bfXqFeh7HUJVuRWMiwX7EZnt4I47Gn6nsrlPDV7gk8297jsNmz9BUUxI3cVoBl8jzEZq37L3FUs1Jx9v2fQQ5JbioFgk3yLw3CkS8r6DpfZiqv9Bdpr8qA51g6rYBM6bHGDwpaUjeXMbVj7XWLilHMa6+i7PbHrE7n++A7Dfs1w9x7m+ART12ijYOjpdxsG51Lw1AeC92SuAJ8oRcbl+N5jM4cKPaFpMXmJtQVultH1DW3bEI2ibw3aR/RRhuo7zGqLXx6jFZjNBYNSDM6lLsXXMF6f1V3pqRNI69RRKBnhiGxF6cSr60mXputgv6ff7eitxdY1rijQdZ10sdqWdrPBZFly9hbdDEAbAz4ko0gGdJbh5gtcXeP7nma/R282qLMzGucwWYYaORRqLBWaoyP8fp8y2O02fbf5PC20UjqUUsMhB2u5nKx6ZDGXYGu1moKwLNEb+fCH03sefTT97c8/nxbUu3dTUCV8kd0u/Vs83yS7lg6o8/P0+uUy/e6FF9Jjv09WL+LtKEhXjOlzfvmX2b/pTRQnJ/TDQFxfsl2AL3KG5pLH45JZIHWB9j2b9RnzxS027Y6szTjOluz7lk/4c3KbioUXNNygpKFHw7XC+cM8unGD+l7exw+IzQ5MhradBxXh8Ze88YjUev6BFr7p/4T/+9vgq566RhD/IE/z1/lW6tEVMv8tFmQdDoPmcY44oeIRZiy4x4c5Y0HGPTLO2JEpi5s/QvnFFRcnn2D34V+Fe/em5pOqSvPo7AxWV5CNCY0ENNIxKHZXIoUiQU3bTtwtQXm77kCba/VgMHRYli/LB+15IL1eGlAkoKuqCYUSE2whwQvKBZMno5T7Xw7V2u/TPL11a/JWBa5iZDPsOHU199lwixlbOmYP6VzzYyKzo+MXucsP8ct8FCZEcBiST2zzq/DHgY8wif3+Y+ANN+Av/VKah1aD0UBAZ5Z/82t/P4UtiUy+hQoRKB33BNQrKsF/tiNeo16pS1mQrE/nlKHH3zjMNVrmPyVze8l7lKawBTFGOt+x63fXAZdW5nrtmpFh0VywY6t6clcRhz37vsNYxxPVo5TmgtP2nLbZYNwoa2FsItJrw3rYE6xiUSzo+z390ND4pIIfshkVGdloZH7THVHogsv2iiH0lDhsULgQyXyHK0qyWUbZlJx2F5wNiQSvbJaaqJyn7ffE3QZlc7RzhKsz4naLu3EDkyeEa2j3NFcX+GJGlmVEP1Bah0YTu47/l703j7blvuo7P/UbajrTHd789CRZyLONTXBsnhVjJYbYJnEwcQKEBQYa6NWkO03otUjTTaeXuzsJYTWLLBLSQNruYIeEaUGzFrRDbGQEHmQDxrJlW1iyNTzpSW+40xnq1FzVf/xq3zr3+enpafKzZP207tK795xTVafOqV3fvfd3f7/aM3h5jTKWSrWU6RITBmjr41uFbyPyYonROZnWtNkCjE9gfOrZjNoY6rXDmKqgKlJKpZ5SunJtWofv+el3tX//lb04qKBFmeJZcdXeV4WW6b8w3CeAN3lOvVw6Ersx6A6AtHlO3TQ01uJ7njOLrJyoaV3XVF2pvq3rfTBlrHUcrMHAXYbdMakO+DVZRrNcOpLeaOSOV6YLPa9vZ0gFS3gYQqiFTsKh428Nhz2vRFoHlQbbVfYkmGrtppeE6yE8r8GgHx+Xc6i127/cMES1Gtzz5QYxn/c3AzlusRKBro2ZUo1G6PEYypI6z6hDTel55GWG73WaSEFIns5RLdgoIs8TjA0wSlOWzmdypBw5XqMIMNS06KvU17pWLY+i0/P5c+7mu/jD/oG6hl+9C267vzO0BWaXvFjEvRvcZ3bTBrzxBYADWb/AOxjugyx9VeT3S9dXayvoyS5noDvkJCN8nFCuuzHabojC6QSZ0QDv0BHyZOYqvTI5GIYOyCQNFLOD2lXSlpOWYRT1AEdikHC4BASJNp1UhmUqsEv29v8m15do1kmrcnV6se0qbOvr7rmLRQ+gRJtPeFry71XwdbnVNI77J4bWUQRKYY0mts6I+DrWiDCMiVhs7X1VfV/abkIupeQMu/w2n+E/cm8f99sWPnQP/NuPwNYFV8G6AbgX+C3gfuCuDKqmryb/wCvZ+Dsv5p++63/j22751u7708vMhCs1Jh/NbGuPw8/wOZHJwKoDUMAVifJSCZMjfbzWovC4rLLunFZO4Nt4yg2J4ap1MslcUqOUu6LyKqNRnpO2UIaidtWq6XyP8WTifAg76aSiKSjbkqE/JtAhpoE8X5C3Ja0x+7w3DwiUT2gcR7dqSrSyBNpH1y1tlqM8g/F9QhthG6iKAqyHpwyqbdx1Pohp69IpugchXl1TJXN3BqMAE8bgKapsQZWmtNZQew6A2jB2Att1RdvU2FZjjaUuC9oyxwQRvrIYbWiNxRiLNpq2bh3BJYrcwN1sgWoVTTwgVIb8X33yWcbR+r9/5l284yV9O0UCm5BIhbC66neWpv3kjpTW43jfX6xpGlcZE6BTlnjzOW1RONJgZxjb4sBTtVxSda9TuIqXp92tv+3AnAJHivN9xw3rxj1ZLHr+1eqEEvQChqIuLUTZJOkBo2hniW7HfgCvIDb9BJNk3zKxKD8CwiQrl/1L8BZOiGTYwg0Rbkddu/exu9tz4qRdIjee6RRmM+rxmLYbJ6/rijayFE1D2RZoNJGnwYRkyRRrLMpYiiwhCEYoD4q6xNOKyPP3s0uD2vfvejyQcS0AhZBzL7DDq/lVZ7Hzq58B5TmlaaPhfXeyz5a9XDRUnvvxNbzrVjg14R3cyL/h7zLAx+nfXN2E4eXWcw1ogWu7RPhcxxqbhB0h2YHysFM5t55yFesjh6lDn2prq2+Zaw16BJtxXy0WVXaRNlm9kUuVSq41AUYCtqS6JX6M0CdRwheT60y07vIVfpj8fXWS6cgRt70k6fcr24WeOC9x77FWUbgJY+GqbW665DEwDP0hFs1xRgzxOcSAZGvK4ScwYfdMr5KahJItEv4z9/B/8gl3ExWA+eH74e3/L9w5d0bRL8AlNL/FQcN2rdw16Gv4mTfxT9/5j3j79a/frxQLH1TijlReFB4Xty6yvrG271FY1uW+nMGlP1VTuXZZe7C990RlIXrj6LYj2l/+9V6XiAqR3r3dx4Zd+9OKHeAq6gKvcT5/QpoPu6SuoaVVyqnEVxmN52FNQKAtVV2ynC4IB534tA3wgLqpnap9U+Ibn8CPGOiAOktJ8gSso0VI9dB4moGJ0MpS1U44XBufSPmQp+jaQ2uDDQaEOqRKl+5dBxavbqCqMfHISTbkS5q2BaVpqwKd5TSewgwi/Gjo2rfJzNkldZJQJnZirBQVdbGkbTwiP6RtXBFDASaICLR12mnGYn2LV2tUWWGiAZ7vQ1nhLWZopcn+zbPN67DReIOB63uukM2x1gEPIcZL0Fpf77kOed6byW5v9yTWtnUcKs/Z87CxAZ5HPZ/jpSkqy9Ba4wUBTZcBqjTdLxOqIEAHAVprVNs64pwxNE2DVxSYtsVsbFC3zpy5mU57qQfhaqxmw8IFETK8GFFvbfUCowLORMU9z6DppqEkgMp5uHjRPc9a11JMEvc3EWEcDPoALrYlIqgoWbhk58Lv2NmBBx90r7n+evd8mVxsGvf4Zz9L9bKXUa2t4U+nZMslbRyzvUyp2havbVk3Q7zhkNl8l/W1I6QKtpdbHBkegaLiXLGL9R2Rc5clFsdhSSgYETxpsPFMLOFlLUh5Ab/U+xh2Xml88PvgnttcK+PTwJ8/xoa+7WZ47Ul4001w+hTfzvX8a75jHzAETwFkPdeXRXMzRzjGhE/yEJ/kvJN/wHRebwmBUtiTN7E3njC/9wsuFoQh1GNYj+HGG10isb3dAxdJfOR6XSz634X/CO462d52rTnR1hGwJfp1MnEo5HeZMBwOHcCTJLLjnO4nkNOp8ywsCnd8soR6IIMyWfbYrUNwf9/t+JySxGlNUtfs1Qt2dMRDTDnJhJR8v5X01bDqTpQ0oeCTnOV3+VPnGSqCzFUFv/85KBoHpmpc2xAOciFb4Mf+KqyF8Ibr+f5vfjNv8V6MugSgOBFNF9frpiTvQFNeZ5R1uT/BZ9Vjc0cFYIkHovyuPNUR0tUT8jCsu/agA1Re5xF7+X3LFGPTVcWqK7QVPc9zsg7a37cTqj3QHaCYdM3TBQWJAs8MWVQJtW4JTMB6tMEjnCPyAqq6oGgSjB8R+hF5mZFXGbstTPwhsY1YGx8lXc6YTi9Sx2O8YEzo+d259xjrGD8wzMs5RVOTacsk3iQsUmyeYbXCqBgzPslussMsW5KHMUVVUGUp1gYUh0+SznYoUmeHk7cl3mKKKjLa4QR/OKGOYsr5Hul0h1xbojBlPF5jcHgdm8RUyYJyvsAGAa31KbICk5d4oyHKjwi1T6J9jPYpUkORpo6nbX3SzEDxGB6kV7muTUXrvf/iXbz9xe4X0YiSUr4EO2kTSntMSK3SQlu1rhHfsU6Lq83cSHhbVbSDAWo4pDIGr23xqgpVFBjoQVdd03a6XVVVucpVnlPXNdoYPN+nNoamEzjVwyF6PHaCqAIUheQqgVkyVbHzEY6WtOmkBSg6WEpBYWCo+/Mi5F0JPpdmuKLRI5wT0fcShWrZr4zECx9FqV6ZPMvcjWE+d8ciXC3hze3tuYA+HFKvr6OShNrz8MKAoliQ0aBx2jQVUCxnDOIJZZXTNi1ROKAqc2qcrouTenBl/BYXK68UZL6SlRvRy0rIeDn/iiW4SpYIk9YNbF+AwVkn23Ae18K4dPkafumt8L2vhlMTvoVj/CJ/j7jTuQkwzzkPyKd7SUXiOtY4yZBFZzWsUfgYgs5cRgcBHN6kCCzt1hZMU4hU7zno+weTNqmYSDIkLTs4OCUsQEYSqeWyf87q9S2TiMLxksEYoQRIchAbUwAAIABJREFURU2q8KJ/Fce9vp5U8KUqJrFE4ttjrbp271FAnchfWI+BiYjQ3MA6QwKKnYSTm0efsc/raldLy5KSBQX3sMVv82nef8efwX/4DNDAyaFL8L54L/zJXk+AvxXHffw0fQXZA77tRfBPTvOKF5zgx9StHGVtf7KvaRtoavwamrpyU3pKO+K4DZnuzjh25Ni+1c6qafSlP6s+hmKj4/hQiks9DJu2axFeJeh6olUuaSs2V0GcD7QjJ6R1RtlUjtvlCQz1aD3Xkq+qAtWCNpblIsMfWtfG9CxFmWKMxfdDqrqiqJwbJTgrrcgfMDFDlumUpMyw2vkgyjKeJtIhHg2qbWlbD6UVVllsq/FRTtra+OgW2jxH+QFtYPByN43oD9cw1qfuPJG9pqJWLW2W0tQNxg87Y2p3T66XC9I0oaXGjobYwRADNEWBrT20MtRtTZUv0VWDZzSBDQmMRfkhnjF4RUHTgg4iPE+x+Pk/e5a1Dn/zf38Xrz3Sqz0LGJDAB72UgQQqKcsLp2FVrR36xyRYCkBZLGi7bK8JQ1rfp8Zdu17TOP554Lt2YafR1XZiqKrzPavz3OlpWUvt+7RVhVcUKN9HhyF6NHLu3lXV80BEwl/kGOQ9ihyESELs7bnnjUZQKGcfIkuCrbQSJXMWLSbhVQ0G/RSjZNvSqhCRxMiZPh8QT5xMemK9yFNAL3oqVcbZzAW/4ZBmMoHl0vnShSFFsaAA2qZm4DvD6TpPCeMReXeBBjagKgtq1RIp2+m+QNzxtTzY92S7dH2lAMUdd9zBr/zq+yhMxXef+g3OyANGwfs+0yvAf3EON+HaGA8C5+gDv/HgB18FP/st8MabwPO4hU1+ie9krVNED7spnae6nutAS5ZCsU7Mi9jAollQ7d+MAiwhGq0UejKmPLROdWEO+bQHKCIHIdeDAKUuJhwQ8F0lpI9G7rXb2/1kocQkiUdScRa1+dXtrj4u16+InZZl34IUfS25plcnHq8EsuQ4pYqWZY7L6Xnkvs/ADwkwHO8mO9nOuG7z6DWf9nXV4oJzzPl97ubf3vH7vZXVr38OXncEtu+HM3e5duE6vYzDBPimV8LHt4AWQgM/dQv6xg3+R/VGXseNzkGkaSlqd4Ne82J8bQl0sG+xIwBoe3ubQ4c2n9L7ERC26mHY0u4ruwvo8vAet83YdtIR9T6X6/JA7VLA9Xg8Lq0E6EBSp9RNTeAZfM9R9PEcYKobN/2fzBYcOnyUvHXm2pGOKLIMPAgDN2CQlxlVV9XzlEJpy3qwRtuUzLMZdVMTKXe+wVXaAh04Y+gWZ8nTunutVZZIh/itwmjrxDfywsk4xbGTVshT/E7lvW0a2tajKQrqttMlWy6hBRsPUEGENpamKsnnU7LlHM9a7GgNYwLausRvPQIdAh5lmUOeoRondurbgMD3sdHQ6WplGX4UsvuzH3uWtQ5zemK38IREyVmkEGQkW7LHVYsZqSJJgBIgIZUiMXyWKpKouDcNTTdJlGuNl+fYuqKtWkLfpxwOqYvCtTTL0uloRBHkOd50uq8Q30QRTRDgdcBHeR5BFNGORpRFQTufu8AnoEv0cuS9jcd95pznDsTs7YHahGMdwXWV5C4WAAKIRL5BdH+yzIGjPO9bDnJDkXarcMYkgxci//q6U6bf2nJ/f/BBt+8bbnDHKQbV8zl86lPwildQHzlCnSSo8Zg6ithdzih1Q9t4bA4HJLMUlewyCMdsJRfRoxPExrCXTzGh3jdUNXisE5FSorsb57VYd9xxB29605soioLWVzS3fR+c7ubHX3cSvv+V8O47hdkKf4ADWA1u7PyWDXjJKfiel8Pp6/ZB7SuAX+Tvs9GZKgeYpwVkfS2uASFv5Ca+jg3+C1/iDHsELDrOjWWATzDUnH9hQFqeoTl7tgdFcey+43t7vcDoantOQA/0HqYy5HLqlLs2pLWXpm4bkjSBuxbn837SUMyho6jX4hORYOFS1nUvASPkeZGF0Vf5HWlblxyJf6MIu9Y1O/WUXR3yALvcyCHirn0YXsN2dUPDnJw5OR/mS/wcH4fbHzggy8Dv3QVH73EvOEUv4/AQkB2F73sxvPnV8NGz8NdOwi038CPqVfz19kbKOkc1LdazjHXMWEVfcWCpPLVf7Wrbdp/7lbXZPmldwMdjrabTFitprig74XUtR4PabyleiccV6QBfW5I6I61StKcZao2nAqynUFYxrxK8siLCoMND7OV7LKolvh9SFhltA3E0QHmaNFuwoKVua1o7olU+42iDwGQsiyVb6RbrdkxoIxrlFOxDHWE8i60SjB7i65JZMadpYd2fMGgihsrnUWUwRUKyTCl8SxE77q9VHpPxJnmxZJnOKdIlVV7Qhj52OacqSuwwRoUhfuhTL3OKZM72+TOk8S6j9aPEG+vUiwVeWjAKhgz8mEWRUC2XqCylDULaOCCwEXYjwB+MSHe2n9L34hrpaHVBajzuq0ASaCQgSeVHyOMCWmTCRojoAiaWyx5giNaUKLoq5fYFLkh2RPJ2NKLoKjrOsFJhum04qf8aUxQ0WtMIiTzPXUCbzx35PgiolaJeLFBao8djvKNHqfPcccaWS/ce9/b64/Y8d5yjUQ8Gl0t4cBvu2XM3hbW1fgAgz/u2hLy/snRBVvS1JMhK20ImqmSMfDbrwZYQ8NO0H5M/fLhXuD93zm3v5pvdcUgbczqFz33OnYfDh8lnM/y1NYowZJbOqWxDVbVMhjHtNEFrn9gP2Fpc4OjoGKiW7XyKCQ2eN9mfsBkRkFDiXSM9qV9533vJsqwTwm1c8D99qh90+Hsvgn9/p+OKtMDZlRc3gD+E734JvO6E+87hLqz38kP7ICvq2obPrye/FIrr2eAfEPMRHuAuznOOBQaN3ynNe7Zmcf1L2dvYIL/33l7ANwx78riIj0oSJhOK8u/h0F2bkozIv9u25z1K8ibVLYlDwscUGy+RcJBBGAFVkkDJNS1Jo7T2pSL/eCtJ3M947K7fLuFclCVTnfMwCVOWpKoko9o3mb4Wa0pGQsmneJhf5DYygDfe4O4HRQ1WwXjny1/4EPA+oLkAv/O7cNs74Se+CTyP13ubvK28mbZtCHTIwIb4njlgan+tlud5zr9QW9rWVbmyynFwxdfwSlWulnZfFPVqAJdF7w/yPBbg0iiGOsJqS1GX5FXuJvO1YqwClMEdV1kSGMtGsIZSmnm+QPshRZlilw3DcICKFGk+Z9E4iDcyA9ARoR+iPI+yKUmagmyZMvKHRH5MSYOnDNqOMdWSlBYbrLMo5izSBB1FHNabRCbmvNpiu1wwqxK8Jkf5A8qmpC4KIn+A8TS5CcjznDxPyW2ArnK8aYYXDmn8ABUHWN+nzTOW2ZLs0fsYjg4xGK8RBCHJfE7oBUyCEVVbs6wKmryArKAODE0cEAUD7LH4KX0Xrk3r8Jd/5l2846X9VI5oQAkvaHVKRzhPnQEvi4W74UugEmA2GvWBbNV3TFqNwnMSYCMTfVm2b1nTNg1NWTqvxapyppydzpdunciqgKt9nR6pGFWdkNtsRgNOUFUmIKWVINOTwkcrioOAUq+BXznwM5/3QNH3+/H01baDqMVLxcqYXsxUWrCr/07TPsuX89A0vbL1ZHJQwHFry73Po0cPjr+L7MRw6ABl5MrJRZWTqhyFhw18ymROYCJa7ZEXGVE0oq1rqroEbQg9000iGgyKkgZ7ySTiM90i++gdH+XHf+zHqeWmtjIluJ8E/NZ7XBtjCuxeZiNnpvAbfwkXMjgUw6kJH+C7OME6ceftFz3NN7ivldbh5ZaP4evY5DAhC+qOJtw6DZ1FxXAUoaOQ5ugGuXy/hVYglAOpPMm1JdQFqRJJa11iitjxQO9DKq0/SURE/0mub7HlkWsqy/pKvVTmhaMq379VVfnVqcTHWsLPEs7X+jooReP7aN95jW4yQM8qblo7RtxdYV/ptaRgRs597PB/8SE+Rsd5OxbD64/DiQi+LcahqkvWZ4D76OVSbpzA6ZOsex4/0Xwzr9DXsWZHDFSA9fRVa2Ptbu9w5NBh9L6kgu68Ib/8R7Sw+v+uXtUd+qlAX/toT1O39X5r8VLT6Mst4XE59foryUOojvP65RrK+8fSvV+UwmrfbauuqRonFrrYmzHcnFBXBb5n8I1zTcmrDK0tVVNTVjmxjfBtQF7mFI1o7jvOl9UdId4DY0OqsiDPl1hlCFXg/q59bKugqbB+hPY0ZZZQeg3WBKz7E0Jl3fS/UjR50QmdK5q6RimNURpjDEppVFPQKCcNU5clXlm4S0hpTBijfQt1S54vqcqc1mtRkUuM27LEKp9A+yhtMMZH1zVeljtZCOCRf/6BZ1nrMK567pLwJOK4z+KkRSZASf4m4EDaaFtbfdVmlQNVVT2pVBSiBwOX0UrwEmL9YuFE8ax1gXU8do/P59QCpBYL6s5gUgNNWToSvIiPXjo9efEi1cWLbn+HDrljFg5ZlvXEWgneInGhGph0AqPTqassidGtTBHOZj3/S0CctC5WLUOSpA/6QrIFt/+dnZ67IhU/qZ5Ju1CsSr7wBbfPm25yx3jxovv9vvvc48ePO1Pq8RjTtszrisbbo9EThpGmSc5xbHSKjIKt5RZHB4dJspTz5Q7a9zq+DRzBjaTPyRl3g8jP9Gppef/tH6CouyEDD/jBV7tqlghN/vzPu8dO4bgiD+IqWwp42bpT8m+AvIZ/90l436f5ydv+NdefPkyEJcQ87SDr+eVuFi/iGMeZ8FEe4C4ucJYZCTMUEQGa0CiiF76U6fo62YMPumtKWvbQiyDLNKFUhEXh/eGHnRyDcKDEW1RU4OV6WzWuXp1wFI2tMOyvc9G9Ep0uiYOrCdGl4Ovx1nzeTzjLUEtRMKsKtk3Kg+wQM+ACC9aIiL/C7euyU36/wJzf5E/5/7joHpDE7TVHwT8Pf/Rnl9/A33oZfOyefvL39ScA+FH1Om7RL2RAsO824V8BZMmEn3gUBq1+SlXmtrPl6e15HodT1y0h1kuVa1ku91uORl35eKRFKADwsUCzM7x+7AqX10mm5FTQVd38umBaJXhlzRohC6tJyhSrNRtmiFGa3WyK0ZaqKUnzJb4NWYsmLLI5Sb50Taa2ZmxGBMZia4+izonDGNPAMk/Ii5Q4GOFrgzYetjEk1RKjY/zIMs9nZE1BbjVr/phQh8TlDjN/xFa6zaJYomipjUelFLoxxP6AQhnyPKNQ0HotZVPRJgmeKcDPUUGIXh+jk8xxzpqaoioItI+1lqDKiND4KqD1arxwSN425EVKuXwct4bHWdcGaFXq4BSdZJSrNjWdAN/+pJwAJgFKcbyvHbOvsr5q0irbFQ7EdOr4YCL9IHylycQFKanUeJ4DG5NJb7OR5+718zm1yElIW0BAjAA9kadIUwdoOhI56+u9OKgQ0FeFRfMcWMm2RXE+Sdw2hPQuP0nSAy7P66tTchNYW+stP6RVKaB0uexvMgK01tZ6z8XBwJ0/IeM++qgL4C95iatuKeXO1cMPu20cO+Y+1snEWYHUFbW3x2EzorAe9fIRTg6PsiiX6GyXQ8E6SbbgvGfwrNdlWCkbRIBmRsaE8BnPvM8z5bZbk751obv9feRBeMWkB1ngEu0HgLcAKfCSGyAZwj0z99puhNIrGtLbHyI8bYmwDAme0ffwtb5GRPxNXsxJxvwpZ0mbGU0HtAIMPkvsIc1sOGb+4P2029t9i0+Ak9AMJPEZDnvV9bNn3e+SpHWacvscLuFfxnHfXhRbHbmWJbGTKrw4Roh1j0xBShVMBEuvdgnn0vcdef/QIUhTsihi16ScYc66gossOUlJ/BVUim9p2SNlTs5/5vP8In/ZPdANDLWtc774oz86+EK53r5hHX78zfDa18GHvgSvPwlveAFvNdfzdl697+UI7FejVteqx+DT3UrsgVu/hMwuGnBXfP2KFENZl/tyDFfTVhTA5bS2njzgCjCU3WO+9jmsfcZE6Kol9jxaHZI2Oar1mJgBXugxzee0qqVpGsoyxxifQTjEyxKW5ZK6baibhjV/TKAtvheRVs6wejJYpyxzZukegfaJ/SGeDrDWON4YYII1FtUSU5akdY4xmsP+BmG1ZDAOuVgsmM63SPOlEzrVmqaqCZSPHxon26GgaKFqKnRRUFQ15AV+EGGikCAcUCznVMs57WBITUOJR94aBk1DgFObD32fwWCdZZle7dfiMT6Ha7Hq2gUZ6KtAUk4X8CHkcakaiZaWgKrl0mWdklWORgcrYFLyzzL3fwFcs5kLrmLtI6BJ2nyr3mmjUb/t4dAFXqkICfBZVYGW1oMQ3qXyVhQOlIh8gpDsfb8P2GUJddVxfvw+m+0qaSyXDtzI+RCx1jTtOSPCC5G2qFTtVhXspZIl2lqSga8o7h8QZJWWSpLApz/t9IlEh2t311n61LUL7k0D6+vUyyVJ01B6M9aimGKZ08xrjsfH2E33UNqw7g+YFlOU52GNBEGPTUJAM6dg/AyClIfZ5Xt4L584PXScj/d92vGw/t1fwLs/Bd/WOvPah3Aj5X8B+3Llb1DwnoehbBw4+/YXw/u/CHWD7/t8861vJMY+o8f//OqXQvFKTnKCMVmxw5KQsyzwcVydEE0YWvwXhiTr50gffrj/jostzu5uf03PZu7fm5vuej1/3rXzJSkZDnt+qLT0RZ1e2vkCtqSSLfQGMXBfrcRLzIK+qn8lDa3Lre3tHtwJRyzPmYU5F7wFD9iWGRnbLFjv1Ny+EmtGxoycj3Ef/wsf6x+QmLW9DR/84MEXPQS8F1c5/ugM3rYFf/U4fINzyDihFP+QWzjGeB9kiaSDrMer+DxTSzSvoAddV9K9kiVcrlWZCF/7jwu4ZB8CJh+rmnclwCXyOqK1NlABR/w19poUqiV1q8jaAtW2TEyMFypm+ZyszWlp3LSiZxkEQ0yZsSwzKmqqvGbDHxOqsGsf5uzRMrYRmyZiUSRM011CExLYiIkdEdQ5izrFmiG2zggpWVQlqQcDHeLVLVF4iFk4ZHuxzWy+TapaKuNRFjlN0+LrAFVXGOVRBpa6KmiqGt1AkcyoipQmGhANR7RVQ57MqU2FHw2hqZlVFb5XMvQCvDyjKjVh+NQ4WtcGaE1KlylKS0w4D1LlkuAlAUlAlwQ/ERJMkl7WQDwDJTOV0WppT4px9WTS69eseqBNJv3ET9O4be/uOnAjQO/o0Z4Mn2V9FU3ADfT7M6b/t1S66rrnN0l1S9oWQQB+A6ruwZq1fUtPwJB4LQrZXfYjGaJINwjBFnrAJIbXEuBFYkKqhfJ5CLkeetAngqh33w0nTzqBU2PcTeiRR/rpqg50NUlCVtfssKSII4pkQZk9wonoGNuLi3gjj7EfsZvvYpRGqT6YHMJN7c3JHzcrfDLrDDt8F+/m48ITOX3KEeDLBprW/fw+/YThanGhBT7c0JMgGidM+k9u4Z23j3nbrW/hltO3MCG45mTcr7W1yYg35tdRsc6f8TAPYLshBDeI4CvF3pHrsKMJs4fPOOqBtPKCwP0+m/WA6Px59+8bb3RAS6rFVdUnK0Jon04PDqCIbt3qZLCIGHvewUQI+lgnXK8nArKgj51Z5tr7p05BmpIMBmzbhBEN97PDIQacYMy4u8aeybWkYJeMuznPP+T9B49VYtGf/Al8ft77GJ7C/VuuubyGPz7jpn87Pt3/wDfzKk7ugyzdtQwdKVzta0Rd6yWgy8e5TYhW1hVfcxnTaKucdMTVAC7VEeOfKOAyXTs17068j2FTDbC+IWhy9uqEaZnQVjmTYIAJNNNyRlKmNE3t9MS0xtqAGI+yLkjajCIvOeyvM9Ax2gY0Vcm0XTIwEaNgSO3HZHnCLN11htNBjPUMfpUQeoYZS6xnCbyaeb2kISAvS0YmwB8fZxCN2Nm7QFIuseGAvMjIyhwFqLp1kg82otRO2b4pC0xRkhU7VGFKGI0w4zUoM7LFHm08QoeWuiipaV3cqCrU4gouDVexrg3Q2uuqMjs7fVldgp2ABhEmhV7OAPoql9jJiGCfABBppwlAk2oZ9OPVSvXBVKYdhZckbT5p3WWZ2/fZs70t0GjUTyKtjm9D/7uIiAqokvcigqBiListzKJwtU5l+vaocNekxSAj5lIJK8u+xSqcsSjqW4PQk3ZXz6lU+aRqJdwO4W7FsTuvq+1NaT+2rQNWWeZuQL7vfj97tp+aKgoHStOUoq7Za5cUsSZP9iiyiuuC41SLCzA+ytgGbKc7eJFHoxzrARzYKoCFVzqtlqcpcN7Lo3wX/55PcUnP/Y03OMucRoQogbvhsoLaLe65XusqWrfeyL88/Z287fQ3sE70Fa0YPL8OLoPhFZzkOCP+lLPczQUeZU7UceV8EkykCG5+MfPJhOzs2f5aPXy4t6YSF4bZrLe7GQxcBUYkUmQiWirmQowXfUBJbjY2XIIl2xKpGjGAl0RtPu9b/FfLz1pdFy86pfjdXZeQAozHTG3OOVq+yDYvYINdUkad1+YztXIqdkh5mD1+lN9kv/EiSWxdwyc+4dr0Ur3SOMeFbGVDLTDN9gelvoebeDuvIOxuXaqTTfE7APHVugTgiLr747UWLzWNTspkxTT6sat0DS051f5E92Odk8sBLrEFk++FRjEhRCuvA3sB02LGYrlH4Mes2zHG08yLhKpyQERrp6beFu66UJ7iYr5NZgsmZogxhqaqWJQJjYmJPMsgHBPWFVm5ZDfZIbIRa3ZEWucErWLWZhivJDATkiZjWicsixzla5QdEh4KmCVT9pJtrB1itU+aL6iaGlOVNHWF8QOMb2mMpSlyqBuK5YKmyDDBgHAwxk5CymVKU+QE8YCiaWjqkkoZTPXUnBWuDdAqfCcdUBQucE2nvXefVK5Wq0GrQqYyOSechOGwJ7iORj1wWi4PqrRLtjgYHOSHic+gAI6icFpSsr1VgVHhg81mveK7SEpI0JVpIeFnLJd9cBYulzGugiaK1TL9pOgrbwI4RVNnNOq5WWL3ISR4aSdKG1N+Lwp3vDLdKcckGlurmXMU9QMEcqORbFxuIPIetHagbD53gf3YMZf9P/po3yotCjhxAoqCpmlYeB7lQFEsZiQ0XOcfplmcpxkdYdxatrIdiLx9I1QFbBBReg1TMsZPg1XPHTzID/I+vnA59DSfw4ta+Hz3uwZeisuuL3267Y6jacGDr2fIm3gZ60SsEVwTiYrn18F1lDF/k5DjxNzJOe7HMuwETgMM294S/8h1TEcjkkcecaryUjmOY3fNZpm7BmTwZjx2AEbstyShkyRQOJXibyjX1+5uzwuV7RrjrjnhnUpiKLFIBmaeyBJSvlgI+T7M58zjGJ+CL7LDC9nhOkacYIx9hr6nJTW7pFxgzj/iN3lYHvjYGXjPJ905eV0If37XwYqxWO1sGw6Uke+6CErxckL+e97AiBgP5983wn/G3sczsRQKv4tjjyfFAJ3QpwnwW2epsyyXVw24RIvLPgHABRC0bsKy7sDXkABFgadibGgI6ohpvodXewxsgA4UsyIhqzICz0MpTRAMoFjS1CW+DlkWCVVTMfHHWGvwqpq0TGhtjO8ZAq0Z6DFxXZIUS3a7lmKsA2yjGLYVu1VGYIf42mdeJuymMxqrUEGAN9wgCEKms21SY7F+SJpMyarMVdyWS1ToO6AVRVR1gyo8mqKiSGa0eY4fDTCDEW3TkOcp1lOUNqBtatrgqQ00XaOpw8yV4oXQvrnpAotM9Ei2uAq4RM4Aer/DPO+zQBH/E50tEfBcvfGLXIRwlSRYFkVv3uz7DgSBC5CyX3m+8CBE22qVmyX8JwmwnueyZHDHOZ/3hFmxzBiNeh/Huoag6wVL1Un2L+dg1XZHAJ20M7V271+qVqL7swrozMpHvsoLWVXhr2v3WWRZD2RXFenFDqko4IEHeh2uvT33uaZpf75Pntw/x7m1XIw8ynSbpG046U8o5zUnhseosJBepI2g9vrQIxyHKTnjbqboia6Sit/js/wIv8tlVHrg/XfBt//O5atXshTwpuvgZKfF9P90AqZVwzferjl2eswQ/5rqFD2/Dq4An9dwA8dZ404e4fNcIMKRfR/GcoEFJjJENw3YW1ujPHu29ykUzqfEGhmoGQ7d910SGLkGRZJh1X5H4kLTuOtC6Afnz/cJThC46wz6tmNd9yDsia7tbfdaAXddYjYj4Cy7fJEtbmKTm0g5zOjpO9ndqnGJ0Vn2+FF+jTullnXHQ/A33udageB0seCgBoHCtQ+/5bXwP63wud7xMsbAT/Gt3MghVNcqHD3L2/MCcur9KteVPQwFcMmkovb0vtr9Y632KsVPVwGXeLEWXbtT4THAR1E5gKs9/MgwLxLKuqb1PCIV0LQVRZHh+zFKQRgMKcrUaW+ZgKouWWRTomCIMZayhqpcMDAxlTLEGDxt2IzWSaucpEwoqgyjAwIMR7yYpKjwfUXsW2IdciHfIVnmxKGPZwfYNZ9kuceyTAhGh0mLJYvlLqXnUec5Xl2hqwAMtP6ARhdUZU5RVRSzKWGWEQzHeEFI09aoqgQ8mqf4Nbs2QGt1mlCqPEHgKiAS0KbTXnhUAJe0ry6tIFWVK5tfvNgLeAr3y/cPAiwJggI8BDytrfXColtbPbgS4LE6vr063bhaMeuETBkM3Dbh8oT9+byfJux8BBmNYNHCctFzoqSFIG1CAUnSUpTjEtApIoqrbVPR1ZL3Ir5uojUm+7AdQJDtyUj7dNrz2IR3Is+VsfULF9zxdUbe7O72fJE8d1Uv2bbvsxeFpOkOWZkzawvmi4Lrh8cpW0OVXqSJXKWoBeYqp+wQkANbwVW3CGoa5ix5Nx/lJ7nj8jjq3Dn4ud/pxUhlSetQYl8LHB/DL/4t+NRF+NW7oKgxvuWtt34rIwKG+M/qwP9cXSeZsEHAccZ8hnPcyxZDfMb4nGGO9TRm0zAfjUjOnaM9d64XMYU+dkBf7V1fd9eaVLBTcCHeAAAgAElEQVSgrxJLUibxTSrCUhU7etQBInGNaJoeeAloe7JLkktw12UnKVEScJGEz3GeF3KYm9lgk8HTShZvaJiRc4Ydfphf505WqnK3fclN5/ZP/vL1QuBH3gLVcbAfd5xJq+CVR/gJvom/zov224RfDYKkT9daNY0urwJwrZpGZ1W2b2/zeIDLTRfWVxwUMOh92QvhbJWd+bXTYHP0VOV5KN8jqVIsBt/4aM9jt56yTKdE4QjjefgmRHmaPF+ijaWgRqVzdDBGGUPhtRTVgrGJKVVNjHVeuCYg1AFpnbEsE9rGdYqi1iPCsLAGXxviyGer2GMnXaB9j0QrRsMNbBZg8yWB9QjGActsStqZYjdNjmOltU6LazCiyQrqqnQ+jrsX8aMIEw/wdECpNF75BKaAL7Ou0dRh2xO0RZxUpuJEfG8y6WUVhHwulRfowYS07obDXjX9woUejAiIk31Ju08se2TacTZz+19fd9o5MtkomakEQwFZsqRFIMFRFNS1dgFZxrrlb1HkJvQ6KYT9SlqaQuLDKOhNbIui17qCg9OFsi/hbEVR31aE/gYgLUGpmPn+wcC+algtoFfOiWTXAvRWp6qgn9YUWYg8d+9rc9P9vqqJdv31PcA2hjwMybOEos1JKZgmKScGxzhelRRpTRnVlF5NrlK2WbJGRIhhSsboCu25thP2q2i4wIyf5oP8soyUX7ruvx/++fucEKmiE0TsHtPAMZxQIt3ff+ML8N98kyPP3/ZOXnz7Lj916w/wN06/kdHzIOurekWEfAMnOMGIo8TczRYBmgkhZ5hygQTrG6JTUV/dunixryRLe1AplyjleS8Ds+rLKsBKrn+JH9IKXAVqIhQMvfCx7EMGeZ6IzIOsvT2XOO7u9pp8dsI2ijNM+RzneBGHuIH1p40ULyDrPi7wA/wanxWi1R0PwW33wUA70FQIoGRfEmV/3QO85zxwboUr2fL1t8/53tPfyBB/n5N1LURXn+mlUASoA4rwV1qr0hACuJ6IFteVJhUF/Fk0ORVL3H037MQknHcjaKtYVCle07LpT/BNyF66w26yTRQOCWzszK3D2Pndtg1L1dBmM2J/6Kx9bMVumTDSIQvdovGoMESez8jE+4ArLVOquqTJa+LKMI5i9pQmDCwDFbJTJ5imIFElTRBjjSUpUkyVYaN1fJOR5kvSaklZO+FT6pYmS1HK4Pk+baOp65osXRAUFXUUoYMAY5/adXJtgFbUuOxOQNKq4GhV9aBEREQFdAnJe5X/JLwhAUpisiqgTEjkQjKV19Z1X9FZ1aHK834fQghfBWhCzJfKlmxXgqkIH0I/4SfTfJ7XB1cBh0J0Xy5dRUsCs3DVRNZBJh+lKiWyGNKa0LoXW5XJRqnACYle2hqiSyaVQd/vxROhPx9S8RNz7DzvNc6k3apUf0MR1f7Dh93fZMhA1LlvuKHnvHQt3lmakrLDrE2YkXNxcIhjVcR0uSQPj5HrBYfZY0nJEYYMsMzICagZdnpAl4oGtrT8BQ/yP/P7fIRZ/7274yE3XfiG6+EDd7r236N05HbgG3HgKgUiHH9k9UZQ9fY8Lz39It59+ju5gQ1G+M/JwP9cWx4exxhzKwHHGPM5HuVedokwjAk5y5RdT6HHmnQwYLq25niHMl0ssUCSEbG8kdglau+rLUMRI7XWbaeuHQAyxiUkkmDKwIkMycj1+2SWDPZIdTkMYZACA7bI+RzneDlHeQEbvORJtuNXlwNZGfezzTv5T3yeDjDe8ZAzjBZ7nbfS21e9CvgoHMiBGpy0itXuJkiD5xt+4tbv5QiOzuHq2c/ta02syGyXNJZX5DT00hBVU+1rcfnax+or0xhkUlGU4i/XVtQoYnx8NAsKKhr8bq5T4QytRyZmWWfkZcHI+ASDo4Q2Ymu5RV3X+L4bvFDGcYObpiH1KtpiTtOUjIIJpTUkVcqgBc/4TClYUhFjGXk+YzMg0D5ZnZOWGcssgTxjbTAmD2ICa4g9y3azJPYqdqsFiTLEfoQ1PrYq0K17j1Zr521Y1+CHeLVH09FoWq3RtOBFlHWNWsyhKGn8/Cl9ptfIVNrrLSOEvJkkPfFcgtYqUVSI76NRL60glZhVa52ydMEReg0qqZq1bT/ZCH1LUfYn+jVraz0nScBfmvbVttWqzyrpXiYKZbsywiyGs53VD2HoHt/e7jW14hgWc6jSg1IRa2tuX/M5nDnTA7eNjX5sXMCfVKzW13vAKKR6kXEQEq5wQIQzNhz2+5EqlxyDEPhFciNNHahbze5lUlGmF7V2xy6t0qqCv/xLV807cqRvsUQRZZ6zU6QkbcWut2Q7Psyjas6D2R5D7WOZcIIR2yw5yoCJszxlSsqQAL+7UTS0XGDOL/ARfoE7OTCQuxr02/bLWxcSy17T/f/DK38DVy/3Ndx6I5vAP+PNHGfCBvHz5Pdn2YoIeDUnOErMUS7yBbYYs8sAw1lmbJGy0BZ73JKsr5M+8kjPq5JrfTUuiJeiAC6hM0D/b61dwhhFLhmZzVyyORz2U4erE8KrSc+TaSVOp267u7twfwWffwi++5Ukr7+e+9nhTh7lJjY5RMxRxk/6XDY07LDkfi7ynbyXB1Yf/KP7e8PopoYFDmDJk4aX2WAL1A38yF/BXj/hp2/9Ab7j9FsArqj6/lxcT9Q02iiDUYa6cfY+eZ1flRbXpW3Fy0lQmK76m1FRUOPhMcRNfc7JUTpCeYqsylFa4fkTtKfZzfeo6hKrfZq6pG1blDIoT5HUBU3VUNUNk3DC2AyZV0uCsiEwIZXnTMhTKkYEBJ4mNhFW+8Q2ZppO2ZvvEBUxwzhG6zEhlt1mSWgC9poF03YJbYMyburQzxKsNhjPZ1nMyYoMFce0WKq8wqsKak/haQ/tQeVBk6eYMvvyE/cE1jW6Q7Q9wVs4U8L/kbL7qoCmcI8ECInMggQxqfAkiXvNcOgClFSDBMyIbpToT8k+hCuxamcjhHVpv0kLbWen378Q5wXISHCUdt9k0gMt+ZEKnjwOLigCaOsAlIAZAZi+77LftTW3jd1ddxzjsfsRA2oRIZWKlIgxyiSitDlFrFHef5b15rtSxZMKl/i1yZLBgt3dngcn0hoijyHCshcv9p+FmPOeP++ee/hwz4vryPZ5WXKRhHldsD0cc9Y32HzJxbrghN7kKANOMeYIA9YYMMCSUlFRMSfnj7mP3+Euzl3uK/dHD/RB/7HWp3A3AnDtROM5QKYV/Fevhne+Cu/0KX6cv8YruY7DDJ6313mWLg+PE6xziCHXMeEzPMKImBifEXPOs2CGxoQWe6PPcmOD6pFHHDiSa118EuVaGXbIQZJFuVaEDylV5PX1vgov1S3xLxVhZYltTxRkiaL6jUA4hy8V8Av3QNXCu++E297JhdOn+AvOcjMbHCZmTEj0JNTiaxousOCD3MV/ywdZrD740TNw3w7oTjJF4apZt9NdUziXBd397nlOMqVtXULzzlfxf5z+bn6YN7gc56tcvuGZXE8UcGmliVX8hLW4wLUVc68mo/wyRX0PjwiLwuvI+2qf6TUjZ6BCjNUsy9Qp3/gjtKfZy3ZpgMgfUDc1STZHeR6BjVhWmct704pRMGbdjsiqlLLMCGxI7bVkVJTUjPCJcF6RGI/N4SFSP2Y32UbNS6JogNIBRiniKiO26wx1zE49JykTstrDCyf4dYCPOye2mrOYzvGiEDsIaesAr8hpiswBLuPjmdZJQjyFdW2AVqt7Mrm0r1Yn1URTRkCVVEuE/5Bl/XNlO1KpKsteKkI0r+TGP5v1+5RRbBH8XC3xC4F+1b9QKjsi3Cmkc8li5X0I8JNtieaWTEjK9vb2XJANAge4pCW4u+zfjwC4VZ9H0Q4TQn2S9MBuVaJBeFQiQyGVQwn60s6TfW1s9O1ZaZvKZOVyeXD6Urhwcv78LkjLJJZUzaQNLOdU+CkCbGcz9zkcOtST+9uWrK7JmobtwQBlNTvplwiDc2zYSecdqKnuOMvs9nsIb30BxekjPESy2iTsl3DaTPH4N60GpwL/aVw1y3YA6/tf5XhZwDt5Cd/OyznG8Hl7nefA8rG8lKMcY8h1XOAuYu5nhzEBjzAnRDNTFn/NkA2HLDc3aVYBlyRiMkizWqESwCTX/Kolz2jUD7EIT1Oq9zIII5Xgq12riuoa+P4MHqmhdMKNFDV86H44fYrPMef9/CVjYg4x4oVsPqH2d0nFw8z4BW7n5/jMwQc/dga+9T905PcWXgzcy8E2YQ2cA/7OKRfTfuDVLm7c/gDceiPvOH0LP8TrsaivaZC1ugRw2StY6qwu0eJq2oayLve1uKyyVyTOg9AxXJXrUi6X48jVlDhKedAd0w6pw8tWsaxSVFmjTYyOFLvpDhUF2ljWhpsk2ZysSvFNyLLIyJuCqqoow5K1cEJdlzRljjUBShkKKqbklLQdV09RezVBEHHIHGMv2SZNZoThEE97tFh0XhD4MQMTsKNj5uWceb6g8SPUMEBnU0yh8E3MYr5FXpbo8RAVD2iCgDJLqcocT2m88NnI0aq7G/GqltOqKrsQwQXoCOdo1X5GqjNSypfJOQE7Iow3mzkgMRj0IEQsN0RUULYpLcVVPSxRbpdtriqri0CnkMSlpQB9+1BkKnzfAQrJhuWxunbH2LZQBNDYnn8G/TFJm0/I7+vr7pwJoV7ERuVHqb59Ke9FBEtXpzBF7FXkKUQ5X5Sr5RiFrNs0fetRTLkXix4Qy2CDVA5XxRiFDD+b9YKKAoCHQ6fHtXq+65qmHrIXhpAvOVd1tiafONu3AX3tLHQ6IAQc1DCqa/jtT8BPfcTdbDxWVN0vWR7dzbBxj1cN3DDZ3/YbOMQP8RpuYJ0R4dN6STy/ru1aZ8A3cQPHGPJZhtzLkHW2eZA9LrAgwDA1GfaoIVtbIz1/3lVnt7bcd1uuO/EglZgi7fhVkWDoq+J17ZKaNO3jiSR247G7Nq4WbD1APz0rmlQ3li7K17gK7WsO7T/9U+wQ8RmOELNByCGGVzXQkVJwN4/y3/Gb3EFy8MGPnoH/9UOQV71lVcnlpVM+BXzqYfAfhR9+jbvOTp/iGxjwL3nrs0KI9FqtVTmGx1OcV546IA0hxHmr7OPyuOAgl0tMuZ1tDxRdu3HSUTi2SfG8AmMHLKolTVkysTEq8tjN9mi8hqotGYQjsjKjrAuGgwl5vmSeJmSLnLRYsjk4hDU+VVUQ6gBf+6Rd56KgYoRPgKXuPBoPjY8yy2Yk+RzdBgyMRbUNzTJHB4bQjtjxLZGJ2Mt2MR744TrWLLHLOf76cRbJLsnOHt4wxkYxamgxRU6dLqmbZ6NgaUNPTJcJm9WsT6bZJOgIMBDpB+FDiMiovF5+RNNGWoZy8xcO02h0sPqUpn2FSqpDAhAEpAgZFnq1eKm4iRn1ZHIQdMm2d3f74xWpBWktSPUIYKvqeWGiJr9qLySeiNC/91XOl1S4pJonU4OrrVXxQxSwKq1Gef0qH07apTKlKEKKwo2TbF4qZqtkYQG0q4a90H/OYk8ymfQAdmenbylqDR8/C3+8BW+/GW69uQd8t93XtwGL2nFBXnuiryKAO7bZDP7wD+FXvtDfgDych+EEp0B9R/d9VMDbFLz2RvjMGSjrfU4WwAsJ+K95LV/PiedB1nN0aRRfx2GOM+br2OPTPMwGMfexzaMsiNDMsCwCQ3D99SSHDlGeP+9cEaTCJUMvcp0Y03Mm9/bcNSbJThi6SnKa9mAqivq4Ibp2UoG+klr8QxycntX0ljbvBB6J4C03ww3KbTtyzgsf5gIBf85xhpzmBVfUgSupeIBdPsDd/GM+xJfBv492lays6odIPNyAyf0cTG4EDNJdw92QyXUofpm/yyHWCDHPg6zHWataXGU3CvRYa1Uaomoqyrokr/N9wHUlAVSQiW5H0BfQ5apr7oONu7biFEVKhTZDTJ0yL1PGJsRGG1xMd8FARUloQ7SnSLIZw2iNOBiRpXNm2ZxlsWAzPsTQH5BWOWFrWTchCwoSSioyBjQMsPuq9uvhGr62LPIFdVNjlc8AWGRLTKVYtxZfK2xkWRYLlnVBoGPswJJmC3S0jvUHJIuLNFmFNxpg/RATRuTJZfslT+BzuhbL1D25XKb5pLoCfaVKwJj8X8CTkMCzrK9yra319jdykxfytkwYCqgT4ri0CyeT3lewqtwNXwCfAJpVdXrhT6y2MIXQLxpUAnTW1/upSclaBaCtVos8D1rbB2p5v9IuFBAlIE8qXsKLkhakgCOpMsn5WfVfE49IyapXVeWlQibVPJko3De+rnvgJa0Q6MEo9Bw4OOi/KK0RuWlkWV/Nmkzc44uFOwcPNvCTn3daOu+5E37trfDNL3Cv/8ZNB4KkovWGU31bUCm47R74Tx8De9bdaG7E3YDq7v/Cw/oV+qz7b3vwfS+DN70JDn0Jfvvz8I6XwelT3IDPP+Cv8FZezoSnZi76/PrqXzEBL+cIxxlwiot8njGf5SIPscsuCdtopuTY2JDfGJEeOkT50EPOiko4nCLoK8C/bV1Fe7l033mpECvVt863t3s/xTB0z5MYd6W292rLUKZnX4X77tP9/1QK4ZarwsWx07ZTihr4LzxCy238C97GzWwyJNhvEzmidMUX2eIDfIGf5fb9wcEDq67hD+52laxVkNUCH++O4Qx8GQ5YGTIZAL/Md3ATx4mxB0yin19XXiLHcDXip9AT56WtKAKoV1Phgh50yRLw5fTNQjQFGRW+1vieZbeaEWrL8egwW9k2CkVJ5fhk/pB5ukcUDBkO16n9mDxbspPsUNQlQxtRFgVFVTD2R0TKMiUjoaDswJbuMoyhHRIon3kxo2xalA4xyjIrE6Bm0LR4ngIzwDaGvK0IdMAyNvjZAssCf+04STon7Yo6KowIhmtP4dO5VkBLr1R7oM/aBAysWtjIzXm1XSh6UsL1Eb2tIOj5XEK0FtkBCWySKYZhDx4uraYJj0iqPHnea1VBL+0QdzddOS5pG5w/33MthsMe8Aj3S96bcKakpZnnsJP0hPk47oHm2lrPNxPelADL3d3++EXeQnhTAoxWq3wbGz1Ym077CUAh908m7r0ID2yVlO/7/bTVqtiiSFxAP7EpEhWrn9elbRABXHt7rp0oGmJ/Mu9MnnGA6vfugsOZ+2xfFMN73wSfOAevOQwPnoFf/wS82Ic7H4H3brvXGZx32nm+vFUoPCxwwT9fhze/Ge7ahX/8B26fHz7DiVee4h2n38KP/P/svXmQZed53vf7lrPdpbfpwcxgMIPBACBAkAQIUAIxJEgOQVokxUhKSqbCaKHkMHHKlbhiVzl2Usp/KZeTSqWicpXL2VOJFTn5Q5WKyjQlWbQhUCZlihIlmVopkRCxYzBLT/ddzvZ9+eM7b5/v3hlsGlgDkOeZ6uqe2/eere859znP+7zPy8PsDCTruwYKxREmvJ8RZ9jkFJv8Ls/xR1xizD4XmXOJOQfKkEwti3tGLE+exH372/D004EkxV7PeNj8zk4/k/TgIHQTb27CiRPhfHvppXAOTSbhnL506XDW33UJ15OslgyhJ1kxnnuuP9en03BN6W6OfpkX+EP+N36A+3iMtzEm5UVmXGLBl778RT73+K8wO38mlPckJqVTe/nCN+H+KdR/0udjCcmSbfoz+t8JEg2ffRA+EzyQf5cP8TBnGZMMnbx/TsThp2KcfyVIWTEjo27rwzE/ZVO+JpVLYNGUNJR4DPpQaapRTHVOkaRcbK6wxHE8P8pL5UtoDLUJc2wn2QaLakbrWybpmLFNKRcHLOoZrW/YGe3QNI4X5y8xTcdsmZQD1VDrlhmepPOKNUBiUjayLRb1nNo1NCZlN8u4Wl6ldC02SbCu4rKvaTzgFZvJlMm4YL/M2FtcJc0MeZqzP7tCUx2QjG+sinFz3s2N6TvZRBERhUhKZ0J6YogaJI+LMiL+qbru87lELZP8KSEX4tsSD5h03ok3SLxQQvYk+mE2C6SkKPqLVFyuVCoQBcnauny5Jyuj0epsRCEnUuo6HLWTgmr6yIaDg377pCQpQ6ZHo1VVTVTA5TKsUy7q0iQgx0OOoxhyp9NeKZMZbkIMjx/vj0c8DiTOGBMVbD7v1SohzLKuolhNr7/ue6IJBBXCsb3LhPKHJ3zf3oOvf70ni1kGDyr43JPwc3t9FlYcOtoQsrCejR5z9O3lMW47FT7YHv/aSlnyzsdn/Kfn3sdJtoZA0u9CGDSn2eEWJtzJEX6XF/gaT/NNrjDBcomaPeYYo8k3LbO3jylPnQrzUoVwCUlaLgOhEiVdzsvFop+GsbMTxlZJTIp4teQ6cb3z5wy9Ygt99+z1yNaLL8LXvtZ7yKKO4m/j+Ad8nf/py5/HPv4k7fkzYfR67If8mY/3NyJC/HzXVfiT3deT9Dl08X2VqMdCxD77IPzDfwuA/4R38u/xvRQkwxirNwAyU1GyuF6tUxH6PK7cBlIxr+dopQ8N9K/WsZhhu5gId/j/KryDUEpxNNlmr9ln1lYcz45yudpj3jqc0Sx9TZ6MqNqSfb/PyI4oRhtUVUpTznh+/3mOjHbZKKaUdUkL5F3/Y6k9rbZ4FWyILZ5UG0bJuEuCb1mqlq1ii7Ipg1HfpuTKcFEtudLsUy8W6Dxla7RLnoy5OHsJUzvsaJdls2Q+m73Cnr86bg7Ryus+ikGUEOmyE5VJlBshJHGJEXrPFvRepDgnS9QeIQFiMDUmEC/oA1D39vpOuem0JwqyfmmzlrLiiy/2/q84uV1In7VhnBD0ZTrpDoxbuSVxWpZfOUjVqgIl5QVR69J0tTtSlDlR7CSNXciXdAaKz0PIp6hoou7J/ghxiwdWj8fhYn9w0Hc0yoU/TtoX9U9Ilhzz2Hcm+/tKBt8rV2BM8JY8qeDeDHYXcHG26lN7Cvi5KBPrehxuvc6hCB9MED6QHCEg8bPvCXfq3947DEu0acrfPv9jnGaXAd/dyEm5l1u4jQ3uZZff5Bl+i2d4kj2mGC5TsscSbTXFlmU+mVCdPh2mDzz1VLgOiXouI7+kk1oytJbdDFgZy3X0aH+zJg0r17vgnwIeBL7a/V9uJq5HtAA+9wL8/c/Bjz8P/9lj/fUB4MtPUX/k/6QWYvWTD6z6IX/+96OYlOiD23fr/EC03mME5fhr3e+NWETcYYQDwA9yG3+T84xIGA0k6w3FeqfiqxnnYVXlalxD4xpm9QyjzGHJ8eVIV9KFmZadSX6DlKuUh0OuCzvCt4r9dsFOskXRzDhoa2xSMGuXJNrigEUzpzUpo3REYixVueSl2QXmacGxfBfvHM5YJnpC7mr225KZL8lUglKaWhtGOidPCsp6yQhD2bbkOsEoQ0HDATXaKwpr2XML9pczWlOTJgm3bhznSnnA3vJqN6rnxm6yb1LXYeejEv9UrLjEP0tnopAu+YAXw3VsPJcUdCEYQrqk5BeP0ZFlitIkXi4powkZEaO3RDiIj0w6B8WoLqZV+dK6j0nQOtylSrK6KE9CuuJ5au0C0mWvaEmul6hkFy/2Ce+yXbKPMkw7Hisky4lH5kAgTEJeRT2U4y5zGte9bnH5UAy7sfdKMoDEGC8kcr1kGKfwC1F+OZwCTnlgiYRNr+QEPclqSVDRq1pwrR9EA99PMAS/853wsRPwR0v4yJ3h93LnbjTf+x9+P//VZ/4GHzv30df0lh7w3YEJOe/iOKfY5B52+Qp/xu9wgec5YMycPUr2KbG2ot7eptzcZHnmTFC3nnqq92fN5/1N2vHjffeueE8vXerPN/FgyoQHuU7FeAD4bfpohzMvswNfBf4JQA0//evw7AL+24/117jHn1wlVrDqh/x37oUn/uzllbUYp7qvD2/D/i785e+BNIEnnoLH7oBzp3iEbX6aj3KUyXfU/MI3I8Q4/1pmKh6+piNW3nta3x4a6F+JdBk0eTcn0aDZIOMqZdeA6ihMjlKay80+SlvGXtHWjsyM2VclZbvEo2lcw747YGrHZMUYayxlueCpg2c5WhyBVuG8I7cZR0zKkpalq1DO07Q1l5uSXKUk2lK3NSOTUtOifI3BYL2hsSMyvyTxmsIaLrZz2sbTqJYtM2ZUWC5nI67O927w2N8MFG3fdRP7rJbLVY+WEAFJjJdOPPFaiVIF/SiMoug9UNL1JvEQYlIVEgV9F950Gn4+OOg9UOLnEtVGlDfxNoiPSzKyxHMhpEVIzP5+d7Rtf1c6n69eRJMENgs4nvR3t3t7fZaOzB6UsFBJw5d4Cimpbmz0KpQY2aVkKiVCUeyEcMq+CEmMjfjiM5HyhuxHUfSdifLhIcrVZNL/TaWsK+uQYd7Qe7peqZsqxleBf0pfTnwvPbESEnWMvnTxeXqD8EOED6P33grqFPyWhk/cCp86HZb99754+AGj8Hz/6YcHkjXgulAothnxXk5xJ7s8wLP8K57h93iR5zngAgtmlBxQYnVNurPDYmuL+swZePLJUFY8OAjn8f5+OM82NoIpXuJPRMWSIe6S1de2YbLC3l5/4wmB0EjZ7gwvr2b9wdr//8HvwDefhfNvg4WGY9NVYvUT98OPvhP++TfhgU1Inocfa0NZMFaL7+m+f3Ft/bfcAvffD29/e99h/IE7APhetvnP+TBv58QQ4/AXiHim4mstKyqlsOr6pEvKi7ZLfA/rCMb4qrsAb5J3ZEtRA7lOOZJscqXZx3mFRpM4z0QnaKuZNzOc8yirudxcZapHpPkIpTVtXXFhcYmJKZgkI7z3ZDYjURqjc0rdYNEUXlH6ClyDRrEoQ0XEGovzHoPH1I4sHVOYjP12Qa5SXqr2qJOExioSlbLrFFnxVlS0vOnH18gFREqIQgCkNBjHKIgCFMcwCAmRDjYxhcvz44DOqurnlgmJEJIjr5G5hONxP14jnisogajxXEUx32vdS/2xKiU+COlaFLVofz+oVEIA6zHopC8VHjkS7nblubPZtU0AEjwqI3KE1EnEgyxLzO5StmmBHXYAACAASURBVJNShgyZhp7oyt9EIM0IEiOxWAQvnJAzKbnK30FS7cVLJTEW0JvjX8mvdT08RSBZchPWAF+iV63O0Y/POdU9X6CARwr4/nfBYhd+/JfDB8l/9xvBc3JxjjoygtRC1ZKnGR87/5de+7YN+K6EwXCMCbvcyX2c4Os8yxN8mz/gAhc54AIpB5QsqUl0SbWxweKd76Q5e7ZXuC5d6qdHiEl9Z6cPJb5ypb/hkxugpunnpEqHMfQK0ivh7cCfrj32+QvhSwGphr99P1ypIGvhf/4VuMvCLTP4nRf79TzIKtE6Qt/5qAg3PZ88Bu96F9x9d9+c1F1X3scR/hrv44Pche1CSQf8xSIuK77WbkVYJV3AYXlxXs9D7IMOapdRhkz1vq0NMg46z5ZGoZTiSLLJXjNj1iwwKAqfkHhNmmywV+/TVBVZNuKqW5DWS0bpGG0MtlLM2oqmahjpnMY1FOkolD2xNLSUylOonFY7lFVspSPKekHdVGTGMm8XVE2Frg2TrMDagtykjE3OheoKV8oSk6Y0mWW7ff2TE2LcpFmHSfAfyIe+fOjKB37cZSjjb0Qdmc+vNXmLQhUHcAoBE7+QEDYxo8eERL7HWVeioMnrxF8hJE/CN196qfcqCRnZ2emjFER5i438RdGXE6VUICb9Nu3DVff2+ouTKFRyzOIsrDiyQsid9z2RlcG1cdeSRF1IB6UQzbiDUkiXKGbQE1RZ12IRPixEGYuHhIvnS/6mso1CPoVwvhKkVPgM13YOxjdhXwLupf+geZLVEmL2Nnj0UfiZ3+xLI2UL//E/Be9RqeWzP/N3OHkx5fvOf5Rz58696tt4wAAQwjVll7u4j+N8lW/zazzNt7jCBfa4QMkBCTUtiV5QTiYs772X9uzZ0An45JPBm3X1at9IIx2HR4/2UxSkVA/9+Zam/Qiu8jWMCfke4F8TugDX4YHSwZd+O6hS/5AoZZ5VErdYe+3z9J2PnnBTZBM4lsH7jvYBzUp1wb+P8HHuIcN26UtDyfBmQroVPZ7EazTqVb1cAlGzAJx3h8OtnXdopbsyo6ZWMFYJCxQV7eFffdOOsdpytbqKcy25zVFtRZpscrnZZ744oCimNDiW9YLMZJg8x1Uli7ah9gvm5YK8mTPNN7uICoUB5tTd+CKoVEuWFiTG4lrHtBiz3y45KPeZza5SZAUYUCpBJduMmgWX6xlLDfUNvj1vkker+8CX8pr4lcQULmF/4vMxJtzhCVmQ8pMoJ3HellJ9iVHM6UJMYNUrBP1rRPWSIcvye+kQki+JixByJesXk7h4vMRDJoOthVRISVKS0osiSOqTCegW0kVffpS4BilpyjaJ0iclOdkPIXKieMm+xyOCYk+b7E/sHZO/SXwHvbfXPyZEFHpfmIwKikuUomLFA3hjsgv9e0BUunU8Rci6ei3ClycYb58kfEicIby7neq8JQ+FbX/sLPy9fxnIllaHKfCqcpy+mPNf/hc//ZrewgMGrMNgOMEmn+A+HuI2fotn+BLP8E1e4nmu8hIlcwwlLSkLmjRldvvtuFOnArn6xjfg+edXB7PLDdx02g2eP1htcJHzSrqm11Xi2NMoROmjvPJ5tSScS9Kv0nT/j4nWGfrEeUNQyr7Fanfv//c0/NLz8Is78P7bQWs+ynE+zUN8hDsZkXbjXQY1680ChcKiyUlwONquvPhqpUWBVvowFFVKjK1rado6lBuVQyuF0R6vFJnqfHkaTLbNXrnHsp6TJ2N0W3HUbnGgl1xcXCbPJpBYlk1FhgmzE5uKui5pjeLAVSwOnmdSbFGkI1wXZDrvVLQUTUlLYQwexbyeM7UjRuOcWTNnf3mVQhdMbMHcVaQGbA179YyFvbH36E0KLO2IgJSnxMAOvVolqlHsJZKSopi2ob/QxF11VbVaapRkeflAF8UnHkWzPntRfF7yuDwGvek8VuRkmUr1d5d7kYEuNsrHyfHSVWhMULNiMiQlQ3l9bHyP1TvZhzgyQsp2so1S0oOeIMpxXh+zE3csClmSfRPCJ51S8ZcQ4nj8jRDXmATK31FUPyHE63fkcdbVq0HRdxEa4CePwk/eCsaGzqnvOR62+/2n4QufIX38Sd595Ay//Td+jraqSdOUj5x/7HW8iQcMuD4shpNsc4JNHuF2vsrTfImn+QYXeI49LlIx6y76CUsqrcMMxZ2doFzt7YWy4osvhp8vXOhv6EajcP7u7696HcVrKk0mdX2d2Yf05cWfIhCwJcG3dSnagS/BNQLTemTE9TxhR3fhH10MA6yBw/mKX3wKPniWxzjGp3iAD3EHO4xRqKFk+CaGDIxOOgN90xGv10q61kuMQrzmrsS1NaUvQxSEUhitSJVmM91k1syZlVcp8g3atmFDF6RFwoXFSyiXkKQ5jfO0TVC3RiahrpZdJGXKfH6Fui4Z51Mao7seqXC+6W4fEqNJVcZ+M8MaS2pzNkaWvcVllKtI8xHbaotRMqZocq7U+zd0LG9S6VCFOzTxHogELiqUKEOicoiSEncixmXGmEzFY3vStC8tTqf98qVcFY+DEYIREx/5EgVIVDEhTbFyJORCIijinyWLS8poss/r5bSZChfFOIdKyJ2Y7eN9FqKU56vbEIewxt2Cso+SEyaeLyG3ki4fK2cxCZJuy7hz05hr76JjhVD+NvGYJSHNsvzXUvJ4OUguD/SkrKULLb0QtuO5ffhbjxyacO8/dx8/de4zfJy388y7foKvPP4lPnz+w0O5cMAbCo3mKFM+xj08zG38Ns/yJb7NN7jC07zEi1QcEAbmZpSUCuaTCW40gtOnw03NCy8E0iWp8QcHqyp1PM8U+uum1vCkWw0yfZJVogSBiK0nrawlN4Tlcm1kROwJe/hh+NTt8NGL8Lmn4ef/NMwKTQ08dpbHOMoP8wDv5Qy3solCkWGGkuFbBJLLBRwqXe1riIqIIcRrQ1sKWgoKFr5m6Spq3+BdS+WrYGTXGfsHL1HkG1hlyZzmRHGMy+Vl6nKJSQMfKJsSiyHJCnwdBlNn2QTX1MznVyjSoIK1OijODkdJQ4um1ZosyWjrGnwYeL09OsK83Keez0iyEalN2LZTcp29+g6+Am4O0VLdXYx0HcqHL/SKknyAxzEDYnYXE7YkysedivJ/KWPFzxe/keRYScyAJMFL+UxKX7GxXtQXuFbpEgVKiE5MpOTxONxPlhGPs2kamFWE1LXozyIlVVGWpPNI9hd6EirHTfZTSJd0J4liJ2OM4tmN6+Z0UaCEdFobypvxcYqJqRzn2PclpWD5G8evvV6ZYx0PEO6k487BA+APo+fE57mEGGsdSoK+e8Iv/DF8/k8YffZBfugz/y5/9dwP8naOMSHnnnMf5KPnzr/ydgwYcAPQaI4w5SPcw/dwij/kRb7Ks/wWz/FtLvMCs45wOXKzoGpL5s7RTCbhnLvzzr7r97nnQnnx0qX++iaZeLFSDkFpMvQG9WJtw55kVTEWziPn0frpuf56gFOnQkfhVjei5ANn4FOPwF97Fh7/FsVjZ/nhc4/xXs7wICe4kx2Armj42lLHB7y5sK50tXhcR7xeKyRvSynQJowOqmgZMWbmS2Y2xZiEq/PLqCRFKU1TtYxNzrxZULZzSFLSJKd1LW2zJOteU5cLrLUoYFHtU7gx2lqcMRhtg19LEsWUJUkSXFNjmxZlLeN8SlktqaoS2yaYxGD0WzEZXtETBbk7k/KVlMHkrkwSjOOZYWIwXy5X1aeYcMnrxIckrdJSyorn8cWG+Ng3Jn6sOI08Jmqi7oiEL9ssJErCO+OSpJARUdtiAqJaKDqCKEREli3kTf4fB6nG+y+EUjwccnyEAArhEvImy43zriS3a39/9Xexv0o8W3GwqhwDIZdxav9rIVbriEscZ+i7Cf+EnnwBh+N2/vrdsHUCjm0Ek3sTnfi1Y/E//hb/7//x+3z2Cw8zPXd7d7IPF/sBf3HYZNSRjpM8wx6/ypN8jWf4Fpd5nhlXSViYkrSd0+hQ2VtCH458/Hg4jw4Owo3nlSuhIefFF8P5Wpbhute2cHcFn1jC5wjnyC8S4k9EhSroFWELfJxgci8I5vbn6DsLFasG+BMn4L3vDQr4l5+G3/iDkEf3iZPhGvDwCe5+/+38sHqYMxzhLna4j2PortPNDOfddwT02hW07ToXX0uJMYzqSVHULGjIOpP8WGWkyobh7TbnoLwKWlPYMXWzxCaGWbOkLCvm9RJlQodjVYZ8rzzNqasS70La/aJdkPoU6yyVbkhtykSlNJ26hbIkNqVuKnTtSGyKTkdorambClU7Eoki+nPiJpnh6TOUxEckJElITOzjEfIVd9rE/iPpfpMPfelUhJ6EyOgLGQUTm8XluaLyyMgMiXCQIdYi24tfS8I95fnikZCBsnGpUjohRYWTcmJMYEwK46xXjubzviQqxyDuHszzfttluPVisVqyFAIWkyo51vL4etkhzgiLHxfVcT1sdH2skJCsNwJxFyGEuYXHgCnw/u6xC2P4vrvhP/h4H6XhfSBbbX+ye++pq4pfe/yLPHru/cPQ2gE3DSkJd7DLbWzzGHfwe1zgd3iWb3CFb5uLPN9a5s6z0A01FSWeQ5eIXM82N4OiBH0ntaj+omw9/bschmd5YPJO+NH74et78F//Ivg2qF6f1PCgu3ZAtaH3PZ4hKFcf+1j47j186Sn49x8Pc0n/hz+AX9qAR27jw8ltfETdw2m2uZ0t3sExEiwWPZx338GQ7kUAH5UXX454KRRjUgyKA2qyrlkkwYQ4CAMq32ReHuCamtwWWN+SJglLX1ErT+VrWqNQSUbT1CzqOVYbMq2ZLw/QSrNwS1JtSZOcsl4wU4Y8yUiVoVQhx35sE1zT0NQVaZKhbY5RhropUe7GStw3h2g506s74iOSD3xRicS3FHudpNQoREz8R9NpWG5MoERhibvnhHjEHX3y+5gorHcqCqkRInY4APpSv7z1aIi4a1G2VbYxHrsjPi2lggIzN/3+ComLvVzxF/RlTMkCk5Jn7EWLu/tE8YqPo2xrXNoUZWudpMm+SNlTFEI51tfrHrwRxBd+xWrEwztSuGsD9EbI6xGS5Rz8lfs5+s5jnP3ZF9h5XvHPP//PaJqGNE05f/5DZMPQ2gFvAiQYjrLBh5jyPk7zIjP+Nc/wNfssv9+8wKW04jI1M5ZMukyuq1ynR0Tr0IgS33wZAz+Swf/6jT6A9AfvD7MU/9G3AjnyhHNqfCd87Cz8978B7aXep/WJY3D7JnzgdAj7lWYX6Qz/yothOV2SvHri2/z4Bz7Ou7mN42xwF9u8jSOkXYjDMCz6uwehg7En1T4qMbruZ0HevT/2qaKgU5iSo3UF2YRlvcA3DdZolAr8QfkGY3Ia39K0Dpvk+ARcEwZGT6Y7+LqmaRq00TRNRWZzvNbMqwVaazKdUKqSuZ+TYzANLKoDCjvqlCxDWS9v6FjcnHd9ZbC7u4c+zRUfE/QlMsnCihWduu6NoPFMwHgsjxAX8R1JiRFWVZvYSyU/Q1iGkLyYREipUYiOlCLn8z7eIY6rEK/U5mZ4nah0QgRlpuBhJx69yhWXSuPynzwWK1NCSiVSIU7Vl/2V7wcHq8ciVrRkm+NjKvsur49N+loHkhuXOGMl7I3Ak6zm88T4TQ//5BI0F+Fnvw1f+Aw8chs0Dffbbf7q+z/Op9//HgoS/tWXf50nHn+CD53/EB889+gbt30DBtwgUgwlDQmWk2xykk0+rO/mj9Vz/Gl7hSfNHn/MSzzHjIvdmJ8DllTUzOinUx3enMXRNu85Bp/7Efj80/DJ2+HhE+G5H74D/puvdOc18PPfhJ96ED77UfiFnw/kyWjYPQKfvBce3A3XBskElPyu24+GmBQPKrX8yGOf4GHOcIIpd3GEs2yLG2e4ufkuh0JhUCtlYxeRLt2RratUpBgaFDVtULy0QieKZbNEeYWnJdUJykFV1yRpSo2nqkswGpuktK5l1pQUScrIpMyrGdaGMTyph3E6wilo2joY7m2KUwpSTdEq2qbGKE2a5KTmrRhYOmnwzz4LSqGNwSuFj2MXpAwnOVOxsRt61Wu9NLYeBSFJ6KNRr/QIkYnztCSIVMhWnPkEfZlP1iGKVZIEErWx0Xc8HhysRhrEOV9xqOl43G+7EJXcw8YaeZTfieomhFRKk6IyQR8kKmqTjBmKOyLjIFd5PI6AgF7Bkn2P1cf4NW9UefCVcIZVQ2+saJ3ahKcuHt5N8y++hXnPMR4xx/lR/TCf5l3k3ZDa9557hEfOnRvmqQ140yE4BVcDIjMS7jMnuaPZIdcFe2rBn3GFP+Qif8SzfJMDLnPAFSpm1OxxwBLHHKjlplDO2w+ehbOn4Tj9Ne3RM/CT74L/5bcD0Woc/Prz8De/F37hh+Ef/wH8X78PP/sH8P/8Efzfn4DvPdE3IWUZ/OYL8Ld+BVqH0oYf+pm/zofOfYhTbHInO5xis6NYajjvBlwX6x6vnISChKtUVF0JcUlDDigNxipmzYJUpzSuRmmLQlOVJVmaYuyIpilpXIO1CW2iWbYNNZ5pNqWsl9RtEyIe6iWpsSQmw+Mo69DE5WyCM5pcJzR1g1UWY2+MKt2keAfweY530aVFCI6QBkkmF8iFI+7Akw9+WPUMSTyCmNuh90+JOhbHIcTkDHqCFHcxShkxLrfJ9gmZkjmIi0Vvho8zvGRMUEzg4jlmFbD0feSClDXjTDFR9YRUxeRrXeWS4yLrl+2Wbsv4uIliJd2EMbGTEqSsQ5QvUePiHLM3Gqcs/EcGnk7g/g345gH8TgWfPAvf/x74+D8+LItMHr2N99iTfFo/xKe5f6VMMbSTD3gzI+lUrRhGG4wyONdyxEw4woSHuI2ad3CJAy6x5Dmu8i2u8Ee8xDNc5QpLltQsuq+5WlAaxSI1pFm4XzlM9/srD8HPfr0vK37w9nBuP3oGvvx86Nxtu9rib1yA953uSZYx7D7xNBcrh3eglCe5WHKWHc6yxQk20J16kQ7n3YDXgQTLFpp5R7ZyDBUtFZZMJ6TWctDMyE1G41oUNdrmLJZzsqwgTcfUTcm8rjDGoGxK61uuNnPGSUZiE+blDK88KFDeYU1CZgta34QyodI0xpImCW1dk96gJeYmBZaCb1uMMbioJOXjkph4DWKD9To5iEts0BMBiReA1Y7C9Ts9UXdikiHkQYielOVEcYvXFS8rVn5kXVqHi5KQl9hfJaVAIWNKwczDwq2W9uJMKyGOoqjFafjrxDE+HkIUJR5CfifbItsvJYEs60sP8jeJfWXyNxEyJj40iZ4QxNvxet6o0qGZpqALuG+nj+u49xj8nXfBffeFbf7CZ+BffIvtR0/xnkffz4/o+/nUGskCyIYOwwFvYoiJeL1FPrMZ83q+MrA3wXKMLY4B7+AEHlhSM6fkCktKWq6yZMaSPRoqSr65eIqT3Np1eWkqKp46t88TXzjF7z3+FS6fP0H53pP9NeEDt60Ol/7YPbC9zcQY3qG2+Cj3sHzsDH//7/5L2qrBpgkfPf8Y97LLEUaH3YWD8X3AnwcGzYgUTU1Fi0KhCcOnjdZk1nDQzMltjtcZy3ZJlkyYVXMSB1k2InUZy2ZO6SoSm+ESzaJtSVsYZRPqpmRRzkmT0IBXu5rUpEzSKVVbsWiWVKoiMQnNDYoIN2motMI6h9Mam6Y4rfE2yHPSbey7D2bftnghYfGHfGxyj6MEhCwIMRDEpm9RueKZikJQqqpXZ4SEiPl9fXbieq6WqGDSOSmqVJquZlfFhn/n1hQufy3Bi7swZdQNrO6PEC4hPbBagpT1xA0GEq0h64hVKinNxrlYsKryyTpk/2Vb5LjExHSdFF8Pknotx3BrC9wE2q6banMT3v1ueNvbDteXPnwrJ95zB/fZ4/yIfhf/Nu+6DsmyA8ka8KZHch2ipZUmMxmLesEoGaHUqjLk8F2HVk5BwoT8MNcIoMFR03KyUZzlzi6sseWAmlMc4XvOnWJx7i/zJC/xdZ7jG/oiV+0C++g25pdOUP/a07z9/Lu5+9yDjMkZk5BiKUgozp3m2Bf+d775+Nf40Pnz/KVzH6IgOUx8HyIcBtwIDPrw/VR35vjDqZgapnbMrJmH7KtkTNmUJNawXx+gPEyzMUVqqZua/XqOMQnGJHgNtA2ZzUh1wqKa0TY1eTGhcS1tOyexKRvplHm7pGwrXmUi76viJpUONWxuotoW3zT4pkF1H86HJMsYlLXhchGX0eRCE5fCJDIh/t16jpOUwGIvl5TzoCcFQjwE18vyEiUsHh0k62qa0GYt3X1SFoxN6rK94os6zKLykET7uE4s4+iLuGQn5ck4LFVI1boaGHcsyuuFOAmxFJVKnhN3horyJb61uBQppFSUPiFccRbYurIlCtpk0u+LtK5bC89cBL+A3d1Ass6ePTw+223LblvwjuRWPq3u52Pcw9e+/FWeePwJPnj+g7z33CNk2OGCP+AtAf0yqlZiEpx3LJoFhS2uIVt152XJSciwtN24lJIG3c2uG5OySU6DY0ZFSsImOQtqlrQcYcT93MrSN8yaeUh0+ECK+wAdbQv/FJoMy4SEbQoeOvd9TM/9ACPSbtRJML0PpcIBbwQ0+tDfZ6L3tEKx1DBJxszqOd5AkRTUbYXyMGvmLNqrTEYbJFZjfcKsmVO7Em0zjE0xDmgb0nyLslpQzvYZZRNsmgVOomDTFjQmp3br4xNeH24O0UoctXToxWW2OABTSnny4R2rTvGFJu5UhNXQUUk3l9cVRa8Grati8py40zAmOtcrUUo4aTxaJk6zF4P8+jDl2FRfRHHLiwqIvGJxFpYQt3i7ZF2iZq3HPwiJjBWneN+k1BeTVtm+WA2Mk+/lbyPKn8RGyPZK2W8+70upcQlYkKZh33d2VhW3o0cD6aqqEMK4qOGOE6FUeObM4Tbe0sARN+aB5DQ/qh7gPHfy1S9/hU9+5ONUVUWapvzyF/4Zj557PwMGvFWQYlhcJ2E7sxnLZsmyWVIk10a017Q0OJJuSLPFHJIuD+TekKIxKHJGh2TMd0ODKxwzv2S/nrGlN9E2ocbR0kbJ3zDGsknGlJwNckZdp5gMIx5KhQPeaGg0GaG7tiBZKSXOVcU4GbGo53gUiUkx2mKMZX+5x8HsMqN8g5G1JMmUWbtgUS+pjCExKZkONpk8zcOcxOUBqpoxGm/ilKeql1idkJnkhvbh5hCtognT6uOMLFg1t8Mq+YrJWJzpFJMkuDaoNPZSCeJlxgQq7jyMvVZCVGJFC1bjDyRaIiZscaBqTMjkteIPk7mJ1kIWkan1bkBZrhAu2a74S/ZTtl/IqixPtktHKo88V/ZFyFesrK0fq3VyKqQzzkATIijLlYaByaTvvhRyurUViJcMBX/xxfD8E6fhwXeEJGqlKLxns9HsMuLB5DQ/od7NOc6gUTzx+BNUVUXbtlRVxRcff2IgWgPeUpAYhHVjPEBucxb1gmWzJLfXjgTxeCpaahw6UpQc/jDTqL8KhmtI2xEt2gV167nFbGKMPYyXFALn8dhONcsxTMm6krw6JFoDBvybQk+22q4sHd5xhox9VVEkI5b1IrzPjUEnBVYbri73WC6ukmUTiiQnMWMSnTBrFjRuSWsScpNitcG0DlMoFtWc/asXSYsxeTahcQ5VvxUVrUatdvHF3+MP/LhsFv9eyFTstVonXrE5XDxWcekq9katSfEryeqx/0mIRpL05UPoVRvZlvWuRViNRZDhzDH5altoa6giciPbImXLeB/lOEgJcr1EKKQqJpWy7RLYKgGn68qdHBshdfFy5djF/qs4UFXWKWVSWacxgUyNx33cxmLRD7IWxe7SpTDTLc9DsOLO2+HEEYxSbDjHqEnYNWMeMWf4Me7nIU4fXuI/eP6DpGl6qGidP3/+5d6BAwa8aSGdehLaGCO3OYtmQdVWL5vt47sk7te2LkXTNCQOjiZbtIrDUcFCoqT8GPwyrIRQDhjwF4WYbBk0OQpNiyHjqlKoRIVUeA/WWjAp26Mj7C/3WCz2ca4hTwu2dEGSGGbtkrIpWeqGzBRYa8jMiEynzMycg+UBVb1kXGyF5d0Abg7RWiSYzc3wAekc3nuUfHArhY8jC5oG5xw+9kJBTwBioiEEIs7XEoiis579FHc1xpEIQhhilSv+Wbxb8nxRbxaLfn3d/hySmjiGQZQ26SD0HlQLk0jJikljTKRij5ase72bMA5dXY9iEDUtVumgzy6Daz1W8YBsKR3KMV4uV71ysh1pGkhVUYRg042N8LrZLDxnZycQLQlZvHAhmN4nk0Cy7r0XFluMFIwbyF3KbXaLR/TtfIp3cD+3rdxHP3LuHL/yhV/hVx//Vc6fP8+5c+dex5tywIA3DywGJ2pTBKUUhS2Y13OAGwpSdN6FAEgUk2R86P3ysHJemc6XNWDAzUZMtoDOg+vYQrGvFHRlRNtAblMq1bJZbGO1ZVbOWDpHmuZsmJzEGGY6YdmWLOsZqcnwJsUklk2zycjmXFlcYf/gAkk+vqHtvjlnz7imvXp1lXQI4u44WC2LxaqSmL/lOfLamJjEg4+FfMUG8bhkJgqMkBwhcGJ4j4lTPLR5XXGLOxZjVUl+F+9rrCg1Dcw9KLeqMCnVk5r1WAUZ+RMfg7isGQevxgqZEFIhZQJJqhdTekxeRRmMvWZC/ISgNU0geDIwO00DuRqP+yHVMjIpScJz8zwoWC+8EJaxuxsG577tbdjplHTmmNSaKRknk23OqzP8AO/g7Rxb+TAQE+77zr2P95173+t4Mw4Y8OZEisXTXGOOV0pRJAVlU3LQHpCZjOR1eEha11K1Fa1vSU16DVmLz6shomHAmw26U7OWNF1JO3gPNQojylYzxzclmQ0NIJNsA2sS5ssZVbnEm5ZROiLTBfvWMHeWuinBtXib0WpNmuYcs8fZX+xxaX7lhrb55hCtuvvQj03SMRFY9wSJKiQ/x54tITNCaIQYwGo58XEhoQAAIABJREFUTIYtC+Ky3npZULr74lKalAqd64dYx2UyWFWQYLVzLzadr/vQZBsU14atCrFb387YHxUrTfFxEcP7OgGNM7Jku+KcMejnBkpnoahk66n8h9vevbYoepWqKAI5OzgIBEuGZRdFXw69cCEQLa2DwnXsGNx1F3lRMGoadOvY1TvcYXZ5jLN8jHs4w/bKh4FFDzPUBnxHIsOypF5JjYcQ+1AkxSFpKtvyVQlX3dbUrsZ7T2IScp1f08EoGCIaBryZIdMGhGyJt9Gg0UqhLCyaBct6QZ4UgYjZEbowLKoZTVtzsLzKNJ2wbXNSrZmlhrKtaOolRieUxtNozWS8xTid3ND23pxPJ0NPNkQtiZWgmHgJeYiJ2LoqFBM2GX8TL1+UrXh568ZyQaxexXEJ8noxdBfF9UlLnFofZ3LFilqe92QoJn+lC8fmekRRCGisaMXlzfi4iBIlr5XHR6N+OeshrOJFk6HZ4iOT9YlhPy4tZlmfERYfZ1l2WYbfTSZhX60NCleWhWaICxfCc6bT8JwTJzBnzjA2hrR2FHpEbjXvMif5CHfwGHdxgo2VP1fadVgNGPCdCjHHr5MtCOnxhV4lXBJsKvDeM6/nh4GMVr/yZX+IaBjwVoCQrfjcsGi2yEmUwSSag3rGop6T24JUGYzJ0ZlmWQeLz9Vyn6It2EhHZCph3xhK3eDaGl+XtMYwNwlJcmM3HDeHaM3TUB4SUiOkaD1jaT3OISY1MQGLu+1iUiXLiKMK5DF5bUzS5Hvs71p/Xlx6lDiD2DcVPzc20sczGeN9jQlmCRTR9sRzGddJl5C/WB2LYySE1IkqJjEM8TEWwiYl0uXy2rgHIWyy7TJ7UlS/6ymKcUlzPg+Pb28HQjWbwTPPhDKiMUHFKgo4fZrs1lsZeU/qLJOkYFuNOKUyfoh7eZQzHKGvk+vujnsIIh3wnQ65W5e79+tBCJfzDufdNSQptzmjZPSq6xrU4QFvJcRdukK2FIpJ9+lgE83VZsayWZDbAqM0E51jE82smVNkE+p6ST2/zCSbsmsL9lXFzGqca/Fti3MV1bog8zpx00bwHKo9sOoZgmsJi/xf8qTk/+uGcCnrxQZ0ITmxWhY/f6V0p3p/Urzc2HgvkP/HJE+M7XG3nuxP7H8SxMTLGJCLqDwm+wqrREt8Y2JSh0Bu1old7GeLFTFZ1mzWkyXZZ1Gv5LtA4isgHOPZrCdXEtUwmfS/PzgIv9vZCV2FZQnPPx8edy74tpIkfD99mvH2NiMMuS2Y6JxbKHiIk5xeWs5zB5v0HxLDh8GA7zbI3XtFe41nK4ZW+hpFSx5/teVLBteAAW8lhHMj6aYe9OdGgcWisFZzpemUraRAK02uU4zVHDQzsnSE8y375T5ZnbKZT8iU5UCX1FpD66mbG8uGvzmfVnkZSkdxl2BMgiSEU0pxcTxBjDiTKv4eG9FlmXCtKX19ubHxvhuculK2lHWuG8nj7/E2xCVQUb+EAMXeKiE7Sw/pmnk+LnWKSjWZ9IpSbHSP1cF4eLYsK1bepEQo2ykdgqNRT9jKMjwny8Jyrl7tFao0DQRKOgqVCiRqNgvr3d3tRui4ENkguWlC3rSGrS3syZNMtrfJ7IhCZ0zJOMMGD3Eb5zjJRlUekqzBNzLguxly9+5wXZjoyxOu17NMi+4SsYZS4YC3LkTZis8LGU9lrWavnTHrPFtaaRJt2UymHNQzjDFMRluU5Yy92SXG2YTdZMxVlixMQ66vDQl+Pbg5REu14UNbMqTiFHfx+8RK0noMQUyc5OfreauE1AhxkeXEHYmwOv9PyJHkXMnv18nPunlfnrdemlsnS+s/x7lWmYFdeqWuLMNyYkIoBC+Oa4jH/8QRFrE6Ja+TLkfxS0kZUMgtBKO/KFbOhTKfREhsbwcVSoJHvYcrV8LzmyYQrKNHw/MvXQp/57ruyZt4tXZ3Gd92G6PNI6Qqo8CwQ87dHOUBbuEct/NOjvMt/hQYup8GDBCEFnd9Q4RLHxKs4Zwa8J2DDEtFsxKLYlBhQLVRpFiu1AekNsdog1aaaTJhXs9ofU2eT/BtGxLi6wWb+SaFTthTyxvarptkhld9WruQBQgeoYOD1bLV9UbPSMktNpPHfq24E1C6+ITcxMZ2ISvL5SqZE+IXk7j1jsU45iAOMxOyFcc+yDYL2YiVuKbpVaCXKli4ftlCwq5XUo0zv2SbZCizlDClJCgDsY0J6lOsKomC6FxQq4Rgye/aNqhW29uBlIkHq2kCkZrN+uXedlufh3X58rXBsl38gzpxgu2Tp0jzKSmWKQm3UHAvt/AAJ3gvp7iTI5iubVcGiw4YMKDH6yVcMrbEdjMVBwz4TkSwlVxLtgoStNGkynKl2ae1wduolGKUjFk2C3xdY5OM6XiLpqq4PL9IbnOOZm/FrsO267yLCVFMPiTJPZ4VKEZrMXjLl5TTYoIVK1jyPSZbQiLiDjz5v6wr9jPFy1rvQhQSJYjVsti8DqtBpLGZP8+DuqQMnLD9wGYhVLGHSo6DKFUytFqIVdsGRUpeHx83UQrjDLK27Y+xi0ietWG7ptNQIpRjN58HBUuUqe1tuOWW8PNLLwWCJf472S7xw+3uMj52jGL3VrIkp8CySc5JNribHR7gOA9zG7exjUGRYEi9GUjWgAGvACFc/nBwzioUitwbCm5sXtuAAW8VpFgULXU0XSF00xrQKUfsJvvNAbXxaGO7bLowxqetSxKbYdOMHZsxK/e5Mrt4Q9tz80bwxIoJHH4gq67kpyYTvNb4WBWKyQGsJrXHvivolaD4Ky7lCa5XQpTtide3nsoe/yzrisugcZehivY3Xlfs56oqaJdwNeo4jBU48Y3FpVV53v5+T7JkfaKGCeLtk+dKoruUBYW8ShaWDOG+erWPe5D9kyDSogjE69Kl8Psk6X1eEEhfkqC3tpieOEW2tUOhMyak3ELBCTa4ix0e4lbezUmOMx3uuAcM+HNAvcLMweFmZcB3GxIMClZGWWmJhNCwkUxD7Il3eGvwePKkoGyWVPWSIhnhtGdabFK39Q1ty80hWpXGjMd4Y/BtG0budEqQ7xQYrxRKa7QxK6F6Xkpn3uPbFtWpPF5e35ETZUx/bxd3N4qSFBMdKV3GPq91MibqzHrX4Ho8BPRqUhxyGqtIMcGKg0LnFopufUXREzhRoYQciTIGq3EO8n8hbnEZMx4uDX0GlvjDZF0SzdC2gcCVZVjOeNyvQ4jUfA7PPsvhYGxZXpKE7SxLKApGO0fJj50gH28yVikbpJxgykk2OMsRHuI4D3KSbYohrmHAgAEDBrwhsN346XhIuyJ4uVAwTsYsmgW+8TRW0+DIbE7VVoddikrd2KirsB03A60lnU5B60PVSkMgTJ1SJATMt224FxN1y3uUtSjAp+khsfJNg69rvNa4tu1nI3bLVQBVhWpbvAlM97DM15EyH+dOxWVNuFbJWjeex+U9IVnxMsRrFgd7ihom21K1kHWk7OCgL+l1+3/4XXxSsp3xeB4x2MeRFhKSKs0GxgSlKTbNQ1+ylHVa2xveY4/ZYhGIVPyY+Oqa5jDaIdk5QrFzlOzIUSbZhAkZRyg4xoSTTHkb2zzC7dzNUUZkb9S7a8CAAQMGDADoBlBbStrD0rqC8JhqKWzBslmS1p7MJixUQ2pSFOow7NTot2KOltPkOkEphVcqkBzNoRKFD4fDe3/4Rdviup9d28+mV4DyHqU1SkzeQrScQ3Wv9V0Zr429VlrTdARtpVwXRy/EBvz4C3qSFKtScYlPnhOvU9QtiVaQUT51DVcacL4nUx0ZPczTiuMwZHvFx+ZcX1YU5SxJgjIGfQfnYhHWHfu8ZH1izpcZhLJdouLN532ZMc/70qOoY3t7UJaYrCDb2CTbvYXx5hE27IgtMrYpOMqU29nkgU7FOsnm0E04YMCAAQP+jSEeRh37GDNM0CuSQLbaumIjyVmqFkzIn1s2CzKb39D6bw7RSlvsosEpj/JtcBa40D2DCqU9pxVegdcqlA67D3uPwndtmeEBj3edCVSB1xqV5IDDOQ+4QzLlutBQ35XhfF2jIKhpUnrsiIrSGpUkNHGXY0d2tChw8e+SJJDGjnR5ITtVhY/T02PvlahnEgaqczgRmdxjoifET5QkCUCFPsi1W9+hyiUkSoJchWBNp30JVYJOpQQ6mYTHRfGKVTEpZ8r8QlG8yhIuXgTnMZMtiq1tiiO7bI532dIZm+TsMuYYI25nh/dwkrdzlF3GQ6lwwIABAwb8G4cMo14fZ5V25UW6kuGyXlIkBZkyHOg6DKmu5ze07pvWdWjTFNc4vE7x2qM8aPGPO4VV4HwLjkBgvEMpi6PFawN1Q+sDCdDO43Copgbn8b7Fu6CIKe+x2qCMBp3gsxSKCcrYcKi9w/uuFNg6VNuiAW80aEOrQVkbyo0KnJCejsR4wDtH25U4XV0HIicJ7tJlKN2RcSBo7KtSChaROhUHnsbBpHEcgyhn4hUT9UkiHmKfmFKBKAkJ29gIz5nPA6mKy4KS3wVhHdNp+F6WwbflXHi9tcEE3zQk+Yh0NCXb3GBr+1Y2sg02SNimYJuCE2xyN5u8m5PcyRE2uLEAuAEDBgwYMOD1QEJ/1ycsJOhgJzIpWmnm9Zzc5mzpnIWqMW/FWYeq9aQqRWXgXRMUqbbFVQ7vHKp13URuj6LFtZ7Wt+BBuyYISRqMUiiToKzCKEubpCirQJlAnowGD76V0l8gSap14JpDw70yGT4p8Aq0UR0B87imxVZLqGp8s8B5j3aBhLWuwTmHd8Hn5L2ndQ6lggLnpTPPGLS1OCFJcZelKGJl2RnQWR3pE+dmlWX48j4Y061dNdq3bZ9mL8uUoFBRrYqiHyx96VKIYxDfVlkGtQz650oCfVWFzsKq6sft7O9jLl/GaUs+2WE0njDe2mVj4ygbtmCDjC1GbFNwmk3ewVHu4RZOh5Gff9FvuQEDBgwYMGBlPmJMtg6nI2gobMGiWZCalMKkZOrGqNJNIVo+8/j5oms41ijlsFrjtaW1XckQsF03oUeRokB7nNcoo/CtQwc5Ce8dznsa1+Brj1MV3muoWlrazkQPWkvEQyhTah3IjquWnRLmqVtH2zaBQGmFd6Gmq1rwuGDP8k0w8WsdVDOtcd5jkgTVdUkqpaCuaZsGVddhP5QK6lhcErQWNRoFcpcq0HWfmB9naQn5EYK1XPbm9TTtiZskvIuPSnxaSgUy9eKL4bXy+7YNJEoUr8kkkKksC8+7ciWoXFrD9ja6qjAXLuCdwuQTitGY0XiX6eY209EWWzpjgxEbZByl4CxHeCfHuYsddhkPSdQDBgwYMOCmI8NSr2VtmcP4B8UoGbGoFzjvyN+KHi1VavLptCu7qU69AvCYTsXxXoMKU+iV8jjXhvxNV0Gl8D5MsveNQ+HAO4xTeO0xGJTuSo4uAR2sX955nGsCkVOKtm5omoq2cWjnwFVBXQsOezAJKgndji436I5IoTXa990L3pgQQ9FFQPjOo6WaFlVXKO9J2jYoYFrj0hQPKKVovMdLiXFWQxIFmorBPY5WkFJi3eV6xJEVolaJb0y8WRcv9t4teZ4MftYaNjdR0ym+e70qS7wEj9Y1ajxGG4O+uo8qK0jHFEnCeLzFaGObyWSH7XTMBgUb5Iy7+Ib7OMLbuIUzbLNBPmT5DBgwYMCANw1eKWtrqWCUjFg2Sxb14obWc5MUrZZqbx+nPF2d7pBoBY4RHlfOoZWn7VQtbTVGG5xSKGVQJpTxtPK0ToN2QZlqG9rGo1XwMrW1x7UNrfc45fC0eB8IlFEem2WQWHSeo9IUlSR4A2iLVx6NCjET3gUflzI4o4LvSzK8WoerSlxZ4uqK4MyHVCtaBWRZ6IB0LmR/STeldCBqDUnwVykx00toqBCxOMFd8q4krkGImZQYxRsm3Y/xuJ26htEIffQoZjyGJAnesy6Rv60qWC4xWuPHY5KyQu0doJUhyafk+ZRiPGW8eYTpaMqWnrBJxpiMLXLuZJu72OVOjnCSjaFUOGDAgAED3pSQrK3quvEPDUXXkXhj67gZSBx+uUArHYzrChwqdK0ZAgmyBDO6CqbzBINXbaBkHnxbg7OAo1UOVItvPDiFSy0qU2ifgrFoq8Ea8ApD8GBpEzr7vAnLa12Lcy2udajG4RuP91Vvllc6CEVJV/qrWnzT0roWXze4tg6dDIpQclQ+vKYJVWBf13gXSpx4T1vXmLZFd6XHFqANKpeX4E/nwkibOHrCmN4EL/EMQpIWi/AlXYjO9QGn3fBok2WYzU1sluG6LK92sUA3DXXToMoS27aoNEV7UFcPSLzGpmOKrCBJC7LJJtPJDpv5BludgjUm4yQb3MUWZ9nhNNtDqXDAgAEDBrzpYa4T/3BItmjfmqVDXVryrR1023XvKY/3oazllAOvaL1DOQ++pWlL2rbFiUcKwCnQXXec1mitUDYEjlpt0FahTIpXPpCbumvoNBZvNA5CeKnTKKVJdIK3Ka1x4FpcG7K1mgZQ4FoPrqGqFsG3VXdqma9R2tAa1Xm6PMo5wON8g9IG5VwXvuqgKvFNjVKKNs/xSYISz5Y1+FT3ZT3ozfNp2hvRJVdrfz+Mx5HOQa2hKNDW4ssyRF1Mp+g0JckyVJKEL6XCMWlb2qYJHZNlSVqWeMKbLik9unVYnZGajCSdkI5H5OMNtkdb7NgJY3JyLLsUnGWXM2xyhh1OssGIZIhuGDBgwIABbwm8XPxDhqG6wWXfnNJhqbHFGO0dbStJ8BUKMC7EJaBBWwvKYm0BOkFpAzZENehu6rbzHq8cbevxrsX5Bte0uLqirhZ9Z58xgMY3NU7TGegVKI9rQ/dgW1XB3K4U2ujgsyIQKLogd+XaMPeoy+xCWVTrMLVHyf4YDXiM0ri6xjWh9Kd1KA366SR874zypCmNDz40Fl0tWLxW3TxBXRTB0zabwYUL/Xgc7yHLsNvbkOcYwDctdARLGxMM+l1EhVeKtsvHap2DxYJ0vsBpRYIlURZdtViv0LogyRKyfEQ2nrAx3mIr22KDjJyUDRJOssXtbHA7O5xhiyOMu+npAwYMGDBgwFsHCkVOck1HYnqDlZmbo2hZhWqCEmSNQWcZyk5B6UBqtCEUCYNzSyHEqItTcNC0Nbg2dAIGOzzgaL3Hao0uxlhrQIf8K+98KOH5hqbpsq6q0BVI22Jaj7Z5iHjw7jAsNahXNW1dBjVNeUxH8hTBp+VsGlQ5bUh0CKVoaNB1i69KkmIMeR46KqWct7+PMiYk1S8W+LKE0kNrDnOwdFGE/aoq3AsvBPVKyFWaYre2MdMpejRCNS26amhpoMiw1qKSEO3gkjA70os3zDnUwQF2NgdtSZIC03isU+jao60lSXNsmpHnI8ajDTZGO2yaMWMSRiTcwpjTbHMbG5xmk1vZYIN8ULEGDBgwYMBbGtfrSLwR3KQRPIC1OBU6DlvfdmNywMtHte7yrJAuxNBZp5TCdT4opQ20YSSP9u4wEgLvw+zDhcO1Nb71OFcHpautcM6jtEGjMZkh1QmkSeh+bGraVuPbGl+3gfAZi90o0GlKGP6j0UrTuprWtxgViJ5zbSBxyzm69TTW4EYZxkO7nOOrEldVKGMPCZZqGlqt8VkGRYoZhZBV7xxcuoSqKnQ3w9EUY/zmNtoabJKSZDm+dbjFMuynTbHJCFOMIE9wJsRP6K5D0dUN7mCGnR2gsCTZBOs0SQOuaTCATjNMkZNnBaNsxHS8zWa21RGslCP/f3v3Fmt5tt13/Tvm5X9Za+2969LXc45tYsXCgBBgWVZIEEQ4RJYVHFCClCccEmRZCAkeEHE4Eg+8IBMJJBQQMhcpSFawCISEKBF2SCKejomxfHwSfJLYkRWMnTjn4NOX2nut/3/OOXiY/yqXu6tPV3f1qt1d9ft0L9Xavdbae+65/rV77DnHHIOJz3HJF7jiW7jiTS55lb0S3kVE5IXxpBOJH9ftlHdwenmE1qu/+8Nq7vQtun7K0DELvdRCYFvfij3JvFXKtt1noW/TWbReRX47dUjrp/ACPTE9eMBSIoz7R6f03HvT6lYL5fSgb90Fxwm9wfSUqdEJWwHUuiw0B8MpwWneaK1hXilrefS9tNS/lpWCXZ9YT8ffbKOTIl4LcW2UYcAOBwbvpy5PtZCWbTWNXnh12B+wnGkhEmslNmAY8ejU6xtYF0IeSFf3CIc9lgecSl23AM3Bl4a//Rbh5kS2yDDfxTwQS8WXhYATw8AwzwzDxDhMHPZXHKY7XIaJAyOXDLzGBZ/jwOe44lu54lX2XDIp4V1ERF44iUjAOD1jsHUrgVbyyH440LZ8KMLWLgenVae0itNPAK61UJcC67Jt8609IOJhuanthID1wMSMvgUJ/bShRdi2IGttlHZDvenJ6ma9PISbYTnQ2lbV3Y0WDbfW2/HUrWgphrlTreLNaM2p65F2PPYkeOjboWuBEB/lZsUQYBy2nDOoecRjYPQGa8G20hE5BPI0PuqFaLFXlA+lEZYFG2fiOPRE99OKTTP26uvEecJpsJ7w5RojkDxQr4/EBw8oN9cMaSYf7hItY+sRP52wWknDSJ52pDQw55Fx3HG5u89F3nNJ5sDAHXa8wQVf4MAXuMvrHLjHjlmrWCIi8gJ7mCT/LG4l0GqpYdc34JXmzlpKP5VnW0BjsQdRtRLrim0BmYUM40yIv3nK0Lfvv7pTamF9WEahVlaveFlxX6gtkGLspxqJeGi4B9rxyFoLlgwL/UQiVCiZGHoBVHejtZ5wX+uxl3MoJ/zmhIVIHAZsnGgpkEKA5rSykPYHmPd9hWpdseB4cVJpeDnR3LAKNo60ELC5EXLEayXUip0awRtxGmB3gbVCK4VwsccOB0LOUAu+3GAEYgvY6pTra/zmXWxppDwwHl4l5dhX0a7fwZdCzAPD5RVjHsmWGMaJw+4ud8Yrdpa5YOAuO15lx5tc8iYHPsclr7DjgpGoVSwREXkJPGux7VsJtEoo3Cw3Pd8KMHMsBswDAaeUgnnDQiCMM8TeCLk3l+7bg0ur1OOxny5sK83rttrUyzUQgGCElAlhIm+nNXsbnb5tWVojTJExxr7VSOuvtYj7CrVQHiy4V9Z1BWsE23LDdlekV3akYSB4X5WrrRFK6ycIo0Gp+OkGD7mXWigOODU4Vo1gBrtMtEhwx5cj4ZgIKWNpxAZ6JXoM90qYdsTd1APMtZJPhYoRWsBuTqzX17Sl4DRyHEiHXprBzFm/8TZ1uSEMM+PVFdMwEYOR48h+d4c70xWHMHPBwIGR1zjw+qMg65J7W3No5WKJiIg8vds5dWiG1dZre+K00KPF1ho1gOWIx9xbSm/9DOu60srac6pa7XFR7LW3PGVCnMCM/LDYWOirUNi2XWd9NchaoxGIMZCHiMcBs0DcyjysZcXWhdoaLSfSfsRT6nlUIZBDz7/aCtr3qu+t0o4nKCcK4OY9LyoYDSMsR2Ip1AAe+2nAsLsip0wtK1b6SUobduwOE6WUnm825L6KF4yQ+wqbNWBpUMGXE/F0opVCKRVvjTyMpBAZcz9B2d5+h+XddwhTZnfvNfIwETFiiOznK+7v7rGPew5kLrbK7q+y4/Pc4XX2vMqeO8wcGHSiUERE5CO6nWT4JRL3e5pXWAve1r6NFgKVSisnWLZEczNKa+D9vJ9br33lMYJtq2EW+p8hPnZa0QjWV6nwRmgBxgMxD70JdGtQK+10pJYTq/ecrZQivt8RLWK10JYCp7XXwIpbux1f+0pSbdT1mtYKdetbSK2E1nA3rK3EPBAPV4RpJMZIMCM1aKeFuDRqDUQzaoCbcoOXkTxfElLobX/MsdQT8lpptHWlHhfwQmje+yc2ZwiZYUikYQIa5d0b2jvfgJg4vPoGaZoIa2UImd2w497+NQ55z47EjswddrzGzOsceJ0LXuXAHSbuMJO1TSgiIvKx3E55h9Tw04mI0WIkp4HG1syZ0O+3gnvfhgvW8JipD6u/b88LFrHQeizlrW/h0fsm+8N6UcForRLMKMtCe/Cgl2BoFSwSciANEymEfrKwNThV8EJzSCFhc4It8HGz3qNxPXFcF6o3vDrWCskiDImQZtK8I04jcZho66mveJ0WcovUVogU2lqx6njKxJwYD1ekw55QVtppJT4ssnrdV9h6j55EskBZGs0LKSTGYSYPI7TC+vYDyvXbxBCZ7r3KMO2x2kg1cJgvuTP3cg2zJXYkLrcVrDc48BoX3GPHXSbuKtldRETkmd1OZfhipGmHB4jm1NarutfWcCv9OUOENBHDlnbt3nvv1UrwfvrP6QFUCInWnNYW6rL2vC1vuFesVYrTE+pDJOZEHkeCJWJIGJVSan+9OxmjxYwHJ+YRTwY4FaPGSDkeKTdv996FIZFCJk0zw35PShlLmRATTqOcTvjXf6M3kg7Wq7GXU6/7FTJx2JFSwOl1wtrxAeGdlZYGYgi0VjHrJxmDRcppgdMNbpGcEuNw6OUtSmH9xjfw5YTlyOH+a6RxR6iN2Iz9dMXd+Q6X4x1my8wk9oy8wo7X2fMGF9xlxx1G7rJjT1ayu4iIyCfgdrYOMxyXB4D34qF9D5AYYm89E7baT8eeMB/MsV5Os1eO3zYHA05Z116MdG1UXwgh9xY9MRLDQIyJOSYsJCwYtgVpzXsvwrUZlvvX7nVQjRYDGBRveFmptVCOJ9rNA4LBNM2M+/vEce5FQ0OglmUrlOqU0wPq6QTLymq9lATFiW5YnkhzopaVWhf8uIJXoiWSJdLhorf2cSfU3vC5nY7gjZgSNu3JIfdA7OZEW27w0ohjJt25zzjMWHOGGtjlHXfme1zOV8w2MJKYGbjPzJsceJ0Dl1uS+11G1cQSERH5hN1ajtZud7Edmewp8SH0k3VrcxLQIqSYwCu1Vai9MXM/gdfb8dCc0BoWB8ZxJMZMDFBDxLw/N0A/Uei9jhY0Co1CxSPEYASPvUqWBZwxLMbGAAAcC0lEQVRGrQttrbj3r2vrwmiR/Mqb5HHuvQNjZF0L6/G4laZwmkG5uaZcv9tXsNJEskSzXjV+LUtfzbpeiUAcZvK4J4wj5IiVEzi06xv8eOx9GXMkz3PPGfNAaCvteKSUhRAjwzhj+0xOA7E6Ywsc8oGL+YqL6ZJDGMkkJhL3mPk8l7zOgT2Zq22L8A6T+hOKiIicwe383zVW0gmMwpauTnXHgvdNqxCogLWyDTL2Glcp9DIODVpbIYKNBwJ9W6418Nbb8YQYtjY9AU9G8ROtNzskmBFJlLJSvEE0Sq3UthDM+7ZeMmoJxGzYxRVhGLAGoVXW45GynvrKm9m24nVNffcBHoywG/GQ8HKiLAsBI8aBPMy9GXZKhJgheA/6SqW+9YDjb7zFQMZiIuSROO/66cy1gZ96q59qpDAQ54kYI9kCsUJumf2053K+y9V0wc5GBiIDkbvMvMGez3GHmcglM3e2E4YzwzPXCBEREZEne6ZAy8z+BPAvAwvwS8C/4e7f+LDXBTfCOEAIW4WGRHDoZcF6hfXe/9B7sjmVujV27q+HECIxDUQLvbp7TOQQIIZe3X37HKVUajmBBWpwaquU5YZSt2DMjOCZPA7MecLdWZYbQnXyPPX2O2Whvfsu67rSSu/q3XDqaaUsD6i1EGOG3UzOA2yNr4kjw+EOljOURisLFiKNxun4LnijLSs4xBQhj6TDDlsqLCuUSgqBGCNOImHYVhQ1eSB4ZLTAPF9wZ3eHy/GCnQ0kIhOZ+0y8ysxrXHJg4IKJu0xcMbFTgCUiInJ2z7qi9VPAH3f3YmY/Cvxx4I992ItsDWRLfTvQC62V3mqHijfwWnqJBAJ4ASIhZ6bxQBrH3uQ5pV4YlAbQtxIxal1ptVC915ZqXqk0ai3U5YSFRBgG5nkgppEQIg2nrSvrg3doxxPBex/DdTkRgIJT6FXsq7eei7VtFYbDgXk+kIb0qL8iBTwaEaOWFV9OsK180WqvrWWOWyJOA06gLCfseAMPjJhn8m4ihYg1JzQnWiCFhC+VCEw2cDFfcrG7y51hz2gDkchM5D47XmPPffbsyFwwccXIHWb2ZNXDEhEReU6eKdBy95987MMvAX/waV5XLxeuv/73+9Zb66sqIURizFiKxHFHw4kh9sruMfWK7TSaV0pbuTke+6lCjEbrW391oZWVVgGrmEPbVshSyEz7K0JIeOgLTuvxSDm+y/Luu/i6gENKCULqCfE58aCsQMMfbflFwpj7FiBGTBmvTr15gJeCE3qPxQVWh2aVVhyjN8C2PBBbDwy9LNQHC8Ei4zwTL17hzr1LUm20pRBOrW8jhgBlJa+VKc9czXe5mC+4yAcGS2Ti1pNw4j477m0nBy+YuNy2CFVwVERE5Pn7JHO0/gjwEx/0oJn9EPBDAPZP38dPI4TUa0WFSPRAWSr1+tRraJkRLOBc09x5+E+ll2pwb5TWq8TXuvQSChaIMeMh9hUknBAixK06/DvXtFJoy4m6HqnlSGiBOI6QRixE1uJUryzliIdATCOWpl4gNMSeVN9uMKdXpS/rVlg1k4aEY5zKkVp7HbCeUGY9MKutn5BsjWyBkGem6Q7jOMG1EfwBp7/3FkurhDgQcSjXpGbshx37+YqDHRivR8K1U/wBY81MJMZWSa2w+ol367tEBlIbCJ65/gxvEX7ta1/jq1/96m0P41NH8/Jkmpcn07y8n+bkyTQvn7wPDbTM7C8DbzzhoS+6+5/bnvNFoAA//kGfx91/DPgxgN13fd4P3/pK37JrlbKeKPUEGDGMxPDYyksIuNH7GVaIbWUtR3xtRKski8R0RRpHGtBq6YVFtwKorbVeyLP2SuqxVfxixC0R7A6Y0epCqYVqDQ9OsMSchu1MZCTEiMeJ4LWfTAyp51aVE4StbtaWD1bWBXwl1UbwreCo0YPAkJjHK4bdBXkYGYnU5US9WWA9cXMDV2/cIXojLI2RwG6+5Opwn12e2ceZkcSBgT0DBzIHxkf9CS+37cErRvYvyArWV7/6Vb7zO7/ztofxqaN5eTLNy5NpXt5Pc/JkmpdP3ocGWu7+e77Z42b2g8DvA77X3f1pvmgbK2+99TW8Fpo1QhqwGIkWqG3hWHtw1LCeiN4a3irujjWHlAk5M6YZ21ru1GWh1nUbVC8AWtjqZTXHt36Kbo6XG6qDW8ENPBg2RMwh5tzzuFLGUsBSxmujlRPeEn5aKKd3MOuNrltzyrEXMKWsmDsxJMI4EnMihIGcMtMwk6YdISTCulDfvWZdFrxBDgNp2IG/w35pTHFgd7jgsL/LVe4J7jN5uyVmEgcm9lvQdZfdoy3CWTlYIiIinxrPeurw++jJ7/+Cu18/7etadZgyhEz0iLfac5ZaodWtwGcMhK2xcrAehIW41YsigjfW1ijlyLoeAadFo5n1xs44XhtQcK/4ccGbU631LcsxEXLu1VONXl0+eK9/FYzetrBixxNeCpSGn46sbeklI3Da0k9GWguklMn7PZYzKSeMQB53jMNISgNtXag3D2g3hVoKOQRyHJnzSFgrdmrkMPH65Zvc293jIu3ZMTAQGbcyDXsye0YODOwYuMvEPWYumRj7mcRneTtFRETkE/asOVp/EhiBnzIzgC+5+w9/2IvMtyIOpQKOmRG3PoEpxr7dVxpkwEI/fUdvSVPXE8d1ZS1LX+2KhsdIxWhlwUt91IzZLbCVycKmmbidViRF2lpodYW6QAhUL7hHQrOeYL8W4rpQr29Ylge9fpeNxDH3BH3rleTdjJTHXrU9JmIeSHlgSAOhFjgW6jf+Ib4UYoMhDIzDFYMFQq2E1ZjHS+7u7rGEle+4/FYSkYyRiQwE9tv24I7MvAVYd5m5YiITFWCJiIh8Sj3rqcPf/rFeFxt5rYSYqIFeq8oLZVlp9QF47+/XasNa7X0LW+uV193BGx7AU09O9/VEbUCAHAc8NkJzijViDBDyVmG+Ua4fYO4QjZYyw7BVem8OrRCWlesHb1PefZcbb4QhkPZXzMNEyAPeS8yDBdyMIQ/EYewrWlt1dpaF+tZbrMdrQm2klJjjnjFnQugFRqcwcLm74N58lzvDJYnE1/l19mTytop1sa1ezWR25EcnCndktcoRERH5DLidptLRabWyLL19TVlPNG+9GU9KmCUsVHAHi7gbNMdbwWh4joQKrZxo7liKTGkkbCcN+8t6AVMLgRagAl6dPPbq7AEjeaWWwul0g68L6+mGcrrGLJGvrpjnA3HopxEdoK34Wggpk4fe5zDGTHLHTwvt7bdYjydoleiNi+HAMA6MNjC5kSyyT3vu7C+5Gi/ZxZlAL9MaCUwtcJ/dtj2YGYgcGLm/9SNU/pWIiMhny60EWs2d4/U71FIwMyxFhjD2Ug8W8OZ9e9EdvPT2PMOwnUi03vNwiuSct1Y2AW+VsizErYRpT6BvtFoop4UYIilGMMdaXxG78UqrJ9abGzgthJTZv/ImeX9JChG3iHntQdR6xGJmONwlDSPBK74U/K1vsB4XKCuxwX7cMQ0XTGlicmNiZJ8m5jxzMV6wSzOD9Wk3enuhvno1kMsFn99aO19s+VdXjIzk23ibRERE5BndSqAVHA67S+Iwkyz23oMW++pUgGaR2hbWstLMyfRq7NULFrcCpiHSaqGVlbJsJxPNadVp1noNK+jB0e6SmBMQWMpNz+U61V4KYm2Mw0S+8yppmokh9ibRtcC64LUQ80C+vEcKkXY80d5+h3ZcsVpJFnpQtbtkl2fmFphsYooDUxo55B1TmhnDwJbHRiQwENgxcNhuM4lY3+HzXHKfHQe2pH8RERH5zLqVQCuXgcv5bs+VCoa3Xo6hubOebqhbgOXBMAKWAqSBHGechjuUdaHWI3UrMOq0vhKWIhZH4tDLKxhQTieW4zW1rD1hPSQ894An7CbyvOv9E1uDWmitQm1ES4RppJ1W/Po3qMdKqpUxDEzjzG7aMaY9oxmZgX0c2U0TY8iMcce4fS2AsCW399WqXv9qT2ZiYEfikpGhvMW3c/823hIRERE5g1sJtAx4WHKrrr3HYfFKa40WHJ+m3kh5q3Hl3lvvPKynVdell1dwCNGY0ozHRItGDEZpTlsWluN1LxsRYg+8hom2nGAt5DwSDwMpJKIH3ALmjbo8gFPBvNJKpa2NGWOOO/bjJdOwZwiJQGQMiSmO7OPELgzEMDDG3OtoWc+l6uUZEgfSFlz104MTmT0Dl1vCeybxFsNtvB0iIiJyJrcTaBnE1BPMW6zbqpTjOTzq7ddT451ggRQG3CuncsK99wsMFmih51CVVnpi/NL65zEgJeLu0Es7rCsce5ueHCPD4S4xBIzYtyQf3LA8eAtfCwA5JUYyu7Rnf7jgkKbe1NkGYggMaWSOI3PIDGSGkEih9z8EyIQtkX3Ygquec5WJ7BnZbYVGldwuIiLyYruVQIs1ULxyWm9oGHGY2OUMIfbm0WZgDmaUsnBcTpTTEfcV80Awej/E+oBqENLQg5xpxAm9+nuttJsbrDZCiL3e1TCRQ8aWhtcj682JdrqBZkw5k4cLhpi5HA7s4sQch14sNURyGkkhMlhiT2YMAzH85tZgJmyBVOaCkQsyF1soNW+rWH0lK5EICrBEREReArcTaOXGGCf20x1CihQKjYABlUarK6flyPH6HU7rCau1FzhNAfMKNFoaSLtLQnAwKFsl+La8jZ8q5k4iYCERSyWngeSZ5pX15oSfHmAY87DnMF8wxYldmjikuedTxYEUE9EC0RKDwxxGhpBJIW8nBgMDPfC6ZOSSgR0jA5FpC6r2W3X3TFDtKxERkZfM7Zw6PCXyPLPQcF9otVHayrLecDpeU05HVq/glRgTnjMpJEJIvWdh/5daF8rxRCkrYV3w1ckpk4Y9Q4pE71XeQzDqurCcvoGvK+Mws794nXk6MKSBySKjjQxxIMdEtN73MGGMITOFkRwSkUDGmBjYbwntdxiZSAz07caZyMxAImzBlVavREREXla3U0crOO9cf4OyFtZaqOXE6iu1VjAnhMgQMo2phyjLQmOlhAAOxSq0XvIhWX9u2l0ypZFWVurNDawLrQFmtAbJjMN8h939S4Y0EYE5zcw2ki0SLBAckkVSSKQQmWxkIjKQHlVnv9oS2HtgFclbk+eJTNoCq4hp9UpERERuJ9Ba5iNff+trpGBU6OUcWsVbJRGobcXNegHTkGAYen9Bd9wboVSMtYczFgjV8QcPONZ3iTEyDTORid4hsedXzdNEjiMpZnZbEnt0I1skbsFVCIkBYyZzycyOvCWyD0xkdttK1UBk3iq39xWrXtk9EdR3UERERB65nRWt2hPd19OR0hrmlSEMxHwg5kgIiZgGVl9ptVJqoV6/QymF6E4MAyEmppjBHQPyMDKmkUiAVkghMQwzwzAzpoGBQPTAYJnR+inBZIlkPYl9R+KCkUvGLcDqDZx78nqv3j6SyMQtgOvBVb+vrUERERF5v9sp7xCN4E5II1MYCNGh9dY6da2sLLTj29QGbr2SfAiRwzCSw0gKgUgk04uO5piBXgcrWmTcXzHGkWyJbIkpZJJlDmF8lDeVSQwEZjJ3mLkis9tKLyQSw7ZlOGxJ7Na/goIrEREReWq3FGhBKr1FTqs3tJogBohQ3PFG3/QLRrLAGDPZBoY8MsYeKlmtROjhjsOYRoY8MQ0jk43sbGK0SCZupwB7uBS33Ko7TNxn4sC4VbgKj7YFH65aAY8Cq6htQREREfmIbiXQ8sXwlCEYhtNaZS0n/LHegUPaAqs0kUMkh9yDn3WFUgkhMsaJKU9Mecc+jsxkRlI/aQjk7QTgRNzqWPVE9qstmT1vQdXDVS7oq1a/uXKlVSsRERH5+G6njtZYKccH5BhpWN8WzDvm/Y4h96KiOSSG0Lf9YgPWiq0rMeyY5x1jHpnixGjpUZPmh4HT/Fhtq2HbBtw/6i2Yf0tgZdhvybnSqpWIiIh8Um4l0IolcP/iVeIwMOaZFAdySL1mlUVGGxg8QmvU4w1tXXry+3zJPk+9qfO2ejUTGciM2xbhbivFkLeiofutp2Deyi08XLFSYCUiIiLndiuB1vRgx5uvfBthK+r5MEiKbtAcKwXKgq8r+zhwsX+Dfdqxt4HxUb5V2BLWI2lbxXpYcqFXZO8V2h8PrHpYpcBKREREno/bWdEicMVAJpHcSA1iNUKtJIdYI3Oc2R8u2KcdmcC0FQXtgZU9lrQeGElMW+HQh6tZCqpERETktt1OCx6MV8pEqE5yI7tta1TGHBKH8cBl3LPbSiw8zL16mE8VtyKhvYho+i1J8CIiIiKfFrcTaEXnYo0cbGAME5P3bcCLuOMy7siWHrWyebgy9TCbyjAmErutabNa3YiIiMin1e3kaLXEPzV8W1/JajDHzBhnssVHwdR79S3CwJ6RcVvTEhEREfk0u5VAa2iRV+tItMiQR4I9OWgKGGnLz3q4PSgiIiLyWXE7kUuAKc3E8P5tv4dlF/Kj5s2JrABLREREPoNuJ0erht8SZD0eXKXtNtLztJTgLiIiIp9Vt7ZU9LCH4MPA6uFpwrRVeFeAJSIiIp91t9NU2mG/hVMP+wk+XNFSkruIiIi8KG6tjtbwWEucQacIRURE5AV0a1uHAXtU2V1ERETkRXQ7W4dbVXcRERGRF9mtLCcpzV1EREReBtq3ExERETkTBVoiIiIiZ6JAS0RERORMFGiJiIiInIkCLREREZEzUaAlIiIiciYKtERERETORIGWiIiIyJko0BIRERE5EwVaIiIiImeiQEtERETkTBRoiYiIiJyJAi0RERGRM1GgJSIiInImCrREREREzkSBloiIiMiZKNASERERORMFWiIiIiJnokBLRERE5EwUaImIiIiciQItERERkTNRoCUiIiJyJgq0RERERM5EgZaIiIjImSjQEhERETkTBVoiIiIiZ6JAS0RERORMFGiJiIiInIkCLREREZEzUaAlIiIiciYKtERERETORIGWiIiIyJko0BIRERE5EwVaIiIiImeiQEtERETkTBRoiYiIiJyJAi0RERGRM1GgJSIiInImCrREREREzkSBloiIiMiZKNASERERORMFWiIiIiJnokBLRERE5EwUaImIiIiciQItERERkTNRoCUiIiJyJgq0RERERM5EgZaIiIjImSjQEhERETkTBVoiIiIiZ6JAS0RERORMFGiJiIiInIkCLREREZEzUaAlIiIiciYKtERERETORIGWiIiIyJko0BIRERE5EwVaIiIiImeiQEtERETkTBRoiYiIiJyJAi0RERGRM1GgJSIiInImCrREREREzkSBloiIiMiZKNASERERORMFWiIiIiJnokBLRERE5EwUaImIiIiciQItERERkTP5RAItM/v3zMzN7JVP4vOJiIiIvAieOdAys28B/iXg7z37cEREREReHJ/EitZ/Bvz7gH8Cn0tERETkhZGe5cVm9gPA/+vuXzazD3vuDwE/tH14MrO/8Sxf+wX1CvC12x7Ep4zm5Mk0L0+meXkyzcv7aU6eTPPyZP/ox32huX/zhSgz+8vAG0946IvAfwD8Xnd/y8x+Gfhud//QN8jMfsbdv/tjjPeFpnl5P83Jk2lenkzz8mSal/fTnDyZ5uXJnmVePnRFy91/zwd80X8S+G3Aw9WsLwA/a2bf4+5//+MMRkRERORF8rG3Dt39K8BrDz/+KCtaIiIiIi+D26qj9WO39HU/7TQv76c5eTLNy5NpXp5M8/J+mpMn07w82ceelw/N0RIRERGRj0eV4UVERETORIGWiIiIyJk8l0DLzP6EmX3VzH7ezP6smd35gOd9n5n9LTP7RTP7kecxtttkZv+amf1NM2tm9oHHRs3sl83sK2b2c2b2M89zjM/bR5iTl+1auWdmP2Vmf2f78+4HPK9u18nPmdmff97jfF4+7P03s9HMfmJ7/KfN7B95/qN8vp5iTv6wmf3Dx66Pf/M2xvm8mdl/Z2a//kG1G637z7d5+3kz+67nPcbn7Snm5Heb2VuPXSv/4fMe420ws28xs79qZr+w/X/o33nCcz769eLuZ78BvxdI2/0fBX70Cc+JwC8B3w4MwJeBf/x5jO+2bsA/Ri+C9tfoJzY/6Hm/DLxy2+P9tMzJS3qt/CfAj2z3f+RJf4e2x9697bE+h7n40Pcf+LeA/2q7/4eAn7jtcX8K5uQPA3/ytsd6C3PzzwPfBfyND3j8+4G/BBjwO4Cfvu0xfwrm5HcDf+G2x3kL8/Im8F3b/Qvgbz/h79FHvl6ey4qWu/+ku5ftwy/Ra2691/cAv+juf9fdF+B/AH7/8xjfbXH3X3D3v3Xb4/g0eco5eemuFfr396e2+38K+FducSy37Wne/8fn688A32sf1r7is+1l/DvxVNz9/wD+v2/ylN8P/PfefQm4Y2ZvPp/R3Y6nmJOXkrv/mrv/7Hb/HeAXgM+/52kf+Xq5jRytP0KPBt/r88D/89jHv8L7v8GXlQM/aWb/19bK6GX3Ml4rr7v7r0H/YcBjNezeYzKznzGzL5nZixqMPc37/+g52y95bwH3n8vobsfT/p34A9t2x58xs295PkP71HsZf548jX/WzL5sZn/JzP6J2x7M87alG/wzwE+/56GPfL08U6/D9wzqA1v1uPuf257zRaAAP/6kT/GE//aZrz3xNPPyFH6Xu/+qmb0G/JSZfXX7jeQz6ROYk5fuWvkIn+Zbt2vl24G/YmZfcfdf+mRG+KnxNO//C3mNfBNP8/3+r8CfdveTmf0wfcXvXzz7yD79XrZr5Wn8LPBt7v6umX0/8L8A33HLY3puzOwA/E/Av+vub7/34Se85JteL59YoOUf0KrnITP7QeD3Ad/r20bne/wK8PhvWF8AfvWTGt9t+bB5ecrP8avbn79uZn+Wvk3wmQ20PoE5eemuFTP7B2b2prv/2rZM/esf8DkeXit/18z+Gv03shct0Hqa9//hc37FzBJwxYu9VfKhc+LuX3/sw/+ani8rL+jPk2fxeHDh7n/RzP5LM3vFX4LOL2aW6UHWj7v7//yEp3zk6+V5nTr8PuCPAT/g7tcf8LS/DnyHmf02MxvoCawv7Kmpp2VmezO7eHiffrDgiSdFXiIv47Xy54Ef3O7/IPC+lT8zu2tm43b/FeB3Af/3cxvh8/M07//j8/UHgb/yAb/gvSg+dE7ek0fyA/T8E+nz9K9vp8l+B/DWw236l5WZvfEwp9HMvoceK3z9m7/qs2/7nv9b4Bfc/T/9gKd99OvlOWXy/yJ9T/PnttvD00CfA/7ie7L5/zb9N/AvPo+x3eYN+Ffp0fEJ+AfA//beeaGfIvrydvubL/q8PM2cvKTXyn3gfwf+zvbnve2/fzfw32z3fyfwle1a+QrwR2973Gecj/e9/8B/RP9lDmAC/sftZ8//CXz7bY/5UzAn//H2M+TLwF8FvvO2x/yc5uVPA78GrNvPlj8K/DDww9vjBvwX27x9hW9yAvxFuT3FnPzbj10rXwJ+522P+TnNyz9H3wb8+cfile9/1utFLXhEREREzkSV4UVERETORIGWiIiIyJko0BIRERE5EwVaIiIiImeiQEtERETkTBRoiYiIiJyJAi0RERGRM/n/AU9iNlxXhDfAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(252.4077, device='cuda:0'),\n",
       " tensor(-271.0292, device='cuda:0'),\n",
       " tensor(-137.5822, device='cuda:0')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show(GeN,n):\n",
    "    Z=GeN(n).detach()\n",
    "    fig=setup.makePlot(Z,device)\n",
    "    plt.title('('+str(nblayers)+' with '+str(layerwidth)+' units) Predictive VI: GeNVI lat_dim='+str(lat_dim))\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "\n",
    "    \n",
    "show(GeN,1000)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5834f72910>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "X=torch.Tensor([[-.7]]).to(device)#torch.arange(-2.,2.,0.1)\n",
    "Y=model(X,GeN(500).detach()).squeeze().cpu()\n",
    "\n",
    "sns.distplot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLPP_train, nLPP_validation, nLPP_test, RSE_train, RSE_validation, RSE_test=setup.evaluate_metrics(GeN(1000).detach(),'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nLPP_valid: (tensor(-0.8587), tensor(0.6231))\n",
      "SE_valid: (tensor(0.0103), tensor(0.0147))\n",
      "nLPP_test: (tensor(0.3586), tensor(1.1520))\n",
      "SE_test: (tensor(0.4413), tensor(0.7950))\n"
     ]
    }
   ],
   "source": [
    "print('nLPP_valid: '+str(nLPP_validation))\n",
    "print('SE_valid: '+str(RSE_validation))\n",
    "print('nLPP_test: '+str(nLPP_test))\n",
    "print('SE_test: '+str(RSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un choix de points $x_0,...,x_{n-1}$, on définit:\n",
    "$$\n",
    "d(\\theta,\\theta')=\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert\n",
    "$$\n",
    "ou\n",
    "$$\n",
    "d_2(\\theta,\\theta')=\\biggl(\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert^2\\biggr)^{\\frac{1}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(f\\in A)=P(\\{\\theta \\mid f_\\theta\\in A\\})$\n",
    "\n",
    "$\\theta \\mapsto f_\\theta$ (is it continuous?)\n",
    "\n",
    "relation entre $d(\\theta,\\theta')$ et $d(f_\\theta,f_\\theta')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
