{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "from Inference.GeNVI_predictive import GeNPredVI, GeNetEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Experiments.foong import Setup\n",
    "setup=Setup(device, layerwidth=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target density #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "logprior=setup.logprior\n",
    "loglikelihood=setup.loglikelihood\n",
    "projection=setup.projection\n",
    "\n",
    "n_data_samples=setup.n_samples\n",
    "param_count=setup.param_count\n",
    "model=setup._model\n",
    "print(n_data_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Network #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation = nn.Tanh()#nn.ReLU()\n",
    "init_b = .001\n",
    "lat_dim=10\n",
    "GeN = GeNetEns(1, lat_dim, 50, param_count, activation, 0.2, init_b, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20000], Loss: 85514.984375, Entropy -369.7100830078125, Learning Rate: 0.05\n",
      "Epoch [1/20000], Loss: 841261.0625, Entropy -292.69781494140625, Learning Rate: 0.05\n",
      "Epoch [2/20000], Loss: 172658.796875, Entropy -312.33526611328125, Learning Rate: 0.05\n",
      "Epoch [3/20000], Loss: 185333.90625, Entropy -340.55194091796875, Learning Rate: 0.05\n",
      "Epoch [4/20000], Loss: 107241.3125, Entropy -318.150634765625, Learning Rate: 0.05\n",
      "Epoch [5/20000], Loss: 165327.25, Entropy -331.7514343261719, Learning Rate: 0.05\n",
      "Epoch [6/20000], Loss: 104656.890625, Entropy -319.3344421386719, Learning Rate: 0.05\n",
      "Epoch [7/20000], Loss: 69832.6328125, Entropy -362.6208801269531, Learning Rate: 0.05\n",
      "Epoch [8/20000], Loss: 115429.7265625, Entropy -337.47442626953125, Learning Rate: 0.05\n",
      "Epoch [9/20000], Loss: 94489.546875, Entropy -331.9835205078125, Learning Rate: 0.05\n",
      "Epoch [10/20000], Loss: 96205.5859375, Entropy -312.2034912109375, Learning Rate: 0.05\n",
      "Epoch [11/20000], Loss: 104614.0703125, Entropy -343.71588134765625, Learning Rate: 0.05\n",
      "Epoch [12/20000], Loss: 76120.3125, Entropy -357.1385192871094, Learning Rate: 0.05\n",
      "Epoch [13/20000], Loss: 55152.8359375, Entropy -343.4635925292969, Learning Rate: 0.05\n",
      "Epoch [14/20000], Loss: 91138.8984375, Entropy -354.154296875, Learning Rate: 0.05\n",
      "Epoch [15/20000], Loss: 81266.125, Entropy -328.2525634765625, Learning Rate: 0.05\n",
      "Epoch [16/20000], Loss: 52417.8125, Entropy -330.02294921875, Learning Rate: 0.05\n",
      "Epoch [17/20000], Loss: 48791.5546875, Entropy -342.2510986328125, Learning Rate: 0.05\n",
      "Epoch [18/20000], Loss: 44239.9921875, Entropy -353.20086669921875, Learning Rate: 0.05\n",
      "Epoch [19/20000], Loss: 43426.1015625, Entropy -353.4378662109375, Learning Rate: 0.05\n",
      "Epoch [20/20000], Loss: 41272.8515625, Entropy -372.7054138183594, Learning Rate: 0.05\n",
      "Epoch [21/20000], Loss: 44552.80859375, Entropy -366.56622314453125, Learning Rate: 0.05\n",
      "Epoch [22/20000], Loss: 40652.42578125, Entropy -368.7049560546875, Learning Rate: 0.05\n",
      "Epoch [23/20000], Loss: 46094.4921875, Entropy -370.67242431640625, Learning Rate: 0.05\n",
      "Epoch [24/20000], Loss: 33102.578125, Entropy -404.08697509765625, Learning Rate: 0.05\n",
      "Epoch [25/20000], Loss: 40958.62109375, Entropy -369.1925048828125, Learning Rate: 0.05\n",
      "Epoch [26/20000], Loss: 54240.98046875, Entropy -383.70941162109375, Learning Rate: 0.05\n",
      "Epoch [27/20000], Loss: 42210.69921875, Entropy -389.90753173828125, Learning Rate: 0.05\n",
      "Epoch [28/20000], Loss: 18473.671875, Entropy -399.8672180175781, Learning Rate: 0.05\n",
      "Epoch [29/20000], Loss: 28105.755859375, Entropy -415.4068908691406, Learning Rate: 0.05\n",
      "Epoch [30/20000], Loss: 38351.2421875, Entropy -419.40057373046875, Learning Rate: 0.05\n",
      "Epoch [31/20000], Loss: 19325.40625, Entropy -428.1979064941406, Learning Rate: 0.05\n",
      "Epoch [32/20000], Loss: 26513.9765625, Entropy -435.9796447753906, Learning Rate: 0.05\n",
      "Epoch [33/20000], Loss: 24303.033203125, Entropy -424.98626708984375, Learning Rate: 0.05\n",
      "Epoch [34/20000], Loss: 20117.173828125, Entropy -450.9651794433594, Learning Rate: 0.05\n",
      "Epoch [35/20000], Loss: 18595.201171875, Entropy -447.68145751953125, Learning Rate: 0.05\n",
      "Epoch [36/20000], Loss: 21903.4765625, Entropy -435.46929931640625, Learning Rate: 0.05\n",
      "Epoch [37/20000], Loss: 19285.779296875, Entropy -428.9716491699219, Learning Rate: 0.05\n",
      "Epoch [38/20000], Loss: 19563.041015625, Entropy -438.82025146484375, Learning Rate: 0.05\n",
      "Epoch [39/20000], Loss: 27902.3515625, Entropy -435.6280212402344, Learning Rate: 0.05\n",
      "Epoch [40/20000], Loss: 17002.814453125, Entropy -440.85723876953125, Learning Rate: 0.05\n",
      "Epoch [41/20000], Loss: 15287.2626953125, Entropy -454.91290283203125, Learning Rate: 0.05\n",
      "Epoch [42/20000], Loss: 15087.591796875, Entropy -464.86871337890625, Learning Rate: 0.05\n",
      "Epoch [43/20000], Loss: 10889.6357421875, Entropy -469.1339111328125, Learning Rate: 0.05\n",
      "Epoch [44/20000], Loss: 15303.55859375, Entropy -472.6614990234375, Learning Rate: 0.05\n",
      "Epoch [45/20000], Loss: 15233.458984375, Entropy -474.9430847167969, Learning Rate: 0.05\n",
      "Epoch [46/20000], Loss: 11565.84375, Entropy -478.5523986816406, Learning Rate: 0.05\n",
      "Epoch [47/20000], Loss: 8562.6201171875, Entropy -498.7080383300781, Learning Rate: 0.05\n",
      "Epoch [48/20000], Loss: 8016.64111328125, Entropy -490.06842041015625, Learning Rate: 0.05\n",
      "Epoch [49/20000], Loss: 8365.880859375, Entropy -500.2306823730469, Learning Rate: 0.05\n",
      "Epoch [50/20000], Loss: 9476.8291015625, Entropy -506.054443359375, Learning Rate: 0.05\n",
      "Epoch [51/20000], Loss: 9784.2197265625, Entropy -489.0572204589844, Learning Rate: 0.05\n",
      "Epoch [52/20000], Loss: 9011.9228515625, Entropy -511.86431884765625, Learning Rate: 0.05\n",
      "Epoch [53/20000], Loss: 8339.9296875, Entropy -531.1654052734375, Learning Rate: 0.05\n",
      "Epoch [54/20000], Loss: 8243.1875, Entropy -515.0474243164062, Learning Rate: 0.05\n",
      "Epoch [55/20000], Loss: 7417.27685546875, Entropy -526.5928344726562, Learning Rate: 0.05\n",
      "Epoch [56/20000], Loss: 5727.22021484375, Entropy -533.4026489257812, Learning Rate: 0.05\n",
      "Epoch [57/20000], Loss: 5893.87744140625, Entropy -537.7042846679688, Learning Rate: 0.05\n",
      "Epoch [58/20000], Loss: 6938.12646484375, Entropy -547.8187255859375, Learning Rate: 0.05\n",
      "Epoch [59/20000], Loss: 6091.25830078125, Entropy -548.60107421875, Learning Rate: 0.05\n",
      "Epoch [60/20000], Loss: 8048.359375, Entropy -550.2034912109375, Learning Rate: 0.05\n",
      "Epoch [61/20000], Loss: 4470.40087890625, Entropy -554.0545043945312, Learning Rate: 0.05\n",
      "Epoch [62/20000], Loss: 6329.8359375, Entropy -542.1968383789062, Learning Rate: 0.05\n",
      "Epoch [63/20000], Loss: 5004.328125, Entropy -553.591552734375, Learning Rate: 0.05\n",
      "Epoch [64/20000], Loss: 6867.25244140625, Entropy -568.9989624023438, Learning Rate: 0.05\n",
      "Epoch [65/20000], Loss: 5225.458984375, Entropy -568.2329711914062, Learning Rate: 0.05\n",
      "Epoch [66/20000], Loss: 5313.69482421875, Entropy -593.6856689453125, Learning Rate: 0.05\n",
      "Epoch [67/20000], Loss: 5722.56787109375, Entropy -575.87353515625, Learning Rate: 0.05\n",
      "Epoch [68/20000], Loss: 6520.6728515625, Entropy -573.06005859375, Learning Rate: 0.05\n",
      "Epoch [69/20000], Loss: 4456.12255859375, Entropy -577.4178466796875, Learning Rate: 0.05\n",
      "Epoch [70/20000], Loss: 5292.14453125, Entropy -597.6422729492188, Learning Rate: 0.05\n",
      "Epoch [71/20000], Loss: 5330.2109375, Entropy -601.995361328125, Learning Rate: 0.05\n",
      "Epoch [72/20000], Loss: 4719.86767578125, Entropy -600.3563232421875, Learning Rate: 0.05\n",
      "Epoch [73/20000], Loss: 3612.372802734375, Entropy -608.739990234375, Learning Rate: 0.05\n",
      "Epoch [74/20000], Loss: 4065.15576171875, Entropy -601.7024536132812, Learning Rate: 0.05\n",
      "Epoch [75/20000], Loss: 4106.673828125, Entropy -594.908203125, Learning Rate: 0.05\n",
      "Epoch [76/20000], Loss: 4679.77880859375, Entropy -616.8997802734375, Learning Rate: 0.05\n",
      "Epoch [77/20000], Loss: 4756.36767578125, Entropy -615.382568359375, Learning Rate: 0.05\n",
      "Epoch [78/20000], Loss: 3656.257080078125, Entropy -639.6192626953125, Learning Rate: 0.05\n",
      "Epoch [79/20000], Loss: 3810.7919921875, Entropy -628.7848510742188, Learning Rate: 0.05\n",
      "Epoch [80/20000], Loss: 4929.59521484375, Entropy -608.6319580078125, Learning Rate: 0.05\n",
      "Epoch [81/20000], Loss: 3494.82958984375, Entropy -627.4364624023438, Learning Rate: 0.05\n",
      "Epoch [82/20000], Loss: 3248.751953125, Entropy -633.536376953125, Learning Rate: 0.05\n",
      "Epoch [83/20000], Loss: 4032.51416015625, Entropy -621.5780639648438, Learning Rate: 0.05\n",
      "Epoch [84/20000], Loss: 4770.32275390625, Entropy -640.8013305664062, Learning Rate: 0.05\n",
      "Epoch [85/20000], Loss: 3132.385009765625, Entropy -633.505859375, Learning Rate: 0.05\n",
      "Epoch [86/20000], Loss: 3532.41357421875, Entropy -645.3153076171875, Learning Rate: 0.05\n",
      "Epoch [87/20000], Loss: 3657.51123046875, Entropy -654.793212890625, Learning Rate: 0.05\n",
      "Epoch [88/20000], Loss: 3049.312744140625, Entropy -643.6426391601562, Learning Rate: 0.05\n",
      "Epoch [89/20000], Loss: 3899.396484375, Entropy -679.3087768554688, Learning Rate: 0.05\n",
      "Epoch [90/20000], Loss: 3152.77294921875, Entropy -656.0614013671875, Learning Rate: 0.05\n",
      "Epoch [91/20000], Loss: 3058.651123046875, Entropy -641.0079345703125, Learning Rate: 0.05\n",
      "Epoch [92/20000], Loss: 3418.15478515625, Entropy -635.5390625, Learning Rate: 0.05\n",
      "Epoch [93/20000], Loss: 4006.33984375, Entropy -610.45068359375, Learning Rate: 0.05\n",
      "Epoch [94/20000], Loss: 2880.62353515625, Entropy -628.019287109375, Learning Rate: 0.05\n",
      "Epoch [95/20000], Loss: 3455.0498046875, Entropy -642.8260498046875, Learning Rate: 0.05\n",
      "Epoch [96/20000], Loss: 2997.78466796875, Entropy -651.7880249023438, Learning Rate: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/20000], Loss: 2707.83251953125, Entropy -664.4271850585938, Learning Rate: 0.05\n",
      "Epoch [98/20000], Loss: 3131.18115234375, Entropy -658.7227172851562, Learning Rate: 0.05\n",
      "Epoch [99/20000], Loss: 3672.07275390625, Entropy -658.0045776367188, Learning Rate: 0.05\n",
      "Epoch [100/20000], Loss: 2465.47216796875, Entropy -670.15087890625, Learning Rate: 0.05\n",
      "Epoch [101/20000], Loss: 2573.1396484375, Entropy -670.8572998046875, Learning Rate: 0.05\n",
      "Epoch [102/20000], Loss: 2382.45947265625, Entropy -695.88037109375, Learning Rate: 0.05\n",
      "Epoch [103/20000], Loss: 2697.568115234375, Entropy -676.0982666015625, Learning Rate: 0.05\n",
      "Epoch [104/20000], Loss: 2945.68408203125, Entropy -662.1534423828125, Learning Rate: 0.05\n",
      "Epoch [105/20000], Loss: 2882.7158203125, Entropy -667.8017578125, Learning Rate: 0.05\n",
      "Epoch [106/20000], Loss: 2581.55029296875, Entropy -668.2271118164062, Learning Rate: 0.05\n",
      "Epoch [107/20000], Loss: 2415.67822265625, Entropy -696.04638671875, Learning Rate: 0.05\n",
      "Epoch [108/20000], Loss: 2046.73876953125, Entropy -676.2708129882812, Learning Rate: 0.05\n",
      "Epoch [109/20000], Loss: 2473.11181640625, Entropy -680.163330078125, Learning Rate: 0.05\n",
      "Epoch [110/20000], Loss: 2625.69091796875, Entropy -679.1163940429688, Learning Rate: 0.05\n",
      "Epoch [111/20000], Loss: 2296.60302734375, Entropy -653.81201171875, Learning Rate: 0.05\n",
      "Epoch [112/20000], Loss: 2616.87890625, Entropy -678.4419555664062, Learning Rate: 0.05\n",
      "Epoch [113/20000], Loss: 2330.8388671875, Entropy -705.6739501953125, Learning Rate: 0.05\n",
      "Epoch [114/20000], Loss: 2087.916259765625, Entropy -679.5457153320312, Learning Rate: 0.05\n",
      "Epoch [115/20000], Loss: 1924.0751953125, Entropy -695.7731323242188, Learning Rate: 0.05\n",
      "Epoch [116/20000], Loss: 2264.293212890625, Entropy -681.5728759765625, Learning Rate: 0.05\n",
      "Epoch [117/20000], Loss: 2173.166748046875, Entropy -682.0035400390625, Learning Rate: 0.05\n",
      "Epoch [118/20000], Loss: 2251.05615234375, Entropy -678.8905639648438, Learning Rate: 0.05\n",
      "Epoch [119/20000], Loss: 1967.93408203125, Entropy -673.2069091796875, Learning Rate: 0.05\n",
      "Epoch [120/20000], Loss: 1986.2547607421875, Entropy -694.0362548828125, Learning Rate: 0.05\n",
      "Epoch [121/20000], Loss: 1896.865478515625, Entropy -689.8431396484375, Learning Rate: 0.05\n",
      "Epoch [122/20000], Loss: 1974.0538330078125, Entropy -694.5384521484375, Learning Rate: 0.05\n",
      "Epoch [123/20000], Loss: 1897.50341796875, Entropy -692.4247436523438, Learning Rate: 0.05\n",
      "Epoch [124/20000], Loss: 1948.1881103515625, Entropy -671.8994750976562, Learning Rate: 0.05\n",
      "Epoch [125/20000], Loss: 2009.79638671875, Entropy -680.1213989257812, Learning Rate: 0.05\n",
      "Epoch [126/20000], Loss: 1797.517578125, Entropy -686.3245849609375, Learning Rate: 0.05\n",
      "Epoch [127/20000], Loss: 1931.160888671875, Entropy -698.0790405273438, Learning Rate: 0.05\n",
      "Epoch [128/20000], Loss: 1699.8336181640625, Entropy -676.2086791992188, Learning Rate: 0.05\n",
      "Epoch [129/20000], Loss: 2008.48046875, Entropy -705.322998046875, Learning Rate: 0.05\n",
      "Epoch [130/20000], Loss: 2205.666015625, Entropy -698.0243530273438, Learning Rate: 0.05\n",
      "Epoch [131/20000], Loss: 1954.060546875, Entropy -675.875, Learning Rate: 0.05\n",
      "Epoch [132/20000], Loss: 1748.2965087890625, Entropy -703.03759765625, Learning Rate: 0.05\n",
      "Epoch [133/20000], Loss: 2190.84228515625, Entropy -701.364990234375, Learning Rate: 0.05\n",
      "Epoch [134/20000], Loss: 1680.750244140625, Entropy -702.5819702148438, Learning Rate: 0.05\n",
      "Epoch [135/20000], Loss: 1837.9669189453125, Entropy -690.41748046875, Learning Rate: 0.05\n",
      "Epoch [136/20000], Loss: 1771.3707275390625, Entropy -702.906494140625, Learning Rate: 0.05\n",
      "Epoch [137/20000], Loss: 1760.722412109375, Entropy -685.1492309570312, Learning Rate: 0.05\n",
      "Epoch [138/20000], Loss: 1744.04833984375, Entropy -682.0436401367188, Learning Rate: 0.05\n",
      "Epoch [139/20000], Loss: 1674.007568359375, Entropy -684.6485595703125, Learning Rate: 0.05\n",
      "Epoch [140/20000], Loss: 1620.80224609375, Entropy -701.3356323242188, Learning Rate: 0.05\n",
      "Epoch [141/20000], Loss: 1654.8350830078125, Entropy -703.9151611328125, Learning Rate: 0.05\n",
      "Epoch [142/20000], Loss: 1588.6181640625, Entropy -706.4873657226562, Learning Rate: 0.05\n",
      "Epoch [143/20000], Loss: 1645.3447265625, Entropy -712.9092407226562, Learning Rate: 0.05\n",
      "Epoch [144/20000], Loss: 1719.785400390625, Entropy -701.2703857421875, Learning Rate: 0.05\n",
      "Epoch [145/20000], Loss: 1541.444580078125, Entropy -692.9959106445312, Learning Rate: 0.05\n",
      "Epoch [146/20000], Loss: 1520.093505859375, Entropy -709.1695556640625, Learning Rate: 0.05\n",
      "Epoch [147/20000], Loss: 1467.93212890625, Entropy -696.847900390625, Learning Rate: 0.05\n",
      "Epoch [148/20000], Loss: 1550.39697265625, Entropy -689.8644409179688, Learning Rate: 0.05\n",
      "Epoch [149/20000], Loss: 1502.535400390625, Entropy -698.002197265625, Learning Rate: 0.05\n",
      "Epoch [150/20000], Loss: 1629.3642578125, Entropy -684.8585815429688, Learning Rate: 0.05\n",
      "Epoch [151/20000], Loss: 1440.8677978515625, Entropy -695.8484497070312, Learning Rate: 0.05\n",
      "Epoch [152/20000], Loss: 1446.4560546875, Entropy -695.8128051757812, Learning Rate: 0.05\n",
      "Epoch [153/20000], Loss: 1425.8271484375, Entropy -693.5098266601562, Learning Rate: 0.05\n",
      "Epoch [154/20000], Loss: 1531.605712890625, Entropy -694.1929321289062, Learning Rate: 0.05\n",
      "Epoch [155/20000], Loss: 1394.1976318359375, Entropy -690.0938110351562, Learning Rate: 0.05\n",
      "Epoch [156/20000], Loss: 1313.906982421875, Entropy -701.4791259765625, Learning Rate: 0.05\n",
      "Epoch [157/20000], Loss: 1496.54150390625, Entropy -689.68994140625, Learning Rate: 0.05\n",
      "Epoch [158/20000], Loss: 1399.777587890625, Entropy -695.324462890625, Learning Rate: 0.05\n",
      "Epoch [159/20000], Loss: 1438.8955078125, Entropy -683.8487548828125, Learning Rate: 0.05\n",
      "Epoch [160/20000], Loss: 1454.30810546875, Entropy -687.7067260742188, Learning Rate: 0.05\n",
      "Epoch [161/20000], Loss: 1397.529541015625, Entropy -716.3382568359375, Learning Rate: 0.05\n",
      "Epoch [162/20000], Loss: 1409.240478515625, Entropy -696.2601928710938, Learning Rate: 0.05\n",
      "Epoch [163/20000], Loss: 1456.8895263671875, Entropy -683.8366088867188, Learning Rate: 0.05\n",
      "Epoch [164/20000], Loss: 1400.92236328125, Entropy -665.1495361328125, Learning Rate: 0.05\n",
      "Epoch [165/20000], Loss: 1377.4454345703125, Entropy -680.7606201171875, Learning Rate: 0.05\n",
      "Epoch [166/20000], Loss: 1348.6461181640625, Entropy -675.5701904296875, Learning Rate: 0.05\n",
      "Epoch [167/20000], Loss: 1347.9248046875, Entropy -696.0418090820312, Learning Rate: 0.05\n",
      "Epoch [168/20000], Loss: 1281.439697265625, Entropy -690.3047485351562, Learning Rate: 0.05\n",
      "Epoch [169/20000], Loss: 1329.836669921875, Entropy -679.9139404296875, Learning Rate: 0.05\n",
      "Epoch [170/20000], Loss: 1320.4793701171875, Entropy -685.3291015625, Learning Rate: 0.05\n",
      "Epoch [171/20000], Loss: 1376.3642578125, Entropy -682.5267333984375, Learning Rate: 0.05\n",
      "Epoch [172/20000], Loss: 1308.24951171875, Entropy -685.4234008789062, Learning Rate: 0.05\n",
      "Epoch [173/20000], Loss: 1311.591064453125, Entropy -703.5439453125, Learning Rate: 0.05\n",
      "Epoch [174/20000], Loss: 1280.763671875, Entropy -674.9371337890625, Learning Rate: 0.05\n",
      "Epoch [175/20000], Loss: 1313.433349609375, Entropy -688.9644775390625, Learning Rate: 0.05\n",
      "Epoch [176/20000], Loss: 1308.8193359375, Entropy -683.3270263671875, Learning Rate: 0.05\n",
      "Epoch [177/20000], Loss: 1235.192138671875, Entropy -688.9827880859375, Learning Rate: 0.05\n",
      "Epoch [178/20000], Loss: 1242.1678466796875, Entropy -691.1959228515625, Learning Rate: 0.05\n",
      "Epoch [179/20000], Loss: 1236.7744140625, Entropy -698.666748046875, Learning Rate: 0.05\n",
      "Epoch [180/20000], Loss: 1362.2835693359375, Entropy -673.7318115234375, Learning Rate: 0.05\n",
      "Epoch [181/20000], Loss: 1274.314453125, Entropy -676.625732421875, Learning Rate: 0.05\n",
      "Epoch [182/20000], Loss: 1274.44873046875, Entropy -690.7430419921875, Learning Rate: 0.05\n",
      "Epoch [183/20000], Loss: 1272.9803466796875, Entropy -677.5161743164062, Learning Rate: 0.05\n",
      "Epoch [184/20000], Loss: 1245.2196044921875, Entropy -667.19970703125, Learning Rate: 0.05\n",
      "Epoch [185/20000], Loss: 1210.294921875, Entropy -671.2085571289062, Learning Rate: 0.05\n",
      "Epoch [186/20000], Loss: 1300.8499755859375, Entropy -676.41650390625, Learning Rate: 0.05\n",
      "Epoch [187/20000], Loss: 1364.4117431640625, Entropy -674.0819091796875, Learning Rate: 0.05\n",
      "Epoch [188/20000], Loss: 1320.328369140625, Entropy -671.5963134765625, Learning Rate: 0.05\n",
      "Epoch [189/20000], Loss: 1229.54931640625, Entropy -652.020263671875, Learning Rate: 0.05\n",
      "Epoch [190/20000], Loss: 1233.0885009765625, Entropy -669.8271484375, Learning Rate: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/20000], Loss: 1223.8671875, Entropy -680.579345703125, Learning Rate: 0.05\n",
      "Epoch [192/20000], Loss: 1210.4822998046875, Entropy -664.0689086914062, Learning Rate: 0.05\n",
      "Epoch [193/20000], Loss: 1194.95068359375, Entropy -662.7930297851562, Learning Rate: 0.05\n",
      "Epoch [194/20000], Loss: 1212.980712890625, Entropy -680.0533447265625, Learning Rate: 0.05\n",
      "Epoch [195/20000], Loss: 1215.2520751953125, Entropy -674.65087890625, Learning Rate: 0.05\n",
      "Epoch [196/20000], Loss: 1129.398193359375, Entropy -677.3185424804688, Learning Rate: 0.05\n",
      "Epoch [197/20000], Loss: 1206.550048828125, Entropy -664.322265625, Learning Rate: 0.05\n",
      "Epoch [198/20000], Loss: 1212.8558349609375, Entropy -680.9649658203125, Learning Rate: 0.05\n",
      "Epoch [199/20000], Loss: 1192.7640380859375, Entropy -670.666015625, Learning Rate: 0.05\n",
      "Epoch [200/20000], Loss: 1284.2958984375, Entropy -658.9891357421875, Learning Rate: 0.05\n",
      "Epoch [201/20000], Loss: 1146.2833251953125, Entropy -669.0416259765625, Learning Rate: 0.05\n",
      "Epoch [202/20000], Loss: 1151.036865234375, Entropy -659.8955688476562, Learning Rate: 0.05\n",
      "Epoch [203/20000], Loss: 1315.0184326171875, Entropy -677.3592529296875, Learning Rate: 0.05\n",
      "Epoch [204/20000], Loss: 1168.7864990234375, Entropy -673.2205810546875, Learning Rate: 0.05\n",
      "Epoch [205/20000], Loss: 1220.9365234375, Entropy -677.0923461914062, Learning Rate: 0.05\n",
      "Epoch [206/20000], Loss: 1104.4217529296875, Entropy -662.9932861328125, Learning Rate: 0.05\n",
      "Epoch [207/20000], Loss: 1252.4002685546875, Entropy -676.8319091796875, Learning Rate: 0.05\n",
      "Epoch [208/20000], Loss: 1273.0927734375, Entropy -667.8555297851562, Learning Rate: 0.05\n",
      "Epoch [209/20000], Loss: 1233.35888671875, Entropy -666.0224609375, Learning Rate: 0.05\n",
      "Epoch [210/20000], Loss: 1266.8876953125, Entropy -663.775634765625, Learning Rate: 0.05\n",
      "Epoch [211/20000], Loss: 1226.953369140625, Entropy -658.8103637695312, Learning Rate: 0.05\n",
      "Epoch [212/20000], Loss: 1171.93408203125, Entropy -649.1896362304688, Learning Rate: 0.05\n",
      "Epoch [213/20000], Loss: 1216.751220703125, Entropy -669.3667602539062, Learning Rate: 0.05\n",
      "Epoch [214/20000], Loss: 1159.41259765625, Entropy -683.1295776367188, Learning Rate: 0.05\n",
      "Epoch [215/20000], Loss: 1190.623046875, Entropy -659.4277954101562, Learning Rate: 0.05\n",
      "Epoch [216/20000], Loss: 1155.9088134765625, Entropy -672.6825561523438, Learning Rate: 0.05\n",
      "Epoch [217/20000], Loss: 1193.9444580078125, Entropy -672.6353149414062, Learning Rate: 0.05\n",
      "Epoch [218/20000], Loss: 1170.4500732421875, Entropy -671.9580078125, Learning Rate: 0.05\n",
      "Epoch [219/20000], Loss: 1109.3427734375, Entropy -665.2880249023438, Learning Rate: 0.05\n",
      "Epoch [220/20000], Loss: 1189.754638671875, Entropy -654.4002075195312, Learning Rate: 0.05\n",
      "Epoch [221/20000], Loss: 1141.1708984375, Entropy -677.3631591796875, Learning Rate: 0.05\n",
      "Epoch [222/20000], Loss: 1124.854736328125, Entropy -658.9404296875, Learning Rate: 0.05\n",
      "Epoch [223/20000], Loss: 1113.647705078125, Entropy -653.4652099609375, Learning Rate: 0.05\n",
      "Epoch [224/20000], Loss: 1113.1285400390625, Entropy -663.8529663085938, Learning Rate: 0.05\n",
      "Epoch [225/20000], Loss: 1115.5084228515625, Entropy -666.50927734375, Learning Rate: 0.05\n",
      "Epoch [226/20000], Loss: 1142.1993408203125, Entropy -665.4678344726562, Learning Rate: 0.05\n",
      "Epoch [227/20000], Loss: 1118.195068359375, Entropy -681.776123046875, Learning Rate: 0.05\n",
      "Epoch [228/20000], Loss: 1175.5714111328125, Entropy -680.0162353515625, Learning Rate: 0.05\n",
      "Epoch [229/20000], Loss: 1124.0516357421875, Entropy -678.04248046875, Learning Rate: 0.05\n",
      "Epoch [230/20000], Loss: 1143.9296875, Entropy -673.5667724609375, Learning Rate: 0.05\n",
      "Epoch [231/20000], Loss: 1182.230712890625, Entropy -657.494873046875, Learning Rate: 0.05\n",
      "Epoch [232/20000], Loss: 1123.461669921875, Entropy -665.4584350585938, Learning Rate: 0.05\n",
      "Epoch [233/20000], Loss: 1119.4033203125, Entropy -675.5733642578125, Learning Rate: 0.05\n",
      "Epoch [234/20000], Loss: 1107.359619140625, Entropy -669.5909423828125, Learning Rate: 0.05\n",
      "Epoch [235/20000], Loss: 1093.94189453125, Entropy -635.1273193359375, Learning Rate: 0.05\n",
      "Epoch [236/20000], Loss: 1074.7947998046875, Entropy -638.9163208007812, Learning Rate: 0.05\n",
      "Epoch [237/20000], Loss: 1134.6781005859375, Entropy -653.4763793945312, Learning Rate: 0.05\n",
      "Epoch [238/20000], Loss: 1074.3121337890625, Entropy -646.757080078125, Learning Rate: 0.05\n",
      "Epoch [239/20000], Loss: 1208.49560546875, Entropy -658.4340209960938, Learning Rate: 0.05\n",
      "Epoch [240/20000], Loss: 1098.7939453125, Entropy -666.0057373046875, Learning Rate: 0.05\n",
      "Epoch [241/20000], Loss: 1123.4266357421875, Entropy -664.3588256835938, Learning Rate: 0.05\n",
      "Epoch [242/20000], Loss: 1114.6851806640625, Entropy -656.1717529296875, Learning Rate: 0.05\n",
      "Epoch [243/20000], Loss: 1157.788330078125, Entropy -662.9337768554688, Learning Rate: 0.05\n",
      "Epoch [244/20000], Loss: 1111.5489501953125, Entropy -669.4599609375, Learning Rate: 0.05\n",
      "Epoch [245/20000], Loss: 1059.384033203125, Entropy -670.0526733398438, Learning Rate: 0.05\n",
      "Epoch [246/20000], Loss: 1137.0853271484375, Entropy -667.6767578125, Learning Rate: 0.05\n",
      "Epoch [247/20000], Loss: 1106.458984375, Entropy -655.1778564453125, Learning Rate: 0.05\n",
      "Epoch [248/20000], Loss: 1128.8350830078125, Entropy -666.297119140625, Learning Rate: 0.05\n",
      "Epoch [249/20000], Loss: 1038.4537353515625, Entropy -663.3722534179688, Learning Rate: 0.05\n",
      "Epoch [250/20000], Loss: 1178.0992431640625, Entropy -663.8010864257812, Learning Rate: 0.05\n",
      "Epoch [251/20000], Loss: 1042.6771240234375, Entropy -661.0656127929688, Learning Rate: 0.05\n",
      "Epoch [252/20000], Loss: 1170.4459228515625, Entropy -692.4368286132812, Learning Rate: 0.05\n",
      "Epoch [253/20000], Loss: 1115.930908203125, Entropy -650.9627685546875, Learning Rate: 0.05\n",
      "Epoch [254/20000], Loss: 1199.064697265625, Entropy -662.2484130859375, Learning Rate: 0.05\n",
      "Epoch [255/20000], Loss: 1153.824462890625, Entropy -661.7456665039062, Learning Rate: 0.05\n",
      "Epoch [256/20000], Loss: 1056.6087646484375, Entropy -645.18603515625, Learning Rate: 0.05\n",
      "Epoch [257/20000], Loss: 1147.1685791015625, Entropy -653.375244140625, Learning Rate: 0.05\n",
      "Epoch [258/20000], Loss: 1075.700927734375, Entropy -670.4640502929688, Learning Rate: 0.05\n",
      "Epoch [259/20000], Loss: 1035.8304443359375, Entropy -681.9878540039062, Learning Rate: 0.05\n",
      "Epoch [260/20000], Loss: 1137.2275390625, Entropy -659.4226684570312, Learning Rate: 0.05\n",
      "Epoch [261/20000], Loss: 1094.7633056640625, Entropy -656.1934814453125, Learning Rate: 0.05\n",
      "Epoch [262/20000], Loss: 1078.3685302734375, Entropy -668.5781860351562, Learning Rate: 0.05\n",
      "Epoch [263/20000], Loss: 1088.5732421875, Entropy -655.301513671875, Learning Rate: 0.05\n",
      "Epoch [264/20000], Loss: 1048.1002197265625, Entropy -667.465576171875, Learning Rate: 0.05\n",
      "Epoch [265/20000], Loss: 1137.931640625, Entropy -667.2993774414062, Learning Rate: 0.05\n",
      "Epoch [266/20000], Loss: 1085.7669677734375, Entropy -662.4437255859375, Learning Rate: 0.05\n",
      "Epoch [267/20000], Loss: 1064.45166015625, Entropy -633.7423095703125, Learning Rate: 0.05\n",
      "Epoch [268/20000], Loss: 1121.1802978515625, Entropy -660.5436401367188, Learning Rate: 0.05\n",
      "Epoch [269/20000], Loss: 1063.551025390625, Entropy -656.1199951171875, Learning Rate: 0.05\n",
      "Epoch [270/20000], Loss: 1264.620361328125, Entropy -633.775146484375, Learning Rate: 0.05\n",
      "Epoch [271/20000], Loss: 1029.8360595703125, Entropy -658.593017578125, Learning Rate: 0.05\n",
      "Epoch [272/20000], Loss: 1125.4267578125, Entropy -659.950927734375, Learning Rate: 0.05\n",
      "Epoch [273/20000], Loss: 1266.260986328125, Entropy -638.7749633789062, Learning Rate: 0.05\n",
      "Epoch [274/20000], Loss: 1008.0066528320312, Entropy -648.135986328125, Learning Rate: 0.05\n",
      "Epoch [275/20000], Loss: 1176.8245849609375, Entropy -657.6410522460938, Learning Rate: 0.05\n",
      "Epoch [276/20000], Loss: 1102.1900634765625, Entropy -652.8538818359375, Learning Rate: 0.05\n",
      "Epoch [277/20000], Loss: 1023.4964599609375, Entropy -636.2013549804688, Learning Rate: 0.05\n",
      "Epoch [278/20000], Loss: 1109.0052490234375, Entropy -645.6209716796875, Learning Rate: 0.05\n",
      "Epoch [279/20000], Loss: 1146.3857421875, Entropy -636.45458984375, Learning Rate: 0.05\n",
      "Epoch [280/20000], Loss: 1061.639892578125, Entropy -656.1889038085938, Learning Rate: 0.05\n",
      "Epoch [281/20000], Loss: 1091.7320556640625, Entropy -661.8016357421875, Learning Rate: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [282/20000], Loss: 1122.60498046875, Entropy -653.2858276367188, Learning Rate: 0.05\n",
      "Epoch [283/20000], Loss: 1147.662109375, Entropy -645.7453002929688, Learning Rate: 0.05\n",
      "Epoch [284/20000], Loss: 1043.44775390625, Entropy -653.9859619140625, Learning Rate: 0.05\n",
      "Epoch [285/20000], Loss: 1070.3055419921875, Entropy -646.826904296875, Learning Rate: 0.05\n",
      "Epoch [286/20000], Loss: 1034.790771484375, Entropy -638.3572387695312, Learning Rate: 0.05\n",
      "Epoch [287/20000], Loss: 1115.44580078125, Entropy -643.0001831054688, Learning Rate: 0.05\n",
      "Epoch [288/20000], Loss: 1092.8436279296875, Entropy -649.9864501953125, Learning Rate: 0.05\n",
      "Epoch [289/20000], Loss: 1206.5947265625, Entropy -642.6759033203125, Learning Rate: 0.05\n",
      "Epoch [290/20000], Loss: 1105.23388671875, Entropy -656.2970581054688, Learning Rate: 0.05\n",
      "Epoch [291/20000], Loss: 1215.0406494140625, Entropy -648.7464599609375, Learning Rate: 0.05\n",
      "Epoch [292/20000], Loss: 1029.12158203125, Entropy -649.6571655273438, Learning Rate: 0.05\n",
      "Epoch [293/20000], Loss: 1079.7308349609375, Entropy -652.8104248046875, Learning Rate: 0.05\n",
      "Epoch [294/20000], Loss: 1134.7271728515625, Entropy -646.7864379882812, Learning Rate: 0.05\n",
      "Epoch [295/20000], Loss: 1020.97216796875, Entropy -641.0429077148438, Learning Rate: 0.05\n",
      "Epoch [296/20000], Loss: 1095.27099609375, Entropy -654.3787841796875, Learning Rate: 0.05\n",
      "Epoch [297/20000], Loss: 1050.2672119140625, Entropy -652.7601318359375, Learning Rate: 0.05\n",
      "Epoch [298/20000], Loss: 1020.4283447265625, Entropy -656.8624877929688, Learning Rate: 0.05\n",
      "Epoch [299/20000], Loss: 1111.10693359375, Entropy -644.2080078125, Learning Rate: 0.05\n",
      "Epoch [300/20000], Loss: 1066.8494873046875, Entropy -666.531494140625, Learning Rate: 0.05\n",
      "Epoch [301/20000], Loss: 1117.5584716796875, Entropy -647.2763061523438, Learning Rate: 0.05\n",
      "Epoch [302/20000], Loss: 1091.8045654296875, Entropy -649.9639282226562, Learning Rate: 0.05\n",
      "Epoch [303/20000], Loss: 1086.114013671875, Entropy -644.492919921875, Learning Rate: 0.05\n",
      "Epoch [304/20000], Loss: 1099.556640625, Entropy -648.10107421875, Learning Rate: 0.05\n",
      "Epoch [305/20000], Loss: 1072.5521240234375, Entropy -644.8031616210938, Learning Rate: 0.05\n",
      "Epoch [306/20000], Loss: 1055.97265625, Entropy -641.051513671875, Learning Rate: 0.05\n",
      "Epoch [307/20000], Loss: 1064.0582275390625, Entropy -664.6505126953125, Learning Rate: 0.05\n",
      "Epoch [308/20000], Loss: 1084.816162109375, Entropy -633.1143798828125, Learning Rate: 0.05\n",
      "Epoch [309/20000], Loss: 1030.85107421875, Entropy -642.37646484375, Learning Rate: 0.05\n",
      "Epoch [310/20000], Loss: 1025.376708984375, Entropy -649.3154907226562, Learning Rate: 0.05\n",
      "Epoch [311/20000], Loss: 1064.08251953125, Entropy -648.29931640625, Learning Rate: 0.05\n",
      "Epoch [312/20000], Loss: 1046.470947265625, Entropy -652.4129638671875, Learning Rate: 0.05\n",
      "Epoch [313/20000], Loss: 1035.802490234375, Entropy -662.27099609375, Learning Rate: 0.05\n",
      "Epoch [314/20000], Loss: 1002.30517578125, Entropy -651.8534545898438, Learning Rate: 0.05\n",
      "Epoch [315/20000], Loss: 961.0560302734375, Entropy -638.6904296875, Learning Rate: 0.05\n",
      "Epoch [316/20000], Loss: 1027.944580078125, Entropy -659.5293579101562, Learning Rate: 0.05\n",
      "Epoch [317/20000], Loss: 1033.3818359375, Entropy -648.4942626953125, Learning Rate: 0.05\n",
      "Epoch [318/20000], Loss: 1002.930419921875, Entropy -660.2571411132812, Learning Rate: 0.05\n",
      "Epoch [319/20000], Loss: 1019.6737670898438, Entropy -651.9900512695312, Learning Rate: 0.05\n",
      "Epoch [320/20000], Loss: 980.9190063476562, Entropy -657.9886474609375, Learning Rate: 0.05\n",
      "Epoch [321/20000], Loss: 995.2647705078125, Entropy -645.5474243164062, Learning Rate: 0.05\n",
      "Epoch [322/20000], Loss: 1023.9680786132812, Entropy -668.3145751953125, Learning Rate: 0.05\n",
      "Epoch [323/20000], Loss: 1009.9072875976562, Entropy -641.2286987304688, Learning Rate: 0.05\n",
      "Epoch [324/20000], Loss: 950.4150390625, Entropy -631.6907348632812, Learning Rate: 0.05\n",
      "Epoch [325/20000], Loss: 992.0260620117188, Entropy -650.8706665039062, Learning Rate: 0.05\n",
      "Epoch [326/20000], Loss: 1007.5185546875, Entropy -647.3135375976562, Learning Rate: 0.05\n",
      "Epoch [327/20000], Loss: 972.23583984375, Entropy -665.3566284179688, Learning Rate: 0.05\n",
      "Epoch [328/20000], Loss: 1017.550537109375, Entropy -655.5880126953125, Learning Rate: 0.05\n",
      "Epoch [329/20000], Loss: 983.461181640625, Entropy -651.5214233398438, Learning Rate: 0.05\n",
      "Epoch [330/20000], Loss: 973.84912109375, Entropy -659.4166259765625, Learning Rate: 0.05\n",
      "Epoch [331/20000], Loss: 964.0106811523438, Entropy -635.318603515625, Learning Rate: 0.05\n",
      "Epoch [332/20000], Loss: 979.092529296875, Entropy -651.0209350585938, Learning Rate: 0.05\n",
      "Epoch [333/20000], Loss: 969.5637817382812, Entropy -658.8233032226562, Learning Rate: 0.05\n",
      "Epoch [334/20000], Loss: 971.612060546875, Entropy -642.6796875, Learning Rate: 0.05\n",
      "Epoch [335/20000], Loss: 980.7446899414062, Entropy -652.135498046875, Learning Rate: 0.05\n",
      "Epoch [336/20000], Loss: 988.2507934570312, Entropy -663.5663452148438, Learning Rate: 0.05\n",
      "Epoch [337/20000], Loss: 986.92041015625, Entropy -647.857666015625, Learning Rate: 0.05\n",
      "Epoch [338/20000], Loss: 985.8768920898438, Entropy -649.5243530273438, Learning Rate: 0.05\n",
      "Epoch [339/20000], Loss: 945.7029418945312, Entropy -655.8425903320312, Learning Rate: 0.05\n",
      "Epoch [340/20000], Loss: 973.85400390625, Entropy -654.3842163085938, Learning Rate: 0.05\n",
      "Epoch [341/20000], Loss: 963.0502319335938, Entropy -650.75048828125, Learning Rate: 0.05\n",
      "Epoch [342/20000], Loss: 976.4767456054688, Entropy -659.6909790039062, Learning Rate: 0.05\n",
      "Epoch [343/20000], Loss: 1003.0450439453125, Entropy -648.7694702148438, Learning Rate: 0.05\n",
      "Epoch [344/20000], Loss: 943.5975341796875, Entropy -637.6217041015625, Learning Rate: 0.05\n",
      "Epoch [345/20000], Loss: 969.8306884765625, Entropy -645.2247314453125, Learning Rate: 0.05\n",
      "Epoch [346/20000], Loss: 982.9752807617188, Entropy -666.837646484375, Learning Rate: 0.05\n",
      "Epoch [347/20000], Loss: 1026.91455078125, Entropy -674.3565673828125, Learning Rate: 0.05\n",
      "Epoch [348/20000], Loss: 982.4622192382812, Entropy -666.67822265625, Learning Rate: 0.05\n",
      "Epoch [349/20000], Loss: 993.079345703125, Entropy -659.62646484375, Learning Rate: 0.05\n",
      "Epoch [350/20000], Loss: 1043.9312744140625, Entropy -652.87353515625, Learning Rate: 0.05\n",
      "Epoch [351/20000], Loss: 904.2929077148438, Entropy -644.0919799804688, Learning Rate: 0.05\n",
      "Epoch [352/20000], Loss: 1045.2459716796875, Entropy -655.11962890625, Learning Rate: 0.05\n",
      "Epoch [353/20000], Loss: 981.8582763671875, Entropy -646.4844970703125, Learning Rate: 0.05\n",
      "Epoch [354/20000], Loss: 1003.6353149414062, Entropy -644.5476684570312, Learning Rate: 0.05\n",
      "Epoch [355/20000], Loss: 923.886962890625, Entropy -652.5798950195312, Learning Rate: 0.05\n",
      "Epoch [356/20000], Loss: 1024.303466796875, Entropy -649.9039306640625, Learning Rate: 0.05\n",
      "Epoch [357/20000], Loss: 950.2168579101562, Entropy -649.9512329101562, Learning Rate: 0.05\n",
      "Epoch [358/20000], Loss: 1079.2567138671875, Entropy -642.195556640625, Learning Rate: 0.05\n",
      "Epoch [359/20000], Loss: 982.7894287109375, Entropy -625.283447265625, Learning Rate: 0.05\n",
      "Epoch [360/20000], Loss: 1019.066162109375, Entropy -652.476806640625, Learning Rate: 0.05\n",
      "Epoch [361/20000], Loss: 960.2899780273438, Entropy -638.5042114257812, Learning Rate: 0.05\n",
      "Epoch [362/20000], Loss: 956.3793334960938, Entropy -662.1236572265625, Learning Rate: 0.05\n",
      "Epoch [363/20000], Loss: 1016.2256469726562, Entropy -653.4827270507812, Learning Rate: 0.05\n",
      "Epoch [364/20000], Loss: 1002.0608520507812, Entropy -649.46826171875, Learning Rate: 0.05\n",
      "Epoch [365/20000], Loss: 1044.44775390625, Entropy -633.4247436523438, Learning Rate: 0.05\n",
      "Epoch [366/20000], Loss: 955.4515380859375, Entropy -634.2442626953125, Learning Rate: 0.05\n",
      "Epoch [367/20000], Loss: 965.3609619140625, Entropy -640.1800537109375, Learning Rate: 0.05\n",
      "Epoch [368/20000], Loss: 983.4833374023438, Entropy -646.4265747070312, Learning Rate: 0.05\n",
      "Epoch [369/20000], Loss: 967.4552001953125, Entropy -642.5646362304688, Learning Rate: 0.05\n",
      "Epoch [370/20000], Loss: 1037.59521484375, Entropy -652.025390625, Learning Rate: 0.05\n",
      "Epoch [371/20000], Loss: 1081.687255859375, Entropy -644.07958984375, Learning Rate: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [372/20000], Loss: 1189.88427734375, Entropy -650.72705078125, Learning Rate: 0.05\n",
      "Epoch [373/20000], Loss: 1017.6375122070312, Entropy -639.0712890625, Learning Rate: 0.05\n",
      "Epoch [374/20000], Loss: 980.828369140625, Entropy -643.1722412109375, Learning Rate: 0.05\n",
      "Epoch [375/20000], Loss: 1023.9752807617188, Entropy -650.4906005859375, Learning Rate: 0.05\n",
      "Epoch [376/20000], Loss: 992.9290161132812, Entropy -639.249267578125, Learning Rate: 0.05\n",
      "Epoch [377/20000], Loss: 1036.126220703125, Entropy -648.777099609375, Learning Rate: 0.05\n",
      "Epoch [378/20000], Loss: 1021.5692749023438, Entropy -639.2091064453125, Learning Rate: 0.05\n",
      "Epoch [379/20000], Loss: 939.5604248046875, Entropy -629.4976806640625, Learning Rate: 0.05\n",
      "Epoch [380/20000], Loss: 988.6957397460938, Entropy -649.206298828125, Learning Rate: 0.05\n",
      "Epoch [381/20000], Loss: 1021.0100708007812, Entropy -663.3134155273438, Learning Rate: 0.05\n",
      "Epoch [382/20000], Loss: 974.1719970703125, Entropy -650.2024536132812, Learning Rate: 0.05\n",
      "Epoch [383/20000], Loss: 996.8746948242188, Entropy -639.0465698242188, Learning Rate: 0.05\n",
      "Epoch [384/20000], Loss: 985.7425537109375, Entropy -643.6658325195312, Learning Rate: 0.05\n",
      "Epoch [385/20000], Loss: 1093.275146484375, Entropy -633.6263427734375, Learning Rate: 0.05\n",
      "Epoch [386/20000], Loss: 1070.4384765625, Entropy -647.4998168945312, Learning Rate: 0.05\n",
      "Epoch [387/20000], Loss: 948.120849609375, Entropy -643.5260620117188, Learning Rate: 0.05\n",
      "Epoch [388/20000], Loss: 1043.9072265625, Entropy -645.9273681640625, Learning Rate: 0.05\n",
      "Epoch [389/20000], Loss: 997.0276489257812, Entropy -649.8842163085938, Learning Rate: 0.05\n",
      "Epoch [390/20000], Loss: 1015.5845947265625, Entropy -637.2652587890625, Learning Rate: 0.05\n",
      "Epoch [391/20000], Loss: 1084.891357421875, Entropy -648.292724609375, Learning Rate: 0.05\n",
      "Epoch [392/20000], Loss: 1011.6610107421875, Entropy -628.31640625, Learning Rate: 0.05\n",
      "Epoch [393/20000], Loss: 944.4794311523438, Entropy -639.259521484375, Learning Rate: 0.05\n",
      "Epoch [394/20000], Loss: 964.0875244140625, Entropy -634.703857421875, Learning Rate: 0.05\n",
      "Epoch [395/20000], Loss: 961.6546020507812, Entropy -641.7890625, Learning Rate: 0.05\n",
      "Epoch [396/20000], Loss: 1007.258056640625, Entropy -652.235107421875, Learning Rate: 0.05\n",
      "Epoch [397/20000], Loss: 999.44921875, Entropy -636.6893310546875, Learning Rate: 0.05\n",
      "Epoch [398/20000], Loss: 951.5632934570312, Entropy -623.7091064453125, Learning Rate: 0.05\n",
      "Epoch [399/20000], Loss: 970.2736206054688, Entropy -630.9500122070312, Learning Rate: 0.05\n",
      "Epoch [400/20000], Loss: 939.0895385742188, Entropy -637.5830078125, Learning Rate: 0.05\n",
      "Epoch [401/20000], Loss: 979.579833984375, Entropy -637.2516479492188, Learning Rate: 0.05\n",
      "Epoch [402/20000], Loss: 954.8661499023438, Entropy -638.2266845703125, Learning Rate: 0.05\n",
      "Epoch [403/20000], Loss: 971.19140625, Entropy -647.3377685546875, Learning Rate: 0.05\n",
      "Epoch [404/20000], Loss: 975.544921875, Entropy -639.116943359375, Learning Rate: 0.05\n",
      "Epoch [405/20000], Loss: 957.9591674804688, Entropy -632.880859375, Learning Rate: 0.05\n",
      "Epoch [406/20000], Loss: 953.6602783203125, Entropy -642.560302734375, Learning Rate: 0.05\n",
      "Epoch [407/20000], Loss: 925.8560791015625, Entropy -635.4146118164062, Learning Rate: 0.05\n",
      "Epoch [408/20000], Loss: 990.029541015625, Entropy -646.9633178710938, Learning Rate: 0.05\n",
      "Epoch [409/20000], Loss: 954.8342895507812, Entropy -638.50439453125, Learning Rate: 0.05\n",
      "Epoch [410/20000], Loss: 955.4356079101562, Entropy -633.491455078125, Learning Rate: 0.05\n",
      "Epoch [411/20000], Loss: 945.8538818359375, Entropy -636.50341796875, Learning Rate: 0.05\n",
      "Epoch [412/20000], Loss: 991.2537231445312, Entropy -624.147705078125, Learning Rate: 0.05\n",
      "Epoch [413/20000], Loss: 1023.5106201171875, Entropy -646.19580078125, Learning Rate: 0.05\n",
      "Epoch [414/20000], Loss: 1040.4263916015625, Entropy -642.2366943359375, Learning Rate: 0.05\n",
      "Epoch [415/20000], Loss: 916.3737182617188, Entropy -639.9804077148438, Learning Rate: 0.05\n",
      "Epoch [416/20000], Loss: 964.0978393554688, Entropy -655.484619140625, Learning Rate: 0.05\n",
      "Epoch [417/20000], Loss: 985.0091552734375, Entropy -637.1558837890625, Learning Rate: 0.05\n",
      "Epoch [418/20000], Loss: 982.6886596679688, Entropy -650.1002807617188, Learning Rate: 0.05\n",
      "Epoch [419/20000], Loss: 923.7900390625, Entropy -631.2969970703125, Learning Rate: 0.05\n",
      "Epoch [420/20000], Loss: 951.4548950195312, Entropy -637.785400390625, Learning Rate: 0.05\n",
      "Epoch [421/20000], Loss: 943.0435791015625, Entropy -625.7929077148438, Learning Rate: 0.05\n",
      "Epoch [422/20000], Loss: 929.4139404296875, Entropy -650.738037109375, Learning Rate: 0.05\n",
      "Epoch [423/20000], Loss: 951.25732421875, Entropy -658.5877685546875, Learning Rate: 0.05\n",
      "Epoch [424/20000], Loss: 954.067138671875, Entropy -634.4791259765625, Learning Rate: 0.05\n",
      "Epoch [425/20000], Loss: 994.4332885742188, Entropy -639.4224853515625, Learning Rate: 0.05\n",
      "Epoch [426/20000], Loss: 946.9244995117188, Entropy -642.1438598632812, Learning Rate: 0.05\n",
      "Epoch [427/20000], Loss: 932.3731079101562, Entropy -640.1047973632812, Learning Rate: 0.05\n",
      "Epoch [428/20000], Loss: 979.4664306640625, Entropy -627.5741577148438, Learning Rate: 0.05\n",
      "Epoch [429/20000], Loss: 969.1976928710938, Entropy -639.2001953125, Learning Rate: 0.05\n",
      "Epoch [430/20000], Loss: 943.6668701171875, Entropy -632.5885009765625, Learning Rate: 0.05\n",
      "Epoch [431/20000], Loss: 932.3411865234375, Entropy -639.3899536132812, Learning Rate: 0.05\n",
      "Epoch [432/20000], Loss: 961.6861572265625, Entropy -630.2546997070312, Learning Rate: 0.05\n",
      "Epoch [433/20000], Loss: 964.3818969726562, Entropy -643.7645263671875, Learning Rate: 0.05\n",
      "Epoch [434/20000], Loss: 942.8719482421875, Entropy -628.0242919921875, Learning Rate: 0.05\n",
      "Epoch [435/20000], Loss: 1048.2537841796875, Entropy -600.3880615234375, Learning Rate: 0.05\n",
      "Epoch [436/20000], Loss: 932.7984619140625, Entropy -641.75634765625, Learning Rate: 0.05\n",
      "Epoch [437/20000], Loss: 987.3823852539062, Entropy -644.8543701171875, Learning Rate: 0.05\n",
      "Epoch [438/20000], Loss: 1020.9996948242188, Entropy -620.6802368164062, Learning Rate: 0.05\n",
      "Epoch [439/20000], Loss: 1014.7445068359375, Entropy -605.7425537109375, Learning Rate: 0.05\n",
      "Epoch [440/20000], Loss: 1123.005859375, Entropy -617.200927734375, Learning Rate: 0.05\n",
      "Epoch [441/20000], Loss: 1177.85302734375, Entropy -633.692138671875, Learning Rate: 0.05\n",
      "Epoch [442/20000], Loss: 1007.5370483398438, Entropy -627.6090698242188, Learning Rate: 0.05\n",
      "Epoch [443/20000], Loss: 971.4301147460938, Entropy -645.6792602539062, Learning Rate: 0.05\n",
      "Epoch [444/20000], Loss: 1029.5738525390625, Entropy -640.2993774414062, Learning Rate: 0.05\n",
      "Epoch [445/20000], Loss: 973.663330078125, Entropy -630.2772216796875, Learning Rate: 0.05\n",
      "Epoch [446/20000], Loss: 958.0502319335938, Entropy -644.49560546875, Learning Rate: 0.05\n",
      "Epoch [447/20000], Loss: 972.243408203125, Entropy -634.7633056640625, Learning Rate: 0.05\n",
      "Epoch [448/20000], Loss: 957.6271362304688, Entropy -639.96875, Learning Rate: 0.05\n",
      "Epoch [449/20000], Loss: 940.0367431640625, Entropy -634.68212890625, Learning Rate: 0.05\n",
      "Epoch [450/20000], Loss: 967.8922729492188, Entropy -622.9259643554688, Learning Rate: 0.05\n",
      "Epoch [451/20000], Loss: 963.8397216796875, Entropy -626.5042114257812, Learning Rate: 0.05\n",
      "Epoch [452/20000], Loss: 927.4177856445312, Entropy -639.6194458007812, Learning Rate: 0.05\n",
      "Epoch [453/20000], Loss: 1025.515380859375, Entropy -622.1770629882812, Learning Rate: 0.025\n",
      "Epoch [454/20000], Loss: 938.701171875, Entropy -645.1611328125, Learning Rate: 0.025\n",
      "Epoch [455/20000], Loss: 904.9334106445312, Entropy -621.3297119140625, Learning Rate: 0.025\n",
      "Epoch [456/20000], Loss: 936.2774658203125, Entropy -627.793701171875, Learning Rate: 0.025\n",
      "Epoch [457/20000], Loss: 918.2335815429688, Entropy -648.8114013671875, Learning Rate: 0.025\n",
      "Epoch [458/20000], Loss: 901.7760009765625, Entropy -632.1954956054688, Learning Rate: 0.025\n",
      "Epoch [459/20000], Loss: 943.3110961914062, Entropy -626.8173217773438, Learning Rate: 0.025\n",
      "Epoch [460/20000], Loss: 932.1502075195312, Entropy -646.455810546875, Learning Rate: 0.025\n",
      "Epoch [461/20000], Loss: 916.0517578125, Entropy -627.64501953125, Learning Rate: 0.025\n",
      "Epoch [462/20000], Loss: 949.685791015625, Entropy -644.0518798828125, Learning Rate: 0.025\n",
      "Epoch [463/20000], Loss: 886.90869140625, Entropy -631.6084594726562, Learning Rate: 0.025\n",
      "Epoch [464/20000], Loss: 928.261474609375, Entropy -650.1249389648438, Learning Rate: 0.025\n",
      "Epoch [465/20000], Loss: 950.2864990234375, Entropy -636.6089477539062, Learning Rate: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [466/20000], Loss: 970.2805786132812, Entropy -635.730224609375, Learning Rate: 0.025\n",
      "Epoch [467/20000], Loss: 880.6124877929688, Entropy -601.5137939453125, Learning Rate: 0.025\n",
      "Epoch [468/20000], Loss: 928.70068359375, Entropy -643.515869140625, Learning Rate: 0.025\n",
      "Epoch [469/20000], Loss: 908.5155639648438, Entropy -643.8715209960938, Learning Rate: 0.025\n",
      "Epoch [470/20000], Loss: 922.645263671875, Entropy -649.9656372070312, Learning Rate: 0.025\n",
      "Epoch [471/20000], Loss: 926.6649780273438, Entropy -646.857666015625, Learning Rate: 0.025\n",
      "Epoch [472/20000], Loss: 905.5877075195312, Entropy -630.0064086914062, Learning Rate: 0.025\n",
      "Epoch [473/20000], Loss: 896.9744262695312, Entropy -643.4158325195312, Learning Rate: 0.025\n",
      "Epoch [474/20000], Loss: 888.64208984375, Entropy -632.6854248046875, Learning Rate: 0.025\n",
      "Epoch [475/20000], Loss: 879.5672607421875, Entropy -626.82763671875, Learning Rate: 0.025\n",
      "Epoch [476/20000], Loss: 893.0722045898438, Entropy -625.2318725585938, Learning Rate: 0.025\n",
      "Epoch [477/20000], Loss: 897.2890625, Entropy -639.3753662109375, Learning Rate: 0.025\n",
      "Epoch [478/20000], Loss: 880.1272583007812, Entropy -639.63671875, Learning Rate: 0.025\n",
      "Epoch [479/20000], Loss: 909.33984375, Entropy -647.8167724609375, Learning Rate: 0.025\n",
      "Epoch [480/20000], Loss: 908.7003173828125, Entropy -639.983642578125, Learning Rate: 0.025\n",
      "Epoch [481/20000], Loss: 859.2059936523438, Entropy -620.284423828125, Learning Rate: 0.025\n",
      "Epoch [482/20000], Loss: 908.3177490234375, Entropy -630.618408203125, Learning Rate: 0.025\n",
      "Epoch [483/20000], Loss: 895.8214111328125, Entropy -635.167236328125, Learning Rate: 0.025\n",
      "Epoch [484/20000], Loss: 863.156982421875, Entropy -631.352783203125, Learning Rate: 0.025\n",
      "Epoch [485/20000], Loss: 869.7348022460938, Entropy -612.226806640625, Learning Rate: 0.025\n",
      "Epoch [486/20000], Loss: 908.8861694335938, Entropy -629.1763916015625, Learning Rate: 0.025\n",
      "Epoch [487/20000], Loss: 884.6165161132812, Entropy -621.4853515625, Learning Rate: 0.025\n",
      "Epoch [488/20000], Loss: 861.560791015625, Entropy -630.5983276367188, Learning Rate: 0.025\n",
      "Epoch [489/20000], Loss: 886.8250732421875, Entropy -626.072509765625, Learning Rate: 0.025\n",
      "Epoch [490/20000], Loss: 898.7055053710938, Entropy -639.9340209960938, Learning Rate: 0.025\n",
      "Epoch [491/20000], Loss: 870.9886474609375, Entropy -627.8358154296875, Learning Rate: 0.025\n",
      "Epoch [492/20000], Loss: 886.476318359375, Entropy -629.59130859375, Learning Rate: 0.025\n",
      "Epoch [493/20000], Loss: 887.4982299804688, Entropy -626.6905517578125, Learning Rate: 0.025\n",
      "Epoch [494/20000], Loss: 857.1926879882812, Entropy -615.239501953125, Learning Rate: 0.025\n",
      "Epoch [495/20000], Loss: 846.385986328125, Entropy -607.5650634765625, Learning Rate: 0.025\n",
      "Epoch [496/20000], Loss: 876.99609375, Entropy -644.816162109375, Learning Rate: 0.025\n",
      "Epoch [497/20000], Loss: 858.9971313476562, Entropy -623.7860107421875, Learning Rate: 0.025\n",
      "Epoch [498/20000], Loss: 868.8929443359375, Entropy -622.0902709960938, Learning Rate: 0.025\n",
      "Epoch [499/20000], Loss: 884.6301879882812, Entropy -643.2130737304688, Learning Rate: 0.025\n",
      "Epoch [500/20000], Loss: 871.9988403320312, Entropy -628.440185546875, Learning Rate: 0.025\n",
      "Epoch [501/20000], Loss: 876.6151733398438, Entropy -633.2830200195312, Learning Rate: 0.025\n",
      "Epoch [502/20000], Loss: 870.85595703125, Entropy -646.4149169921875, Learning Rate: 0.025\n",
      "Epoch [503/20000], Loss: 887.8211059570312, Entropy -643.2399291992188, Learning Rate: 0.025\n",
      "Epoch [504/20000], Loss: 882.5355834960938, Entropy -635.057373046875, Learning Rate: 0.025\n",
      "Epoch [505/20000], Loss: 916.529052734375, Entropy -639.1004028320312, Learning Rate: 0.025\n",
      "Epoch [506/20000], Loss: 858.980224609375, Entropy -620.9658813476562, Learning Rate: 0.025\n",
      "Epoch [507/20000], Loss: 912.5430908203125, Entropy -628.8831787109375, Learning Rate: 0.025\n",
      "Epoch [508/20000], Loss: 874.1039428710938, Entropy -640.6224365234375, Learning Rate: 0.025\n",
      "Epoch [509/20000], Loss: 865.7904663085938, Entropy -627.0238647460938, Learning Rate: 0.025\n",
      "Epoch [510/20000], Loss: 884.4468383789062, Entropy -615.0442504882812, Learning Rate: 0.025\n",
      "Epoch [511/20000], Loss: 873.609619140625, Entropy -631.6090087890625, Learning Rate: 0.025\n",
      "Epoch [512/20000], Loss: 836.9349365234375, Entropy -616.9193725585938, Learning Rate: 0.025\n",
      "Epoch [513/20000], Loss: 871.3776245117188, Entropy -625.2393798828125, Learning Rate: 0.025\n",
      "Epoch [514/20000], Loss: 906.437255859375, Entropy -633.85498046875, Learning Rate: 0.025\n",
      "Epoch [515/20000], Loss: 869.2566528320312, Entropy -632.255859375, Learning Rate: 0.025\n",
      "Epoch [516/20000], Loss: 873.9049682617188, Entropy -620.4118041992188, Learning Rate: 0.025\n",
      "Epoch [517/20000], Loss: 881.2078247070312, Entropy -630.4544067382812, Learning Rate: 0.025\n",
      "Epoch [518/20000], Loss: 891.374755859375, Entropy -639.605224609375, Learning Rate: 0.025\n",
      "Epoch [519/20000], Loss: 885.98291015625, Entropy -618.1075439453125, Learning Rate: 0.025\n",
      "Epoch [520/20000], Loss: 865.9187622070312, Entropy -626.27392578125, Learning Rate: 0.025\n",
      "Epoch [521/20000], Loss: 892.8759765625, Entropy -623.806640625, Learning Rate: 0.025\n",
      "Epoch [522/20000], Loss: 885.7654418945312, Entropy -627.08740234375, Learning Rate: 0.025\n",
      "Epoch [523/20000], Loss: 852.4706420898438, Entropy -617.5191650390625, Learning Rate: 0.025\n",
      "Epoch [524/20000], Loss: 857.3933715820312, Entropy -617.1162109375, Learning Rate: 0.025\n",
      "Epoch [525/20000], Loss: 914.5480346679688, Entropy -630.1248168945312, Learning Rate: 0.025\n",
      "Epoch [526/20000], Loss: 876.3469848632812, Entropy -637.3919067382812, Learning Rate: 0.025\n",
      "Epoch [527/20000], Loss: 857.8668212890625, Entropy -627.229248046875, Learning Rate: 0.025\n",
      "Epoch [528/20000], Loss: 853.017333984375, Entropy -618.280517578125, Learning Rate: 0.025\n",
      "Epoch [529/20000], Loss: 893.383056640625, Entropy -621.875244140625, Learning Rate: 0.025\n",
      "Epoch [530/20000], Loss: 858.1971435546875, Entropy -619.1920166015625, Learning Rate: 0.025\n",
      "Epoch [531/20000], Loss: 858.0909423828125, Entropy -615.7096557617188, Learning Rate: 0.025\n",
      "Epoch [532/20000], Loss: 858.4241943359375, Entropy -621.6602172851562, Learning Rate: 0.025\n",
      "Epoch [533/20000], Loss: 842.5853271484375, Entropy -628.6980590820312, Learning Rate: 0.025\n",
      "Epoch [534/20000], Loss: 851.7755126953125, Entropy -622.2591552734375, Learning Rate: 0.025\n",
      "Epoch [535/20000], Loss: 854.4610595703125, Entropy -608.5303955078125, Learning Rate: 0.025\n",
      "Epoch [536/20000], Loss: 836.1533203125, Entropy -605.8363647460938, Learning Rate: 0.025\n",
      "Epoch [537/20000], Loss: 831.7294921875, Entropy -603.821533203125, Learning Rate: 0.025\n",
      "Epoch [538/20000], Loss: 889.9868774414062, Entropy -632.9752197265625, Learning Rate: 0.025\n",
      "Epoch [539/20000], Loss: 844.8148193359375, Entropy -626.7750244140625, Learning Rate: 0.025\n",
      "Epoch [540/20000], Loss: 882.9119873046875, Entropy -642.1456909179688, Learning Rate: 0.025\n",
      "Epoch [541/20000], Loss: 853.5773315429688, Entropy -631.05029296875, Learning Rate: 0.025\n",
      "Epoch [542/20000], Loss: 902.9273681640625, Entropy -648.589599609375, Learning Rate: 0.025\n",
      "Epoch [543/20000], Loss: 835.5474243164062, Entropy -613.634765625, Learning Rate: 0.025\n",
      "Epoch [544/20000], Loss: 865.8477172851562, Entropy -647.0810546875, Learning Rate: 0.025\n",
      "Epoch [545/20000], Loss: 850.1220703125, Entropy -613.4613037109375, Learning Rate: 0.025\n",
      "Epoch [546/20000], Loss: 837.8613891601562, Entropy -603.9937744140625, Learning Rate: 0.025\n",
      "Epoch [547/20000], Loss: 859.6648559570312, Entropy -609.5875854492188, Learning Rate: 0.025\n",
      "Epoch [548/20000], Loss: 836.2354736328125, Entropy -606.8726196289062, Learning Rate: 0.025\n",
      "Epoch [549/20000], Loss: 904.5771484375, Entropy -646.1409301757812, Learning Rate: 0.025\n",
      "Epoch [550/20000], Loss: 882.232666015625, Entropy -625.5538330078125, Learning Rate: 0.025\n",
      "Epoch [551/20000], Loss: 852.1459350585938, Entropy -622.01904296875, Learning Rate: 0.025\n",
      "Epoch [552/20000], Loss: 855.31396484375, Entropy -626.0862426757812, Learning Rate: 0.025\n",
      "Epoch [553/20000], Loss: 830.723388671875, Entropy -602.852783203125, Learning Rate: 0.025\n",
      "Epoch [554/20000], Loss: 868.1456909179688, Entropy -611.5573120117188, Learning Rate: 0.025\n",
      "Epoch [555/20000], Loss: 856.3434448242188, Entropy -608.2380981445312, Learning Rate: 0.025\n",
      "Epoch [556/20000], Loss: 890.2080688476562, Entropy -628.1558837890625, Learning Rate: 0.025\n",
      "Epoch [557/20000], Loss: 834.620361328125, Entropy -607.1195068359375, Learning Rate: 0.025\n",
      "Epoch [558/20000], Loss: 878.5821533203125, Entropy -632.7420654296875, Learning Rate: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [559/20000], Loss: 918.8614501953125, Entropy -619.9102783203125, Learning Rate: 0.025\n",
      "Epoch [560/20000], Loss: 867.0537109375, Entropy -622.248779296875, Learning Rate: 0.025\n",
      "Epoch [561/20000], Loss: 870.7639770507812, Entropy -630.8809814453125, Learning Rate: 0.025\n",
      "Epoch [562/20000], Loss: 839.3795166015625, Entropy -595.020263671875, Learning Rate: 0.025\n",
      "Epoch [563/20000], Loss: 890.63818359375, Entropy -626.3421020507812, Learning Rate: 0.025\n",
      "Epoch [564/20000], Loss: 884.1104736328125, Entropy -642.8135986328125, Learning Rate: 0.025\n",
      "Epoch [565/20000], Loss: 848.3388061523438, Entropy -619.6113891601562, Learning Rate: 0.025\n",
      "Epoch [566/20000], Loss: 882.2625732421875, Entropy -623.83203125, Learning Rate: 0.025\n",
      "Epoch [567/20000], Loss: 858.2948608398438, Entropy -612.3029174804688, Learning Rate: 0.025\n",
      "Epoch [568/20000], Loss: 861.1693725585938, Entropy -614.21337890625, Learning Rate: 0.025\n",
      "Epoch [569/20000], Loss: 856.7506103515625, Entropy -612.734619140625, Learning Rate: 0.025\n",
      "Epoch [570/20000], Loss: 864.308837890625, Entropy -592.369873046875, Learning Rate: 0.025\n",
      "Epoch [571/20000], Loss: 873.3001098632812, Entropy -637.4095458984375, Learning Rate: 0.025\n",
      "Epoch [572/20000], Loss: 821.5823364257812, Entropy -606.470703125, Learning Rate: 0.025\n",
      "Epoch [573/20000], Loss: 866.3094482421875, Entropy -627.3543701171875, Learning Rate: 0.025\n",
      "Epoch [574/20000], Loss: 852.3438720703125, Entropy -604.2400512695312, Learning Rate: 0.025\n",
      "Epoch [575/20000], Loss: 846.0243530273438, Entropy -607.3219604492188, Learning Rate: 0.025\n",
      "Epoch [576/20000], Loss: 835.7291870117188, Entropy -620.965087890625, Learning Rate: 0.025\n",
      "Epoch [577/20000], Loss: 846.8411254882812, Entropy -597.650634765625, Learning Rate: 0.025\n",
      "Epoch [578/20000], Loss: 878.2664794921875, Entropy -616.7381591796875, Learning Rate: 0.025\n",
      "Epoch [579/20000], Loss: 835.851318359375, Entropy -605.8126220703125, Learning Rate: 0.025\n",
      "Epoch [580/20000], Loss: 852.9351806640625, Entropy -619.7908935546875, Learning Rate: 0.025\n",
      "Epoch [581/20000], Loss: 861.451904296875, Entropy -609.1217041015625, Learning Rate: 0.025\n",
      "Epoch [582/20000], Loss: 828.01513671875, Entropy -589.708740234375, Learning Rate: 0.025\n",
      "Epoch [583/20000], Loss: 830.2720947265625, Entropy -609.148681640625, Learning Rate: 0.025\n",
      "Epoch [584/20000], Loss: 828.2379150390625, Entropy -628.7987060546875, Learning Rate: 0.025\n",
      "Epoch [585/20000], Loss: 861.9067993164062, Entropy -630.7755737304688, Learning Rate: 0.025\n",
      "Epoch [586/20000], Loss: 830.0220947265625, Entropy -620.3305053710938, Learning Rate: 0.025\n",
      "Epoch [587/20000], Loss: 857.1109008789062, Entropy -598.1221923828125, Learning Rate: 0.025\n",
      "Epoch [588/20000], Loss: 832.8828125, Entropy -611.3316650390625, Learning Rate: 0.025\n",
      "Epoch [589/20000], Loss: 834.925537109375, Entropy -612.0108642578125, Learning Rate: 0.025\n",
      "Epoch [590/20000], Loss: 845.0712890625, Entropy -621.9987182617188, Learning Rate: 0.025\n",
      "Epoch [591/20000], Loss: 831.4295043945312, Entropy -608.5491943359375, Learning Rate: 0.025\n",
      "Epoch [592/20000], Loss: 820.97412109375, Entropy -600.670166015625, Learning Rate: 0.025\n",
      "Epoch [593/20000], Loss: 827.8363647460938, Entropy -619.376953125, Learning Rate: 0.025\n",
      "Epoch [594/20000], Loss: 853.6884765625, Entropy -609.9511108398438, Learning Rate: 0.025\n",
      "Epoch [595/20000], Loss: 814.8013916015625, Entropy -595.2557373046875, Learning Rate: 0.025\n",
      "Epoch [596/20000], Loss: 895.1083984375, Entropy -614.1758422851562, Learning Rate: 0.025\n",
      "Epoch [597/20000], Loss: 843.18701171875, Entropy -595.5032958984375, Learning Rate: 0.025\n",
      "Epoch [598/20000], Loss: 823.666015625, Entropy -607.085205078125, Learning Rate: 0.025\n",
      "Epoch [599/20000], Loss: 836.8803100585938, Entropy -615.0880737304688, Learning Rate: 0.025\n",
      "Epoch [600/20000], Loss: 837.1256103515625, Entropy -605.0428466796875, Learning Rate: 0.025\n",
      "Epoch [601/20000], Loss: 835.4990234375, Entropy -605.6063842773438, Learning Rate: 0.025\n",
      "Epoch [602/20000], Loss: 814.0130004882812, Entropy -592.7918701171875, Learning Rate: 0.025\n",
      "Epoch [603/20000], Loss: 843.5902099609375, Entropy -609.0972290039062, Learning Rate: 0.025\n",
      "Epoch [604/20000], Loss: 817.910400390625, Entropy -595.94775390625, Learning Rate: 0.025\n",
      "Epoch [605/20000], Loss: 864.3012084960938, Entropy -613.20654296875, Learning Rate: 0.025\n",
      "Epoch [606/20000], Loss: 848.3104858398438, Entropy -618.7947998046875, Learning Rate: 0.025\n",
      "Epoch [607/20000], Loss: 808.3659057617188, Entropy -601.9676513671875, Learning Rate: 0.025\n",
      "Epoch [608/20000], Loss: 806.512451171875, Entropy -584.3326416015625, Learning Rate: 0.025\n",
      "Epoch [609/20000], Loss: 815.197509765625, Entropy -620.3458251953125, Learning Rate: 0.025\n",
      "Epoch [610/20000], Loss: 835.4741821289062, Entropy -609.3673095703125, Learning Rate: 0.025\n",
      "Epoch [611/20000], Loss: 812.2584838867188, Entropy -612.9066162109375, Learning Rate: 0.025\n",
      "Epoch [612/20000], Loss: 814.0794067382812, Entropy -605.607421875, Learning Rate: 0.025\n",
      "Epoch [613/20000], Loss: 809.36376953125, Entropy -599.433349609375, Learning Rate: 0.025\n",
      "Epoch [614/20000], Loss: 819.6615600585938, Entropy -614.3448486328125, Learning Rate: 0.025\n",
      "Epoch [615/20000], Loss: 811.6300659179688, Entropy -607.402099609375, Learning Rate: 0.025\n",
      "Epoch [616/20000], Loss: 784.7175903320312, Entropy -587.11572265625, Learning Rate: 0.025\n",
      "Epoch [617/20000], Loss: 802.3028564453125, Entropy -596.6299438476562, Learning Rate: 0.025\n",
      "Epoch [618/20000], Loss: 843.0559692382812, Entropy -602.99658203125, Learning Rate: 0.025\n",
      "Epoch [619/20000], Loss: 822.367919921875, Entropy -607.9555053710938, Learning Rate: 0.025\n",
      "Epoch [620/20000], Loss: 815.8604736328125, Entropy -594.1019287109375, Learning Rate: 0.025\n",
      "Epoch [621/20000], Loss: 810.9456787109375, Entropy -600.5763549804688, Learning Rate: 0.025\n",
      "Epoch [622/20000], Loss: 843.0320434570312, Entropy -591.3590087890625, Learning Rate: 0.025\n",
      "Epoch [623/20000], Loss: 834.0423583984375, Entropy -614.737060546875, Learning Rate: 0.025\n",
      "Epoch [624/20000], Loss: 807.5804443359375, Entropy -573.624267578125, Learning Rate: 0.025\n",
      "Epoch [625/20000], Loss: 807.0570068359375, Entropy -588.0975341796875, Learning Rate: 0.025\n",
      "Epoch [626/20000], Loss: 786.7529296875, Entropy -596.4708251953125, Learning Rate: 0.025\n",
      "Epoch [627/20000], Loss: 799.4412841796875, Entropy -596.2832641601562, Learning Rate: 0.025\n",
      "Epoch [628/20000], Loss: 812.890869140625, Entropy -593.1827392578125, Learning Rate: 0.025\n",
      "Epoch [629/20000], Loss: 790.4520874023438, Entropy -587.64013671875, Learning Rate: 0.025\n",
      "Epoch [630/20000], Loss: 809.1919555664062, Entropy -593.534423828125, Learning Rate: 0.025\n",
      "Epoch [631/20000], Loss: 790.26953125, Entropy -604.1148681640625, Learning Rate: 0.025\n",
      "Epoch [632/20000], Loss: 813.6285400390625, Entropy -609.0889892578125, Learning Rate: 0.025\n",
      "Epoch [633/20000], Loss: 804.1771850585938, Entropy -598.510009765625, Learning Rate: 0.025\n",
      "Epoch [634/20000], Loss: 799.7275390625, Entropy -601.2183227539062, Learning Rate: 0.025\n",
      "Epoch [635/20000], Loss: 793.9050903320312, Entropy -592.8235473632812, Learning Rate: 0.025\n",
      "Epoch [636/20000], Loss: 790.0107421875, Entropy -598.96630859375, Learning Rate: 0.025\n",
      "Epoch [637/20000], Loss: 781.6796264648438, Entropy -583.51171875, Learning Rate: 0.025\n",
      "Epoch [638/20000], Loss: 799.4844360351562, Entropy -586.069091796875, Learning Rate: 0.025\n",
      "Epoch [639/20000], Loss: 795.8355712890625, Entropy -611.59912109375, Learning Rate: 0.025\n",
      "Epoch [640/20000], Loss: 828.298095703125, Entropy -604.3681640625, Learning Rate: 0.025\n",
      "Epoch [641/20000], Loss: 805.14990234375, Entropy -604.3051147460938, Learning Rate: 0.025\n",
      "Epoch [642/20000], Loss: 834.2432250976562, Entropy -598.6260375976562, Learning Rate: 0.025\n",
      "Epoch [643/20000], Loss: 806.8570556640625, Entropy -590.680419921875, Learning Rate: 0.025\n",
      "Epoch [644/20000], Loss: 806.2083740234375, Entropy -575.698486328125, Learning Rate: 0.025\n",
      "Epoch [645/20000], Loss: 813.0956420898438, Entropy -581.6533813476562, Learning Rate: 0.025\n",
      "Epoch [646/20000], Loss: 792.2103881835938, Entropy -572.3298950195312, Learning Rate: 0.025\n",
      "Epoch [647/20000], Loss: 815.8585205078125, Entropy -582.8116455078125, Learning Rate: 0.025\n",
      "Epoch [648/20000], Loss: 843.7258911132812, Entropy -619.9473266601562, Learning Rate: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [649/20000], Loss: 810.180419921875, Entropy -603.7877197265625, Learning Rate: 0.025\n",
      "Epoch [650/20000], Loss: 784.9221801757812, Entropy -596.3776245117188, Learning Rate: 0.025\n",
      "Epoch [651/20000], Loss: 818.2252197265625, Entropy -584.18994140625, Learning Rate: 0.025\n",
      "Epoch [652/20000], Loss: 796.7614135742188, Entropy -587.6463623046875, Learning Rate: 0.025\n",
      "Epoch [653/20000], Loss: 811.385498046875, Entropy -593.507080078125, Learning Rate: 0.025\n",
      "Epoch [654/20000], Loss: 802.8959350585938, Entropy -579.0506591796875, Learning Rate: 0.025\n",
      "Epoch [655/20000], Loss: 818.1876831054688, Entropy -589.01708984375, Learning Rate: 0.025\n",
      "Epoch [656/20000], Loss: 768.5260009765625, Entropy -586.2549438476562, Learning Rate: 0.025\n",
      "Epoch [657/20000], Loss: 806.4053344726562, Entropy -589.1961669921875, Learning Rate: 0.025\n",
      "Epoch [658/20000], Loss: 829.279541015625, Entropy -595.2721557617188, Learning Rate: 0.025\n",
      "Epoch [659/20000], Loss: 806.410400390625, Entropy -586.2070922851562, Learning Rate: 0.025\n",
      "Epoch [660/20000], Loss: 817.5905151367188, Entropy -606.6826782226562, Learning Rate: 0.025\n",
      "Epoch [661/20000], Loss: 810.6114501953125, Entropy -577.6879272460938, Learning Rate: 0.025\n",
      "Epoch [662/20000], Loss: 789.58837890625, Entropy -594.0501098632812, Learning Rate: 0.025\n",
      "Epoch [663/20000], Loss: 822.03515625, Entropy -588.7203979492188, Learning Rate: 0.025\n",
      "Epoch [664/20000], Loss: 818.1890258789062, Entropy -595.1237182617188, Learning Rate: 0.025\n",
      "Epoch [665/20000], Loss: 811.2481079101562, Entropy -584.0472412109375, Learning Rate: 0.025\n",
      "Epoch [666/20000], Loss: 832.891357421875, Entropy -603.39794921875, Learning Rate: 0.025\n",
      "Epoch [667/20000], Loss: 777.5940551757812, Entropy -581.4403686523438, Learning Rate: 0.025\n",
      "Epoch [668/20000], Loss: 775.3318481445312, Entropy -575.974609375, Learning Rate: 0.025\n",
      "Epoch [669/20000], Loss: 799.9930419921875, Entropy -581.633056640625, Learning Rate: 0.025\n",
      "Epoch [670/20000], Loss: 791.05615234375, Entropy -596.10400390625, Learning Rate: 0.025\n",
      "Epoch [671/20000], Loss: 784.5359497070312, Entropy -585.5197143554688, Learning Rate: 0.025\n",
      "Epoch [672/20000], Loss: 795.6890258789062, Entropy -588.2444458007812, Learning Rate: 0.025\n",
      "Epoch [673/20000], Loss: 802.3621826171875, Entropy -596.5975341796875, Learning Rate: 0.025\n",
      "Epoch [674/20000], Loss: 803.9241943359375, Entropy -604.00390625, Learning Rate: 0.025\n",
      "Epoch [675/20000], Loss: 789.53759765625, Entropy -584.4137573242188, Learning Rate: 0.025\n",
      "Epoch [676/20000], Loss: 798.7470703125, Entropy -605.52587890625, Learning Rate: 0.025\n",
      "Epoch [677/20000], Loss: 778.8690185546875, Entropy -592.4910888671875, Learning Rate: 0.025\n",
      "Epoch [678/20000], Loss: 767.2628173828125, Entropy -577.0225830078125, Learning Rate: 0.025\n",
      "Epoch [679/20000], Loss: 798.4859619140625, Entropy -588.6148071289062, Learning Rate: 0.025\n",
      "Epoch [680/20000], Loss: 760.797119140625, Entropy -564.0496826171875, Learning Rate: 0.025\n",
      "Epoch [681/20000], Loss: 796.7991333007812, Entropy -597.6958618164062, Learning Rate: 0.025\n",
      "Epoch [682/20000], Loss: 785.2367553710938, Entropy -585.470947265625, Learning Rate: 0.025\n",
      "Epoch [683/20000], Loss: 789.6693115234375, Entropy -581.2106323242188, Learning Rate: 0.025\n",
      "Epoch [684/20000], Loss: 786.177978515625, Entropy -590.54248046875, Learning Rate: 0.025\n",
      "Epoch [685/20000], Loss: 784.8831787109375, Entropy -576.5109252929688, Learning Rate: 0.025\n",
      "Epoch [686/20000], Loss: 792.2734375, Entropy -591.8014526367188, Learning Rate: 0.025\n",
      "Epoch [687/20000], Loss: 791.42919921875, Entropy -579.5549926757812, Learning Rate: 0.025\n",
      "Epoch [688/20000], Loss: 767.4271850585938, Entropy -582.4517822265625, Learning Rate: 0.025\n",
      "Epoch [689/20000], Loss: 800.4904174804688, Entropy -585.6487426757812, Learning Rate: 0.025\n",
      "Epoch [690/20000], Loss: 794.7418212890625, Entropy -593.45849609375, Learning Rate: 0.025\n",
      "Epoch [691/20000], Loss: 761.9857788085938, Entropy -572.8812255859375, Learning Rate: 0.025\n",
      "Epoch [692/20000], Loss: 792.00830078125, Entropy -584.1658935546875, Learning Rate: 0.025\n",
      "Epoch [693/20000], Loss: 780.3228759765625, Entropy -587.4266357421875, Learning Rate: 0.025\n",
      "Epoch [694/20000], Loss: 825.9181518554688, Entropy -600.484130859375, Learning Rate: 0.025\n",
      "Epoch [695/20000], Loss: 780.7802124023438, Entropy -581.0551147460938, Learning Rate: 0.025\n",
      "Epoch [696/20000], Loss: 831.046142578125, Entropy -604.5404663085938, Learning Rate: 0.025\n",
      "Epoch [697/20000], Loss: 841.498046875, Entropy -598.89111328125, Learning Rate: 0.025\n",
      "Epoch [698/20000], Loss: 766.6395263671875, Entropy -575.3043212890625, Learning Rate: 0.025\n",
      "Epoch [699/20000], Loss: 816.3098754882812, Entropy -589.468505859375, Learning Rate: 0.025\n",
      "Epoch [700/20000], Loss: 829.09521484375, Entropy -578.6806640625, Learning Rate: 0.025\n",
      "Epoch [701/20000], Loss: 768.231689453125, Entropy -583.7316284179688, Learning Rate: 0.025\n",
      "Epoch [702/20000], Loss: 827.22998046875, Entropy -586.7063598632812, Learning Rate: 0.025\n",
      "Epoch [703/20000], Loss: 827.996337890625, Entropy -566.225830078125, Learning Rate: 0.025\n",
      "Epoch [704/20000], Loss: 778.2468872070312, Entropy -573.913818359375, Learning Rate: 0.025\n",
      "Epoch [705/20000], Loss: 860.1345825195312, Entropy -580.5851440429688, Learning Rate: 0.025\n",
      "Epoch [706/20000], Loss: 858.4378051757812, Entropy -566.890625, Learning Rate: 0.025\n",
      "Epoch [707/20000], Loss: 795.8018188476562, Entropy -595.3902587890625, Learning Rate: 0.025\n",
      "Epoch [708/20000], Loss: 836.287841796875, Entropy -583.989501953125, Learning Rate: 0.025\n",
      "Epoch [709/20000], Loss: 810.3012084960938, Entropy -585.40283203125, Learning Rate: 0.025\n",
      "Epoch [710/20000], Loss: 773.4930419921875, Entropy -586.2135009765625, Learning Rate: 0.025\n",
      "Epoch [711/20000], Loss: 864.013916015625, Entropy -594.2393188476562, Learning Rate: 0.025\n",
      "Epoch [712/20000], Loss: 793.6238403320312, Entropy -590.6735229492188, Learning Rate: 0.025\n",
      "Epoch [713/20000], Loss: 812.7998657226562, Entropy -570.576416015625, Learning Rate: 0.025\n",
      "Epoch [714/20000], Loss: 960.8297729492188, Entropy -569.2330932617188, Learning Rate: 0.025\n",
      "Epoch [715/20000], Loss: 895.2523803710938, Entropy -588.776123046875, Learning Rate: 0.025\n",
      "Epoch [716/20000], Loss: 745.5399169921875, Entropy -567.6995849609375, Learning Rate: 0.025\n",
      "Epoch [717/20000], Loss: 933.4827880859375, Entropy -570.3035888671875, Learning Rate: 0.025\n",
      "Epoch [718/20000], Loss: 1003.8916015625, Entropy -600.524169921875, Learning Rate: 0.025\n",
      "Epoch [719/20000], Loss: 775.9581298828125, Entropy -578.0092163085938, Learning Rate: 0.025\n",
      "Epoch [720/20000], Loss: 856.3963012695312, Entropy -604.8726806640625, Learning Rate: 0.025\n",
      "Epoch [721/20000], Loss: 791.7235717773438, Entropy -596.9743041992188, Learning Rate: 0.025\n",
      "Epoch [722/20000], Loss: 787.4036254882812, Entropy -576.6467895507812, Learning Rate: 0.025\n",
      "Epoch [723/20000], Loss: 901.1610717773438, Entropy -583.4727172851562, Learning Rate: 0.025\n",
      "Epoch [724/20000], Loss: 856.1116333007812, Entropy -586.993408203125, Learning Rate: 0.025\n",
      "Epoch [725/20000], Loss: 781.46533203125, Entropy -576.9498291015625, Learning Rate: 0.025\n",
      "Epoch [726/20000], Loss: 823.4218139648438, Entropy -619.0431518554688, Learning Rate: 0.025\n",
      "Epoch [727/20000], Loss: 804.1387329101562, Entropy -586.9661865234375, Learning Rate: 0.025\n",
      "Epoch [728/20000], Loss: 785.9186401367188, Entropy -594.4462890625, Learning Rate: 0.025\n",
      "Epoch [729/20000], Loss: 782.9021606445312, Entropy -576.1023559570312, Learning Rate: 0.025\n",
      "Epoch [730/20000], Loss: 812.3424072265625, Entropy -589.949951171875, Learning Rate: 0.025\n",
      "Epoch [731/20000], Loss: 815.6747436523438, Entropy -581.349609375, Learning Rate: 0.025\n",
      "Epoch [732/20000], Loss: 773.8751220703125, Entropy -566.4337158203125, Learning Rate: 0.025\n",
      "Epoch [733/20000], Loss: 781.8423461914062, Entropy -590.352294921875, Learning Rate: 0.025\n",
      "Epoch [734/20000], Loss: 757.0496215820312, Entropy -568.0858154296875, Learning Rate: 0.025\n",
      "Epoch [735/20000], Loss: 777.9498901367188, Entropy -586.6392822265625, Learning Rate: 0.025\n",
      "Epoch [736/20000], Loss: 775.4031372070312, Entropy -583.81884765625, Learning Rate: 0.025\n",
      "Epoch [737/20000], Loss: 757.2429809570312, Entropy -586.5814819335938, Learning Rate: 0.025\n",
      "Epoch [738/20000], Loss: 774.6585693359375, Entropy -580.9513549804688, Learning Rate: 0.025\n",
      "Epoch [739/20000], Loss: 793.7166748046875, Entropy -593.3717041015625, Learning Rate: 0.025\n",
      "Epoch [740/20000], Loss: 805.145263671875, Entropy -579.1573486328125, Learning Rate: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [741/20000], Loss: 769.9932861328125, Entropy -590.304931640625, Learning Rate: 0.025\n",
      "Epoch [742/20000], Loss: 795.2640380859375, Entropy -573.1338500976562, Learning Rate: 0.025\n",
      "Epoch [743/20000], Loss: 785.1207885742188, Entropy -599.2135009765625, Learning Rate: 0.025\n",
      "Epoch [744/20000], Loss: 758.7972412109375, Entropy -558.9764404296875, Learning Rate: 0.025\n",
      "Epoch [745/20000], Loss: 787.7720947265625, Entropy -573.4781494140625, Learning Rate: 0.025\n",
      "Epoch [746/20000], Loss: 759.2921142578125, Entropy -586.7393188476562, Learning Rate: 0.025\n",
      "Epoch [747/20000], Loss: 798.5419311523438, Entropy -572.78173828125, Learning Rate: 0.025\n",
      "Epoch [748/20000], Loss: 773.578125, Entropy -557.7694091796875, Learning Rate: 0.025\n",
      "Epoch [749/20000], Loss: 748.264404296875, Entropy -590.0115966796875, Learning Rate: 0.025\n",
      "Epoch [750/20000], Loss: 759.3707885742188, Entropy -568.2135009765625, Learning Rate: 0.025\n",
      "Epoch [751/20000], Loss: 778.8255615234375, Entropy -570.9907836914062, Learning Rate: 0.025\n",
      "Epoch [752/20000], Loss: 774.2689819335938, Entropy -582.2105712890625, Learning Rate: 0.025\n",
      "Epoch [753/20000], Loss: 781.291015625, Entropy -590.559814453125, Learning Rate: 0.025\n",
      "Epoch [754/20000], Loss: 848.4877319335938, Entropy -574.5762939453125, Learning Rate: 0.025\n",
      "Epoch [755/20000], Loss: 844.3405151367188, Entropy -580.6527099609375, Learning Rate: 0.025\n",
      "Epoch [756/20000], Loss: 787.572998046875, Entropy -581.1767578125, Learning Rate: 0.025\n",
      "Epoch [757/20000], Loss: 787.781494140625, Entropy -566.7503662109375, Learning Rate: 0.025\n",
      "Epoch [758/20000], Loss: 879.7731323242188, Entropy -567.757568359375, Learning Rate: 0.025\n",
      "Epoch [759/20000], Loss: 882.2891845703125, Entropy -582.4210815429688, Learning Rate: 0.025\n",
      "Epoch [760/20000], Loss: 780.9840698242188, Entropy -566.8759155273438, Learning Rate: 0.025\n",
      "Epoch [761/20000], Loss: 758.468017578125, Entropy -584.6156005859375, Learning Rate: 0.025\n",
      "Epoch [762/20000], Loss: 879.31396484375, Entropy -578.059326171875, Learning Rate: 0.025\n",
      "Epoch [763/20000], Loss: 1021.9495849609375, Entropy -599.846923828125, Learning Rate: 0.025\n",
      "Epoch [764/20000], Loss: 824.759033203125, Entropy -586.876220703125, Learning Rate: 0.025\n",
      "Epoch [765/20000], Loss: 751.603515625, Entropy -571.7236328125, Learning Rate: 0.025\n",
      "Epoch [766/20000], Loss: 872.80810546875, Entropy -572.482177734375, Learning Rate: 0.025\n",
      "Epoch [767/20000], Loss: 778.9396362304688, Entropy -578.01123046875, Learning Rate: 0.025\n",
      "Epoch [768/20000], Loss: 795.6694946289062, Entropy -567.3104248046875, Learning Rate: 0.025\n",
      "Epoch [769/20000], Loss: 883.6251220703125, Entropy -571.5011596679688, Learning Rate: 0.025\n",
      "Epoch [770/20000], Loss: 908.7019653320312, Entropy -581.5330810546875, Learning Rate: 0.025\n",
      "Epoch [771/20000], Loss: 786.0120239257812, Entropy -579.032470703125, Learning Rate: 0.025\n",
      "Epoch [772/20000], Loss: 805.6407470703125, Entropy -585.4764404296875, Learning Rate: 0.025\n",
      "Epoch [773/20000], Loss: 800.7340698242188, Entropy -610.64404296875, Learning Rate: 0.025\n",
      "Epoch [774/20000], Loss: 782.139404296875, Entropy -590.691162109375, Learning Rate: 0.025\n",
      "Epoch [775/20000], Loss: 798.209716796875, Entropy -587.0536499023438, Learning Rate: 0.025\n",
      "Epoch [776/20000], Loss: 749.65478515625, Entropy -568.34765625, Learning Rate: 0.025\n",
      "Epoch [777/20000], Loss: 772.2028198242188, Entropy -588.727294921875, Learning Rate: 0.025\n",
      "Epoch [778/20000], Loss: 799.2399291992188, Entropy -570.49853515625, Learning Rate: 0.025\n",
      "Epoch [779/20000], Loss: 752.6597900390625, Entropy -572.6598510742188, Learning Rate: 0.025\n",
      "Epoch [780/20000], Loss: 814.6898193359375, Entropy -577.414306640625, Learning Rate: 0.025\n",
      "Epoch [781/20000], Loss: 887.3726196289062, Entropy -581.7322387695312, Learning Rate: 0.025\n",
      "Epoch [782/20000], Loss: 789.3706665039062, Entropy -587.9465942382812, Learning Rate: 0.025\n",
      "Epoch [783/20000], Loss: 778.9481201171875, Entropy -584.7147827148438, Learning Rate: 0.025\n",
      "Epoch [784/20000], Loss: 812.5299072265625, Entropy -569.4502563476562, Learning Rate: 0.025\n",
      "Epoch [785/20000], Loss: 775.8643188476562, Entropy -568.7131958007812, Learning Rate: 0.025\n",
      "Epoch [786/20000], Loss: 783.2269287109375, Entropy -567.0510864257812, Learning Rate: 0.025\n",
      "Epoch [787/20000], Loss: 839.7520141601562, Entropy -550.7906494140625, Learning Rate: 0.025\n",
      "Epoch [788/20000], Loss: 884.7907104492188, Entropy -555.73095703125, Learning Rate: 0.025\n",
      "Epoch [789/20000], Loss: 763.5687866210938, Entropy -585.11279296875, Learning Rate: 0.025\n",
      "Epoch [790/20000], Loss: 843.307373046875, Entropy -571.477294921875, Learning Rate: 0.025\n",
      "Epoch [791/20000], Loss: 913.3470458984375, Entropy -568.222900390625, Learning Rate: 0.025\n",
      "Epoch [792/20000], Loss: 779.7612915039062, Entropy -569.70654296875, Learning Rate: 0.025\n",
      "Epoch [793/20000], Loss: 861.801513671875, Entropy -574.4884643554688, Learning Rate: 0.025\n",
      "Epoch [794/20000], Loss: 1287.7340087890625, Entropy -564.7019653320312, Learning Rate: 0.025\n",
      "Epoch [795/20000], Loss: 1324.060302734375, Entropy -592.07373046875, Learning Rate: 0.025\n",
      "Epoch [796/20000], Loss: 1071.58544921875, Entropy -575.3621215820312, Learning Rate: 0.025\n",
      "Epoch [797/20000], Loss: 765.36376953125, Entropy -563.6761474609375, Learning Rate: 0.025\n",
      "Epoch [798/20000], Loss: 934.8558959960938, Entropy -564.908447265625, Learning Rate: 0.025\n",
      "Epoch [799/20000], Loss: 1042.88037109375, Entropy -562.3587646484375, Learning Rate: 0.025\n",
      "Epoch [800/20000], Loss: 816.2868041992188, Entropy -564.8562622070312, Learning Rate: 0.025\n",
      "Epoch [801/20000], Loss: 792.9081420898438, Entropy -568.93603515625, Learning Rate: 0.025\n",
      "Epoch [802/20000], Loss: 1000.8280639648438, Entropy -559.3001708984375, Learning Rate: 0.025\n",
      "Epoch [803/20000], Loss: 852.7034301757812, Entropy -568.8096923828125, Learning Rate: 0.025\n",
      "Epoch [804/20000], Loss: 793.059326171875, Entropy -565.2699584960938, Learning Rate: 0.025\n",
      "Epoch [805/20000], Loss: 881.1506958007812, Entropy -576.2577514648438, Learning Rate: 0.025\n",
      "Epoch [806/20000], Loss: 813.0211181640625, Entropy -571.81982421875, Learning Rate: 0.025\n",
      "Epoch [807/20000], Loss: 786.9114990234375, Entropy -591.1446533203125, Learning Rate: 0.025\n",
      "Epoch [808/20000], Loss: 860.4398803710938, Entropy -576.5394287109375, Learning Rate: 0.025\n",
      "Epoch [809/20000], Loss: 801.9205322265625, Entropy -567.92236328125, Learning Rate: 0.025\n",
      "Epoch [810/20000], Loss: 789.6930541992188, Entropy -586.832275390625, Learning Rate: 0.025\n",
      "Epoch [811/20000], Loss: 743.5953979492188, Entropy -558.3181762695312, Learning Rate: 0.025\n",
      "Epoch [812/20000], Loss: 841.9547729492188, Entropy -576.6824951171875, Learning Rate: 0.025\n",
      "Epoch [813/20000], Loss: 858.0217895507812, Entropy -584.3731689453125, Learning Rate: 0.025\n",
      "Epoch [814/20000], Loss: 765.8595581054688, Entropy -573.638671875, Learning Rate: 0.025\n",
      "Epoch [815/20000], Loss: 778.2659301757812, Entropy -584.6627197265625, Learning Rate: 0.025\n",
      "Epoch [816/20000], Loss: 781.0445556640625, Entropy -572.4439697265625, Learning Rate: 0.025\n",
      "Epoch [817/20000], Loss: 761.6082153320312, Entropy -554.68896484375, Learning Rate: 0.025\n",
      "Epoch [818/20000], Loss: 741.7127685546875, Entropy -584.607421875, Learning Rate: 0.025\n",
      "Epoch [819/20000], Loss: 726.5164794921875, Entropy -578.514892578125, Learning Rate: 0.025\n",
      "Epoch [820/20000], Loss: 735.8419799804688, Entropy -556.57470703125, Learning Rate: 0.025\n",
      "Epoch [821/20000], Loss: 786.0579223632812, Entropy -565.9951171875, Learning Rate: 0.025\n",
      "Epoch [822/20000], Loss: 750.6173706054688, Entropy -581.5198974609375, Learning Rate: 0.025\n",
      "Epoch [823/20000], Loss: 711.9345092773438, Entropy -557.4603271484375, Learning Rate: 0.025\n",
      "Epoch [824/20000], Loss: 764.1701049804688, Entropy -567.97119140625, Learning Rate: 0.025\n",
      "Epoch [825/20000], Loss: 732.7216796875, Entropy -562.8033447265625, Learning Rate: 0.025\n",
      "Epoch [826/20000], Loss: 745.993408203125, Entropy -576.4765014648438, Learning Rate: 0.025\n",
      "Epoch [827/20000], Loss: 795.7239990234375, Entropy -581.941162109375, Learning Rate: 0.025\n",
      "Epoch [828/20000], Loss: 770.26171875, Entropy -577.2364501953125, Learning Rate: 0.025\n",
      "Epoch [829/20000], Loss: 729.4467163085938, Entropy -553.3696899414062, Learning Rate: 0.025\n",
      "Epoch [830/20000], Loss: 763.0086669921875, Entropy -572.67529296875, Learning Rate: 0.025\n",
      "Epoch [831/20000], Loss: 755.0955810546875, Entropy -566.273193359375, Learning Rate: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [832/20000], Loss: 739.8898315429688, Entropy -589.3541870117188, Learning Rate: 0.025\n",
      "Epoch [833/20000], Loss: 736.466796875, Entropy -568.61865234375, Learning Rate: 0.025\n",
      "Epoch [834/20000], Loss: 756.46435546875, Entropy -563.2174072265625, Learning Rate: 0.025\n",
      "Epoch [835/20000], Loss: 740.2277221679688, Entropy -567.3961181640625, Learning Rate: 0.025\n",
      "Epoch [836/20000], Loss: 764.7675170898438, Entropy -583.3494262695312, Learning Rate: 0.025\n",
      "Epoch [837/20000], Loss: 764.8092651367188, Entropy -546.8946533203125, Learning Rate: 0.025\n",
      "Epoch [838/20000], Loss: 773.1082763671875, Entropy -572.5897827148438, Learning Rate: 0.025\n",
      "Epoch [839/20000], Loss: 750.4594116210938, Entropy -576.1595458984375, Learning Rate: 0.025\n",
      "Epoch [840/20000], Loss: 755.8993530273438, Entropy -559.9730834960938, Learning Rate: 0.025\n",
      "Epoch [841/20000], Loss: 792.7554321289062, Entropy -563.1080932617188, Learning Rate: 0.025\n",
      "Epoch [842/20000], Loss: 779.2236938476562, Entropy -600.332763671875, Learning Rate: 0.025\n",
      "Epoch [843/20000], Loss: 737.5128173828125, Entropy -563.4423828125, Learning Rate: 0.025\n",
      "Epoch [844/20000], Loss: 760.2880859375, Entropy -565.350830078125, Learning Rate: 0.025\n",
      "Epoch [845/20000], Loss: 757.7308959960938, Entropy -573.7183837890625, Learning Rate: 0.025\n",
      "Epoch [846/20000], Loss: 742.62646484375, Entropy -565.43798828125, Learning Rate: 0.025\n",
      "Epoch [847/20000], Loss: 723.2128295898438, Entropy -574.1541748046875, Learning Rate: 0.025\n",
      "Epoch [848/20000], Loss: 719.78076171875, Entropy -548.2955322265625, Learning Rate: 0.025\n",
      "Epoch [849/20000], Loss: 717.50830078125, Entropy -563.9571533203125, Learning Rate: 0.025\n",
      "Epoch [850/20000], Loss: 739.4658203125, Entropy -570.69970703125, Learning Rate: 0.025\n",
      "Epoch [851/20000], Loss: 729.3894653320312, Entropy -568.1107788085938, Learning Rate: 0.025\n",
      "Epoch [852/20000], Loss: 750.145751953125, Entropy -578.091796875, Learning Rate: 0.025\n",
      "Epoch [853/20000], Loss: 724.49658203125, Entropy -567.6171875, Learning Rate: 0.025\n",
      "Epoch [854/20000], Loss: 769.596435546875, Entropy -565.4806518554688, Learning Rate: 0.025\n",
      "Epoch [855/20000], Loss: 802.6197509765625, Entropy -568.361083984375, Learning Rate: 0.025\n",
      "Epoch [856/20000], Loss: 803.1727294921875, Entropy -575.2852783203125, Learning Rate: 0.025\n",
      "Epoch [857/20000], Loss: 708.747802734375, Entropy -559.4323120117188, Learning Rate: 0.025\n",
      "Epoch [858/20000], Loss: 782.7825927734375, Entropy -564.9497680664062, Learning Rate: 0.025\n",
      "Epoch [859/20000], Loss: 813.6431884765625, Entropy -576.6593017578125, Learning Rate: 0.025\n",
      "Epoch [860/20000], Loss: 751.3240966796875, Entropy -570.601806640625, Learning Rate: 0.025\n",
      "Epoch [861/20000], Loss: 721.8485717773438, Entropy -558.343017578125, Learning Rate: 0.025\n",
      "Epoch [862/20000], Loss: 775.827392578125, Entropy -579.033203125, Learning Rate: 0.025\n",
      "Epoch [863/20000], Loss: 839.492431640625, Entropy -573.4488525390625, Learning Rate: 0.025\n",
      "Epoch [864/20000], Loss: 812.2136840820312, Entropy -554.139892578125, Learning Rate: 0.025\n",
      "Epoch [865/20000], Loss: 757.2879638671875, Entropy -565.343994140625, Learning Rate: 0.025\n",
      "Epoch [866/20000], Loss: 733.1904907226562, Entropy -584.2603149414062, Learning Rate: 0.025\n",
      "Epoch [867/20000], Loss: 773.3649291992188, Entropy -586.05224609375, Learning Rate: 0.025\n",
      "Epoch [868/20000], Loss: 857.4790649414062, Entropy -553.1497192382812, Learning Rate: 0.025\n",
      "Epoch [869/20000], Loss: 758.8363647460938, Entropy -557.529541015625, Learning Rate: 0.025\n",
      "Epoch [870/20000], Loss: 704.112060546875, Entropy -546.2174682617188, Learning Rate: 0.025\n",
      "Epoch [871/20000], Loss: 787.6547241210938, Entropy -568.7069091796875, Learning Rate: 0.025\n",
      "Epoch [872/20000], Loss: 781.9359741210938, Entropy -559.3541259765625, Learning Rate: 0.025\n",
      "Epoch [873/20000], Loss: 729.700927734375, Entropy -559.7259521484375, Learning Rate: 0.025\n",
      "Epoch [874/20000], Loss: 744.6015014648438, Entropy -575.4137573242188, Learning Rate: 0.025\n",
      "Epoch [875/20000], Loss: 771.5936889648438, Entropy -563.784423828125, Learning Rate: 0.025\n",
      "Epoch [876/20000], Loss: 739.5552368164062, Entropy -566.0494384765625, Learning Rate: 0.025\n",
      "Epoch [877/20000], Loss: 749.5272827148438, Entropy -569.153564453125, Learning Rate: 0.025\n",
      "Epoch [878/20000], Loss: 739.1091918945312, Entropy -576.8649291992188, Learning Rate: 0.025\n",
      "Epoch [879/20000], Loss: 783.2249145507812, Entropy -582.593505859375, Learning Rate: 0.025\n",
      "Epoch [880/20000], Loss: 792.26123046875, Entropy -570.4229125976562, Learning Rate: 0.025\n",
      "Epoch [881/20000], Loss: 729.3638916015625, Entropy -573.8507690429688, Learning Rate: 0.025\n",
      "Epoch [882/20000], Loss: 716.1890869140625, Entropy -573.2374877929688, Learning Rate: 0.025\n",
      "Epoch [883/20000], Loss: 739.3992919921875, Entropy -569.476806640625, Learning Rate: 0.025\n",
      "Epoch [884/20000], Loss: 695.443359375, Entropy -564.0589599609375, Learning Rate: 0.025\n",
      "Epoch [885/20000], Loss: 713.6873779296875, Entropy -552.0753173828125, Learning Rate: 0.025\n",
      "Epoch [886/20000], Loss: 755.16845703125, Entropy -557.810302734375, Learning Rate: 0.025\n",
      "Epoch [887/20000], Loss: 813.188232421875, Entropy -556.0457763671875, Learning Rate: 0.025\n",
      "Epoch [888/20000], Loss: 752.5203247070312, Entropy -549.5556030273438, Learning Rate: 0.025\n",
      "Epoch [889/20000], Loss: 756.0845336914062, Entropy -564.6715087890625, Learning Rate: 0.025\n",
      "Epoch [890/20000], Loss: 744.58349609375, Entropy -585.9615478515625, Learning Rate: 0.025\n",
      "Epoch [891/20000], Loss: 733.4053344726562, Entropy -574.6226806640625, Learning Rate: 0.025\n",
      "Epoch [892/20000], Loss: 728.8104248046875, Entropy -567.5479736328125, Learning Rate: 0.025\n",
      "Epoch [893/20000], Loss: 757.9846801757812, Entropy -555.9599609375, Learning Rate: 0.025\n",
      "Epoch [894/20000], Loss: 842.6760864257812, Entropy -558.8624877929688, Learning Rate: 0.025\n",
      "Epoch [895/20000], Loss: 827.8255004882812, Entropy -555.689208984375, Learning Rate: 0.025\n",
      "Epoch [896/20000], Loss: 745.451171875, Entropy -565.646484375, Learning Rate: 0.025\n",
      "Epoch [897/20000], Loss: 767.68017578125, Entropy -556.8607177734375, Learning Rate: 0.025\n",
      "Epoch [898/20000], Loss: 1008.2369384765625, Entropy -546.048095703125, Learning Rate: 0.025\n",
      "Epoch [899/20000], Loss: 984.8634643554688, Entropy -560.4356689453125, Learning Rate: 0.025\n",
      "Epoch [900/20000], Loss: 865.238037109375, Entropy -548.4053955078125, Learning Rate: 0.025\n",
      "Epoch [901/20000], Loss: 739.7652587890625, Entropy -549.578369140625, Learning Rate: 0.025\n",
      "Epoch [902/20000], Loss: 715.8016357421875, Entropy -563.6295776367188, Learning Rate: 0.025\n",
      "Epoch [903/20000], Loss: 765.4069213867188, Entropy -582.3260498046875, Learning Rate: 0.025\n",
      "Epoch [904/20000], Loss: 757.891357421875, Entropy -570.4202270507812, Learning Rate: 0.025\n",
      "Epoch [905/20000], Loss: 735.8939208984375, Entropy -551.6156616210938, Learning Rate: 0.025\n",
      "Epoch [906/20000], Loss: 729.6387939453125, Entropy -558.2060546875, Learning Rate: 0.025\n",
      "Epoch [907/20000], Loss: 738.36181640625, Entropy -560.84033203125, Learning Rate: 0.025\n",
      "Epoch [908/20000], Loss: 709.9420776367188, Entropy -557.3222045898438, Learning Rate: 0.025\n",
      "Epoch [909/20000], Loss: 746.736572265625, Entropy -571.2298583984375, Learning Rate: 0.025\n",
      "Epoch [910/20000], Loss: 747.43701171875, Entropy -577.10009765625, Learning Rate: 0.025\n",
      "Epoch [911/20000], Loss: 715.785888671875, Entropy -558.0224609375, Learning Rate: 0.025\n",
      "Epoch [912/20000], Loss: 743.6763305664062, Entropy -548.9071044921875, Learning Rate: 0.025\n",
      "Epoch [913/20000], Loss: 763.4409790039062, Entropy -564.1851806640625, Learning Rate: 0.025\n",
      "Epoch [914/20000], Loss: 707.3265991210938, Entropy -548.4285888671875, Learning Rate: 0.025\n",
      "Epoch [915/20000], Loss: 745.2452392578125, Entropy -563.3204956054688, Learning Rate: 0.025\n",
      "Epoch [916/20000], Loss: 710.0794677734375, Entropy -558.8751220703125, Learning Rate: 0.025\n",
      "Epoch [917/20000], Loss: 739.160888671875, Entropy -550.4812622070312, Learning Rate: 0.025\n",
      "Epoch [918/20000], Loss: 726.2765502929688, Entropy -568.49560546875, Learning Rate: 0.025\n",
      "Epoch [919/20000], Loss: 748.9201049804688, Entropy -570.207763671875, Learning Rate: 0.025\n",
      "Epoch [920/20000], Loss: 738.5952758789062, Entropy -553.859619140625, Learning Rate: 0.025\n",
      "Epoch [921/20000], Loss: 869.9301147460938, Entropy -577.6465454101562, Learning Rate: 0.025\n",
      "Epoch [922/20000], Loss: 760.6389770507812, Entropy -572.3580322265625, Learning Rate: 0.025\n",
      "Epoch [923/20000], Loss: 724.5449829101562, Entropy -554.2921142578125, Learning Rate: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [924/20000], Loss: 787.4205932617188, Entropy -550.4625854492188, Learning Rate: 0.025\n",
      "Epoch [925/20000], Loss: 862.935791015625, Entropy -568.5742797851562, Learning Rate: 0.025\n",
      "Epoch [926/20000], Loss: 753.317626953125, Entropy -557.1133422851562, Learning Rate: 0.025\n",
      "Epoch [927/20000], Loss: 786.352783203125, Entropy -559.5181884765625, Learning Rate: 0.025\n",
      "Epoch [928/20000], Loss: 995.81689453125, Entropy -573.1336669921875, Learning Rate: 0.025\n",
      "Epoch [929/20000], Loss: 1097.2322998046875, Entropy -578.946533203125, Learning Rate: 0.025\n",
      "Epoch [930/20000], Loss: 829.9841918945312, Entropy -556.3412475585938, Learning Rate: 0.025\n",
      "Epoch [931/20000], Loss: 736.3866577148438, Entropy -567.417236328125, Learning Rate: 0.025\n",
      "Epoch [932/20000], Loss: 953.9842529296875, Entropy -572.4922485351562, Learning Rate: 0.025\n",
      "Epoch [933/20000], Loss: 1021.1099853515625, Entropy -541.6870727539062, Learning Rate: 0.025\n",
      "Epoch [934/20000], Loss: 838.835693359375, Entropy -548.52392578125, Learning Rate: 0.025\n",
      "Epoch [935/20000], Loss: 736.461181640625, Entropy -543.1383056640625, Learning Rate: 0.025\n",
      "Epoch [936/20000], Loss: 851.5249633789062, Entropy -557.3724975585938, Learning Rate: 0.025\n",
      "Epoch [937/20000], Loss: 754.3931274414062, Entropy -560.3524169921875, Learning Rate: 0.025\n",
      "Epoch [938/20000], Loss: 760.450439453125, Entropy -562.1326904296875, Learning Rate: 0.025\n",
      "Epoch [939/20000], Loss: 817.9674072265625, Entropy -554.9674072265625, Learning Rate: 0.025\n",
      "Epoch [940/20000], Loss: 892.7510375976562, Entropy -553.7771606445312, Learning Rate: 0.025\n",
      "Epoch [941/20000], Loss: 849.3844604492188, Entropy -552.004638671875, Learning Rate: 0.025\n",
      "Epoch [942/20000], Loss: 719.60009765625, Entropy -541.8984375, Learning Rate: 0.025\n",
      "Epoch [943/20000], Loss: 783.622314453125, Entropy -557.059326171875, Learning Rate: 0.025\n",
      "Epoch [944/20000], Loss: 873.9082641601562, Entropy -536.04833984375, Learning Rate: 0.025\n",
      "Epoch [945/20000], Loss: 919.5421142578125, Entropy -557.4955444335938, Learning Rate: 0.025\n",
      "Epoch [946/20000], Loss: 779.1041259765625, Entropy -538.8929443359375, Learning Rate: 0.025\n",
      "Epoch [947/20000], Loss: 742.3505859375, Entropy -555.8277587890625, Learning Rate: 0.025\n",
      "Epoch [948/20000], Loss: 850.28662109375, Entropy -563.9453125, Learning Rate: 0.025\n",
      "Epoch [949/20000], Loss: 1073.77001953125, Entropy -547.8597412109375, Learning Rate: 0.025\n",
      "Epoch [950/20000], Loss: 1198.2236328125, Entropy -581.4677734375, Learning Rate: 0.025\n",
      "Epoch [951/20000], Loss: 880.8970336914062, Entropy -570.9754638671875, Learning Rate: 0.025\n",
      "Epoch [952/20000], Loss: 870.184814453125, Entropy -582.7208251953125, Learning Rate: 0.025\n",
      "Epoch [953/20000], Loss: 1178.8834228515625, Entropy -562.7695922851562, Learning Rate: 0.025\n",
      "Epoch [954/20000], Loss: 1593.164794921875, Entropy -561.0843505859375, Learning Rate: 0.025\n",
      "Epoch [955/20000], Loss: 1369.178955078125, Entropy -564.82177734375, Learning Rate: 0.025\n",
      "Epoch [956/20000], Loss: 749.2189331054688, Entropy -552.7945556640625, Learning Rate: 0.025\n",
      "Epoch [957/20000], Loss: 1348.981689453125, Entropy -554.947265625, Learning Rate: 0.025\n",
      "Epoch [958/20000], Loss: 1456.399169921875, Entropy -581.220703125, Learning Rate: 0.025\n",
      "Epoch [959/20000], Loss: 985.4141235351562, Entropy -555.6956787109375, Learning Rate: 0.025\n",
      "Epoch [960/20000], Loss: 874.6045532226562, Entropy -552.7757568359375, Learning Rate: 0.025\n",
      "Epoch [961/20000], Loss: 877.0518188476562, Entropy -591.8941650390625, Learning Rate: 0.025\n",
      "Epoch [962/20000], Loss: 868.5912475585938, Entropy -560.6363525390625, Learning Rate: 0.025\n",
      "Epoch [963/20000], Loss: 1314.8653564453125, Entropy -556.5119018554688, Learning Rate: 0.025\n",
      "Epoch [964/20000], Loss: 1516.372314453125, Entropy -558.853271484375, Learning Rate: 0.025\n",
      "Epoch [965/20000], Loss: 951.7572631835938, Entropy -555.5812377929688, Learning Rate: 0.025\n",
      "Epoch [966/20000], Loss: 949.3087768554688, Entropy -570.6116943359375, Learning Rate: 0.025\n",
      "Epoch [967/20000], Loss: 1405.5087890625, Entropy -565.1077880859375, Learning Rate: 0.025\n",
      "Epoch [968/20000], Loss: 1068.6265869140625, Entropy -582.16796875, Learning Rate: 0.025\n",
      "Epoch [969/20000], Loss: 1091.6822509765625, Entropy -566.1868896484375, Learning Rate: 0.025\n",
      "Epoch [970/20000], Loss: 1918.313232421875, Entropy -577.8334350585938, Learning Rate: 0.025\n",
      "Epoch [971/20000], Loss: 1192.6986083984375, Entropy -557.2427368164062, Learning Rate: 0.025\n",
      "Epoch [972/20000], Loss: 996.510986328125, Entropy -569.8436279296875, Learning Rate: 0.025\n",
      "Epoch [973/20000], Loss: 1806.7373046875, Entropy -564.0960693359375, Learning Rate: 0.025\n",
      "Epoch [974/20000], Loss: 1163.408203125, Entropy -556.5810546875, Learning Rate: 0.025\n",
      "Epoch [975/20000], Loss: 1240.28173828125, Entropy -554.5263061523438, Learning Rate: 0.025\n",
      "Epoch [976/20000], Loss: 1335.05419921875, Entropy -559.7872314453125, Learning Rate: 0.025\n",
      "Epoch [977/20000], Loss: 1068.683837890625, Entropy -565.5940551757812, Learning Rate: 0.025\n",
      "Epoch [978/20000], Loss: 2098.91064453125, Entropy -577.4825439453125, Learning Rate: 0.025\n",
      "Epoch [979/20000], Loss: 809.0857543945312, Entropy -577.3417358398438, Learning Rate: 0.025\n",
      "Epoch [980/20000], Loss: 2142.908203125, Entropy -582.2077026367188, Learning Rate: 0.025\n",
      "Epoch [981/20000], Loss: 1397.8350830078125, Entropy -570.6751708984375, Learning Rate: 0.025\n",
      "Epoch [982/20000], Loss: 1321.1009521484375, Entropy -584.22998046875, Learning Rate: 0.025\n",
      "Epoch [983/20000], Loss: 1956.2891845703125, Entropy -563.8413696289062, Learning Rate: 0.025\n",
      "Epoch [984/20000], Loss: 942.0128173828125, Entropy -583.8519897460938, Learning Rate: 0.025\n",
      "Epoch [985/20000], Loss: 1293.9791259765625, Entropy -557.3458251953125, Learning Rate: 0.025\n",
      "Epoch [986/20000], Loss: 1135.8040771484375, Entropy -561.1438598632812, Learning Rate: 0.0125\n",
      "Epoch [987/20000], Loss: 855.16845703125, Entropy -582.1201171875, Learning Rate: 0.0125\n",
      "Epoch [988/20000], Loss: 1039.3697509765625, Entropy -578.7689208984375, Learning Rate: 0.0125\n",
      "Epoch [989/20000], Loss: 1105.890380859375, Entropy -583.4293823242188, Learning Rate: 0.0125\n",
      "Epoch [990/20000], Loss: 907.6853637695312, Entropy -574.4820556640625, Learning Rate: 0.0125\n",
      "Epoch [991/20000], Loss: 1088.7314453125, Entropy -579.03271484375, Learning Rate: 0.0125\n",
      "Epoch [992/20000], Loss: 933.8081665039062, Entropy -593.6392211914062, Learning Rate: 0.0125\n",
      "Epoch [993/20000], Loss: 827.0879516601562, Entropy -601.361328125, Learning Rate: 0.0125\n",
      "Epoch [994/20000], Loss: 967.1333618164062, Entropy -569.9738159179688, Learning Rate: 0.0125\n",
      "Epoch [995/20000], Loss: 970.1259155273438, Entropy -582.2217407226562, Learning Rate: 0.0125\n",
      "Epoch [996/20000], Loss: 824.7857055664062, Entropy -582.8533325195312, Learning Rate: 0.0125\n",
      "Epoch [997/20000], Loss: 813.7176513671875, Entropy -583.9472045898438, Learning Rate: 0.0125\n",
      "Epoch [998/20000], Loss: 935.802978515625, Entropy -611.25048828125, Learning Rate: 0.0125\n",
      "Epoch [999/20000], Loss: 747.237548828125, Entropy -589.0579223632812, Learning Rate: 0.0125\n",
      "Epoch [1000/20000], Loss: 812.635986328125, Entropy -604.4091796875, Learning Rate: 0.0125\n",
      "Epoch [1001/20000], Loss: 848.2731323242188, Entropy -613.7362670898438, Learning Rate: 0.0125\n",
      "Epoch [1002/20000], Loss: 765.45751953125, Entropy -604.7333374023438, Learning Rate: 0.0125\n",
      "Epoch [1003/20000], Loss: 772.886474609375, Entropy -597.6942138671875, Learning Rate: 0.0125\n",
      "Epoch [1004/20000], Loss: 825.6987915039062, Entropy -584.5957641601562, Learning Rate: 0.0125\n",
      "Epoch [1005/20000], Loss: 778.6409912109375, Entropy -599.2401123046875, Learning Rate: 0.0125\n",
      "Epoch [1006/20000], Loss: 811.4265747070312, Entropy -594.2467041015625, Learning Rate: 0.0125\n",
      "Epoch [1007/20000], Loss: 807.3684692382812, Entropy -613.0679321289062, Learning Rate: 0.0125\n",
      "Epoch [1008/20000], Loss: 798.1292114257812, Entropy -613.5877685546875, Learning Rate: 0.0125\n",
      "Epoch [1009/20000], Loss: 723.804443359375, Entropy -583.0967407226562, Learning Rate: 0.0125\n",
      "Epoch [1010/20000], Loss: 766.6024780273438, Entropy -584.6790771484375, Learning Rate: 0.0125\n",
      "Epoch [1011/20000], Loss: 757.9974365234375, Entropy -595.2861938476562, Learning Rate: 0.0125\n",
      "Epoch [1012/20000], Loss: 719.1443481445312, Entropy -586.3779296875, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1013/20000], Loss: 761.0093994140625, Entropy -603.5323486328125, Learning Rate: 0.0125\n",
      "Epoch [1014/20000], Loss: 759.3649291992188, Entropy -583.63916015625, Learning Rate: 0.0125\n",
      "Epoch [1015/20000], Loss: 740.791259765625, Entropy -589.774658203125, Learning Rate: 0.0125\n",
      "Epoch [1016/20000], Loss: 762.8919067382812, Entropy -588.4427490234375, Learning Rate: 0.0125\n",
      "Epoch [1017/20000], Loss: 767.6133422851562, Entropy -581.4027099609375, Learning Rate: 0.0125\n",
      "Epoch [1018/20000], Loss: 774.5690307617188, Entropy -602.200927734375, Learning Rate: 0.0125\n",
      "Epoch [1019/20000], Loss: 762.6397705078125, Entropy -601.036865234375, Learning Rate: 0.0125\n",
      "Epoch [1020/20000], Loss: 742.6161499023438, Entropy -591.941162109375, Learning Rate: 0.0125\n",
      "Epoch [1021/20000], Loss: 747.0885620117188, Entropy -596.6710815429688, Learning Rate: 0.0125\n",
      "Epoch [1022/20000], Loss: 719.9151611328125, Entropy -582.49462890625, Learning Rate: 0.0125\n",
      "Epoch [1023/20000], Loss: 763.1021118164062, Entropy -607.564208984375, Learning Rate: 0.0125\n",
      "Epoch [1024/20000], Loss: 728.9066162109375, Entropy -571.40380859375, Learning Rate: 0.0125\n",
      "Epoch [1025/20000], Loss: 718.788818359375, Entropy -591.86083984375, Learning Rate: 0.0125\n",
      "Epoch [1026/20000], Loss: 744.829833984375, Entropy -593.6160888671875, Learning Rate: 0.0125\n",
      "Epoch [1027/20000], Loss: 740.7335205078125, Entropy -587.7459106445312, Learning Rate: 0.0125\n",
      "Epoch [1028/20000], Loss: 720.1730346679688, Entropy -576.9639892578125, Learning Rate: 0.0125\n",
      "Epoch [1029/20000], Loss: 717.4406127929688, Entropy -572.6702270507812, Learning Rate: 0.0125\n",
      "Epoch [1030/20000], Loss: 754.1751098632812, Entropy -607.0873413085938, Learning Rate: 0.0125\n",
      "Epoch [1031/20000], Loss: 733.9771118164062, Entropy -594.21923828125, Learning Rate: 0.0125\n",
      "Epoch [1032/20000], Loss: 721.3656616210938, Entropy -575.1465454101562, Learning Rate: 0.0125\n",
      "Epoch [1033/20000], Loss: 714.3316650390625, Entropy -578.010498046875, Learning Rate: 0.0125\n",
      "Epoch [1034/20000], Loss: 702.9044189453125, Entropy -560.524169921875, Learning Rate: 0.0125\n",
      "Epoch [1035/20000], Loss: 756.802978515625, Entropy -594.7284545898438, Learning Rate: 0.0125\n",
      "Epoch [1036/20000], Loss: 720.0715942382812, Entropy -569.9859619140625, Learning Rate: 0.0125\n",
      "Epoch [1037/20000], Loss: 723.8638916015625, Entropy -582.7694702148438, Learning Rate: 0.0125\n",
      "Epoch [1038/20000], Loss: 729.5572509765625, Entropy -597.3316650390625, Learning Rate: 0.0125\n",
      "Epoch [1039/20000], Loss: 747.9902954101562, Entropy -590.036376953125, Learning Rate: 0.0125\n",
      "Epoch [1040/20000], Loss: 708.6675415039062, Entropy -573.7003173828125, Learning Rate: 0.0125\n",
      "Epoch [1041/20000], Loss: 711.8816528320312, Entropy -565.801025390625, Learning Rate: 0.0125\n",
      "Epoch [1042/20000], Loss: 715.6241455078125, Entropy -572.9962158203125, Learning Rate: 0.0125\n",
      "Epoch [1043/20000], Loss: 721.976318359375, Entropy -589.282470703125, Learning Rate: 0.0125\n",
      "Epoch [1044/20000], Loss: 746.9655151367188, Entropy -607.347900390625, Learning Rate: 0.0125\n",
      "Epoch [1045/20000], Loss: 729.5062255859375, Entropy -598.1563110351562, Learning Rate: 0.0125\n",
      "Epoch [1046/20000], Loss: 726.824951171875, Entropy -591.467041015625, Learning Rate: 0.0125\n",
      "Epoch [1047/20000], Loss: 714.5697021484375, Entropy -576.6968383789062, Learning Rate: 0.0125\n",
      "Epoch [1048/20000], Loss: 699.983154296875, Entropy -569.6259155273438, Learning Rate: 0.0125\n",
      "Epoch [1049/20000], Loss: 704.0247802734375, Entropy -582.4669799804688, Learning Rate: 0.0125\n",
      "Epoch [1050/20000], Loss: 699.483154296875, Entropy -563.8714599609375, Learning Rate: 0.0125\n",
      "Epoch [1051/20000], Loss: 727.4842529296875, Entropy -601.4232177734375, Learning Rate: 0.0125\n",
      "Epoch [1052/20000], Loss: 706.1683959960938, Entropy -560.299560546875, Learning Rate: 0.0125\n",
      "Epoch [1053/20000], Loss: 705.0272216796875, Entropy -582.6029052734375, Learning Rate: 0.0125\n",
      "Epoch [1054/20000], Loss: 690.8963623046875, Entropy -559.1400756835938, Learning Rate: 0.0125\n",
      "Epoch [1055/20000], Loss: 691.7418823242188, Entropy -564.403564453125, Learning Rate: 0.0125\n",
      "Epoch [1056/20000], Loss: 692.966064453125, Entropy -570.56494140625, Learning Rate: 0.0125\n",
      "Epoch [1057/20000], Loss: 710.1048583984375, Entropy -575.4708862304688, Learning Rate: 0.0125\n",
      "Epoch [1058/20000], Loss: 708.0824584960938, Entropy -564.531982421875, Learning Rate: 0.0125\n",
      "Epoch [1059/20000], Loss: 705.8112182617188, Entropy -567.6512451171875, Learning Rate: 0.0125\n",
      "Epoch [1060/20000], Loss: 723.48046875, Entropy -594.6815795898438, Learning Rate: 0.0125\n",
      "Epoch [1061/20000], Loss: 702.5848999023438, Entropy -575.5474243164062, Learning Rate: 0.0125\n",
      "Epoch [1062/20000], Loss: 691.10400390625, Entropy -549.656982421875, Learning Rate: 0.0125\n",
      "Epoch [1063/20000], Loss: 706.90966796875, Entropy -578.1546630859375, Learning Rate: 0.0125\n",
      "Epoch [1064/20000], Loss: 702.297119140625, Entropy -572.326171875, Learning Rate: 0.0125\n",
      "Epoch [1065/20000], Loss: 696.61181640625, Entropy -566.885498046875, Learning Rate: 0.0125\n",
      "Epoch [1066/20000], Loss: 707.8887329101562, Entropy -574.154296875, Learning Rate: 0.0125\n",
      "Epoch [1067/20000], Loss: 727.6878051757812, Entropy -583.86328125, Learning Rate: 0.0125\n",
      "Epoch [1068/20000], Loss: 719.624755859375, Entropy -590.3358764648438, Learning Rate: 0.0125\n",
      "Epoch [1069/20000], Loss: 707.4208374023438, Entropy -574.8712768554688, Learning Rate: 0.0125\n",
      "Epoch [1070/20000], Loss: 705.8084716796875, Entropy -584.8287353515625, Learning Rate: 0.0125\n",
      "Epoch [1071/20000], Loss: 702.9187622070312, Entropy -565.5794677734375, Learning Rate: 0.0125\n",
      "Epoch [1072/20000], Loss: 685.3743286132812, Entropy -564.64306640625, Learning Rate: 0.0125\n",
      "Epoch [1073/20000], Loss: 717.0026245117188, Entropy -579.4412841796875, Learning Rate: 0.0125\n",
      "Epoch [1074/20000], Loss: 718.0099487304688, Entropy -589.4168701171875, Learning Rate: 0.0125\n",
      "Epoch [1075/20000], Loss: 695.7276000976562, Entropy -572.3316650390625, Learning Rate: 0.0125\n",
      "Epoch [1076/20000], Loss: 704.7747802734375, Entropy -575.3229370117188, Learning Rate: 0.0125\n",
      "Epoch [1077/20000], Loss: 688.481689453125, Entropy -572.1796875, Learning Rate: 0.0125\n",
      "Epoch [1078/20000], Loss: 697.914306640625, Entropy -564.3515625, Learning Rate: 0.0125\n",
      "Epoch [1079/20000], Loss: 686.1827392578125, Entropy -563.2088623046875, Learning Rate: 0.0125\n",
      "Epoch [1080/20000], Loss: 687.8724365234375, Entropy -566.8341674804688, Learning Rate: 0.0125\n",
      "Epoch [1081/20000], Loss: 690.4974365234375, Entropy -567.5845336914062, Learning Rate: 0.0125\n",
      "Epoch [1082/20000], Loss: 687.0861206054688, Entropy -560.197509765625, Learning Rate: 0.0125\n",
      "Epoch [1083/20000], Loss: 709.8102416992188, Entropy -565.2228393554688, Learning Rate: 0.0125\n",
      "Epoch [1084/20000], Loss: 691.7388305664062, Entropy -558.5804443359375, Learning Rate: 0.0125\n",
      "Epoch [1085/20000], Loss: 704.4263305664062, Entropy -593.0015869140625, Learning Rate: 0.0125\n",
      "Epoch [1086/20000], Loss: 708.8633422851562, Entropy -586.1878051757812, Learning Rate: 0.0125\n",
      "Epoch [1087/20000], Loss: 681.9536743164062, Entropy -554.6743774414062, Learning Rate: 0.0125\n",
      "Epoch [1088/20000], Loss: 696.24560546875, Entropy -578.6356201171875, Learning Rate: 0.0125\n",
      "Epoch [1089/20000], Loss: 691.798583984375, Entropy -571.142578125, Learning Rate: 0.0125\n",
      "Epoch [1090/20000], Loss: 689.8828735351562, Entropy -551.9424438476562, Learning Rate: 0.0125\n",
      "Epoch [1091/20000], Loss: 702.0548706054688, Entropy -579.775390625, Learning Rate: 0.0125\n",
      "Epoch [1092/20000], Loss: 691.727294921875, Entropy -564.5528564453125, Learning Rate: 0.0125\n",
      "Epoch [1093/20000], Loss: 681.8760375976562, Entropy -543.5067138671875, Learning Rate: 0.0125\n",
      "Epoch [1094/20000], Loss: 683.4959716796875, Entropy -562.3966674804688, Learning Rate: 0.0125\n",
      "Epoch [1095/20000], Loss: 689.4163208007812, Entropy -563.986328125, Learning Rate: 0.0125\n",
      "Epoch [1096/20000], Loss: 697.33447265625, Entropy -561.812255859375, Learning Rate: 0.0125\n",
      "Epoch [1097/20000], Loss: 701.6676635742188, Entropy -564.6414184570312, Learning Rate: 0.0125\n",
      "Epoch [1098/20000], Loss: 703.8568725585938, Entropy -580.7750244140625, Learning Rate: 0.0125\n",
      "Epoch [1099/20000], Loss: 688.0484619140625, Entropy -567.574462890625, Learning Rate: 0.0125\n",
      "Epoch [1100/20000], Loss: 675.5545654296875, Entropy -552.0668334960938, Learning Rate: 0.0125\n",
      "Epoch [1101/20000], Loss: 680.3751220703125, Entropy -562.1358642578125, Learning Rate: 0.0125\n",
      "Epoch [1102/20000], Loss: 673.2335205078125, Entropy -552.93115234375, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1103/20000], Loss: 685.172607421875, Entropy -566.93310546875, Learning Rate: 0.0125\n",
      "Epoch [1104/20000], Loss: 706.150146484375, Entropy -568.0045776367188, Learning Rate: 0.0125\n",
      "Epoch [1105/20000], Loss: 713.8656616210938, Entropy -585.917724609375, Learning Rate: 0.0125\n",
      "Epoch [1106/20000], Loss: 707.3584594726562, Entropy -579.7257080078125, Learning Rate: 0.0125\n",
      "Epoch [1107/20000], Loss: 690.7490844726562, Entropy -572.469970703125, Learning Rate: 0.0125\n",
      "Epoch [1108/20000], Loss: 686.376220703125, Entropy -559.617431640625, Learning Rate: 0.0125\n",
      "Epoch [1109/20000], Loss: 687.649658203125, Entropy -552.0755615234375, Learning Rate: 0.0125\n",
      "Epoch [1110/20000], Loss: 765.8495483398438, Entropy -567.723388671875, Learning Rate: 0.0125\n",
      "Epoch [1111/20000], Loss: 687.8261108398438, Entropy -556.877685546875, Learning Rate: 0.0125\n",
      "Epoch [1112/20000], Loss: 716.131591796875, Entropy -591.228271484375, Learning Rate: 0.0125\n",
      "Epoch [1113/20000], Loss: 693.4888916015625, Entropy -560.9839477539062, Learning Rate: 0.0125\n",
      "Epoch [1114/20000], Loss: 710.9784545898438, Entropy -565.3023681640625, Learning Rate: 0.0125\n",
      "Epoch [1115/20000], Loss: 673.9105834960938, Entropy -557.66552734375, Learning Rate: 0.0125\n",
      "Epoch [1116/20000], Loss: 686.7554321289062, Entropy -549.4586181640625, Learning Rate: 0.0125\n",
      "Epoch [1117/20000], Loss: 699.3677978515625, Entropy -587.606689453125, Learning Rate: 0.0125\n",
      "Epoch [1118/20000], Loss: 701.5447387695312, Entropy -565.525634765625, Learning Rate: 0.0125\n",
      "Epoch [1119/20000], Loss: 695.5889282226562, Entropy -559.7716674804688, Learning Rate: 0.0125\n",
      "Epoch [1120/20000], Loss: 701.7044067382812, Entropy -554.5202026367188, Learning Rate: 0.0125\n",
      "Epoch [1121/20000], Loss: 689.5155029296875, Entropy -561.6865234375, Learning Rate: 0.0125\n",
      "Epoch [1122/20000], Loss: 697.0831909179688, Entropy -567.6861572265625, Learning Rate: 0.0125\n",
      "Epoch [1123/20000], Loss: 696.3489990234375, Entropy -568.874755859375, Learning Rate: 0.0125\n",
      "Epoch [1124/20000], Loss: 689.0623779296875, Entropy -564.1591186523438, Learning Rate: 0.0125\n",
      "Epoch [1125/20000], Loss: 691.1178588867188, Entropy -555.927490234375, Learning Rate: 0.0125\n",
      "Epoch [1126/20000], Loss: 690.4005126953125, Entropy -552.4962158203125, Learning Rate: 0.0125\n",
      "Epoch [1127/20000], Loss: 695.4041748046875, Entropy -560.2822265625, Learning Rate: 0.0125\n",
      "Epoch [1128/20000], Loss: 687.52587890625, Entropy -569.2235107421875, Learning Rate: 0.0125\n",
      "Epoch [1129/20000], Loss: 702.773681640625, Entropy -570.7958984375, Learning Rate: 0.0125\n",
      "Epoch [1130/20000], Loss: 706.199951171875, Entropy -570.14306640625, Learning Rate: 0.0125\n",
      "Epoch [1131/20000], Loss: 680.7818603515625, Entropy -571.556640625, Learning Rate: 0.0125\n",
      "Epoch [1132/20000], Loss: 710.5286865234375, Entropy -584.8512573242188, Learning Rate: 0.0125\n",
      "Epoch [1133/20000], Loss: 694.8875732421875, Entropy -571.8764038085938, Learning Rate: 0.0125\n",
      "Epoch [1134/20000], Loss: 677.5487060546875, Entropy -564.2807006835938, Learning Rate: 0.0125\n",
      "Epoch [1135/20000], Loss: 693.1492919921875, Entropy -559.090087890625, Learning Rate: 0.0125\n",
      "Epoch [1136/20000], Loss: 656.3663330078125, Entropy -543.3706665039062, Learning Rate: 0.0125\n",
      "Epoch [1137/20000], Loss: 673.7061767578125, Entropy -552.0, Learning Rate: 0.0125\n",
      "Epoch [1138/20000], Loss: 697.107666015625, Entropy -577.1026611328125, Learning Rate: 0.0125\n",
      "Epoch [1139/20000], Loss: 687.8834228515625, Entropy -562.4163818359375, Learning Rate: 0.0125\n",
      "Epoch [1140/20000], Loss: 683.6368408203125, Entropy -568.81396484375, Learning Rate: 0.0125\n",
      "Epoch [1141/20000], Loss: 685.4032592773438, Entropy -551.0865478515625, Learning Rate: 0.0125\n",
      "Epoch [1142/20000], Loss: 682.4697875976562, Entropy -565.1791381835938, Learning Rate: 0.0125\n",
      "Epoch [1143/20000], Loss: 691.288330078125, Entropy -567.3455810546875, Learning Rate: 0.0125\n",
      "Epoch [1144/20000], Loss: 664.3933715820312, Entropy -544.026611328125, Learning Rate: 0.0125\n",
      "Epoch [1145/20000], Loss: 692.161865234375, Entropy -556.54736328125, Learning Rate: 0.0125\n",
      "Epoch [1146/20000], Loss: 682.557861328125, Entropy -573.8270874023438, Learning Rate: 0.0125\n",
      "Epoch [1147/20000], Loss: 691.8451538085938, Entropy -572.202392578125, Learning Rate: 0.0125\n",
      "Epoch [1148/20000], Loss: 687.119140625, Entropy -564.8751831054688, Learning Rate: 0.0125\n",
      "Epoch [1149/20000], Loss: 692.4710693359375, Entropy -574.050048828125, Learning Rate: 0.0125\n",
      "Epoch [1150/20000], Loss: 706.6741333007812, Entropy -566.6207275390625, Learning Rate: 0.0125\n",
      "Epoch [1151/20000], Loss: 682.1885986328125, Entropy -549.004150390625, Learning Rate: 0.0125\n",
      "Epoch [1152/20000], Loss: 667.3584594726562, Entropy -557.1302490234375, Learning Rate: 0.0125\n",
      "Epoch [1153/20000], Loss: 676.7374877929688, Entropy -551.1520385742188, Learning Rate: 0.0125\n",
      "Epoch [1154/20000], Loss: 686.1974487304688, Entropy -555.1819458007812, Learning Rate: 0.0125\n",
      "Epoch [1155/20000], Loss: 683.81884765625, Entropy -561.0032958984375, Learning Rate: 0.0125\n",
      "Epoch [1156/20000], Loss: 664.5619506835938, Entropy -549.4603271484375, Learning Rate: 0.0125\n",
      "Epoch [1157/20000], Loss: 662.2354125976562, Entropy -542.9917602539062, Learning Rate: 0.0125\n",
      "Epoch [1158/20000], Loss: 700.4949951171875, Entropy -573.3452758789062, Learning Rate: 0.0125\n",
      "Epoch [1159/20000], Loss: 689.06787109375, Entropy -550.833251953125, Learning Rate: 0.0125\n",
      "Epoch [1160/20000], Loss: 671.6566772460938, Entropy -552.1480712890625, Learning Rate: 0.0125\n",
      "Epoch [1161/20000], Loss: 674.2271118164062, Entropy -551.9896240234375, Learning Rate: 0.0125\n",
      "Epoch [1162/20000], Loss: 678.9368896484375, Entropy -561.845703125, Learning Rate: 0.0125\n",
      "Epoch [1163/20000], Loss: 675.4014892578125, Entropy -544.5086669921875, Learning Rate: 0.0125\n",
      "Epoch [1164/20000], Loss: 691.6766357421875, Entropy -563.0139770507812, Learning Rate: 0.0125\n",
      "Epoch [1165/20000], Loss: 677.7271118164062, Entropy -552.6439208984375, Learning Rate: 0.0125\n",
      "Epoch [1166/20000], Loss: 676.3040161132812, Entropy -553.5810546875, Learning Rate: 0.0125\n",
      "Epoch [1167/20000], Loss: 664.701171875, Entropy -547.6353759765625, Learning Rate: 0.0125\n",
      "Epoch [1168/20000], Loss: 671.1475830078125, Entropy -554.5053100585938, Learning Rate: 0.0125\n",
      "Epoch [1169/20000], Loss: 681.04833984375, Entropy -556.1311645507812, Learning Rate: 0.0125\n",
      "Epoch [1170/20000], Loss: 663.5851440429688, Entropy -538.70263671875, Learning Rate: 0.0125\n",
      "Epoch [1171/20000], Loss: 671.6502685546875, Entropy -546.0008544921875, Learning Rate: 0.0125\n",
      "Epoch [1172/20000], Loss: 660.6343994140625, Entropy -529.1968383789062, Learning Rate: 0.0125\n",
      "Epoch [1173/20000], Loss: 682.17041015625, Entropy -554.3483276367188, Learning Rate: 0.0125\n",
      "Epoch [1174/20000], Loss: 675.0905151367188, Entropy -557.783447265625, Learning Rate: 0.0125\n",
      "Epoch [1175/20000], Loss: 672.1787719726562, Entropy -560.5315551757812, Learning Rate: 0.0125\n",
      "Epoch [1176/20000], Loss: 663.9723510742188, Entropy -544.089111328125, Learning Rate: 0.0125\n",
      "Epoch [1177/20000], Loss: 665.703857421875, Entropy -547.3209228515625, Learning Rate: 0.0125\n",
      "Epoch [1178/20000], Loss: 669.7030639648438, Entropy -550.1171875, Learning Rate: 0.0125\n",
      "Epoch [1179/20000], Loss: 669.8031005859375, Entropy -544.6043090820312, Learning Rate: 0.0125\n",
      "Epoch [1180/20000], Loss: 663.7635498046875, Entropy -549.5491333007812, Learning Rate: 0.0125\n",
      "Epoch [1181/20000], Loss: 670.9358520507812, Entropy -561.2872314453125, Learning Rate: 0.0125\n",
      "Epoch [1182/20000], Loss: 665.0203247070312, Entropy -540.4171752929688, Learning Rate: 0.0125\n",
      "Epoch [1183/20000], Loss: 671.047607421875, Entropy -555.8609008789062, Learning Rate: 0.0125\n",
      "Epoch [1184/20000], Loss: 687.2398681640625, Entropy -573.6275634765625, Learning Rate: 0.0125\n",
      "Epoch [1185/20000], Loss: 667.9633178710938, Entropy -554.3898315429688, Learning Rate: 0.0125\n",
      "Epoch [1186/20000], Loss: 676.26611328125, Entropy -567.896484375, Learning Rate: 0.0125\n",
      "Epoch [1187/20000], Loss: 669.9798583984375, Entropy -556.5917358398438, Learning Rate: 0.0125\n",
      "Epoch [1188/20000], Loss: 666.6456909179688, Entropy -556.410400390625, Learning Rate: 0.0125\n",
      "Epoch [1189/20000], Loss: 675.1349487304688, Entropy -554.2186889648438, Learning Rate: 0.0125\n",
      "Epoch [1190/20000], Loss: 667.2952880859375, Entropy -540.6661987304688, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1191/20000], Loss: 678.2763061523438, Entropy -557.5665893554688, Learning Rate: 0.0125\n",
      "Epoch [1192/20000], Loss: 679.0631713867188, Entropy -567.375244140625, Learning Rate: 0.0125\n",
      "Epoch [1193/20000], Loss: 675.4013061523438, Entropy -558.42578125, Learning Rate: 0.0125\n",
      "Epoch [1194/20000], Loss: 651.9092407226562, Entropy -538.6436767578125, Learning Rate: 0.0125\n",
      "Epoch [1195/20000], Loss: 684.8185424804688, Entropy -558.4624633789062, Learning Rate: 0.0125\n",
      "Epoch [1196/20000], Loss: 667.920166015625, Entropy -555.8269653320312, Learning Rate: 0.0125\n",
      "Epoch [1197/20000], Loss: 664.7124633789062, Entropy -555.4366455078125, Learning Rate: 0.0125\n",
      "Epoch [1198/20000], Loss: 648.1207275390625, Entropy -535.3717041015625, Learning Rate: 0.0125\n",
      "Epoch [1199/20000], Loss: 650.2626342773438, Entropy -532.4885864257812, Learning Rate: 0.0125\n",
      "Epoch [1200/20000], Loss: 653.0253295898438, Entropy -536.4006958007812, Learning Rate: 0.0125\n",
      "Epoch [1201/20000], Loss: 647.846923828125, Entropy -530.5916748046875, Learning Rate: 0.0125\n",
      "Epoch [1202/20000], Loss: 682.9453125, Entropy -566.74951171875, Learning Rate: 0.0125\n",
      "Epoch [1203/20000], Loss: 677.155517578125, Entropy -539.8984985351562, Learning Rate: 0.0125\n",
      "Epoch [1204/20000], Loss: 667.9931030273438, Entropy -543.51220703125, Learning Rate: 0.0125\n",
      "Epoch [1205/20000], Loss: 644.9894409179688, Entropy -535.4324340820312, Learning Rate: 0.0125\n",
      "Epoch [1206/20000], Loss: 651.6316528320312, Entropy -533.844482421875, Learning Rate: 0.0125\n",
      "Epoch [1207/20000], Loss: 651.7379760742188, Entropy -545.9188232421875, Learning Rate: 0.0125\n",
      "Epoch [1208/20000], Loss: 664.1494140625, Entropy -539.0599975585938, Learning Rate: 0.0125\n",
      "Epoch [1209/20000], Loss: 650.4651489257812, Entropy -541.766357421875, Learning Rate: 0.0125\n",
      "Epoch [1210/20000], Loss: 681.8007202148438, Entropy -559.6386108398438, Learning Rate: 0.0125\n",
      "Epoch [1211/20000], Loss: 680.4306640625, Entropy -557.3609619140625, Learning Rate: 0.0125\n",
      "Epoch [1212/20000], Loss: 654.8522338867188, Entropy -548.8790893554688, Learning Rate: 0.0125\n",
      "Epoch [1213/20000], Loss: 658.3812255859375, Entropy -548.208251953125, Learning Rate: 0.0125\n",
      "Epoch [1214/20000], Loss: 663.7652587890625, Entropy -557.7351684570312, Learning Rate: 0.0125\n",
      "Epoch [1215/20000], Loss: 680.31640625, Entropy -547.081298828125, Learning Rate: 0.0125\n",
      "Epoch [1216/20000], Loss: 667.0535888671875, Entropy -561.282470703125, Learning Rate: 0.0125\n",
      "Epoch [1217/20000], Loss: 679.0027465820312, Entropy -560.998046875, Learning Rate: 0.0125\n",
      "Epoch [1218/20000], Loss: 663.9973754882812, Entropy -547.8895263671875, Learning Rate: 0.0125\n",
      "Epoch [1219/20000], Loss: 669.25341796875, Entropy -542.669677734375, Learning Rate: 0.0125\n",
      "Epoch [1220/20000], Loss: 656.817626953125, Entropy -538.539794921875, Learning Rate: 0.0125\n",
      "Epoch [1221/20000], Loss: 675.4713134765625, Entropy -561.8402099609375, Learning Rate: 0.0125\n",
      "Epoch [1222/20000], Loss: 673.8348999023438, Entropy -544.09033203125, Learning Rate: 0.0125\n",
      "Epoch [1223/20000], Loss: 653.9440307617188, Entropy -537.3811645507812, Learning Rate: 0.0125\n",
      "Epoch [1224/20000], Loss: 635.3167114257812, Entropy -509.68353271484375, Learning Rate: 0.0125\n",
      "Epoch [1225/20000], Loss: 649.5512084960938, Entropy -537.0924072265625, Learning Rate: 0.0125\n",
      "Epoch [1226/20000], Loss: 667.4044189453125, Entropy -554.093505859375, Learning Rate: 0.0125\n",
      "Epoch [1227/20000], Loss: 673.1278076171875, Entropy -560.8262939453125, Learning Rate: 0.0125\n",
      "Epoch [1228/20000], Loss: 662.5147094726562, Entropy -551.0322265625, Learning Rate: 0.0125\n",
      "Epoch [1229/20000], Loss: 656.9547729492188, Entropy -535.4046630859375, Learning Rate: 0.0125\n",
      "Epoch [1230/20000], Loss: 666.193603515625, Entropy -547.0800170898438, Learning Rate: 0.0125\n",
      "Epoch [1231/20000], Loss: 664.0623168945312, Entropy -550.7662963867188, Learning Rate: 0.0125\n",
      "Epoch [1232/20000], Loss: 671.7734985351562, Entropy -552.077880859375, Learning Rate: 0.0125\n",
      "Epoch [1233/20000], Loss: 662.5259399414062, Entropy -555.7411499023438, Learning Rate: 0.0125\n",
      "Epoch [1234/20000], Loss: 646.3234252929688, Entropy -536.14013671875, Learning Rate: 0.0125\n",
      "Epoch [1235/20000], Loss: 669.0052490234375, Entropy -552.6436767578125, Learning Rate: 0.0125\n",
      "Epoch [1236/20000], Loss: 668.054931640625, Entropy -548.81640625, Learning Rate: 0.0125\n",
      "Epoch [1237/20000], Loss: 681.6097412109375, Entropy -558.651123046875, Learning Rate: 0.0125\n",
      "Epoch [1238/20000], Loss: 635.4663696289062, Entropy -513.0454711914062, Learning Rate: 0.0125\n",
      "Epoch [1239/20000], Loss: 655.275146484375, Entropy -524.07958984375, Learning Rate: 0.0125\n",
      "Epoch [1240/20000], Loss: 668.0560302734375, Entropy -532.3201904296875, Learning Rate: 0.0125\n",
      "Epoch [1241/20000], Loss: 638.160888671875, Entropy -527.97412109375, Learning Rate: 0.0125\n",
      "Epoch [1242/20000], Loss: 667.1473388671875, Entropy -537.500732421875, Learning Rate: 0.0125\n",
      "Epoch [1243/20000], Loss: 656.247314453125, Entropy -535.6325073242188, Learning Rate: 0.0125\n",
      "Epoch [1244/20000], Loss: 665.8551025390625, Entropy -547.9000854492188, Learning Rate: 0.0125\n",
      "Epoch [1245/20000], Loss: 658.1041870117188, Entropy -531.0682373046875, Learning Rate: 0.0125\n",
      "Epoch [1246/20000], Loss: 643.196044921875, Entropy -529.3492431640625, Learning Rate: 0.0125\n",
      "Epoch [1247/20000], Loss: 676.2454833984375, Entropy -543.3447265625, Learning Rate: 0.0125\n",
      "Epoch [1248/20000], Loss: 644.8782958984375, Entropy -526.4234619140625, Learning Rate: 0.0125\n",
      "Epoch [1249/20000], Loss: 655.3614501953125, Entropy -527.3645629882812, Learning Rate: 0.0125\n",
      "Epoch [1250/20000], Loss: 666.7967529296875, Entropy -544.4600830078125, Learning Rate: 0.0125\n",
      "Epoch [1251/20000], Loss: 695.4783935546875, Entropy -557.821044921875, Learning Rate: 0.0125\n",
      "Epoch [1252/20000], Loss: 652.448486328125, Entropy -539.2919311523438, Learning Rate: 0.0125\n",
      "Epoch [1253/20000], Loss: 658.8781127929688, Entropy -545.9356079101562, Learning Rate: 0.0125\n",
      "Epoch [1254/20000], Loss: 665.6243286132812, Entropy -527.14892578125, Learning Rate: 0.0125\n",
      "Epoch [1255/20000], Loss: 641.4918823242188, Entropy -521.3201904296875, Learning Rate: 0.0125\n",
      "Epoch [1256/20000], Loss: 643.2276000976562, Entropy -528.9835815429688, Learning Rate: 0.0125\n",
      "Epoch [1257/20000], Loss: 659.199951171875, Entropy -541.9362182617188, Learning Rate: 0.0125\n",
      "Epoch [1258/20000], Loss: 668.173095703125, Entropy -543.2534790039062, Learning Rate: 0.0125\n",
      "Epoch [1259/20000], Loss: 648.2595825195312, Entropy -523.07275390625, Learning Rate: 0.0125\n",
      "Epoch [1260/20000], Loss: 661.4725341796875, Entropy -542.1195678710938, Learning Rate: 0.0125\n",
      "Epoch [1261/20000], Loss: 664.4998779296875, Entropy -548.5145263671875, Learning Rate: 0.0125\n",
      "Epoch [1262/20000], Loss: 667.01611328125, Entropy -525.1762084960938, Learning Rate: 0.0125\n",
      "Epoch [1263/20000], Loss: 670.257568359375, Entropy -552.547119140625, Learning Rate: 0.0125\n",
      "Epoch [1264/20000], Loss: 653.10693359375, Entropy -535.9759521484375, Learning Rate: 0.0125\n",
      "Epoch [1265/20000], Loss: 634.8704833984375, Entropy -531.1045532226562, Learning Rate: 0.0125\n",
      "Epoch [1266/20000], Loss: 668.3936767578125, Entropy -544.444580078125, Learning Rate: 0.0125\n",
      "Epoch [1267/20000], Loss: 663.7781982421875, Entropy -547.302490234375, Learning Rate: 0.0125\n",
      "Epoch [1268/20000], Loss: 643.8883056640625, Entropy -536.5065307617188, Learning Rate: 0.0125\n",
      "Epoch [1269/20000], Loss: 646.0745849609375, Entropy -544.364990234375, Learning Rate: 0.0125\n",
      "Epoch [1270/20000], Loss: 657.1737060546875, Entropy -532.5074462890625, Learning Rate: 0.0125\n",
      "Epoch [1271/20000], Loss: 646.8265380859375, Entropy -537.2268676757812, Learning Rate: 0.0125\n",
      "Epoch [1272/20000], Loss: 661.9259033203125, Entropy -550.421875, Learning Rate: 0.0125\n",
      "Epoch [1273/20000], Loss: 666.5849609375, Entropy -532.6642456054688, Learning Rate: 0.0125\n",
      "Epoch [1274/20000], Loss: 641.0510864257812, Entropy -525.684814453125, Learning Rate: 0.0125\n",
      "Epoch [1275/20000], Loss: 659.7152099609375, Entropy -531.7036743164062, Learning Rate: 0.0125\n",
      "Epoch [1276/20000], Loss: 632.9375610351562, Entropy -515.22216796875, Learning Rate: 0.0125\n",
      "Epoch [1277/20000], Loss: 652.1994018554688, Entropy -543.0526733398438, Learning Rate: 0.0125\n",
      "Epoch [1278/20000], Loss: 639.1006469726562, Entropy -527.1555786132812, Learning Rate: 0.0125\n",
      "Epoch [1279/20000], Loss: 644.78369140625, Entropy -536.3645629882812, Learning Rate: 0.0125\n",
      "Epoch [1280/20000], Loss: 647.0379638671875, Entropy -533.6270751953125, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1281/20000], Loss: 645.2578735351562, Entropy -524.1752319335938, Learning Rate: 0.0125\n",
      "Epoch [1282/20000], Loss: 649.4246215820312, Entropy -533.3230590820312, Learning Rate: 0.0125\n",
      "Epoch [1283/20000], Loss: 652.1134033203125, Entropy -536.10205078125, Learning Rate: 0.0125\n",
      "Epoch [1284/20000], Loss: 718.2144165039062, Entropy -544.9901123046875, Learning Rate: 0.0125\n",
      "Epoch [1285/20000], Loss: 689.6380004882812, Entropy -559.5023193359375, Learning Rate: 0.0125\n",
      "Epoch [1286/20000], Loss: 652.28857421875, Entropy -543.281494140625, Learning Rate: 0.0125\n",
      "Epoch [1287/20000], Loss: 655.4957885742188, Entropy -535.6965942382812, Learning Rate: 0.0125\n",
      "Epoch [1288/20000], Loss: 659.10400390625, Entropy -531.557861328125, Learning Rate: 0.0125\n",
      "Epoch [1289/20000], Loss: 645.4909057617188, Entropy -533.4508056640625, Learning Rate: 0.0125\n",
      "Epoch [1290/20000], Loss: 653.9497680664062, Entropy -537.08056640625, Learning Rate: 0.0125\n",
      "Epoch [1291/20000], Loss: 643.1478271484375, Entropy -531.2886962890625, Learning Rate: 0.0125\n",
      "Epoch [1292/20000], Loss: 641.5137939453125, Entropy -520.832763671875, Learning Rate: 0.0125\n",
      "Epoch [1293/20000], Loss: 655.9915771484375, Entropy -538.61376953125, Learning Rate: 0.0125\n",
      "Epoch [1294/20000], Loss: 659.9166259765625, Entropy -544.5760498046875, Learning Rate: 0.0125\n",
      "Epoch [1295/20000], Loss: 659.5157470703125, Entropy -541.7672729492188, Learning Rate: 0.0125\n",
      "Epoch [1296/20000], Loss: 668.1495971679688, Entropy -557.0499877929688, Learning Rate: 0.0125\n",
      "Epoch [1297/20000], Loss: 667.7816162109375, Entropy -563.4672241210938, Learning Rate: 0.0125\n",
      "Epoch [1298/20000], Loss: 657.8714599609375, Entropy -548.1402587890625, Learning Rate: 0.0125\n",
      "Epoch [1299/20000], Loss: 646.0941162109375, Entropy -538.5308227539062, Learning Rate: 0.0125\n",
      "Epoch [1300/20000], Loss: 684.1611328125, Entropy -561.816650390625, Learning Rate: 0.0125\n",
      "Epoch [1301/20000], Loss: 650.8973999023438, Entropy -547.6317749023438, Learning Rate: 0.0125\n",
      "Epoch [1302/20000], Loss: 645.0653076171875, Entropy -527.1805419921875, Learning Rate: 0.0125\n",
      "Epoch [1303/20000], Loss: 653.1859130859375, Entropy -526.859375, Learning Rate: 0.0125\n",
      "Epoch [1304/20000], Loss: 654.2119140625, Entropy -543.7337646484375, Learning Rate: 0.0125\n",
      "Epoch [1305/20000], Loss: 638.2166748046875, Entropy -509.6400451660156, Learning Rate: 0.0125\n",
      "Epoch [1306/20000], Loss: 663.4229736328125, Entropy -533.203857421875, Learning Rate: 0.0125\n",
      "Epoch [1307/20000], Loss: 635.2593383789062, Entropy -525.802978515625, Learning Rate: 0.0125\n",
      "Epoch [1308/20000], Loss: 658.5929565429688, Entropy -549.957763671875, Learning Rate: 0.0125\n",
      "Epoch [1309/20000], Loss: 648.1622314453125, Entropy -529.76123046875, Learning Rate: 0.0125\n",
      "Epoch [1310/20000], Loss: 655.7423706054688, Entropy -536.169921875, Learning Rate: 0.0125\n",
      "Epoch [1311/20000], Loss: 654.2283325195312, Entropy -540.8003540039062, Learning Rate: 0.0125\n",
      "Epoch [1312/20000], Loss: 663.246826171875, Entropy -550.701904296875, Learning Rate: 0.0125\n",
      "Epoch [1313/20000], Loss: 649.8671875, Entropy -536.030029296875, Learning Rate: 0.0125\n",
      "Epoch [1314/20000], Loss: 648.3590087890625, Entropy -527.0179443359375, Learning Rate: 0.0125\n",
      "Epoch [1315/20000], Loss: 650.775634765625, Entropy -526.6300048828125, Learning Rate: 0.0125\n",
      "Epoch [1316/20000], Loss: 635.4603881835938, Entropy -512.156005859375, Learning Rate: 0.0125\n",
      "Epoch [1317/20000], Loss: 631.983154296875, Entropy -514.506591796875, Learning Rate: 0.0125\n",
      "Epoch [1318/20000], Loss: 652.2844848632812, Entropy -540.283203125, Learning Rate: 0.0125\n",
      "Epoch [1319/20000], Loss: 644.5604858398438, Entropy -533.0053100585938, Learning Rate: 0.0125\n",
      "Epoch [1320/20000], Loss: 638.8367919921875, Entropy -534.0841064453125, Learning Rate: 0.0125\n",
      "Epoch [1321/20000], Loss: 649.3250732421875, Entropy -540.6781616210938, Learning Rate: 0.0125\n",
      "Epoch [1322/20000], Loss: 644.719482421875, Entropy -525.395263671875, Learning Rate: 0.0125\n",
      "Epoch [1323/20000], Loss: 661.9149169921875, Entropy -543.0790405273438, Learning Rate: 0.0125\n",
      "Epoch [1324/20000], Loss: 647.2906494140625, Entropy -535.6171875, Learning Rate: 0.0125\n",
      "Epoch [1325/20000], Loss: 647.2039184570312, Entropy -523.13671875, Learning Rate: 0.0125\n",
      "Epoch [1326/20000], Loss: 654.5880126953125, Entropy -544.8450927734375, Learning Rate: 0.0125\n",
      "Epoch [1327/20000], Loss: 654.1971435546875, Entropy -531.283935546875, Learning Rate: 0.0125\n",
      "Epoch [1328/20000], Loss: 661.0035400390625, Entropy -537.6295166015625, Learning Rate: 0.0125\n",
      "Epoch [1329/20000], Loss: 644.3280029296875, Entropy -532.8585815429688, Learning Rate: 0.0125\n",
      "Epoch [1330/20000], Loss: 639.4676513671875, Entropy -524.870361328125, Learning Rate: 0.0125\n",
      "Epoch [1331/20000], Loss: 644.2785034179688, Entropy -528.1973876953125, Learning Rate: 0.0125\n",
      "Epoch [1332/20000], Loss: 651.8848876953125, Entropy -544.6692504882812, Learning Rate: 0.0125\n",
      "Epoch [1333/20000], Loss: 634.76123046875, Entropy -527.8751220703125, Learning Rate: 0.0125\n",
      "Epoch [1334/20000], Loss: 689.0592041015625, Entropy -523.6046142578125, Learning Rate: 0.0125\n",
      "Epoch [1335/20000], Loss: 653.4073486328125, Entropy -533.3616943359375, Learning Rate: 0.0125\n",
      "Epoch [1336/20000], Loss: 647.37890625, Entropy -540.289306640625, Learning Rate: 0.0125\n",
      "Epoch [1337/20000], Loss: 645.3653564453125, Entropy -528.5421142578125, Learning Rate: 0.0125\n",
      "Epoch [1338/20000], Loss: 635.7235107421875, Entropy -520.6763916015625, Learning Rate: 0.0125\n",
      "Epoch [1339/20000], Loss: 649.7445068359375, Entropy -553.7207641601562, Learning Rate: 0.0125\n",
      "Epoch [1340/20000], Loss: 652.036376953125, Entropy -544.4830932617188, Learning Rate: 0.0125\n",
      "Epoch [1341/20000], Loss: 655.3724975585938, Entropy -539.1689453125, Learning Rate: 0.0125\n",
      "Epoch [1342/20000], Loss: 639.1646728515625, Entropy -515.9822998046875, Learning Rate: 0.0125\n",
      "Epoch [1343/20000], Loss: 672.4053955078125, Entropy -551.8074340820312, Learning Rate: 0.0125\n",
      "Epoch [1344/20000], Loss: 645.6327514648438, Entropy -533.5784912109375, Learning Rate: 0.0125\n",
      "Epoch [1345/20000], Loss: 677.0551147460938, Entropy -550.4705200195312, Learning Rate: 0.0125\n",
      "Epoch [1346/20000], Loss: 652.3588256835938, Entropy -529.2528076171875, Learning Rate: 0.0125\n",
      "Epoch [1347/20000], Loss: 651.3833618164062, Entropy -530.0472412109375, Learning Rate: 0.0125\n",
      "Epoch [1348/20000], Loss: 650.0066528320312, Entropy -537.2283325195312, Learning Rate: 0.0125\n",
      "Epoch [1349/20000], Loss: 657.4493408203125, Entropy -535.2726440429688, Learning Rate: 0.0125\n",
      "Epoch [1350/20000], Loss: 660.49365234375, Entropy -532.9019165039062, Learning Rate: 0.0125\n",
      "Epoch [1351/20000], Loss: 638.77685546875, Entropy -524.2069702148438, Learning Rate: 0.0125\n",
      "Epoch [1352/20000], Loss: 676.4578857421875, Entropy -543.3426513671875, Learning Rate: 0.0125\n",
      "Epoch [1353/20000], Loss: 653.1726684570312, Entropy -543.9439697265625, Learning Rate: 0.0125\n",
      "Epoch [1354/20000], Loss: 668.628173828125, Entropy -542.612060546875, Learning Rate: 0.0125\n",
      "Epoch [1355/20000], Loss: 628.2711181640625, Entropy -511.173095703125, Learning Rate: 0.0125\n",
      "Epoch [1356/20000], Loss: 644.8410034179688, Entropy -522.239013671875, Learning Rate: 0.0125\n",
      "Epoch [1357/20000], Loss: 636.8948974609375, Entropy -512.3741455078125, Learning Rate: 0.0125\n",
      "Epoch [1358/20000], Loss: 650.1614990234375, Entropy -521.3341064453125, Learning Rate: 0.0125\n",
      "Epoch [1359/20000], Loss: 646.0392456054688, Entropy -524.2734985351562, Learning Rate: 0.0125\n",
      "Epoch [1360/20000], Loss: 635.2069702148438, Entropy -507.4621276855469, Learning Rate: 0.0125\n",
      "Epoch [1361/20000], Loss: 640.623046875, Entropy -522.1287841796875, Learning Rate: 0.0125\n",
      "Epoch [1362/20000], Loss: 666.45947265625, Entropy -538.8238525390625, Learning Rate: 0.0125\n",
      "Epoch [1363/20000], Loss: 651.44970703125, Entropy -521.002685546875, Learning Rate: 0.0125\n",
      "Epoch [1364/20000], Loss: 650.38427734375, Entropy -515.1829833984375, Learning Rate: 0.0125\n",
      "Epoch [1365/20000], Loss: 659.8535766601562, Entropy -544.607421875, Learning Rate: 0.0125\n",
      "Epoch [1366/20000], Loss: 671.4127197265625, Entropy -526.531005859375, Learning Rate: 0.0125\n",
      "Epoch [1367/20000], Loss: 681.0135498046875, Entropy -550.3095703125, Learning Rate: 0.0125\n",
      "Epoch [1368/20000], Loss: 642.9429321289062, Entropy -531.6278686523438, Learning Rate: 0.0125\n",
      "Epoch [1369/20000], Loss: 639.0040893554688, Entropy -511.27362060546875, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1370/20000], Loss: 651.7362670898438, Entropy -539.653076171875, Learning Rate: 0.0125\n",
      "Epoch [1371/20000], Loss: 639.2506103515625, Entropy -521.263671875, Learning Rate: 0.0125\n",
      "Epoch [1372/20000], Loss: 640.58935546875, Entropy -516.3271484375, Learning Rate: 0.0125\n",
      "Epoch [1373/20000], Loss: 667.9519653320312, Entropy -544.3834228515625, Learning Rate: 0.0125\n",
      "Epoch [1374/20000], Loss: 662.5790405273438, Entropy -552.4664306640625, Learning Rate: 0.0125\n",
      "Epoch [1375/20000], Loss: 673.3611450195312, Entropy -535.7734985351562, Learning Rate: 0.0125\n",
      "Epoch [1376/20000], Loss: 638.7882080078125, Entropy -520.4003295898438, Learning Rate: 0.0125\n",
      "Epoch [1377/20000], Loss: 688.6663208007812, Entropy -528.9949951171875, Learning Rate: 0.0125\n",
      "Epoch [1378/20000], Loss: 646.6817016601562, Entropy -526.3896484375, Learning Rate: 0.0125\n",
      "Epoch [1379/20000], Loss: 658.0742797851562, Entropy -529.97509765625, Learning Rate: 0.0125\n",
      "Epoch [1380/20000], Loss: 652.1342163085938, Entropy -527.8551025390625, Learning Rate: 0.0125\n",
      "Epoch [1381/20000], Loss: 662.760009765625, Entropy -530.8392333984375, Learning Rate: 0.0125\n",
      "Epoch [1382/20000], Loss: 658.7479248046875, Entropy -519.4540405273438, Learning Rate: 0.0125\n",
      "Epoch [1383/20000], Loss: 651.2598876953125, Entropy -538.462158203125, Learning Rate: 0.0125\n",
      "Epoch [1384/20000], Loss: 661.0259399414062, Entropy -536.12158203125, Learning Rate: 0.0125\n",
      "Epoch [1385/20000], Loss: 647.1846923828125, Entropy -516.196044921875, Learning Rate: 0.0125\n",
      "Epoch [1386/20000], Loss: 681.8988647460938, Entropy -544.5062255859375, Learning Rate: 0.0125\n",
      "Epoch [1387/20000], Loss: 663.047119140625, Entropy -546.1873779296875, Learning Rate: 0.0125\n",
      "Epoch [1388/20000], Loss: 650.3675537109375, Entropy -530.4697875976562, Learning Rate: 0.0125\n",
      "Epoch [1389/20000], Loss: 651.1228637695312, Entropy -527.6199951171875, Learning Rate: 0.0125\n",
      "Epoch [1390/20000], Loss: 624.1387329101562, Entropy -500.40093994140625, Learning Rate: 0.0125\n",
      "Epoch [1391/20000], Loss: 647.5094604492188, Entropy -511.9535217285156, Learning Rate: 0.0125\n",
      "Epoch [1392/20000], Loss: 655.8358154296875, Entropy -542.0184936523438, Learning Rate: 0.0125\n",
      "Epoch [1393/20000], Loss: 648.9222412109375, Entropy -511.3294677734375, Learning Rate: 0.0125\n",
      "Epoch [1394/20000], Loss: 649.58349609375, Entropy -536.275390625, Learning Rate: 0.0125\n",
      "Epoch [1395/20000], Loss: 654.8701782226562, Entropy -539.5997924804688, Learning Rate: 0.0125\n",
      "Epoch [1396/20000], Loss: 640.6148681640625, Entropy -522.4168090820312, Learning Rate: 0.0125\n",
      "Epoch [1397/20000], Loss: 645.405517578125, Entropy -517.8294067382812, Learning Rate: 0.0125\n",
      "Epoch [1398/20000], Loss: 629.3314208984375, Entropy -522.281982421875, Learning Rate: 0.0125\n",
      "Epoch [1399/20000], Loss: 632.4130249023438, Entropy -512.7171020507812, Learning Rate: 0.0125\n",
      "Epoch [1400/20000], Loss: 629.9041748046875, Entropy -519.3170776367188, Learning Rate: 0.0125\n",
      "Epoch [1401/20000], Loss: 642.5132446289062, Entropy -534.3140869140625, Learning Rate: 0.0125\n",
      "Epoch [1402/20000], Loss: 631.3936767578125, Entropy -513.5523681640625, Learning Rate: 0.0125\n",
      "Epoch [1403/20000], Loss: 644.3200073242188, Entropy -536.353759765625, Learning Rate: 0.0125\n",
      "Epoch [1404/20000], Loss: 639.1702880859375, Entropy -521.5203857421875, Learning Rate: 0.0125\n",
      "Epoch [1405/20000], Loss: 647.1121826171875, Entropy -539.5817260742188, Learning Rate: 0.0125\n",
      "Epoch [1406/20000], Loss: 653.0157470703125, Entropy -531.462646484375, Learning Rate: 0.0125\n",
      "Epoch [1407/20000], Loss: 666.3798217773438, Entropy -549.0186767578125, Learning Rate: 0.0125\n",
      "Epoch [1408/20000], Loss: 634.8359375, Entropy -531.6463623046875, Learning Rate: 0.0125\n",
      "Epoch [1409/20000], Loss: 632.7317504882812, Entropy -517.6612548828125, Learning Rate: 0.0125\n",
      "Epoch [1410/20000], Loss: 636.888671875, Entropy -527.226318359375, Learning Rate: 0.0125\n",
      "Epoch [1411/20000], Loss: 620.44580078125, Entropy -515.2296752929688, Learning Rate: 0.0125\n",
      "Epoch [1412/20000], Loss: 620.9359741210938, Entropy -516.5888671875, Learning Rate: 0.0125\n",
      "Epoch [1413/20000], Loss: 639.9033203125, Entropy -534.5540161132812, Learning Rate: 0.0125\n",
      "Epoch [1414/20000], Loss: 618.847412109375, Entropy -507.5614013671875, Learning Rate: 0.0125\n",
      "Epoch [1415/20000], Loss: 612.7049560546875, Entropy -502.76678466796875, Learning Rate: 0.0125\n",
      "Epoch [1416/20000], Loss: 652.9025268554688, Entropy -524.65869140625, Learning Rate: 0.0125\n",
      "Epoch [1417/20000], Loss: 615.60009765625, Entropy -509.45166015625, Learning Rate: 0.0125\n",
      "Epoch [1418/20000], Loss: 637.7052612304688, Entropy -532.6129150390625, Learning Rate: 0.0125\n",
      "Epoch [1419/20000], Loss: 638.6410522460938, Entropy -531.91552734375, Learning Rate: 0.0125\n",
      "Epoch [1420/20000], Loss: 637.3753662109375, Entropy -520.16845703125, Learning Rate: 0.0125\n",
      "Epoch [1421/20000], Loss: 633.346435546875, Entropy -536.2994384765625, Learning Rate: 0.0125\n",
      "Epoch [1422/20000], Loss: 630.59814453125, Entropy -525.360107421875, Learning Rate: 0.0125\n",
      "Epoch [1423/20000], Loss: 648.9346923828125, Entropy -531.3192138671875, Learning Rate: 0.0125\n",
      "Epoch [1424/20000], Loss: 649.0396728515625, Entropy -553.691162109375, Learning Rate: 0.0125\n",
      "Epoch [1425/20000], Loss: 647.52978515625, Entropy -530.2427978515625, Learning Rate: 0.0125\n",
      "Epoch [1426/20000], Loss: 629.87353515625, Entropy -520.8652954101562, Learning Rate: 0.0125\n",
      "Epoch [1427/20000], Loss: 647.0540771484375, Entropy -536.6239013671875, Learning Rate: 0.0125\n",
      "Epoch [1428/20000], Loss: 642.312255859375, Entropy -540.9398193359375, Learning Rate: 0.0125\n",
      "Epoch [1429/20000], Loss: 638.8975219726562, Entropy -512.4197998046875, Learning Rate: 0.0125\n",
      "Epoch [1430/20000], Loss: 630.2769165039062, Entropy -508.55938720703125, Learning Rate: 0.0125\n",
      "Epoch [1431/20000], Loss: 622.197509765625, Entropy -515.7234497070312, Learning Rate: 0.0125\n",
      "Epoch [1432/20000], Loss: 667.750244140625, Entropy -542.819580078125, Learning Rate: 0.0125\n",
      "Epoch [1433/20000], Loss: 633.7451171875, Entropy -513.930419921875, Learning Rate: 0.0125\n",
      "Epoch [1434/20000], Loss: 657.7476196289062, Entropy -540.1788330078125, Learning Rate: 0.0125\n",
      "Epoch [1435/20000], Loss: 624.8857421875, Entropy -510.0119934082031, Learning Rate: 0.0125\n",
      "Epoch [1436/20000], Loss: 622.8017578125, Entropy -510.7821960449219, Learning Rate: 0.0125\n",
      "Epoch [1437/20000], Loss: 609.1569213867188, Entropy -494.0892333984375, Learning Rate: 0.0125\n",
      "Epoch [1438/20000], Loss: 669.7410278320312, Entropy -536.2649536132812, Learning Rate: 0.0125\n",
      "Epoch [1439/20000], Loss: 620.5213623046875, Entropy -506.60693359375, Learning Rate: 0.0125\n",
      "Epoch [1440/20000], Loss: 626.0869140625, Entropy -525.8740844726562, Learning Rate: 0.0125\n",
      "Epoch [1441/20000], Loss: 641.4168701171875, Entropy -518.9508056640625, Learning Rate: 0.0125\n",
      "Epoch [1442/20000], Loss: 625.8602294921875, Entropy -509.87017822265625, Learning Rate: 0.0125\n",
      "Epoch [1443/20000], Loss: 637.6991577148438, Entropy -502.1412353515625, Learning Rate: 0.0125\n",
      "Epoch [1444/20000], Loss: 634.2576904296875, Entropy -520.7860107421875, Learning Rate: 0.0125\n",
      "Epoch [1445/20000], Loss: 655.4715576171875, Entropy -531.061279296875, Learning Rate: 0.0125\n",
      "Epoch [1446/20000], Loss: 704.4574584960938, Entropy -521.66455078125, Learning Rate: 0.0125\n",
      "Epoch [1447/20000], Loss: 647.15380859375, Entropy -531.8115234375, Learning Rate: 0.0125\n",
      "Epoch [1448/20000], Loss: 653.28564453125, Entropy -516.897216796875, Learning Rate: 0.0125\n",
      "Epoch [1449/20000], Loss: 651.5206298828125, Entropy -526.3162841796875, Learning Rate: 0.0125\n",
      "Epoch [1450/20000], Loss: 652.3941040039062, Entropy -536.1708374023438, Learning Rate: 0.0125\n",
      "Epoch [1451/20000], Loss: 659.6873779296875, Entropy -514.6768188476562, Learning Rate: 0.0125\n",
      "Epoch [1452/20000], Loss: 650.6544799804688, Entropy -538.80859375, Learning Rate: 0.0125\n",
      "Epoch [1453/20000], Loss: 630.03125, Entropy -507.31243896484375, Learning Rate: 0.0125\n",
      "Epoch [1454/20000], Loss: 643.4644165039062, Entropy -527.7373657226562, Learning Rate: 0.0125\n",
      "Epoch [1455/20000], Loss: 626.6813354492188, Entropy -519.6981811523438, Learning Rate: 0.0125\n",
      "Epoch [1456/20000], Loss: 623.0823974609375, Entropy -510.5099792480469, Learning Rate: 0.0125\n",
      "Epoch [1457/20000], Loss: 654.0267944335938, Entropy -512.3223876953125, Learning Rate: 0.0125\n",
      "Epoch [1458/20000], Loss: 634.448486328125, Entropy -509.0744934082031, Learning Rate: 0.0125\n",
      "Epoch [1459/20000], Loss: 632.5685424804688, Entropy -505.5450439453125, Learning Rate: 0.0125\n",
      "Epoch [1460/20000], Loss: 633.6959228515625, Entropy -527.1553344726562, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1461/20000], Loss: 651.1551513671875, Entropy -537.5559692382812, Learning Rate: 0.0125\n",
      "Epoch [1462/20000], Loss: 676.227783203125, Entropy -549.718994140625, Learning Rate: 0.0125\n",
      "Epoch [1463/20000], Loss: 636.33203125, Entropy -522.6488037109375, Learning Rate: 0.0125\n",
      "Epoch [1464/20000], Loss: 653.3530883789062, Entropy -511.46966552734375, Learning Rate: 0.0125\n",
      "Epoch [1465/20000], Loss: 653.7228393554688, Entropy -517.2703247070312, Learning Rate: 0.0125\n",
      "Epoch [1466/20000], Loss: 633.8848876953125, Entropy -521.4071044921875, Learning Rate: 0.0125\n",
      "Epoch [1467/20000], Loss: 645.3494873046875, Entropy -520.4024658203125, Learning Rate: 0.0125\n",
      "Epoch [1468/20000], Loss: 620.0322265625, Entropy -500.0926208496094, Learning Rate: 0.0125\n",
      "Epoch [1469/20000], Loss: 645.8645629882812, Entropy -519.8429565429688, Learning Rate: 0.0125\n",
      "Epoch [1470/20000], Loss: 636.1964111328125, Entropy -517.7422485351562, Learning Rate: 0.0125\n",
      "Epoch [1471/20000], Loss: 633.1090087890625, Entropy -521.690673828125, Learning Rate: 0.0125\n",
      "Epoch [1472/20000], Loss: 635.67529296875, Entropy -525.5960693359375, Learning Rate: 0.0125\n",
      "Epoch [1473/20000], Loss: 640.2552490234375, Entropy -517.0238037109375, Learning Rate: 0.0125\n",
      "Epoch [1474/20000], Loss: 631.16650390625, Entropy -505.939697265625, Learning Rate: 0.0125\n",
      "Epoch [1475/20000], Loss: 637.329345703125, Entropy -507.4130859375, Learning Rate: 0.0125\n",
      "Epoch [1476/20000], Loss: 631.683349609375, Entropy -518.8052978515625, Learning Rate: 0.0125\n",
      "Epoch [1477/20000], Loss: 651.4892578125, Entropy -527.510009765625, Learning Rate: 0.0125\n",
      "Epoch [1478/20000], Loss: 614.2484130859375, Entropy -510.0703430175781, Learning Rate: 0.0125\n",
      "Epoch [1479/20000], Loss: 628.4188232421875, Entropy -527.7734375, Learning Rate: 0.0125\n",
      "Epoch [1480/20000], Loss: 628.8154296875, Entropy -522.9707641601562, Learning Rate: 0.0125\n",
      "Epoch [1481/20000], Loss: 612.791748046875, Entropy -507.95050048828125, Learning Rate: 0.0125\n",
      "Epoch [1482/20000], Loss: 622.1004028320312, Entropy -509.4115905761719, Learning Rate: 0.0125\n",
      "Epoch [1483/20000], Loss: 632.9874267578125, Entropy -518.7823486328125, Learning Rate: 0.0125\n",
      "Epoch [1484/20000], Loss: 629.2208251953125, Entropy -514.3079833984375, Learning Rate: 0.0125\n",
      "Epoch [1485/20000], Loss: 620.4708251953125, Entropy -513.457275390625, Learning Rate: 0.0125\n",
      "Epoch [1486/20000], Loss: 638.0241088867188, Entropy -522.1248779296875, Learning Rate: 0.0125\n",
      "Epoch [1487/20000], Loss: 641.846923828125, Entropy -546.2747802734375, Learning Rate: 0.0125\n",
      "Epoch [1488/20000], Loss: 627.1846923828125, Entropy -512.255126953125, Learning Rate: 0.0125\n",
      "Epoch [1489/20000], Loss: 636.3828125, Entropy -530.515380859375, Learning Rate: 0.0125\n",
      "Epoch [1490/20000], Loss: 645.6680908203125, Entropy -539.5943603515625, Learning Rate: 0.0125\n",
      "Epoch [1491/20000], Loss: 627.286376953125, Entropy -522.70751953125, Learning Rate: 0.0125\n",
      "Epoch [1492/20000], Loss: 616.0809326171875, Entropy -493.4625244140625, Learning Rate: 0.0125\n",
      "Epoch [1493/20000], Loss: 619.2352294921875, Entropy -509.43408203125, Learning Rate: 0.0125\n",
      "Epoch [1494/20000], Loss: 630.6114501953125, Entropy -526.83740234375, Learning Rate: 0.0125\n",
      "Epoch [1495/20000], Loss: 635.0735473632812, Entropy -519.8553466796875, Learning Rate: 0.0125\n",
      "Epoch [1496/20000], Loss: 620.0975341796875, Entropy -496.09112548828125, Learning Rate: 0.0125\n",
      "Epoch [1497/20000], Loss: 651.5025024414062, Entropy -529.4024658203125, Learning Rate: 0.0125\n",
      "Epoch [1498/20000], Loss: 630.9025268554688, Entropy -523.4788208007812, Learning Rate: 0.0125\n",
      "Epoch [1499/20000], Loss: 639.5857543945312, Entropy -531.9988403320312, Learning Rate: 0.0125\n",
      "Epoch [1500/20000], Loss: 618.5294799804688, Entropy -508.3258972167969, Learning Rate: 0.0125\n",
      "Epoch [1501/20000], Loss: 621.0557861328125, Entropy -502.49951171875, Learning Rate: 0.0125\n",
      "Epoch [1502/20000], Loss: 642.783447265625, Entropy -533.54296875, Learning Rate: 0.0125\n",
      "Epoch [1503/20000], Loss: 617.7245483398438, Entropy -499.2816162109375, Learning Rate: 0.0125\n",
      "Epoch [1504/20000], Loss: 627.0728149414062, Entropy -516.9620361328125, Learning Rate: 0.0125\n",
      "Epoch [1505/20000], Loss: 608.3303833007812, Entropy -500.6973876953125, Learning Rate: 0.0125\n",
      "Epoch [1506/20000], Loss: 629.7603149414062, Entropy -523.0260009765625, Learning Rate: 0.0125\n",
      "Epoch [1507/20000], Loss: 617.4385986328125, Entropy -514.5996704101562, Learning Rate: 0.0125\n",
      "Epoch [1508/20000], Loss: 644.709228515625, Entropy -533.15576171875, Learning Rate: 0.0125\n",
      "Epoch [1509/20000], Loss: 620.4126586914062, Entropy -501.2872314453125, Learning Rate: 0.0125\n",
      "Epoch [1510/20000], Loss: 621.5654296875, Entropy -517.3997802734375, Learning Rate: 0.0125\n",
      "Epoch [1511/20000], Loss: 643.9688720703125, Entropy -523.23876953125, Learning Rate: 0.0125\n",
      "Epoch [1512/20000], Loss: 623.4213256835938, Entropy -501.1346435546875, Learning Rate: 0.0125\n",
      "Epoch [1513/20000], Loss: 628.9617919921875, Entropy -520.6376953125, Learning Rate: 0.0125\n",
      "Epoch [1514/20000], Loss: 623.8250732421875, Entropy -519.5792236328125, Learning Rate: 0.0125\n",
      "Epoch [1515/20000], Loss: 617.940673828125, Entropy -502.8031311035156, Learning Rate: 0.0125\n",
      "Epoch [1516/20000], Loss: 621.202392578125, Entropy -503.36083984375, Learning Rate: 0.0125\n",
      "Epoch [1517/20000], Loss: 629.8019409179688, Entropy -507.9926452636719, Learning Rate: 0.0125\n",
      "Epoch [1518/20000], Loss: 645.5546264648438, Entropy -525.6543579101562, Learning Rate: 0.0125\n",
      "Epoch [1519/20000], Loss: 628.8780517578125, Entropy -507.2393798828125, Learning Rate: 0.0125\n",
      "Epoch [1520/20000], Loss: 631.6124267578125, Entropy -501.6371154785156, Learning Rate: 0.0125\n",
      "Epoch [1521/20000], Loss: 621.8343505859375, Entropy -513.513427734375, Learning Rate: 0.0125\n",
      "Epoch [1522/20000], Loss: 635.5055541992188, Entropy -526.914794921875, Learning Rate: 0.0125\n",
      "Epoch [1523/20000], Loss: 630.878662109375, Entropy -521.359619140625, Learning Rate: 0.0125\n",
      "Epoch [1524/20000], Loss: 629.9900512695312, Entropy -513.2144775390625, Learning Rate: 0.0125\n",
      "Epoch [1525/20000], Loss: 629.781494140625, Entropy -498.7341613769531, Learning Rate: 0.0125\n",
      "Epoch [1526/20000], Loss: 633.2879028320312, Entropy -515.7054443359375, Learning Rate: 0.0125\n",
      "Epoch [1527/20000], Loss: 644.6200561523438, Entropy -524.798095703125, Learning Rate: 0.0125\n",
      "Epoch [1528/20000], Loss: 614.3966064453125, Entropy -504.3033752441406, Learning Rate: 0.0125\n",
      "Epoch [1529/20000], Loss: 619.02734375, Entropy -501.9004211425781, Learning Rate: 0.0125\n",
      "Epoch [1530/20000], Loss: 618.8939819335938, Entropy -514.121337890625, Learning Rate: 0.0125\n",
      "Epoch [1531/20000], Loss: 623.8671264648438, Entropy -523.8866577148438, Learning Rate: 0.0125\n",
      "Epoch [1532/20000], Loss: 645.954345703125, Entropy -522.392333984375, Learning Rate: 0.0125\n",
      "Epoch [1533/20000], Loss: 623.0157470703125, Entropy -509.73223876953125, Learning Rate: 0.0125\n",
      "Epoch [1534/20000], Loss: 641.0443725585938, Entropy -519.7532958984375, Learning Rate: 0.0125\n",
      "Epoch [1535/20000], Loss: 645.2222900390625, Entropy -518.5743408203125, Learning Rate: 0.0125\n",
      "Epoch [1536/20000], Loss: 623.7733154296875, Entropy -513.2464599609375, Learning Rate: 0.0125\n",
      "Epoch [1537/20000], Loss: 619.3817749023438, Entropy -504.3892822265625, Learning Rate: 0.0125\n",
      "Epoch [1538/20000], Loss: 625.8161010742188, Entropy -505.44952392578125, Learning Rate: 0.0125\n",
      "Epoch [1539/20000], Loss: 620.952880859375, Entropy -508.982421875, Learning Rate: 0.0125\n",
      "Epoch [1540/20000], Loss: 630.0413208007812, Entropy -499.7271728515625, Learning Rate: 0.0125\n",
      "Epoch [1541/20000], Loss: 621.7046508789062, Entropy -505.715087890625, Learning Rate: 0.0125\n",
      "Epoch [1542/20000], Loss: 616.6156616210938, Entropy -490.888916015625, Learning Rate: 0.0125\n",
      "Epoch [1543/20000], Loss: 630.0702514648438, Entropy -506.0486755371094, Learning Rate: 0.0125\n",
      "Epoch [1544/20000], Loss: 629.3925170898438, Entropy -519.2332763671875, Learning Rate: 0.0125\n",
      "Epoch [1545/20000], Loss: 618.9401245117188, Entropy -506.52532958984375, Learning Rate: 0.0125\n",
      "Epoch [1546/20000], Loss: 636.0734252929688, Entropy -530.8334350585938, Learning Rate: 0.0125\n",
      "Epoch [1547/20000], Loss: 611.9598388671875, Entropy -495.09515380859375, Learning Rate: 0.0125\n",
      "Epoch [1548/20000], Loss: 607.13037109375, Entropy -496.7076416015625, Learning Rate: 0.0125\n",
      "Epoch [1549/20000], Loss: 614.4613037109375, Entropy -501.95025634765625, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1550/20000], Loss: 617.7460327148438, Entropy -497.633544921875, Learning Rate: 0.0125\n",
      "Epoch [1551/20000], Loss: 656.232177734375, Entropy -535.2235107421875, Learning Rate: 0.0125\n",
      "Epoch [1552/20000], Loss: 637.348388671875, Entropy -503.86181640625, Learning Rate: 0.0125\n",
      "Epoch [1553/20000], Loss: 614.1669921875, Entropy -507.0655517578125, Learning Rate: 0.0125\n",
      "Epoch [1554/20000], Loss: 669.4287109375, Entropy -511.44384765625, Learning Rate: 0.0125\n",
      "Epoch [1555/20000], Loss: 628.0386962890625, Entropy -493.956787109375, Learning Rate: 0.0125\n",
      "Epoch [1556/20000], Loss: 627.30224609375, Entropy -503.2073974609375, Learning Rate: 0.0125\n",
      "Epoch [1557/20000], Loss: 656.7916870117188, Entropy -532.02587890625, Learning Rate: 0.0125\n",
      "Epoch [1558/20000], Loss: 633.6116943359375, Entropy -503.73626708984375, Learning Rate: 0.0125\n",
      "Epoch [1559/20000], Loss: 653.5537109375, Entropy -534.88525390625, Learning Rate: 0.0125\n",
      "Epoch [1560/20000], Loss: 695.579345703125, Entropy -517.6533813476562, Learning Rate: 0.0125\n",
      "Epoch [1561/20000], Loss: 631.650390625, Entropy -508.551025390625, Learning Rate: 0.0125\n",
      "Epoch [1562/20000], Loss: 662.58740234375, Entropy -512.244384765625, Learning Rate: 0.0125\n",
      "Epoch [1563/20000], Loss: 627.696533203125, Entropy -511.2119140625, Learning Rate: 0.0125\n",
      "Epoch [1564/20000], Loss: 631.3387451171875, Entropy -510.35101318359375, Learning Rate: 0.0125\n",
      "Epoch [1565/20000], Loss: 645.2293701171875, Entropy -523.4451904296875, Learning Rate: 0.0125\n",
      "Epoch [1566/20000], Loss: 652.64794921875, Entropy -528.966064453125, Learning Rate: 0.0125\n",
      "Epoch [1567/20000], Loss: 630.7352294921875, Entropy -501.602783203125, Learning Rate: 0.0125\n",
      "Epoch [1568/20000], Loss: 659.4208984375, Entropy -508.8567199707031, Learning Rate: 0.0125\n",
      "Epoch [1569/20000], Loss: 659.08642578125, Entropy -525.5928955078125, Learning Rate: 0.0125\n",
      "Epoch [1570/20000], Loss: 619.8350830078125, Entropy -498.55853271484375, Learning Rate: 0.0125\n",
      "Epoch [1571/20000], Loss: 640.8855590820312, Entropy -519.5975952148438, Learning Rate: 0.0125\n",
      "Epoch [1572/20000], Loss: 610.744384765625, Entropy -500.5067138671875, Learning Rate: 0.0125\n",
      "Epoch [1573/20000], Loss: 636.970703125, Entropy -515.6533203125, Learning Rate: 0.0125\n",
      "Epoch [1574/20000], Loss: 623.7875366210938, Entropy -501.671630859375, Learning Rate: 0.0125\n",
      "Epoch [1575/20000], Loss: 617.4390258789062, Entropy -503.8367919921875, Learning Rate: 0.0125\n",
      "Epoch [1576/20000], Loss: 637.6380615234375, Entropy -519.5325317382812, Learning Rate: 0.0125\n",
      "Epoch [1577/20000], Loss: 627.955078125, Entropy -496.1043395996094, Learning Rate: 0.0125\n",
      "Epoch [1578/20000], Loss: 635.2337646484375, Entropy -516.5849609375, Learning Rate: 0.0125\n",
      "Epoch [1579/20000], Loss: 637.482666015625, Entropy -521.8768920898438, Learning Rate: 0.0125\n",
      "Epoch [1580/20000], Loss: 631.8493041992188, Entropy -495.20013427734375, Learning Rate: 0.0125\n",
      "Epoch [1581/20000], Loss: 614.3646240234375, Entropy -494.6304931640625, Learning Rate: 0.0125\n",
      "Epoch [1582/20000], Loss: 644.3597412109375, Entropy -506.61181640625, Learning Rate: 0.0125\n",
      "Epoch [1583/20000], Loss: 626.6268310546875, Entropy -492.79913330078125, Learning Rate: 0.0125\n",
      "Epoch [1584/20000], Loss: 643.1181030273438, Entropy -508.42132568359375, Learning Rate: 0.0125\n",
      "Epoch [1585/20000], Loss: 649.1326904296875, Entropy -523.8890380859375, Learning Rate: 0.0125\n",
      "Epoch [1586/20000], Loss: 654.8350219726562, Entropy -513.1649780273438, Learning Rate: 0.0125\n",
      "Epoch [1587/20000], Loss: 626.233642578125, Entropy -514.7588500976562, Learning Rate: 0.0125\n",
      "Epoch [1588/20000], Loss: 629.203857421875, Entropy -524.4415283203125, Learning Rate: 0.0125\n",
      "Epoch [1589/20000], Loss: 625.610595703125, Entropy -505.201904296875, Learning Rate: 0.0125\n",
      "Epoch [1590/20000], Loss: 636.2861328125, Entropy -526.1358642578125, Learning Rate: 0.0125\n",
      "Epoch [1591/20000], Loss: 633.8264770507812, Entropy -511.42156982421875, Learning Rate: 0.0125\n",
      "Epoch [1592/20000], Loss: 629.4881591796875, Entropy -506.5880432128906, Learning Rate: 0.0125\n",
      "Epoch [1593/20000], Loss: 651.2318115234375, Entropy -545.120361328125, Learning Rate: 0.0125\n",
      "Epoch [1594/20000], Loss: 626.7806396484375, Entropy -496.55718994140625, Learning Rate: 0.0125\n",
      "Epoch [1595/20000], Loss: 621.200439453125, Entropy -513.0466918945312, Learning Rate: 0.0125\n",
      "Epoch [1596/20000], Loss: 666.1614990234375, Entropy -528.7337036132812, Learning Rate: 0.0125\n",
      "Epoch [1597/20000], Loss: 657.7505493164062, Entropy -525.9490966796875, Learning Rate: 0.0125\n",
      "Epoch [1598/20000], Loss: 618.121337890625, Entropy -510.510986328125, Learning Rate: 0.0125\n",
      "Epoch [1599/20000], Loss: 654.2765502929688, Entropy -505.6131591796875, Learning Rate: 0.0125\n",
      "Epoch [1600/20000], Loss: 617.6141967773438, Entropy -501.33563232421875, Learning Rate: 0.0125\n",
      "Epoch [1601/20000], Loss: 629.101806640625, Entropy -505.31427001953125, Learning Rate: 0.0125\n",
      "Epoch [1602/20000], Loss: 643.1546630859375, Entropy -487.91986083984375, Learning Rate: 0.0125\n",
      "Epoch [1603/20000], Loss: 614.3333740234375, Entropy -493.383056640625, Learning Rate: 0.0125\n",
      "Epoch [1604/20000], Loss: 617.4821166992188, Entropy -504.1043395996094, Learning Rate: 0.0125\n",
      "Epoch [1605/20000], Loss: 633.5192260742188, Entropy -510.0323791503906, Learning Rate: 0.0125\n",
      "Epoch [1606/20000], Loss: 622.4423217773438, Entropy -501.86712646484375, Learning Rate: 0.0125\n",
      "Epoch [1607/20000], Loss: 643.313720703125, Entropy -518.8484497070312, Learning Rate: 0.0125\n",
      "Epoch [1608/20000], Loss: 631.3216552734375, Entropy -494.1962890625, Learning Rate: 0.0125\n",
      "Epoch [1609/20000], Loss: 634.2396850585938, Entropy -507.7066955566406, Learning Rate: 0.0125\n",
      "Epoch [1610/20000], Loss: 667.8881225585938, Entropy -543.327880859375, Learning Rate: 0.0125\n",
      "Epoch [1611/20000], Loss: 642.375732421875, Entropy -488.8957824707031, Learning Rate: 0.0125\n",
      "Epoch [1612/20000], Loss: 625.4569091796875, Entropy -486.53472900390625, Learning Rate: 0.0125\n",
      "Epoch [1613/20000], Loss: 626.548828125, Entropy -492.2632141113281, Learning Rate: 0.0125\n",
      "Epoch [1614/20000], Loss: 672.504150390625, Entropy -503.8560791015625, Learning Rate: 0.0125\n",
      "Epoch [1615/20000], Loss: 655.2350463867188, Entropy -515.904052734375, Learning Rate: 0.0125\n",
      "Epoch [1616/20000], Loss: 654.3811645507812, Entropy -537.8947143554688, Learning Rate: 0.0125\n",
      "Epoch [1617/20000], Loss: 667.3739013671875, Entropy -509.0643310546875, Learning Rate: 0.0125\n",
      "Epoch [1618/20000], Loss: 631.0523071289062, Entropy -508.52520751953125, Learning Rate: 0.0125\n",
      "Epoch [1619/20000], Loss: 640.1396484375, Entropy -511.27587890625, Learning Rate: 0.0125\n",
      "Epoch [1620/20000], Loss: 643.61669921875, Entropy -504.45074462890625, Learning Rate: 0.0125\n",
      "Epoch [1621/20000], Loss: 640.0418090820312, Entropy -526.3627319335938, Learning Rate: 0.0125\n",
      "Epoch [1622/20000], Loss: 640.5416259765625, Entropy -521.5045776367188, Learning Rate: 0.0125\n",
      "Epoch [1623/20000], Loss: 629.5587768554688, Entropy -497.1145935058594, Learning Rate: 0.0125\n",
      "Epoch [1624/20000], Loss: 636.544677734375, Entropy -518.687744140625, Learning Rate: 0.0125\n",
      "Epoch [1625/20000], Loss: 635.927001953125, Entropy -500.83795166015625, Learning Rate: 0.0125\n",
      "Epoch [1626/20000], Loss: 647.8770751953125, Entropy -509.7455139160156, Learning Rate: 0.0125\n",
      "Epoch [1627/20000], Loss: 625.1319580078125, Entropy -501.65484619140625, Learning Rate: 0.0125\n",
      "Epoch [1628/20000], Loss: 641.97412109375, Entropy -514.2491455078125, Learning Rate: 0.0125\n",
      "Epoch [1629/20000], Loss: 628.6067504882812, Entropy -497.52520751953125, Learning Rate: 0.0125\n",
      "Epoch [1630/20000], Loss: 613.2318725585938, Entropy -507.99078369140625, Learning Rate: 0.0125\n",
      "Epoch [1631/20000], Loss: 634.2715454101562, Entropy -511.3905334472656, Learning Rate: 0.0125\n",
      "Epoch [1632/20000], Loss: 653.617431640625, Entropy -510.3304443359375, Learning Rate: 0.0125\n",
      "Epoch [1633/20000], Loss: 646.4459838867188, Entropy -509.9670104980469, Learning Rate: 0.0125\n",
      "Epoch [1634/20000], Loss: 627.8982543945312, Entropy -512.0249633789062, Learning Rate: 0.0125\n",
      "Epoch [1635/20000], Loss: 644.3952026367188, Entropy -513.1568603515625, Learning Rate: 0.0125\n",
      "Epoch [1636/20000], Loss: 609.8626708984375, Entropy -491.2391357421875, Learning Rate: 0.0125\n",
      "Epoch [1637/20000], Loss: 607.6641235351562, Entropy -484.62945556640625, Learning Rate: 0.0125\n",
      "Epoch [1638/20000], Loss: 634.670654296875, Entropy -508.269775390625, Learning Rate: 0.0125\n",
      "Epoch [1639/20000], Loss: 626.5177001953125, Entropy -498.48944091796875, Learning Rate: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1640/20000], Loss: 613.868408203125, Entropy -486.08245849609375, Learning Rate: 0.0125\n",
      "Epoch [1641/20000], Loss: 661.1765747070312, Entropy -524.1134033203125, Learning Rate: 0.0125\n",
      "Epoch [1642/20000], Loss: 649.771484375, Entropy -515.4078369140625, Learning Rate: 0.0125\n",
      "Epoch [1643/20000], Loss: 624.0277709960938, Entropy -495.48046875, Learning Rate: 0.0125\n",
      "Epoch [1644/20000], Loss: 621.267333984375, Entropy -497.7792663574219, Learning Rate: 0.0125\n",
      "Epoch [1645/20000], Loss: 626.1472778320312, Entropy -504.3415222167969, Learning Rate: 0.0125\n",
      "Epoch [1646/20000], Loss: 624.952880859375, Entropy -497.03802490234375, Learning Rate: 0.0125\n",
      "Epoch [1647/20000], Loss: 643.1739501953125, Entropy -506.997802734375, Learning Rate: 0.0125\n",
      "Epoch [1648/20000], Loss: 637.3779907226562, Entropy -517.658447265625, Learning Rate: 0.0125\n",
      "Epoch [1649/20000], Loss: 657.8844604492188, Entropy -501.6224365234375, Learning Rate: 0.0125\n",
      "Epoch [1650/20000], Loss: 636.9610595703125, Entropy -519.1771850585938, Learning Rate: 0.00625\n",
      "Epoch [1651/20000], Loss: 615.0458984375, Entropy -491.8497619628906, Learning Rate: 0.00625\n",
      "Epoch [1652/20000], Loss: 621.0706176757812, Entropy -494.51788330078125, Learning Rate: 0.00625\n",
      "Epoch [1653/20000], Loss: 631.8145751953125, Entropy -505.6617736816406, Learning Rate: 0.00625\n",
      "Epoch [1654/20000], Loss: 634.5693359375, Entropy -504.03173828125, Learning Rate: 0.00625\n",
      "Epoch [1655/20000], Loss: 637.1747436523438, Entropy -496.0044860839844, Learning Rate: 0.00625\n",
      "Epoch [1656/20000], Loss: 623.570068359375, Entropy -505.7977600097656, Learning Rate: 0.00625\n",
      "Epoch [1657/20000], Loss: 614.74560546875, Entropy -495.1417541503906, Learning Rate: 0.00625\n",
      "Epoch [1658/20000], Loss: 617.0220947265625, Entropy -498.74365234375, Learning Rate: 0.00625\n",
      "Epoch [1659/20000], Loss: 633.1036987304688, Entropy -498.6238708496094, Learning Rate: 0.00625\n",
      "Epoch [1660/20000], Loss: 632.8179931640625, Entropy -514.0817260742188, Learning Rate: 0.00625\n",
      "Epoch [1661/20000], Loss: 610.621826171875, Entropy -507.4344787597656, Learning Rate: 0.00625\n",
      "Epoch [1662/20000], Loss: 600.760009765625, Entropy -487.0802001953125, Learning Rate: 0.00625\n",
      "Epoch [1663/20000], Loss: 619.40869140625, Entropy -502.1111755371094, Learning Rate: 0.00625\n",
      "Epoch [1664/20000], Loss: 610.1634521484375, Entropy -511.52923583984375, Learning Rate: 0.00625\n",
      "Epoch [1665/20000], Loss: 636.0236206054688, Entropy -523.145263671875, Learning Rate: 0.00625\n",
      "Epoch [1666/20000], Loss: 618.5692138671875, Entropy -509.8169250488281, Learning Rate: 0.00625\n",
      "Epoch [1667/20000], Loss: 614.9918212890625, Entropy -488.84918212890625, Learning Rate: 0.00625\n",
      "Epoch [1668/20000], Loss: 618.5728759765625, Entropy -513.8753662109375, Learning Rate: 0.00625\n",
      "Epoch [1669/20000], Loss: 633.5662841796875, Entropy -517.68212890625, Learning Rate: 0.00625\n",
      "Epoch [1670/20000], Loss: 629.7958374023438, Entropy -516.2926025390625, Learning Rate: 0.00625\n",
      "Epoch [1671/20000], Loss: 653.879150390625, Entropy -522.3218994140625, Learning Rate: 0.00625\n",
      "Epoch [1672/20000], Loss: 630.7757568359375, Entropy -523.0892944335938, Learning Rate: 0.00625\n",
      "Epoch [1673/20000], Loss: 602.0906982421875, Entropy -504.20587158203125, Learning Rate: 0.00625\n",
      "Epoch [1674/20000], Loss: 617.5537719726562, Entropy -503.94683837890625, Learning Rate: 0.00625\n",
      "Epoch [1675/20000], Loss: 588.3801879882812, Entropy -482.3912658691406, Learning Rate: 0.00625\n",
      "Epoch [1676/20000], Loss: 587.4236450195312, Entropy -486.38873291015625, Learning Rate: 0.00625\n",
      "Epoch [1677/20000], Loss: 601.1093139648438, Entropy -489.9274597167969, Learning Rate: 0.00625\n",
      "Epoch [1678/20000], Loss: 606.6661376953125, Entropy -494.181884765625, Learning Rate: 0.00625\n",
      "Epoch [1679/20000], Loss: 614.407958984375, Entropy -506.1680603027344, Learning Rate: 0.00625\n",
      "Epoch [1680/20000], Loss: 597.0843505859375, Entropy -488.7267761230469, Learning Rate: 0.00625\n",
      "Epoch [1681/20000], Loss: 620.6592407226562, Entropy -502.4552917480469, Learning Rate: 0.00625\n",
      "Epoch [1682/20000], Loss: 624.4637451171875, Entropy -523.4327392578125, Learning Rate: 0.00625\n",
      "Epoch [1683/20000], Loss: 593.18212890625, Entropy -488.7933349609375, Learning Rate: 0.00625\n",
      "Epoch [1684/20000], Loss: 596.6738891601562, Entropy -482.24615478515625, Learning Rate: 0.00625\n",
      "Epoch [1685/20000], Loss: 600.9940795898438, Entropy -503.2506103515625, Learning Rate: 0.00625\n",
      "Epoch [1686/20000], Loss: 605.702880859375, Entropy -497.48779296875, Learning Rate: 0.00625\n",
      "Epoch [1687/20000], Loss: 613.2011108398438, Entropy -492.6273193359375, Learning Rate: 0.00625\n",
      "Epoch [1688/20000], Loss: 606.2025756835938, Entropy -489.6402587890625, Learning Rate: 0.00625\n",
      "Epoch [1689/20000], Loss: 609.59521484375, Entropy -498.37841796875, Learning Rate: 0.00625\n",
      "Epoch [1690/20000], Loss: 612.2431640625, Entropy -512.2838745117188, Learning Rate: 0.00625\n",
      "Epoch [1691/20000], Loss: 622.2564697265625, Entropy -512.5902099609375, Learning Rate: 0.00625\n",
      "Epoch [1692/20000], Loss: 616.541259765625, Entropy -509.60699462890625, Learning Rate: 0.00625\n",
      "Epoch [1693/20000], Loss: 596.6773681640625, Entropy -490.890380859375, Learning Rate: 0.00625\n",
      "Epoch [1694/20000], Loss: 606.45361328125, Entropy -488.23193359375, Learning Rate: 0.00625\n",
      "Epoch [1695/20000], Loss: 605.2271118164062, Entropy -484.951904296875, Learning Rate: 0.00625\n",
      "Epoch [1696/20000], Loss: 618.2252197265625, Entropy -510.51666259765625, Learning Rate: 0.00625\n",
      "Epoch [1697/20000], Loss: 611.822998046875, Entropy -509.3075866699219, Learning Rate: 0.00625\n",
      "Epoch [1698/20000], Loss: 611.8565063476562, Entropy -494.3761291503906, Learning Rate: 0.00625\n",
      "Epoch [1699/20000], Loss: 589.845947265625, Entropy -478.76837158203125, Learning Rate: 0.00625\n",
      "Epoch [1700/20000], Loss: 616.592041015625, Entropy -499.79046630859375, Learning Rate: 0.00625\n",
      "Epoch [1701/20000], Loss: 606.9608764648438, Entropy -492.5215148925781, Learning Rate: 0.00625\n",
      "Epoch [1702/20000], Loss: 620.0323486328125, Entropy -512.531494140625, Learning Rate: 0.00625\n",
      "Epoch [1703/20000], Loss: 607.2125854492188, Entropy -487.2033386230469, Learning Rate: 0.00625\n",
      "Epoch [1704/20000], Loss: 599.8965454101562, Entropy -494.49420166015625, Learning Rate: 0.00625\n",
      "Epoch [1705/20000], Loss: 633.9359130859375, Entropy -523.30908203125, Learning Rate: 0.00625\n",
      "Epoch [1706/20000], Loss: 596.2221069335938, Entropy -478.0122375488281, Learning Rate: 0.00625\n",
      "Epoch [1707/20000], Loss: 608.609619140625, Entropy -502.0280456542969, Learning Rate: 0.00625\n",
      "Epoch [1708/20000], Loss: 603.5599365234375, Entropy -497.74298095703125, Learning Rate: 0.00625\n",
      "Epoch [1709/20000], Loss: 607.6451416015625, Entropy -507.29248046875, Learning Rate: 0.00625\n",
      "Epoch [1710/20000], Loss: 579.434326171875, Entropy -479.73492431640625, Learning Rate: 0.00625\n",
      "Epoch [1711/20000], Loss: 619.903076171875, Entropy -526.1590576171875, Learning Rate: 0.00625\n",
      "Epoch [1712/20000], Loss: 598.0158081054688, Entropy -491.7861328125, Learning Rate: 0.00625\n",
      "Epoch [1713/20000], Loss: 630.246826171875, Entropy -489.3099365234375, Learning Rate: 0.00625\n",
      "Epoch [1714/20000], Loss: 599.02392578125, Entropy -478.19427490234375, Learning Rate: 0.00625\n",
      "Epoch [1715/20000], Loss: 624.7195434570312, Entropy -499.8363037109375, Learning Rate: 0.00625\n",
      "Epoch [1716/20000], Loss: 599.8624877929688, Entropy -495.90533447265625, Learning Rate: 0.00625\n",
      "Epoch [1717/20000], Loss: 630.6715087890625, Entropy -525.8179321289062, Learning Rate: 0.00625\n",
      "Epoch [1718/20000], Loss: 593.475830078125, Entropy -491.2698974609375, Learning Rate: 0.00625\n",
      "Epoch [1719/20000], Loss: 601.5579223632812, Entropy -506.00506591796875, Learning Rate: 0.00625\n",
      "Epoch [1720/20000], Loss: 612.124267578125, Entropy -502.0353698730469, Learning Rate: 0.00625\n",
      "Epoch [1721/20000], Loss: 618.968017578125, Entropy -514.0311889648438, Learning Rate: 0.00625\n",
      "Epoch [1722/20000], Loss: 615.587890625, Entropy -516.8270263671875, Learning Rate: 0.00625\n",
      "Epoch [1723/20000], Loss: 605.458251953125, Entropy -497.3504333496094, Learning Rate: 0.00625\n",
      "Epoch [1724/20000], Loss: 608.3309326171875, Entropy -496.574462890625, Learning Rate: 0.00625\n",
      "Epoch [1725/20000], Loss: 607.674072265625, Entropy -500.2022399902344, Learning Rate: 0.00625\n",
      "Epoch [1726/20000], Loss: 613.795654296875, Entropy -504.18780517578125, Learning Rate: 0.00625\n",
      "Epoch [1727/20000], Loss: 604.947998046875, Entropy -504.677734375, Learning Rate: 0.00625\n",
      "Epoch [1728/20000], Loss: 610.9609985351562, Entropy -490.5335693359375, Learning Rate: 0.00625\n",
      "Epoch [1729/20000], Loss: 618.0252685546875, Entropy -506.4212951660156, Learning Rate: 0.00625\n",
      "Epoch [1730/20000], Loss: 597.50537109375, Entropy -485.3609619140625, Learning Rate: 0.00625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1731/20000], Loss: 614.4827270507812, Entropy -513.5467529296875, Learning Rate: 0.00625\n",
      "Epoch [1732/20000], Loss: 619.0569458007812, Entropy -509.1435546875, Learning Rate: 0.00625\n",
      "Epoch [1733/20000], Loss: 619.1218872070312, Entropy -504.53839111328125, Learning Rate: 0.00625\n",
      "Epoch [1734/20000], Loss: 599.482177734375, Entropy -495.74310302734375, Learning Rate: 0.00625\n",
      "Epoch [1735/20000], Loss: 610.7009887695312, Entropy -498.01666259765625, Learning Rate: 0.00625\n",
      "Epoch [1736/20000], Loss: 594.7669677734375, Entropy -489.3381042480469, Learning Rate: 0.00625\n",
      "Epoch [1737/20000], Loss: 604.0843505859375, Entropy -491.3780212402344, Learning Rate: 0.00625\n",
      "Epoch [1738/20000], Loss: 608.7401733398438, Entropy -504.1002197265625, Learning Rate: 0.00625\n",
      "Epoch [1739/20000], Loss: 613.9951171875, Entropy -497.24395751953125, Learning Rate: 0.00625\n",
      "Epoch [1740/20000], Loss: 626.085205078125, Entropy -515.9542236328125, Learning Rate: 0.00625\n",
      "Epoch [1741/20000], Loss: 621.5325927734375, Entropy -517.7310180664062, Learning Rate: 0.00625\n",
      "Epoch [1742/20000], Loss: 616.43798828125, Entropy -511.502685546875, Learning Rate: 0.00625\n",
      "Epoch [1743/20000], Loss: 629.803466796875, Entropy -519.6840209960938, Learning Rate: 0.00625\n",
      "Epoch [1744/20000], Loss: 607.9779052734375, Entropy -505.78472900390625, Learning Rate: 0.00625\n",
      "Epoch [1745/20000], Loss: 619.0751953125, Entropy -519.9396362304688, Learning Rate: 0.00625\n",
      "Epoch [1746/20000], Loss: 607.0154418945312, Entropy -499.90228271484375, Learning Rate: 0.00625\n",
      "Epoch [1747/20000], Loss: 615.7884521484375, Entropy -496.9368591308594, Learning Rate: 0.00625\n",
      "Epoch [1748/20000], Loss: 598.8673706054688, Entropy -498.4217529296875, Learning Rate: 0.00625\n",
      "Epoch [1749/20000], Loss: 605.9307861328125, Entropy -503.4754638671875, Learning Rate: 0.00625\n",
      "Epoch [1750/20000], Loss: 591.93017578125, Entropy -488.86492919921875, Learning Rate: 0.00625\n",
      "Epoch [1751/20000], Loss: 619.9684448242188, Entropy -504.3270263671875, Learning Rate: 0.00625\n",
      "Epoch [1752/20000], Loss: 608.8115844726562, Entropy -512.9083251953125, Learning Rate: 0.00625\n",
      "Epoch [1753/20000], Loss: 610.419921875, Entropy -511.974609375, Learning Rate: 0.00625\n",
      "Epoch [1754/20000], Loss: 593.1929321289062, Entropy -484.0384521484375, Learning Rate: 0.00625\n",
      "Epoch [1755/20000], Loss: 606.418701171875, Entropy -495.4356689453125, Learning Rate: 0.00625\n",
      "Epoch [1756/20000], Loss: 605.915283203125, Entropy -504.2234191894531, Learning Rate: 0.00625\n",
      "Epoch [1757/20000], Loss: 634.5571899414062, Entropy -501.9660339355469, Learning Rate: 0.00625\n",
      "Epoch [1758/20000], Loss: 632.724365234375, Entropy -514.1572875976562, Learning Rate: 0.00625\n",
      "Epoch [1759/20000], Loss: 598.335693359375, Entropy -492.2335205078125, Learning Rate: 0.00625\n",
      "Epoch [1760/20000], Loss: 612.2791137695312, Entropy -513.48876953125, Learning Rate: 0.00625\n",
      "Epoch [1761/20000], Loss: 598.7149658203125, Entropy -483.50811767578125, Learning Rate: 0.00625\n",
      "Epoch [1762/20000], Loss: 602.467041015625, Entropy -494.8994445800781, Learning Rate: 0.00625\n",
      "Epoch [1763/20000], Loss: 619.2066650390625, Entropy -505.984130859375, Learning Rate: 0.00625\n",
      "Epoch [1764/20000], Loss: 598.6295776367188, Entropy -487.0167541503906, Learning Rate: 0.00625\n",
      "Epoch [1765/20000], Loss: 603.4234619140625, Entropy -498.3403015136719, Learning Rate: 0.00625\n",
      "Epoch [1766/20000], Loss: 591.6890258789062, Entropy -488.2746887207031, Learning Rate: 0.00625\n",
      "Epoch [1767/20000], Loss: 619.2224731445312, Entropy -500.908203125, Learning Rate: 0.00625\n",
      "Epoch [1768/20000], Loss: 606.1929931640625, Entropy -493.91455078125, Learning Rate: 0.00625\n",
      "Epoch [1769/20000], Loss: 590.307373046875, Entropy -483.78411865234375, Learning Rate: 0.00625\n",
      "Epoch [1770/20000], Loss: 585.2930908203125, Entropy -485.581298828125, Learning Rate: 0.00625\n",
      "Epoch [1771/20000], Loss: 597.8541259765625, Entropy -486.79925537109375, Learning Rate: 0.00625\n",
      "Epoch [1772/20000], Loss: 612.1381225585938, Entropy -492.9234619140625, Learning Rate: 0.00625\n",
      "Epoch [1773/20000], Loss: 621.5491943359375, Entropy -495.3330078125, Learning Rate: 0.00625\n",
      "Epoch [1774/20000], Loss: 606.9602661132812, Entropy -501.04693603515625, Learning Rate: 0.00625\n",
      "Epoch [1775/20000], Loss: 612.946533203125, Entropy -497.2087707519531, Learning Rate: 0.00625\n",
      "Epoch [1776/20000], Loss: 601.1173095703125, Entropy -496.7021484375, Learning Rate: 0.00625\n",
      "Epoch [1777/20000], Loss: 607.3657836914062, Entropy -504.47857666015625, Learning Rate: 0.00625\n",
      "Epoch [1778/20000], Loss: 622.692138671875, Entropy -519.1353759765625, Learning Rate: 0.00625\n",
      "Epoch [1779/20000], Loss: 611.481201171875, Entropy -502.4598083496094, Learning Rate: 0.00625\n",
      "Epoch [1780/20000], Loss: 614.9959716796875, Entropy -497.61724853515625, Learning Rate: 0.00625\n",
      "Epoch [1781/20000], Loss: 588.0826416015625, Entropy -476.6881103515625, Learning Rate: 0.00625\n",
      "Epoch [1782/20000], Loss: 623.6804809570312, Entropy -511.63800048828125, Learning Rate: 0.00625\n",
      "Epoch [1783/20000], Loss: 603.86669921875, Entropy -496.54931640625, Learning Rate: 0.00625\n",
      "Epoch [1784/20000], Loss: 613.64013671875, Entropy -502.6654052734375, Learning Rate: 0.00625\n",
      "Epoch [1785/20000], Loss: 593.3590087890625, Entropy -487.863037109375, Learning Rate: 0.00625\n",
      "Epoch [1786/20000], Loss: 604.6580810546875, Entropy -492.7345275878906, Learning Rate: 0.00625\n",
      "Epoch [1787/20000], Loss: 646.0228271484375, Entropy -484.7764892578125, Learning Rate: 0.00625\n",
      "Epoch [1788/20000], Loss: 603.6419677734375, Entropy -503.8641662597656, Learning Rate: 0.00625\n",
      "Epoch [1789/20000], Loss: 613.7530517578125, Entropy -504.0718994140625, Learning Rate: 0.00625\n",
      "Epoch [1790/20000], Loss: 604.9219970703125, Entropy -494.6723937988281, Learning Rate: 0.00625\n",
      "Epoch [1791/20000], Loss: 619.268798828125, Entropy -509.58660888671875, Learning Rate: 0.00625\n",
      "Epoch [1792/20000], Loss: 619.650390625, Entropy -519.3832397460938, Learning Rate: 0.00625\n",
      "Epoch [1793/20000], Loss: 608.84228515625, Entropy -504.9970397949219, Learning Rate: 0.00625\n",
      "Epoch [1794/20000], Loss: 612.6307983398438, Entropy -509.92486572265625, Learning Rate: 0.00625\n",
      "Epoch [1795/20000], Loss: 592.1488647460938, Entropy -469.17657470703125, Learning Rate: 0.00625\n",
      "Epoch [1796/20000], Loss: 611.213623046875, Entropy -496.2037658691406, Learning Rate: 0.00625\n",
      "Epoch [1797/20000], Loss: 592.52587890625, Entropy -483.8297119140625, Learning Rate: 0.00625\n",
      "Epoch [1798/20000], Loss: 605.6909790039062, Entropy -495.5112609863281, Learning Rate: 0.00625\n",
      "Epoch [1799/20000], Loss: 615.5939331054688, Entropy -512.60888671875, Learning Rate: 0.00625\n",
      "Epoch [1800/20000], Loss: 597.2701416015625, Entropy -491.4498291015625, Learning Rate: 0.00625\n",
      "Epoch [1801/20000], Loss: 598.7967529296875, Entropy -496.19427490234375, Learning Rate: 0.00625\n",
      "Epoch [1802/20000], Loss: 590.9075927734375, Entropy -491.06298828125, Learning Rate: 0.00625\n",
      "Epoch [1803/20000], Loss: 610.190673828125, Entropy -504.5106201171875, Learning Rate: 0.00625\n",
      "Epoch [1804/20000], Loss: 588.7470703125, Entropy -485.7967529296875, Learning Rate: 0.00625\n",
      "Epoch [1805/20000], Loss: 595.2926025390625, Entropy -496.2137451171875, Learning Rate: 0.00625\n",
      "Epoch [1806/20000], Loss: 611.180908203125, Entropy -505.53350830078125, Learning Rate: 0.00625\n",
      "Epoch [1807/20000], Loss: 613.0199584960938, Entropy -505.93939208984375, Learning Rate: 0.00625\n",
      "Epoch [1808/20000], Loss: 600.748291015625, Entropy -495.5980224609375, Learning Rate: 0.00625\n",
      "Epoch [1809/20000], Loss: 615.4708251953125, Entropy -495.2427978515625, Learning Rate: 0.00625\n",
      "Epoch [1810/20000], Loss: 587.6921997070312, Entropy -485.01812744140625, Learning Rate: 0.00625\n",
      "Epoch [1811/20000], Loss: 593.3885498046875, Entropy -491.8775329589844, Learning Rate: 0.00625\n",
      "Epoch [1812/20000], Loss: 597.7864990234375, Entropy -495.0899353027344, Learning Rate: 0.003125\n",
      "Epoch [1813/20000], Loss: 616.1580810546875, Entropy -514.4967041015625, Learning Rate: 0.003125\n",
      "Epoch [1814/20000], Loss: 612.16259765625, Entropy -508.6170654296875, Learning Rate: 0.003125\n",
      "Epoch [1815/20000], Loss: 617.960693359375, Entropy -501.59033203125, Learning Rate: 0.003125\n",
      "Epoch [1816/20000], Loss: 607.7586669921875, Entropy -493.40338134765625, Learning Rate: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1817/20000], Loss: 603.0432739257812, Entropy -498.7829895019531, Learning Rate: 0.003125\n",
      "Epoch [1818/20000], Loss: 605.029296875, Entropy -493.8631896972656, Learning Rate: 0.003125\n",
      "Epoch [1819/20000], Loss: 604.2030029296875, Entropy -500.7176513671875, Learning Rate: 0.003125\n",
      "Epoch [1820/20000], Loss: 604.7716064453125, Entropy -499.7668762207031, Learning Rate: 0.003125\n",
      "Epoch [1821/20000], Loss: 603.2835693359375, Entropy -504.49212646484375, Learning Rate: 0.003125\n",
      "Epoch [1822/20000], Loss: 586.5860595703125, Entropy -476.1278076171875, Learning Rate: 0.003125\n",
      "Epoch [1823/20000], Loss: 636.3912963867188, Entropy -526.1051025390625, Learning Rate: 0.003125\n",
      "Epoch [1824/20000], Loss: 617.1707763671875, Entropy -506.1015930175781, Learning Rate: 0.003125\n",
      "Epoch [1825/20000], Loss: 628.5675659179688, Entropy -502.12884521484375, Learning Rate: 0.003125\n",
      "Epoch [1826/20000], Loss: 597.0032348632812, Entropy -500.6761779785156, Learning Rate: 0.003125\n",
      "Epoch [1827/20000], Loss: 600.9255981445312, Entropy -491.7829895019531, Learning Rate: 0.003125\n",
      "Epoch [1828/20000], Loss: 593.7293701171875, Entropy -475.44635009765625, Learning Rate: 0.003125\n",
      "Epoch [1829/20000], Loss: 598.906982421875, Entropy -502.3578186035156, Learning Rate: 0.003125\n",
      "Epoch [1830/20000], Loss: 596.77392578125, Entropy -493.4432067871094, Learning Rate: 0.003125\n",
      "Epoch [1831/20000], Loss: 612.5350341796875, Entropy -507.8582763671875, Learning Rate: 0.003125\n",
      "Epoch [1832/20000], Loss: 593.0691528320312, Entropy -487.82177734375, Learning Rate: 0.003125\n",
      "Epoch [1833/20000], Loss: 599.87890625, Entropy -490.65557861328125, Learning Rate: 0.003125\n",
      "Epoch [1834/20000], Loss: 597.1353149414062, Entropy -482.76654052734375, Learning Rate: 0.003125\n",
      "Epoch [1835/20000], Loss: 624.6087646484375, Entropy -504.10577392578125, Learning Rate: 0.003125\n",
      "Epoch [1836/20000], Loss: 589.8314819335938, Entropy -488.64556884765625, Learning Rate: 0.003125\n",
      "Epoch [1837/20000], Loss: 616.5982666015625, Entropy -503.77197265625, Learning Rate: 0.003125\n",
      "Epoch [1838/20000], Loss: 594.58203125, Entropy -484.028564453125, Learning Rate: 0.003125\n",
      "Epoch [1839/20000], Loss: 610.4130859375, Entropy -502.0187683105469, Learning Rate: 0.003125\n",
      "Epoch [1840/20000], Loss: 601.0667724609375, Entropy -485.1585693359375, Learning Rate: 0.003125\n",
      "Epoch [1841/20000], Loss: 608.5996704101562, Entropy -497.96575927734375, Learning Rate: 0.003125\n",
      "Epoch [1842/20000], Loss: 611.6922607421875, Entropy -505.5169677734375, Learning Rate: 0.003125\n",
      "Epoch [1843/20000], Loss: 616.1790161132812, Entropy -519.045166015625, Learning Rate: 0.003125\n",
      "Epoch [1844/20000], Loss: 607.9017944335938, Entropy -496.4478759765625, Learning Rate: 0.003125\n",
      "Epoch [1845/20000], Loss: 588.446533203125, Entropy -483.454833984375, Learning Rate: 0.003125\n",
      "Epoch [1846/20000], Loss: 649.8115234375, Entropy -506.02850341796875, Learning Rate: 0.003125\n",
      "Epoch [1847/20000], Loss: 611.3329467773438, Entropy -506.9137268066406, Learning Rate: 0.003125\n",
      "Epoch [1848/20000], Loss: 615.23095703125, Entropy -486.9637451171875, Learning Rate: 0.003125\n",
      "Epoch [1849/20000], Loss: 621.0738525390625, Entropy -515.3009033203125, Learning Rate: 0.003125\n",
      "Epoch [1850/20000], Loss: 608.0004272460938, Entropy -515.446533203125, Learning Rate: 0.003125\n",
      "Epoch [1851/20000], Loss: 602.1466674804688, Entropy -482.5395812988281, Learning Rate: 0.003125\n",
      "Epoch [1852/20000], Loss: 604.8077392578125, Entropy -500.1394958496094, Learning Rate: 0.003125\n",
      "Epoch [1853/20000], Loss: 590.682861328125, Entropy -490.64300537109375, Learning Rate: 0.003125\n",
      "Epoch [1854/20000], Loss: 591.9846801757812, Entropy -481.3982849121094, Learning Rate: 0.003125\n",
      "Epoch [1855/20000], Loss: 600.6901245117188, Entropy -500.8132019042969, Learning Rate: 0.003125\n",
      "Epoch [1856/20000], Loss: 600.4646606445312, Entropy -503.73187255859375, Learning Rate: 0.003125\n",
      "Epoch [1857/20000], Loss: 647.991943359375, Entropy -515.32763671875, Learning Rate: 0.003125\n",
      "Epoch [1858/20000], Loss: 600.1322021484375, Entropy -492.26788330078125, Learning Rate: 0.003125\n",
      "Epoch [1859/20000], Loss: 612.9627685546875, Entropy -504.90277099609375, Learning Rate: 0.003125\n",
      "Epoch [1860/20000], Loss: 587.9533081054688, Entropy -475.2589111328125, Learning Rate: 0.003125\n",
      "Epoch [1861/20000], Loss: 601.7891845703125, Entropy -499.4707946777344, Learning Rate: 0.003125\n",
      "Epoch [1862/20000], Loss: 594.2103271484375, Entropy -496.5278625488281, Learning Rate: 0.003125\n",
      "Epoch [1863/20000], Loss: 595.1779174804688, Entropy -495.2889404296875, Learning Rate: 0.003125\n",
      "Epoch [1864/20000], Loss: 598.125, Entropy -485.9035949707031, Learning Rate: 0.003125\n",
      "Epoch [1865/20000], Loss: 597.8018798828125, Entropy -488.4595947265625, Learning Rate: 0.003125\n",
      "Epoch [1866/20000], Loss: 598.1029052734375, Entropy -495.1838073730469, Learning Rate: 0.003125\n",
      "Epoch [1867/20000], Loss: 619.623046875, Entropy -513.9830322265625, Learning Rate: 0.003125\n",
      "Epoch [1868/20000], Loss: 610.6104736328125, Entropy -488.0848083496094, Learning Rate: 0.003125\n",
      "Epoch [1869/20000], Loss: 607.5027465820312, Entropy -498.4721374511719, Learning Rate: 0.003125\n",
      "Epoch [1870/20000], Loss: 596.1474609375, Entropy -489.4820251464844, Learning Rate: 0.003125\n",
      "Epoch [1871/20000], Loss: 612.857177734375, Entropy -504.177490234375, Learning Rate: 0.003125\n",
      "Epoch [1872/20000], Loss: 607.8202514648438, Entropy -504.6593017578125, Learning Rate: 0.003125\n",
      "Epoch [1873/20000], Loss: 623.4559326171875, Entropy -513.4368286132812, Learning Rate: 0.003125\n",
      "Epoch [1874/20000], Loss: 604.1563110351562, Entropy -506.54803466796875, Learning Rate: 0.003125\n",
      "Epoch [1875/20000], Loss: 585.9672241210938, Entropy -485.50244140625, Learning Rate: 0.003125\n",
      "Epoch [1876/20000], Loss: 603.8464965820312, Entropy -504.47235107421875, Learning Rate: 0.003125\n",
      "Epoch [1877/20000], Loss: 595.540771484375, Entropy -485.97149658203125, Learning Rate: 0.003125\n",
      "Epoch [1878/20000], Loss: 607.6814575195312, Entropy -506.5008544921875, Learning Rate: 0.003125\n",
      "Epoch [1879/20000], Loss: 619.9581298828125, Entropy -519.8213500976562, Learning Rate: 0.003125\n",
      "Epoch [1880/20000], Loss: 591.728271484375, Entropy -492.631591796875, Learning Rate: 0.003125\n",
      "Epoch [1881/20000], Loss: 604.5725708007812, Entropy -495.8031005859375, Learning Rate: 0.003125\n",
      "Epoch [1882/20000], Loss: 617.4307250976562, Entropy -520.1242065429688, Learning Rate: 0.003125\n",
      "Epoch [1883/20000], Loss: 595.7899169921875, Entropy -485.5523681640625, Learning Rate: 0.003125\n",
      "Epoch [1884/20000], Loss: 607.03564453125, Entropy -506.2496337890625, Learning Rate: 0.003125\n",
      "Epoch [1885/20000], Loss: 609.2182006835938, Entropy -501.4062194824219, Learning Rate: 0.003125\n",
      "Epoch [1886/20000], Loss: 583.1505126953125, Entropy -462.4915466308594, Learning Rate: 0.003125\n",
      "Epoch [1887/20000], Loss: 608.3897705078125, Entropy -503.09149169921875, Learning Rate: 0.003125\n",
      "Epoch [1888/20000], Loss: 593.0592041015625, Entropy -479.9173278808594, Learning Rate: 0.003125\n",
      "Epoch [1889/20000], Loss: 601.94873046875, Entropy -498.9368896484375, Learning Rate: 0.003125\n",
      "Epoch [1890/20000], Loss: 583.76904296875, Entropy -489.5375671386719, Learning Rate: 0.003125\n",
      "Epoch [1891/20000], Loss: 614.2313232421875, Entropy -516.8778686523438, Learning Rate: 0.003125\n",
      "Epoch [1892/20000], Loss: 607.7504272460938, Entropy -507.84832763671875, Learning Rate: 0.003125\n",
      "Epoch [1893/20000], Loss: 615.8203735351562, Entropy -499.30133056640625, Learning Rate: 0.003125\n",
      "Epoch [1894/20000], Loss: 591.1875610351562, Entropy -486.1627502441406, Learning Rate: 0.003125\n",
      "Epoch [1895/20000], Loss: 605.6068115234375, Entropy -496.02227783203125, Learning Rate: 0.003125\n",
      "Epoch [1896/20000], Loss: 597.132080078125, Entropy -488.4686279296875, Learning Rate: 0.003125\n",
      "Epoch [1897/20000], Loss: 613.0610961914062, Entropy -501.0217590332031, Learning Rate: 0.003125\n",
      "Epoch [1898/20000], Loss: 586.114501953125, Entropy -482.9970397949219, Learning Rate: 0.003125\n",
      "Epoch [1899/20000], Loss: 578.7189331054688, Entropy -476.4522705078125, Learning Rate: 0.003125\n",
      "Epoch [1900/20000], Loss: 601.4232177734375, Entropy -493.60369873046875, Learning Rate: 0.003125\n",
      "Epoch [1901/20000], Loss: 610.4840698242188, Entropy -508.61175537109375, Learning Rate: 0.003125\n",
      "Epoch [1902/20000], Loss: 584.2576293945312, Entropy -485.99725341796875, Learning Rate: 0.003125\n",
      "Epoch [1903/20000], Loss: 603.880126953125, Entropy -482.40545654296875, Learning Rate: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1904/20000], Loss: 598.6199951171875, Entropy -506.73199462890625, Learning Rate: 0.003125\n",
      "Epoch [1905/20000], Loss: 593.9019775390625, Entropy -483.3630676269531, Learning Rate: 0.003125\n",
      "Epoch [1906/20000], Loss: 601.8731079101562, Entropy -498.16973876953125, Learning Rate: 0.003125\n",
      "Epoch [1907/20000], Loss: 603.8291625976562, Entropy -499.35784912109375, Learning Rate: 0.003125\n",
      "Epoch [1908/20000], Loss: 608.0104370117188, Entropy -501.49090576171875, Learning Rate: 0.003125\n",
      "Epoch [1909/20000], Loss: 603.2958984375, Entropy -496.7147521972656, Learning Rate: 0.003125\n",
      "Epoch [1910/20000], Loss: 631.4671020507812, Entropy -519.3358154296875, Learning Rate: 0.003125\n",
      "Epoch [1911/20000], Loss: 610.7197875976562, Entropy -500.0961608886719, Learning Rate: 0.003125\n",
      "Epoch [1912/20000], Loss: 617.539794921875, Entropy -512.8781127929688, Learning Rate: 0.003125\n",
      "Epoch [1913/20000], Loss: 601.3170776367188, Entropy -494.82440185546875, Learning Rate: 0.003125\n",
      "Epoch [1914/20000], Loss: 593.3189086914062, Entropy -503.184814453125, Learning Rate: 0.003125\n",
      "Epoch [1915/20000], Loss: 606.1776123046875, Entropy -512.6044921875, Learning Rate: 0.003125\n",
      "Epoch [1916/20000], Loss: 605.6268310546875, Entropy -508.30133056640625, Learning Rate: 0.003125\n",
      "Epoch [1917/20000], Loss: 602.758544921875, Entropy -483.4449462890625, Learning Rate: 0.003125\n",
      "Epoch [1918/20000], Loss: 589.242431640625, Entropy -487.82281494140625, Learning Rate: 0.003125\n",
      "Epoch [1919/20000], Loss: 602.5370483398438, Entropy -501.6289978027344, Learning Rate: 0.003125\n",
      "Epoch [1920/20000], Loss: 601.7715454101562, Entropy -490.4931640625, Learning Rate: 0.003125\n",
      "Epoch [1921/20000], Loss: 603.7199096679688, Entropy -505.10504150390625, Learning Rate: 0.003125\n",
      "Epoch [1922/20000], Loss: 595.0716552734375, Entropy -487.5870056152344, Learning Rate: 0.003125\n",
      "Epoch [1923/20000], Loss: 605.5917358398438, Entropy -498.64910888671875, Learning Rate: 0.003125\n",
      "Epoch [1924/20000], Loss: 587.9822998046875, Entropy -476.4248046875, Learning Rate: 0.003125\n",
      "Epoch [1925/20000], Loss: 603.8438110351562, Entropy -495.90509033203125, Learning Rate: 0.003125\n",
      "Epoch [1926/20000], Loss: 614.01904296875, Entropy -504.94097900390625, Learning Rate: 0.003125\n",
      "Epoch [1927/20000], Loss: 617.8927001953125, Entropy -511.25836181640625, Learning Rate: 0.003125\n",
      "Epoch [1928/20000], Loss: 599.4763793945312, Entropy -490.914794921875, Learning Rate: 0.003125\n",
      "Epoch [1929/20000], Loss: 590.1011962890625, Entropy -485.38092041015625, Learning Rate: 0.003125\n",
      "Epoch [1930/20000], Loss: 613.1723022460938, Entropy -511.3556213378906, Learning Rate: 0.003125\n",
      "Epoch [1931/20000], Loss: 610.841796875, Entropy -511.638671875, Learning Rate: 0.003125\n",
      "Epoch [1932/20000], Loss: 583.984619140625, Entropy -491.7057189941406, Learning Rate: 0.003125\n",
      "Epoch [1933/20000], Loss: 617.2155151367188, Entropy -509.7494812011719, Learning Rate: 0.003125\n",
      "Epoch [1934/20000], Loss: 604.815185546875, Entropy -500.15875244140625, Learning Rate: 0.003125\n",
      "Epoch [1935/20000], Loss: 599.4071655273438, Entropy -493.7914733886719, Learning Rate: 0.003125\n",
      "Epoch [1936/20000], Loss: 603.3348388671875, Entropy -498.5840759277344, Learning Rate: 0.003125\n",
      "Epoch [1937/20000], Loss: 603.7119140625, Entropy -507.58087158203125, Learning Rate: 0.003125\n",
      "Epoch [1938/20000], Loss: 609.60009765625, Entropy -489.57452392578125, Learning Rate: 0.003125\n",
      "Epoch [1939/20000], Loss: 597.690673828125, Entropy -500.6753234863281, Learning Rate: 0.003125\n",
      "Epoch [1940/20000], Loss: 594.1795043945312, Entropy -480.0576477050781, Learning Rate: 0.003125\n",
      "Epoch [1941/20000], Loss: 594.7239379882812, Entropy -483.19573974609375, Learning Rate: 0.003125\n",
      "Epoch [1942/20000], Loss: 604.8244018554688, Entropy -495.3800964355469, Learning Rate: 0.003125\n",
      "Epoch [1943/20000], Loss: 591.9569702148438, Entropy -490.684814453125, Learning Rate: 0.003125\n",
      "Epoch [1944/20000], Loss: 599.1737060546875, Entropy -499.61279296875, Learning Rate: 0.003125\n",
      "Epoch [1945/20000], Loss: 617.68798828125, Entropy -514.2298583984375, Learning Rate: 0.003125\n",
      "Epoch [1946/20000], Loss: 611.394287109375, Entropy -503.9239501953125, Learning Rate: 0.003125\n",
      "Epoch [1947/20000], Loss: 613.0924072265625, Entropy -504.3799133300781, Learning Rate: 0.003125\n",
      "Epoch [1948/20000], Loss: 597.4494018554688, Entropy -479.3138427734375, Learning Rate: 0.003125\n",
      "Epoch [1949/20000], Loss: 603.5541381835938, Entropy -497.51666259765625, Learning Rate: 0.003125\n",
      "Epoch [1950/20000], Loss: 597.4819946289062, Entropy -482.7794494628906, Learning Rate: 0.003125\n",
      "Epoch [1951/20000], Loss: 593.6942749023438, Entropy -486.88055419921875, Learning Rate: 0.003125\n",
      "Epoch [1952/20000], Loss: 586.4136352539062, Entropy -471.2784423828125, Learning Rate: 0.003125\n",
      "Epoch [1953/20000], Loss: 598.4808959960938, Entropy -490.1545104980469, Learning Rate: 0.003125\n",
      "Epoch [1954/20000], Loss: 589.2611694335938, Entropy -487.23565673828125, Learning Rate: 0.003125\n",
      "Epoch [1955/20000], Loss: 613.4290161132812, Entropy -505.56146240234375, Learning Rate: 0.003125\n",
      "Epoch [1956/20000], Loss: 603.742431640625, Entropy -492.18975830078125, Learning Rate: 0.003125\n",
      "Epoch [1957/20000], Loss: 591.65283203125, Entropy -496.02239990234375, Learning Rate: 0.003125\n",
      "Epoch [1958/20000], Loss: 603.10791015625, Entropy -502.63958740234375, Learning Rate: 0.003125\n",
      "Epoch [1959/20000], Loss: 607.790771484375, Entropy -502.493408203125, Learning Rate: 0.003125\n",
      "Epoch [1960/20000], Loss: 579.47607421875, Entropy -481.35260009765625, Learning Rate: 0.003125\n",
      "Epoch [1961/20000], Loss: 593.2218017578125, Entropy -482.4881286621094, Learning Rate: 0.003125\n",
      "Epoch [1962/20000], Loss: 592.5155029296875, Entropy -485.41375732421875, Learning Rate: 0.003125\n",
      "Epoch [1963/20000], Loss: 603.9558715820312, Entropy -484.6229248046875, Learning Rate: 0.003125\n",
      "Epoch [1964/20000], Loss: 613.927001953125, Entropy -502.79339599609375, Learning Rate: 0.003125\n",
      "Epoch [1965/20000], Loss: 606.15673828125, Entropy -503.58355712890625, Learning Rate: 0.003125\n",
      "Epoch [1966/20000], Loss: 586.908935546875, Entropy -484.9388122558594, Learning Rate: 0.003125\n",
      "Epoch [1967/20000], Loss: 593.7237548828125, Entropy -481.861572265625, Learning Rate: 0.003125\n",
      "Epoch [1968/20000], Loss: 610.747802734375, Entropy -502.37640380859375, Learning Rate: 0.003125\n",
      "Epoch [1969/20000], Loss: 599.2442626953125, Entropy -498.71435546875, Learning Rate: 0.003125\n",
      "Epoch [1970/20000], Loss: 587.542724609375, Entropy -489.3424377441406, Learning Rate: 0.003125\n",
      "Epoch [1971/20000], Loss: 620.6829833984375, Entropy -501.91961669921875, Learning Rate: 0.003125\n",
      "Epoch [1972/20000], Loss: 590.2192993164062, Entropy -485.8270263671875, Learning Rate: 0.003125\n",
      "Epoch [1973/20000], Loss: 591.726806640625, Entropy -486.54608154296875, Learning Rate: 0.003125\n",
      "Epoch [1974/20000], Loss: 608.7781372070312, Entropy -499.07373046875, Learning Rate: 0.003125\n",
      "Epoch [1975/20000], Loss: 587.238525390625, Entropy -483.90606689453125, Learning Rate: 0.003125\n",
      "Epoch [1976/20000], Loss: 579.0479736328125, Entropy -479.51751708984375, Learning Rate: 0.003125\n",
      "Epoch [1977/20000], Loss: 601.1611938476562, Entropy -505.6905822753906, Learning Rate: 0.003125\n",
      "Epoch [1978/20000], Loss: 651.7940673828125, Entropy -528.6521606445312, Learning Rate: 0.003125\n",
      "Epoch [1979/20000], Loss: 602.594482421875, Entropy -492.847412109375, Learning Rate: 0.003125\n",
      "Epoch [1980/20000], Loss: 625.701416015625, Entropy -523.2471923828125, Learning Rate: 0.003125\n",
      "Epoch [1981/20000], Loss: 614.917724609375, Entropy -495.7115478515625, Learning Rate: 0.003125\n",
      "Epoch [1982/20000], Loss: 601.265380859375, Entropy -481.19964599609375, Learning Rate: 0.003125\n",
      "Epoch [1983/20000], Loss: 609.5018310546875, Entropy -502.0033264160156, Learning Rate: 0.003125\n",
      "Epoch [1984/20000], Loss: 610.9568481445312, Entropy -509.39715576171875, Learning Rate: 0.003125\n",
      "Epoch [1985/20000], Loss: 603.4606323242188, Entropy -485.9895324707031, Learning Rate: 0.003125\n",
      "Epoch [1986/20000], Loss: 618.57275390625, Entropy -509.73602294921875, Learning Rate: 0.003125\n",
      "Epoch [1987/20000], Loss: 608.2703247070312, Entropy -505.91107177734375, Learning Rate: 0.003125\n",
      "Epoch [1988/20000], Loss: 604.474365234375, Entropy -499.859375, Learning Rate: 0.003125\n",
      "Epoch [1989/20000], Loss: 614.5963745117188, Entropy -514.8211669921875, Learning Rate: 0.003125\n",
      "Epoch [1990/20000], Loss: 607.502685546875, Entropy -502.25604248046875, Learning Rate: 0.003125\n",
      "Epoch [1991/20000], Loss: 596.3175048828125, Entropy -484.25634765625, Learning Rate: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1992/20000], Loss: 600.5260620117188, Entropy -501.256591796875, Learning Rate: 0.003125\n",
      "Epoch [1993/20000], Loss: 609.280517578125, Entropy -507.27691650390625, Learning Rate: 0.003125\n",
      "Epoch [1994/20000], Loss: 596.9911499023438, Entropy -496.918212890625, Learning Rate: 0.003125\n",
      "Epoch [1995/20000], Loss: 601.67578125, Entropy -501.5509033203125, Learning Rate: 0.003125\n",
      "Epoch [1996/20000], Loss: 596.9148559570312, Entropy -486.59844970703125, Learning Rate: 0.003125\n",
      "Epoch [1997/20000], Loss: 602.231201171875, Entropy -500.11358642578125, Learning Rate: 0.003125\n",
      "Epoch [1998/20000], Loss: 613.6505126953125, Entropy -517.199951171875, Learning Rate: 0.003125\n",
      "Epoch [1999/20000], Loss: 609.1078491210938, Entropy -507.0863037109375, Learning Rate: 0.003125\n",
      "Epoch [2000/20000], Loss: 589.8876953125, Entropy -478.1832580566406, Learning Rate: 0.003125\n",
      "Epoch [2001/20000], Loss: 590.4262084960938, Entropy -484.4249267578125, Learning Rate: 0.0015625\n",
      "Epoch [2002/20000], Loss: 593.3672485351562, Entropy -492.13861083984375, Learning Rate: 0.0015625\n",
      "Epoch [2003/20000], Loss: 607.3206176757812, Entropy -505.63104248046875, Learning Rate: 0.0015625\n",
      "Epoch [2004/20000], Loss: 594.14306640625, Entropy -487.139892578125, Learning Rate: 0.0015625\n",
      "Epoch [2005/20000], Loss: 601.1881713867188, Entropy -486.0321044921875, Learning Rate: 0.0015625\n",
      "Epoch [2006/20000], Loss: 605.34716796875, Entropy -494.826904296875, Learning Rate: 0.0015625\n",
      "Epoch [2007/20000], Loss: 609.2551879882812, Entropy -508.77801513671875, Learning Rate: 0.0015625\n",
      "Epoch [2008/20000], Loss: 586.13671875, Entropy -482.1066589355469, Learning Rate: 0.0015625\n",
      "Epoch [2009/20000], Loss: 578.1142578125, Entropy -474.105712890625, Learning Rate: 0.0015625\n",
      "Epoch [2010/20000], Loss: 596.8209228515625, Entropy -507.58709716796875, Learning Rate: 0.0015625\n",
      "Epoch [2011/20000], Loss: 603.6536865234375, Entropy -491.3292236328125, Learning Rate: 0.0015625\n",
      "Epoch [2012/20000], Loss: 604.48974609375, Entropy -504.50714111328125, Learning Rate: 0.0015625\n",
      "Epoch [2013/20000], Loss: 586.3024291992188, Entropy -481.3066101074219, Learning Rate: 0.0015625\n",
      "Epoch [2014/20000], Loss: 597.7444458007812, Entropy -496.0051574707031, Learning Rate: 0.0015625\n",
      "Epoch [2015/20000], Loss: 591.3670654296875, Entropy -496.863037109375, Learning Rate: 0.0015625\n",
      "Epoch [2016/20000], Loss: 584.7559814453125, Entropy -482.6767883300781, Learning Rate: 0.0015625\n",
      "Epoch [2017/20000], Loss: 603.3607177734375, Entropy -491.224853515625, Learning Rate: 0.0015625\n",
      "Epoch [2018/20000], Loss: 594.5288696289062, Entropy -481.3616638183594, Learning Rate: 0.0015625\n",
      "Epoch [2019/20000], Loss: 602.1574096679688, Entropy -493.89166259765625, Learning Rate: 0.0015625\n",
      "Epoch [2020/20000], Loss: 610.1790771484375, Entropy -513.8094482421875, Learning Rate: 0.0015625\n",
      "Epoch [2021/20000], Loss: 602.419921875, Entropy -490.95550537109375, Learning Rate: 0.0015625\n",
      "Epoch [2022/20000], Loss: 584.74169921875, Entropy -483.36492919921875, Learning Rate: 0.0015625\n",
      "Epoch [2023/20000], Loss: 587.9552001953125, Entropy -476.46405029296875, Learning Rate: 0.0015625\n",
      "Epoch [2024/20000], Loss: 584.40869140625, Entropy -464.694091796875, Learning Rate: 0.0015625\n",
      "Epoch [2025/20000], Loss: 612.0181274414062, Entropy -479.09954833984375, Learning Rate: 0.0015625\n",
      "Epoch [2026/20000], Loss: 594.5215454101562, Entropy -491.5144958496094, Learning Rate: 0.0015625\n",
      "Epoch [2027/20000], Loss: 592.4517822265625, Entropy -489.2513732910156, Learning Rate: 0.0015625\n",
      "Epoch [2028/20000], Loss: 592.013427734375, Entropy -493.74713134765625, Learning Rate: 0.0015625\n",
      "Epoch [2029/20000], Loss: 593.6453857421875, Entropy -486.98883056640625, Learning Rate: 0.0015625\n",
      "Epoch [2030/20000], Loss: 595.663330078125, Entropy -497.0693359375, Learning Rate: 0.0015625\n",
      "Epoch [2031/20000], Loss: 598.654541015625, Entropy -480.6562805175781, Learning Rate: 0.0015625\n",
      "Epoch [2032/20000], Loss: 607.0888671875, Entropy -499.80047607421875, Learning Rate: 0.0015625\n",
      "Epoch [2033/20000], Loss: 610.65576171875, Entropy -510.8015441894531, Learning Rate: 0.0015625\n",
      "Epoch [2034/20000], Loss: 597.9546508789062, Entropy -484.92138671875, Learning Rate: 0.0015625\n",
      "Epoch [2035/20000], Loss: 599.62890625, Entropy -502.27069091796875, Learning Rate: 0.0015625\n",
      "Epoch [2036/20000], Loss: 600.9304809570312, Entropy -495.42413330078125, Learning Rate: 0.0015625\n",
      "Epoch [2037/20000], Loss: 599.280029296875, Entropy -499.853759765625, Learning Rate: 0.0015625\n",
      "Epoch [2038/20000], Loss: 595.7255859375, Entropy -499.3175964355469, Learning Rate: 0.0015625\n",
      "Epoch [2039/20000], Loss: 597.1353759765625, Entropy -492.173583984375, Learning Rate: 0.0015625\n",
      "Epoch [2040/20000], Loss: 594.233154296875, Entropy -491.37939453125, Learning Rate: 0.0015625\n",
      "Epoch [2041/20000], Loss: 615.207763671875, Entropy -495.8924865722656, Learning Rate: 0.0015625\n",
      "Epoch [2042/20000], Loss: 602.7672119140625, Entropy -497.05975341796875, Learning Rate: 0.0015625\n",
      "Epoch [2043/20000], Loss: 590.6505737304688, Entropy -486.97161865234375, Learning Rate: 0.0015625\n",
      "Epoch [2044/20000], Loss: 614.601318359375, Entropy -512.0410766601562, Learning Rate: 0.0015625\n",
      "Epoch [2045/20000], Loss: 589.7999267578125, Entropy -475.783447265625, Learning Rate: 0.0015625\n",
      "Epoch [2046/20000], Loss: 591.797119140625, Entropy -482.11431884765625, Learning Rate: 0.0015625\n",
      "Epoch [2047/20000], Loss: 584.6431274414062, Entropy -473.94708251953125, Learning Rate: 0.0015625\n",
      "Epoch [2048/20000], Loss: 610.5877075195312, Entropy -514.8089599609375, Learning Rate: 0.0015625\n",
      "Epoch [2049/20000], Loss: 581.1490478515625, Entropy -479.57550048828125, Learning Rate: 0.0015625\n",
      "Epoch [2050/20000], Loss: 588.9494018554688, Entropy -478.02587890625, Learning Rate: 0.0015625\n",
      "Epoch [2051/20000], Loss: 605.2007446289062, Entropy -503.3192138671875, Learning Rate: 0.0015625\n",
      "Epoch [2052/20000], Loss: 594.2775268554688, Entropy -482.56268310546875, Learning Rate: 0.0015625\n",
      "Epoch [2053/20000], Loss: 613.1923828125, Entropy -514.3372802734375, Learning Rate: 0.0015625\n",
      "Epoch [2054/20000], Loss: 600.367431640625, Entropy -496.58123779296875, Learning Rate: 0.0015625\n",
      "Epoch [2055/20000], Loss: 591.916748046875, Entropy -488.55181884765625, Learning Rate: 0.0015625\n",
      "Epoch [2056/20000], Loss: 591.122802734375, Entropy -491.04791259765625, Learning Rate: 0.0015625\n",
      "Epoch [2057/20000], Loss: 604.23828125, Entropy -508.45172119140625, Learning Rate: 0.0015625\n",
      "Epoch [2058/20000], Loss: 587.4995727539062, Entropy -475.82073974609375, Learning Rate: 0.0015625\n",
      "Epoch [2059/20000], Loss: 591.350830078125, Entropy -490.02362060546875, Learning Rate: 0.0015625\n",
      "Epoch [2060/20000], Loss: 599.5125122070312, Entropy -488.0067443847656, Learning Rate: 0.0015625\n",
      "Epoch [2061/20000], Loss: 592.66650390625, Entropy -482.609375, Learning Rate: 0.0015625\n",
      "Epoch [2062/20000], Loss: 585.7841796875, Entropy -471.652099609375, Learning Rate: 0.0015625\n",
      "Epoch [2063/20000], Loss: 618.4152221679688, Entropy -501.26751708984375, Learning Rate: 0.0015625\n",
      "Epoch [2064/20000], Loss: 620.3541870117188, Entropy -520.476806640625, Learning Rate: 0.0015625\n",
      "Epoch [2065/20000], Loss: 600.0486450195312, Entropy -494.41217041015625, Learning Rate: 0.0015625\n",
      "Epoch [2066/20000], Loss: 588.7249755859375, Entropy -481.02099609375, Learning Rate: 0.0015625\n",
      "Epoch [2067/20000], Loss: 605.255615234375, Entropy -515.6766357421875, Learning Rate: 0.0015625\n",
      "Epoch [2068/20000], Loss: 616.4007568359375, Entropy -511.59735107421875, Learning Rate: 0.0015625\n",
      "Epoch [2069/20000], Loss: 587.5623779296875, Entropy -470.27685546875, Learning Rate: 0.0015625\n",
      "Epoch [2070/20000], Loss: 604.5770263671875, Entropy -503.87628173828125, Learning Rate: 0.0015625\n",
      "Epoch [2071/20000], Loss: 607.6641845703125, Entropy -502.4667053222656, Learning Rate: 0.0015625\n",
      "Epoch [2072/20000], Loss: 601.119873046875, Entropy -491.7877197265625, Learning Rate: 0.0015625\n",
      "Epoch [2073/20000], Loss: 600.921630859375, Entropy -495.5196533203125, Learning Rate: 0.0015625\n",
      "Epoch [2074/20000], Loss: 601.6011962890625, Entropy -497.74066162109375, Learning Rate: 0.0015625\n",
      "Epoch [2075/20000], Loss: 608.1824951171875, Entropy -508.7767333984375, Learning Rate: 0.0015625\n",
      "Epoch [2076/20000], Loss: 612.4268798828125, Entropy -514.933349609375, Learning Rate: 0.0015625\n",
      "Epoch [2077/20000], Loss: 581.2102661132812, Entropy -479.80889892578125, Learning Rate: 0.0015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2078/20000], Loss: 595.9552612304688, Entropy -489.9543151855469, Learning Rate: 0.0015625\n",
      "Epoch [2079/20000], Loss: 600.33984375, Entropy -497.91253662109375, Learning Rate: 0.0015625\n",
      "Epoch [2080/20000], Loss: 592.826904296875, Entropy -497.02142333984375, Learning Rate: 0.0015625\n",
      "Epoch [2081/20000], Loss: 575.7904052734375, Entropy -476.951904296875, Learning Rate: 0.0015625\n",
      "Epoch [2082/20000], Loss: 598.4144287109375, Entropy -502.23016357421875, Learning Rate: 0.0015625\n",
      "Epoch [2083/20000], Loss: 590.174072265625, Entropy -478.1948547363281, Learning Rate: 0.0015625\n",
      "Epoch [2084/20000], Loss: 618.0174560546875, Entropy -497.3076171875, Learning Rate: 0.0015625\n",
      "Epoch [2085/20000], Loss: 601.7408447265625, Entropy -472.148193359375, Learning Rate: 0.0015625\n",
      "Epoch [2086/20000], Loss: 602.2686157226562, Entropy -480.4417419433594, Learning Rate: 0.0015625\n",
      "Epoch [2087/20000], Loss: 592.663330078125, Entropy -489.38946533203125, Learning Rate: 0.0015625\n",
      "Epoch [2088/20000], Loss: 615.9259643554688, Entropy -504.169921875, Learning Rate: 0.0015625\n",
      "Epoch [2089/20000], Loss: 599.1480712890625, Entropy -493.572509765625, Learning Rate: 0.0015625\n",
      "Epoch [2090/20000], Loss: 603.9781494140625, Entropy -495.35955810546875, Learning Rate: 0.0015625\n",
      "Epoch [2091/20000], Loss: 583.6431274414062, Entropy -484.8834228515625, Learning Rate: 0.0015625\n",
      "Epoch [2092/20000], Loss: 611.6557006835938, Entropy -508.82720947265625, Learning Rate: 0.0015625\n",
      "Epoch [2093/20000], Loss: 591.0109252929688, Entropy -481.76544189453125, Learning Rate: 0.0015625\n",
      "Epoch [2094/20000], Loss: 596.5159912109375, Entropy -476.195556640625, Learning Rate: 0.0015625\n",
      "Epoch [2095/20000], Loss: 572.96923828125, Entropy -468.93072509765625, Learning Rate: 0.0015625\n",
      "Epoch [2096/20000], Loss: 607.4523315429688, Entropy -502.67022705078125, Learning Rate: 0.0015625\n",
      "Epoch [2097/20000], Loss: 593.414794921875, Entropy -494.74346923828125, Learning Rate: 0.0015625\n",
      "Epoch [2098/20000], Loss: 581.514892578125, Entropy -487.5990905761719, Learning Rate: 0.0015625\n",
      "Epoch [2099/20000], Loss: 581.1461181640625, Entropy -484.58062744140625, Learning Rate: 0.0015625\n",
      "Epoch [2100/20000], Loss: 679.4222412109375, Entropy -504.2444763183594, Learning Rate: 0.0015625\n",
      "Epoch [2101/20000], Loss: 574.8269653320312, Entropy -480.052001953125, Learning Rate: 0.0015625\n",
      "Epoch [2102/20000], Loss: 588.0760498046875, Entropy -483.49151611328125, Learning Rate: 0.0015625\n",
      "Epoch [2103/20000], Loss: 587.0513916015625, Entropy -481.58673095703125, Learning Rate: 0.0015625\n",
      "Epoch [2104/20000], Loss: 599.3781127929688, Entropy -482.19940185546875, Learning Rate: 0.0015625\n",
      "Epoch [2105/20000], Loss: 595.3306274414062, Entropy -489.84954833984375, Learning Rate: 0.0015625\n",
      "Epoch [2106/20000], Loss: 582.1016845703125, Entropy -465.07525634765625, Learning Rate: 0.0015625\n",
      "Epoch [2107/20000], Loss: 588.0663452148438, Entropy -478.85833740234375, Learning Rate: 0.0015625\n",
      "Epoch [2108/20000], Loss: 596.83642578125, Entropy -496.1456604003906, Learning Rate: 0.0015625\n",
      "Epoch [2109/20000], Loss: 583.716064453125, Entropy -481.49267578125, Learning Rate: 0.0015625\n",
      "Epoch [2110/20000], Loss: 602.13037109375, Entropy -505.69842529296875, Learning Rate: 0.0015625\n",
      "Epoch [2111/20000], Loss: 601.2037353515625, Entropy -496.15057373046875, Learning Rate: 0.0015625\n",
      "Epoch [2112/20000], Loss: 591.6932373046875, Entropy -487.94189453125, Learning Rate: 0.0015625\n",
      "Epoch [2113/20000], Loss: 604.5775756835938, Entropy -484.3157958984375, Learning Rate: 0.0015625\n",
      "Epoch [2114/20000], Loss: 596.8440551757812, Entropy -495.65179443359375, Learning Rate: 0.0015625\n",
      "Epoch [2115/20000], Loss: 604.6474609375, Entropy -486.3157958984375, Learning Rate: 0.0015625\n",
      "Epoch [2116/20000], Loss: 606.3680419921875, Entropy -507.7632141113281, Learning Rate: 0.0015625\n",
      "Epoch [2117/20000], Loss: 595.364501953125, Entropy -488.991943359375, Learning Rate: 0.0015625\n",
      "Epoch [2118/20000], Loss: 591.8656005859375, Entropy -487.7235107421875, Learning Rate: 0.0015625\n",
      "Epoch [2119/20000], Loss: 599.958251953125, Entropy -487.529541015625, Learning Rate: 0.0015625\n",
      "Epoch [2120/20000], Loss: 585.2701416015625, Entropy -485.6683654785156, Learning Rate: 0.0015625\n",
      "Epoch [2121/20000], Loss: 577.2188110351562, Entropy -471.3741760253906, Learning Rate: 0.0015625\n",
      "Epoch [2122/20000], Loss: 604.4901123046875, Entropy -483.8936767578125, Learning Rate: 0.0015625\n",
      "Epoch [2123/20000], Loss: 603.710205078125, Entropy -492.20635986328125, Learning Rate: 0.0015625\n",
      "Epoch [2124/20000], Loss: 593.2523193359375, Entropy -493.2322692871094, Learning Rate: 0.0015625\n",
      "Epoch [2125/20000], Loss: 592.240234375, Entropy -492.52056884765625, Learning Rate: 0.0015625\n",
      "Epoch [2126/20000], Loss: 589.138916015625, Entropy -490.27801513671875, Learning Rate: 0.0015625\n",
      "Epoch [2127/20000], Loss: 589.714111328125, Entropy -487.761962890625, Learning Rate: 0.0015625\n",
      "Epoch [2128/20000], Loss: 604.7659301757812, Entropy -498.9142150878906, Learning Rate: 0.0015625\n",
      "Epoch [2129/20000], Loss: 606.1061401367188, Entropy -507.4285888671875, Learning Rate: 0.0015625\n",
      "Epoch [2130/20000], Loss: 594.4388427734375, Entropy -488.99005126953125, Learning Rate: 0.0015625\n",
      "Epoch [2131/20000], Loss: 615.3619384765625, Entropy -509.8077087402344, Learning Rate: 0.0015625\n",
      "Epoch [2132/20000], Loss: 608.5814208984375, Entropy -509.41876220703125, Learning Rate: 0.0015625\n",
      "Epoch [2133/20000], Loss: 600.3705444335938, Entropy -489.8033752441406, Learning Rate: 0.0015625\n",
      "Epoch [2134/20000], Loss: 616.4825439453125, Entropy -496.34173583984375, Learning Rate: 0.0015625\n",
      "Epoch [2135/20000], Loss: 584.3246459960938, Entropy -478.483642578125, Learning Rate: 0.0015625\n",
      "Epoch [2136/20000], Loss: 600.902587890625, Entropy -495.6995544433594, Learning Rate: 0.0015625\n",
      "Epoch [2137/20000], Loss: 604.6092529296875, Entropy -494.05487060546875, Learning Rate: 0.0015625\n",
      "Epoch [2138/20000], Loss: 588.5189208984375, Entropy -478.09185791015625, Learning Rate: 0.0015625\n",
      "Epoch [2139/20000], Loss: 581.8049926757812, Entropy -471.1163024902344, Learning Rate: 0.0015625\n",
      "Epoch [2140/20000], Loss: 599.35107421875, Entropy -491.01153564453125, Learning Rate: 0.0015625\n",
      "Epoch [2141/20000], Loss: 600.7884521484375, Entropy -499.796142578125, Learning Rate: 0.0015625\n",
      "Epoch [2142/20000], Loss: 612.2987670898438, Entropy -505.5688171386719, Learning Rate: 0.0015625\n",
      "Epoch [2143/20000], Loss: 576.228515625, Entropy -470.6274719238281, Learning Rate: 0.0015625\n",
      "Epoch [2144/20000], Loss: 582.7639770507812, Entropy -474.71337890625, Learning Rate: 0.0015625\n",
      "Epoch [2145/20000], Loss: 588.4197387695312, Entropy -485.30499267578125, Learning Rate: 0.0015625\n",
      "Epoch [2146/20000], Loss: 608.8084716796875, Entropy -506.8396911621094, Learning Rate: 0.0015625\n",
      "Epoch [2147/20000], Loss: 588.1417236328125, Entropy -489.15936279296875, Learning Rate: 0.0015625\n",
      "Epoch [2148/20000], Loss: 594.9707641601562, Entropy -499.0788269042969, Learning Rate: 0.0015625\n",
      "Epoch [2149/20000], Loss: 609.3755493164062, Entropy -507.1263732910156, Learning Rate: 0.0015625\n",
      "Epoch [2150/20000], Loss: 588.7725830078125, Entropy -491.8236389160156, Learning Rate: 0.0015625\n",
      "Epoch [2151/20000], Loss: 597.316650390625, Entropy -478.43853759765625, Learning Rate: 0.0015625\n",
      "Epoch [2152/20000], Loss: 590.1943359375, Entropy -479.0596008300781, Learning Rate: 0.0015625\n",
      "Epoch [2153/20000], Loss: 586.4373779296875, Entropy -479.3824768066406, Learning Rate: 0.0015625\n",
      "Epoch [2154/20000], Loss: 589.3319702148438, Entropy -473.98382568359375, Learning Rate: 0.0015625\n",
      "Epoch [2155/20000], Loss: 613.0208129882812, Entropy -510.6028747558594, Learning Rate: 0.0015625\n",
      "Epoch [2156/20000], Loss: 615.3959350585938, Entropy -518.2493896484375, Learning Rate: 0.0015625\n",
      "Epoch [2157/20000], Loss: 596.8858642578125, Entropy -492.98541259765625, Learning Rate: 0.0015625\n",
      "Epoch [2158/20000], Loss: 601.0341186523438, Entropy -502.37530517578125, Learning Rate: 0.0015625\n",
      "Epoch [2159/20000], Loss: 591.9014282226562, Entropy -478.45977783203125, Learning Rate: 0.0015625\n",
      "Epoch [2160/20000], Loss: 582.4757690429688, Entropy -482.0045166015625, Learning Rate: 0.0015625\n",
      "Epoch [2161/20000], Loss: 597.2637329101562, Entropy -490.74737548828125, Learning Rate: 0.0015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2162/20000], Loss: 600.5427856445312, Entropy -495.092041015625, Learning Rate: 0.0015625\n",
      "Epoch [2163/20000], Loss: 612.09814453125, Entropy -485.490234375, Learning Rate: 0.0015625\n",
      "Epoch [2164/20000], Loss: 591.8444213867188, Entropy -481.3197937011719, Learning Rate: 0.0015625\n",
      "Epoch [2165/20000], Loss: 590.8215942382812, Entropy -490.53985595703125, Learning Rate: 0.0015625\n",
      "Epoch [2166/20000], Loss: 598.096435546875, Entropy -496.3322448730469, Learning Rate: 0.0015625\n",
      "Epoch [2167/20000], Loss: 608.6705932617188, Entropy -505.69744873046875, Learning Rate: 0.0015625\n",
      "Epoch [2168/20000], Loss: 607.62841796875, Entropy -493.69915771484375, Learning Rate: 0.0015625\n",
      "Epoch [2169/20000], Loss: 597.4393310546875, Entropy -493.7464904785156, Learning Rate: 0.0015625\n",
      "Epoch [2170/20000], Loss: 587.978759765625, Entropy -484.44989013671875, Learning Rate: 0.0015625\n",
      "Epoch [2171/20000], Loss: 603.7442626953125, Entropy -509.70751953125, Learning Rate: 0.0015625\n",
      "Epoch [2172/20000], Loss: 602.2233276367188, Entropy -506.2734069824219, Learning Rate: 0.0015625\n",
      "Epoch [2173/20000], Loss: 613.4845581054688, Entropy -487.0157470703125, Learning Rate: 0.0015625\n",
      "Epoch [2174/20000], Loss: 597.5228271484375, Entropy -499.2674255371094, Learning Rate: 0.0015625\n",
      "Epoch [2175/20000], Loss: 591.86865234375, Entropy -489.2729797363281, Learning Rate: 0.0015625\n",
      "Epoch [2176/20000], Loss: 602.9623413085938, Entropy -505.7620849609375, Learning Rate: 0.0015625\n",
      "Epoch [2177/20000], Loss: 596.5255126953125, Entropy -506.5821533203125, Learning Rate: 0.0015625\n",
      "Epoch [2178/20000], Loss: 593.6203002929688, Entropy -482.96112060546875, Learning Rate: 0.0015625\n",
      "Epoch [2179/20000], Loss: 601.5007934570312, Entropy -498.0830078125, Learning Rate: 0.0015625\n",
      "Epoch [2180/20000], Loss: 604.4461669921875, Entropy -502.4001159667969, Learning Rate: 0.0015625\n",
      "Epoch [2181/20000], Loss: 593.4519653320312, Entropy -496.4342041015625, Learning Rate: 0.0015625\n",
      "Epoch [2182/20000], Loss: 590.2726440429688, Entropy -494.596435546875, Learning Rate: 0.0015625\n",
      "Epoch [2183/20000], Loss: 592.519287109375, Entropy -477.1755065917969, Learning Rate: 0.0015625\n",
      "Epoch [2184/20000], Loss: 592.9430541992188, Entropy -490.14093017578125, Learning Rate: 0.0015625\n",
      "Epoch [2185/20000], Loss: 589.14111328125, Entropy -467.0908203125, Learning Rate: 0.0015625\n",
      "Epoch [2186/20000], Loss: 605.7470092773438, Entropy -493.87164306640625, Learning Rate: 0.0015625\n",
      "Epoch [2187/20000], Loss: 601.2860107421875, Entropy -485.111083984375, Learning Rate: 0.0015625\n",
      "Epoch [2188/20000], Loss: 589.663818359375, Entropy -492.7442321777344, Learning Rate: 0.0015625\n",
      "Epoch [2189/20000], Loss: 606.8277587890625, Entropy -500.6924133300781, Learning Rate: 0.0015625\n",
      "Epoch [2190/20000], Loss: 599.89794921875, Entropy -499.0867004394531, Learning Rate: 0.0015625\n",
      "Epoch [2191/20000], Loss: 627.0335693359375, Entropy -532.5098876953125, Learning Rate: 0.0015625\n",
      "Epoch [2192/20000], Loss: 584.9959716796875, Entropy -488.180908203125, Learning Rate: 0.0015625\n",
      "Epoch [2193/20000], Loss: 605.68994140625, Entropy -503.9200439453125, Learning Rate: 0.0015625\n",
      "Epoch [2194/20000], Loss: 606.8569946289062, Entropy -488.39337158203125, Learning Rate: 0.0015625\n",
      "Epoch [2195/20000], Loss: 581.6940307617188, Entropy -479.941162109375, Learning Rate: 0.0015625\n",
      "Epoch [2196/20000], Loss: 597.3124389648438, Entropy -489.6416015625, Learning Rate: 0.0015625\n",
      "Epoch [2197/20000], Loss: 621.3262939453125, Entropy -495.2310485839844, Learning Rate: 0.00078125\n",
      "Epoch [2198/20000], Loss: 603.5584716796875, Entropy -503.63446044921875, Learning Rate: 0.00078125\n",
      "Epoch [2199/20000], Loss: 594.6171875, Entropy -489.436767578125, Learning Rate: 0.00078125\n",
      "Epoch [2200/20000], Loss: 600.8587036132812, Entropy -491.4685363769531, Learning Rate: 0.00078125\n",
      "Epoch [2201/20000], Loss: 599.4332885742188, Entropy -503.7833251953125, Learning Rate: 0.00078125\n",
      "Epoch [2202/20000], Loss: 660.0004272460938, Entropy -501.745849609375, Learning Rate: 0.00078125\n",
      "Epoch [2203/20000], Loss: 598.4351196289062, Entropy -502.75128173828125, Learning Rate: 0.00078125\n",
      "Epoch [2204/20000], Loss: 596.826904296875, Entropy -507.20697021484375, Learning Rate: 0.00078125\n",
      "Epoch [2205/20000], Loss: 599.49755859375, Entropy -498.1251525878906, Learning Rate: 0.00078125\n",
      "Epoch [2206/20000], Loss: 599.9578857421875, Entropy -501.216552734375, Learning Rate: 0.00078125\n",
      "Epoch [2207/20000], Loss: 595.2449951171875, Entropy -495.421142578125, Learning Rate: 0.00078125\n",
      "Epoch [2208/20000], Loss: 582.1702880859375, Entropy -476.3520202636719, Learning Rate: 0.00078125\n",
      "Epoch [2209/20000], Loss: 616.6988525390625, Entropy -501.7077941894531, Learning Rate: 0.00078125\n",
      "Epoch [2210/20000], Loss: 588.223388671875, Entropy -465.8593444824219, Learning Rate: 0.00078125\n",
      "Epoch [2211/20000], Loss: 586.6019897460938, Entropy -475.78973388671875, Learning Rate: 0.00078125\n",
      "Epoch [2212/20000], Loss: 596.4046630859375, Entropy -488.10382080078125, Learning Rate: 0.00078125\n",
      "Epoch [2213/20000], Loss: 582.555908203125, Entropy -475.61492919921875, Learning Rate: 0.00078125\n",
      "Epoch [2214/20000], Loss: 611.9781494140625, Entropy -510.6954040527344, Learning Rate: 0.00078125\n",
      "Epoch [2215/20000], Loss: 595.2903442382812, Entropy -488.6121520996094, Learning Rate: 0.00078125\n",
      "Epoch [2216/20000], Loss: 582.3870849609375, Entropy -482.52911376953125, Learning Rate: 0.00078125\n",
      "Epoch [2217/20000], Loss: 592.8021240234375, Entropy -493.7319030761719, Learning Rate: 0.00078125\n",
      "Epoch [2218/20000], Loss: 583.4686279296875, Entropy -478.6991271972656, Learning Rate: 0.00078125\n",
      "Epoch [2219/20000], Loss: 589.9213256835938, Entropy -487.33770751953125, Learning Rate: 0.00078125\n",
      "Epoch [2220/20000], Loss: 593.79150390625, Entropy -483.78094482421875, Learning Rate: 0.00078125\n",
      "Epoch [2221/20000], Loss: 609.6326904296875, Entropy -508.86151123046875, Learning Rate: 0.00078125\n",
      "Epoch [2222/20000], Loss: 598.7213134765625, Entropy -491.16986083984375, Learning Rate: 0.00078125\n",
      "Epoch [2223/20000], Loss: 589.9439697265625, Entropy -483.9998779296875, Learning Rate: 0.00078125\n",
      "Epoch [2224/20000], Loss: 577.1100463867188, Entropy -480.8037109375, Learning Rate: 0.00078125\n",
      "Epoch [2225/20000], Loss: 604.6651611328125, Entropy -498.520263671875, Learning Rate: 0.00078125\n",
      "Epoch [2226/20000], Loss: 592.4371337890625, Entropy -492.56597900390625, Learning Rate: 0.00078125\n",
      "Epoch [2227/20000], Loss: 601.8414916992188, Entropy -497.1341857910156, Learning Rate: 0.00078125\n",
      "Epoch [2228/20000], Loss: 596.3299560546875, Entropy -487.07696533203125, Learning Rate: 0.00078125\n",
      "Epoch [2229/20000], Loss: 592.713134765625, Entropy -493.344482421875, Learning Rate: 0.00078125\n",
      "Epoch [2230/20000], Loss: 590.70458984375, Entropy -485.2967224121094, Learning Rate: 0.00078125\n",
      "Epoch [2231/20000], Loss: 592.4136962890625, Entropy -488.1139221191406, Learning Rate: 0.00078125\n",
      "Epoch [2232/20000], Loss: 585.91748046875, Entropy -474.8809814453125, Learning Rate: 0.00078125\n",
      "Epoch [2233/20000], Loss: 602.345947265625, Entropy -488.2578430175781, Learning Rate: 0.00078125\n",
      "Epoch [2234/20000], Loss: 590.4153442382812, Entropy -483.3470764160156, Learning Rate: 0.00078125\n",
      "Epoch [2235/20000], Loss: 607.4261474609375, Entropy -501.73931884765625, Learning Rate: 0.00078125\n",
      "Epoch [2236/20000], Loss: 591.0452880859375, Entropy -485.17083740234375, Learning Rate: 0.00078125\n",
      "Epoch [2237/20000], Loss: 590.984130859375, Entropy -492.9171142578125, Learning Rate: 0.00078125\n",
      "Epoch [2238/20000], Loss: 602.13916015625, Entropy -489.77081298828125, Learning Rate: 0.00078125\n",
      "Epoch [2239/20000], Loss: 584.7517700195312, Entropy -477.2713317871094, Learning Rate: 0.00078125\n",
      "Epoch [2240/20000], Loss: 577.8101196289062, Entropy -471.20440673828125, Learning Rate: 0.00078125\n",
      "Epoch [2241/20000], Loss: 587.9830322265625, Entropy -489.941162109375, Learning Rate: 0.00078125\n",
      "Epoch [2242/20000], Loss: 597.2333984375, Entropy -498.78271484375, Learning Rate: 0.00078125\n",
      "Epoch [2243/20000], Loss: 598.4760131835938, Entropy -495.09002685546875, Learning Rate: 0.00078125\n",
      "Epoch [2244/20000], Loss: 578.3937377929688, Entropy -471.73602294921875, Learning Rate: 0.00078125\n",
      "Epoch [2245/20000], Loss: 595.8422241210938, Entropy -492.1982116699219, Learning Rate: 0.00078125\n",
      "Epoch [2246/20000], Loss: 603.0984497070312, Entropy -502.27337646484375, Learning Rate: 0.00078125\n",
      "Epoch [2247/20000], Loss: 593.413330078125, Entropy -485.8224792480469, Learning Rate: 0.00078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2248/20000], Loss: 585.5828857421875, Entropy -470.57025146484375, Learning Rate: 0.00078125\n",
      "Epoch [2249/20000], Loss: 586.5092163085938, Entropy -474.44415283203125, Learning Rate: 0.00078125\n",
      "Epoch [2250/20000], Loss: 600.4814453125, Entropy -491.7349853515625, Learning Rate: 0.00078125\n",
      "Epoch [2251/20000], Loss: 600.1973876953125, Entropy -500.3919372558594, Learning Rate: 0.00078125\n",
      "Epoch [2252/20000], Loss: 587.6826782226562, Entropy -478.94281005859375, Learning Rate: 0.00078125\n",
      "Epoch [2253/20000], Loss: 587.9141845703125, Entropy -492.1141662597656, Learning Rate: 0.00078125\n",
      "Epoch [2254/20000], Loss: 607.294921875, Entropy -507.65008544921875, Learning Rate: 0.00078125\n",
      "Epoch [2255/20000], Loss: 578.4921875, Entropy -479.311279296875, Learning Rate: 0.00078125\n",
      "Epoch [2256/20000], Loss: 599.0070190429688, Entropy -486.40887451171875, Learning Rate: 0.00078125\n",
      "Epoch [2257/20000], Loss: 600.804443359375, Entropy -502.3494873046875, Learning Rate: 0.00078125\n",
      "Epoch [2258/20000], Loss: 587.12548828125, Entropy -472.8046569824219, Learning Rate: 0.00078125\n",
      "Epoch [2259/20000], Loss: 586.4522705078125, Entropy -467.35400390625, Learning Rate: 0.00078125\n",
      "Epoch [2260/20000], Loss: 603.628173828125, Entropy -484.67852783203125, Learning Rate: 0.00078125\n",
      "Epoch [2261/20000], Loss: 584.3375244140625, Entropy -480.326904296875, Learning Rate: 0.00078125\n",
      "Epoch [2262/20000], Loss: 606.7127685546875, Entropy -503.697021484375, Learning Rate: 0.00078125\n",
      "Epoch [2263/20000], Loss: 578.532470703125, Entropy -476.02923583984375, Learning Rate: 0.00078125\n",
      "Epoch [2264/20000], Loss: 627.4710083007812, Entropy -506.5667419433594, Learning Rate: 0.00078125\n",
      "Epoch [2265/20000], Loss: 592.1056518554688, Entropy -481.17041015625, Learning Rate: 0.00078125\n",
      "Epoch [2266/20000], Loss: 596.5376586914062, Entropy -495.290283203125, Learning Rate: 0.00078125\n",
      "Epoch [2267/20000], Loss: 596.9971923828125, Entropy -492.9630432128906, Learning Rate: 0.00078125\n",
      "Epoch [2268/20000], Loss: 595.7222900390625, Entropy -486.9617614746094, Learning Rate: 0.00078125\n",
      "Epoch [2269/20000], Loss: 586.852783203125, Entropy -483.4967041015625, Learning Rate: 0.00078125\n",
      "Epoch [2270/20000], Loss: 600.6585693359375, Entropy -500.6280517578125, Learning Rate: 0.00078125\n",
      "Epoch [2271/20000], Loss: 586.4694213867188, Entropy -479.49224853515625, Learning Rate: 0.00078125\n",
      "Epoch [2272/20000], Loss: 600.9219970703125, Entropy -499.3271789550781, Learning Rate: 0.00078125\n",
      "Epoch [2273/20000], Loss: 601.8013305664062, Entropy -509.6993408203125, Learning Rate: 0.00078125\n",
      "Epoch [2274/20000], Loss: 608.6650390625, Entropy -481.48248291015625, Learning Rate: 0.00078125\n",
      "Epoch [2275/20000], Loss: 597.4388427734375, Entropy -498.7073974609375, Learning Rate: 0.00078125\n",
      "Epoch [2276/20000], Loss: 608.5113525390625, Entropy -504.2823181152344, Learning Rate: 0.00078125\n",
      "Epoch [2277/20000], Loss: 596.315185546875, Entropy -495.8964538574219, Learning Rate: 0.00078125\n",
      "Epoch [2278/20000], Loss: 609.378173828125, Entropy -514.0113525390625, Learning Rate: 0.00078125\n",
      "Epoch [2279/20000], Loss: 597.9026489257812, Entropy -489.5006103515625, Learning Rate: 0.00078125\n",
      "Epoch [2280/20000], Loss: 588.0316772460938, Entropy -484.96868896484375, Learning Rate: 0.00078125\n",
      "Epoch [2281/20000], Loss: 583.6213989257812, Entropy -491.4766845703125, Learning Rate: 0.00078125\n",
      "Epoch [2282/20000], Loss: 615.5977783203125, Entropy -516.1871948242188, Learning Rate: 0.00078125\n",
      "Epoch [2283/20000], Loss: 589.2288208007812, Entropy -487.48736572265625, Learning Rate: 0.00078125\n",
      "Epoch [2284/20000], Loss: 592.4862670898438, Entropy -492.627197265625, Learning Rate: 0.00078125\n",
      "Epoch [2285/20000], Loss: 587.2200927734375, Entropy -486.8902282714844, Learning Rate: 0.00078125\n",
      "Epoch [2286/20000], Loss: 611.7528076171875, Entropy -504.157958984375, Learning Rate: 0.00078125\n",
      "Epoch [2287/20000], Loss: 600.853271484375, Entropy -501.4864807128906, Learning Rate: 0.00078125\n",
      "Epoch [2288/20000], Loss: 586.7870483398438, Entropy -475.72802734375, Learning Rate: 0.00078125\n",
      "Epoch [2289/20000], Loss: 600.75537109375, Entropy -497.9394836425781, Learning Rate: 0.00078125\n",
      "Epoch [2290/20000], Loss: 590.0789794921875, Entropy -474.8952331542969, Learning Rate: 0.00078125\n",
      "Epoch [2291/20000], Loss: 590.5760498046875, Entropy -500.240478515625, Learning Rate: 0.00078125\n",
      "Epoch [2292/20000], Loss: 595.024658203125, Entropy -487.357666015625, Learning Rate: 0.00078125\n",
      "Epoch [2293/20000], Loss: 590.904296875, Entropy -490.515625, Learning Rate: 0.00078125\n",
      "Epoch [2294/20000], Loss: 597.8768920898438, Entropy -477.6820373535156, Learning Rate: 0.00078125\n",
      "Epoch [2295/20000], Loss: 614.5794677734375, Entropy -510.47369384765625, Learning Rate: 0.00078125\n",
      "Epoch [2296/20000], Loss: 572.6627197265625, Entropy -471.45941162109375, Learning Rate: 0.00078125\n",
      "Epoch [2297/20000], Loss: 598.7757568359375, Entropy -488.837890625, Learning Rate: 0.00078125\n",
      "Epoch [2298/20000], Loss: 598.1929931640625, Entropy -493.58685302734375, Learning Rate: 0.00078125\n",
      "Epoch [2299/20000], Loss: 573.9805297851562, Entropy -463.74017333984375, Learning Rate: 0.00078125\n",
      "Epoch [2300/20000], Loss: 588.4801025390625, Entropy -478.5393981933594, Learning Rate: 0.00078125\n",
      "Epoch [2301/20000], Loss: 570.4347534179688, Entropy -466.2259521484375, Learning Rate: 0.00078125\n",
      "Epoch [2302/20000], Loss: 600.775634765625, Entropy -494.7187805175781, Learning Rate: 0.00078125\n",
      "Epoch [2303/20000], Loss: 592.5197143554688, Entropy -491.578857421875, Learning Rate: 0.00078125\n",
      "Epoch [2304/20000], Loss: 570.3085327148438, Entropy -478.13604736328125, Learning Rate: 0.00078125\n",
      "Epoch [2305/20000], Loss: 606.6494750976562, Entropy -498.00946044921875, Learning Rate: 0.00078125\n",
      "Epoch [2306/20000], Loss: 612.542724609375, Entropy -502.593994140625, Learning Rate: 0.00078125\n",
      "Epoch [2307/20000], Loss: 590.4284057617188, Entropy -493.15887451171875, Learning Rate: 0.00078125\n",
      "Epoch [2308/20000], Loss: 606.776123046875, Entropy -507.21533203125, Learning Rate: 0.00078125\n",
      "Epoch [2309/20000], Loss: 590.3161010742188, Entropy -485.49188232421875, Learning Rate: 0.00078125\n",
      "Epoch [2310/20000], Loss: 591.9683227539062, Entropy -488.6021728515625, Learning Rate: 0.00078125\n",
      "Epoch [2311/20000], Loss: 601.1610107421875, Entropy -504.5323486328125, Learning Rate: 0.00078125\n",
      "Epoch [2312/20000], Loss: 589.7070922851562, Entropy -474.6678466796875, Learning Rate: 0.00078125\n",
      "Epoch [2313/20000], Loss: 592.6019287109375, Entropy -488.88653564453125, Learning Rate: 0.00078125\n",
      "Epoch [2314/20000], Loss: 574.0914916992188, Entropy -463.5859375, Learning Rate: 0.00078125\n",
      "Epoch [2315/20000], Loss: 601.7048950195312, Entropy -500.1568298339844, Learning Rate: 0.00078125\n",
      "Epoch [2316/20000], Loss: 594.5736083984375, Entropy -489.15655517578125, Learning Rate: 0.00078125\n",
      "Epoch [2317/20000], Loss: 595.5775146484375, Entropy -500.9000244140625, Learning Rate: 0.00078125\n",
      "Epoch [2318/20000], Loss: 605.574951171875, Entropy -495.503173828125, Learning Rate: 0.00078125\n",
      "Epoch [2319/20000], Loss: 592.2311401367188, Entropy -498.50018310546875, Learning Rate: 0.00078125\n",
      "Epoch [2320/20000], Loss: 595.951904296875, Entropy -493.420166015625, Learning Rate: 0.00078125\n",
      "Epoch [2321/20000], Loss: 613.0037841796875, Entropy -506.8250732421875, Learning Rate: 0.00078125\n",
      "Epoch [2322/20000], Loss: 579.2518920898438, Entropy -470.20953369140625, Learning Rate: 0.00078125\n",
      "Epoch [2323/20000], Loss: 604.1268310546875, Entropy -481.95330810546875, Learning Rate: 0.00078125\n",
      "Epoch [2324/20000], Loss: 603.14208984375, Entropy -497.83209228515625, Learning Rate: 0.00078125\n",
      "Epoch [2325/20000], Loss: 643.8345336914062, Entropy -505.4066162109375, Learning Rate: 0.00078125\n",
      "Epoch [2326/20000], Loss: 578.1309204101562, Entropy -485.0704040527344, Learning Rate: 0.00078125\n",
      "Epoch [2327/20000], Loss: 598.5543823242188, Entropy -494.9957580566406, Learning Rate: 0.00078125\n",
      "Epoch [2328/20000], Loss: 590.89013671875, Entropy -494.851806640625, Learning Rate: 0.00078125\n",
      "Epoch [2329/20000], Loss: 595.6632080078125, Entropy -476.98455810546875, Learning Rate: 0.00078125\n",
      "Epoch [2330/20000], Loss: 595.490234375, Entropy -501.49481201171875, Learning Rate: 0.00078125\n",
      "Epoch [2331/20000], Loss: 589.7265014648438, Entropy -480.28643798828125, Learning Rate: 0.00078125\n",
      "Epoch [2332/20000], Loss: 582.1058349609375, Entropy -473.6318359375, Learning Rate: 0.00078125\n",
      "Epoch [2333/20000], Loss: 584.9340209960938, Entropy -476.0137023925781, Learning Rate: 0.00078125\n",
      "Epoch [2334/20000], Loss: 615.2198486328125, Entropy -499.0005798339844, Learning Rate: 0.00078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2335/20000], Loss: 591.8341674804688, Entropy -482.2544860839844, Learning Rate: 0.00078125\n",
      "Epoch [2336/20000], Loss: 594.566650390625, Entropy -487.01690673828125, Learning Rate: 0.00078125\n",
      "Epoch [2337/20000], Loss: 598.9818115234375, Entropy -470.90960693359375, Learning Rate: 0.00078125\n",
      "Epoch [2338/20000], Loss: 604.01904296875, Entropy -506.56707763671875, Learning Rate: 0.00078125\n",
      "Epoch [2339/20000], Loss: 592.3546142578125, Entropy -489.681884765625, Learning Rate: 0.00078125\n",
      "Epoch [2340/20000], Loss: 605.7119750976562, Entropy -490.12261962890625, Learning Rate: 0.00078125\n",
      "Epoch [2341/20000], Loss: 603.350830078125, Entropy -499.56097412109375, Learning Rate: 0.00078125\n",
      "Epoch [2342/20000], Loss: 589.380615234375, Entropy -479.44720458984375, Learning Rate: 0.00078125\n",
      "Epoch [2343/20000], Loss: 592.9451293945312, Entropy -486.6318359375, Learning Rate: 0.00078125\n",
      "Epoch [2344/20000], Loss: 608.86474609375, Entropy -506.46392822265625, Learning Rate: 0.00078125\n",
      "Epoch [2345/20000], Loss: 592.6795654296875, Entropy -491.877685546875, Learning Rate: 0.00078125\n",
      "Epoch [2346/20000], Loss: 601.7603149414062, Entropy -499.44000244140625, Learning Rate: 0.00078125\n",
      "Epoch [2347/20000], Loss: 599.853271484375, Entropy -492.0469970703125, Learning Rate: 0.00078125\n",
      "Epoch [2348/20000], Loss: 601.2686767578125, Entropy -483.2010803222656, Learning Rate: 0.00078125\n",
      "Epoch [2349/20000], Loss: 581.1171875, Entropy -486.7020263671875, Learning Rate: 0.00078125\n",
      "Epoch [2350/20000], Loss: 601.0066528320312, Entropy -475.1632080078125, Learning Rate: 0.00078125\n",
      "Epoch [2351/20000], Loss: 580.3419189453125, Entropy -477.2860412597656, Learning Rate: 0.00078125\n",
      "Epoch [2352/20000], Loss: 591.8782958984375, Entropy -497.0489196777344, Learning Rate: 0.00078125\n",
      "Epoch [2353/20000], Loss: 579.2744140625, Entropy -481.5234680175781, Learning Rate: 0.00078125\n",
      "Epoch [2354/20000], Loss: 596.1669921875, Entropy -494.8329162597656, Learning Rate: 0.00078125\n",
      "Epoch [2355/20000], Loss: 605.7360229492188, Entropy -498.11016845703125, Learning Rate: 0.00078125\n",
      "Epoch [2356/20000], Loss: 599.5693359375, Entropy -493.85125732421875, Learning Rate: 0.00078125\n",
      "Epoch [2357/20000], Loss: 591.5652465820312, Entropy -486.86669921875, Learning Rate: 0.00078125\n",
      "Epoch [2358/20000], Loss: 581.0260620117188, Entropy -470.10992431640625, Learning Rate: 0.00078125\n",
      "Epoch [2359/20000], Loss: 597.5325927734375, Entropy -495.368408203125, Learning Rate: 0.00078125\n",
      "Epoch [2360/20000], Loss: 577.8120727539062, Entropy -486.04754638671875, Learning Rate: 0.00078125\n",
      "Epoch [2361/20000], Loss: 592.910400390625, Entropy -491.2109375, Learning Rate: 0.00078125\n",
      "Epoch [2362/20000], Loss: 616.3632202148438, Entropy -461.04998779296875, Learning Rate: 0.00078125\n",
      "Epoch [2363/20000], Loss: 592.7673950195312, Entropy -479.95819091796875, Learning Rate: 0.00078125\n",
      "Epoch [2364/20000], Loss: 590.6884155273438, Entropy -476.851318359375, Learning Rate: 0.00078125\n",
      "Epoch [2365/20000], Loss: 596.4661254882812, Entropy -473.6051025390625, Learning Rate: 0.00078125\n",
      "Epoch [2366/20000], Loss: 597.24267578125, Entropy -506.4528503417969, Learning Rate: 0.00078125\n",
      "Epoch [2367/20000], Loss: 592.6329345703125, Entropy -473.85540771484375, Learning Rate: 0.00078125\n",
      "Epoch [2368/20000], Loss: 592.3601684570312, Entropy -483.4075012207031, Learning Rate: 0.00078125\n",
      "Epoch [2369/20000], Loss: 589.4065551757812, Entropy -475.5478820800781, Learning Rate: 0.00078125\n",
      "Epoch [2370/20000], Loss: 625.8248291015625, Entropy -509.94952392578125, Learning Rate: 0.00078125\n",
      "Epoch [2371/20000], Loss: 598.865478515625, Entropy -507.2608337402344, Learning Rate: 0.00078125\n",
      "Epoch [2372/20000], Loss: 590.5804443359375, Entropy -490.44390869140625, Learning Rate: 0.00078125\n",
      "Epoch [2373/20000], Loss: 615.0533447265625, Entropy -498.0247802734375, Learning Rate: 0.00078125\n",
      "Epoch [2374/20000], Loss: 595.302734375, Entropy -482.5816650390625, Learning Rate: 0.00078125\n",
      "Epoch [2375/20000], Loss: 586.801025390625, Entropy -479.59735107421875, Learning Rate: 0.00078125\n",
      "Epoch [2376/20000], Loss: 586.2574462890625, Entropy -490.07952880859375, Learning Rate: 0.00078125\n",
      "Epoch [2377/20000], Loss: 600.7574462890625, Entropy -491.829833984375, Learning Rate: 0.00078125\n",
      "Epoch [2378/20000], Loss: 583.694091796875, Entropy -473.2163391113281, Learning Rate: 0.00078125\n",
      "Epoch [2379/20000], Loss: 592.1708374023438, Entropy -489.24493408203125, Learning Rate: 0.00078125\n",
      "Epoch [2380/20000], Loss: 585.0897216796875, Entropy -477.7838134765625, Learning Rate: 0.00078125\n",
      "Epoch [2381/20000], Loss: 623.39501953125, Entropy -495.89361572265625, Learning Rate: 0.00078125\n",
      "Epoch [2382/20000], Loss: 595.25244140625, Entropy -495.0363464355469, Learning Rate: 0.00078125\n",
      "Epoch [2383/20000], Loss: 594.8739624023438, Entropy -489.4670104980469, Learning Rate: 0.00078125\n",
      "Epoch [2384/20000], Loss: 591.6195678710938, Entropy -492.04534912109375, Learning Rate: 0.00078125\n",
      "Epoch [2385/20000], Loss: 603.483154296875, Entropy -501.0301818847656, Learning Rate: 0.00078125\n",
      "Epoch [2386/20000], Loss: 591.5039672851562, Entropy -486.61737060546875, Learning Rate: 0.00078125\n",
      "Epoch [2387/20000], Loss: 592.7228393554688, Entropy -484.8095703125, Learning Rate: 0.00078125\n",
      "Epoch [2388/20000], Loss: 579.5503540039062, Entropy -481.752197265625, Learning Rate: 0.00078125\n",
      "Epoch [2389/20000], Loss: 610.0113525390625, Entropy -504.3479309082031, Learning Rate: 0.00078125\n",
      "Epoch [2390/20000], Loss: 583.5433959960938, Entropy -478.7541198730469, Learning Rate: 0.00078125\n",
      "Epoch [2391/20000], Loss: 618.1095581054688, Entropy -505.454833984375, Learning Rate: 0.00078125\n",
      "Epoch [2392/20000], Loss: 581.4022827148438, Entropy -470.70831298828125, Learning Rate: 0.00078125\n",
      "Epoch [2393/20000], Loss: 595.8502197265625, Entropy -491.446044921875, Learning Rate: 0.00078125\n",
      "Epoch [2394/20000], Loss: 613.0946044921875, Entropy -503.9238586425781, Learning Rate: 0.00078125\n",
      "Epoch [2395/20000], Loss: 596.6795043945312, Entropy -498.04443359375, Learning Rate: 0.00078125\n",
      "Epoch [2396/20000], Loss: 597.7918090820312, Entropy -492.6412353515625, Learning Rate: 0.00078125\n",
      "Epoch [2397/20000], Loss: 612.0635986328125, Entropy -486.1332702636719, Learning Rate: 0.00078125\n",
      "Epoch [2398/20000], Loss: 593.3856811523438, Entropy -493.057861328125, Learning Rate: 0.00078125\n",
      "Epoch [2399/20000], Loss: 588.7725830078125, Entropy -488.89984130859375, Learning Rate: 0.00078125\n",
      "Epoch [2400/20000], Loss: 586.844970703125, Entropy -492.97601318359375, Learning Rate: 0.00078125\n",
      "Epoch [2401/20000], Loss: 583.2681884765625, Entropy -475.3017578125, Learning Rate: 0.00078125\n",
      "Epoch [2402/20000], Loss: 581.2645874023438, Entropy -464.59149169921875, Learning Rate: 0.00078125\n",
      "Epoch [2403/20000], Loss: 594.397705078125, Entropy -484.59942626953125, Learning Rate: 0.00078125\n",
      "Epoch [2404/20000], Loss: 608.5363159179688, Entropy -489.2679748535156, Learning Rate: 0.00078125\n",
      "Epoch [2405/20000], Loss: 615.1905517578125, Entropy -518.5842895507812, Learning Rate: 0.00078125\n",
      "Epoch [2406/20000], Loss: 602.6771850585938, Entropy -504.6197204589844, Learning Rate: 0.000390625\n",
      "Epoch [2407/20000], Loss: 585.9314575195312, Entropy -474.5323486328125, Learning Rate: 0.000390625\n",
      "Epoch [2408/20000], Loss: 576.0989990234375, Entropy -472.50958251953125, Learning Rate: 0.000390625\n",
      "Epoch [2409/20000], Loss: 603.7050170898438, Entropy -503.5589599609375, Learning Rate: 0.000390625\n",
      "Epoch [2410/20000], Loss: 589.0116577148438, Entropy -490.7966613769531, Learning Rate: 0.000390625\n",
      "Epoch [2411/20000], Loss: 595.0634155273438, Entropy -496.30712890625, Learning Rate: 0.000390625\n",
      "Epoch [2412/20000], Loss: 594.2356567382812, Entropy -495.375, Learning Rate: 0.000390625\n",
      "Epoch [2413/20000], Loss: 591.3173217773438, Entropy -491.3179931640625, Learning Rate: 0.000390625\n",
      "Epoch [2414/20000], Loss: 586.2840576171875, Entropy -477.85260009765625, Learning Rate: 0.000390625\n",
      "Epoch [2415/20000], Loss: 575.7720336914062, Entropy -469.631591796875, Learning Rate: 0.000390625\n",
      "Epoch [2416/20000], Loss: 605.0656127929688, Entropy -499.2373046875, Learning Rate: 0.000390625\n",
      "Epoch [2417/20000], Loss: 585.9629516601562, Entropy -480.9158630371094, Learning Rate: 0.000390625\n",
      "Epoch [2418/20000], Loss: 599.4412841796875, Entropy -496.9129638671875, Learning Rate: 0.000390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2419/20000], Loss: 580.0821533203125, Entropy -478.96734619140625, Learning Rate: 0.000390625\n",
      "Epoch [2420/20000], Loss: 596.2705688476562, Entropy -491.3195495605469, Learning Rate: 0.000390625\n",
      "Epoch [2421/20000], Loss: 594.303466796875, Entropy -488.794677734375, Learning Rate: 0.000390625\n",
      "Epoch [2422/20000], Loss: 585.5006713867188, Entropy -482.27081298828125, Learning Rate: 0.000390625\n",
      "Epoch [2423/20000], Loss: 619.1827392578125, Entropy -514.8970947265625, Learning Rate: 0.000390625\n",
      "Epoch [2424/20000], Loss: 573.7110595703125, Entropy -475.259765625, Learning Rate: 0.000390625\n",
      "Epoch [2425/20000], Loss: 601.085693359375, Entropy -488.640625, Learning Rate: 0.000390625\n",
      "Epoch [2426/20000], Loss: 577.531982421875, Entropy -477.4062805175781, Learning Rate: 0.000390625\n",
      "Epoch [2427/20000], Loss: 586.07373046875, Entropy -473.3031311035156, Learning Rate: 0.000390625\n",
      "Epoch [2428/20000], Loss: 593.592041015625, Entropy -490.57110595703125, Learning Rate: 0.000390625\n",
      "Epoch [2429/20000], Loss: 615.409423828125, Entropy -488.4249267578125, Learning Rate: 0.000390625\n",
      "Epoch [2430/20000], Loss: 612.397705078125, Entropy -492.38323974609375, Learning Rate: 0.000390625\n",
      "Epoch [2431/20000], Loss: 627.94189453125, Entropy -518.400390625, Learning Rate: 0.000390625\n",
      "Epoch [2432/20000], Loss: 592.884765625, Entropy -488.4900207519531, Learning Rate: 0.000390625\n",
      "Epoch [2433/20000], Loss: 594.672119140625, Entropy -490.772216796875, Learning Rate: 0.000390625\n",
      "Epoch [2434/20000], Loss: 599.413330078125, Entropy -478.8157958984375, Learning Rate: 0.000390625\n",
      "Epoch [2435/20000], Loss: 591.0367431640625, Entropy -485.245361328125, Learning Rate: 0.000390625\n",
      "Epoch [2436/20000], Loss: 576.2847900390625, Entropy -476.99627685546875, Learning Rate: 0.000390625\n",
      "Epoch [2437/20000], Loss: 595.0660400390625, Entropy -501.2520446777344, Learning Rate: 0.000390625\n",
      "Epoch [2438/20000], Loss: 607.704833984375, Entropy -505.25787353515625, Learning Rate: 0.000390625\n",
      "Epoch [2439/20000], Loss: 587.7304077148438, Entropy -476.2684020996094, Learning Rate: 0.000390625\n",
      "Epoch [2440/20000], Loss: 576.0740356445312, Entropy -471.6944580078125, Learning Rate: 0.000390625\n",
      "Epoch [2441/20000], Loss: 602.2459106445312, Entropy -499.5942687988281, Learning Rate: 0.000390625\n",
      "Epoch [2442/20000], Loss: 599.73388671875, Entropy -500.5224609375, Learning Rate: 0.000390625\n",
      "Epoch [2443/20000], Loss: 608.7391357421875, Entropy -515.45556640625, Learning Rate: 0.000390625\n",
      "Epoch [2444/20000], Loss: 602.1478881835938, Entropy -496.0951232910156, Learning Rate: 0.000390625\n",
      "Epoch [2445/20000], Loss: 604.9577026367188, Entropy -496.6454772949219, Learning Rate: 0.000390625\n",
      "Epoch [2446/20000], Loss: 604.7407836914062, Entropy -511.5576477050781, Learning Rate: 0.000390625\n",
      "Epoch [2447/20000], Loss: 596.440185546875, Entropy -488.1080322265625, Learning Rate: 0.000390625\n",
      "Epoch [2448/20000], Loss: 596.6041259765625, Entropy -490.87677001953125, Learning Rate: 0.000390625\n",
      "Epoch [2449/20000], Loss: 589.882080078125, Entropy -480.09368896484375, Learning Rate: 0.000390625\n",
      "Epoch [2450/20000], Loss: 588.7750854492188, Entropy -496.95098876953125, Learning Rate: 0.000390625\n",
      "Epoch [2451/20000], Loss: 596.3359375, Entropy -492.41607666015625, Learning Rate: 0.000390625\n",
      "Epoch [2452/20000], Loss: 589.033203125, Entropy -488.7659912109375, Learning Rate: 0.000390625\n",
      "Epoch [2453/20000], Loss: 588.5753173828125, Entropy -476.98895263671875, Learning Rate: 0.000390625\n",
      "Epoch [2454/20000], Loss: 598.61181640625, Entropy -496.5083312988281, Learning Rate: 0.000390625\n",
      "Epoch [2455/20000], Loss: 591.0808715820312, Entropy -482.718994140625, Learning Rate: 0.000390625\n",
      "Epoch [2456/20000], Loss: 580.3880615234375, Entropy -471.92999267578125, Learning Rate: 0.000390625\n",
      "Epoch [2457/20000], Loss: 601.1041870117188, Entropy -507.2244873046875, Learning Rate: 0.000390625\n",
      "Epoch [2458/20000], Loss: 581.094970703125, Entropy -477.505126953125, Learning Rate: 0.000390625\n",
      "Epoch [2459/20000], Loss: 586.203857421875, Entropy -481.8226623535156, Learning Rate: 0.000390625\n",
      "Epoch [2460/20000], Loss: 586.580078125, Entropy -490.1053161621094, Learning Rate: 0.000390625\n",
      "Epoch [2461/20000], Loss: 589.5559692382812, Entropy -475.631591796875, Learning Rate: 0.000390625\n",
      "Epoch [2462/20000], Loss: 603.8475341796875, Entropy -504.2001037597656, Learning Rate: 0.000390625\n",
      "Epoch [2463/20000], Loss: 579.4712524414062, Entropy -472.45281982421875, Learning Rate: 0.000390625\n",
      "Epoch [2464/20000], Loss: 598.146728515625, Entropy -500.1463623046875, Learning Rate: 0.000390625\n",
      "Epoch [2465/20000], Loss: 579.0487060546875, Entropy -471.660400390625, Learning Rate: 0.000390625\n",
      "Epoch [2466/20000], Loss: 599.0015869140625, Entropy -495.9263000488281, Learning Rate: 0.000390625\n",
      "Epoch [2467/20000], Loss: 592.0626220703125, Entropy -495.25384521484375, Learning Rate: 0.000390625\n",
      "Epoch [2468/20000], Loss: 603.5060424804688, Entropy -472.3140869140625, Learning Rate: 0.000390625\n",
      "Epoch [2469/20000], Loss: 616.3338012695312, Entropy -486.7358093261719, Learning Rate: 0.000390625\n",
      "Epoch [2470/20000], Loss: 602.7591552734375, Entropy -509.1787109375, Learning Rate: 0.000390625\n",
      "Epoch [2471/20000], Loss: 584.8495483398438, Entropy -484.1390380859375, Learning Rate: 0.000390625\n",
      "Epoch [2472/20000], Loss: 585.4011840820312, Entropy -485.59637451171875, Learning Rate: 0.000390625\n",
      "Epoch [2473/20000], Loss: 590.7806396484375, Entropy -486.5072021484375, Learning Rate: 0.000390625\n",
      "Epoch [2474/20000], Loss: 601.619873046875, Entropy -503.6485595703125, Learning Rate: 0.000390625\n",
      "Epoch [2475/20000], Loss: 579.9425659179688, Entropy -462.255126953125, Learning Rate: 0.000390625\n",
      "Epoch [2476/20000], Loss: 584.3911743164062, Entropy -486.1711120605469, Learning Rate: 0.000390625\n",
      "Epoch [2477/20000], Loss: 590.3634643554688, Entropy -476.7251281738281, Learning Rate: 0.000390625\n",
      "Epoch [2478/20000], Loss: 607.43603515625, Entropy -501.2740173339844, Learning Rate: 0.000390625\n",
      "Epoch [2479/20000], Loss: 600.0532836914062, Entropy -502.40325927734375, Learning Rate: 0.000390625\n",
      "Epoch [2480/20000], Loss: 607.8880004882812, Entropy -517.877685546875, Learning Rate: 0.000390625\n",
      "Epoch [2481/20000], Loss: 595.895751953125, Entropy -489.38519287109375, Learning Rate: 0.000390625\n",
      "Epoch [2482/20000], Loss: 582.8721923828125, Entropy -476.1944580078125, Learning Rate: 0.000390625\n",
      "Epoch [2483/20000], Loss: 584.4560546875, Entropy -484.8985290527344, Learning Rate: 0.000390625\n",
      "Epoch [2484/20000], Loss: 627.5537109375, Entropy -499.8967590332031, Learning Rate: 0.000390625\n",
      "Epoch [2485/20000], Loss: 584.3564453125, Entropy -475.61419677734375, Learning Rate: 0.000390625\n",
      "Epoch [2486/20000], Loss: 586.6175537109375, Entropy -479.0511474609375, Learning Rate: 0.000390625\n",
      "Epoch [2487/20000], Loss: 603.5234375, Entropy -496.22943115234375, Learning Rate: 0.000390625\n",
      "Epoch [2488/20000], Loss: 592.56494140625, Entropy -481.5672607421875, Learning Rate: 0.000390625\n",
      "Epoch [2489/20000], Loss: 599.8110961914062, Entropy -499.4375305175781, Learning Rate: 0.000390625\n",
      "Epoch [2490/20000], Loss: 606.1065673828125, Entropy -506.9659729003906, Learning Rate: 0.000390625\n",
      "Epoch [2491/20000], Loss: 602.1884765625, Entropy -501.72161865234375, Learning Rate: 0.000390625\n",
      "Epoch [2492/20000], Loss: 607.1409301757812, Entropy -502.56744384765625, Learning Rate: 0.000390625\n",
      "Epoch [2493/20000], Loss: 575.0418701171875, Entropy -475.8876953125, Learning Rate: 0.000390625\n",
      "Epoch [2494/20000], Loss: 598.4572143554688, Entropy -489.671875, Learning Rate: 0.000390625\n",
      "Epoch [2495/20000], Loss: 607.405029296875, Entropy -495.56231689453125, Learning Rate: 0.000390625\n",
      "Epoch [2496/20000], Loss: 593.4540405273438, Entropy -496.4722900390625, Learning Rate: 0.000390625\n",
      "Epoch [2497/20000], Loss: 574.654052734375, Entropy -464.7779235839844, Learning Rate: 0.000390625\n",
      "Epoch [2498/20000], Loss: 598.8056640625, Entropy -494.14996337890625, Learning Rate: 0.000390625\n",
      "Epoch [2499/20000], Loss: 593.16943359375, Entropy -494.092529296875, Learning Rate: 0.000390625\n",
      "Epoch [2500/20000], Loss: 606.8033447265625, Entropy -490.48211669921875, Learning Rate: 0.000390625\n",
      "Epoch [2501/20000], Loss: 619.4334106445312, Entropy -521.5555419921875, Learning Rate: 0.000390625\n",
      "Epoch [2502/20000], Loss: 574.020751953125, Entropy -480.51910400390625, Learning Rate: 0.000390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2503/20000], Loss: 604.5516357421875, Entropy -495.1950378417969, Learning Rate: 0.000390625\n",
      "Epoch [2504/20000], Loss: 595.5324096679688, Entropy -473.82708740234375, Learning Rate: 0.000390625\n",
      "Epoch [2505/20000], Loss: 600.351806640625, Entropy -501.1659851074219, Learning Rate: 0.000390625\n",
      "Epoch [2506/20000], Loss: 600.6574096679688, Entropy -496.7757568359375, Learning Rate: 0.000390625\n",
      "Epoch [2507/20000], Loss: 599.8892822265625, Entropy -495.45465087890625, Learning Rate: 0.0001953125\n",
      "Epoch [2508/20000], Loss: 596.318603515625, Entropy -492.6513366699219, Learning Rate: 0.0001953125\n",
      "Epoch [2509/20000], Loss: 579.647216796875, Entropy -474.0322570800781, Learning Rate: 0.0001953125\n",
      "Epoch [2510/20000], Loss: 577.1505126953125, Entropy -475.249267578125, Learning Rate: 0.0001953125\n",
      "Epoch [2511/20000], Loss: 603.0162353515625, Entropy -500.92401123046875, Learning Rate: 0.0001953125\n",
      "Epoch [2512/20000], Loss: 608.6940307617188, Entropy -494.5877685546875, Learning Rate: 0.0001953125\n",
      "Epoch [2513/20000], Loss: 586.255126953125, Entropy -489.18927001953125, Learning Rate: 0.0001953125\n",
      "Epoch [2514/20000], Loss: 588.7617797851562, Entropy -470.5321044921875, Learning Rate: 0.0001953125\n",
      "Epoch [2515/20000], Loss: 598.1832885742188, Entropy -489.67779541015625, Learning Rate: 0.0001953125\n",
      "Epoch [2516/20000], Loss: 572.983154296875, Entropy -466.8402404785156, Learning Rate: 0.0001953125\n",
      "Epoch [2517/20000], Loss: 577.8035888671875, Entropy -476.72369384765625, Learning Rate: 0.0001953125\n",
      "Epoch [2518/20000], Loss: 597.1585693359375, Entropy -482.1575927734375, Learning Rate: 0.0001953125\n",
      "Epoch [2519/20000], Loss: 603.2523193359375, Entropy -497.482666015625, Learning Rate: 0.0001953125\n",
      "Epoch [2520/20000], Loss: 581.899658203125, Entropy -471.0415344238281, Learning Rate: 0.0001953125\n",
      "Epoch [2521/20000], Loss: 595.2109375, Entropy -491.31622314453125, Learning Rate: 0.0001953125\n",
      "Epoch [2522/20000], Loss: 600.9646606445312, Entropy -503.34930419921875, Learning Rate: 0.0001953125\n",
      "Epoch [2523/20000], Loss: 587.6533813476562, Entropy -476.8192138671875, Learning Rate: 0.0001953125\n",
      "Epoch [2524/20000], Loss: 594.02880859375, Entropy -486.57244873046875, Learning Rate: 0.0001953125\n",
      "Epoch [2525/20000], Loss: 589.1124877929688, Entropy -476.65283203125, Learning Rate: 0.0001953125\n",
      "Epoch [2526/20000], Loss: 601.0591430664062, Entropy -491.8033142089844, Learning Rate: 0.0001953125\n",
      "Epoch [2527/20000], Loss: 599.9750366210938, Entropy -476.5714416503906, Learning Rate: 0.0001953125\n",
      "Epoch [2528/20000], Loss: 579.5556640625, Entropy -461.38726806640625, Learning Rate: 0.0001953125\n",
      "Epoch [2529/20000], Loss: 594.9671630859375, Entropy -486.3311462402344, Learning Rate: 0.0001953125\n",
      "Epoch [2530/20000], Loss: 580.5902099609375, Entropy -472.7944030761719, Learning Rate: 0.0001953125\n",
      "Epoch [2531/20000], Loss: 613.7723388671875, Entropy -503.687255859375, Learning Rate: 0.0001953125\n",
      "Epoch [2532/20000], Loss: 601.6986083984375, Entropy -499.5740966796875, Learning Rate: 0.0001953125\n",
      "Epoch [2533/20000], Loss: 574.3143310546875, Entropy -480.06494140625, Learning Rate: 0.0001953125\n",
      "Epoch [2534/20000], Loss: 593.4344482421875, Entropy -499.00927734375, Learning Rate: 0.0001953125\n",
      "Epoch [2535/20000], Loss: 612.4680786132812, Entropy -516.2515869140625, Learning Rate: 0.0001953125\n",
      "Epoch [2536/20000], Loss: 590.5791625976562, Entropy -479.51861572265625, Learning Rate: 0.0001953125\n",
      "Epoch [2537/20000], Loss: 603.929931640625, Entropy -502.8969421386719, Learning Rate: 0.0001953125\n",
      "Epoch [2538/20000], Loss: 577.0921630859375, Entropy -483.12969970703125, Learning Rate: 0.0001953125\n",
      "Epoch [2539/20000], Loss: 592.0260620117188, Entropy -497.15771484375, Learning Rate: 0.0001953125\n",
      "Epoch [2540/20000], Loss: 579.6323852539062, Entropy -484.5926818847656, Learning Rate: 0.0001953125\n",
      "Epoch [2541/20000], Loss: 604.0498046875, Entropy -505.0318908691406, Learning Rate: 0.0001953125\n",
      "Epoch [2542/20000], Loss: 573.7163696289062, Entropy -463.7451171875, Learning Rate: 0.0001953125\n",
      "Epoch [2543/20000], Loss: 626.9607543945312, Entropy -488.03948974609375, Learning Rate: 0.0001953125\n",
      "Epoch [2544/20000], Loss: 599.2008056640625, Entropy -491.0692138671875, Learning Rate: 0.0001953125\n",
      "Epoch [2545/20000], Loss: 590.1593627929688, Entropy -481.745849609375, Learning Rate: 0.0001953125\n",
      "Epoch [2546/20000], Loss: 593.5516357421875, Entropy -497.1236877441406, Learning Rate: 0.0001953125\n",
      "Epoch [2547/20000], Loss: 590.4395751953125, Entropy -489.3782043457031, Learning Rate: 0.0001953125\n",
      "Epoch [2548/20000], Loss: 592.62451171875, Entropy -480.283203125, Learning Rate: 0.0001953125\n",
      "Epoch [2549/20000], Loss: 600.830078125, Entropy -495.92913818359375, Learning Rate: 0.0001953125\n",
      "Epoch [2550/20000], Loss: 593.6629028320312, Entropy -490.9706115722656, Learning Rate: 0.0001953125\n",
      "Epoch [2551/20000], Loss: 592.8275146484375, Entropy -492.29425048828125, Learning Rate: 0.0001953125\n",
      "Epoch [2552/20000], Loss: 594.735595703125, Entropy -492.45867919921875, Learning Rate: 0.0001953125\n",
      "Epoch [2553/20000], Loss: 588.6832275390625, Entropy -492.76593017578125, Learning Rate: 0.0001953125\n",
      "Epoch [2554/20000], Loss: 586.2813720703125, Entropy -482.5667419433594, Learning Rate: 0.0001953125\n",
      "Epoch [2555/20000], Loss: 586.5435180664062, Entropy -477.6487731933594, Learning Rate: 0.0001953125\n",
      "Epoch [2556/20000], Loss: 592.6158447265625, Entropy -484.9416198730469, Learning Rate: 0.0001953125\n",
      "Epoch [2557/20000], Loss: 584.9122314453125, Entropy -477.7286682128906, Learning Rate: 0.0001953125\n",
      "Epoch [2558/20000], Loss: 610.534912109375, Entropy -509.5298156738281, Learning Rate: 0.0001953125\n",
      "Epoch [2559/20000], Loss: 595.1490478515625, Entropy -475.9371337890625, Learning Rate: 0.0001953125\n",
      "Epoch [2560/20000], Loss: 585.3512573242188, Entropy -477.99432373046875, Learning Rate: 0.0001953125\n",
      "Epoch [2561/20000], Loss: 586.3142700195312, Entropy -482.24176025390625, Learning Rate: 0.0001953125\n",
      "Epoch [2562/20000], Loss: 589.2078857421875, Entropy -486.27886962890625, Learning Rate: 0.0001953125\n",
      "Epoch [2563/20000], Loss: 607.03173828125, Entropy -491.8420715332031, Learning Rate: 0.0001953125\n",
      "Epoch [2564/20000], Loss: 570.2425537109375, Entropy -463.1993408203125, Learning Rate: 0.0001953125\n",
      "Epoch [2565/20000], Loss: 590.6575927734375, Entropy -487.94659423828125, Learning Rate: 0.0001953125\n",
      "Epoch [2566/20000], Loss: 602.6915283203125, Entropy -505.84716796875, Learning Rate: 0.0001953125\n",
      "Epoch [2567/20000], Loss: 583.5433959960938, Entropy -484.3074035644531, Learning Rate: 0.0001953125\n",
      "Epoch [2568/20000], Loss: 588.0933227539062, Entropy -494.95648193359375, Learning Rate: 0.0001953125\n",
      "Epoch [2569/20000], Loss: 604.7169189453125, Entropy -497.12506103515625, Learning Rate: 0.0001953125\n",
      "Epoch [2570/20000], Loss: 591.6876220703125, Entropy -490.849853515625, Learning Rate: 0.0001953125\n",
      "Epoch [2571/20000], Loss: 578.6183471679688, Entropy -472.03216552734375, Learning Rate: 0.0001953125\n",
      "Epoch [2572/20000], Loss: 588.6558837890625, Entropy -483.1523742675781, Learning Rate: 0.0001953125\n",
      "Epoch [2573/20000], Loss: 579.933837890625, Entropy -467.9136962890625, Learning Rate: 0.0001953125\n",
      "Epoch [2574/20000], Loss: 603.236572265625, Entropy -504.69451904296875, Learning Rate: 0.0001953125\n",
      "Epoch [2575/20000], Loss: 598.5982666015625, Entropy -496.0824279785156, Learning Rate: 0.0001953125\n",
      "Epoch [2576/20000], Loss: 580.3884887695312, Entropy -470.3144226074219, Learning Rate: 0.0001953125\n",
      "Epoch [2577/20000], Loss: 603.0142822265625, Entropy -496.22503662109375, Learning Rate: 0.0001953125\n",
      "Epoch [2578/20000], Loss: 573.4189453125, Entropy -474.4289245605469, Learning Rate: 0.0001953125\n",
      "Epoch [2579/20000], Loss: 589.466064453125, Entropy -481.34027099609375, Learning Rate: 0.0001953125\n",
      "Epoch [2580/20000], Loss: 588.7535400390625, Entropy -482.90045166015625, Learning Rate: 0.0001953125\n",
      "Epoch [2581/20000], Loss: 589.2230224609375, Entropy -478.4224853515625, Learning Rate: 0.0001953125\n",
      "Epoch [2582/20000], Loss: 592.90576171875, Entropy -484.22210693359375, Learning Rate: 0.0001953125\n",
      "Epoch [2583/20000], Loss: 582.2460327148438, Entropy -473.75775146484375, Learning Rate: 0.0001953125\n",
      "Epoch [2584/20000], Loss: 587.7449951171875, Entropy -483.74920654296875, Learning Rate: 0.0001953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2585/20000], Loss: 597.7892456054688, Entropy -488.8132019042969, Learning Rate: 0.0001953125\n",
      "Epoch [2586/20000], Loss: 591.0517578125, Entropy -489.24261474609375, Learning Rate: 0.0001953125\n",
      "Epoch [2587/20000], Loss: 579.5443115234375, Entropy -486.89349365234375, Learning Rate: 0.0001953125\n",
      "Epoch [2588/20000], Loss: 598.4183959960938, Entropy -495.59625244140625, Learning Rate: 0.0001953125\n",
      "Epoch [2589/20000], Loss: 581.9385375976562, Entropy -473.89617919921875, Learning Rate: 0.0001953125\n",
      "Epoch [2590/20000], Loss: 588.7769165039062, Entropy -480.5870056152344, Learning Rate: 0.0001953125\n",
      "Epoch [2591/20000], Loss: 596.879638671875, Entropy -491.9566650390625, Learning Rate: 0.0001953125\n",
      "Epoch [2592/20000], Loss: 593.2594604492188, Entropy -473.69580078125, Learning Rate: 0.0001953125\n",
      "Epoch [2593/20000], Loss: 617.8565063476562, Entropy -502.883056640625, Learning Rate: 0.0001953125\n",
      "Epoch [2594/20000], Loss: 594.4918823242188, Entropy -489.58306884765625, Learning Rate: 0.0001953125\n",
      "Epoch [2595/20000], Loss: 597.3977661132812, Entropy -497.4840393066406, Learning Rate: 0.0001953125\n",
      "Epoch [2596/20000], Loss: 583.083251953125, Entropy -474.6324768066406, Learning Rate: 0.0001953125\n",
      "Epoch [2597/20000], Loss: 596.04736328125, Entropy -486.4206848144531, Learning Rate: 0.0001953125\n",
      "Epoch [2598/20000], Loss: 586.158203125, Entropy -491.213134765625, Learning Rate: 0.0001953125\n",
      "Epoch [2599/20000], Loss: 605.7373046875, Entropy -489.95703125, Learning Rate: 0.0001953125\n",
      "Epoch [2600/20000], Loss: 592.005126953125, Entropy -488.60162353515625, Learning Rate: 0.0001953125\n",
      "Epoch [2601/20000], Loss: 587.85595703125, Entropy -482.09765625, Learning Rate: 0.0001953125\n",
      "Epoch [2602/20000], Loss: 590.3479614257812, Entropy -486.7657470703125, Learning Rate: 0.0001953125\n",
      "Epoch [2603/20000], Loss: 588.2788696289062, Entropy -489.3857421875, Learning Rate: 0.0001953125\n",
      "Epoch [2604/20000], Loss: 587.1749877929688, Entropy -487.02191162109375, Learning Rate: 0.0001953125\n",
      "Epoch [2605/20000], Loss: 586.7598266601562, Entropy -468.44256591796875, Learning Rate: 0.0001953125\n",
      "Epoch [2606/20000], Loss: 611.6797485351562, Entropy -505.18841552734375, Learning Rate: 0.0001953125\n",
      "Epoch [2607/20000], Loss: 584.6221923828125, Entropy -489.109619140625, Learning Rate: 0.0001953125\n",
      "Epoch [2608/20000], Loss: 608.1357421875, Entropy -497.93450927734375, Learning Rate: 0.0001953125\n",
      "Epoch [2609/20000], Loss: 583.4868774414062, Entropy -479.1219482421875, Learning Rate: 0.0001953125\n",
      "Epoch [2610/20000], Loss: 588.6930541992188, Entropy -496.96075439453125, Learning Rate: 0.0001953125\n",
      "Epoch [2611/20000], Loss: 612.7598876953125, Entropy -508.6247863769531, Learning Rate: 0.0001953125\n",
      "Epoch [2612/20000], Loss: 596.958251953125, Entropy -488.0252380371094, Learning Rate: 0.0001953125\n",
      "Epoch [2613/20000], Loss: 615.0147705078125, Entropy -475.689453125, Learning Rate: 0.0001953125\n",
      "Epoch [2614/20000], Loss: 601.6810302734375, Entropy -493.0915222167969, Learning Rate: 0.0001953125\n",
      "Epoch [2615/20000], Loss: 589.9662475585938, Entropy -477.11279296875, Learning Rate: 0.0001953125\n",
      "Epoch [2616/20000], Loss: 585.6454467773438, Entropy -495.719482421875, Learning Rate: 0.0001953125\n",
      "Epoch [2617/20000], Loss: 589.2291870117188, Entropy -489.8771667480469, Learning Rate: 0.0001953125\n",
      "Epoch [2618/20000], Loss: 586.0415649414062, Entropy -484.7156677246094, Learning Rate: 0.0001953125\n",
      "Epoch [2619/20000], Loss: 591.5838012695312, Entropy -487.35589599609375, Learning Rate: 0.0001953125\n",
      "Epoch [2620/20000], Loss: 592.660400390625, Entropy -460.7811584472656, Learning Rate: 0.0001953125\n",
      "Epoch [2621/20000], Loss: 622.6193237304688, Entropy -486.54327392578125, Learning Rate: 0.0001953125\n",
      "Epoch [2622/20000], Loss: 592.0824584960938, Entropy -488.7540588378906, Learning Rate: 0.0001953125\n",
      "Epoch [2623/20000], Loss: 602.55029296875, Entropy -486.6778869628906, Learning Rate: 0.0001953125\n",
      "Epoch [2624/20000], Loss: 625.6397094726562, Entropy -499.63494873046875, Learning Rate: 0.0001953125\n",
      "Epoch [2625/20000], Loss: 598.0250244140625, Entropy -486.22479248046875, Learning Rate: 0.0001953125\n",
      "Epoch [2626/20000], Loss: 601.1478271484375, Entropy -495.15643310546875, Learning Rate: 0.0001953125\n",
      "Epoch [2627/20000], Loss: 585.095947265625, Entropy -482.22015380859375, Learning Rate: 0.0001953125\n",
      "Epoch [2628/20000], Loss: 592.4476318359375, Entropy -481.47796630859375, Learning Rate: 0.0001953125\n",
      "Epoch [2629/20000], Loss: 591.528076171875, Entropy -476.86627197265625, Learning Rate: 0.0001953125\n",
      "Epoch [2630/20000], Loss: 582.2326049804688, Entropy -471.140869140625, Learning Rate: 0.0001953125\n",
      "Epoch [2631/20000], Loss: 588.9397583007812, Entropy -490.083984375, Learning Rate: 0.0001953125\n",
      "Epoch [2632/20000], Loss: 595.4133911132812, Entropy -496.51727294921875, Learning Rate: 0.0001953125\n",
      "Epoch [2633/20000], Loss: 596.437744140625, Entropy -508.47998046875, Learning Rate: 0.0001953125\n",
      "Epoch [2634/20000], Loss: 579.6943359375, Entropy -472.50323486328125, Learning Rate: 0.0001953125\n",
      "Epoch [2635/20000], Loss: 594.232666015625, Entropy -488.5090637207031, Learning Rate: 0.0001953125\n",
      "Epoch [2636/20000], Loss: 575.2528686523438, Entropy -468.54522705078125, Learning Rate: 0.0001953125\n",
      "Epoch [2637/20000], Loss: 603.1676025390625, Entropy -491.8262939453125, Learning Rate: 0.0001953125\n",
      "Epoch [2638/20000], Loss: 591.8743896484375, Entropy -479.1915283203125, Learning Rate: 0.0001953125\n",
      "Epoch [2639/20000], Loss: 590.373779296875, Entropy -489.4020690917969, Learning Rate: 0.0001953125\n",
      "Epoch [2640/20000], Loss: 591.5059814453125, Entropy -488.8455810546875, Learning Rate: 0.0001953125\n",
      "Epoch [2641/20000], Loss: 589.317138671875, Entropy -485.57281494140625, Learning Rate: 0.0001953125\n",
      "Epoch [2642/20000], Loss: 599.4017333984375, Entropy -504.42535400390625, Learning Rate: 0.0001953125\n",
      "Epoch [2643/20000], Loss: 595.5, Entropy -494.7716369628906, Learning Rate: 0.0001953125\n",
      "Epoch [2644/20000], Loss: 598.848876953125, Entropy -490.7817687988281, Learning Rate: 0.0001953125\n",
      "Epoch [2645/20000], Loss: 595.2369384765625, Entropy -501.98541259765625, Learning Rate: 0.0001953125\n",
      "Epoch [2646/20000], Loss: 588.4496459960938, Entropy -493.24615478515625, Learning Rate: 0.0001953125\n",
      "Epoch [2647/20000], Loss: 602.3557739257812, Entropy -505.700927734375, Learning Rate: 0.0001953125\n",
      "Epoch [2648/20000], Loss: 593.1484985351562, Entropy -478.05535888671875, Learning Rate: 0.0001953125\n",
      "Epoch [2649/20000], Loss: 581.637451171875, Entropy -478.53955078125, Learning Rate: 0.0001953125\n",
      "Epoch [2650/20000], Loss: 622.540283203125, Entropy -503.1924133300781, Learning Rate: 0.0001953125\n",
      "Epoch [2651/20000], Loss: 601.824462890625, Entropy -504.79510498046875, Learning Rate: 0.0001953125\n",
      "Epoch [2652/20000], Loss: 592.8526611328125, Entropy -487.89569091796875, Learning Rate: 0.0001953125\n",
      "Epoch [2653/20000], Loss: 593.53857421875, Entropy -487.0360412597656, Learning Rate: 0.0001953125\n",
      "Epoch [2654/20000], Loss: 584.3668823242188, Entropy -485.3180236816406, Learning Rate: 0.0001953125\n",
      "Epoch [2655/20000], Loss: 588.7553100585938, Entropy -477.56854248046875, Learning Rate: 0.0001953125\n",
      "Epoch [2656/20000], Loss: 586.2534790039062, Entropy -482.99114990234375, Learning Rate: 0.0001953125\n",
      "Epoch [2657/20000], Loss: 601.8870849609375, Entropy -508.5481872558594, Learning Rate: 0.0001953125\n",
      "Epoch [2658/20000], Loss: 618.0521850585938, Entropy -483.6841735839844, Learning Rate: 0.0001953125\n",
      "Epoch [2659/20000], Loss: 622.7677001953125, Entropy -509.94268798828125, Learning Rate: 0.0001953125\n",
      "Epoch [2660/20000], Loss: 582.5509643554688, Entropy -475.8006591796875, Learning Rate: 0.0001953125\n",
      "Epoch [2661/20000], Loss: 580.4274291992188, Entropy -479.5673828125, Learning Rate: 0.0001953125\n",
      "Epoch [2662/20000], Loss: 592.39599609375, Entropy -497.5782775878906, Learning Rate: 0.0001953125\n",
      "Epoch [2663/20000], Loss: 595.332275390625, Entropy -474.5357360839844, Learning Rate: 0.0001953125\n",
      "Epoch [2664/20000], Loss: 578.895751953125, Entropy -463.32354736328125, Learning Rate: 0.0001953125\n",
      "Epoch [2665/20000], Loss: 584.73486328125, Entropy -469.47052001953125, Learning Rate: 0.0001953125\n",
      "Epoch [2666/20000], Loss: 587.9902954101562, Entropy -471.786376953125, Learning Rate: 9.765625e-05\n",
      "Epoch [2667/20000], Loss: 595.9345703125, Entropy -493.0081787109375, Learning Rate: 9.765625e-05\n",
      "Epoch [2668/20000], Loss: 602.31201171875, Entropy -485.4488525390625, Learning Rate: 9.765625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2669/20000], Loss: 569.7042846679688, Entropy -473.85308837890625, Learning Rate: 9.765625e-05\n",
      "Epoch [2670/20000], Loss: 589.1417236328125, Entropy -490.3517150878906, Learning Rate: 9.765625e-05\n",
      "Epoch [2671/20000], Loss: 590.9493408203125, Entropy -500.06744384765625, Learning Rate: 9.765625e-05\n",
      "Epoch [2672/20000], Loss: 592.26513671875, Entropy -478.29119873046875, Learning Rate: 9.765625e-05\n",
      "Epoch [2673/20000], Loss: 592.6072998046875, Entropy -495.3506774902344, Learning Rate: 9.765625e-05\n",
      "Epoch [2674/20000], Loss: 602.1522216796875, Entropy -497.03668212890625, Learning Rate: 9.765625e-05\n",
      "Epoch [2675/20000], Loss: 581.2857055664062, Entropy -479.30133056640625, Learning Rate: 9.765625e-05\n",
      "Epoch [2676/20000], Loss: 598.418212890625, Entropy -494.87554931640625, Learning Rate: 9.765625e-05\n",
      "Epoch [2677/20000], Loss: 589.0357666015625, Entropy -488.442626953125, Learning Rate: 9.765625e-05\n",
      "Epoch [2678/20000], Loss: 592.6245727539062, Entropy -476.53070068359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2679/20000], Loss: 583.966796875, Entropy -484.95880126953125, Learning Rate: 9.765625e-05\n",
      "Epoch [2680/20000], Loss: 597.78564453125, Entropy -503.396240234375, Learning Rate: 9.765625e-05\n",
      "Epoch [2681/20000], Loss: 595.2427978515625, Entropy -494.4288330078125, Learning Rate: 9.765625e-05\n",
      "Epoch [2682/20000], Loss: 599.1724853515625, Entropy -495.5543212890625, Learning Rate: 9.765625e-05\n",
      "Epoch [2683/20000], Loss: 594.5137939453125, Entropy -496.71051025390625, Learning Rate: 9.765625e-05\n",
      "Epoch [2684/20000], Loss: 594.6251831054688, Entropy -495.60394287109375, Learning Rate: 9.765625e-05\n",
      "Epoch [2685/20000], Loss: 587.9041748046875, Entropy -488.60870361328125, Learning Rate: 9.765625e-05\n",
      "Epoch [2686/20000], Loss: 591.3262329101562, Entropy -488.46038818359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2687/20000], Loss: 596.819091796875, Entropy -496.6995544433594, Learning Rate: 9.765625e-05\n",
      "Epoch [2688/20000], Loss: 591.47802734375, Entropy -498.1085205078125, Learning Rate: 9.765625e-05\n",
      "Epoch [2689/20000], Loss: 615.2591552734375, Entropy -506.92242431640625, Learning Rate: 9.765625e-05\n",
      "Epoch [2690/20000], Loss: 622.8991088867188, Entropy -502.1043701171875, Learning Rate: 9.765625e-05\n",
      "Epoch [2691/20000], Loss: 606.6695556640625, Entropy -509.6042785644531, Learning Rate: 9.765625e-05\n",
      "Epoch [2692/20000], Loss: 579.012451171875, Entropy -474.1006774902344, Learning Rate: 9.765625e-05\n",
      "Epoch [2693/20000], Loss: 601.135009765625, Entropy -496.39971923828125, Learning Rate: 9.765625e-05\n",
      "Epoch [2694/20000], Loss: 590.8675537109375, Entropy -489.48101806640625, Learning Rate: 9.765625e-05\n",
      "Epoch [2695/20000], Loss: 592.0838012695312, Entropy -481.9656982421875, Learning Rate: 9.765625e-05\n",
      "Epoch [2696/20000], Loss: 586.9090576171875, Entropy -477.16448974609375, Learning Rate: 9.765625e-05\n",
      "Epoch [2697/20000], Loss: 583.1160278320312, Entropy -483.0652160644531, Learning Rate: 9.765625e-05\n",
      "Epoch [2698/20000], Loss: 594.3297729492188, Entropy -496.19989013671875, Learning Rate: 9.765625e-05\n",
      "Epoch [2699/20000], Loss: 598.518798828125, Entropy -496.86181640625, Learning Rate: 9.765625e-05\n",
      "Epoch [2700/20000], Loss: 604.6290283203125, Entropy -485.10565185546875, Learning Rate: 9.765625e-05\n",
      "Epoch [2701/20000], Loss: 601.675048828125, Entropy -502.7002258300781, Learning Rate: 9.765625e-05\n",
      "Epoch [2702/20000], Loss: 579.1219482421875, Entropy -480.05126953125, Learning Rate: 9.765625e-05\n",
      "Epoch [2703/20000], Loss: 597.0164184570312, Entropy -498.54541015625, Learning Rate: 9.765625e-05\n",
      "Epoch [2704/20000], Loss: 573.3515014648438, Entropy -463.427001953125, Learning Rate: 9.765625e-05\n",
      "Epoch [2705/20000], Loss: 593.922119140625, Entropy -492.2474365234375, Learning Rate: 9.765625e-05\n",
      "Epoch [2706/20000], Loss: 591.1024780273438, Entropy -489.1043701171875, Learning Rate: 9.765625e-05\n",
      "Epoch [2707/20000], Loss: 583.7593383789062, Entropy -482.7887268066406, Learning Rate: 9.765625e-05\n",
      "Epoch [2708/20000], Loss: 593.0249633789062, Entropy -487.18634033203125, Learning Rate: 9.765625e-05\n",
      "Epoch [2709/20000], Loss: 587.922607421875, Entropy -491.3166809082031, Learning Rate: 9.765625e-05\n",
      "Epoch [2710/20000], Loss: 582.1084594726562, Entropy -480.6878662109375, Learning Rate: 9.765625e-05\n",
      "Epoch [2711/20000], Loss: 604.1883544921875, Entropy -502.5929260253906, Learning Rate: 9.765625e-05\n",
      "Epoch [2712/20000], Loss: 595.9263916015625, Entropy -499.80712890625, Learning Rate: 9.765625e-05\n",
      "Epoch [2713/20000], Loss: 592.4961547851562, Entropy -487.2674255371094, Learning Rate: 9.765625e-05\n",
      "Epoch [2714/20000], Loss: 595.5640869140625, Entropy -494.4837341308594, Learning Rate: 9.765625e-05\n",
      "Epoch [2715/20000], Loss: 595.15966796875, Entropy -490.2525329589844, Learning Rate: 9.765625e-05\n",
      "Epoch [2716/20000], Loss: 584.3936157226562, Entropy -475.93109130859375, Learning Rate: 9.765625e-05\n",
      "Epoch [2717/20000], Loss: 585.1385498046875, Entropy -475.86187744140625, Learning Rate: 9.765625e-05\n",
      "Epoch [2718/20000], Loss: 592.5023193359375, Entropy -485.31561279296875, Learning Rate: 9.765625e-05\n",
      "Epoch [2719/20000], Loss: 597.4156494140625, Entropy -504.61627197265625, Learning Rate: 9.765625e-05\n",
      "Epoch [2720/20000], Loss: 590.5039672851562, Entropy -480.77410888671875, Learning Rate: 9.765625e-05\n",
      "Epoch [2721/20000], Loss: 577.9696655273438, Entropy -471.628662109375, Learning Rate: 9.765625e-05\n",
      "Epoch [2722/20000], Loss: 578.391357421875, Entropy -478.60736083984375, Learning Rate: 9.765625e-05\n",
      "Epoch [2723/20000], Loss: 592.51806640625, Entropy -489.1412658691406, Learning Rate: 9.765625e-05\n",
      "Epoch [2724/20000], Loss: 605.3836669921875, Entropy -504.72857666015625, Learning Rate: 9.765625e-05\n",
      "Epoch [2725/20000], Loss: 597.5484008789062, Entropy -487.580322265625, Learning Rate: 9.765625e-05\n",
      "Epoch [2726/20000], Loss: 603.897216796875, Entropy -498.0179443359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2727/20000], Loss: 592.0045776367188, Entropy -477.36376953125, Learning Rate: 9.765625e-05\n",
      "Epoch [2728/20000], Loss: 600.7969970703125, Entropy -499.36822509765625, Learning Rate: 9.765625e-05\n",
      "Epoch [2729/20000], Loss: 592.2722778320312, Entropy -489.526611328125, Learning Rate: 9.765625e-05\n",
      "Epoch [2730/20000], Loss: 604.6522827148438, Entropy -499.33172607421875, Learning Rate: 9.765625e-05\n",
      "Epoch [2731/20000], Loss: 573.0071411132812, Entropy -467.1128234863281, Learning Rate: 9.765625e-05\n",
      "Epoch [2732/20000], Loss: 585.7672119140625, Entropy -484.45599365234375, Learning Rate: 9.765625e-05\n",
      "Epoch [2733/20000], Loss: 609.2196044921875, Entropy -495.31640625, Learning Rate: 9.765625e-05\n",
      "Epoch [2734/20000], Loss: 587.622802734375, Entropy -482.81976318359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2735/20000], Loss: 599.8510131835938, Entropy -484.52197265625, Learning Rate: 9.765625e-05\n",
      "Epoch [2736/20000], Loss: 602.6187744140625, Entropy -500.94049072265625, Learning Rate: 9.765625e-05\n",
      "Epoch [2737/20000], Loss: 573.815673828125, Entropy -473.6571960449219, Learning Rate: 9.765625e-05\n",
      "Epoch [2738/20000], Loss: 592.2382202148438, Entropy -490.67608642578125, Learning Rate: 9.765625e-05\n",
      "Epoch [2739/20000], Loss: 591.2752075195312, Entropy -484.35101318359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2740/20000], Loss: 596.386474609375, Entropy -487.344482421875, Learning Rate: 9.765625e-05\n",
      "Epoch [2741/20000], Loss: 592.555419921875, Entropy -479.36651611328125, Learning Rate: 9.765625e-05\n",
      "Epoch [2742/20000], Loss: 587.06103515625, Entropy -482.039794921875, Learning Rate: 9.765625e-05\n",
      "Epoch [2743/20000], Loss: 597.2349853515625, Entropy -492.49029541015625, Learning Rate: 9.765625e-05\n",
      "Epoch [2744/20000], Loss: 596.8405151367188, Entropy -498.8687744140625, Learning Rate: 9.765625e-05\n",
      "Epoch [2745/20000], Loss: 575.692626953125, Entropy -468.401123046875, Learning Rate: 9.765625e-05\n",
      "Epoch [2746/20000], Loss: 608.8582153320312, Entropy -504.6239929199219, Learning Rate: 9.765625e-05\n",
      "Epoch [2747/20000], Loss: 630.722900390625, Entropy -518.926025390625, Learning Rate: 9.765625e-05\n",
      "Epoch [2748/20000], Loss: 587.8648681640625, Entropy -486.9108581542969, Learning Rate: 9.765625e-05\n",
      "Epoch [2749/20000], Loss: 588.8575439453125, Entropy -491.236328125, Learning Rate: 9.765625e-05\n",
      "Epoch [2750/20000], Loss: 601.6104125976562, Entropy -499.787353515625, Learning Rate: 9.765625e-05\n",
      "Epoch [2751/20000], Loss: 631.949462890625, Entropy -514.90283203125, Learning Rate: 9.765625e-05\n",
      "Epoch [2752/20000], Loss: 587.7347412109375, Entropy -491.78253173828125, Learning Rate: 9.765625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2753/20000], Loss: 595.8031005859375, Entropy -493.18695068359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2754/20000], Loss: 603.9057006835938, Entropy -492.16778564453125, Learning Rate: 9.765625e-05\n",
      "Epoch [2755/20000], Loss: 588.6478271484375, Entropy -497.76422119140625, Learning Rate: 9.765625e-05\n",
      "Epoch [2756/20000], Loss: 592.2569580078125, Entropy -492.219970703125, Learning Rate: 9.765625e-05\n",
      "Epoch [2757/20000], Loss: 606.1103515625, Entropy -500.70281982421875, Learning Rate: 9.765625e-05\n",
      "Epoch [2758/20000], Loss: 591.7623901367188, Entropy -492.14093017578125, Learning Rate: 9.765625e-05\n",
      "Epoch [2759/20000], Loss: 572.1866455078125, Entropy -456.0252685546875, Learning Rate: 9.765625e-05\n",
      "Epoch [2760/20000], Loss: 591.5936279296875, Entropy -490.29888916015625, Learning Rate: 9.765625e-05\n",
      "Epoch [2761/20000], Loss: 594.4791870117188, Entropy -490.2327880859375, Learning Rate: 9.765625e-05\n",
      "Epoch [2762/20000], Loss: 596.7313842773438, Entropy -485.46417236328125, Learning Rate: 9.765625e-05\n",
      "Epoch [2763/20000], Loss: 593.4729614257812, Entropy -486.5341796875, Learning Rate: 9.765625e-05\n",
      "Epoch [2764/20000], Loss: 586.7938842773438, Entropy -488.51116943359375, Learning Rate: 9.765625e-05\n",
      "Epoch [2765/20000], Loss: 578.962646484375, Entropy -485.97125244140625, Learning Rate: 9.765625e-05\n",
      "Epoch [2766/20000], Loss: 602.13525390625, Entropy -502.3943786621094, Learning Rate: 9.765625e-05\n",
      "Epoch [2767/20000], Loss: 596.0314331054688, Entropy -489.28216552734375, Learning Rate: 9.765625e-05\n",
      "Epoch [2768/20000], Loss: 613.3621215820312, Entropy -509.414794921875, Learning Rate: 9.765625e-05\n",
      "Epoch [2769/20000], Loss: 596.699462890625, Entropy -500.7964172363281, Learning Rate: 9.765625e-05\n",
      "Epoch [2770/20000], Loss: 587.7236328125, Entropy -477.097412109375, Learning Rate: 9.765625e-05\n",
      "Epoch [2771/20000], Loss: 593.15380859375, Entropy -489.79046630859375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2772/20000], Loss: 595.3016967773438, Entropy -468.2237854003906, Learning Rate: 4.8828125e-05\n",
      "Epoch [2773/20000], Loss: 608.2701416015625, Entropy -511.9028015136719, Learning Rate: 4.8828125e-05\n",
      "Epoch [2774/20000], Loss: 600.080078125, Entropy -497.88592529296875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2775/20000], Loss: 630.1708374023438, Entropy -500.29986572265625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2776/20000], Loss: 583.5797119140625, Entropy -486.1171569824219, Learning Rate: 4.8828125e-05\n",
      "Epoch [2777/20000], Loss: 584.3502197265625, Entropy -463.96148681640625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2778/20000], Loss: 618.0547485351562, Entropy -521.952392578125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2779/20000], Loss: 600.4530639648438, Entropy -500.12530517578125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2780/20000], Loss: 582.9349975585938, Entropy -466.7831726074219, Learning Rate: 4.8828125e-05\n",
      "Epoch [2781/20000], Loss: 585.8422241210938, Entropy -481.52899169921875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2782/20000], Loss: 605.6448974609375, Entropy -499.10888671875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2783/20000], Loss: 597.245849609375, Entropy -484.325927734375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2784/20000], Loss: 602.1796875, Entropy -480.7159423828125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2785/20000], Loss: 601.7333984375, Entropy -486.2178955078125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2786/20000], Loss: 588.42578125, Entropy -479.3087463378906, Learning Rate: 4.8828125e-05\n",
      "Epoch [2787/20000], Loss: 594.9593505859375, Entropy -492.40423583984375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2788/20000], Loss: 603.71044921875, Entropy -510.3424072265625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2789/20000], Loss: 572.7786865234375, Entropy -462.9150390625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2790/20000], Loss: 597.78564453125, Entropy -492.2825927734375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2791/20000], Loss: 604.784423828125, Entropy -485.6289367675781, Learning Rate: 4.8828125e-05\n",
      "Epoch [2792/20000], Loss: 582.087158203125, Entropy -472.6055908203125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2793/20000], Loss: 587.8672485351562, Entropy -473.037353515625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2794/20000], Loss: 571.5176391601562, Entropy -465.90496826171875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2795/20000], Loss: 599.6776123046875, Entropy -490.7662353515625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2796/20000], Loss: 577.8467407226562, Entropy -476.7351989746094, Learning Rate: 4.8828125e-05\n",
      "Epoch [2797/20000], Loss: 603.2777709960938, Entropy -507.2003479003906, Learning Rate: 4.8828125e-05\n",
      "Epoch [2798/20000], Loss: 601.6983032226562, Entropy -509.56005859375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2799/20000], Loss: 621.7702026367188, Entropy -519.6712646484375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2800/20000], Loss: 594.85400390625, Entropy -480.61810302734375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2801/20000], Loss: 601.5928955078125, Entropy -501.8436279296875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2802/20000], Loss: 600.2069702148438, Entropy -501.31390380859375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2803/20000], Loss: 604.48095703125, Entropy -490.47088623046875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2804/20000], Loss: 592.52783203125, Entropy -480.44537353515625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2805/20000], Loss: 604.2147827148438, Entropy -492.3508605957031, Learning Rate: 4.8828125e-05\n",
      "Epoch [2806/20000], Loss: 594.8751220703125, Entropy -492.14227294921875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2807/20000], Loss: 608.1138916015625, Entropy -491.648193359375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2808/20000], Loss: 593.4432373046875, Entropy -493.09161376953125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2809/20000], Loss: 584.1378173828125, Entropy -482.10198974609375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2810/20000], Loss: 583.2967529296875, Entropy -479.2545166015625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2811/20000], Loss: 586.802001953125, Entropy -491.1004638671875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2812/20000], Loss: 598.8391723632812, Entropy -492.707763671875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2813/20000], Loss: 599.4105224609375, Entropy -496.44091796875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2814/20000], Loss: 598.5936279296875, Entropy -492.30938720703125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2815/20000], Loss: 579.0050048828125, Entropy -477.00384521484375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2816/20000], Loss: 591.9878540039062, Entropy -479.5619812011719, Learning Rate: 4.8828125e-05\n",
      "Epoch [2817/20000], Loss: 591.727783203125, Entropy -490.0313415527344, Learning Rate: 4.8828125e-05\n",
      "Epoch [2818/20000], Loss: 599.9580688476562, Entropy -500.45440673828125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2819/20000], Loss: 599.9430541992188, Entropy -491.6599426269531, Learning Rate: 4.8828125e-05\n",
      "Epoch [2820/20000], Loss: 601.9285888671875, Entropy -501.8839111328125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2821/20000], Loss: 598.8612060546875, Entropy -489.9014892578125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2822/20000], Loss: 602.7233276367188, Entropy -502.18377685546875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2823/20000], Loss: 585.057861328125, Entropy -475.1465759277344, Learning Rate: 4.8828125e-05\n",
      "Epoch [2824/20000], Loss: 584.5618896484375, Entropy -479.18804931640625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2825/20000], Loss: 596.7249145507812, Entropy -490.3470458984375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2826/20000], Loss: 606.8565673828125, Entropy -503.33905029296875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2827/20000], Loss: 595.0650024414062, Entropy -493.8470458984375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2828/20000], Loss: 596.9067993164062, Entropy -490.11712646484375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2829/20000], Loss: 586.7031860351562, Entropy -481.0350341796875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2830/20000], Loss: 599.865966796875, Entropy -488.6669616699219, Learning Rate: 4.8828125e-05\n",
      "Epoch [2831/20000], Loss: 596.973876953125, Entropy -497.189697265625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2832/20000], Loss: 591.19970703125, Entropy -478.5166931152344, Learning Rate: 4.8828125e-05\n",
      "Epoch [2833/20000], Loss: 591.8714599609375, Entropy -498.3022155761719, Learning Rate: 4.8828125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2834/20000], Loss: 592.277587890625, Entropy -491.0062561035156, Learning Rate: 4.8828125e-05\n",
      "Epoch [2835/20000], Loss: 592.3685302734375, Entropy -489.22491455078125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2836/20000], Loss: 582.0064697265625, Entropy -480.5738525390625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2837/20000], Loss: 585.4887084960938, Entropy -481.75140380859375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2838/20000], Loss: 594.963623046875, Entropy -476.65814208984375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2839/20000], Loss: 596.0894775390625, Entropy -494.085693359375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2840/20000], Loss: 588.0484619140625, Entropy -477.5855712890625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2841/20000], Loss: 601.52783203125, Entropy -493.3597717285156, Learning Rate: 4.8828125e-05\n",
      "Epoch [2842/20000], Loss: 599.4033203125, Entropy -501.75982666015625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2843/20000], Loss: 575.133056640625, Entropy -469.34844970703125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2844/20000], Loss: 600.9414672851562, Entropy -501.45965576171875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2845/20000], Loss: 609.3145751953125, Entropy -507.3765869140625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2846/20000], Loss: 592.69775390625, Entropy -492.6958923339844, Learning Rate: 4.8828125e-05\n",
      "Epoch [2847/20000], Loss: 584.4296264648438, Entropy -475.55194091796875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2848/20000], Loss: 584.78466796875, Entropy -480.4148254394531, Learning Rate: 4.8828125e-05\n",
      "Epoch [2849/20000], Loss: 598.3343505859375, Entropy -487.43634033203125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2850/20000], Loss: 583.9512329101562, Entropy -475.44830322265625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2851/20000], Loss: 584.552490234375, Entropy -473.830078125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2852/20000], Loss: 592.103759765625, Entropy -490.9851989746094, Learning Rate: 4.8828125e-05\n",
      "Epoch [2853/20000], Loss: 587.919921875, Entropy -477.97271728515625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2854/20000], Loss: 593.3283081054688, Entropy -482.6163330078125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2855/20000], Loss: 601.1026611328125, Entropy -499.9873046875, Learning Rate: 4.8828125e-05\n",
      "Epoch [2856/20000], Loss: 599.8623046875, Entropy -504.9054870605469, Learning Rate: 4.8828125e-05\n",
      "Epoch [2857/20000], Loss: 593.232666015625, Entropy -491.322265625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2858/20000], Loss: 595.6846923828125, Entropy -492.11566162109375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2859/20000], Loss: 587.5775146484375, Entropy -492.6585693359375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2860/20000], Loss: 601.6000366210938, Entropy -496.21966552734375, Learning Rate: 4.8828125e-05\n",
      "Epoch [2861/20000], Loss: 604.104736328125, Entropy -512.2047119140625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2862/20000], Loss: 588.1249389648438, Entropy -487.7596740722656, Learning Rate: 4.8828125e-05\n",
      "Epoch [2863/20000], Loss: 595.016845703125, Entropy -497.77545166015625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2864/20000], Loss: 588.3974609375, Entropy -456.15289306640625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2865/20000], Loss: 584.4080200195312, Entropy -490.3127136230469, Learning Rate: 4.8828125e-05\n",
      "Epoch [2866/20000], Loss: 579.1995849609375, Entropy -474.67388916015625, Learning Rate: 4.8828125e-05\n",
      "Epoch [2867/20000], Loss: 604.2858276367188, Entropy -493.3193054199219, Learning Rate: 4.8828125e-05\n",
      "Epoch [2868/20000], Loss: 582.3026123046875, Entropy -475.9684143066406, Learning Rate: 4.8828125e-05\n",
      "Epoch [2869/20000], Loss: 600.978515625, Entropy -493.602783203125, Learning Rate: 4.8828125e-05\n",
      "Epoch [2870/20000], Loss: 599.1841430664062, Entropy -493.3843688964844, Learning Rate: 4.8828125e-05\n",
      "Epoch [2871/20000], Loss: 602.9910888671875, Entropy -496.0396423339844, Learning Rate: 4.8828125e-05\n",
      "Epoch [2872/20000], Loss: 590.061279296875, Entropy -479.92718505859375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2873/20000], Loss: 608.6796875, Entropy -509.69244384765625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2874/20000], Loss: 599.4987182617188, Entropy -498.5771179199219, Learning Rate: 2.44140625e-05\n",
      "Epoch [2875/20000], Loss: 578.1556396484375, Entropy -473.176025390625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2876/20000], Loss: 603.7879638671875, Entropy -505.11358642578125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2877/20000], Loss: 598.6287841796875, Entropy -502.578369140625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2878/20000], Loss: 585.6771240234375, Entropy -489.1669921875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2879/20000], Loss: 596.5931396484375, Entropy -489.77142333984375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2880/20000], Loss: 573.1131591796875, Entropy -469.1131591796875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2881/20000], Loss: 574.1318969726562, Entropy -466.1332092285156, Learning Rate: 2.44140625e-05\n",
      "Epoch [2882/20000], Loss: 599.6884765625, Entropy -503.2391662597656, Learning Rate: 2.44140625e-05\n",
      "Epoch [2883/20000], Loss: 602.722900390625, Entropy -492.6373291015625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2884/20000], Loss: 592.802734375, Entropy -481.7160339355469, Learning Rate: 2.44140625e-05\n",
      "Epoch [2885/20000], Loss: 586.14453125, Entropy -481.474853515625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2886/20000], Loss: 604.6445922851562, Entropy -490.8173828125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2887/20000], Loss: 590.2241821289062, Entropy -489.861083984375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2888/20000], Loss: 591.236328125, Entropy -477.5965881347656, Learning Rate: 2.44140625e-05\n",
      "Epoch [2889/20000], Loss: 596.2067260742188, Entropy -486.9796142578125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2890/20000], Loss: 581.312255859375, Entropy -480.79412841796875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2891/20000], Loss: 601.9478759765625, Entropy -504.1771545410156, Learning Rate: 2.44140625e-05\n",
      "Epoch [2892/20000], Loss: 573.6226806640625, Entropy -456.68206787109375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2893/20000], Loss: 603.8016357421875, Entropy -508.24285888671875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2894/20000], Loss: 590.703369140625, Entropy -485.41094970703125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2895/20000], Loss: 595.5133056640625, Entropy -493.18878173828125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2896/20000], Loss: 605.5154418945312, Entropy -484.300048828125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2897/20000], Loss: 588.4711303710938, Entropy -494.6898193359375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2898/20000], Loss: 586.5379028320312, Entropy -470.7359619140625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2899/20000], Loss: 586.880126953125, Entropy -480.22198486328125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2900/20000], Loss: 588.8643798828125, Entropy -492.033203125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2901/20000], Loss: 607.4788208007812, Entropy -501.3212585449219, Learning Rate: 2.44140625e-05\n",
      "Epoch [2902/20000], Loss: 583.2396240234375, Entropy -473.4205322265625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2903/20000], Loss: 583.4024658203125, Entropy -490.0858459472656, Learning Rate: 2.44140625e-05\n",
      "Epoch [2904/20000], Loss: 579.6941528320312, Entropy -470.9818420410156, Learning Rate: 2.44140625e-05\n",
      "Epoch [2905/20000], Loss: 589.7303466796875, Entropy -492.886474609375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2906/20000], Loss: 609.1499633789062, Entropy -489.863525390625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2907/20000], Loss: 593.797119140625, Entropy -495.58111572265625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2908/20000], Loss: 610.1094360351562, Entropy -513.9323120117188, Learning Rate: 2.44140625e-05\n",
      "Epoch [2909/20000], Loss: 579.86865234375, Entropy -485.2635498046875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2910/20000], Loss: 604.1105346679688, Entropy -498.04534912109375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2911/20000], Loss: 587.7285766601562, Entropy -481.8433837890625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2912/20000], Loss: 586.9794921875, Entropy -478.9819641113281, Learning Rate: 2.44140625e-05\n",
      "Epoch [2913/20000], Loss: 589.6901245117188, Entropy -494.0526428222656, Learning Rate: 2.44140625e-05\n",
      "Epoch [2914/20000], Loss: 597.6300048828125, Entropy -494.566650390625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2915/20000], Loss: 603.0638427734375, Entropy -500.510009765625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2916/20000], Loss: 609.0352172851562, Entropy -498.04132080078125, Learning Rate: 2.44140625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2917/20000], Loss: 580.8300170898438, Entropy -471.3840026855469, Learning Rate: 2.44140625e-05\n",
      "Epoch [2918/20000], Loss: 584.1301879882812, Entropy -471.1512756347656, Learning Rate: 2.44140625e-05\n",
      "Epoch [2919/20000], Loss: 592.6856689453125, Entropy -491.9746398925781, Learning Rate: 2.44140625e-05\n",
      "Epoch [2920/20000], Loss: 597.7685546875, Entropy -490.0811767578125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2921/20000], Loss: 591.4967651367188, Entropy -478.1888122558594, Learning Rate: 2.44140625e-05\n",
      "Epoch [2922/20000], Loss: 587.2245483398438, Entropy -477.246826171875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2923/20000], Loss: 598.2127075195312, Entropy -505.13079833984375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2924/20000], Loss: 581.31591796875, Entropy -474.7220458984375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2925/20000], Loss: 585.3972778320312, Entropy -480.8480224609375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2926/20000], Loss: 584.697998046875, Entropy -487.992431640625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2927/20000], Loss: 589.6117553710938, Entropy -473.31707763671875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2928/20000], Loss: 578.9978637695312, Entropy -473.24591064453125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2929/20000], Loss: 604.0528564453125, Entropy -494.6729431152344, Learning Rate: 2.44140625e-05\n",
      "Epoch [2930/20000], Loss: 582.7216186523438, Entropy -476.2882995605469, Learning Rate: 2.44140625e-05\n",
      "Epoch [2931/20000], Loss: 585.83203125, Entropy -480.45538330078125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2932/20000], Loss: 588.3614501953125, Entropy -488.2164611816406, Learning Rate: 2.44140625e-05\n",
      "Epoch [2933/20000], Loss: 605.3455810546875, Entropy -497.54010009765625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2934/20000], Loss: 576.3743286132812, Entropy -474.4779968261719, Learning Rate: 2.44140625e-05\n",
      "Epoch [2935/20000], Loss: 588.118896484375, Entropy -489.32269287109375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2936/20000], Loss: 587.32568359375, Entropy -493.3885498046875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2937/20000], Loss: 576.4270629882812, Entropy -467.56805419921875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2938/20000], Loss: 593.0070190429688, Entropy -497.401611328125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2939/20000], Loss: 588.8257446289062, Entropy -475.62054443359375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2940/20000], Loss: 636.4892578125, Entropy -511.9154052734375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2941/20000], Loss: 621.5564575195312, Entropy -488.754638671875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2942/20000], Loss: 600.32373046875, Entropy -497.97625732421875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2943/20000], Loss: 588.0121459960938, Entropy -490.8594055175781, Learning Rate: 2.44140625e-05\n",
      "Epoch [2944/20000], Loss: 600.6668701171875, Entropy -496.98455810546875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2945/20000], Loss: 586.336181640625, Entropy -472.75628662109375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2946/20000], Loss: 596.4828491210938, Entropy -486.5606994628906, Learning Rate: 2.44140625e-05\n",
      "Epoch [2947/20000], Loss: 594.1341552734375, Entropy -498.9933166503906, Learning Rate: 2.44140625e-05\n",
      "Epoch [2948/20000], Loss: 598.565185546875, Entropy -500.30224609375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2949/20000], Loss: 592.026611328125, Entropy -492.792236328125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2950/20000], Loss: 601.8551025390625, Entropy -499.1292724609375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2951/20000], Loss: 609.5623168945312, Entropy -510.53070068359375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2952/20000], Loss: 597.498291015625, Entropy -499.9765319824219, Learning Rate: 2.44140625e-05\n",
      "Epoch [2953/20000], Loss: 595.697998046875, Entropy -498.9490051269531, Learning Rate: 2.44140625e-05\n",
      "Epoch [2954/20000], Loss: 596.7183227539062, Entropy -489.00360107421875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2955/20000], Loss: 623.2265625, Entropy -519.9664306640625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2956/20000], Loss: 600.92236328125, Entropy -497.4402770996094, Learning Rate: 2.44140625e-05\n",
      "Epoch [2957/20000], Loss: 598.4664916992188, Entropy -485.8848876953125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2958/20000], Loss: 579.5594482421875, Entropy -482.38690185546875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2959/20000], Loss: 582.9102783203125, Entropy -471.76776123046875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2960/20000], Loss: 598.3740844726562, Entropy -493.2081298828125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2961/20000], Loss: 590.5593872070312, Entropy -505.1434326171875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2962/20000], Loss: 594.6705322265625, Entropy -476.2798767089844, Learning Rate: 2.44140625e-05\n",
      "Epoch [2963/20000], Loss: 598.223876953125, Entropy -475.6204833984375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2964/20000], Loss: 580.1942138671875, Entropy -464.41082763671875, Learning Rate: 2.44140625e-05\n",
      "Epoch [2965/20000], Loss: 600.7225341796875, Entropy -491.8890380859375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2966/20000], Loss: 586.8292846679688, Entropy -482.29290771484375, Learning Rate: 2.44140625e-05\n",
      "Epoch [2967/20000], Loss: 586.8861694335938, Entropy -480.6609802246094, Learning Rate: 2.44140625e-05\n",
      "Epoch [2968/20000], Loss: 594.5087890625, Entropy -493.2080078125, Learning Rate: 2.44140625e-05\n",
      "Epoch [2969/20000], Loss: 598.2186889648438, Entropy -496.7125244140625, Learning Rate: 2.44140625e-05\n",
      "Epoch [2970/20000], Loss: 599.6005859375, Entropy -495.2156677246094, Learning Rate: 2.44140625e-05\n",
      "Epoch [2971/20000], Loss: 585.8167724609375, Entropy -481.4039611816406, Learning Rate: 2.44140625e-05\n",
      "Epoch [2972/20000], Loss: 577.248291015625, Entropy -475.0306091308594, Learning Rate: 2.44140625e-05\n",
      "Epoch [2973/20000], Loss: 593.4508666992188, Entropy -491.48529052734375, Learning Rate: 1.220703125e-05\n",
      "Epoch [2974/20000], Loss: 592.0590209960938, Entropy -489.1656799316406, Learning Rate: 1.220703125e-05\n",
      "Epoch [2975/20000], Loss: 591.2379150390625, Entropy -493.1013488769531, Learning Rate: 1.220703125e-05\n",
      "Epoch [2976/20000], Loss: 613.5077514648438, Entropy -502.59722900390625, Learning Rate: 1.220703125e-05\n",
      "Epoch [2977/20000], Loss: 594.2984619140625, Entropy -483.631103515625, Learning Rate: 1.220703125e-05\n",
      "Epoch [2978/20000], Loss: 596.5587158203125, Entropy -487.9329833984375, Learning Rate: 1.220703125e-05\n",
      "Epoch [2979/20000], Loss: 589.696044921875, Entropy -482.44451904296875, Learning Rate: 1.220703125e-05\n",
      "Epoch [2980/20000], Loss: 591.9586181640625, Entropy -492.9063720703125, Learning Rate: 1.220703125e-05\n",
      "Epoch [2981/20000], Loss: 600.748291015625, Entropy -506.1343994140625, Learning Rate: 1.220703125e-05\n",
      "Epoch [2982/20000], Loss: 582.22509765625, Entropy -472.7975158691406, Learning Rate: 1.220703125e-05\n",
      "Epoch [2983/20000], Loss: 590.3714599609375, Entropy -495.32794189453125, Learning Rate: 1.220703125e-05\n",
      "Epoch [2984/20000], Loss: 587.9888916015625, Entropy -483.9496154785156, Learning Rate: 1.220703125e-05\n",
      "Epoch [2985/20000], Loss: 572.74169921875, Entropy -465.8221435546875, Learning Rate: 1.220703125e-05\n",
      "Epoch [2986/20000], Loss: 599.0966186523438, Entropy -499.1534423828125, Learning Rate: 1.220703125e-05\n",
      "Epoch [2987/20000], Loss: 606.029052734375, Entropy -483.87152099609375, Learning Rate: 1.220703125e-05\n",
      "Epoch [2988/20000], Loss: 610.5414428710938, Entropy -494.293701171875, Learning Rate: 1.220703125e-05\n",
      "Epoch [2989/20000], Loss: 589.490966796875, Entropy -482.034423828125, Learning Rate: 1.220703125e-05\n",
      "Epoch [2990/20000], Loss: 589.5997314453125, Entropy -483.4471435546875, Learning Rate: 1.220703125e-05\n",
      "Epoch [2991/20000], Loss: 588.0380859375, Entropy -491.94451904296875, Learning Rate: 1.220703125e-05\n",
      "Epoch [2992/20000], Loss: 594.63525390625, Entropy -492.2496032714844, Learning Rate: 1.220703125e-05\n",
      "Epoch [2993/20000], Loss: 593.8218994140625, Entropy -484.5885009765625, Learning Rate: 1.220703125e-05\n",
      "Epoch [2994/20000], Loss: 573.035888671875, Entropy -459.43817138671875, Learning Rate: 1.220703125e-05\n",
      "Epoch [2995/20000], Loss: 600.0602416992188, Entropy -495.259765625, Learning Rate: 1.220703125e-05\n",
      "Epoch [2996/20000], Loss: 587.3106689453125, Entropy -485.76519775390625, Learning Rate: 1.220703125e-05\n",
      "Epoch [2997/20000], Loss: 613.0758056640625, Entropy -513.3643188476562, Learning Rate: 1.220703125e-05\n",
      "Epoch [2998/20000], Loss: 581.7288208007812, Entropy -487.9769592285156, Learning Rate: 1.220703125e-05\n",
      "Epoch [2999/20000], Loss: 583.1788330078125, Entropy -483.56732177734375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3000/20000], Loss: 604.4232177734375, Entropy -504.05035400390625, Learning Rate: 1.220703125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3001/20000], Loss: 592.9345703125, Entropy -485.38067626953125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3002/20000], Loss: 598.818115234375, Entropy -486.5653076171875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3003/20000], Loss: 583.6514892578125, Entropy -479.06787109375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3004/20000], Loss: 602.1224365234375, Entropy -489.89093017578125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3005/20000], Loss: 601.706298828125, Entropy -489.2720642089844, Learning Rate: 1.220703125e-05\n",
      "Epoch [3006/20000], Loss: 584.5424194335938, Entropy -478.8409729003906, Learning Rate: 1.220703125e-05\n",
      "Epoch [3007/20000], Loss: 569.984375, Entropy -474.04351806640625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3008/20000], Loss: 590.2894287109375, Entropy -480.84136962890625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3009/20000], Loss: 593.6536865234375, Entropy -489.5335693359375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3010/20000], Loss: 583.176025390625, Entropy -479.75933837890625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3011/20000], Loss: 587.3939819335938, Entropy -484.06170654296875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3012/20000], Loss: 595.8530883789062, Entropy -495.1517333984375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3013/20000], Loss: 576.11669921875, Entropy -480.4962158203125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3014/20000], Loss: 600.265869140625, Entropy -500.62445068359375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3015/20000], Loss: 584.2637329101562, Entropy -484.55279541015625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3016/20000], Loss: 594.4412841796875, Entropy -486.01702880859375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3017/20000], Loss: 585.0792236328125, Entropy -479.05908203125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3018/20000], Loss: 590.7428588867188, Entropy -482.16632080078125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3019/20000], Loss: 593.9067993164062, Entropy -491.48046875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3020/20000], Loss: 609.9547119140625, Entropy -518.4287719726562, Learning Rate: 1.220703125e-05\n",
      "Epoch [3021/20000], Loss: 573.8301391601562, Entropy -457.76312255859375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3022/20000], Loss: 591.6058959960938, Entropy -486.7476806640625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3023/20000], Loss: 580.6550903320312, Entropy -472.7850341796875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3024/20000], Loss: 582.1873168945312, Entropy -479.39093017578125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3025/20000], Loss: 605.5097045898438, Entropy -496.897216796875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3026/20000], Loss: 582.671142578125, Entropy -473.3300476074219, Learning Rate: 1.220703125e-05\n",
      "Epoch [3027/20000], Loss: 589.0118408203125, Entropy -482.55255126953125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3028/20000], Loss: 591.7412109375, Entropy -473.50689697265625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3029/20000], Loss: 591.022705078125, Entropy -488.24951171875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3030/20000], Loss: 597.5675048828125, Entropy -489.4603271484375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3031/20000], Loss: 591.185791015625, Entropy -491.0924987792969, Learning Rate: 1.220703125e-05\n",
      "Epoch [3032/20000], Loss: 610.6922607421875, Entropy -503.84716796875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3033/20000], Loss: 593.8932495117188, Entropy -501.77294921875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3034/20000], Loss: 604.74462890625, Entropy -515.0411376953125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3035/20000], Loss: 578.4686279296875, Entropy -468.16265869140625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3036/20000], Loss: 577.49755859375, Entropy -470.2982482910156, Learning Rate: 1.220703125e-05\n",
      "Epoch [3037/20000], Loss: 601.8792724609375, Entropy -498.6974182128906, Learning Rate: 1.220703125e-05\n",
      "Epoch [3038/20000], Loss: 579.2493896484375, Entropy -473.7793273925781, Learning Rate: 1.220703125e-05\n",
      "Epoch [3039/20000], Loss: 592.393310546875, Entropy -490.9558410644531, Learning Rate: 1.220703125e-05\n",
      "Epoch [3040/20000], Loss: 586.39990234375, Entropy -477.4251403808594, Learning Rate: 1.220703125e-05\n",
      "Epoch [3041/20000], Loss: 590.3495483398438, Entropy -491.1041259765625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3042/20000], Loss: 592.3220825195312, Entropy -489.03668212890625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3043/20000], Loss: 621.4090576171875, Entropy -501.03082275390625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3044/20000], Loss: 583.5054931640625, Entropy -485.2432861328125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3045/20000], Loss: 595.9348754882812, Entropy -482.94866943359375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3046/20000], Loss: 622.1528930664062, Entropy -519.7601928710938, Learning Rate: 1.220703125e-05\n",
      "Epoch [3047/20000], Loss: 584.3980712890625, Entropy -482.3993835449219, Learning Rate: 1.220703125e-05\n",
      "Epoch [3048/20000], Loss: 590.423095703125, Entropy -495.6925354003906, Learning Rate: 1.220703125e-05\n",
      "Epoch [3049/20000], Loss: 587.0831298828125, Entropy -496.5408935546875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3050/20000], Loss: 584.3828125, Entropy -488.08197021484375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3051/20000], Loss: 577.0474853515625, Entropy -469.0263977050781, Learning Rate: 1.220703125e-05\n",
      "Epoch [3052/20000], Loss: 591.472412109375, Entropy -474.6986389160156, Learning Rate: 1.220703125e-05\n",
      "Epoch [3053/20000], Loss: 591.3308715820312, Entropy -491.2366638183594, Learning Rate: 1.220703125e-05\n",
      "Epoch [3054/20000], Loss: 590.4613037109375, Entropy -486.56817626953125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3055/20000], Loss: 592.4883422851562, Entropy -475.0526123046875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3056/20000], Loss: 573.82275390625, Entropy -469.0375671386719, Learning Rate: 1.220703125e-05\n",
      "Epoch [3057/20000], Loss: 610.2752685546875, Entropy -501.53814697265625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3058/20000], Loss: 588.7841796875, Entropy -493.1220703125, Learning Rate: 1.220703125e-05\n",
      "Epoch [3059/20000], Loss: 610.2388305664062, Entropy -490.5867919921875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3060/20000], Loss: 584.2348022460938, Entropy -489.49761962890625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3061/20000], Loss: 600.3234252929688, Entropy -495.4192810058594, Learning Rate: 1.220703125e-05\n",
      "Epoch [3062/20000], Loss: 580.8511352539062, Entropy -480.966796875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3063/20000], Loss: 588.1918334960938, Entropy -487.52593994140625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3064/20000], Loss: 581.574951171875, Entropy -492.078369140625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3065/20000], Loss: 596.9028930664062, Entropy -490.24066162109375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3066/20000], Loss: 584.215576171875, Entropy -475.17144775390625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3067/20000], Loss: 584.2509765625, Entropy -481.16650390625, Learning Rate: 1.220703125e-05\n",
      "Epoch [3068/20000], Loss: 577.313232421875, Entropy -464.45306396484375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3069/20000], Loss: 606.8038330078125, Entropy -500.9638366699219, Learning Rate: 1.220703125e-05\n",
      "Epoch [3070/20000], Loss: 587.0244750976562, Entropy -482.28582763671875, Learning Rate: 1.220703125e-05\n",
      "Epoch [3071/20000], Loss: 579.2928466796875, Entropy -475.9751892089844, Learning Rate: 1.220703125e-05\n",
      "Epoch [3072/20000], Loss: 597.9957885742188, Entropy -506.685302734375, Learning Rate: 1.220703125e-05\n",
      "Epoch [3073/20000], Loss: 596.4569091796875, Entropy -505.6423645019531, Learning Rate: 1.220703125e-05\n",
      "Epoch [3074/20000], Loss: 592.0217895507812, Entropy -487.78143310546875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3075/20000], Loss: 582.1861572265625, Entropy -476.17169189453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3076/20000], Loss: 590.3001708984375, Entropy -479.84368896484375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3077/20000], Loss: 600.2923583984375, Entropy -489.5953674316406, Learning Rate: 6.103515625e-06\n",
      "Epoch [3078/20000], Loss: 591.6657104492188, Entropy -489.2064208984375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3079/20000], Loss: 590.8935546875, Entropy -480.83953857421875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3080/20000], Loss: 584.3099365234375, Entropy -477.85040283203125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3081/20000], Loss: 596.348876953125, Entropy -484.411376953125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3082/20000], Loss: 585.0079956054688, Entropy -468.77301025390625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3083/20000], Loss: 604.0804443359375, Entropy -491.791259765625, Learning Rate: 6.103515625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3084/20000], Loss: 591.1849975585938, Entropy -490.32684326171875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3085/20000], Loss: 583.7139892578125, Entropy -479.2562561035156, Learning Rate: 6.103515625e-06\n",
      "Epoch [3086/20000], Loss: 586.5150146484375, Entropy -476.51202392578125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3087/20000], Loss: 590.6350708007812, Entropy -483.21038818359375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3088/20000], Loss: 593.934326171875, Entropy -490.0779113769531, Learning Rate: 6.103515625e-06\n",
      "Epoch [3089/20000], Loss: 601.1778564453125, Entropy -491.9556884765625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3090/20000], Loss: 610.6326293945312, Entropy -505.62872314453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3091/20000], Loss: 595.311767578125, Entropy -491.6329650878906, Learning Rate: 6.103515625e-06\n",
      "Epoch [3092/20000], Loss: 598.7962646484375, Entropy -502.56231689453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3093/20000], Loss: 580.0784301757812, Entropy -469.4875793457031, Learning Rate: 6.103515625e-06\n",
      "Epoch [3094/20000], Loss: 597.2532958984375, Entropy -494.231201171875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3095/20000], Loss: 604.0319213867188, Entropy -496.55096435546875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3096/20000], Loss: 575.8359985351562, Entropy -471.2238464355469, Learning Rate: 6.103515625e-06\n",
      "Epoch [3097/20000], Loss: 586.3883056640625, Entropy -481.63079833984375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3098/20000], Loss: 573.9713745117188, Entropy -468.7625427246094, Learning Rate: 6.103515625e-06\n",
      "Epoch [3099/20000], Loss: 605.9553833007812, Entropy -499.1996154785156, Learning Rate: 6.103515625e-06\n",
      "Epoch [3100/20000], Loss: 584.8109130859375, Entropy -485.52215576171875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3101/20000], Loss: 605.9969482421875, Entropy -501.34747314453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3102/20000], Loss: 580.22265625, Entropy -482.434814453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3103/20000], Loss: 601.0074462890625, Entropy -508.3737487792969, Learning Rate: 6.103515625e-06\n",
      "Epoch [3104/20000], Loss: 581.2911376953125, Entropy -477.6314392089844, Learning Rate: 6.103515625e-06\n",
      "Epoch [3105/20000], Loss: 587.5589599609375, Entropy -485.1246337890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3106/20000], Loss: 594.87255859375, Entropy -490.8943786621094, Learning Rate: 6.103515625e-06\n",
      "Epoch [3107/20000], Loss: 611.2552490234375, Entropy -503.4573974609375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3108/20000], Loss: 588.9596557617188, Entropy -477.64263916015625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3109/20000], Loss: 588.405517578125, Entropy -481.5106201171875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3110/20000], Loss: 595.6533203125, Entropy -493.00982666015625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3111/20000], Loss: 593.697265625, Entropy -495.41229248046875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3112/20000], Loss: 606.7945556640625, Entropy -500.8985900878906, Learning Rate: 6.103515625e-06\n",
      "Epoch [3113/20000], Loss: 572.807861328125, Entropy -457.3470153808594, Learning Rate: 6.103515625e-06\n",
      "Epoch [3114/20000], Loss: 582.4833984375, Entropy -480.77459716796875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3115/20000], Loss: 595.1176147460938, Entropy -492.8992919921875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3116/20000], Loss: 585.960693359375, Entropy -489.8436584472656, Learning Rate: 6.103515625e-06\n",
      "Epoch [3117/20000], Loss: 596.7387084960938, Entropy -494.9718322753906, Learning Rate: 6.103515625e-06\n",
      "Epoch [3118/20000], Loss: 579.7108154296875, Entropy -476.28106689453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3119/20000], Loss: 593.3317260742188, Entropy -493.8387451171875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3120/20000], Loss: 598.9500732421875, Entropy -502.67474365234375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3121/20000], Loss: 618.594482421875, Entropy -510.1108703613281, Learning Rate: 6.103515625e-06\n",
      "Epoch [3122/20000], Loss: 610.61083984375, Entropy -515.18212890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3123/20000], Loss: 594.3956298828125, Entropy -482.504150390625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3124/20000], Loss: 582.5057373046875, Entropy -480.6275634765625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3125/20000], Loss: 568.0008544921875, Entropy -471.76226806640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3126/20000], Loss: 599.88623046875, Entropy -492.8045654296875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3127/20000], Loss: 562.2739868164062, Entropy -446.06756591796875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3128/20000], Loss: 607.1400146484375, Entropy -495.43572998046875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3129/20000], Loss: 586.3409423828125, Entropy -481.9961853027344, Learning Rate: 6.103515625e-06\n",
      "Epoch [3130/20000], Loss: 607.713623046875, Entropy -505.9979248046875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3131/20000], Loss: 588.8972778320312, Entropy -488.431640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3132/20000], Loss: 587.5035400390625, Entropy -487.1789245605469, Learning Rate: 6.103515625e-06\n",
      "Epoch [3133/20000], Loss: 579.5594482421875, Entropy -476.0950622558594, Learning Rate: 6.103515625e-06\n",
      "Epoch [3134/20000], Loss: 605.6213989257812, Entropy -502.75555419921875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3135/20000], Loss: 600.2518920898438, Entropy -494.4571533203125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3136/20000], Loss: 589.705810546875, Entropy -489.5631408691406, Learning Rate: 6.103515625e-06\n",
      "Epoch [3137/20000], Loss: 584.9085693359375, Entropy -476.52398681640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3138/20000], Loss: 592.5325927734375, Entropy -467.361572265625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3139/20000], Loss: 597.867431640625, Entropy -497.4156188964844, Learning Rate: 6.103515625e-06\n",
      "Epoch [3140/20000], Loss: 600.5289916992188, Entropy -499.5386047363281, Learning Rate: 6.103515625e-06\n",
      "Epoch [3141/20000], Loss: 612.4293212890625, Entropy -511.2466125488281, Learning Rate: 6.103515625e-06\n",
      "Epoch [3142/20000], Loss: 589.0323486328125, Entropy -487.7596435546875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3143/20000], Loss: 584.250732421875, Entropy -475.23876953125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3144/20000], Loss: 582.7239990234375, Entropy -481.5125732421875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3145/20000], Loss: 573.847412109375, Entropy -474.9245910644531, Learning Rate: 6.103515625e-06\n",
      "Epoch [3146/20000], Loss: 588.8704223632812, Entropy -489.1872253417969, Learning Rate: 6.103515625e-06\n",
      "Epoch [3147/20000], Loss: 591.9224853515625, Entropy -496.2452392578125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3148/20000], Loss: 568.65625, Entropy -463.798583984375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3149/20000], Loss: 579.7149047851562, Entropy -474.5328369140625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3150/20000], Loss: 594.316650390625, Entropy -497.05548095703125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3151/20000], Loss: 586.5145874023438, Entropy -481.6195983886719, Learning Rate: 6.103515625e-06\n",
      "Epoch [3152/20000], Loss: 577.9664916992188, Entropy -463.34344482421875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3153/20000], Loss: 592.5877685546875, Entropy -484.49224853515625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3154/20000], Loss: 582.6953735351562, Entropy -481.69183349609375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3155/20000], Loss: 579.3383178710938, Entropy -472.18817138671875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3156/20000], Loss: 590.9569091796875, Entropy -493.5343933105469, Learning Rate: 6.103515625e-06\n",
      "Epoch [3157/20000], Loss: 600.2800903320312, Entropy -484.93280029296875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3158/20000], Loss: 600.6378784179688, Entropy -492.954833984375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3159/20000], Loss: 587.7759399414062, Entropy -469.81402587890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3160/20000], Loss: 583.3761596679688, Entropy -478.94903564453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3161/20000], Loss: 600.773681640625, Entropy -504.45367431640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3162/20000], Loss: 574.89111328125, Entropy -472.0762939453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3163/20000], Loss: 594.1845703125, Entropy -490.75262451171875, Learning Rate: 6.103515625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3164/20000], Loss: 601.2735595703125, Entropy -495.13226318359375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3165/20000], Loss: 586.1407470703125, Entropy -494.790771484375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3166/20000], Loss: 592.2021484375, Entropy -491.50067138671875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3167/20000], Loss: 596.7401123046875, Entropy -493.27008056640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3168/20000], Loss: 589.7486572265625, Entropy -480.67559814453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3169/20000], Loss: 599.5735473632812, Entropy -495.5540466308594, Learning Rate: 6.103515625e-06\n",
      "Epoch [3170/20000], Loss: 579.5096435546875, Entropy -473.6143798828125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3171/20000], Loss: 581.4769287109375, Entropy -469.1936340332031, Learning Rate: 6.103515625e-06\n",
      "Epoch [3172/20000], Loss: 600.1257934570312, Entropy -500.83648681640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3173/20000], Loss: 590.7631225585938, Entropy -476.7813415527344, Learning Rate: 6.103515625e-06\n",
      "Epoch [3174/20000], Loss: 607.79296875, Entropy -507.29095458984375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3175/20000], Loss: 594.6717529296875, Entropy -499.3630065917969, Learning Rate: 6.103515625e-06\n",
      "Epoch [3176/20000], Loss: 602.07470703125, Entropy -497.53607177734375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3177/20000], Loss: 602.960205078125, Entropy -492.51214599609375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3178/20000], Loss: 613.538818359375, Entropy -510.0106506347656, Learning Rate: 6.103515625e-06\n",
      "Epoch [3179/20000], Loss: 605.7570190429688, Entropy -520.180908203125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3180/20000], Loss: 595.8880615234375, Entropy -493.797119140625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3181/20000], Loss: 587.167236328125, Entropy -492.9503173828125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3182/20000], Loss: 578.42236328125, Entropy -472.920166015625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3183/20000], Loss: 598.4539184570312, Entropy -494.672119140625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3184/20000], Loss: 614.5460815429688, Entropy -511.92303466796875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3185/20000], Loss: 573.8563842773438, Entropy -475.7533264160156, Learning Rate: 6.103515625e-06\n",
      "Epoch [3186/20000], Loss: 580.4566040039062, Entropy -483.0696105957031, Learning Rate: 6.103515625e-06\n",
      "Epoch [3187/20000], Loss: 589.4324951171875, Entropy -487.966796875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3188/20000], Loss: 587.279052734375, Entropy -481.18121337890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3189/20000], Loss: 588.712890625, Entropy -479.98895263671875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3190/20000], Loss: 577.142333984375, Entropy -472.22442626953125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3191/20000], Loss: 579.2887573242188, Entropy -466.1746826171875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3192/20000], Loss: 593.55029296875, Entropy -494.8106689453125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3193/20000], Loss: 570.4853515625, Entropy -473.09881591796875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3194/20000], Loss: 588.8232421875, Entropy -482.3402404785156, Learning Rate: 6.103515625e-06\n",
      "Epoch [3195/20000], Loss: 606.890625, Entropy -504.17822265625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3196/20000], Loss: 585.486083984375, Entropy -478.6370849609375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3197/20000], Loss: 587.6570434570312, Entropy -476.73101806640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3198/20000], Loss: 600.2501831054688, Entropy -496.52947998046875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3199/20000], Loss: 606.4830932617188, Entropy -501.91693115234375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3200/20000], Loss: 594.6905517578125, Entropy -482.7745666503906, Learning Rate: 6.103515625e-06\n",
      "Epoch [3201/20000], Loss: 618.5889892578125, Entropy -507.5234680175781, Learning Rate: 6.103515625e-06\n",
      "Epoch [3202/20000], Loss: 594.106689453125, Entropy -488.2996520996094, Learning Rate: 6.103515625e-06\n",
      "Epoch [3203/20000], Loss: 606.5802001953125, Entropy -505.3578186035156, Learning Rate: 6.103515625e-06\n",
      "Epoch [3204/20000], Loss: 610.6710205078125, Entropy -502.03570556640625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3205/20000], Loss: 591.7762451171875, Entropy -486.0543212890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3206/20000], Loss: 583.235595703125, Entropy -478.2931213378906, Learning Rate: 6.103515625e-06\n",
      "Epoch [3207/20000], Loss: 585.3154296875, Entropy -487.49029541015625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3208/20000], Loss: 587.039794921875, Entropy -481.2159423828125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3209/20000], Loss: 631.2627563476562, Entropy -531.0715942382812, Learning Rate: 6.103515625e-06\n",
      "Epoch [3210/20000], Loss: 583.3403930664062, Entropy -478.152099609375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3211/20000], Loss: 594.868408203125, Entropy -486.86395263671875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3212/20000], Loss: 577.1399536132812, Entropy -477.64471435546875, Learning Rate: 6.103515625e-06\n",
      "Epoch [3213/20000], Loss: 596.7616577148438, Entropy -492.8244934082031, Learning Rate: 6.103515625e-06\n",
      "Epoch [3214/20000], Loss: 593.8243408203125, Entropy -483.7322082519531, Learning Rate: 6.103515625e-06\n",
      "Epoch [3215/20000], Loss: 603.1471557617188, Entropy -497.4774475097656, Learning Rate: 6.103515625e-06\n",
      "Epoch [3216/20000], Loss: 590.717529296875, Entropy -491.8280944824219, Learning Rate: 6.103515625e-06\n",
      "Epoch [3217/20000], Loss: 595.07177734375, Entropy -498.59112548828125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3218/20000], Loss: 576.537109375, Entropy -472.3884582519531, Learning Rate: 6.103515625e-06\n",
      "Epoch [3219/20000], Loss: 592.7605590820312, Entropy -493.1594543457031, Learning Rate: 6.103515625e-06\n",
      "Epoch [3220/20000], Loss: 596.0816650390625, Entropy -483.6144104003906, Learning Rate: 6.103515625e-06\n",
      "Epoch [3221/20000], Loss: 584.75927734375, Entropy -486.8852233886719, Learning Rate: 6.103515625e-06\n",
      "Epoch [3222/20000], Loss: 589.342529296875, Entropy -490.03021240234375, Learning Rate: 6.103515625e-06\n",
      "Epoch [3223/20000], Loss: 588.0704345703125, Entropy -484.5484619140625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3224/20000], Loss: 599.6282958984375, Entropy -480.62261962890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3225/20000], Loss: 589.677978515625, Entropy -483.4058837890625, Learning Rate: 6.103515625e-06\n",
      "Epoch [3226/20000], Loss: 602.99365234375, Entropy -508.9345703125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3227/20000], Loss: 595.8861083984375, Entropy -488.79962158203125, Learning Rate: 6.103515625e-06\n",
      "Epoch [3228/20000], Loss: 581.907470703125, Entropy -481.6891784667969, Learning Rate: 6.103515625e-06\n",
      "Epoch [3229/20000], Loss: 596.689453125, Entropy -494.10040283203125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3230/20000], Loss: 603.8429565429688, Entropy -463.6849670410156, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3231/20000], Loss: 590.0673217773438, Entropy -478.46417236328125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3232/20000], Loss: 595.2529296875, Entropy -496.2815246582031, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3233/20000], Loss: 609.4502563476562, Entropy -481.0919189453125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3234/20000], Loss: 593.3494873046875, Entropy -489.3305969238281, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3235/20000], Loss: 603.0947265625, Entropy -479.5224304199219, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3236/20000], Loss: 585.5313720703125, Entropy -480.87847900390625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3237/20000], Loss: 585.1143188476562, Entropy -475.98822021484375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3238/20000], Loss: 579.9259033203125, Entropy -484.1699523925781, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3239/20000], Loss: 605.9116821289062, Entropy -494.8168640136719, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3240/20000], Loss: 609.4895629882812, Entropy -510.1576232910156, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3241/20000], Loss: 581.2222900390625, Entropy -474.4112548828125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3242/20000], Loss: 600.2633056640625, Entropy -504.82879638671875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3243/20000], Loss: 583.6978759765625, Entropy -471.277099609375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3244/20000], Loss: 595.199462890625, Entropy -493.8875732421875, Learning Rate: 3.0517578125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3245/20000], Loss: 601.3045654296875, Entropy -494.8212585449219, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3246/20000], Loss: 581.6752319335938, Entropy -466.5199890136719, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3247/20000], Loss: 592.2398681640625, Entropy -484.49407958984375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3248/20000], Loss: 599.4564208984375, Entropy -500.93621826171875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3249/20000], Loss: 609.397705078125, Entropy -495.985107421875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3250/20000], Loss: 588.0972900390625, Entropy -474.6208190917969, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3251/20000], Loss: 583.6466064453125, Entropy -461.975341796875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3252/20000], Loss: 585.0882568359375, Entropy -481.12139892578125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3253/20000], Loss: 601.510986328125, Entropy -490.14013671875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3254/20000], Loss: 590.4341430664062, Entropy -477.4955749511719, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3255/20000], Loss: 584.333251953125, Entropy -472.33038330078125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3256/20000], Loss: 593.7796630859375, Entropy -479.1000061035156, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3257/20000], Loss: 587.2227783203125, Entropy -481.7144775390625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3258/20000], Loss: 595.7156372070312, Entropy -490.8847961425781, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3259/20000], Loss: 581.8525390625, Entropy -480.3916320800781, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3260/20000], Loss: 579.4908447265625, Entropy -482.4840087890625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3261/20000], Loss: 596.4716186523438, Entropy -493.3633117675781, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3262/20000], Loss: 606.1958618164062, Entropy -508.69635009765625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3263/20000], Loss: 657.2294921875, Entropy -495.085693359375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3264/20000], Loss: 606.72705078125, Entropy -513.2532958984375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3265/20000], Loss: 578.619873046875, Entropy -481.44482421875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3266/20000], Loss: 603.7037963867188, Entropy -499.1707763671875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3267/20000], Loss: 596.750244140625, Entropy -494.02484130859375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3268/20000], Loss: 588.4249267578125, Entropy -474.9062805175781, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3269/20000], Loss: 621.36083984375, Entropy -506.5711669921875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3270/20000], Loss: 592.7664794921875, Entropy -490.6971740722656, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3271/20000], Loss: 582.6427001953125, Entropy -481.6888427734375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3272/20000], Loss: 618.6421508789062, Entropy -509.93817138671875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3273/20000], Loss: 592.8319091796875, Entropy -487.4130859375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3274/20000], Loss: 607.5023193359375, Entropy -510.0579833984375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3275/20000], Loss: 586.3468017578125, Entropy -478.770263671875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3276/20000], Loss: 612.2675170898438, Entropy -490.93572998046875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3277/20000], Loss: 611.0720825195312, Entropy -489.4263916015625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3278/20000], Loss: 590.3609619140625, Entropy -494.9506530761719, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3279/20000], Loss: 579.23876953125, Entropy -477.650634765625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3280/20000], Loss: 581.5201416015625, Entropy -478.4483337402344, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3281/20000], Loss: 587.6084594726562, Entropy -479.869873046875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3282/20000], Loss: 586.994384765625, Entropy -486.880126953125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3283/20000], Loss: 605.6099243164062, Entropy -504.8565673828125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3284/20000], Loss: 597.7565307617188, Entropy -497.83355712890625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3285/20000], Loss: 606.3948364257812, Entropy -509.84185791015625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3286/20000], Loss: 608.704345703125, Entropy -492.1709289550781, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3287/20000], Loss: 604.246826171875, Entropy -487.78997802734375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3288/20000], Loss: 588.7394409179688, Entropy -477.0140380859375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3289/20000], Loss: 580.0493774414062, Entropy -471.6370544433594, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3290/20000], Loss: 583.4219970703125, Entropy -478.5926513671875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3291/20000], Loss: 608.8836059570312, Entropy -498.68402099609375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3292/20000], Loss: 596.8292236328125, Entropy -502.20916748046875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3293/20000], Loss: 585.2820434570312, Entropy -471.4682922363281, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3294/20000], Loss: 595.8941040039062, Entropy -487.742919921875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3295/20000], Loss: 589.287109375, Entropy -478.51861572265625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3296/20000], Loss: 590.0691528320312, Entropy -483.001953125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3297/20000], Loss: 589.4342041015625, Entropy -470.13787841796875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3298/20000], Loss: 592.5947875976562, Entropy -482.64166259765625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3299/20000], Loss: 595.1080322265625, Entropy -493.8495178222656, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3300/20000], Loss: 600.3826293945312, Entropy -504.0354309082031, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3301/20000], Loss: 588.2008056640625, Entropy -486.4344482421875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3302/20000], Loss: 570.8300170898438, Entropy -473.10955810546875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3303/20000], Loss: 602.3004150390625, Entropy -492.69488525390625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3304/20000], Loss: 603.9442138671875, Entropy -487.88458251953125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3305/20000], Loss: 611.1572265625, Entropy -506.64501953125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3306/20000], Loss: 587.1635131835938, Entropy -487.1534423828125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3307/20000], Loss: 580.0302734375, Entropy -465.7691650390625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3308/20000], Loss: 603.551513671875, Entropy -500.62945556640625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3309/20000], Loss: 596.3085327148438, Entropy -495.54864501953125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3310/20000], Loss: 610.333251953125, Entropy -495.9150390625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3311/20000], Loss: 576.6177978515625, Entropy -459.34027099609375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3312/20000], Loss: 591.289794921875, Entropy -469.29864501953125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3313/20000], Loss: 601.4698486328125, Entropy -500.9125671386719, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3314/20000], Loss: 590.91357421875, Entropy -482.81488037109375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3315/20000], Loss: 591.0411987304688, Entropy -483.4826965332031, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3316/20000], Loss: 589.1679077148438, Entropy -488.02203369140625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3317/20000], Loss: 592.2625732421875, Entropy -489.25213623046875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3318/20000], Loss: 588.25439453125, Entropy -485.1244812011719, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3319/20000], Loss: 596.016845703125, Entropy -485.5212097167969, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3320/20000], Loss: 596.2740478515625, Entropy -500.1405029296875, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3321/20000], Loss: 589.7679443359375, Entropy -496.1900634765625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3322/20000], Loss: 581.8604125976562, Entropy -460.5494384765625, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3323/20000], Loss: 582.1490478515625, Entropy -470.2589111328125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3324/20000], Loss: 585.5185546875, Entropy -482.24798583984375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3325/20000], Loss: 602.1298828125, Entropy -502.875, Learning Rate: 3.0517578125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3326/20000], Loss: 597.88671875, Entropy -484.7820129394531, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3327/20000], Loss: 591.509521484375, Entropy -480.79327392578125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3328/20000], Loss: 581.5836181640625, Entropy -481.20733642578125, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3329/20000], Loss: 594.87109375, Entropy -487.19818115234375, Learning Rate: 3.0517578125e-06\n",
      "Epoch [3330/20000], Loss: 583.44287109375, Entropy -477.3863220214844, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3331/20000], Loss: 593.3524169921875, Entropy -485.077392578125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3332/20000], Loss: 575.424072265625, Entropy -467.6591796875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3333/20000], Loss: 604.3778686523438, Entropy -507.2043151855469, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3334/20000], Loss: 581.7832641601562, Entropy -484.28338623046875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3335/20000], Loss: 593.3355102539062, Entropy -482.47930908203125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3336/20000], Loss: 600.230224609375, Entropy -507.27960205078125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3337/20000], Loss: 600.35546875, Entropy -501.61480712890625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3338/20000], Loss: 584.8902587890625, Entropy -493.189208984375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3339/20000], Loss: 587.3186645507812, Entropy -470.169921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3340/20000], Loss: 591.2283325195312, Entropy -471.09765625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3341/20000], Loss: 582.079833984375, Entropy -475.8949890136719, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3342/20000], Loss: 583.1029052734375, Entropy -466.040283203125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3343/20000], Loss: 602.5775756835938, Entropy -477.49298095703125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3344/20000], Loss: 587.8150634765625, Entropy -482.0194396972656, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3345/20000], Loss: 588.981689453125, Entropy -491.89312744140625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3346/20000], Loss: 602.213623046875, Entropy -498.4200744628906, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3347/20000], Loss: 593.6923217773438, Entropy -494.2552490234375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3348/20000], Loss: 604.3699951171875, Entropy -505.12579345703125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3349/20000], Loss: 588.5126953125, Entropy -478.0565490722656, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3350/20000], Loss: 593.8410034179688, Entropy -488.50164794921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3351/20000], Loss: 598.0214233398438, Entropy -480.727294921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3352/20000], Loss: 599.467529296875, Entropy -496.58856201171875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3353/20000], Loss: 595.5142211914062, Entropy -476.46142578125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3354/20000], Loss: 572.31591796875, Entropy -469.9435729980469, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3355/20000], Loss: 589.6922607421875, Entropy -490.6935119628906, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3356/20000], Loss: 591.9320068359375, Entropy -495.3215637207031, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3357/20000], Loss: 588.8114624023438, Entropy -475.1371154785156, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3358/20000], Loss: 594.4393920898438, Entropy -488.9296875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3359/20000], Loss: 598.3668823242188, Entropy -508.05511474609375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3360/20000], Loss: 585.4058837890625, Entropy -480.1055908203125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3361/20000], Loss: 591.7430419921875, Entropy -485.2734375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3362/20000], Loss: 578.8704223632812, Entropy -471.79229736328125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3363/20000], Loss: 593.4381713867188, Entropy -489.1640625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3364/20000], Loss: 614.4627685546875, Entropy -501.19573974609375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3365/20000], Loss: 584.6353759765625, Entropy -486.50531005859375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3366/20000], Loss: 579.1687622070312, Entropy -476.670654296875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3367/20000], Loss: 602.9290771484375, Entropy -500.059814453125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3368/20000], Loss: 617.771484375, Entropy -502.1114501953125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3369/20000], Loss: 592.0905151367188, Entropy -482.4713439941406, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3370/20000], Loss: 592.6463623046875, Entropy -493.244384765625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3371/20000], Loss: 592.4200439453125, Entropy -483.2906494140625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3372/20000], Loss: 596.3785400390625, Entropy -494.919677734375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3373/20000], Loss: 604.3412475585938, Entropy -498.6298828125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3374/20000], Loss: 589.2980346679688, Entropy -486.7249755859375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3375/20000], Loss: 607.2948608398438, Entropy -509.757080078125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3376/20000], Loss: 598.75, Entropy -492.4559326171875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3377/20000], Loss: 600.6602783203125, Entropy -491.71453857421875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3378/20000], Loss: 593.4056396484375, Entropy -495.17340087890625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3379/20000], Loss: 571.1702270507812, Entropy -460.9683837890625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3380/20000], Loss: 602.213134765625, Entropy -510.0076904296875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3381/20000], Loss: 594.6657104492188, Entropy -494.03717041015625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3382/20000], Loss: 604.7061157226562, Entropy -490.6706237792969, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3383/20000], Loss: 601.60546875, Entropy -503.7276916503906, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3384/20000], Loss: 588.572509765625, Entropy -484.9724426269531, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3385/20000], Loss: 595.12548828125, Entropy -497.498291015625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3386/20000], Loss: 598.5927124023438, Entropy -504.42919921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3387/20000], Loss: 584.6729736328125, Entropy -484.4311218261719, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3388/20000], Loss: 595.9575805664062, Entropy -495.89154052734375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3389/20000], Loss: 607.2957153320312, Entropy -498.86492919921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3390/20000], Loss: 595.034912109375, Entropy -491.728515625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3391/20000], Loss: 601.7451171875, Entropy -489.27899169921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3392/20000], Loss: 606.89892578125, Entropy -493.9775390625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3393/20000], Loss: 602.1701049804688, Entropy -489.9981689453125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3394/20000], Loss: 576.3897094726562, Entropy -470.2566833496094, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3395/20000], Loss: 593.6681518554688, Entropy -494.0887451171875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3396/20000], Loss: 592.7662353515625, Entropy -479.38470458984375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3397/20000], Loss: 596.346923828125, Entropy -486.5977783203125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3398/20000], Loss: 600.6768798828125, Entropy -482.485595703125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3399/20000], Loss: 590.3251953125, Entropy -477.8946228027344, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3400/20000], Loss: 585.0750732421875, Entropy -480.75567626953125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3401/20000], Loss: 597.822265625, Entropy -493.6365966796875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3402/20000], Loss: 591.0640869140625, Entropy -483.5201721191406, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3403/20000], Loss: 605.8797607421875, Entropy -503.2227478027344, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3404/20000], Loss: 600.7821044921875, Entropy -502.1780700683594, Learning Rate: 1.52587890625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3405/20000], Loss: 597.880615234375, Entropy -481.43109130859375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3406/20000], Loss: 589.94970703125, Entropy -481.0621337890625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3407/20000], Loss: 601.6871337890625, Entropy -504.96734619140625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3408/20000], Loss: 592.8444213867188, Entropy -485.40228271484375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3409/20000], Loss: 589.4357299804688, Entropy -496.1001281738281, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3410/20000], Loss: 595.7514038085938, Entropy -493.20733642578125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3411/20000], Loss: 591.58251953125, Entropy -480.53680419921875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3412/20000], Loss: 594.2362670898438, Entropy -477.8907470703125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3413/20000], Loss: 590.1309814453125, Entropy -481.874755859375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3414/20000], Loss: 612.6751708984375, Entropy -504.564697265625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3415/20000], Loss: 590.23974609375, Entropy -488.60955810546875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3416/20000], Loss: 595.4273681640625, Entropy -488.2682800292969, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3417/20000], Loss: 618.6280517578125, Entropy -481.1624450683594, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3418/20000], Loss: 617.5443115234375, Entropy -512.4241943359375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3419/20000], Loss: 601.8872680664062, Entropy -497.23681640625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3420/20000], Loss: 591.5281372070312, Entropy -479.2838439941406, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3421/20000], Loss: 598.4196166992188, Entropy -497.21826171875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3422/20000], Loss: 604.6575927734375, Entropy -502.6715087890625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3423/20000], Loss: 589.2578735351562, Entropy -487.542236328125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3424/20000], Loss: 602.8466186523438, Entropy -495.66192626953125, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3425/20000], Loss: 594.670654296875, Entropy -493.8160400390625, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3426/20000], Loss: 586.1317749023438, Entropy -487.4505920410156, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3427/20000], Loss: 583.1839599609375, Entropy -478.53924560546875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3428/20000], Loss: 581.3553466796875, Entropy -468.9637451171875, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3429/20000], Loss: 588.9238891601562, Entropy -485.9554443359375, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3430/20000], Loss: 579.1414184570312, Entropy -471.6800842285156, Learning Rate: 1.52587890625e-06\n",
      "Epoch [3431/20000], Loss: 601.3839111328125, Entropy -498.58050537109375, Learning Rate: 7.62939453125e-07\n",
      "3127 [tensor(562.2740, device='cuda:0'), tensor(-446.0676, device='cuda:0'), tensor(-279.4181, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "k_MC=200\n",
    "\n",
    "#sample, = ax.scatter([],[],color='red',alpha=0.07)\n",
    "#fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "'''\n",
    "def show(GeN,n,alpha=0.07):\n",
    "    Z=GeN(n).detach().clone().cpu()\n",
    "    plt.pcolormesh(grid_x.numpy(),grid_y.numpy(),p.exp().numpy())\n",
    "    plt.scatter(Z[:,0],Z[:,1],color='red',alpha=alpha) \n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "''' \n",
    "\n",
    "def show(GeN,n):\n",
    "    #Z=GeN(200).detach()\n",
    "    #fig=setup.makePlot(Z,device)\n",
    "    #plt.show()\n",
    "    return\n",
    "    \n",
    "#lr =.03 for lat_dim 5\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    optimizer = GeNPredVI(loglikelihood, logprior, projection, k_MC,\n",
    "\t\t                                    0, 100, 1000, 50, 50,\n",
    "\t\t                                    20000, .05, .000001, 100, .5,\n",
    "\t\t                                    device, True, temp_dir, save_best=True)\n",
    "    best_epoch, scores=optimizer.run(GeN,show)\n",
    "print(best_epoch,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeNPredVI' object has no attribute 'score_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3c789e9d5144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Catoni temperature C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeNPredVI' object has no attribute 'score_temp'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_temp\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('Catoni temperature C')\n",
    "plt.plot(time, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb5741b54d0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_entropy\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('KL divergence')\n",
    "plt.plot(time, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb56ba61e50>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=torch.as_tensor(optimizer.score_elbo)\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('ELBO')\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb57426c810>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_lr\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(1068.5360, device='cuda:0'),\n",
       " tensor(-924.5271, device='cuda:0'),\n",
       " tensor(-236.4646, device='cuda:0')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show(GeN,n):\n",
    "    Z=GeN(n).detach()\n",
    "    fig=setup.makePlot(Z,device)\n",
    "    plt.title('Predictive Variatiational Inference, GeNVI lat_dim='+str(lat_dim))\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "\n",
    "show(GeN,1000)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLPP_train, nLPP_validation, nLPP_test, RSE_train, RSE_validation, RSE_test=setup.evaluate_metrics(GeN(1000).detach(),'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nLPP_valid: (tensor(-0.7768), tensor(0.4444))\n",
      "SE_valid: (tensor(0.0107), tensor(0.0154))\n",
      "nLPP_test: (tensor(33.0666), tensor(63.2011))\n",
      "SE_test: (tensor(1.5427), tensor(2.6888))\n"
     ]
    }
   ],
   "source": [
    "print('nLPP_valid: '+str(nLPP_validation))\n",
    "print('SE_valid: '+str(RSE_validation))\n",
    "print('nLPP_test: '+str(nLPP_test))\n",
    "print('SE_test: '+str(RSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un choix de points $x_0,...,x_{n-1}$, on dfinit:\n",
    "$$\n",
    "d(\\theta,\\theta')=\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert\n",
    "$$\n",
    "ou\n",
    "$$\n",
    "d_2(\\theta,\\theta')=\\biggl(\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert^2\\biggr)^{\\frac{1}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(f\\in A)=P(\\{\\theta \\mid f_\\theta\\in A\\})$\n",
    "\n",
    "$\\theta \\mapsto f_\\theta$ (is it continuous?)\n",
    "\n",
    "relation entre $d(\\theta,\\theta')$ et $d(f_\\theta,f_\\theta')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
