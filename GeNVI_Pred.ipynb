{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "from Inference.GeNVI_predictive import GeNPredVI, GeNetEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Experiments.foong import Setup\n",
    "setup=Setup(device,layerwidth=5,nblayers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target density #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprior=setup.logPredPrior\n",
    "loglikelihood=setup.loglikelihood\n",
    "projection=setup.projection\n",
    "size_sample=setup.n_train_samples\n",
    "param_count=setup.param_count\n",
    "model=setup._model\n",
    "\n",
    "size_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Network #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation = nn.Tanh()#nn.ReLU()\n",
    "init_b = .001\n",
    "lat_dim=5\n",
    "\n",
    "\n",
    "GeN = GeNetEns(1, lat_dim, 50, param_count, activation, 0.2, init_b, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20000], Loss: 19185.373046875, Entropy -277.71697998046875, Learning Rate: 0.01\n",
      "Epoch [1/20000], Loss: 8874.4814453125, Entropy -286.50384521484375, Learning Rate: 0.01\n",
      "Epoch [2/20000], Loss: 5438.6806640625, Entropy -298.22686767578125, Learning Rate: 0.01\n",
      "Epoch [3/20000], Loss: 9164.26953125, Entropy -306.91131591796875, Learning Rate: 0.01\n",
      "Epoch [4/20000], Loss: 4904.8251953125, Entropy -314.847412109375, Learning Rate: 0.01\n",
      "Epoch [5/20000], Loss: 3312.064208984375, Entropy -340.0749816894531, Learning Rate: 0.01\n",
      "Epoch [6/20000], Loss: 3739.7763671875, Entropy -338.7950439453125, Learning Rate: 0.01\n",
      "Epoch [7/20000], Loss: 4047.796875, Entropy -353.6628723144531, Learning Rate: 0.01\n",
      "Epoch [8/20000], Loss: 3981.8671875, Entropy -359.8682556152344, Learning Rate: 0.01\n",
      "Epoch [9/20000], Loss: 3497.3388671875, Entropy -363.1210021972656, Learning Rate: 0.01\n",
      "Epoch [10/20000], Loss: 2999.29052734375, Entropy -369.17144775390625, Learning Rate: 0.01\n",
      "Epoch [11/20000], Loss: 2694.520263671875, Entropy -379.772216796875, Learning Rate: 0.01\n",
      "Epoch [12/20000], Loss: 2655.3818359375, Entropy -365.05841064453125, Learning Rate: 0.01\n",
      "Epoch [13/20000], Loss: 3015.632080078125, Entropy -366.6260070800781, Learning Rate: 0.01\n",
      "Epoch [14/20000], Loss: 2611.376953125, Entropy -389.3335266113281, Learning Rate: 0.01\n",
      "Epoch [15/20000], Loss: 2419.83544921875, Entropy -371.8256530761719, Learning Rate: 0.01\n",
      "Epoch [16/20000], Loss: 2205.73681640625, Entropy -378.504638671875, Learning Rate: 0.01\n",
      "Epoch [17/20000], Loss: 2197.28271484375, Entropy -375.0487976074219, Learning Rate: 0.01\n",
      "Epoch [18/20000], Loss: 2901.43212890625, Entropy -386.3950500488281, Learning Rate: 0.01\n",
      "Epoch [19/20000], Loss: 2840.37451171875, Entropy -381.944091796875, Learning Rate: 0.01\n",
      "Epoch [20/20000], Loss: 2475.982666015625, Entropy -372.6604919433594, Learning Rate: 0.01\n",
      "Epoch [21/20000], Loss: 2096.22705078125, Entropy -388.2926025390625, Learning Rate: 0.01\n",
      "Epoch [22/20000], Loss: 2058.9775390625, Entropy -395.31134033203125, Learning Rate: 0.01\n",
      "Epoch [23/20000], Loss: 2190.73046875, Entropy -388.0712890625, Learning Rate: 0.01\n",
      "Epoch [24/20000], Loss: 2174.728271484375, Entropy -378.134521484375, Learning Rate: 0.01\n",
      "Epoch [25/20000], Loss: 2410.5390625, Entropy -382.92144775390625, Learning Rate: 0.01\n",
      "Epoch [26/20000], Loss: 2042.306396484375, Entropy -389.396484375, Learning Rate: 0.01\n",
      "Epoch [27/20000], Loss: 2181.59912109375, Entropy -382.3460693359375, Learning Rate: 0.01\n",
      "Epoch [28/20000], Loss: 2310.35888671875, Entropy -386.2614440917969, Learning Rate: 0.01\n",
      "Epoch [29/20000], Loss: 2064.49755859375, Entropy -393.02313232421875, Learning Rate: 0.01\n",
      "Epoch [30/20000], Loss: 1929.0213623046875, Entropy -398.4449462890625, Learning Rate: 0.01\n",
      "Epoch [31/20000], Loss: 2081.716552734375, Entropy -398.332275390625, Learning Rate: 0.01\n",
      "Epoch [32/20000], Loss: 2153.06640625, Entropy -391.6939697265625, Learning Rate: 0.01\n",
      "Epoch [33/20000], Loss: 2108.56591796875, Entropy -384.7830810546875, Learning Rate: 0.01\n",
      "Epoch [34/20000], Loss: 2140.331298828125, Entropy -392.4472961425781, Learning Rate: 0.01\n",
      "Epoch [35/20000], Loss: 1995.272216796875, Entropy -389.6217041015625, Learning Rate: 0.01\n",
      "Epoch [36/20000], Loss: 1947.7532958984375, Entropy -387.87689208984375, Learning Rate: 0.01\n",
      "Epoch [37/20000], Loss: 2017.2276611328125, Entropy -390.5036315917969, Learning Rate: 0.01\n",
      "Epoch [38/20000], Loss: 1964.6119384765625, Entropy -390.6942138671875, Learning Rate: 0.01\n",
      "Epoch [39/20000], Loss: 1915.05029296875, Entropy -403.70648193359375, Learning Rate: 0.01\n",
      "Epoch [40/20000], Loss: 1828.4326171875, Entropy -412.06378173828125, Learning Rate: 0.01\n",
      "Epoch [41/20000], Loss: 1888.29541015625, Entropy -405.2793884277344, Learning Rate: 0.01\n",
      "Epoch [42/20000], Loss: 1897.160888671875, Entropy -398.8271789550781, Learning Rate: 0.01\n",
      "Epoch [43/20000], Loss: 1951.3951416015625, Entropy -422.7322998046875, Learning Rate: 0.01\n",
      "Epoch [44/20000], Loss: 1876.0517578125, Entropy -406.2730712890625, Learning Rate: 0.01\n",
      "Epoch [45/20000], Loss: 1744.151611328125, Entropy -407.45404052734375, Learning Rate: 0.01\n",
      "Epoch [46/20000], Loss: 1884.582275390625, Entropy -397.7969970703125, Learning Rate: 0.01\n",
      "Epoch [47/20000], Loss: 1772.2939453125, Entropy -399.96826171875, Learning Rate: 0.01\n",
      "Epoch [48/20000], Loss: 1810.33203125, Entropy -403.85894775390625, Learning Rate: 0.01\n",
      "Epoch [49/20000], Loss: 1789.244384765625, Entropy -394.1211242675781, Learning Rate: 0.01\n",
      "Epoch [50/20000], Loss: 1830.264892578125, Entropy -398.7723083496094, Learning Rate: 0.01\n",
      "Epoch [51/20000], Loss: 1842.830322265625, Entropy -409.6708984375, Learning Rate: 0.01\n",
      "Epoch [52/20000], Loss: 1774.7742919921875, Entropy -391.7778625488281, Learning Rate: 0.01\n",
      "Epoch [53/20000], Loss: 1793.2147216796875, Entropy -413.3310241699219, Learning Rate: 0.01\n",
      "Epoch [54/20000], Loss: 1749.9561767578125, Entropy -397.1646728515625, Learning Rate: 0.01\n",
      "Epoch [55/20000], Loss: 1705.313232421875, Entropy -406.1247253417969, Learning Rate: 0.01\n",
      "Epoch [56/20000], Loss: 1701.2677001953125, Entropy -396.41632080078125, Learning Rate: 0.01\n",
      "Epoch [57/20000], Loss: 1697.1793212890625, Entropy -394.85174560546875, Learning Rate: 0.01\n",
      "Epoch [58/20000], Loss: 1677.892333984375, Entropy -399.13970947265625, Learning Rate: 0.01\n",
      "Epoch [59/20000], Loss: 1727.027587890625, Entropy -398.2221984863281, Learning Rate: 0.01\n",
      "Epoch [60/20000], Loss: 1667.63330078125, Entropy -393.51214599609375, Learning Rate: 0.01\n",
      "Epoch [61/20000], Loss: 1667.225830078125, Entropy -395.3155517578125, Learning Rate: 0.01\n",
      "Epoch [62/20000], Loss: 1740.9327392578125, Entropy -386.128173828125, Learning Rate: 0.01\n",
      "Epoch [63/20000], Loss: 1654.885498046875, Entropy -405.31689453125, Learning Rate: 0.01\n",
      "Epoch [64/20000], Loss: 1620.558837890625, Entropy -398.99749755859375, Learning Rate: 0.01\n",
      "Epoch [65/20000], Loss: 1685.857666015625, Entropy -403.20941162109375, Learning Rate: 0.01\n",
      "Epoch [66/20000], Loss: 1592.9727783203125, Entropy -391.2397155761719, Learning Rate: 0.01\n",
      "Epoch [67/20000], Loss: 1607.04345703125, Entropy -394.2364196777344, Learning Rate: 0.01\n",
      "Epoch [68/20000], Loss: 1522.815185546875, Entropy -374.886474609375, Learning Rate: 0.01\n",
      "Epoch [69/20000], Loss: 1595.7208251953125, Entropy -373.58648681640625, Learning Rate: 0.01\n",
      "Epoch [70/20000], Loss: 1459.7073974609375, Entropy -374.21533203125, Learning Rate: 0.01\n",
      "Epoch [71/20000], Loss: 1608.98583984375, Entropy -377.87591552734375, Learning Rate: 0.01\n",
      "Epoch [72/20000], Loss: 1450.5833740234375, Entropy -375.1944885253906, Learning Rate: 0.01\n",
      "Epoch [73/20000], Loss: 1418.85888671875, Entropy -369.2830810546875, Learning Rate: 0.01\n",
      "Epoch [74/20000], Loss: 1479.037841796875, Entropy -381.8692932128906, Learning Rate: 0.01\n",
      "Epoch [75/20000], Loss: 1445.85546875, Entropy -376.61041259765625, Learning Rate: 0.01\n",
      "Epoch [76/20000], Loss: 1507.431884765625, Entropy -374.85601806640625, Learning Rate: 0.01\n",
      "Epoch [77/20000], Loss: 1505.650634765625, Entropy -379.60235595703125, Learning Rate: 0.01\n",
      "Epoch [78/20000], Loss: 1432.976318359375, Entropy -386.41070556640625, Learning Rate: 0.01\n",
      "Epoch [79/20000], Loss: 1473.6129150390625, Entropy -386.4465026855469, Learning Rate: 0.01\n",
      "Epoch [80/20000], Loss: 1303.939453125, Entropy -373.3788146972656, Learning Rate: 0.01\n",
      "Epoch [81/20000], Loss: 1459.36181640625, Entropy -366.3390808105469, Learning Rate: 0.01\n",
      "Epoch [82/20000], Loss: 1343.24951171875, Entropy -367.23492431640625, Learning Rate: 0.01\n",
      "Epoch [83/20000], Loss: 1333.8104248046875, Entropy -368.939453125, Learning Rate: 0.01\n",
      "Epoch [84/20000], Loss: 1363.568115234375, Entropy -363.8468017578125, Learning Rate: 0.01\n",
      "Epoch [85/20000], Loss: 1330.6116943359375, Entropy -365.1779479980469, Learning Rate: 0.01\n",
      "Epoch [86/20000], Loss: 1301.111328125, Entropy -349.1029052734375, Learning Rate: 0.01\n",
      "Epoch [87/20000], Loss: 1361.033203125, Entropy -363.6080627441406, Learning Rate: 0.01\n",
      "Epoch [88/20000], Loss: 1265.2232666015625, Entropy -361.03826904296875, Learning Rate: 0.01\n",
      "Epoch [89/20000], Loss: 1286.02783203125, Entropy -371.3034973144531, Learning Rate: 0.01\n",
      "Epoch [90/20000], Loss: 1259.989013671875, Entropy -365.7668762207031, Learning Rate: 0.01\n",
      "Epoch [91/20000], Loss: 1249.1822509765625, Entropy -361.611083984375, Learning Rate: 0.01\n",
      "Epoch [92/20000], Loss: 1342.069580078125, Entropy -357.5626220703125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/20000], Loss: 1210.4833984375, Entropy -358.2379455566406, Learning Rate: 0.01\n",
      "Epoch [94/20000], Loss: 1196.382568359375, Entropy -370.1676025390625, Learning Rate: 0.01\n",
      "Epoch [95/20000], Loss: 1171.7801513671875, Entropy -361.1373291015625, Learning Rate: 0.01\n",
      "Epoch [96/20000], Loss: 1279.456298828125, Entropy -355.40435791015625, Learning Rate: 0.01\n",
      "Epoch [97/20000], Loss: 1193.8828125, Entropy -366.04473876953125, Learning Rate: 0.01\n",
      "Epoch [98/20000], Loss: 1169.6495361328125, Entropy -358.47161865234375, Learning Rate: 0.01\n",
      "Epoch [99/20000], Loss: 1296.508056640625, Entropy -349.8759460449219, Learning Rate: 0.01\n",
      "Epoch [100/20000], Loss: 1216.15234375, Entropy -372.847900390625, Learning Rate: 0.01\n",
      "Epoch [101/20000], Loss: 1204.716796875, Entropy -363.138671875, Learning Rate: 0.01\n",
      "Epoch [102/20000], Loss: 1185.3756103515625, Entropy -364.791259765625, Learning Rate: 0.01\n",
      "Epoch [103/20000], Loss: 1059.039306640625, Entropy -356.1771545410156, Learning Rate: 0.01\n",
      "Epoch [104/20000], Loss: 1141.57177734375, Entropy -363.6697082519531, Learning Rate: 0.01\n",
      "Epoch [105/20000], Loss: 1182.33837890625, Entropy -358.24462890625, Learning Rate: 0.01\n",
      "Epoch [106/20000], Loss: 1113.43115234375, Entropy -360.86956787109375, Learning Rate: 0.01\n",
      "Epoch [107/20000], Loss: 1145.328369140625, Entropy -367.5682067871094, Learning Rate: 0.01\n",
      "Epoch [108/20000], Loss: 1202.631103515625, Entropy -358.4878234863281, Learning Rate: 0.01\n",
      "Epoch [109/20000], Loss: 1079.3455810546875, Entropy -352.8236389160156, Learning Rate: 0.01\n",
      "Epoch [110/20000], Loss: 1025.0040283203125, Entropy -359.2388610839844, Learning Rate: 0.01\n",
      "Epoch [111/20000], Loss: 1163.4227294921875, Entropy -360.286865234375, Learning Rate: 0.01\n",
      "Epoch [112/20000], Loss: 1152.962158203125, Entropy -367.498779296875, Learning Rate: 0.01\n",
      "Epoch [113/20000], Loss: 1161.6094970703125, Entropy -370.4792785644531, Learning Rate: 0.01\n",
      "Epoch [114/20000], Loss: 1027.43701171875, Entropy -355.81964111328125, Learning Rate: 0.01\n",
      "Epoch [115/20000], Loss: 1064.60205078125, Entropy -374.1896057128906, Learning Rate: 0.01\n",
      "Epoch [116/20000], Loss: 1092.511474609375, Entropy -358.8682861328125, Learning Rate: 0.01\n",
      "Epoch [117/20000], Loss: 1043.5787353515625, Entropy -368.2898864746094, Learning Rate: 0.01\n",
      "Epoch [118/20000], Loss: 1042.126953125, Entropy -368.65704345703125, Learning Rate: 0.01\n",
      "Epoch [119/20000], Loss: 1039.67041015625, Entropy -370.6865234375, Learning Rate: 0.01\n",
      "Epoch [120/20000], Loss: 1014.665771484375, Entropy -362.6680603027344, Learning Rate: 0.01\n",
      "Epoch [121/20000], Loss: 946.81298828125, Entropy -367.1382751464844, Learning Rate: 0.01\n",
      "Epoch [122/20000], Loss: 1023.01171875, Entropy -368.538330078125, Learning Rate: 0.01\n",
      "Epoch [123/20000], Loss: 948.7889404296875, Entropy -365.79833984375, Learning Rate: 0.01\n",
      "Epoch [124/20000], Loss: 960.7311401367188, Entropy -370.83221435546875, Learning Rate: 0.01\n",
      "Epoch [125/20000], Loss: 1022.7158203125, Entropy -362.5922546386719, Learning Rate: 0.01\n",
      "Epoch [126/20000], Loss: 977.526611328125, Entropy -370.9541320800781, Learning Rate: 0.01\n",
      "Epoch [127/20000], Loss: 982.5989990234375, Entropy -369.6619567871094, Learning Rate: 0.01\n",
      "Epoch [128/20000], Loss: 933.787109375, Entropy -368.06396484375, Learning Rate: 0.01\n",
      "Epoch [129/20000], Loss: 924.8441772460938, Entropy -382.3928527832031, Learning Rate: 0.01\n",
      "Epoch [130/20000], Loss: 928.9471435546875, Entropy -366.3121337890625, Learning Rate: 0.01\n",
      "Epoch [131/20000], Loss: 918.0364990234375, Entropy -369.63397216796875, Learning Rate: 0.01\n",
      "Epoch [132/20000], Loss: 988.15771484375, Entropy -391.68743896484375, Learning Rate: 0.01\n",
      "Epoch [133/20000], Loss: 929.1087036132812, Entropy -376.27557373046875, Learning Rate: 0.01\n",
      "Epoch [134/20000], Loss: 915.7750854492188, Entropy -374.5787048339844, Learning Rate: 0.01\n",
      "Epoch [135/20000], Loss: 917.7423095703125, Entropy -371.2239685058594, Learning Rate: 0.01\n",
      "Epoch [136/20000], Loss: 917.72314453125, Entropy -361.3843078613281, Learning Rate: 0.01\n",
      "Epoch [137/20000], Loss: 862.990234375, Entropy -371.02294921875, Learning Rate: 0.01\n",
      "Epoch [138/20000], Loss: 843.3366088867188, Entropy -361.6614685058594, Learning Rate: 0.01\n",
      "Epoch [139/20000], Loss: 870.86279296875, Entropy -371.33441162109375, Learning Rate: 0.01\n",
      "Epoch [140/20000], Loss: 998.0072021484375, Entropy -374.8787841796875, Learning Rate: 0.01\n",
      "Epoch [141/20000], Loss: 892.4964599609375, Entropy -365.8455810546875, Learning Rate: 0.01\n",
      "Epoch [142/20000], Loss: 897.17333984375, Entropy -384.8641052246094, Learning Rate: 0.01\n",
      "Epoch [143/20000], Loss: 866.174072265625, Entropy -374.32025146484375, Learning Rate: 0.01\n",
      "Epoch [144/20000], Loss: 935.00927734375, Entropy -383.1541442871094, Learning Rate: 0.01\n",
      "Epoch [145/20000], Loss: 879.2030029296875, Entropy -376.4110107421875, Learning Rate: 0.01\n",
      "Epoch [146/20000], Loss: 868.8203735351562, Entropy -361.4274597167969, Learning Rate: 0.01\n",
      "Epoch [147/20000], Loss: 870.0531616210938, Entropy -375.0304260253906, Learning Rate: 0.01\n",
      "Epoch [148/20000], Loss: 903.8729248046875, Entropy -375.240234375, Learning Rate: 0.01\n",
      "Epoch [149/20000], Loss: 874.587158203125, Entropy -385.1905822753906, Learning Rate: 0.01\n",
      "Epoch [150/20000], Loss: 888.849853515625, Entropy -386.7408447265625, Learning Rate: 0.01\n",
      "Epoch [151/20000], Loss: 865.221923828125, Entropy -382.7771911621094, Learning Rate: 0.01\n",
      "Epoch [152/20000], Loss: 844.2905883789062, Entropy -371.8077392578125, Learning Rate: 0.01\n",
      "Epoch [153/20000], Loss: 881.6278076171875, Entropy -367.153076171875, Learning Rate: 0.01\n",
      "Epoch [154/20000], Loss: 896.0245361328125, Entropy -381.5697326660156, Learning Rate: 0.01\n",
      "Epoch [155/20000], Loss: 854.3033447265625, Entropy -385.9868469238281, Learning Rate: 0.01\n",
      "Epoch [156/20000], Loss: 872.9310302734375, Entropy -385.9859619140625, Learning Rate: 0.01\n",
      "Epoch [157/20000], Loss: 889.080322265625, Entropy -371.783935546875, Learning Rate: 0.01\n",
      "Epoch [158/20000], Loss: 836.48486328125, Entropy -375.70611572265625, Learning Rate: 0.01\n",
      "Epoch [159/20000], Loss: 883.6761474609375, Entropy -379.1949768066406, Learning Rate: 0.01\n",
      "Epoch [160/20000], Loss: 864.1307373046875, Entropy -375.67889404296875, Learning Rate: 0.01\n",
      "Epoch [161/20000], Loss: 847.3086547851562, Entropy -384.40008544921875, Learning Rate: 0.01\n",
      "Epoch [162/20000], Loss: 859.1286010742188, Entropy -378.37872314453125, Learning Rate: 0.01\n",
      "Epoch [163/20000], Loss: 883.0107421875, Entropy -364.4039306640625, Learning Rate: 0.01\n",
      "Epoch [164/20000], Loss: 872.2655029296875, Entropy -376.66986083984375, Learning Rate: 0.01\n",
      "Epoch [165/20000], Loss: 863.33544921875, Entropy -373.8482360839844, Learning Rate: 0.01\n",
      "Epoch [166/20000], Loss: 860.8572387695312, Entropy -376.5108642578125, Learning Rate: 0.01\n",
      "Epoch [167/20000], Loss: 874.368408203125, Entropy -385.26708984375, Learning Rate: 0.01\n",
      "Epoch [168/20000], Loss: 856.7359008789062, Entropy -379.9541931152344, Learning Rate: 0.01\n",
      "Epoch [169/20000], Loss: 858.3900146484375, Entropy -374.03070068359375, Learning Rate: 0.01\n",
      "Epoch [170/20000], Loss: 857.162109375, Entropy -380.8675842285156, Learning Rate: 0.01\n",
      "Epoch [171/20000], Loss: 870.25927734375, Entropy -378.21893310546875, Learning Rate: 0.01\n",
      "Epoch [172/20000], Loss: 855.1661376953125, Entropy -367.2232666015625, Learning Rate: 0.01\n",
      "Epoch [173/20000], Loss: 872.19384765625, Entropy -372.53375244140625, Learning Rate: 0.01\n",
      "Epoch [174/20000], Loss: 858.990478515625, Entropy -378.58447265625, Learning Rate: 0.01\n",
      "Epoch [175/20000], Loss: 918.2141723632812, Entropy -372.3864440917969, Learning Rate: 0.01\n",
      "Epoch [176/20000], Loss: 852.6317749023438, Entropy -383.0942687988281, Learning Rate: 0.01\n",
      "Epoch [177/20000], Loss: 950.5919189453125, Entropy -372.3094787597656, Learning Rate: 0.01\n",
      "Epoch [178/20000], Loss: 895.6255493164062, Entropy -371.677490234375, Learning Rate: 0.01\n",
      "Epoch [179/20000], Loss: 860.153564453125, Entropy -381.50164794921875, Learning Rate: 0.01\n",
      "Epoch [180/20000], Loss: 918.11572265625, Entropy -367.9591064453125, Learning Rate: 0.01\n",
      "Epoch [181/20000], Loss: 881.083251953125, Entropy -372.12615966796875, Learning Rate: 0.01\n",
      "Epoch [182/20000], Loss: 889.2022094726562, Entropy -370.24395751953125, Learning Rate: 0.01\n",
      "Epoch [183/20000], Loss: 893.708251953125, Entropy -379.9423828125, Learning Rate: 0.01\n",
      "Epoch [184/20000], Loss: 881.4039306640625, Entropy -376.3830871582031, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/20000], Loss: 828.5933837890625, Entropy -386.9256591796875, Learning Rate: 0.01\n",
      "Epoch [186/20000], Loss: 903.560302734375, Entropy -383.5079345703125, Learning Rate: 0.01\n",
      "Epoch [187/20000], Loss: 867.0908203125, Entropy -382.0802001953125, Learning Rate: 0.01\n",
      "Epoch [188/20000], Loss: 861.920166015625, Entropy -378.469482421875, Learning Rate: 0.01\n",
      "Epoch [189/20000], Loss: 894.65771484375, Entropy -375.1465148925781, Learning Rate: 0.01\n",
      "Epoch [190/20000], Loss: 863.6829833984375, Entropy -374.1241149902344, Learning Rate: 0.01\n",
      "Epoch [191/20000], Loss: 806.3613891601562, Entropy -382.34716796875, Learning Rate: 0.01\n",
      "Epoch [192/20000], Loss: 915.8748168945312, Entropy -395.01373291015625, Learning Rate: 0.01\n",
      "Epoch [193/20000], Loss: 877.345703125, Entropy -377.55755615234375, Learning Rate: 0.01\n",
      "Epoch [194/20000], Loss: 832.5194702148438, Entropy -380.7595520019531, Learning Rate: 0.01\n",
      "Epoch [195/20000], Loss: 848.833740234375, Entropy -378.593994140625, Learning Rate: 0.01\n",
      "Epoch [196/20000], Loss: 840.4608154296875, Entropy -369.7606201171875, Learning Rate: 0.01\n",
      "Epoch [197/20000], Loss: 845.8115844726562, Entropy -372.7944641113281, Learning Rate: 0.01\n",
      "Epoch [198/20000], Loss: 831.2828979492188, Entropy -367.63751220703125, Learning Rate: 0.01\n",
      "Epoch [199/20000], Loss: 868.3541259765625, Entropy -373.492431640625, Learning Rate: 0.01\n",
      "Epoch [200/20000], Loss: 836.992919921875, Entropy -372.8949890136719, Learning Rate: 0.01\n",
      "Epoch [201/20000], Loss: 837.1300048828125, Entropy -372.772216796875, Learning Rate: 0.01\n",
      "Epoch [202/20000], Loss: 870.9783325195312, Entropy -379.12078857421875, Learning Rate: 0.01\n",
      "Epoch [203/20000], Loss: 829.8299560546875, Entropy -369.0616149902344, Learning Rate: 0.01\n",
      "Epoch [204/20000], Loss: 827.4556884765625, Entropy -368.2681884765625, Learning Rate: 0.01\n",
      "Epoch [205/20000], Loss: 849.970703125, Entropy -373.70355224609375, Learning Rate: 0.01\n",
      "Epoch [206/20000], Loss: 838.2900390625, Entropy -369.0563659667969, Learning Rate: 0.01\n",
      "Epoch [207/20000], Loss: 857.9561767578125, Entropy -368.3132019042969, Learning Rate: 0.01\n",
      "Epoch [208/20000], Loss: 815.5740966796875, Entropy -368.9788818359375, Learning Rate: 0.01\n",
      "Epoch [209/20000], Loss: 822.2850952148438, Entropy -368.7818603515625, Learning Rate: 0.01\n",
      "Epoch [210/20000], Loss: 800.5919799804688, Entropy -368.6275939941406, Learning Rate: 0.01\n",
      "Epoch [211/20000], Loss: 813.2716674804688, Entropy -373.72210693359375, Learning Rate: 0.01\n",
      "Epoch [212/20000], Loss: 802.0972900390625, Entropy -373.4020690917969, Learning Rate: 0.01\n",
      "Epoch [213/20000], Loss: 839.7326049804688, Entropy -376.0782165527344, Learning Rate: 0.01\n",
      "Epoch [214/20000], Loss: 811.25634765625, Entropy -369.6004638671875, Learning Rate: 0.01\n",
      "Epoch [215/20000], Loss: 836.0267944335938, Entropy -372.80865478515625, Learning Rate: 0.01\n",
      "Epoch [216/20000], Loss: 798.784423828125, Entropy -368.4583740234375, Learning Rate: 0.01\n",
      "Epoch [217/20000], Loss: 845.5106201171875, Entropy -379.00946044921875, Learning Rate: 0.01\n",
      "Epoch [218/20000], Loss: 804.6483764648438, Entropy -362.8484802246094, Learning Rate: 0.01\n",
      "Epoch [219/20000], Loss: 831.775146484375, Entropy -365.9405517578125, Learning Rate: 0.01\n",
      "Epoch [220/20000], Loss: 811.4525756835938, Entropy -357.505615234375, Learning Rate: 0.01\n",
      "Epoch [221/20000], Loss: 783.74267578125, Entropy -379.9859924316406, Learning Rate: 0.01\n",
      "Epoch [222/20000], Loss: 799.3485107421875, Entropy -357.3459167480469, Learning Rate: 0.01\n",
      "Epoch [223/20000], Loss: 782.8623046875, Entropy -357.5953063964844, Learning Rate: 0.01\n",
      "Epoch [224/20000], Loss: 835.8673706054688, Entropy -365.4837951660156, Learning Rate: 0.01\n",
      "Epoch [225/20000], Loss: 778.0640869140625, Entropy -364.96405029296875, Learning Rate: 0.01\n",
      "Epoch [226/20000], Loss: 824.2152099609375, Entropy -355.49591064453125, Learning Rate: 0.01\n",
      "Epoch [227/20000], Loss: 810.977783203125, Entropy -363.3822326660156, Learning Rate: 0.01\n",
      "Epoch [228/20000], Loss: 777.703857421875, Entropy -358.6972351074219, Learning Rate: 0.01\n",
      "Epoch [229/20000], Loss: 808.093505859375, Entropy -380.6846008300781, Learning Rate: 0.01\n",
      "Epoch [230/20000], Loss: 800.169921875, Entropy -362.6734313964844, Learning Rate: 0.01\n",
      "Epoch [231/20000], Loss: 782.781005859375, Entropy -359.7909240722656, Learning Rate: 0.01\n",
      "Epoch [232/20000], Loss: 796.78271484375, Entropy -368.947021484375, Learning Rate: 0.01\n",
      "Epoch [233/20000], Loss: 801.775634765625, Entropy -362.97613525390625, Learning Rate: 0.01\n",
      "Epoch [234/20000], Loss: 835.7938232421875, Entropy -368.50067138671875, Learning Rate: 0.01\n",
      "Epoch [235/20000], Loss: 779.4739990234375, Entropy -358.8503112792969, Learning Rate: 0.01\n",
      "Epoch [236/20000], Loss: 803.069091796875, Entropy -361.8609619140625, Learning Rate: 0.01\n",
      "Epoch [237/20000], Loss: 797.9954833984375, Entropy -355.45843505859375, Learning Rate: 0.01\n",
      "Epoch [238/20000], Loss: 788.6820068359375, Entropy -356.90521240234375, Learning Rate: 0.01\n",
      "Epoch [239/20000], Loss: 788.9791259765625, Entropy -354.8153076171875, Learning Rate: 0.01\n",
      "Epoch [240/20000], Loss: 802.9918212890625, Entropy -350.9104919433594, Learning Rate: 0.01\n",
      "Epoch [241/20000], Loss: 811.6940307617188, Entropy -364.5751953125, Learning Rate: 0.01\n",
      "Epoch [242/20000], Loss: 796.3107299804688, Entropy -354.8179931640625, Learning Rate: 0.01\n",
      "Epoch [243/20000], Loss: 786.2749633789062, Entropy -362.5594787597656, Learning Rate: 0.01\n",
      "Epoch [244/20000], Loss: 802.2354125976562, Entropy -359.1077575683594, Learning Rate: 0.01\n",
      "Epoch [245/20000], Loss: 738.6731567382812, Entropy -353.83062744140625, Learning Rate: 0.01\n",
      "Epoch [246/20000], Loss: 739.8621215820312, Entropy -351.5662536621094, Learning Rate: 0.01\n",
      "Epoch [247/20000], Loss: 827.21142578125, Entropy -350.7684020996094, Learning Rate: 0.01\n",
      "Epoch [248/20000], Loss: 821.393798828125, Entropy -345.4613952636719, Learning Rate: 0.01\n",
      "Epoch [249/20000], Loss: 823.8041381835938, Entropy -354.86285400390625, Learning Rate: 0.01\n",
      "Epoch [250/20000], Loss: 811.9900512695312, Entropy -355.821044921875, Learning Rate: 0.01\n",
      "Epoch [251/20000], Loss: 773.1062622070312, Entropy -358.38690185546875, Learning Rate: 0.01\n",
      "Epoch [252/20000], Loss: 786.4672241210938, Entropy -340.1731872558594, Learning Rate: 0.01\n",
      "Epoch [253/20000], Loss: 758.983154296875, Entropy -353.34100341796875, Learning Rate: 0.01\n",
      "Epoch [254/20000], Loss: 763.226318359375, Entropy -344.25933837890625, Learning Rate: 0.01\n",
      "Epoch [255/20000], Loss: 751.5247802734375, Entropy -348.1148376464844, Learning Rate: 0.01\n",
      "Epoch [256/20000], Loss: 742.9049072265625, Entropy -353.6484375, Learning Rate: 0.01\n",
      "Epoch [257/20000], Loss: 711.6005859375, Entropy -346.0815734863281, Learning Rate: 0.01\n",
      "Epoch [258/20000], Loss: 715.9129638671875, Entropy -348.4559020996094, Learning Rate: 0.01\n",
      "Epoch [259/20000], Loss: 812.009765625, Entropy -345.1112060546875, Learning Rate: 0.01\n",
      "Epoch [260/20000], Loss: 751.866943359375, Entropy -352.7632751464844, Learning Rate: 0.01\n",
      "Epoch [261/20000], Loss: 761.6724853515625, Entropy -345.23760986328125, Learning Rate: 0.01\n",
      "Epoch [262/20000], Loss: 747.7147827148438, Entropy -353.184814453125, Learning Rate: 0.01\n",
      "Epoch [263/20000], Loss: 718.964111328125, Entropy -343.7760925292969, Learning Rate: 0.01\n",
      "Epoch [264/20000], Loss: 752.0645751953125, Entropy -350.6793518066406, Learning Rate: 0.01\n",
      "Epoch [265/20000], Loss: 705.3547973632812, Entropy -347.6681213378906, Learning Rate: 0.01\n",
      "Epoch [266/20000], Loss: 675.2220458984375, Entropy -344.3219909667969, Learning Rate: 0.01\n",
      "Epoch [267/20000], Loss: 713.6994018554688, Entropy -344.65740966796875, Learning Rate: 0.01\n",
      "Epoch [268/20000], Loss: 674.7716674804688, Entropy -342.29180908203125, Learning Rate: 0.01\n",
      "Epoch [269/20000], Loss: 711.1543579101562, Entropy -340.0655517578125, Learning Rate: 0.01\n",
      "Epoch [270/20000], Loss: 681.2574462890625, Entropy -338.53460693359375, Learning Rate: 0.01\n",
      "Epoch [271/20000], Loss: 693.2353515625, Entropy -344.43206787109375, Learning Rate: 0.01\n",
      "Epoch [272/20000], Loss: 776.0316772460938, Entropy -342.70062255859375, Learning Rate: 0.01\n",
      "Epoch [273/20000], Loss: 704.5914916992188, Entropy -345.75299072265625, Learning Rate: 0.01\n",
      "Epoch [274/20000], Loss: 692.4281616210938, Entropy -341.594482421875, Learning Rate: 0.01\n",
      "Epoch [275/20000], Loss: 753.091796875, Entropy -330.878662109375, Learning Rate: 0.01\n",
      "Epoch [276/20000], Loss: 700.9972534179688, Entropy -336.21026611328125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [277/20000], Loss: 690.6685791015625, Entropy -339.6494140625, Learning Rate: 0.01\n",
      "Epoch [278/20000], Loss: 698.1328735351562, Entropy -333.49542236328125, Learning Rate: 0.01\n",
      "Epoch [279/20000], Loss: 730.813720703125, Entropy -321.7376708984375, Learning Rate: 0.01\n",
      "Epoch [280/20000], Loss: 646.1891479492188, Entropy -341.429443359375, Learning Rate: 0.01\n",
      "Epoch [281/20000], Loss: 686.7725830078125, Entropy -337.5199279785156, Learning Rate: 0.01\n",
      "Epoch [282/20000], Loss: 684.1298828125, Entropy -335.782958984375, Learning Rate: 0.01\n",
      "Epoch [283/20000], Loss: 615.8395385742188, Entropy -326.9752197265625, Learning Rate: 0.01\n",
      "Epoch [284/20000], Loss: 631.5377197265625, Entropy -337.7322998046875, Learning Rate: 0.01\n",
      "Epoch [285/20000], Loss: 641.0888061523438, Entropy -328.8880920410156, Learning Rate: 0.01\n",
      "Epoch [286/20000], Loss: 661.6477661132812, Entropy -325.85284423828125, Learning Rate: 0.01\n",
      "Epoch [287/20000], Loss: 609.8319702148438, Entropy -337.42626953125, Learning Rate: 0.01\n",
      "Epoch [288/20000], Loss: 623.7405395507812, Entropy -334.30072021484375, Learning Rate: 0.01\n",
      "Epoch [289/20000], Loss: 669.009765625, Entropy -328.4547424316406, Learning Rate: 0.01\n",
      "Epoch [290/20000], Loss: 685.4393310546875, Entropy -331.15667724609375, Learning Rate: 0.01\n",
      "Epoch [291/20000], Loss: 728.631103515625, Entropy -332.8291931152344, Learning Rate: 0.01\n",
      "Epoch [292/20000], Loss: 582.7799682617188, Entropy -347.3367919921875, Learning Rate: 0.01\n",
      "Epoch [293/20000], Loss: 687.1361083984375, Entropy -333.00787353515625, Learning Rate: 0.01\n",
      "Epoch [294/20000], Loss: 620.11181640625, Entropy -339.09210205078125, Learning Rate: 0.01\n",
      "Epoch [295/20000], Loss: 773.9798583984375, Entropy -335.2532653808594, Learning Rate: 0.01\n",
      "Epoch [296/20000], Loss: 672.8342895507812, Entropy -341.8950500488281, Learning Rate: 0.01\n",
      "Epoch [297/20000], Loss: 628.3187866210938, Entropy -336.67779541015625, Learning Rate: 0.01\n",
      "Epoch [298/20000], Loss: 754.8779296875, Entropy -344.82818603515625, Learning Rate: 0.01\n",
      "Epoch [299/20000], Loss: 564.331298828125, Entropy -332.9989013671875, Learning Rate: 0.01\n",
      "Epoch [300/20000], Loss: 689.7916870117188, Entropy -341.1164245605469, Learning Rate: 0.01\n",
      "Epoch [301/20000], Loss: 643.2028198242188, Entropy -344.3963623046875, Learning Rate: 0.01\n",
      "Epoch [302/20000], Loss: 616.75244140625, Entropy -333.3858947753906, Learning Rate: 0.01\n",
      "Epoch [303/20000], Loss: 707.7899780273438, Entropy -330.4451599121094, Learning Rate: 0.01\n",
      "Epoch [304/20000], Loss: 564.9177856445312, Entropy -333.2788391113281, Learning Rate: 0.01\n",
      "Epoch [305/20000], Loss: 608.0398559570312, Entropy -325.4989318847656, Learning Rate: 0.01\n",
      "Epoch [306/20000], Loss: 717.496337890625, Entropy -326.4048156738281, Learning Rate: 0.01\n",
      "Epoch [307/20000], Loss: 683.072509765625, Entropy -326.3610534667969, Learning Rate: 0.01\n",
      "Epoch [308/20000], Loss: 649.3609619140625, Entropy -331.24859619140625, Learning Rate: 0.01\n",
      "Epoch [309/20000], Loss: 897.4783935546875, Entropy -312.1086120605469, Learning Rate: 0.01\n",
      "Epoch [310/20000], Loss: 675.7263793945312, Entropy -329.0634765625, Learning Rate: 0.01\n",
      "Epoch [311/20000], Loss: 833.708984375, Entropy -328.8898620605469, Learning Rate: 0.01\n",
      "Epoch [312/20000], Loss: 618.1477661132812, Entropy -317.45458984375, Learning Rate: 0.01\n",
      "Epoch [313/20000], Loss: 635.992919921875, Entropy -324.47454833984375, Learning Rate: 0.01\n",
      "Epoch [314/20000], Loss: 846.35107421875, Entropy -331.3636474609375, Learning Rate: 0.01\n",
      "Epoch [315/20000], Loss: 795.1212158203125, Entropy -321.10406494140625, Learning Rate: 0.01\n",
      "Epoch [316/20000], Loss: 665.4073486328125, Entropy -320.1627502441406, Learning Rate: 0.01\n",
      "Epoch [317/20000], Loss: 790.6344604492188, Entropy -331.322021484375, Learning Rate: 0.01\n",
      "Epoch [318/20000], Loss: 636.6760864257812, Entropy -333.2198181152344, Learning Rate: 0.01\n",
      "Epoch [319/20000], Loss: 577.572509765625, Entropy -339.1666259765625, Learning Rate: 0.01\n",
      "Epoch [320/20000], Loss: 810.9689331054688, Entropy -336.25811767578125, Learning Rate: 0.01\n",
      "Epoch [321/20000], Loss: 636.1683349609375, Entropy -341.0973205566406, Learning Rate: 0.01\n",
      "Epoch [322/20000], Loss: 510.3658752441406, Entropy -331.5677490234375, Learning Rate: 0.01\n",
      "Epoch [323/20000], Loss: 619.8646850585938, Entropy -320.6279602050781, Learning Rate: 0.01\n",
      "Epoch [324/20000], Loss: 601.7026977539062, Entropy -330.0030822753906, Learning Rate: 0.01\n",
      "Epoch [325/20000], Loss: 595.307373046875, Entropy -336.0313720703125, Learning Rate: 0.01\n",
      "Epoch [326/20000], Loss: 551.1212768554688, Entropy -331.5903015136719, Learning Rate: 0.01\n",
      "Epoch [327/20000], Loss: 553.434326171875, Entropy -330.9943542480469, Learning Rate: 0.01\n",
      "Epoch [328/20000], Loss: 521.3092041015625, Entropy -330.22515869140625, Learning Rate: 0.01\n",
      "Epoch [329/20000], Loss: 620.4292602539062, Entropy -332.41326904296875, Learning Rate: 0.01\n",
      "Epoch [330/20000], Loss: 548.5413208007812, Entropy -333.13232421875, Learning Rate: 0.01\n",
      "Epoch [331/20000], Loss: 479.7713928222656, Entropy -340.3073425292969, Learning Rate: 0.01\n",
      "Epoch [332/20000], Loss: 502.7060546875, Entropy -330.83782958984375, Learning Rate: 0.01\n",
      "Epoch [333/20000], Loss: 602.21240234375, Entropy -333.74237060546875, Learning Rate: 0.01\n",
      "Epoch [334/20000], Loss: 522.78955078125, Entropy -331.1419677734375, Learning Rate: 0.01\n",
      "Epoch [335/20000], Loss: 540.4374389648438, Entropy -323.296630859375, Learning Rate: 0.01\n",
      "Epoch [336/20000], Loss: 514.2285766601562, Entropy -340.0043029785156, Learning Rate: 0.01\n",
      "Epoch [337/20000], Loss: 565.8546142578125, Entropy -334.7500305175781, Learning Rate: 0.01\n",
      "Epoch [338/20000], Loss: 513.1248168945312, Entropy -326.1024169921875, Learning Rate: 0.01\n",
      "Epoch [339/20000], Loss: 498.1276550292969, Entropy -324.7744140625, Learning Rate: 0.01\n",
      "Epoch [340/20000], Loss: 705.98095703125, Entropy -328.3601989746094, Learning Rate: 0.01\n",
      "Epoch [341/20000], Loss: 501.073486328125, Entropy -326.0203552246094, Learning Rate: 0.01\n",
      "Epoch [342/20000], Loss: 589.5260620117188, Entropy -316.47088623046875, Learning Rate: 0.01\n",
      "Epoch [343/20000], Loss: 649.8237915039062, Entropy -322.5121765136719, Learning Rate: 0.01\n",
      "Epoch [344/20000], Loss: 472.9580383300781, Entropy -336.9458312988281, Learning Rate: 0.01\n",
      "Epoch [345/20000], Loss: 574.9432373046875, Entropy -330.79925537109375, Learning Rate: 0.01\n",
      "Epoch [346/20000], Loss: 490.041015625, Entropy -331.1112976074219, Learning Rate: 0.01\n",
      "Epoch [347/20000], Loss: 660.8740234375, Entropy -327.3302917480469, Learning Rate: 0.01\n",
      "Epoch [348/20000], Loss: 534.3746948242188, Entropy -336.6148376464844, Learning Rate: 0.01\n",
      "Epoch [349/20000], Loss: 458.37689208984375, Entropy -327.3512268066406, Learning Rate: 0.01\n",
      "Epoch [350/20000], Loss: 548.7759399414062, Entropy -336.0537109375, Learning Rate: 0.01\n",
      "Epoch [351/20000], Loss: 519.5668334960938, Entropy -322.57763671875, Learning Rate: 0.01\n",
      "Epoch [352/20000], Loss: 483.0629577636719, Entropy -328.1014404296875, Learning Rate: 0.01\n",
      "Epoch [353/20000], Loss: 488.1569519042969, Entropy -336.6898498535156, Learning Rate: 0.01\n",
      "Epoch [354/20000], Loss: 539.8511962890625, Entropy -329.01434326171875, Learning Rate: 0.01\n",
      "Epoch [355/20000], Loss: 378.88897705078125, Entropy -329.7265930175781, Learning Rate: 0.01\n",
      "Epoch [356/20000], Loss: 446.1978759765625, Entropy -333.8467102050781, Learning Rate: 0.01\n",
      "Epoch [357/20000], Loss: 517.2272338867188, Entropy -334.52313232421875, Learning Rate: 0.01\n",
      "Epoch [358/20000], Loss: 524.7999877929688, Entropy -334.017333984375, Learning Rate: 0.01\n",
      "Epoch [359/20000], Loss: 435.9707946777344, Entropy -331.5210876464844, Learning Rate: 0.01\n",
      "Epoch [360/20000], Loss: 419.6413269042969, Entropy -343.35247802734375, Learning Rate: 0.01\n",
      "Epoch [361/20000], Loss: 453.6701965332031, Entropy -332.1758728027344, Learning Rate: 0.01\n",
      "Epoch [362/20000], Loss: 498.20068359375, Entropy -322.3031921386719, Learning Rate: 0.01\n",
      "Epoch [363/20000], Loss: 409.76763916015625, Entropy -324.77960205078125, Learning Rate: 0.01\n",
      "Epoch [364/20000], Loss: 388.00592041015625, Entropy -331.177978515625, Learning Rate: 0.01\n",
      "Epoch [365/20000], Loss: 436.3182067871094, Entropy -329.7943420410156, Learning Rate: 0.01\n",
      "Epoch [366/20000], Loss: 403.8674621582031, Entropy -337.7890930175781, Learning Rate: 0.01\n",
      "Epoch [367/20000], Loss: 397.4687805175781, Entropy -342.27801513671875, Learning Rate: 0.01\n",
      "Epoch [368/20000], Loss: 402.83892822265625, Entropy -333.0364990234375, Learning Rate: 0.01\n",
      "Epoch [369/20000], Loss: 384.94403076171875, Entropy -334.62799072265625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [370/20000], Loss: 374.048095703125, Entropy -337.89385986328125, Learning Rate: 0.01\n",
      "Epoch [371/20000], Loss: 399.0714416503906, Entropy -337.3543395996094, Learning Rate: 0.01\n",
      "Epoch [372/20000], Loss: 412.343505859375, Entropy -329.0572814941406, Learning Rate: 0.01\n",
      "Epoch [373/20000], Loss: 395.1407470703125, Entropy -338.8208923339844, Learning Rate: 0.01\n",
      "Epoch [374/20000], Loss: 348.4022216796875, Entropy -321.48809814453125, Learning Rate: 0.01\n",
      "Epoch [375/20000], Loss: 365.0540466308594, Entropy -340.1568603515625, Learning Rate: 0.01\n",
      "Epoch [376/20000], Loss: 381.3280944824219, Entropy -328.4397277832031, Learning Rate: 0.01\n",
      "Epoch [377/20000], Loss: 369.83660888671875, Entropy -331.9544982910156, Learning Rate: 0.01\n",
      "Epoch [378/20000], Loss: 352.357177734375, Entropy -344.2488708496094, Learning Rate: 0.01\n",
      "Epoch [379/20000], Loss: 368.9476318359375, Entropy -333.5129699707031, Learning Rate: 0.01\n",
      "Epoch [380/20000], Loss: 370.0797119140625, Entropy -338.2281188964844, Learning Rate: 0.01\n",
      "Epoch [381/20000], Loss: 341.1870422363281, Entropy -323.40667724609375, Learning Rate: 0.01\n",
      "Epoch [382/20000], Loss: 346.49884033203125, Entropy -337.4925231933594, Learning Rate: 0.01\n",
      "Epoch [383/20000], Loss: 369.63037109375, Entropy -338.4724426269531, Learning Rate: 0.01\n",
      "Epoch [384/20000], Loss: 389.515869140625, Entropy -341.82659912109375, Learning Rate: 0.01\n",
      "Epoch [385/20000], Loss: 368.00946044921875, Entropy -346.20166015625, Learning Rate: 0.01\n",
      "Epoch [386/20000], Loss: 348.9080810546875, Entropy -334.1176452636719, Learning Rate: 0.01\n",
      "Epoch [387/20000], Loss: 337.079833984375, Entropy -330.94000244140625, Learning Rate: 0.01\n",
      "Epoch [388/20000], Loss: 358.90594482421875, Entropy -334.0765075683594, Learning Rate: 0.01\n",
      "Epoch [389/20000], Loss: 346.138671875, Entropy -333.81268310546875, Learning Rate: 0.01\n",
      "Epoch [390/20000], Loss: 358.75030517578125, Entropy -338.486083984375, Learning Rate: 0.01\n",
      "Epoch [391/20000], Loss: 348.9302978515625, Entropy -332.857177734375, Learning Rate: 0.01\n",
      "Epoch [392/20000], Loss: 346.74530029296875, Entropy -335.89080810546875, Learning Rate: 0.01\n",
      "Epoch [393/20000], Loss: 327.42987060546875, Entropy -326.8181457519531, Learning Rate: 0.01\n",
      "Epoch [394/20000], Loss: 340.36712646484375, Entropy -331.43994140625, Learning Rate: 0.01\n",
      "Epoch [395/20000], Loss: 357.5279541015625, Entropy -344.1611328125, Learning Rate: 0.01\n",
      "Epoch [396/20000], Loss: 349.1298522949219, Entropy -334.9822082519531, Learning Rate: 0.01\n",
      "Epoch [397/20000], Loss: 349.3426513671875, Entropy -335.93798828125, Learning Rate: 0.01\n",
      "Epoch [398/20000], Loss: 349.4447937011719, Entropy -336.3274841308594, Learning Rate: 0.01\n",
      "Epoch [399/20000], Loss: 354.3461608886719, Entropy -327.822265625, Learning Rate: 0.01\n",
      "Epoch [400/20000], Loss: 324.6286315917969, Entropy -321.24566650390625, Learning Rate: 0.01\n",
      "Epoch [401/20000], Loss: 336.0157165527344, Entropy -334.4620056152344, Learning Rate: 0.01\n",
      "Epoch [402/20000], Loss: 350.9475402832031, Entropy -333.9198303222656, Learning Rate: 0.01\n",
      "Epoch [403/20000], Loss: 316.69171142578125, Entropy -318.858154296875, Learning Rate: 0.01\n",
      "Epoch [404/20000], Loss: 340.7076110839844, Entropy -340.586181640625, Learning Rate: 0.01\n",
      "Epoch [405/20000], Loss: 344.2371520996094, Entropy -335.33770751953125, Learning Rate: 0.01\n",
      "Epoch [406/20000], Loss: 336.6962585449219, Entropy -321.051025390625, Learning Rate: 0.01\n",
      "Epoch [407/20000], Loss: 320.85650634765625, Entropy -326.2720642089844, Learning Rate: 0.01\n",
      "Epoch [408/20000], Loss: 356.117431640625, Entropy -335.150390625, Learning Rate: 0.01\n",
      "Epoch [409/20000], Loss: 358.6283874511719, Entropy -340.56109619140625, Learning Rate: 0.01\n",
      "Epoch [410/20000], Loss: 335.8434143066406, Entropy -321.4759826660156, Learning Rate: 0.01\n",
      "Epoch [411/20000], Loss: 340.5132141113281, Entropy -332.6442565917969, Learning Rate: 0.01\n",
      "Epoch [412/20000], Loss: 342.15765380859375, Entropy -328.0426330566406, Learning Rate: 0.01\n",
      "Epoch [413/20000], Loss: 342.78924560546875, Entropy -334.3544616699219, Learning Rate: 0.01\n",
      "Epoch [414/20000], Loss: 331.2317199707031, Entropy -323.997314453125, Learning Rate: 0.01\n",
      "Epoch [415/20000], Loss: 340.2996826171875, Entropy -333.6090393066406, Learning Rate: 0.01\n",
      "Epoch [416/20000], Loss: 350.7414245605469, Entropy -336.53277587890625, Learning Rate: 0.01\n",
      "Epoch [417/20000], Loss: 332.44158935546875, Entropy -326.2733459472656, Learning Rate: 0.01\n",
      "Epoch [418/20000], Loss: 342.31707763671875, Entropy -328.38250732421875, Learning Rate: 0.01\n",
      "Epoch [419/20000], Loss: 348.56439208984375, Entropy -338.89111328125, Learning Rate: 0.01\n",
      "Epoch [420/20000], Loss: 321.91748046875, Entropy -315.573486328125, Learning Rate: 0.01\n",
      "Epoch [421/20000], Loss: 336.3321533203125, Entropy -332.095703125, Learning Rate: 0.01\n",
      "Epoch [422/20000], Loss: 326.3182067871094, Entropy -311.4276123046875, Learning Rate: 0.01\n",
      "Epoch [423/20000], Loss: 325.4970703125, Entropy -309.2552185058594, Learning Rate: 0.01\n",
      "Epoch [424/20000], Loss: 330.0832824707031, Entropy -318.77874755859375, Learning Rate: 0.01\n",
      "Epoch [425/20000], Loss: 334.888427734375, Entropy -320.2203674316406, Learning Rate: 0.01\n",
      "Epoch [426/20000], Loss: 342.49432373046875, Entropy -331.7153015136719, Learning Rate: 0.01\n",
      "Epoch [427/20000], Loss: 333.9493103027344, Entropy -317.2308044433594, Learning Rate: 0.01\n",
      "Epoch [428/20000], Loss: 314.739013671875, Entropy -323.1131896972656, Learning Rate: 0.01\n",
      "Epoch [429/20000], Loss: 335.30596923828125, Entropy -316.8816223144531, Learning Rate: 0.01\n",
      "Epoch [430/20000], Loss: 306.0163269042969, Entropy -310.2679748535156, Learning Rate: 0.01\n",
      "Epoch [431/20000], Loss: 322.69708251953125, Entropy -324.48663330078125, Learning Rate: 0.01\n",
      "Epoch [432/20000], Loss: 337.0272521972656, Entropy -329.7130432128906, Learning Rate: 0.01\n",
      "Epoch [433/20000], Loss: 337.00177001953125, Entropy -342.7969665527344, Learning Rate: 0.01\n",
      "Epoch [434/20000], Loss: 319.563720703125, Entropy -320.7488098144531, Learning Rate: 0.01\n",
      "Epoch [435/20000], Loss: 327.6180725097656, Entropy -331.868896484375, Learning Rate: 0.01\n",
      "Epoch [436/20000], Loss: 353.05755615234375, Entropy -330.33636474609375, Learning Rate: 0.01\n",
      "Epoch [437/20000], Loss: 324.5698547363281, Entropy -321.01934814453125, Learning Rate: 0.01\n",
      "Epoch [438/20000], Loss: 306.21539306640625, Entropy -318.9046936035156, Learning Rate: 0.01\n",
      "Epoch [439/20000], Loss: 332.769287109375, Entropy -324.6033935546875, Learning Rate: 0.01\n",
      "Epoch [440/20000], Loss: 322.6909484863281, Entropy -318.1556396484375, Learning Rate: 0.01\n",
      "Epoch [441/20000], Loss: 313.3291931152344, Entropy -316.37225341796875, Learning Rate: 0.01\n",
      "Epoch [442/20000], Loss: 335.4653015136719, Entropy -330.0431823730469, Learning Rate: 0.01\n",
      "Epoch [443/20000], Loss: 317.51788330078125, Entropy -331.22552490234375, Learning Rate: 0.01\n",
      "Epoch [444/20000], Loss: 322.48345947265625, Entropy -318.9402160644531, Learning Rate: 0.01\n",
      "Epoch [445/20000], Loss: 316.6183166503906, Entropy -310.3162841796875, Learning Rate: 0.01\n",
      "Epoch [446/20000], Loss: 309.1402282714844, Entropy -313.0664367675781, Learning Rate: 0.01\n",
      "Epoch [447/20000], Loss: 324.3641357421875, Entropy -320.042236328125, Learning Rate: 0.01\n",
      "Epoch [448/20000], Loss: 341.7215270996094, Entropy -322.4661560058594, Learning Rate: 0.01\n",
      "Epoch [449/20000], Loss: 332.15106201171875, Entropy -313.6559753417969, Learning Rate: 0.01\n",
      "Epoch [450/20000], Loss: 289.51495361328125, Entropy -305.546142578125, Learning Rate: 0.01\n",
      "Epoch [451/20000], Loss: 325.09246826171875, Entropy -322.4538879394531, Learning Rate: 0.01\n",
      "Epoch [452/20000], Loss: 331.15228271484375, Entropy -324.3645935058594, Learning Rate: 0.01\n",
      "Epoch [453/20000], Loss: 313.7496032714844, Entropy -319.3949890136719, Learning Rate: 0.01\n",
      "Epoch [454/20000], Loss: 323.6911315917969, Entropy -314.9659729003906, Learning Rate: 0.01\n",
      "Epoch [455/20000], Loss: 308.8648681640625, Entropy -310.8974914550781, Learning Rate: 0.01\n",
      "Epoch [456/20000], Loss: 352.5896911621094, Entropy -318.9391174316406, Learning Rate: 0.01\n",
      "Epoch [457/20000], Loss: 303.4759826660156, Entropy -299.1780700683594, Learning Rate: 0.01\n",
      "Epoch [458/20000], Loss: 313.1038513183594, Entropy -299.7591857910156, Learning Rate: 0.01\n",
      "Epoch [459/20000], Loss: 300.0096435546875, Entropy -304.4743957519531, Learning Rate: 0.01\n",
      "Epoch [460/20000], Loss: 310.6192626953125, Entropy -305.3276062011719, Learning Rate: 0.01\n",
      "Epoch [461/20000], Loss: 331.466552734375, Entropy -314.8951721191406, Learning Rate: 0.01\n",
      "Epoch [462/20000], Loss: 349.6995849609375, Entropy -310.4106140136719, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [463/20000], Loss: 317.0667724609375, Entropy -310.0008544921875, Learning Rate: 0.01\n",
      "Epoch [464/20000], Loss: 331.34857177734375, Entropy -309.4884033203125, Learning Rate: 0.01\n",
      "Epoch [465/20000], Loss: 320.771240234375, Entropy -312.35064697265625, Learning Rate: 0.01\n",
      "Epoch [466/20000], Loss: 360.2376403808594, Entropy -305.4042053222656, Learning Rate: 0.01\n",
      "Epoch [467/20000], Loss: 300.2474060058594, Entropy -295.27655029296875, Learning Rate: 0.01\n",
      "Epoch [468/20000], Loss: 333.408447265625, Entropy -312.9112548828125, Learning Rate: 0.01\n",
      "Epoch [469/20000], Loss: 335.8448791503906, Entropy -322.86181640625, Learning Rate: 0.01\n",
      "Epoch [470/20000], Loss: 309.5675048828125, Entropy -308.7554016113281, Learning Rate: 0.01\n",
      "Epoch [471/20000], Loss: 313.9311828613281, Entropy -321.68109130859375, Learning Rate: 0.01\n",
      "Epoch [472/20000], Loss: 342.55120849609375, Entropy -307.4255676269531, Learning Rate: 0.01\n",
      "Epoch [473/20000], Loss: 339.6944580078125, Entropy -306.1761474609375, Learning Rate: 0.01\n",
      "Epoch [474/20000], Loss: 322.0947265625, Entropy -309.59375, Learning Rate: 0.01\n",
      "Epoch [475/20000], Loss: 322.9970397949219, Entropy -311.5647888183594, Learning Rate: 0.01\n",
      "Epoch [476/20000], Loss: 330.77288818359375, Entropy -312.2055358886719, Learning Rate: 0.01\n",
      "Epoch [477/20000], Loss: 352.15625, Entropy -310.36322021484375, Learning Rate: 0.01\n",
      "Epoch [478/20000], Loss: 319.4055480957031, Entropy -322.66522216796875, Learning Rate: 0.01\n",
      "Epoch [479/20000], Loss: 362.6329345703125, Entropy -307.17242431640625, Learning Rate: 0.01\n",
      "Epoch [480/20000], Loss: 317.3384704589844, Entropy -305.2320251464844, Learning Rate: 0.01\n",
      "Epoch [481/20000], Loss: 376.89349365234375, Entropy -316.57904052734375, Learning Rate: 0.01\n",
      "Epoch [482/20000], Loss: 316.2645263671875, Entropy -310.08447265625, Learning Rate: 0.01\n",
      "Epoch [483/20000], Loss: 363.7849426269531, Entropy -302.8619079589844, Learning Rate: 0.01\n",
      "Epoch [484/20000], Loss: 334.45849609375, Entropy -311.45196533203125, Learning Rate: 0.01\n",
      "Epoch [485/20000], Loss: 338.8922119140625, Entropy -307.23846435546875, Learning Rate: 0.01\n",
      "Epoch [486/20000], Loss: 349.8475036621094, Entropy -306.6022033691406, Learning Rate: 0.01\n",
      "Epoch [487/20000], Loss: 308.63104248046875, Entropy -301.8550720214844, Learning Rate: 0.01\n",
      "Epoch [488/20000], Loss: 324.745849609375, Entropy -309.04425048828125, Learning Rate: 0.01\n",
      "Epoch [489/20000], Loss: 337.3830871582031, Entropy -320.8775329589844, Learning Rate: 0.01\n",
      "Epoch [490/20000], Loss: 352.5628356933594, Entropy -308.6645812988281, Learning Rate: 0.01\n",
      "Epoch [491/20000], Loss: 311.2747497558594, Entropy -307.3887939453125, Learning Rate: 0.01\n",
      "Epoch [492/20000], Loss: 315.15521240234375, Entropy -307.4278259277344, Learning Rate: 0.01\n",
      "Epoch [493/20000], Loss: 315.8988952636719, Entropy -296.567626953125, Learning Rate: 0.01\n",
      "Epoch [494/20000], Loss: 347.9571228027344, Entropy -308.9784851074219, Learning Rate: 0.01\n",
      "Epoch [495/20000], Loss: 340.29437255859375, Entropy -303.6900634765625, Learning Rate: 0.01\n",
      "Epoch [496/20000], Loss: 339.27325439453125, Entropy -297.39398193359375, Learning Rate: 0.01\n",
      "Epoch [497/20000], Loss: 335.3492431640625, Entropy -305.7738342285156, Learning Rate: 0.01\n",
      "Epoch [498/20000], Loss: 348.0340576171875, Entropy -312.21502685546875, Learning Rate: 0.01\n",
      "Epoch [499/20000], Loss: 366.01568603515625, Entropy -300.7111511230469, Learning Rate: 0.01\n",
      "Epoch [500/20000], Loss: 304.23272705078125, Entropy -301.12567138671875, Learning Rate: 0.01\n",
      "Epoch [501/20000], Loss: 353.04852294921875, Entropy -312.3393249511719, Learning Rate: 0.01\n",
      "Epoch [502/20000], Loss: 326.7209777832031, Entropy -306.8565368652344, Learning Rate: 0.01\n",
      "Epoch [503/20000], Loss: 322.6494445800781, Entropy -300.8008728027344, Learning Rate: 0.01\n",
      "Epoch [504/20000], Loss: 323.60321044921875, Entropy -320.10174560546875, Learning Rate: 0.01\n",
      "Epoch [505/20000], Loss: 327.3407897949219, Entropy -306.4222717285156, Learning Rate: 0.01\n",
      "Epoch [506/20000], Loss: 309.302490234375, Entropy -296.8042907714844, Learning Rate: 0.01\n",
      "Epoch [507/20000], Loss: 331.1362609863281, Entropy -309.610595703125, Learning Rate: 0.01\n",
      "Epoch [508/20000], Loss: 295.33416748046875, Entropy -294.26531982421875, Learning Rate: 0.01\n",
      "Epoch [509/20000], Loss: 341.49169921875, Entropy -301.26947021484375, Learning Rate: 0.01\n",
      "Epoch [510/20000], Loss: 301.1793212890625, Entropy -305.2457580566406, Learning Rate: 0.01\n",
      "Epoch [511/20000], Loss: 299.2278747558594, Entropy -309.9410095214844, Learning Rate: 0.01\n",
      "Epoch [512/20000], Loss: 312.6139221191406, Entropy -312.5689392089844, Learning Rate: 0.01\n",
      "Epoch [513/20000], Loss: 309.68487548828125, Entropy -312.1123352050781, Learning Rate: 0.01\n",
      "Epoch [514/20000], Loss: 322.68817138671875, Entropy -311.3940124511719, Learning Rate: 0.01\n",
      "Epoch [515/20000], Loss: 338.62652587890625, Entropy -301.5592041015625, Learning Rate: 0.01\n",
      "Epoch [516/20000], Loss: 317.02880859375, Entropy -302.51824951171875, Learning Rate: 0.01\n",
      "Epoch [517/20000], Loss: 342.7778625488281, Entropy -306.3362121582031, Learning Rate: 0.01\n",
      "Epoch [518/20000], Loss: 320.1971435546875, Entropy -308.9776611328125, Learning Rate: 0.01\n",
      "Epoch [519/20000], Loss: 316.62933349609375, Entropy -300.46221923828125, Learning Rate: 0.01\n",
      "Epoch [520/20000], Loss: 320.605224609375, Entropy -300.6297912597656, Learning Rate: 0.01\n",
      "Epoch [521/20000], Loss: 315.71484375, Entropy -302.96087646484375, Learning Rate: 0.01\n",
      "Epoch [522/20000], Loss: 313.9009704589844, Entropy -300.6854248046875, Learning Rate: 0.01\n",
      "Epoch [523/20000], Loss: 333.82244873046875, Entropy -305.7062683105469, Learning Rate: 0.01\n",
      "Epoch [524/20000], Loss: 301.6189270019531, Entropy -301.7978820800781, Learning Rate: 0.01\n",
      "Epoch [525/20000], Loss: 331.4454345703125, Entropy -304.0444641113281, Learning Rate: 0.01\n",
      "Epoch [526/20000], Loss: 309.3885498046875, Entropy -299.8966979980469, Learning Rate: 0.01\n",
      "Epoch [527/20000], Loss: 302.37457275390625, Entropy -300.67315673828125, Learning Rate: 0.01\n",
      "Epoch [528/20000], Loss: 317.5738830566406, Entropy -301.5787658691406, Learning Rate: 0.01\n",
      "Epoch [529/20000], Loss: 331.0502014160156, Entropy -300.4397277832031, Learning Rate: 0.01\n",
      "Epoch [530/20000], Loss: 301.73406982421875, Entropy -300.5166320800781, Learning Rate: 0.01\n",
      "Epoch [531/20000], Loss: 312.181640625, Entropy -302.91668701171875, Learning Rate: 0.01\n",
      "Epoch [532/20000], Loss: 301.95477294921875, Entropy -302.0442199707031, Learning Rate: 0.01\n",
      "Epoch [533/20000], Loss: 290.42620849609375, Entropy -288.9968566894531, Learning Rate: 0.01\n",
      "Epoch [534/20000], Loss: 299.387451171875, Entropy -295.6458740234375, Learning Rate: 0.01\n",
      "Epoch [535/20000], Loss: 277.5767822265625, Entropy -283.7738342285156, Learning Rate: 0.01\n",
      "Epoch [536/20000], Loss: 280.54986572265625, Entropy -289.20465087890625, Learning Rate: 0.01\n",
      "Epoch [537/20000], Loss: 287.82257080078125, Entropy -290.90509033203125, Learning Rate: 0.01\n",
      "Epoch [538/20000], Loss: 285.5658264160156, Entropy -288.9788513183594, Learning Rate: 0.01\n",
      "Epoch [539/20000], Loss: 281.94891357421875, Entropy -296.63714599609375, Learning Rate: 0.01\n",
      "Epoch [540/20000], Loss: 310.7184143066406, Entropy -309.4598693847656, Learning Rate: 0.01\n",
      "Epoch [541/20000], Loss: 319.9496154785156, Entropy -300.1429138183594, Learning Rate: 0.01\n",
      "Epoch [542/20000], Loss: 294.7272644042969, Entropy -297.6392822265625, Learning Rate: 0.01\n",
      "Epoch [543/20000], Loss: 309.31329345703125, Entropy -303.3416748046875, Learning Rate: 0.01\n",
      "Epoch [544/20000], Loss: 295.33843994140625, Entropy -292.96337890625, Learning Rate: 0.01\n",
      "Epoch [545/20000], Loss: 299.5744323730469, Entropy -290.5218811035156, Learning Rate: 0.01\n",
      "Epoch [546/20000], Loss: 304.97210693359375, Entropy -294.20062255859375, Learning Rate: 0.01\n",
      "Epoch [547/20000], Loss: 303.071533203125, Entropy -291.9493408203125, Learning Rate: 0.01\n",
      "Epoch [548/20000], Loss: 301.65057373046875, Entropy -295.56304931640625, Learning Rate: 0.01\n",
      "Epoch [549/20000], Loss: 277.3253173828125, Entropy -278.78387451171875, Learning Rate: 0.01\n",
      "Epoch [550/20000], Loss: 295.40570068359375, Entropy -286.1119689941406, Learning Rate: 0.01\n",
      "Epoch [551/20000], Loss: 304.2771301269531, Entropy -294.986083984375, Learning Rate: 0.01\n",
      "Epoch [552/20000], Loss: 295.31134033203125, Entropy -285.730224609375, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [553/20000], Loss: 305.3948974609375, Entropy -294.886474609375, Learning Rate: 0.01\n",
      "Epoch [554/20000], Loss: 314.3367614746094, Entropy -290.2964172363281, Learning Rate: 0.01\n",
      "Epoch [555/20000], Loss: 305.8283996582031, Entropy -292.7257995605469, Learning Rate: 0.01\n",
      "Epoch [556/20000], Loss: 307.74261474609375, Entropy -296.2278137207031, Learning Rate: 0.01\n",
      "Epoch [557/20000], Loss: 284.51141357421875, Entropy -278.86517333984375, Learning Rate: 0.01\n",
      "Epoch [558/20000], Loss: 317.8828125, Entropy -303.38262939453125, Learning Rate: 0.01\n",
      "Epoch [559/20000], Loss: 326.74090576171875, Entropy -306.0803527832031, Learning Rate: 0.01\n",
      "Epoch [560/20000], Loss: 336.7811584472656, Entropy -299.810791015625, Learning Rate: 0.01\n",
      "Epoch [561/20000], Loss: 296.33905029296875, Entropy -302.9076843261719, Learning Rate: 0.01\n",
      "Epoch [562/20000], Loss: 326.6912841796875, Entropy -286.6494445800781, Learning Rate: 0.01\n",
      "Epoch [563/20000], Loss: 338.99053955078125, Entropy -298.47186279296875, Learning Rate: 0.01\n",
      "Epoch [564/20000], Loss: 307.5616760253906, Entropy -295.3747863769531, Learning Rate: 0.01\n",
      "Epoch [565/20000], Loss: 376.38861083984375, Entropy -290.9315185546875, Learning Rate: 0.01\n",
      "Epoch [566/20000], Loss: 337.5204162597656, Entropy -302.5342712402344, Learning Rate: 0.01\n",
      "Epoch [567/20000], Loss: 345.33172607421875, Entropy -293.36370849609375, Learning Rate: 0.01\n",
      "Epoch [568/20000], Loss: 337.9948425292969, Entropy -300.9122009277344, Learning Rate: 0.01\n",
      "Epoch [569/20000], Loss: 324.3846130371094, Entropy -295.5115661621094, Learning Rate: 0.01\n",
      "Epoch [570/20000], Loss: 309.3023376464844, Entropy -300.3035888671875, Learning Rate: 0.01\n",
      "Epoch [571/20000], Loss: 324.072021484375, Entropy -300.46856689453125, Learning Rate: 0.01\n",
      "Epoch [572/20000], Loss: 315.3199157714844, Entropy -296.3625793457031, Learning Rate: 0.01\n",
      "Epoch [573/20000], Loss: 347.89581298828125, Entropy -283.83721923828125, Learning Rate: 0.01\n",
      "Epoch [574/20000], Loss: 323.23779296875, Entropy -289.86456298828125, Learning Rate: 0.01\n",
      "Epoch [575/20000], Loss: 324.10595703125, Entropy -290.82928466796875, Learning Rate: 0.01\n",
      "Epoch [576/20000], Loss: 336.82879638671875, Entropy -295.7487487792969, Learning Rate: 0.01\n",
      "Epoch [577/20000], Loss: 324.69873046875, Entropy -293.2911071777344, Learning Rate: 0.01\n",
      "Epoch [578/20000], Loss: 338.1251220703125, Entropy -290.42327880859375, Learning Rate: 0.01\n",
      "Epoch [579/20000], Loss: 314.7575378417969, Entropy -299.7684326171875, Learning Rate: 0.01\n",
      "Epoch [580/20000], Loss: 338.8380432128906, Entropy -291.63031005859375, Learning Rate: 0.01\n",
      "Epoch [581/20000], Loss: 317.1667175292969, Entropy -282.4785461425781, Learning Rate: 0.01\n",
      "Epoch [582/20000], Loss: 332.8804626464844, Entropy -297.7582702636719, Learning Rate: 0.01\n",
      "Epoch [583/20000], Loss: 341.4411926269531, Entropy -299.24835205078125, Learning Rate: 0.01\n",
      "Epoch [584/20000], Loss: 356.00555419921875, Entropy -291.6325988769531, Learning Rate: 0.01\n",
      "Epoch [585/20000], Loss: 322.07647705078125, Entropy -285.69769287109375, Learning Rate: 0.01\n",
      "Epoch [586/20000], Loss: 314.78680419921875, Entropy -291.66400146484375, Learning Rate: 0.01\n",
      "Epoch [587/20000], Loss: 330.3137512207031, Entropy -296.7547302246094, Learning Rate: 0.01\n",
      "Epoch [588/20000], Loss: 309.5106506347656, Entropy -292.4509582519531, Learning Rate: 0.01\n",
      "Epoch [589/20000], Loss: 326.03472900390625, Entropy -294.7369689941406, Learning Rate: 0.01\n",
      "Epoch [590/20000], Loss: 317.5315856933594, Entropy -304.5868225097656, Learning Rate: 0.01\n",
      "Epoch [591/20000], Loss: 331.8124084472656, Entropy -294.3935852050781, Learning Rate: 0.01\n",
      "Epoch [592/20000], Loss: 304.41339111328125, Entropy -302.33734130859375, Learning Rate: 0.01\n",
      "Epoch [593/20000], Loss: 316.2602844238281, Entropy -293.2181091308594, Learning Rate: 0.01\n",
      "Epoch [594/20000], Loss: 306.24603271484375, Entropy -290.9766845703125, Learning Rate: 0.01\n",
      "Epoch [595/20000], Loss: 304.7154235839844, Entropy -289.1865234375, Learning Rate: 0.01\n",
      "Epoch [596/20000], Loss: 342.2389831542969, Entropy -282.3224182128906, Learning Rate: 0.01\n",
      "Epoch [597/20000], Loss: 296.54888916015625, Entropy -284.79852294921875, Learning Rate: 0.01\n",
      "Epoch [598/20000], Loss: 342.6933898925781, Entropy -283.1622619628906, Learning Rate: 0.01\n",
      "Epoch [599/20000], Loss: 355.5772399902344, Entropy -291.67364501953125, Learning Rate: 0.01\n",
      "Epoch [600/20000], Loss: 326.8157653808594, Entropy -274.7729187011719, Learning Rate: 0.01\n",
      "Epoch [601/20000], Loss: 348.69842529296875, Entropy -290.9934387207031, Learning Rate: 0.01\n",
      "Epoch [602/20000], Loss: 355.9656982421875, Entropy -282.29156494140625, Learning Rate: 0.01\n",
      "Epoch [603/20000], Loss: 355.3786926269531, Entropy -280.434814453125, Learning Rate: 0.01\n",
      "Epoch [604/20000], Loss: 318.8911437988281, Entropy -289.8035583496094, Learning Rate: 0.01\n",
      "Epoch [605/20000], Loss: 391.97637939453125, Entropy -285.60162353515625, Learning Rate: 0.01\n",
      "Epoch [606/20000], Loss: 329.92437744140625, Entropy -285.4268493652344, Learning Rate: 0.01\n",
      "Epoch [607/20000], Loss: 394.6991882324219, Entropy -286.82464599609375, Learning Rate: 0.01\n",
      "Epoch [608/20000], Loss: 315.56903076171875, Entropy -292.2230224609375, Learning Rate: 0.01\n",
      "Epoch [609/20000], Loss: 326.0035400390625, Entropy -288.8190002441406, Learning Rate: 0.01\n",
      "Epoch [610/20000], Loss: 341.993896484375, Entropy -276.925537109375, Learning Rate: 0.01\n",
      "Epoch [611/20000], Loss: 297.2334289550781, Entropy -285.13763427734375, Learning Rate: 0.01\n",
      "Epoch [612/20000], Loss: 347.27655029296875, Entropy -301.61737060546875, Learning Rate: 0.01\n",
      "Epoch [613/20000], Loss: 319.07904052734375, Entropy -290.5949401855469, Learning Rate: 0.01\n",
      "Epoch [614/20000], Loss: 363.2551574707031, Entropy -297.38946533203125, Learning Rate: 0.01\n",
      "Epoch [615/20000], Loss: 324.060546875, Entropy -284.4927673339844, Learning Rate: 0.01\n",
      "Epoch [616/20000], Loss: 327.4889221191406, Entropy -289.8752136230469, Learning Rate: 0.01\n",
      "Epoch [617/20000], Loss: 327.0150146484375, Entropy -285.7889709472656, Learning Rate: 0.01\n",
      "Epoch [618/20000], Loss: 340.4789733886719, Entropy -283.98663330078125, Learning Rate: 0.01\n",
      "Epoch [619/20000], Loss: 329.99993896484375, Entropy -284.2579040527344, Learning Rate: 0.01\n",
      "Epoch [620/20000], Loss: 318.8644714355469, Entropy -283.6927185058594, Learning Rate: 0.01\n",
      "Epoch [621/20000], Loss: 307.3918762207031, Entropy -291.1817626953125, Learning Rate: 0.01\n",
      "Epoch [622/20000], Loss: 324.69866943359375, Entropy -286.0794372558594, Learning Rate: 0.01\n",
      "Epoch [623/20000], Loss: 314.0557556152344, Entropy -291.4312744140625, Learning Rate: 0.01\n",
      "Epoch [624/20000], Loss: 368.72027587890625, Entropy -297.7691650390625, Learning Rate: 0.01\n",
      "Epoch [625/20000], Loss: 291.962646484375, Entropy -284.76727294921875, Learning Rate: 0.01\n",
      "Epoch [626/20000], Loss: 359.3937072753906, Entropy -301.1866455078125, Learning Rate: 0.01\n",
      "Epoch [627/20000], Loss: 336.1314697265625, Entropy -292.4841613769531, Learning Rate: 0.01\n",
      "Epoch [628/20000], Loss: 314.58087158203125, Entropy -295.534912109375, Learning Rate: 0.01\n",
      "Epoch [629/20000], Loss: 367.7177734375, Entropy -279.4601745605469, Learning Rate: 0.01\n",
      "Epoch [630/20000], Loss: 316.7575988769531, Entropy -283.3217468261719, Learning Rate: 0.01\n",
      "Epoch [631/20000], Loss: 364.0121154785156, Entropy -288.1859130859375, Learning Rate: 0.01\n",
      "Epoch [632/20000], Loss: 329.8143310546875, Entropy -297.794189453125, Learning Rate: 0.01\n",
      "Epoch [633/20000], Loss: 394.87701416015625, Entropy -291.2493896484375, Learning Rate: 0.01\n",
      "Epoch [634/20000], Loss: 304.0303955078125, Entropy -287.9700927734375, Learning Rate: 0.01\n",
      "Epoch [635/20000], Loss: 318.403564453125, Entropy -267.9013671875, Learning Rate: 0.01\n",
      "Epoch [636/20000], Loss: 325.5912170410156, Entropy -270.3604431152344, Learning Rate: 0.01\n",
      "Epoch [637/20000], Loss: 333.16552734375, Entropy -291.1839599609375, Learning Rate: 0.01\n",
      "Epoch [638/20000], Loss: 323.22100830078125, Entropy -302.707275390625, Learning Rate: 0.01\n",
      "Epoch [639/20000], Loss: 371.9747314453125, Entropy -271.683837890625, Learning Rate: 0.01\n",
      "Epoch [640/20000], Loss: 302.8938293457031, Entropy -281.5274963378906, Learning Rate: 0.01\n",
      "Epoch [641/20000], Loss: 306.64788818359375, Entropy -285.2015686035156, Learning Rate: 0.01\n",
      "Epoch [642/20000], Loss: 340.43182373046875, Entropy -296.9193420410156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [643/20000], Loss: 333.7760009765625, Entropy -289.6817932128906, Learning Rate: 0.01\n",
      "Epoch [644/20000], Loss: 297.51788330078125, Entropy -280.9175109863281, Learning Rate: 0.01\n",
      "Epoch [645/20000], Loss: 305.7808837890625, Entropy -293.7845153808594, Learning Rate: 0.01\n",
      "Epoch [646/20000], Loss: 326.76507568359375, Entropy -302.04718017578125, Learning Rate: 0.01\n",
      "Epoch [647/20000], Loss: 305.47412109375, Entropy -284.5994873046875, Learning Rate: 0.01\n",
      "Epoch [648/20000], Loss: 305.9295654296875, Entropy -283.76177978515625, Learning Rate: 0.01\n",
      "Epoch [649/20000], Loss: 326.7519836425781, Entropy -280.4834899902344, Learning Rate: 0.01\n",
      "Epoch [650/20000], Loss: 311.473388671875, Entropy -277.10760498046875, Learning Rate: 0.01\n",
      "Epoch [651/20000], Loss: 311.8140563964844, Entropy -295.96148681640625, Learning Rate: 0.01\n",
      "Epoch [652/20000], Loss: 299.44500732421875, Entropy -281.153564453125, Learning Rate: 0.01\n",
      "Epoch [653/20000], Loss: 310.7027587890625, Entropy -284.2265930175781, Learning Rate: 0.01\n",
      "Epoch [654/20000], Loss: 289.3272399902344, Entropy -276.79931640625, Learning Rate: 0.01\n",
      "Epoch [655/20000], Loss: 313.7015686035156, Entropy -281.3540954589844, Learning Rate: 0.01\n",
      "Epoch [656/20000], Loss: 290.78057861328125, Entropy -273.26849365234375, Learning Rate: 0.01\n",
      "Epoch [657/20000], Loss: 333.1329345703125, Entropy -277.22271728515625, Learning Rate: 0.01\n",
      "Epoch [658/20000], Loss: 291.5342102050781, Entropy -291.5008850097656, Learning Rate: 0.01\n",
      "Epoch [659/20000], Loss: 340.4193115234375, Entropy -284.24835205078125, Learning Rate: 0.01\n",
      "Epoch [660/20000], Loss: 338.5063171386719, Entropy -289.16583251953125, Learning Rate: 0.01\n",
      "Epoch [661/20000], Loss: 327.1174621582031, Entropy -279.1278381347656, Learning Rate: 0.01\n",
      "Epoch [662/20000], Loss: 298.37396240234375, Entropy -293.2919006347656, Learning Rate: 0.01\n",
      "Epoch [663/20000], Loss: 318.4678039550781, Entropy -300.51165771484375, Learning Rate: 0.01\n",
      "Epoch [664/20000], Loss: 307.35101318359375, Entropy -294.77960205078125, Learning Rate: 0.01\n",
      "Epoch [665/20000], Loss: 261.2478942871094, Entropy -270.90447998046875, Learning Rate: 0.01\n",
      "Epoch [666/20000], Loss: 322.9659118652344, Entropy -296.0674743652344, Learning Rate: 0.01\n",
      "Epoch [667/20000], Loss: 295.17779541015625, Entropy -296.07647705078125, Learning Rate: 0.01\n",
      "Epoch [668/20000], Loss: 313.5068359375, Entropy -282.31939697265625, Learning Rate: 0.01\n",
      "Epoch [669/20000], Loss: 287.1793518066406, Entropy -271.6127624511719, Learning Rate: 0.01\n",
      "Epoch [670/20000], Loss: 324.26708984375, Entropy -280.66546630859375, Learning Rate: 0.01\n",
      "Epoch [671/20000], Loss: 364.9764099121094, Entropy -268.70697021484375, Learning Rate: 0.01\n",
      "Epoch [672/20000], Loss: 329.1445007324219, Entropy -292.876220703125, Learning Rate: 0.01\n",
      "Epoch [673/20000], Loss: 361.15521240234375, Entropy -274.9418029785156, Learning Rate: 0.01\n",
      "Epoch [674/20000], Loss: 340.49481201171875, Entropy -282.6370544433594, Learning Rate: 0.01\n",
      "Epoch [675/20000], Loss: 287.58026123046875, Entropy -284.0792236328125, Learning Rate: 0.01\n",
      "Epoch [676/20000], Loss: 370.9217529296875, Entropy -288.3823547363281, Learning Rate: 0.01\n",
      "Epoch [677/20000], Loss: 292.15802001953125, Entropy -281.9175109863281, Learning Rate: 0.01\n",
      "Epoch [678/20000], Loss: 304.293212890625, Entropy -295.6598205566406, Learning Rate: 0.01\n",
      "Epoch [679/20000], Loss: 280.9400939941406, Entropy -280.46661376953125, Learning Rate: 0.01\n",
      "Epoch [680/20000], Loss: 334.58099365234375, Entropy -295.531494140625, Learning Rate: 0.01\n",
      "Epoch [681/20000], Loss: 293.2420349121094, Entropy -279.01416015625, Learning Rate: 0.01\n",
      "Epoch [682/20000], Loss: 325.45758056640625, Entropy -289.4471740722656, Learning Rate: 0.01\n",
      "Epoch [683/20000], Loss: 288.3921813964844, Entropy -267.9378967285156, Learning Rate: 0.01\n",
      "Epoch [684/20000], Loss: 294.2678527832031, Entropy -270.498779296875, Learning Rate: 0.01\n",
      "Epoch [685/20000], Loss: 312.2666015625, Entropy -290.9649658203125, Learning Rate: 0.01\n",
      "Epoch [686/20000], Loss: 292.61590576171875, Entropy -278.1932678222656, Learning Rate: 0.01\n",
      "Epoch [687/20000], Loss: 300.0556335449219, Entropy -281.63665771484375, Learning Rate: 0.01\n",
      "Epoch [688/20000], Loss: 321.194091796875, Entropy -285.0247802734375, Learning Rate: 0.01\n",
      "Epoch [689/20000], Loss: 318.63385009765625, Entropy -278.10986328125, Learning Rate: 0.01\n",
      "Epoch [690/20000], Loss: 284.0572814941406, Entropy -278.3115539550781, Learning Rate: 0.01\n",
      "Epoch [691/20000], Loss: 316.1571044921875, Entropy -283.9825744628906, Learning Rate: 0.01\n",
      "Epoch [692/20000], Loss: 290.83013916015625, Entropy -271.6122131347656, Learning Rate: 0.01\n",
      "Epoch [693/20000], Loss: 282.52874755859375, Entropy -270.45599365234375, Learning Rate: 0.01\n",
      "Epoch [694/20000], Loss: 302.5027160644531, Entropy -273.98486328125, Learning Rate: 0.01\n",
      "Epoch [695/20000], Loss: 341.903076171875, Entropy -285.8016357421875, Learning Rate: 0.01\n",
      "Epoch [696/20000], Loss: 312.1708068847656, Entropy -289.175537109375, Learning Rate: 0.01\n",
      "Epoch [697/20000], Loss: 298.9950866699219, Entropy -276.503173828125, Learning Rate: 0.01\n",
      "Epoch [698/20000], Loss: 302.86151123046875, Entropy -291.00750732421875, Learning Rate: 0.01\n",
      "Epoch [699/20000], Loss: 293.17327880859375, Entropy -277.5921936035156, Learning Rate: 0.01\n",
      "Epoch [700/20000], Loss: 296.06817626953125, Entropy -281.8364562988281, Learning Rate: 0.01\n",
      "Epoch [701/20000], Loss: 267.951171875, Entropy -280.8727111816406, Learning Rate: 0.01\n",
      "Epoch [702/20000], Loss: 277.5931396484375, Entropy -276.9884338378906, Learning Rate: 0.01\n",
      "Epoch [703/20000], Loss: 293.4956970214844, Entropy -278.7815856933594, Learning Rate: 0.01\n",
      "Epoch [704/20000], Loss: 321.82342529296875, Entropy -279.7821960449219, Learning Rate: 0.01\n",
      "Epoch [705/20000], Loss: 310.950439453125, Entropy -290.560546875, Learning Rate: 0.01\n",
      "Epoch [706/20000], Loss: 285.03851318359375, Entropy -268.7272033691406, Learning Rate: 0.01\n",
      "Epoch [707/20000], Loss: 281.93780517578125, Entropy -289.1213684082031, Learning Rate: 0.01\n",
      "Epoch [708/20000], Loss: 295.6380920410156, Entropy -271.6199035644531, Learning Rate: 0.01\n",
      "Epoch [709/20000], Loss: 281.4658203125, Entropy -274.6016540527344, Learning Rate: 0.01\n",
      "Epoch [710/20000], Loss: 275.24053955078125, Entropy -275.43865966796875, Learning Rate: 0.01\n",
      "Epoch [711/20000], Loss: 274.85455322265625, Entropy -280.4465026855469, Learning Rate: 0.01\n",
      "Epoch [712/20000], Loss: 277.3291320800781, Entropy -275.117919921875, Learning Rate: 0.01\n",
      "Epoch [713/20000], Loss: 288.60040283203125, Entropy -280.8304138183594, Learning Rate: 0.01\n",
      "Epoch [714/20000], Loss: 265.6177062988281, Entropy -272.407470703125, Learning Rate: 0.01\n",
      "Epoch [715/20000], Loss: 288.08636474609375, Entropy -274.2230224609375, Learning Rate: 0.01\n",
      "Epoch [716/20000], Loss: 274.96136474609375, Entropy -282.02215576171875, Learning Rate: 0.01\n",
      "Epoch [717/20000], Loss: 277.8905029296875, Entropy -271.62884521484375, Learning Rate: 0.01\n",
      "Epoch [718/20000], Loss: 271.1015625, Entropy -266.57904052734375, Learning Rate: 0.01\n",
      "Epoch [719/20000], Loss: 272.51617431640625, Entropy -271.0947570800781, Learning Rate: 0.01\n",
      "Epoch [720/20000], Loss: 310.1343078613281, Entropy -299.8200988769531, Learning Rate: 0.01\n",
      "Epoch [721/20000], Loss: 263.6617431640625, Entropy -272.2100830078125, Learning Rate: 0.01\n",
      "Epoch [722/20000], Loss: 276.250244140625, Entropy -274.8544921875, Learning Rate: 0.01\n",
      "Epoch [723/20000], Loss: 244.20132446289062, Entropy -258.0617370605469, Learning Rate: 0.01\n",
      "Epoch [724/20000], Loss: 272.11993408203125, Entropy -271.40789794921875, Learning Rate: 0.01\n",
      "Epoch [725/20000], Loss: 276.15447998046875, Entropy -279.43695068359375, Learning Rate: 0.01\n",
      "Epoch [726/20000], Loss: 277.64599609375, Entropy -277.2143859863281, Learning Rate: 0.01\n",
      "Epoch [727/20000], Loss: 273.32879638671875, Entropy -284.46734619140625, Learning Rate: 0.01\n",
      "Epoch [728/20000], Loss: 278.54620361328125, Entropy -272.7250061035156, Learning Rate: 0.01\n",
      "Epoch [729/20000], Loss: 253.2484588623047, Entropy -268.5420837402344, Learning Rate: 0.01\n",
      "Epoch [730/20000], Loss: 276.72406005859375, Entropy -283.2687683105469, Learning Rate: 0.01\n",
      "Epoch [731/20000], Loss: 273.2791748046875, Entropy -276.210693359375, Learning Rate: 0.01\n",
      "Epoch [732/20000], Loss: 254.5189666748047, Entropy -274.5732727050781, Learning Rate: 0.01\n",
      "Epoch [733/20000], Loss: 268.2774963378906, Entropy -272.07330322265625, Learning Rate: 0.01\n",
      "Epoch [734/20000], Loss: 257.0182189941406, Entropy -264.0660400390625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [735/20000], Loss: 266.02728271484375, Entropy -273.45880126953125, Learning Rate: 0.01\n",
      "Epoch [736/20000], Loss: 293.0136413574219, Entropy -284.529296875, Learning Rate: 0.01\n",
      "Epoch [737/20000], Loss: 256.3553771972656, Entropy -269.9297180175781, Learning Rate: 0.01\n",
      "Epoch [738/20000], Loss: 279.8276672363281, Entropy -266.9670715332031, Learning Rate: 0.01\n",
      "Epoch [739/20000], Loss: 267.1047058105469, Entropy -272.08001708984375, Learning Rate: 0.01\n",
      "Epoch [740/20000], Loss: 261.912841796875, Entropy -265.1812744140625, Learning Rate: 0.01\n",
      "Epoch [741/20000], Loss: 286.95263671875, Entropy -284.9505920410156, Learning Rate: 0.01\n",
      "Epoch [742/20000], Loss: 264.48675537109375, Entropy -268.1442565917969, Learning Rate: 0.01\n",
      "Epoch [743/20000], Loss: 279.8408508300781, Entropy -273.5506896972656, Learning Rate: 0.01\n",
      "Epoch [744/20000], Loss: 280.3063049316406, Entropy -278.35296630859375, Learning Rate: 0.01\n",
      "Epoch [745/20000], Loss: 257.6588134765625, Entropy -262.4213562011719, Learning Rate: 0.01\n",
      "Epoch [746/20000], Loss: 263.3021240234375, Entropy -261.388671875, Learning Rate: 0.01\n",
      "Epoch [747/20000], Loss: 284.26513671875, Entropy -276.4857482910156, Learning Rate: 0.01\n",
      "Epoch [748/20000], Loss: 277.23291015625, Entropy -270.6216735839844, Learning Rate: 0.01\n",
      "Epoch [749/20000], Loss: 278.1900634765625, Entropy -278.5966796875, Learning Rate: 0.01\n",
      "Epoch [750/20000], Loss: 290.4554443359375, Entropy -265.67181396484375, Learning Rate: 0.01\n",
      "Epoch [751/20000], Loss: 279.7657470703125, Entropy -256.933837890625, Learning Rate: 0.01\n",
      "Epoch [752/20000], Loss: 296.0576171875, Entropy -277.3638000488281, Learning Rate: 0.01\n",
      "Epoch [753/20000], Loss: 268.65399169921875, Entropy -254.0128173828125, Learning Rate: 0.01\n",
      "Epoch [754/20000], Loss: 272.5943908691406, Entropy -265.1409606933594, Learning Rate: 0.01\n",
      "Epoch [755/20000], Loss: 281.0787048339844, Entropy -249.63717651367188, Learning Rate: 0.01\n",
      "Epoch [756/20000], Loss: 289.4725036621094, Entropy -270.8909912109375, Learning Rate: 0.01\n",
      "Epoch [757/20000], Loss: 288.8985290527344, Entropy -268.8416442871094, Learning Rate: 0.01\n",
      "Epoch [758/20000], Loss: 318.4261779785156, Entropy -270.5926208496094, Learning Rate: 0.01\n",
      "Epoch [759/20000], Loss: 266.2225036621094, Entropy -263.06878662109375, Learning Rate: 0.01\n",
      "Epoch [760/20000], Loss: 324.48876953125, Entropy -266.643798828125, Learning Rate: 0.01\n",
      "Epoch [761/20000], Loss: 359.5975341796875, Entropy -256.60479736328125, Learning Rate: 0.01\n",
      "Epoch [762/20000], Loss: 302.9974365234375, Entropy -257.40765380859375, Learning Rate: 0.01\n",
      "Epoch [763/20000], Loss: 335.6382141113281, Entropy -272.7210998535156, Learning Rate: 0.01\n",
      "Epoch [764/20000], Loss: 376.7098388671875, Entropy -285.97039794921875, Learning Rate: 0.01\n",
      "Epoch [765/20000], Loss: 347.0711975097656, Entropy -269.998779296875, Learning Rate: 0.01\n",
      "Epoch [766/20000], Loss: 318.072265625, Entropy -263.0591125488281, Learning Rate: 0.01\n",
      "Epoch [767/20000], Loss: 274.0640869140625, Entropy -261.1487121582031, Learning Rate: 0.01\n",
      "Epoch [768/20000], Loss: 351.29254150390625, Entropy -252.16201782226562, Learning Rate: 0.01\n",
      "Epoch [769/20000], Loss: 355.6415710449219, Entropy -263.0684814453125, Learning Rate: 0.01\n",
      "Epoch [770/20000], Loss: 328.3086242675781, Entropy -270.599853515625, Learning Rate: 0.01\n",
      "Epoch [771/20000], Loss: 293.073974609375, Entropy -267.9936218261719, Learning Rate: 0.01\n",
      "Epoch [772/20000], Loss: 370.2995300292969, Entropy -266.62652587890625, Learning Rate: 0.01\n",
      "Epoch [773/20000], Loss: 328.2312316894531, Entropy -265.59722900390625, Learning Rate: 0.01\n",
      "Epoch [774/20000], Loss: 277.00665283203125, Entropy -262.91375732421875, Learning Rate: 0.01\n",
      "Epoch [775/20000], Loss: 320.6502685546875, Entropy -269.16357421875, Learning Rate: 0.01\n",
      "Epoch [776/20000], Loss: 309.791748046875, Entropy -267.76873779296875, Learning Rate: 0.01\n",
      "Epoch [777/20000], Loss: 315.8730163574219, Entropy -263.0563659667969, Learning Rate: 0.01\n",
      "Epoch [778/20000], Loss: 291.40081787109375, Entropy -259.75787353515625, Learning Rate: 0.01\n",
      "Epoch [779/20000], Loss: 293.60906982421875, Entropy -266.48712158203125, Learning Rate: 0.01\n",
      "Epoch [780/20000], Loss: 277.57159423828125, Entropy -254.71063232421875, Learning Rate: 0.01\n",
      "Epoch [781/20000], Loss: 316.104248046875, Entropy -273.2801818847656, Learning Rate: 0.01\n",
      "Epoch [782/20000], Loss: 304.4344177246094, Entropy -268.2014465332031, Learning Rate: 0.01\n",
      "Epoch [783/20000], Loss: 303.52764892578125, Entropy -252.73544311523438, Learning Rate: 0.01\n",
      "Epoch [784/20000], Loss: 325.65594482421875, Entropy -270.5555114746094, Learning Rate: 0.01\n",
      "Epoch [785/20000], Loss: 290.760986328125, Entropy -270.3141174316406, Learning Rate: 0.01\n",
      "Epoch [786/20000], Loss: 285.9734191894531, Entropy -263.046875, Learning Rate: 0.01\n",
      "Epoch [787/20000], Loss: 283.6888732910156, Entropy -268.3868103027344, Learning Rate: 0.01\n",
      "Epoch [788/20000], Loss: 259.8074035644531, Entropy -261.70721435546875, Learning Rate: 0.01\n",
      "Epoch [789/20000], Loss: 264.59136962890625, Entropy -267.2076110839844, Learning Rate: 0.01\n",
      "Epoch [790/20000], Loss: 276.01678466796875, Entropy -266.5138854980469, Learning Rate: 0.01\n",
      "Epoch [791/20000], Loss: 285.9747314453125, Entropy -272.3592834472656, Learning Rate: 0.01\n",
      "Epoch [792/20000], Loss: 315.4904479980469, Entropy -291.6285705566406, Learning Rate: 0.01\n",
      "Epoch [793/20000], Loss: 267.75445556640625, Entropy -272.33514404296875, Learning Rate: 0.01\n",
      "Epoch [794/20000], Loss: 284.69671630859375, Entropy -267.12921142578125, Learning Rate: 0.01\n",
      "Epoch [795/20000], Loss: 298.2890319824219, Entropy -267.33282470703125, Learning Rate: 0.01\n",
      "Epoch [796/20000], Loss: 267.4123840332031, Entropy -271.55657958984375, Learning Rate: 0.01\n",
      "Epoch [797/20000], Loss: 294.0888366699219, Entropy -275.381103515625, Learning Rate: 0.01\n",
      "Epoch [798/20000], Loss: 249.18356323242188, Entropy -256.08062744140625, Learning Rate: 0.01\n",
      "Epoch [799/20000], Loss: 254.9395751953125, Entropy -265.9201965332031, Learning Rate: 0.01\n",
      "Epoch [800/20000], Loss: 276.3553771972656, Entropy -265.1866149902344, Learning Rate: 0.01\n",
      "Epoch [801/20000], Loss: 254.81146240234375, Entropy -265.0575256347656, Learning Rate: 0.01\n",
      "Epoch [802/20000], Loss: 242.595703125, Entropy -252.26800537109375, Learning Rate: 0.01\n",
      "Epoch [803/20000], Loss: 254.54078674316406, Entropy -252.45388793945312, Learning Rate: 0.01\n",
      "Epoch [804/20000], Loss: 272.8822021484375, Entropy -272.7798156738281, Learning Rate: 0.01\n",
      "Epoch [805/20000], Loss: 273.7613525390625, Entropy -276.61468505859375, Learning Rate: 0.01\n",
      "Epoch [806/20000], Loss: 268.5666198730469, Entropy -258.83563232421875, Learning Rate: 0.01\n",
      "Epoch [807/20000], Loss: 259.05316162109375, Entropy -261.0779724121094, Learning Rate: 0.01\n",
      "Epoch [808/20000], Loss: 265.21209716796875, Entropy -271.35076904296875, Learning Rate: 0.01\n",
      "Epoch [809/20000], Loss: 273.6441345214844, Entropy -279.3743591308594, Learning Rate: 0.01\n",
      "Epoch [810/20000], Loss: 246.005126953125, Entropy -259.7201232910156, Learning Rate: 0.01\n",
      "Epoch [811/20000], Loss: 254.8671875, Entropy -267.8244934082031, Learning Rate: 0.01\n",
      "Epoch [812/20000], Loss: 260.37261962890625, Entropy -271.03790283203125, Learning Rate: 0.01\n",
      "Epoch [813/20000], Loss: 250.10572814941406, Entropy -260.41131591796875, Learning Rate: 0.01\n",
      "Epoch [814/20000], Loss: 247.4990234375, Entropy -260.96075439453125, Learning Rate: 0.01\n",
      "Epoch [815/20000], Loss: 254.0965118408203, Entropy -249.52035522460938, Learning Rate: 0.01\n",
      "Epoch [816/20000], Loss: 255.5730743408203, Entropy -253.459228515625, Learning Rate: 0.01\n",
      "Epoch [817/20000], Loss: 268.4879455566406, Entropy -257.1942443847656, Learning Rate: 0.01\n",
      "Epoch [818/20000], Loss: 265.2897644042969, Entropy -265.22381591796875, Learning Rate: 0.01\n",
      "Epoch [819/20000], Loss: 263.0010986328125, Entropy -273.4649353027344, Learning Rate: 0.01\n",
      "Epoch [820/20000], Loss: 261.9530029296875, Entropy -252.43035888671875, Learning Rate: 0.01\n",
      "Epoch [821/20000], Loss: 274.6319885253906, Entropy -267.94512939453125, Learning Rate: 0.01\n",
      "Epoch [822/20000], Loss: 259.77587890625, Entropy -261.6246032714844, Learning Rate: 0.01\n",
      "Epoch [823/20000], Loss: 269.73504638671875, Entropy -253.0591583251953, Learning Rate: 0.01\n",
      "Epoch [824/20000], Loss: 270.08001708984375, Entropy -271.3715515136719, Learning Rate: 0.01\n",
      "Epoch [825/20000], Loss: 272.78326416015625, Entropy -272.76177978515625, Learning Rate: 0.01\n",
      "Epoch [826/20000], Loss: 248.5926055908203, Entropy -255.46319580078125, Learning Rate: 0.01\n",
      "Epoch [827/20000], Loss: 270.51904296875, Entropy -267.8568115234375, Learning Rate: 0.01\n",
      "Epoch [828/20000], Loss: 270.50653076171875, Entropy -248.77496337890625, Learning Rate: 0.01\n",
      "Epoch [829/20000], Loss: 283.05780029296875, Entropy -268.3357238769531, Learning Rate: 0.01\n",
      "Epoch [830/20000], Loss: 264.94677734375, Entropy -262.42449951171875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [831/20000], Loss: 300.217529296875, Entropy -256.70770263671875, Learning Rate: 0.01\n",
      "Epoch [832/20000], Loss: 323.2779235839844, Entropy -256.9765625, Learning Rate: 0.01\n",
      "Epoch [833/20000], Loss: 289.39715576171875, Entropy -256.87054443359375, Learning Rate: 0.01\n",
      "Epoch [834/20000], Loss: 288.66571044921875, Entropy -264.95440673828125, Learning Rate: 0.01\n",
      "Epoch [835/20000], Loss: 296.16656494140625, Entropy -264.41986083984375, Learning Rate: 0.01\n",
      "Epoch [836/20000], Loss: 266.7054443359375, Entropy -253.70364379882812, Learning Rate: 0.01\n",
      "Epoch [837/20000], Loss: 261.1354675292969, Entropy -264.40789794921875, Learning Rate: 0.01\n",
      "Epoch [838/20000], Loss: 269.88818359375, Entropy -265.3967590332031, Learning Rate: 0.01\n",
      "Epoch [839/20000], Loss: 253.3096160888672, Entropy -252.97952270507812, Learning Rate: 0.01\n",
      "Epoch [840/20000], Loss: 286.8292541503906, Entropy -255.3712158203125, Learning Rate: 0.01\n",
      "Epoch [841/20000], Loss: 283.111083984375, Entropy -264.83734130859375, Learning Rate: 0.01\n",
      "Epoch [842/20000], Loss: 257.1141357421875, Entropy -253.12509155273438, Learning Rate: 0.01\n",
      "Epoch [843/20000], Loss: 284.39361572265625, Entropy -241.9824676513672, Learning Rate: 0.01\n",
      "Epoch [844/20000], Loss: 276.1905517578125, Entropy -243.96417236328125, Learning Rate: 0.01\n",
      "Epoch [845/20000], Loss: 277.21405029296875, Entropy -251.30484008789062, Learning Rate: 0.01\n",
      "Epoch [846/20000], Loss: 315.9748229980469, Entropy -254.2371826171875, Learning Rate: 0.01\n",
      "Epoch [847/20000], Loss: 311.10833740234375, Entropy -260.2762756347656, Learning Rate: 0.01\n",
      "Epoch [848/20000], Loss: 257.7061462402344, Entropy -251.70631408691406, Learning Rate: 0.01\n",
      "Epoch [849/20000], Loss: 340.1827392578125, Entropy -249.65597534179688, Learning Rate: 0.01\n",
      "Epoch [850/20000], Loss: 269.50323486328125, Entropy -258.19940185546875, Learning Rate: 0.01\n",
      "Epoch [851/20000], Loss: 314.017822265625, Entropy -251.1457061767578, Learning Rate: 0.01\n",
      "Epoch [852/20000], Loss: 276.8731384277344, Entropy -250.97161865234375, Learning Rate: 0.01\n",
      "Epoch [853/20000], Loss: 292.5221862792969, Entropy -242.73275756835938, Learning Rate: 0.01\n",
      "Epoch [854/20000], Loss: 274.2925109863281, Entropy -250.58114624023438, Learning Rate: 0.01\n",
      "Epoch [855/20000], Loss: 322.2948913574219, Entropy -255.77830505371094, Learning Rate: 0.01\n",
      "Epoch [856/20000], Loss: 330.63726806640625, Entropy -250.63284301757812, Learning Rate: 0.01\n",
      "Epoch [857/20000], Loss: 267.30938720703125, Entropy -258.5739440917969, Learning Rate: 0.01\n",
      "Epoch [858/20000], Loss: 316.00531005859375, Entropy -255.16427612304688, Learning Rate: 0.01\n",
      "Epoch [859/20000], Loss: 269.5110778808594, Entropy -257.0984191894531, Learning Rate: 0.01\n",
      "Epoch [860/20000], Loss: 368.3262939453125, Entropy -248.56414794921875, Learning Rate: 0.01\n",
      "Epoch [861/20000], Loss: 288.0821533203125, Entropy -259.5217590332031, Learning Rate: 0.01\n",
      "Epoch [862/20000], Loss: 290.1828308105469, Entropy -243.244140625, Learning Rate: 0.01\n",
      "Epoch [863/20000], Loss: 263.4188232421875, Entropy -244.16635131835938, Learning Rate: 0.01\n",
      "Epoch [864/20000], Loss: 284.78094482421875, Entropy -256.22979736328125, Learning Rate: 0.01\n",
      "Epoch [865/20000], Loss: 299.70758056640625, Entropy -244.3618621826172, Learning Rate: 0.01\n",
      "Epoch [866/20000], Loss: 260.4171447753906, Entropy -252.9254150390625, Learning Rate: 0.01\n",
      "Epoch [867/20000], Loss: 288.77764892578125, Entropy -259.7355041503906, Learning Rate: 0.01\n",
      "Epoch [868/20000], Loss: 270.5205993652344, Entropy -245.79148864746094, Learning Rate: 0.01\n",
      "Epoch [869/20000], Loss: 367.56610107421875, Entropy -262.6077575683594, Learning Rate: 0.01\n",
      "Epoch [870/20000], Loss: 268.756591796875, Entropy -257.4168701171875, Learning Rate: 0.01\n",
      "Epoch [871/20000], Loss: 362.10797119140625, Entropy -261.0088806152344, Learning Rate: 0.01\n",
      "Epoch [872/20000], Loss: 293.3264465332031, Entropy -264.7980041503906, Learning Rate: 0.01\n",
      "Epoch [873/20000], Loss: 313.2388000488281, Entropy -257.3558654785156, Learning Rate: 0.01\n",
      "Epoch [874/20000], Loss: 287.0177307128906, Entropy -260.9335632324219, Learning Rate: 0.01\n",
      "Epoch [875/20000], Loss: 308.6485290527344, Entropy -251.38546752929688, Learning Rate: 0.01\n",
      "Epoch [876/20000], Loss: 280.6073913574219, Entropy -257.28662109375, Learning Rate: 0.01\n",
      "Epoch [877/20000], Loss: 399.56121826171875, Entropy -273.0415954589844, Learning Rate: 0.01\n",
      "Epoch [878/20000], Loss: 288.63421630859375, Entropy -259.91680908203125, Learning Rate: 0.01\n",
      "Epoch [879/20000], Loss: 269.7821044921875, Entropy -240.2307586669922, Learning Rate: 0.01\n",
      "Epoch [880/20000], Loss: 312.3883361816406, Entropy -248.6375274658203, Learning Rate: 0.01\n",
      "Epoch [881/20000], Loss: 294.40557861328125, Entropy -252.54835510253906, Learning Rate: 0.01\n",
      "Epoch [882/20000], Loss: 317.1143798828125, Entropy -245.62428283691406, Learning Rate: 0.01\n",
      "Epoch [883/20000], Loss: 333.38360595703125, Entropy -252.65298461914062, Learning Rate: 0.01\n",
      "Epoch [884/20000], Loss: 309.3056640625, Entropy -259.1956787109375, Learning Rate: 0.01\n",
      "Epoch [885/20000], Loss: 268.43548583984375, Entropy -256.2171630859375, Learning Rate: 0.01\n",
      "Epoch [886/20000], Loss: 326.3280334472656, Entropy -257.2745666503906, Learning Rate: 0.01\n",
      "Epoch [887/20000], Loss: 280.25360107421875, Entropy -260.2581481933594, Learning Rate: 0.01\n",
      "Epoch [888/20000], Loss: 272.5681457519531, Entropy -248.54376220703125, Learning Rate: 0.01\n",
      "Epoch [889/20000], Loss: 288.75860595703125, Entropy -262.4604797363281, Learning Rate: 0.01\n",
      "Epoch [890/20000], Loss: 286.59912109375, Entropy -252.52088928222656, Learning Rate: 0.01\n",
      "Epoch [891/20000], Loss: 269.01953125, Entropy -252.01390075683594, Learning Rate: 0.01\n",
      "Epoch [892/20000], Loss: 313.619873046875, Entropy -264.5102233886719, Learning Rate: 0.01\n",
      "Epoch [893/20000], Loss: 273.57037353515625, Entropy -279.4411926269531, Learning Rate: 0.01\n",
      "Epoch [894/20000], Loss: 267.06719970703125, Entropy -241.6265869140625, Learning Rate: 0.01\n",
      "Epoch [895/20000], Loss: 275.2059020996094, Entropy -254.34271240234375, Learning Rate: 0.01\n",
      "Epoch [896/20000], Loss: 292.5238952636719, Entropy -261.5115051269531, Learning Rate: 0.01\n",
      "Epoch [897/20000], Loss: 269.6689758300781, Entropy -258.6243896484375, Learning Rate: 0.01\n",
      "Epoch [898/20000], Loss: 318.44366455078125, Entropy -247.01878356933594, Learning Rate: 0.01\n",
      "Epoch [899/20000], Loss: 257.6885986328125, Entropy -252.52996826171875, Learning Rate: 0.01\n",
      "Epoch [900/20000], Loss: 284.2216491699219, Entropy -248.4287872314453, Learning Rate: 0.01\n",
      "Epoch [901/20000], Loss: 271.24517822265625, Entropy -253.62008666992188, Learning Rate: 0.01\n",
      "Epoch [902/20000], Loss: 263.7093505859375, Entropy -251.9263916015625, Learning Rate: 0.01\n",
      "Epoch [903/20000], Loss: 241.4186248779297, Entropy -247.79476928710938, Learning Rate: 0.01\n",
      "Epoch [904/20000], Loss: 302.82366943359375, Entropy -240.86219787597656, Learning Rate: 0.01\n",
      "Epoch [905/20000], Loss: 251.21311950683594, Entropy -250.80001831054688, Learning Rate: 0.01\n",
      "Epoch [906/20000], Loss: 291.3246765136719, Entropy -254.27737426757812, Learning Rate: 0.01\n",
      "Epoch [907/20000], Loss: 277.49847412109375, Entropy -245.25289916992188, Learning Rate: 0.01\n",
      "Epoch [908/20000], Loss: 310.85980224609375, Entropy -244.08018493652344, Learning Rate: 0.01\n",
      "Epoch [909/20000], Loss: 278.47344970703125, Entropy -255.9967041015625, Learning Rate: 0.01\n",
      "Epoch [910/20000], Loss: 308.0146789550781, Entropy -253.1953125, Learning Rate: 0.01\n",
      "Epoch [911/20000], Loss: 293.85968017578125, Entropy -259.6753845214844, Learning Rate: 0.01\n",
      "Epoch [912/20000], Loss: 293.4864501953125, Entropy -244.09608459472656, Learning Rate: 0.01\n",
      "Epoch [913/20000], Loss: 273.6826171875, Entropy -247.310302734375, Learning Rate: 0.01\n",
      "Epoch [914/20000], Loss: 272.57794189453125, Entropy -261.8565673828125, Learning Rate: 0.01\n",
      "Epoch [915/20000], Loss: 284.8880615234375, Entropy -264.43585205078125, Learning Rate: 0.01\n",
      "Epoch [916/20000], Loss: 294.95269775390625, Entropy -256.86761474609375, Learning Rate: 0.01\n",
      "Epoch [917/20000], Loss: 277.0846252441406, Entropy -256.1339416503906, Learning Rate: 0.01\n",
      "Epoch [918/20000], Loss: 259.833740234375, Entropy -263.302978515625, Learning Rate: 0.01\n",
      "Epoch [919/20000], Loss: 265.3541564941406, Entropy -245.791259765625, Learning Rate: 0.01\n",
      "Epoch [920/20000], Loss: 276.24444580078125, Entropy -248.10031127929688, Learning Rate: 0.01\n",
      "Epoch [921/20000], Loss: 281.0592346191406, Entropy -271.66168212890625, Learning Rate: 0.01\n",
      "Epoch [922/20000], Loss: 277.5535888671875, Entropy -257.23809814453125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [923/20000], Loss: 265.65057373046875, Entropy -251.53970336914062, Learning Rate: 0.01\n",
      "Epoch [924/20000], Loss: 280.2795715332031, Entropy -242.56396484375, Learning Rate: 0.01\n",
      "Epoch [925/20000], Loss: 245.3998260498047, Entropy -253.05538940429688, Learning Rate: 0.01\n",
      "Epoch [926/20000], Loss: 273.8970947265625, Entropy -266.06463623046875, Learning Rate: 0.01\n",
      "Epoch [927/20000], Loss: 244.0922088623047, Entropy -244.7059783935547, Learning Rate: 0.01\n",
      "Epoch [928/20000], Loss: 256.89447021484375, Entropy -244.5294952392578, Learning Rate: 0.01\n",
      "Epoch [929/20000], Loss: 247.7971954345703, Entropy -250.9749298095703, Learning Rate: 0.01\n",
      "Epoch [930/20000], Loss: 233.8145751953125, Entropy -240.9320831298828, Learning Rate: 0.01\n",
      "Epoch [931/20000], Loss: 271.12628173828125, Entropy -257.2949523925781, Learning Rate: 0.01\n",
      "Epoch [932/20000], Loss: 259.4367370605469, Entropy -255.21182250976562, Learning Rate: 0.01\n",
      "Epoch [933/20000], Loss: 263.7207946777344, Entropy -251.4344482421875, Learning Rate: 0.01\n",
      "Epoch [934/20000], Loss: 255.2767333984375, Entropy -246.050048828125, Learning Rate: 0.01\n",
      "Epoch [935/20000], Loss: 264.9538269042969, Entropy -251.52130126953125, Learning Rate: 0.01\n",
      "Epoch [936/20000], Loss: 252.29689025878906, Entropy -245.0526123046875, Learning Rate: 0.01\n",
      "Epoch [937/20000], Loss: 257.3653564453125, Entropy -250.10714721679688, Learning Rate: 0.01\n",
      "Epoch [938/20000], Loss: 266.95489501953125, Entropy -272.66168212890625, Learning Rate: 0.01\n",
      "Epoch [939/20000], Loss: 257.79388427734375, Entropy -254.61004638671875, Learning Rate: 0.01\n",
      "Epoch [940/20000], Loss: 252.98406982421875, Entropy -247.97125244140625, Learning Rate: 0.01\n",
      "Epoch [941/20000], Loss: 262.39691162109375, Entropy -256.29345703125, Learning Rate: 0.01\n",
      "Epoch [942/20000], Loss: 233.1486053466797, Entropy -239.03746032714844, Learning Rate: 0.01\n",
      "Epoch [943/20000], Loss: 230.91273498535156, Entropy -231.2135009765625, Learning Rate: 0.01\n",
      "Epoch [944/20000], Loss: 251.55369567871094, Entropy -251.72561645507812, Learning Rate: 0.01\n",
      "Epoch [945/20000], Loss: 257.63720703125, Entropy -245.4073028564453, Learning Rate: 0.01\n",
      "Epoch [946/20000], Loss: 241.2737274169922, Entropy -241.04885864257812, Learning Rate: 0.01\n",
      "Epoch [947/20000], Loss: 246.14639282226562, Entropy -248.8533477783203, Learning Rate: 0.01\n",
      "Epoch [948/20000], Loss: 240.1402130126953, Entropy -236.73727416992188, Learning Rate: 0.01\n",
      "Epoch [949/20000], Loss: 254.2462921142578, Entropy -250.5179901123047, Learning Rate: 0.01\n",
      "Epoch [950/20000], Loss: 249.63241577148438, Entropy -256.0943298339844, Learning Rate: 0.01\n",
      "Epoch [951/20000], Loss: 236.3785400390625, Entropy -240.0682373046875, Learning Rate: 0.01\n",
      "Epoch [952/20000], Loss: 241.6665496826172, Entropy -248.30979919433594, Learning Rate: 0.01\n",
      "Epoch [953/20000], Loss: 242.8114471435547, Entropy -243.4261474609375, Learning Rate: 0.01\n",
      "Epoch [954/20000], Loss: 232.0214385986328, Entropy -244.20538330078125, Learning Rate: 0.01\n",
      "Epoch [955/20000], Loss: 232.2664794921875, Entropy -249.275146484375, Learning Rate: 0.01\n",
      "Epoch [956/20000], Loss: 216.158935546875, Entropy -228.78456115722656, Learning Rate: 0.01\n",
      "Epoch [957/20000], Loss: 256.9488220214844, Entropy -253.08963012695312, Learning Rate: 0.01\n",
      "Epoch [958/20000], Loss: 229.15109252929688, Entropy -242.6015625, Learning Rate: 0.01\n",
      "Epoch [959/20000], Loss: 236.3620147705078, Entropy -239.82083129882812, Learning Rate: 0.01\n",
      "Epoch [960/20000], Loss: 251.44107055664062, Entropy -247.66131591796875, Learning Rate: 0.01\n",
      "Epoch [961/20000], Loss: 251.38140869140625, Entropy -254.17645263671875, Learning Rate: 0.01\n",
      "Epoch [962/20000], Loss: 248.33358764648438, Entropy -245.02110290527344, Learning Rate: 0.01\n",
      "Epoch [963/20000], Loss: 220.96212768554688, Entropy -231.4532012939453, Learning Rate: 0.01\n",
      "Epoch [964/20000], Loss: 225.95339965820312, Entropy -235.73257446289062, Learning Rate: 0.01\n",
      "Epoch [965/20000], Loss: 232.6492156982422, Entropy -232.09942626953125, Learning Rate: 0.01\n",
      "Epoch [966/20000], Loss: 235.8549346923828, Entropy -231.81719970703125, Learning Rate: 0.01\n",
      "Epoch [967/20000], Loss: 238.2895965576172, Entropy -247.388916015625, Learning Rate: 0.01\n",
      "Epoch [968/20000], Loss: 239.0166778564453, Entropy -236.78802490234375, Learning Rate: 0.01\n",
      "Epoch [969/20000], Loss: 238.41796875, Entropy -245.11244201660156, Learning Rate: 0.01\n",
      "Epoch [970/20000], Loss: 266.3888854980469, Entropy -250.92724609375, Learning Rate: 0.01\n",
      "Epoch [971/20000], Loss: 251.84535217285156, Entropy -240.69125366210938, Learning Rate: 0.01\n",
      "Epoch [972/20000], Loss: 231.99607849121094, Entropy -243.9805908203125, Learning Rate: 0.01\n",
      "Epoch [973/20000], Loss: 263.70880126953125, Entropy -243.2100830078125, Learning Rate: 0.01\n",
      "Epoch [974/20000], Loss: 220.54049682617188, Entropy -229.90682983398438, Learning Rate: 0.01\n",
      "Epoch [975/20000], Loss: 245.21865844726562, Entropy -249.9302978515625, Learning Rate: 0.01\n",
      "Epoch [976/20000], Loss: 232.31407165527344, Entropy -232.2584686279297, Learning Rate: 0.01\n",
      "Epoch [977/20000], Loss: 267.42193603515625, Entropy -258.3331298828125, Learning Rate: 0.01\n",
      "Epoch [978/20000], Loss: 240.37362670898438, Entropy -255.69921875, Learning Rate: 0.01\n",
      "Epoch [979/20000], Loss: 247.6131134033203, Entropy -252.16107177734375, Learning Rate: 0.01\n",
      "Epoch [980/20000], Loss: 245.4842529296875, Entropy -259.4306640625, Learning Rate: 0.01\n",
      "Epoch [981/20000], Loss: 227.0558319091797, Entropy -244.65155029296875, Learning Rate: 0.01\n",
      "Epoch [982/20000], Loss: 243.23965454101562, Entropy -249.71624755859375, Learning Rate: 0.01\n",
      "Epoch [983/20000], Loss: 240.70379638671875, Entropy -243.49530029296875, Learning Rate: 0.01\n",
      "Epoch [984/20000], Loss: 238.7113494873047, Entropy -245.3612060546875, Learning Rate: 0.01\n",
      "Epoch [985/20000], Loss: 227.6044158935547, Entropy -224.33969116210938, Learning Rate: 0.01\n",
      "Epoch [986/20000], Loss: 235.9827423095703, Entropy -247.80587768554688, Learning Rate: 0.01\n",
      "Epoch [987/20000], Loss: 229.24972534179688, Entropy -222.12445068359375, Learning Rate: 0.01\n",
      "Epoch [988/20000], Loss: 245.2078094482422, Entropy -253.14556884765625, Learning Rate: 0.01\n",
      "Epoch [989/20000], Loss: 236.64732360839844, Entropy -240.2418975830078, Learning Rate: 0.01\n",
      "Epoch [990/20000], Loss: 220.0513153076172, Entropy -234.81106567382812, Learning Rate: 0.01\n",
      "Epoch [991/20000], Loss: 234.52296447753906, Entropy -236.5166473388672, Learning Rate: 0.01\n",
      "Epoch [992/20000], Loss: 235.88211059570312, Entropy -239.37911987304688, Learning Rate: 0.01\n",
      "Epoch [993/20000], Loss: 246.81678771972656, Entropy -232.40228271484375, Learning Rate: 0.01\n",
      "Epoch [994/20000], Loss: 229.85499572753906, Entropy -231.0652618408203, Learning Rate: 0.01\n",
      "Epoch [995/20000], Loss: 244.00733947753906, Entropy -238.25775146484375, Learning Rate: 0.01\n",
      "Epoch [996/20000], Loss: 226.39230346679688, Entropy -220.94110107421875, Learning Rate: 0.01\n",
      "Epoch [997/20000], Loss: 231.72972106933594, Entropy -233.90513610839844, Learning Rate: 0.01\n",
      "Epoch [998/20000], Loss: 239.77737426757812, Entropy -243.3717041015625, Learning Rate: 0.01\n",
      "Epoch [999/20000], Loss: 227.9344482421875, Entropy -235.8497314453125, Learning Rate: 0.01\n",
      "Epoch [1000/20000], Loss: 248.5464630126953, Entropy -244.1796875, Learning Rate: 0.01\n",
      "Epoch [1001/20000], Loss: 247.04208374023438, Entropy -244.2996368408203, Learning Rate: 0.01\n",
      "Epoch [1002/20000], Loss: 244.0250701904297, Entropy -232.66744995117188, Learning Rate: 0.01\n",
      "Epoch [1003/20000], Loss: 231.7216796875, Entropy -232.6367645263672, Learning Rate: 0.01\n",
      "Epoch [1004/20000], Loss: 217.67823791503906, Entropy -231.01287841796875, Learning Rate: 0.01\n",
      "Epoch [1005/20000], Loss: 253.20994567871094, Entropy -227.39682006835938, Learning Rate: 0.01\n",
      "Epoch [1006/20000], Loss: 228.53736877441406, Entropy -230.70623779296875, Learning Rate: 0.01\n",
      "Epoch [1007/20000], Loss: 242.41065979003906, Entropy -237.59027099609375, Learning Rate: 0.01\n",
      "Epoch [1008/20000], Loss: 249.17727661132812, Entropy -236.91238403320312, Learning Rate: 0.01\n",
      "Epoch [1009/20000], Loss: 243.48594665527344, Entropy -243.41079711914062, Learning Rate: 0.01\n",
      "Epoch [1010/20000], Loss: 235.3700408935547, Entropy -241.001953125, Learning Rate: 0.01\n",
      "Epoch [1011/20000], Loss: 231.87721252441406, Entropy -235.86782836914062, Learning Rate: 0.01\n",
      "Epoch [1012/20000], Loss: 234.5071258544922, Entropy -234.970947265625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1013/20000], Loss: 237.36331176757812, Entropy -231.6076202392578, Learning Rate: 0.01\n",
      "Epoch [1014/20000], Loss: 226.26181030273438, Entropy -236.32974243164062, Learning Rate: 0.01\n",
      "Epoch [1015/20000], Loss: 236.1527862548828, Entropy -247.0478515625, Learning Rate: 0.01\n",
      "Epoch [1016/20000], Loss: 220.93678283691406, Entropy -221.27783203125, Learning Rate: 0.01\n",
      "Epoch [1017/20000], Loss: 238.41036987304688, Entropy -235.57403564453125, Learning Rate: 0.01\n",
      "Epoch [1018/20000], Loss: 231.09921264648438, Entropy -234.03440856933594, Learning Rate: 0.01\n",
      "Epoch [1019/20000], Loss: 216.94549560546875, Entropy -227.86541748046875, Learning Rate: 0.01\n",
      "Epoch [1020/20000], Loss: 242.73446655273438, Entropy -226.2346954345703, Learning Rate: 0.01\n",
      "Epoch [1021/20000], Loss: 213.46995544433594, Entropy -228.81155395507812, Learning Rate: 0.01\n",
      "Epoch [1022/20000], Loss: 244.65855407714844, Entropy -234.26771545410156, Learning Rate: 0.01\n",
      "Epoch [1023/20000], Loss: 233.36834716796875, Entropy -236.83230590820312, Learning Rate: 0.01\n",
      "Epoch [1024/20000], Loss: 231.13461303710938, Entropy -248.7164306640625, Learning Rate: 0.01\n",
      "Epoch [1025/20000], Loss: 246.83099365234375, Entropy -242.83905029296875, Learning Rate: 0.01\n",
      "Epoch [1026/20000], Loss: 249.60623168945312, Entropy -265.79302978515625, Learning Rate: 0.01\n",
      "Epoch [1027/20000], Loss: 240.07090759277344, Entropy -245.7232208251953, Learning Rate: 0.01\n",
      "Epoch [1028/20000], Loss: 230.4488067626953, Entropy -224.43646240234375, Learning Rate: 0.01\n",
      "Epoch [1029/20000], Loss: 239.76947021484375, Entropy -235.6061248779297, Learning Rate: 0.01\n",
      "Epoch [1030/20000], Loss: 208.23851013183594, Entropy -221.15179443359375, Learning Rate: 0.01\n",
      "Epoch [1031/20000], Loss: 217.13470458984375, Entropy -225.25418090820312, Learning Rate: 0.01\n",
      "Epoch [1032/20000], Loss: 233.1442413330078, Entropy -238.56817626953125, Learning Rate: 0.01\n",
      "Epoch [1033/20000], Loss: 232.80938720703125, Entropy -229.4441680908203, Learning Rate: 0.01\n",
      "Epoch [1034/20000], Loss: 228.16644287109375, Entropy -234.03500366210938, Learning Rate: 0.01\n",
      "Epoch [1035/20000], Loss: 220.9803466796875, Entropy -220.2481689453125, Learning Rate: 0.01\n",
      "Epoch [1036/20000], Loss: 222.6910400390625, Entropy -230.2227783203125, Learning Rate: 0.01\n",
      "Epoch [1037/20000], Loss: 224.40789794921875, Entropy -237.12391662597656, Learning Rate: 0.01\n",
      "Epoch [1038/20000], Loss: 224.37306213378906, Entropy -227.9156951904297, Learning Rate: 0.01\n",
      "Epoch [1039/20000], Loss: 245.45108032226562, Entropy -215.62322998046875, Learning Rate: 0.01\n",
      "Epoch [1040/20000], Loss: 216.3438720703125, Entropy -225.66348266601562, Learning Rate: 0.01\n",
      "Epoch [1041/20000], Loss: 241.815185546875, Entropy -242.42263793945312, Learning Rate: 0.01\n",
      "Epoch [1042/20000], Loss: 234.88595581054688, Entropy -227.4947509765625, Learning Rate: 0.01\n",
      "Epoch [1043/20000], Loss: 228.2232666015625, Entropy -243.60708618164062, Learning Rate: 0.01\n",
      "Epoch [1044/20000], Loss: 231.91122436523438, Entropy -235.42984008789062, Learning Rate: 0.01\n",
      "Epoch [1045/20000], Loss: 244.32772827148438, Entropy -251.52987670898438, Learning Rate: 0.01\n",
      "Epoch [1046/20000], Loss: 247.9800262451172, Entropy -238.84912109375, Learning Rate: 0.01\n",
      "Epoch [1047/20000], Loss: 241.58934020996094, Entropy -253.09567260742188, Learning Rate: 0.01\n",
      "Epoch [1048/20000], Loss: 225.6682586669922, Entropy -221.1707305908203, Learning Rate: 0.01\n",
      "Epoch [1049/20000], Loss: 222.73757934570312, Entropy -231.89749145507812, Learning Rate: 0.01\n",
      "Epoch [1050/20000], Loss: 229.31349182128906, Entropy -231.56527709960938, Learning Rate: 0.01\n",
      "Epoch [1051/20000], Loss: 213.81918334960938, Entropy -230.82276916503906, Learning Rate: 0.01\n",
      "Epoch [1052/20000], Loss: 237.82821655273438, Entropy -245.66879272460938, Learning Rate: 0.01\n",
      "Epoch [1053/20000], Loss: 224.7582550048828, Entropy -242.80648803710938, Learning Rate: 0.01\n",
      "Epoch [1054/20000], Loss: 222.9847869873047, Entropy -226.8444061279297, Learning Rate: 0.01\n",
      "Epoch [1055/20000], Loss: 247.8125, Entropy -245.00830078125, Learning Rate: 0.01\n",
      "Epoch [1056/20000], Loss: 234.8147735595703, Entropy -230.49549865722656, Learning Rate: 0.01\n",
      "Epoch [1057/20000], Loss: 231.18675231933594, Entropy -223.72808837890625, Learning Rate: 0.01\n",
      "Epoch [1058/20000], Loss: 226.2100067138672, Entropy -229.73590087890625, Learning Rate: 0.01\n",
      "Epoch [1059/20000], Loss: 231.99205017089844, Entropy -219.6005096435547, Learning Rate: 0.01\n",
      "Epoch [1060/20000], Loss: 231.2994384765625, Entropy -236.5594940185547, Learning Rate: 0.01\n",
      "Epoch [1061/20000], Loss: 230.0782012939453, Entropy -228.8841552734375, Learning Rate: 0.01\n",
      "Epoch [1062/20000], Loss: 214.09559631347656, Entropy -224.08523559570312, Learning Rate: 0.01\n",
      "Epoch [1063/20000], Loss: 220.470703125, Entropy -218.30641174316406, Learning Rate: 0.01\n",
      "Epoch [1064/20000], Loss: 232.48585510253906, Entropy -244.0325927734375, Learning Rate: 0.01\n",
      "Epoch [1065/20000], Loss: 219.5596160888672, Entropy -232.8299560546875, Learning Rate: 0.01\n",
      "Epoch [1066/20000], Loss: 212.18710327148438, Entropy -219.57736206054688, Learning Rate: 0.01\n",
      "Epoch [1067/20000], Loss: 216.35777282714844, Entropy -227.331787109375, Learning Rate: 0.01\n",
      "Epoch [1068/20000], Loss: 207.75894165039062, Entropy -219.79171752929688, Learning Rate: 0.01\n",
      "Epoch [1069/20000], Loss: 238.26699829101562, Entropy -237.87696838378906, Learning Rate: 0.01\n",
      "Epoch [1070/20000], Loss: 218.73497009277344, Entropy -231.88946533203125, Learning Rate: 0.01\n",
      "Epoch [1071/20000], Loss: 225.56773376464844, Entropy -230.16543579101562, Learning Rate: 0.01\n",
      "Epoch [1072/20000], Loss: 218.3544464111328, Entropy -217.171142578125, Learning Rate: 0.01\n",
      "Epoch [1073/20000], Loss: 225.00448608398438, Entropy -236.02127075195312, Learning Rate: 0.01\n",
      "Epoch [1074/20000], Loss: 216.0808868408203, Entropy -223.27334594726562, Learning Rate: 0.01\n",
      "Epoch [1075/20000], Loss: 212.07188415527344, Entropy -224.08226013183594, Learning Rate: 0.01\n",
      "Epoch [1076/20000], Loss: 209.4703826904297, Entropy -216.30101013183594, Learning Rate: 0.01\n",
      "Epoch [1077/20000], Loss: 239.11915588378906, Entropy -245.00100708007812, Learning Rate: 0.01\n",
      "Epoch [1078/20000], Loss: 225.76141357421875, Entropy -228.99160766601562, Learning Rate: 0.01\n",
      "Epoch [1079/20000], Loss: 234.81321716308594, Entropy -233.57269287109375, Learning Rate: 0.01\n",
      "Epoch [1080/20000], Loss: 219.78956604003906, Entropy -229.0496063232422, Learning Rate: 0.01\n",
      "Epoch [1081/20000], Loss: 201.0990753173828, Entropy -214.11190795898438, Learning Rate: 0.01\n",
      "Epoch [1082/20000], Loss: 235.7815704345703, Entropy -254.93994140625, Learning Rate: 0.01\n",
      "Epoch [1083/20000], Loss: 223.7403106689453, Entropy -231.78414916992188, Learning Rate: 0.01\n",
      "Epoch [1084/20000], Loss: 219.14028930664062, Entropy -220.58438110351562, Learning Rate: 0.01\n",
      "Epoch [1085/20000], Loss: 215.261962890625, Entropy -224.177734375, Learning Rate: 0.01\n",
      "Epoch [1086/20000], Loss: 249.1562042236328, Entropy -223.94119262695312, Learning Rate: 0.01\n",
      "Epoch [1087/20000], Loss: 219.59918212890625, Entropy -225.19573974609375, Learning Rate: 0.01\n",
      "Epoch [1088/20000], Loss: 213.11508178710938, Entropy -224.18795776367188, Learning Rate: 0.01\n",
      "Epoch [1089/20000], Loss: 227.462890625, Entropy -239.35995483398438, Learning Rate: 0.01\n",
      "Epoch [1090/20000], Loss: 233.85919189453125, Entropy -230.72314453125, Learning Rate: 0.01\n",
      "Epoch [1091/20000], Loss: 230.98158264160156, Entropy -249.89407348632812, Learning Rate: 0.01\n",
      "Epoch [1092/20000], Loss: 229.85108947753906, Entropy -239.03988647460938, Learning Rate: 0.01\n",
      "Epoch [1093/20000], Loss: 209.0589599609375, Entropy -223.6689453125, Learning Rate: 0.01\n",
      "Epoch [1094/20000], Loss: 225.10377502441406, Entropy -241.07933044433594, Learning Rate: 0.01\n",
      "Epoch [1095/20000], Loss: 218.7353973388672, Entropy -223.98919677734375, Learning Rate: 0.01\n",
      "Epoch [1096/20000], Loss: 202.52102661132812, Entropy -215.28091430664062, Learning Rate: 0.01\n",
      "Epoch [1097/20000], Loss: 218.2573699951172, Entropy -231.0032958984375, Learning Rate: 0.01\n",
      "Epoch [1098/20000], Loss: 215.0290069580078, Entropy -223.30279541015625, Learning Rate: 0.01\n",
      "Epoch [1099/20000], Loss: 218.5841827392578, Entropy -226.99102783203125, Learning Rate: 0.01\n",
      "Epoch [1100/20000], Loss: 214.66397094726562, Entropy -231.31460571289062, Learning Rate: 0.01\n",
      "Epoch [1101/20000], Loss: 205.1057891845703, Entropy -222.71307373046875, Learning Rate: 0.01\n",
      "Epoch [1102/20000], Loss: 210.39930725097656, Entropy -214.03720092773438, Learning Rate: 0.01\n",
      "Epoch [1103/20000], Loss: 208.7628173828125, Entropy -224.33303833007812, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1104/20000], Loss: 205.31356811523438, Entropy -218.93292236328125, Learning Rate: 0.01\n",
      "Epoch [1105/20000], Loss: 207.3670196533203, Entropy -218.1387939453125, Learning Rate: 0.01\n",
      "Epoch [1106/20000], Loss: 207.6284637451172, Entropy -220.0770263671875, Learning Rate: 0.01\n",
      "Epoch [1107/20000], Loss: 211.2382354736328, Entropy -218.51893615722656, Learning Rate: 0.01\n",
      "Epoch [1108/20000], Loss: 209.95626831054688, Entropy -226.11282348632812, Learning Rate: 0.01\n",
      "Epoch [1109/20000], Loss: 209.51730346679688, Entropy -208.0666961669922, Learning Rate: 0.01\n",
      "Epoch [1110/20000], Loss: 218.55264282226562, Entropy -233.75274658203125, Learning Rate: 0.01\n",
      "Epoch [1111/20000], Loss: 209.75833129882812, Entropy -228.0337677001953, Learning Rate: 0.01\n",
      "Epoch [1112/20000], Loss: 216.0222930908203, Entropy -214.16702270507812, Learning Rate: 0.01\n",
      "Epoch [1113/20000], Loss: 194.48236083984375, Entropy -199.85598754882812, Learning Rate: 0.01\n",
      "Epoch [1114/20000], Loss: 204.76551818847656, Entropy -210.26470947265625, Learning Rate: 0.01\n",
      "Epoch [1115/20000], Loss: 216.46067810058594, Entropy -226.5771026611328, Learning Rate: 0.01\n",
      "Epoch [1116/20000], Loss: 210.5773468017578, Entropy -219.430908203125, Learning Rate: 0.01\n",
      "Epoch [1117/20000], Loss: 209.1929931640625, Entropy -218.01324462890625, Learning Rate: 0.01\n",
      "Epoch [1118/20000], Loss: 209.39942932128906, Entropy -223.11595153808594, Learning Rate: 0.01\n",
      "Epoch [1119/20000], Loss: 218.216064453125, Entropy -224.9193115234375, Learning Rate: 0.01\n",
      "Epoch [1120/20000], Loss: 240.35186767578125, Entropy -224.67030334472656, Learning Rate: 0.01\n",
      "Epoch [1121/20000], Loss: 204.6618194580078, Entropy -223.30064392089844, Learning Rate: 0.01\n",
      "Epoch [1122/20000], Loss: 207.60369873046875, Entropy -218.7652587890625, Learning Rate: 0.01\n",
      "Epoch [1123/20000], Loss: 220.75503540039062, Entropy -234.77957153320312, Learning Rate: 0.01\n",
      "Epoch [1124/20000], Loss: 205.72560119628906, Entropy -211.778076171875, Learning Rate: 0.01\n",
      "Epoch [1125/20000], Loss: 208.80783081054688, Entropy -215.59078979492188, Learning Rate: 0.01\n",
      "Epoch [1126/20000], Loss: 212.0272979736328, Entropy -230.9206085205078, Learning Rate: 0.01\n",
      "Epoch [1127/20000], Loss: 202.42955017089844, Entropy -221.6649169921875, Learning Rate: 0.01\n",
      "Epoch [1128/20000], Loss: 208.42269897460938, Entropy -224.4695587158203, Learning Rate: 0.01\n",
      "Epoch [1129/20000], Loss: 203.268310546875, Entropy -213.2497100830078, Learning Rate: 0.01\n",
      "Epoch [1130/20000], Loss: 198.56082153320312, Entropy -211.10421752929688, Learning Rate: 0.01\n",
      "Epoch [1131/20000], Loss: 219.4433135986328, Entropy -227.2294921875, Learning Rate: 0.01\n",
      "Epoch [1132/20000], Loss: 206.8719940185547, Entropy -212.75244140625, Learning Rate: 0.01\n",
      "Epoch [1133/20000], Loss: 211.0163116455078, Entropy -222.8041229248047, Learning Rate: 0.01\n",
      "Epoch [1134/20000], Loss: 222.6249237060547, Entropy -219.94876098632812, Learning Rate: 0.01\n",
      "Epoch [1135/20000], Loss: 209.777099609375, Entropy -213.00112915039062, Learning Rate: 0.01\n",
      "Epoch [1136/20000], Loss: 206.01271057128906, Entropy -211.88101196289062, Learning Rate: 0.01\n",
      "Epoch [1137/20000], Loss: 207.62855529785156, Entropy -209.88198852539062, Learning Rate: 0.01\n",
      "Epoch [1138/20000], Loss: 205.40206909179688, Entropy -206.77517700195312, Learning Rate: 0.01\n",
      "Epoch [1139/20000], Loss: 208.61912536621094, Entropy -229.33505249023438, Learning Rate: 0.01\n",
      "Epoch [1140/20000], Loss: 215.31747436523438, Entropy -214.88623046875, Learning Rate: 0.01\n",
      "Epoch [1141/20000], Loss: 215.39950561523438, Entropy -233.7519989013672, Learning Rate: 0.01\n",
      "Epoch [1142/20000], Loss: 215.00852966308594, Entropy -220.52194213867188, Learning Rate: 0.01\n",
      "Epoch [1143/20000], Loss: 222.59811401367188, Entropy -227.3937225341797, Learning Rate: 0.01\n",
      "Epoch [1144/20000], Loss: 216.60067749023438, Entropy -217.01031494140625, Learning Rate: 0.01\n",
      "Epoch [1145/20000], Loss: 201.90316772460938, Entropy -217.7187042236328, Learning Rate: 0.01\n",
      "Epoch [1146/20000], Loss: 219.86488342285156, Entropy -221.47601318359375, Learning Rate: 0.01\n",
      "Epoch [1147/20000], Loss: 208.0579071044922, Entropy -219.6937713623047, Learning Rate: 0.01\n",
      "Epoch [1148/20000], Loss: 200.4907684326172, Entropy -209.77572631835938, Learning Rate: 0.01\n",
      "Epoch [1149/20000], Loss: 207.8106231689453, Entropy -213.1517333984375, Learning Rate: 0.01\n",
      "Epoch [1150/20000], Loss: 194.8349609375, Entropy -204.5836181640625, Learning Rate: 0.01\n",
      "Epoch [1151/20000], Loss: 203.1588592529297, Entropy -204.61790466308594, Learning Rate: 0.01\n",
      "Epoch [1152/20000], Loss: 210.43792724609375, Entropy -232.32052612304688, Learning Rate: 0.01\n",
      "Epoch [1153/20000], Loss: 200.23062133789062, Entropy -213.98756408691406, Learning Rate: 0.01\n",
      "Epoch [1154/20000], Loss: 212.0962371826172, Entropy -221.09515380859375, Learning Rate: 0.01\n",
      "Epoch [1155/20000], Loss: 212.4481201171875, Entropy -226.22402954101562, Learning Rate: 0.01\n",
      "Epoch [1156/20000], Loss: 209.5727081298828, Entropy -225.00827026367188, Learning Rate: 0.01\n",
      "Epoch [1157/20000], Loss: 200.7634735107422, Entropy -208.16612243652344, Learning Rate: 0.01\n",
      "Epoch [1158/20000], Loss: 211.07498168945312, Entropy -229.32623291015625, Learning Rate: 0.01\n",
      "Epoch [1159/20000], Loss: 211.48245239257812, Entropy -226.01780700683594, Learning Rate: 0.01\n",
      "Epoch [1160/20000], Loss: 203.02162170410156, Entropy -217.98587036132812, Learning Rate: 0.01\n",
      "Epoch [1161/20000], Loss: 210.60728454589844, Entropy -213.79705810546875, Learning Rate: 0.01\n",
      "Epoch [1162/20000], Loss: 202.56829833984375, Entropy -220.16049194335938, Learning Rate: 0.01\n",
      "Epoch [1163/20000], Loss: 198.330322265625, Entropy -213.23812866210938, Learning Rate: 0.01\n",
      "Epoch [1164/20000], Loss: 218.92909240722656, Entropy -220.43321228027344, Learning Rate: 0.01\n",
      "Epoch [1165/20000], Loss: 206.13140869140625, Entropy -221.9744415283203, Learning Rate: 0.01\n",
      "Epoch [1166/20000], Loss: 198.5198974609375, Entropy -220.73097229003906, Learning Rate: 0.01\n",
      "Epoch [1167/20000], Loss: 198.88067626953125, Entropy -204.52774047851562, Learning Rate: 0.01\n",
      "Epoch [1168/20000], Loss: 213.87646484375, Entropy -225.24952697753906, Learning Rate: 0.01\n",
      "Epoch [1169/20000], Loss: 212.31814575195312, Entropy -216.5557098388672, Learning Rate: 0.01\n",
      "Epoch [1170/20000], Loss: 202.18124389648438, Entropy -216.54151916503906, Learning Rate: 0.01\n",
      "Epoch [1171/20000], Loss: 204.2811279296875, Entropy -217.25567626953125, Learning Rate: 0.01\n",
      "Epoch [1172/20000], Loss: 200.92083740234375, Entropy -207.58935546875, Learning Rate: 0.01\n",
      "Epoch [1173/20000], Loss: 215.5995635986328, Entropy -232.43008422851562, Learning Rate: 0.01\n",
      "Epoch [1174/20000], Loss: 200.6804656982422, Entropy -207.05319213867188, Learning Rate: 0.01\n",
      "Epoch [1175/20000], Loss: 205.6697998046875, Entropy -212.12692260742188, Learning Rate: 0.01\n",
      "Epoch [1176/20000], Loss: 199.08522033691406, Entropy -209.8536376953125, Learning Rate: 0.01\n",
      "Epoch [1177/20000], Loss: 203.65586853027344, Entropy -204.22042846679688, Learning Rate: 0.01\n",
      "Epoch [1178/20000], Loss: 218.41932678222656, Entropy -222.85443115234375, Learning Rate: 0.01\n",
      "Epoch [1179/20000], Loss: 206.24444580078125, Entropy -214.20138549804688, Learning Rate: 0.01\n",
      "Epoch [1180/20000], Loss: 216.4375, Entropy -217.59042358398438, Learning Rate: 0.01\n",
      "Epoch [1181/20000], Loss: 219.47581481933594, Entropy -207.6392822265625, Learning Rate: 0.01\n",
      "Epoch [1182/20000], Loss: 205.53338623046875, Entropy -212.47018432617188, Learning Rate: 0.01\n",
      "Epoch [1183/20000], Loss: 212.49278259277344, Entropy -203.6072540283203, Learning Rate: 0.01\n",
      "Epoch [1184/20000], Loss: 223.23544311523438, Entropy -208.79684448242188, Learning Rate: 0.01\n",
      "Epoch [1185/20000], Loss: 215.4593505859375, Entropy -207.62844848632812, Learning Rate: 0.01\n",
      "Epoch [1186/20000], Loss: 224.60433959960938, Entropy -233.426025390625, Learning Rate: 0.01\n",
      "Epoch [1187/20000], Loss: 196.61598205566406, Entropy -202.03717041015625, Learning Rate: 0.01\n",
      "Epoch [1188/20000], Loss: 211.1638946533203, Entropy -221.98397827148438, Learning Rate: 0.01\n",
      "Epoch [1189/20000], Loss: 216.2946014404297, Entropy -225.42945861816406, Learning Rate: 0.01\n",
      "Epoch [1190/20000], Loss: 201.0083770751953, Entropy -201.84036254882812, Learning Rate: 0.01\n",
      "Epoch [1191/20000], Loss: 199.5547637939453, Entropy -206.9039306640625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1192/20000], Loss: 205.6673126220703, Entropy -220.13955688476562, Learning Rate: 0.01\n",
      "Epoch [1193/20000], Loss: 213.0382843017578, Entropy -226.34701538085938, Learning Rate: 0.01\n",
      "Epoch [1194/20000], Loss: 204.80624389648438, Entropy -225.65438842773438, Learning Rate: 0.01\n",
      "Epoch [1195/20000], Loss: 191.46829223632812, Entropy -203.9429168701172, Learning Rate: 0.01\n",
      "Epoch [1196/20000], Loss: 203.4646453857422, Entropy -211.79489135742188, Learning Rate: 0.01\n",
      "Epoch [1197/20000], Loss: 197.61102294921875, Entropy -214.9153289794922, Learning Rate: 0.01\n",
      "Epoch [1198/20000], Loss: 222.3052520751953, Entropy -232.7657012939453, Learning Rate: 0.01\n",
      "Epoch [1199/20000], Loss: 204.9266357421875, Entropy -220.33541870117188, Learning Rate: 0.01\n",
      "Epoch [1200/20000], Loss: 191.5978546142578, Entropy -216.5845184326172, Learning Rate: 0.01\n",
      "Epoch [1201/20000], Loss: 202.10751342773438, Entropy -216.28811645507812, Learning Rate: 0.01\n",
      "Epoch [1202/20000], Loss: 193.62786865234375, Entropy -198.43856811523438, Learning Rate: 0.01\n",
      "Epoch [1203/20000], Loss: 193.93617248535156, Entropy -206.77015686035156, Learning Rate: 0.01\n",
      "Epoch [1204/20000], Loss: 197.95741271972656, Entropy -210.8462677001953, Learning Rate: 0.01\n",
      "Epoch [1205/20000], Loss: 187.11244201660156, Entropy -199.37359619140625, Learning Rate: 0.01\n",
      "Epoch [1206/20000], Loss: 194.12255859375, Entropy -211.20379638671875, Learning Rate: 0.01\n",
      "Epoch [1207/20000], Loss: 195.62789916992188, Entropy -215.18496704101562, Learning Rate: 0.01\n",
      "Epoch [1208/20000], Loss: 190.77809143066406, Entropy -200.97665405273438, Learning Rate: 0.01\n",
      "Epoch [1209/20000], Loss: 194.79864501953125, Entropy -211.3231658935547, Learning Rate: 0.01\n",
      "Epoch [1210/20000], Loss: 191.5146942138672, Entropy -212.98475646972656, Learning Rate: 0.01\n",
      "Epoch [1211/20000], Loss: 198.83689880371094, Entropy -219.57977294921875, Learning Rate: 0.01\n",
      "Epoch [1212/20000], Loss: 194.66549682617188, Entropy -219.60130310058594, Learning Rate: 0.01\n",
      "Epoch [1213/20000], Loss: 197.0081787109375, Entropy -211.7977294921875, Learning Rate: 0.01\n",
      "Epoch [1214/20000], Loss: 188.0127716064453, Entropy -201.23760986328125, Learning Rate: 0.01\n",
      "Epoch [1215/20000], Loss: 206.84243774414062, Entropy -213.98402404785156, Learning Rate: 0.01\n",
      "Epoch [1216/20000], Loss: 196.7637481689453, Entropy -213.34906005859375, Learning Rate: 0.01\n",
      "Epoch [1217/20000], Loss: 208.33639526367188, Entropy -221.30239868164062, Learning Rate: 0.01\n",
      "Epoch [1218/20000], Loss: 181.984130859375, Entropy -196.95501708984375, Learning Rate: 0.01\n",
      "Epoch [1219/20000], Loss: 181.597412109375, Entropy -204.7823944091797, Learning Rate: 0.01\n",
      "Epoch [1220/20000], Loss: 196.024658203125, Entropy -211.56983947753906, Learning Rate: 0.01\n",
      "Epoch [1221/20000], Loss: 197.357666015625, Entropy -207.82711791992188, Learning Rate: 0.01\n",
      "Epoch [1222/20000], Loss: 187.00462341308594, Entropy -212.76666259765625, Learning Rate: 0.01\n",
      "Epoch [1223/20000], Loss: 185.5082244873047, Entropy -194.95765686035156, Learning Rate: 0.01\n",
      "Epoch [1224/20000], Loss: 203.5884552001953, Entropy -221.21395874023438, Learning Rate: 0.01\n",
      "Epoch [1225/20000], Loss: 197.42959594726562, Entropy -209.86251831054688, Learning Rate: 0.01\n",
      "Epoch [1226/20000], Loss: 202.60867309570312, Entropy -207.51454162597656, Learning Rate: 0.01\n",
      "Epoch [1227/20000], Loss: 206.70458984375, Entropy -219.30438232421875, Learning Rate: 0.01\n",
      "Epoch [1228/20000], Loss: 204.4071502685547, Entropy -213.8243408203125, Learning Rate: 0.01\n",
      "Epoch [1229/20000], Loss: 188.55722045898438, Entropy -199.99044799804688, Learning Rate: 0.01\n",
      "Epoch [1230/20000], Loss: 195.2159423828125, Entropy -214.72317504882812, Learning Rate: 0.01\n",
      "Epoch [1231/20000], Loss: 198.8175811767578, Entropy -202.93865966796875, Learning Rate: 0.01\n",
      "Epoch [1232/20000], Loss: 195.63113403320312, Entropy -206.78311157226562, Learning Rate: 0.01\n",
      "Epoch [1233/20000], Loss: 202.17974853515625, Entropy -216.92727661132812, Learning Rate: 0.01\n",
      "Epoch [1234/20000], Loss: 188.8975830078125, Entropy -203.64752197265625, Learning Rate: 0.01\n",
      "Epoch [1235/20000], Loss: 198.07211303710938, Entropy -207.95584106445312, Learning Rate: 0.01\n",
      "Epoch [1236/20000], Loss: 195.31622314453125, Entropy -204.42218017578125, Learning Rate: 0.01\n",
      "Epoch [1237/20000], Loss: 203.97225952148438, Entropy -225.21331787109375, Learning Rate: 0.01\n",
      "Epoch [1238/20000], Loss: 189.55596923828125, Entropy -210.95068359375, Learning Rate: 0.01\n",
      "Epoch [1239/20000], Loss: 203.5419158935547, Entropy -206.46157836914062, Learning Rate: 0.01\n",
      "Epoch [1240/20000], Loss: 207.2941131591797, Entropy -202.6102294921875, Learning Rate: 0.01\n",
      "Epoch [1241/20000], Loss: 202.66021728515625, Entropy -209.07366943359375, Learning Rate: 0.01\n",
      "Epoch [1242/20000], Loss: 192.00668334960938, Entropy -212.13397216796875, Learning Rate: 0.01\n",
      "Epoch [1243/20000], Loss: 209.00965881347656, Entropy -211.75283813476562, Learning Rate: 0.01\n",
      "Epoch [1244/20000], Loss: 212.018310546875, Entropy -205.13861083984375, Learning Rate: 0.01\n",
      "Epoch [1245/20000], Loss: 198.24591064453125, Entropy -209.1138916015625, Learning Rate: 0.01\n",
      "Epoch [1246/20000], Loss: 189.3372039794922, Entropy -190.39236450195312, Learning Rate: 0.01\n",
      "Epoch [1247/20000], Loss: 221.6757354736328, Entropy -215.77450561523438, Learning Rate: 0.01\n",
      "Epoch [1248/20000], Loss: 192.23849487304688, Entropy -196.8408203125, Learning Rate: 0.01\n",
      "Epoch [1249/20000], Loss: 221.7549591064453, Entropy -211.2261199951172, Learning Rate: 0.01\n",
      "Epoch [1250/20000], Loss: 203.58209228515625, Entropy -201.18409729003906, Learning Rate: 0.01\n",
      "Epoch [1251/20000], Loss: 223.74502563476562, Entropy -221.575927734375, Learning Rate: 0.01\n",
      "Epoch [1252/20000], Loss: 204.98643493652344, Entropy -196.8022003173828, Learning Rate: 0.01\n",
      "Epoch [1253/20000], Loss: 185.75540161132812, Entropy -194.48452758789062, Learning Rate: 0.01\n",
      "Epoch [1254/20000], Loss: 202.9202880859375, Entropy -203.9684295654297, Learning Rate: 0.01\n",
      "Epoch [1255/20000], Loss: 191.20547485351562, Entropy -196.15606689453125, Learning Rate: 0.01\n",
      "Epoch [1256/20000], Loss: 213.48370361328125, Entropy -229.825439453125, Learning Rate: 0.01\n",
      "Epoch [1257/20000], Loss: 195.3101806640625, Entropy -197.87701416015625, Learning Rate: 0.01\n",
      "Epoch [1258/20000], Loss: 185.2595672607422, Entropy -202.04586791992188, Learning Rate: 0.01\n",
      "Epoch [1259/20000], Loss: 185.63247680664062, Entropy -200.2076873779297, Learning Rate: 0.01\n",
      "Epoch [1260/20000], Loss: 182.55543518066406, Entropy -192.5787353515625, Learning Rate: 0.01\n",
      "Epoch [1261/20000], Loss: 191.67367553710938, Entropy -206.0309295654297, Learning Rate: 0.01\n",
      "Epoch [1262/20000], Loss: 195.2127227783203, Entropy -207.7490997314453, Learning Rate: 0.01\n",
      "Epoch [1263/20000], Loss: 195.90402221679688, Entropy -203.857421875, Learning Rate: 0.01\n",
      "Epoch [1264/20000], Loss: 201.80673217773438, Entropy -206.34347534179688, Learning Rate: 0.01\n",
      "Epoch [1265/20000], Loss: 203.47589111328125, Entropy -218.27175903320312, Learning Rate: 0.01\n",
      "Epoch [1266/20000], Loss: 208.54849243164062, Entropy -212.70162963867188, Learning Rate: 0.01\n",
      "Epoch [1267/20000], Loss: 189.34947204589844, Entropy -193.8774871826172, Learning Rate: 0.01\n",
      "Epoch [1268/20000], Loss: 221.34576416015625, Entropy -217.83758544921875, Learning Rate: 0.01\n",
      "Epoch [1269/20000], Loss: 213.7080841064453, Entropy -208.0976104736328, Learning Rate: 0.01\n",
      "Epoch [1270/20000], Loss: 199.87216186523438, Entropy -207.23594665527344, Learning Rate: 0.01\n",
      "Epoch [1271/20000], Loss: 219.25607299804688, Entropy -200.7945556640625, Learning Rate: 0.01\n",
      "Epoch [1272/20000], Loss: 228.88832092285156, Entropy -194.79505920410156, Learning Rate: 0.01\n",
      "Epoch [1273/20000], Loss: 225.40501403808594, Entropy -216.76425170898438, Learning Rate: 0.01\n",
      "Epoch [1274/20000], Loss: 201.12417602539062, Entropy -202.9279022216797, Learning Rate: 0.01\n",
      "Epoch [1275/20000], Loss: 187.63121032714844, Entropy -202.42794799804688, Learning Rate: 0.01\n",
      "Epoch [1276/20000], Loss: 193.5421905517578, Entropy -193.99769592285156, Learning Rate: 0.01\n",
      "Epoch [1277/20000], Loss: 224.12210083007812, Entropy -217.434326171875, Learning Rate: 0.01\n",
      "Epoch [1278/20000], Loss: 212.9368133544922, Entropy -214.16571044921875, Learning Rate: 0.01\n",
      "Epoch [1279/20000], Loss: 200.11386108398438, Entropy -198.6142578125, Learning Rate: 0.01\n",
      "Epoch [1280/20000], Loss: 207.41014099121094, Entropy -205.26722717285156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1281/20000], Loss: 190.888427734375, Entropy -194.74050903320312, Learning Rate: 0.01\n",
      "Epoch [1282/20000], Loss: 191.3363494873047, Entropy -201.93875122070312, Learning Rate: 0.01\n",
      "Epoch [1283/20000], Loss: 199.12025451660156, Entropy -208.92762756347656, Learning Rate: 0.01\n",
      "Epoch [1284/20000], Loss: 201.50411987304688, Entropy -200.81015014648438, Learning Rate: 0.01\n",
      "Epoch [1285/20000], Loss: 213.42616271972656, Entropy -210.5948944091797, Learning Rate: 0.01\n",
      "Epoch [1286/20000], Loss: 212.91375732421875, Entropy -213.40472412109375, Learning Rate: 0.01\n",
      "Epoch [1287/20000], Loss: 185.6702880859375, Entropy -196.3134765625, Learning Rate: 0.01\n",
      "Epoch [1288/20000], Loss: 206.3376007080078, Entropy -204.43661499023438, Learning Rate: 0.01\n",
      "Epoch [1289/20000], Loss: 185.1501922607422, Entropy -194.1013946533203, Learning Rate: 0.01\n",
      "Epoch [1290/20000], Loss: 189.86529541015625, Entropy -199.49270629882812, Learning Rate: 0.01\n",
      "Epoch [1291/20000], Loss: 183.0230255126953, Entropy -195.35678100585938, Learning Rate: 0.01\n",
      "Epoch [1292/20000], Loss: 189.05624389648438, Entropy -203.49253845214844, Learning Rate: 0.01\n",
      "Epoch [1293/20000], Loss: 185.95115661621094, Entropy -200.8470458984375, Learning Rate: 0.01\n",
      "Epoch [1294/20000], Loss: 188.62725830078125, Entropy -200.97952270507812, Learning Rate: 0.01\n",
      "Epoch [1295/20000], Loss: 179.28067016601562, Entropy -194.83277893066406, Learning Rate: 0.01\n",
      "Epoch [1296/20000], Loss: 185.20095825195312, Entropy -199.087158203125, Learning Rate: 0.01\n",
      "Epoch [1297/20000], Loss: 180.45919799804688, Entropy -194.9701385498047, Learning Rate: 0.01\n",
      "Epoch [1298/20000], Loss: 191.1537628173828, Entropy -205.26400756835938, Learning Rate: 0.01\n",
      "Epoch [1299/20000], Loss: 201.6200714111328, Entropy -199.5999755859375, Learning Rate: 0.01\n",
      "Epoch [1300/20000], Loss: 192.96522521972656, Entropy -218.1469268798828, Learning Rate: 0.01\n",
      "Epoch [1301/20000], Loss: 196.627197265625, Entropy -209.4041748046875, Learning Rate: 0.01\n",
      "Epoch [1302/20000], Loss: 176.80221557617188, Entropy -191.78675842285156, Learning Rate: 0.01\n",
      "Epoch [1303/20000], Loss: 180.73110961914062, Entropy -179.1199951171875, Learning Rate: 0.01\n",
      "Epoch [1304/20000], Loss: 185.40945434570312, Entropy -205.28775024414062, Learning Rate: 0.01\n",
      "Epoch [1305/20000], Loss: 193.85009765625, Entropy -203.4932098388672, Learning Rate: 0.01\n",
      "Epoch [1306/20000], Loss: 187.65599060058594, Entropy -200.66146850585938, Learning Rate: 0.01\n",
      "Epoch [1307/20000], Loss: 195.1925506591797, Entropy -207.47744750976562, Learning Rate: 0.01\n",
      "Epoch [1308/20000], Loss: 184.60162353515625, Entropy -205.09344482421875, Learning Rate: 0.01\n",
      "Epoch [1309/20000], Loss: 188.4170684814453, Entropy -200.958984375, Learning Rate: 0.01\n",
      "Epoch [1310/20000], Loss: 179.61915588378906, Entropy -188.92335510253906, Learning Rate: 0.01\n",
      "Epoch [1311/20000], Loss: 187.33164978027344, Entropy -191.46731567382812, Learning Rate: 0.01\n",
      "Epoch [1312/20000], Loss: 199.6195831298828, Entropy -214.09689331054688, Learning Rate: 0.01\n",
      "Epoch [1313/20000], Loss: 178.456298828125, Entropy -192.34097290039062, Learning Rate: 0.01\n",
      "Epoch [1314/20000], Loss: 185.70883178710938, Entropy -196.40049743652344, Learning Rate: 0.01\n",
      "Epoch [1315/20000], Loss: 180.2512969970703, Entropy -191.97683715820312, Learning Rate: 0.01\n",
      "Epoch [1316/20000], Loss: 192.48521423339844, Entropy -190.77377319335938, Learning Rate: 0.01\n",
      "Epoch [1317/20000], Loss: 186.8576202392578, Entropy -192.44735717773438, Learning Rate: 0.01\n",
      "Epoch [1318/20000], Loss: 194.98789978027344, Entropy -197.5281982421875, Learning Rate: 0.01\n",
      "Epoch [1319/20000], Loss: 192.62269592285156, Entropy -203.3911590576172, Learning Rate: 0.01\n",
      "Epoch [1320/20000], Loss: 173.43663024902344, Entropy -194.23294067382812, Learning Rate: 0.01\n",
      "Epoch [1321/20000], Loss: 187.93727111816406, Entropy -202.24452209472656, Learning Rate: 0.01\n",
      "Epoch [1322/20000], Loss: 182.74835205078125, Entropy -199.21444702148438, Learning Rate: 0.01\n",
      "Epoch [1323/20000], Loss: 174.95721435546875, Entropy -194.45962524414062, Learning Rate: 0.01\n",
      "Epoch [1324/20000], Loss: 191.74343872070312, Entropy -216.14657592773438, Learning Rate: 0.01\n",
      "Epoch [1325/20000], Loss: 181.14718627929688, Entropy -200.4739227294922, Learning Rate: 0.01\n",
      "Epoch [1326/20000], Loss: 190.53956604003906, Entropy -204.83229064941406, Learning Rate: 0.01\n",
      "Epoch [1327/20000], Loss: 184.40428161621094, Entropy -186.68975830078125, Learning Rate: 0.01\n",
      "Epoch [1328/20000], Loss: 197.5912628173828, Entropy -214.80313110351562, Learning Rate: 0.01\n",
      "Epoch [1329/20000], Loss: 179.22317504882812, Entropy -189.3561248779297, Learning Rate: 0.01\n",
      "Epoch [1330/20000], Loss: 183.4850616455078, Entropy -197.14495849609375, Learning Rate: 0.01\n",
      "Epoch [1331/20000], Loss: 170.98495483398438, Entropy -182.88174438476562, Learning Rate: 0.01\n",
      "Epoch [1332/20000], Loss: 192.09799194335938, Entropy -204.80836486816406, Learning Rate: 0.01\n",
      "Epoch [1333/20000], Loss: 195.11436462402344, Entropy -197.86131286621094, Learning Rate: 0.01\n",
      "Epoch [1334/20000], Loss: 185.02809143066406, Entropy -194.71011352539062, Learning Rate: 0.01\n",
      "Epoch [1335/20000], Loss: 191.159423828125, Entropy -210.51416015625, Learning Rate: 0.01\n",
      "Epoch [1336/20000], Loss: 180.3252410888672, Entropy -192.44773864746094, Learning Rate: 0.01\n",
      "Epoch [1337/20000], Loss: 218.09259033203125, Entropy -199.591064453125, Learning Rate: 0.01\n",
      "Epoch [1338/20000], Loss: 189.95790100097656, Entropy -194.56787109375, Learning Rate: 0.01\n",
      "Epoch [1339/20000], Loss: 194.99722290039062, Entropy -217.9033966064453, Learning Rate: 0.01\n",
      "Epoch [1340/20000], Loss: 226.28775024414062, Entropy -188.43795776367188, Learning Rate: 0.01\n",
      "Epoch [1341/20000], Loss: 247.41317749023438, Entropy -188.6707763671875, Learning Rate: 0.01\n",
      "Epoch [1342/20000], Loss: 282.3360595703125, Entropy -208.51470947265625, Learning Rate: 0.01\n",
      "Epoch [1343/20000], Loss: 193.24082946777344, Entropy -191.1542205810547, Learning Rate: 0.01\n",
      "Epoch [1344/20000], Loss: 197.9730224609375, Entropy -189.2436065673828, Learning Rate: 0.01\n",
      "Epoch [1345/20000], Loss: 195.68121337890625, Entropy -193.4155731201172, Learning Rate: 0.01\n",
      "Epoch [1346/20000], Loss: 185.62924194335938, Entropy -188.94284057617188, Learning Rate: 0.01\n",
      "Epoch [1347/20000], Loss: 189.45672607421875, Entropy -202.07952880859375, Learning Rate: 0.01\n",
      "Epoch [1348/20000], Loss: 207.70562744140625, Entropy -198.5596923828125, Learning Rate: 0.01\n",
      "Epoch [1349/20000], Loss: 207.50682067871094, Entropy -215.4757843017578, Learning Rate: 0.01\n",
      "Epoch [1350/20000], Loss: 192.12652587890625, Entropy -194.490966796875, Learning Rate: 0.01\n",
      "Epoch [1351/20000], Loss: 180.86190795898438, Entropy -194.52853393554688, Learning Rate: 0.01\n",
      "Epoch [1352/20000], Loss: 191.48838806152344, Entropy -202.62139892578125, Learning Rate: 0.01\n",
      "Epoch [1353/20000], Loss: 175.50030517578125, Entropy -174.01956176757812, Learning Rate: 0.01\n",
      "Epoch [1354/20000], Loss: 185.4072265625, Entropy -191.13462829589844, Learning Rate: 0.01\n",
      "Epoch [1355/20000], Loss: 178.89913940429688, Entropy -192.6787567138672, Learning Rate: 0.01\n",
      "Epoch [1356/20000], Loss: 206.96669006347656, Entropy -213.94061279296875, Learning Rate: 0.01\n",
      "Epoch [1357/20000], Loss: 177.95620727539062, Entropy -184.49224853515625, Learning Rate: 0.01\n",
      "Epoch [1358/20000], Loss: 192.1461944580078, Entropy -200.01217651367188, Learning Rate: 0.01\n",
      "Epoch [1359/20000], Loss: 186.82736206054688, Entropy -201.8287811279297, Learning Rate: 0.01\n",
      "Epoch [1360/20000], Loss: 174.79067993164062, Entropy -195.21139526367188, Learning Rate: 0.01\n",
      "Epoch [1361/20000], Loss: 332.6312561035156, Entropy -200.02920532226562, Learning Rate: 0.01\n",
      "Epoch [1362/20000], Loss: 213.18203735351562, Entropy -196.87835693359375, Learning Rate: 0.01\n",
      "Epoch [1363/20000], Loss: 225.8426055908203, Entropy -202.39703369140625, Learning Rate: 0.01\n",
      "Epoch [1364/20000], Loss: 227.16184997558594, Entropy -203.41648864746094, Learning Rate: 0.01\n",
      "Epoch [1365/20000], Loss: 267.42852783203125, Entropy -197.36892700195312, Learning Rate: 0.01\n",
      "Epoch [1366/20000], Loss: 304.7684020996094, Entropy -213.88314819335938, Learning Rate: 0.01\n",
      "Epoch [1367/20000], Loss: 252.1132354736328, Entropy -213.33981323242188, Learning Rate: 0.01\n",
      "Epoch [1368/20000], Loss: 250.384521484375, Entropy -212.45486450195312, Learning Rate: 0.01\n",
      "Epoch [1369/20000], Loss: 321.6410827636719, Entropy -218.51052856445312, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1370/20000], Loss: 673.9093627929688, Entropy -208.66050720214844, Learning Rate: 0.01\n",
      "Epoch [1371/20000], Loss: 804.381591796875, Entropy -212.1507110595703, Learning Rate: 0.01\n",
      "Epoch [1372/20000], Loss: 346.1454772949219, Entropy -186.17691040039062, Learning Rate: 0.01\n",
      "Epoch [1373/20000], Loss: 479.6373596191406, Entropy -209.7293243408203, Learning Rate: 0.01\n",
      "Epoch [1374/20000], Loss: 429.7010192871094, Entropy -199.81759643554688, Learning Rate: 0.01\n",
      "Epoch [1375/20000], Loss: 375.87762451171875, Entropy -197.268310546875, Learning Rate: 0.01\n",
      "Epoch [1376/20000], Loss: 518.5125732421875, Entropy -209.64291381835938, Learning Rate: 0.01\n",
      "Epoch [1377/20000], Loss: 303.31494140625, Entropy -197.18582153320312, Learning Rate: 0.01\n",
      "Epoch [1378/20000], Loss: 377.3687438964844, Entropy -214.50323486328125, Learning Rate: 0.01\n",
      "Epoch [1379/20000], Loss: 264.202880859375, Entropy -213.9420166015625, Learning Rate: 0.01\n",
      "Epoch [1380/20000], Loss: 346.8036193847656, Entropy -217.27548217773438, Learning Rate: 0.01\n",
      "Epoch [1381/20000], Loss: 256.4746398925781, Entropy -201.70834350585938, Learning Rate: 0.01\n",
      "Epoch [1382/20000], Loss: 328.3414611816406, Entropy -213.19100952148438, Learning Rate: 0.01\n",
      "Epoch [1383/20000], Loss: 253.22906494140625, Entropy -218.3660888671875, Learning Rate: 0.01\n",
      "Epoch [1384/20000], Loss: 264.26763916015625, Entropy -211.41006469726562, Learning Rate: 0.01\n",
      "Epoch [1385/20000], Loss: 261.36602783203125, Entropy -227.49417114257812, Learning Rate: 0.01\n",
      "Epoch [1386/20000], Loss: 251.70948791503906, Entropy -209.73513793945312, Learning Rate: 0.01\n",
      "Epoch [1387/20000], Loss: 210.09197998046875, Entropy -197.55589294433594, Learning Rate: 0.01\n",
      "Epoch [1388/20000], Loss: 245.765380859375, Entropy -217.66897583007812, Learning Rate: 0.01\n",
      "Epoch [1389/20000], Loss: 231.8282470703125, Entropy -222.14126586914062, Learning Rate: 0.01\n",
      "Epoch [1390/20000], Loss: 220.9619140625, Entropy -212.2342071533203, Learning Rate: 0.01\n",
      "Epoch [1391/20000], Loss: 230.18368530273438, Entropy -206.40277099609375, Learning Rate: 0.01\n",
      "Epoch [1392/20000], Loss: 223.49058532714844, Entropy -212.82164001464844, Learning Rate: 0.01\n",
      "Epoch [1393/20000], Loss: 200.64675903320312, Entropy -198.42919921875, Learning Rate: 0.01\n",
      "Epoch [1394/20000], Loss: 226.7953338623047, Entropy -216.75949096679688, Learning Rate: 0.01\n",
      "Epoch [1395/20000], Loss: 212.13084411621094, Entropy -216.69345092773438, Learning Rate: 0.01\n",
      "Epoch [1396/20000], Loss: 249.68304443359375, Entropy -232.96070861816406, Learning Rate: 0.01\n",
      "Epoch [1397/20000], Loss: 230.8310546875, Entropy -220.943359375, Learning Rate: 0.01\n",
      "Epoch [1398/20000], Loss: 226.47056579589844, Entropy -217.09136962890625, Learning Rate: 0.01\n",
      "Epoch [1399/20000], Loss: 214.38597106933594, Entropy -226.7124786376953, Learning Rate: 0.01\n",
      "Epoch [1400/20000], Loss: 213.29669189453125, Entropy -211.20767211914062, Learning Rate: 0.01\n",
      "Epoch [1401/20000], Loss: 199.67156982421875, Entropy -201.36752319335938, Learning Rate: 0.01\n",
      "Epoch [1402/20000], Loss: 216.1913299560547, Entropy -220.39389038085938, Learning Rate: 0.01\n",
      "Epoch [1403/20000], Loss: 209.6876983642578, Entropy -205.54408264160156, Learning Rate: 0.01\n",
      "Epoch [1404/20000], Loss: 193.52322387695312, Entropy -195.2869873046875, Learning Rate: 0.01\n",
      "Epoch [1405/20000], Loss: 205.25750732421875, Entropy -205.9170684814453, Learning Rate: 0.01\n",
      "Epoch [1406/20000], Loss: 198.45437622070312, Entropy -194.92025756835938, Learning Rate: 0.01\n",
      "Epoch [1407/20000], Loss: 192.23500061035156, Entropy -197.04539489746094, Learning Rate: 0.01\n",
      "Epoch [1408/20000], Loss: 211.7817840576172, Entropy -207.2275848388672, Learning Rate: 0.01\n",
      "Epoch [1409/20000], Loss: 178.98587036132812, Entropy -195.31756591796875, Learning Rate: 0.01\n",
      "Epoch [1410/20000], Loss: 201.8359375, Entropy -208.1131591796875, Learning Rate: 0.01\n",
      "Epoch [1411/20000], Loss: 192.36199951171875, Entropy -211.06494140625, Learning Rate: 0.01\n",
      "Epoch [1412/20000], Loss: 211.93515014648438, Entropy -214.27163696289062, Learning Rate: 0.01\n",
      "Epoch [1413/20000], Loss: 191.94969177246094, Entropy -211.29904174804688, Learning Rate: 0.01\n",
      "Epoch [1414/20000], Loss: 195.2271728515625, Entropy -201.82113647460938, Learning Rate: 0.01\n",
      "Epoch [1415/20000], Loss: 195.93472290039062, Entropy -212.09779357910156, Learning Rate: 0.01\n",
      "Epoch [1416/20000], Loss: 198.56448364257812, Entropy -199.6141815185547, Learning Rate: 0.01\n",
      "Epoch [1417/20000], Loss: 199.3212127685547, Entropy -213.70640563964844, Learning Rate: 0.01\n",
      "Epoch [1418/20000], Loss: 179.46315002441406, Entropy -197.98727416992188, Learning Rate: 0.01\n",
      "Epoch [1419/20000], Loss: 168.6826629638672, Entropy -178.95468139648438, Learning Rate: 0.01\n",
      "Epoch [1420/20000], Loss: 180.92227172851562, Entropy -194.48171997070312, Learning Rate: 0.01\n",
      "Epoch [1421/20000], Loss: 185.7952423095703, Entropy -192.27206420898438, Learning Rate: 0.01\n",
      "Epoch [1422/20000], Loss: 193.2078399658203, Entropy -208.01309204101562, Learning Rate: 0.01\n",
      "Epoch [1423/20000], Loss: 193.72216796875, Entropy -210.88571166992188, Learning Rate: 0.01\n",
      "Epoch [1424/20000], Loss: 193.9715118408203, Entropy -201.400146484375, Learning Rate: 0.01\n",
      "Epoch [1425/20000], Loss: 176.03610229492188, Entropy -197.17239379882812, Learning Rate: 0.01\n",
      "Epoch [1426/20000], Loss: 187.24966430664062, Entropy -188.10585021972656, Learning Rate: 0.01\n",
      "Epoch [1427/20000], Loss: 187.96104431152344, Entropy -199.98068237304688, Learning Rate: 0.01\n",
      "Epoch [1428/20000], Loss: 180.98101806640625, Entropy -202.74468994140625, Learning Rate: 0.01\n",
      "Epoch [1429/20000], Loss: 174.918701171875, Entropy -184.50326538085938, Learning Rate: 0.01\n",
      "Epoch [1430/20000], Loss: 193.105224609375, Entropy -187.05099487304688, Learning Rate: 0.01\n",
      "Epoch [1431/20000], Loss: 180.82168579101562, Entropy -188.14932250976562, Learning Rate: 0.01\n",
      "Epoch [1432/20000], Loss: 173.07167053222656, Entropy -195.58560180664062, Learning Rate: 0.01\n",
      "Epoch [1433/20000], Loss: 185.1241455078125, Entropy -199.69876098632812, Learning Rate: 0.01\n",
      "Epoch [1434/20000], Loss: 171.11231994628906, Entropy -183.1134490966797, Learning Rate: 0.01\n",
      "Epoch [1435/20000], Loss: 191.00320434570312, Entropy -178.48904418945312, Learning Rate: 0.01\n",
      "Epoch [1436/20000], Loss: 171.61514282226562, Entropy -195.96902465820312, Learning Rate: 0.01\n",
      "Epoch [1437/20000], Loss: 183.25619506835938, Entropy -180.38856506347656, Learning Rate: 0.01\n",
      "Epoch [1438/20000], Loss: 174.739013671875, Entropy -190.20277404785156, Learning Rate: 0.01\n",
      "Epoch [1439/20000], Loss: 200.58209228515625, Entropy -225.3831329345703, Learning Rate: 0.01\n",
      "Epoch [1440/20000], Loss: 175.35122680664062, Entropy -193.9638671875, Learning Rate: 0.01\n",
      "Epoch [1441/20000], Loss: 181.5033416748047, Entropy -199.24061584472656, Learning Rate: 0.01\n",
      "Epoch [1442/20000], Loss: 182.47454833984375, Entropy -202.28350830078125, Learning Rate: 0.01\n",
      "Epoch [1443/20000], Loss: 175.37477111816406, Entropy -192.65631103515625, Learning Rate: 0.01\n",
      "Epoch [1444/20000], Loss: 186.00210571289062, Entropy -194.11782836914062, Learning Rate: 0.01\n",
      "Epoch [1445/20000], Loss: 195.7959442138672, Entropy -222.262451171875, Learning Rate: 0.01\n",
      "Epoch [1446/20000], Loss: 196.33428955078125, Entropy -214.4925537109375, Learning Rate: 0.01\n",
      "Epoch [1447/20000], Loss: 182.72988891601562, Entropy -203.25491333007812, Learning Rate: 0.01\n",
      "Epoch [1448/20000], Loss: 175.79116821289062, Entropy -197.06295776367188, Learning Rate: 0.01\n",
      "Epoch [1449/20000], Loss: 169.21578979492188, Entropy -188.89227294921875, Learning Rate: 0.01\n",
      "Epoch [1450/20000], Loss: 190.74803161621094, Entropy -208.4724884033203, Learning Rate: 0.01\n",
      "Epoch [1451/20000], Loss: 178.56011962890625, Entropy -201.4729766845703, Learning Rate: 0.01\n",
      "Epoch [1452/20000], Loss: 183.72885131835938, Entropy -195.828125, Learning Rate: 0.01\n",
      "Epoch [1453/20000], Loss: 171.1417999267578, Entropy -194.04913330078125, Learning Rate: 0.01\n",
      "Epoch [1454/20000], Loss: 178.8406982421875, Entropy -194.8564453125, Learning Rate: 0.01\n",
      "Epoch [1455/20000], Loss: 175.59808349609375, Entropy -199.01739501953125, Learning Rate: 0.01\n",
      "Epoch [1456/20000], Loss: 169.2339630126953, Entropy -188.4227294921875, Learning Rate: 0.01\n",
      "Epoch [1457/20000], Loss: 170.12222290039062, Entropy -186.01663208007812, Learning Rate: 0.01\n",
      "Epoch [1458/20000], Loss: 174.8865509033203, Entropy -184.70529174804688, Learning Rate: 0.01\n",
      "Epoch [1459/20000], Loss: 154.74887084960938, Entropy -172.86309814453125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1460/20000], Loss: 174.49118041992188, Entropy -193.84251403808594, Learning Rate: 0.01\n",
      "Epoch [1461/20000], Loss: 169.16915893554688, Entropy -183.841064453125, Learning Rate: 0.01\n",
      "Epoch [1462/20000], Loss: 171.99618530273438, Entropy -176.17581176757812, Learning Rate: 0.01\n",
      "Epoch [1463/20000], Loss: 176.4598388671875, Entropy -191.63101196289062, Learning Rate: 0.01\n",
      "Epoch [1464/20000], Loss: 168.35946655273438, Entropy -191.78311157226562, Learning Rate: 0.01\n",
      "Epoch [1465/20000], Loss: 171.3719024658203, Entropy -181.00128173828125, Learning Rate: 0.01\n",
      "Epoch [1466/20000], Loss: 166.32383728027344, Entropy -179.32412719726562, Learning Rate: 0.01\n",
      "Epoch [1467/20000], Loss: 168.17642211914062, Entropy -184.20773315429688, Learning Rate: 0.01\n",
      "Epoch [1468/20000], Loss: 163.5169219970703, Entropy -186.6129150390625, Learning Rate: 0.01\n",
      "Epoch [1469/20000], Loss: 166.58811950683594, Entropy -197.2620849609375, Learning Rate: 0.01\n",
      "Epoch [1470/20000], Loss: 158.03033447265625, Entropy -172.46945190429688, Learning Rate: 0.01\n",
      "Epoch [1471/20000], Loss: 155.98768615722656, Entropy -176.25811767578125, Learning Rate: 0.01\n",
      "Epoch [1472/20000], Loss: 223.15078735351562, Entropy -172.0912628173828, Learning Rate: 0.01\n",
      "Epoch [1473/20000], Loss: 183.68199157714844, Entropy -198.73538208007812, Learning Rate: 0.01\n",
      "Epoch [1474/20000], Loss: 183.83749389648438, Entropy -189.21029663085938, Learning Rate: 0.01\n",
      "Epoch [1475/20000], Loss: 183.8456573486328, Entropy -186.9263458251953, Learning Rate: 0.01\n",
      "Epoch [1476/20000], Loss: 171.43817138671875, Entropy -186.42214965820312, Learning Rate: 0.01\n",
      "Epoch [1477/20000], Loss: 173.59164428710938, Entropy -174.28482055664062, Learning Rate: 0.01\n",
      "Epoch [1478/20000], Loss: 184.18063354492188, Entropy -187.65673828125, Learning Rate: 0.01\n",
      "Epoch [1479/20000], Loss: 174.55857849121094, Entropy -194.49147033691406, Learning Rate: 0.01\n",
      "Epoch [1480/20000], Loss: 181.30340576171875, Entropy -190.9149169921875, Learning Rate: 0.01\n",
      "Epoch [1481/20000], Loss: 165.22523498535156, Entropy -189.54981994628906, Learning Rate: 0.01\n",
      "Epoch [1482/20000], Loss: 171.999755859375, Entropy -183.7090301513672, Learning Rate: 0.01\n",
      "Epoch [1483/20000], Loss: 188.17715454101562, Entropy -200.45364379882812, Learning Rate: 0.01\n",
      "Epoch [1484/20000], Loss: 175.38478088378906, Entropy -190.63406372070312, Learning Rate: 0.01\n",
      "Epoch [1485/20000], Loss: 180.2338104248047, Entropy -172.0412139892578, Learning Rate: 0.01\n",
      "Epoch [1486/20000], Loss: 196.00953674316406, Entropy -200.93731689453125, Learning Rate: 0.01\n",
      "Epoch [1487/20000], Loss: 180.4121856689453, Entropy -198.9337921142578, Learning Rate: 0.01\n",
      "Epoch [1488/20000], Loss: 184.80587768554688, Entropy -183.549072265625, Learning Rate: 0.01\n",
      "Epoch [1489/20000], Loss: 174.75909423828125, Entropy -186.152587890625, Learning Rate: 0.01\n",
      "Epoch [1490/20000], Loss: 191.40945434570312, Entropy -199.2611541748047, Learning Rate: 0.01\n",
      "Epoch [1491/20000], Loss: 174.13565063476562, Entropy -181.46478271484375, Learning Rate: 0.01\n",
      "Epoch [1492/20000], Loss: 179.8710174560547, Entropy -193.34857177734375, Learning Rate: 0.01\n",
      "Epoch [1493/20000], Loss: 203.13014221191406, Entropy -203.37437438964844, Learning Rate: 0.01\n",
      "Epoch [1494/20000], Loss: 180.5948486328125, Entropy -188.84849548339844, Learning Rate: 0.01\n",
      "Epoch [1495/20000], Loss: 208.0026092529297, Entropy -191.7184295654297, Learning Rate: 0.01\n",
      "Epoch [1496/20000], Loss: 232.96644592285156, Entropy -204.6252899169922, Learning Rate: 0.01\n",
      "Epoch [1497/20000], Loss: 204.95611572265625, Entropy -204.8284454345703, Learning Rate: 0.01\n",
      "Epoch [1498/20000], Loss: 239.04202270507812, Entropy -208.78128051757812, Learning Rate: 0.01\n",
      "Epoch [1499/20000], Loss: 248.27236938476562, Entropy -195.72735595703125, Learning Rate: 0.01\n",
      "Epoch [1500/20000], Loss: 214.87063598632812, Entropy -190.9022674560547, Learning Rate: 0.01\n",
      "Epoch [1501/20000], Loss: 200.1135711669922, Entropy -187.82281494140625, Learning Rate: 0.01\n",
      "Epoch [1502/20000], Loss: 214.41693115234375, Entropy -209.7276611328125, Learning Rate: 0.01\n",
      "Epoch [1503/20000], Loss: 211.72828674316406, Entropy -192.97293090820312, Learning Rate: 0.01\n",
      "Epoch [1504/20000], Loss: 183.2318878173828, Entropy -193.26634216308594, Learning Rate: 0.01\n",
      "Epoch [1505/20000], Loss: 197.7168426513672, Entropy -202.16351318359375, Learning Rate: 0.01\n",
      "Epoch [1506/20000], Loss: 204.1665802001953, Entropy -188.09727478027344, Learning Rate: 0.01\n",
      "Epoch [1507/20000], Loss: 185.73301696777344, Entropy -192.83253479003906, Learning Rate: 0.01\n",
      "Epoch [1508/20000], Loss: 195.92674255371094, Entropy -212.33078002929688, Learning Rate: 0.01\n",
      "Epoch [1509/20000], Loss: 186.7766876220703, Entropy -185.9774932861328, Learning Rate: 0.01\n",
      "Epoch [1510/20000], Loss: 165.94297790527344, Entropy -172.34356689453125, Learning Rate: 0.01\n",
      "Epoch [1511/20000], Loss: 170.7360076904297, Entropy -190.5489959716797, Learning Rate: 0.01\n",
      "Epoch [1512/20000], Loss: 183.49557495117188, Entropy -180.80491638183594, Learning Rate: 0.01\n",
      "Epoch [1513/20000], Loss: 185.49949645996094, Entropy -178.48208618164062, Learning Rate: 0.01\n",
      "Epoch [1514/20000], Loss: 174.9959716796875, Entropy -193.96202087402344, Learning Rate: 0.01\n",
      "Epoch [1515/20000], Loss: 176.04893493652344, Entropy -180.60317993164062, Learning Rate: 0.01\n",
      "Epoch [1516/20000], Loss: 187.40159606933594, Entropy -183.98529052734375, Learning Rate: 0.01\n",
      "Epoch [1517/20000], Loss: 176.24664306640625, Entropy -183.065673828125, Learning Rate: 0.01\n",
      "Epoch [1518/20000], Loss: 176.47227478027344, Entropy -196.54922485351562, Learning Rate: 0.01\n",
      "Epoch [1519/20000], Loss: 179.6883544921875, Entropy -196.60516357421875, Learning Rate: 0.01\n",
      "Epoch [1520/20000], Loss: 166.40887451171875, Entropy -183.85018920898438, Learning Rate: 0.01\n",
      "Epoch [1521/20000], Loss: 172.68971252441406, Entropy -174.61160278320312, Learning Rate: 0.01\n",
      "Epoch [1522/20000], Loss: 167.81336975097656, Entropy -182.40103149414062, Learning Rate: 0.01\n",
      "Epoch [1523/20000], Loss: 160.8641815185547, Entropy -172.24085998535156, Learning Rate: 0.01\n",
      "Epoch [1524/20000], Loss: 171.887451171875, Entropy -192.22454833984375, Learning Rate: 0.01\n",
      "Epoch [1525/20000], Loss: 176.73562622070312, Entropy -193.13726806640625, Learning Rate: 0.01\n",
      "Epoch [1526/20000], Loss: 170.8059539794922, Entropy -188.72216796875, Learning Rate: 0.01\n",
      "Epoch [1527/20000], Loss: 164.67843627929688, Entropy -175.579833984375, Learning Rate: 0.01\n",
      "Epoch [1528/20000], Loss: 170.0091094970703, Entropy -190.4962615966797, Learning Rate: 0.01\n",
      "Epoch [1529/20000], Loss: 172.04864501953125, Entropy -199.73171997070312, Learning Rate: 0.01\n",
      "Epoch [1530/20000], Loss: 166.69178771972656, Entropy -181.20689392089844, Learning Rate: 0.01\n",
      "Epoch [1531/20000], Loss: 168.87025451660156, Entropy -182.4920654296875, Learning Rate: 0.01\n",
      "Epoch [1532/20000], Loss: 167.28955078125, Entropy -178.96005249023438, Learning Rate: 0.01\n",
      "Epoch [1533/20000], Loss: 165.34095764160156, Entropy -183.312255859375, Learning Rate: 0.01\n",
      "Epoch [1534/20000], Loss: 179.99778747558594, Entropy -200.40390014648438, Learning Rate: 0.01\n",
      "Epoch [1535/20000], Loss: 178.1137237548828, Entropy -195.59974670410156, Learning Rate: 0.01\n",
      "Epoch [1536/20000], Loss: 187.3154754638672, Entropy -195.04580688476562, Learning Rate: 0.01\n",
      "Epoch [1537/20000], Loss: 180.31150817871094, Entropy -188.53941345214844, Learning Rate: 0.01\n",
      "Epoch [1538/20000], Loss: 169.21238708496094, Entropy -173.5269775390625, Learning Rate: 0.01\n",
      "Epoch [1539/20000], Loss: 171.97137451171875, Entropy -178.63436889648438, Learning Rate: 0.01\n",
      "Epoch [1540/20000], Loss: 175.4726104736328, Entropy -189.973876953125, Learning Rate: 0.01\n",
      "Epoch [1541/20000], Loss: 187.91781616210938, Entropy -187.4886932373047, Learning Rate: 0.01\n",
      "Epoch [1542/20000], Loss: 153.84291076660156, Entropy -172.23257446289062, Learning Rate: 0.01\n",
      "Epoch [1543/20000], Loss: 178.2942657470703, Entropy -178.8799591064453, Learning Rate: 0.01\n",
      "Epoch [1544/20000], Loss: 189.38677978515625, Entropy -194.91807556152344, Learning Rate: 0.01\n",
      "Epoch [1545/20000], Loss: 158.6927032470703, Entropy -173.48252868652344, Learning Rate: 0.01\n",
      "Epoch [1546/20000], Loss: 170.54388427734375, Entropy -185.54794311523438, Learning Rate: 0.01\n",
      "Epoch [1547/20000], Loss: 172.6458282470703, Entropy -183.19021606445312, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1548/20000], Loss: 168.1075897216797, Entropy -175.09591674804688, Learning Rate: 0.01\n",
      "Epoch [1549/20000], Loss: 170.59642028808594, Entropy -187.8758087158203, Learning Rate: 0.01\n",
      "Epoch [1550/20000], Loss: 172.3701171875, Entropy -195.31005859375, Learning Rate: 0.01\n",
      "Epoch [1551/20000], Loss: 167.22129821777344, Entropy -179.6259765625, Learning Rate: 0.01\n",
      "Epoch [1552/20000], Loss: 159.63841247558594, Entropy -177.1333465576172, Learning Rate: 0.01\n",
      "Epoch [1553/20000], Loss: 168.50283813476562, Entropy -173.74911499023438, Learning Rate: 0.01\n",
      "Epoch [1554/20000], Loss: 165.25791931152344, Entropy -166.77438354492188, Learning Rate: 0.01\n",
      "Epoch [1555/20000], Loss: 162.7736358642578, Entropy -165.967529296875, Learning Rate: 0.01\n",
      "Epoch [1556/20000], Loss: 168.85211181640625, Entropy -181.03550720214844, Learning Rate: 0.01\n",
      "Epoch [1557/20000], Loss: 160.216064453125, Entropy -174.6402587890625, Learning Rate: 0.01\n",
      "Epoch [1558/20000], Loss: 171.38650512695312, Entropy -183.9270477294922, Learning Rate: 0.01\n",
      "Epoch [1559/20000], Loss: 164.34793090820312, Entropy -183.12362670898438, Learning Rate: 0.01\n",
      "Epoch [1560/20000], Loss: 170.3423614501953, Entropy -176.8043670654297, Learning Rate: 0.01\n",
      "Epoch [1561/20000], Loss: 161.0326690673828, Entropy -173.32952880859375, Learning Rate: 0.01\n",
      "Epoch [1562/20000], Loss: 168.15040588378906, Entropy -196.13775634765625, Learning Rate: 0.01\n",
      "Epoch [1563/20000], Loss: 152.38021850585938, Entropy -172.73794555664062, Learning Rate: 0.01\n",
      "Epoch [1564/20000], Loss: 176.85733032226562, Entropy -198.56600952148438, Learning Rate: 0.01\n",
      "Epoch [1565/20000], Loss: 162.75204467773438, Entropy -186.49078369140625, Learning Rate: 0.01\n",
      "Epoch [1566/20000], Loss: 157.12701416015625, Entropy -174.2454833984375, Learning Rate: 0.01\n",
      "Epoch [1567/20000], Loss: 161.27499389648438, Entropy -185.86862182617188, Learning Rate: 0.01\n",
      "Epoch [1568/20000], Loss: 170.9497528076172, Entropy -189.43643188476562, Learning Rate: 0.01\n",
      "Epoch [1569/20000], Loss: 164.62625122070312, Entropy -184.28594970703125, Learning Rate: 0.01\n",
      "Epoch [1570/20000], Loss: 158.04344177246094, Entropy -162.7186737060547, Learning Rate: 0.01\n",
      "Epoch [1571/20000], Loss: 173.100830078125, Entropy -198.6113739013672, Learning Rate: 0.01\n",
      "Epoch [1572/20000], Loss: 154.90577697753906, Entropy -176.33241271972656, Learning Rate: 0.01\n",
      "Epoch [1573/20000], Loss: 164.09127807617188, Entropy -178.05288696289062, Learning Rate: 0.01\n",
      "Epoch [1574/20000], Loss: 161.60951232910156, Entropy -185.11737060546875, Learning Rate: 0.01\n",
      "Epoch [1575/20000], Loss: 164.40835571289062, Entropy -167.17007446289062, Learning Rate: 0.01\n",
      "Epoch [1576/20000], Loss: 175.4200897216797, Entropy -173.9718780517578, Learning Rate: 0.01\n",
      "Epoch [1577/20000], Loss: 165.61480712890625, Entropy -177.68011474609375, Learning Rate: 0.01\n",
      "Epoch [1578/20000], Loss: 163.85025024414062, Entropy -187.18821716308594, Learning Rate: 0.01\n",
      "Epoch [1579/20000], Loss: 155.53616333007812, Entropy -175.7328643798828, Learning Rate: 0.01\n",
      "Epoch [1580/20000], Loss: 158.04092407226562, Entropy -164.3226318359375, Learning Rate: 0.01\n",
      "Epoch [1581/20000], Loss: 157.7451934814453, Entropy -174.04052734375, Learning Rate: 0.01\n",
      "Epoch [1582/20000], Loss: 158.68817138671875, Entropy -183.10003662109375, Learning Rate: 0.01\n",
      "Epoch [1583/20000], Loss: 162.614501953125, Entropy -175.87384033203125, Learning Rate: 0.01\n",
      "Epoch [1584/20000], Loss: 176.96173095703125, Entropy -179.27554321289062, Learning Rate: 0.01\n",
      "Epoch [1585/20000], Loss: 162.1182098388672, Entropy -177.74462890625, Learning Rate: 0.01\n",
      "Epoch [1586/20000], Loss: 152.34263610839844, Entropy -184.89263916015625, Learning Rate: 0.01\n",
      "Epoch [1587/20000], Loss: 154.1249542236328, Entropy -166.5915985107422, Learning Rate: 0.01\n",
      "Epoch [1588/20000], Loss: 165.451416015625, Entropy -191.104736328125, Learning Rate: 0.01\n",
      "Epoch [1589/20000], Loss: 163.4656524658203, Entropy -186.0047607421875, Learning Rate: 0.01\n",
      "Epoch [1590/20000], Loss: 166.5595703125, Entropy -182.15406799316406, Learning Rate: 0.01\n",
      "Epoch [1591/20000], Loss: 156.60057067871094, Entropy -169.57080078125, Learning Rate: 0.01\n",
      "Epoch [1592/20000], Loss: 157.71231079101562, Entropy -183.2718505859375, Learning Rate: 0.01\n",
      "Epoch [1593/20000], Loss: 152.0225067138672, Entropy -176.21493530273438, Learning Rate: 0.01\n",
      "Epoch [1594/20000], Loss: 152.84315490722656, Entropy -175.7490692138672, Learning Rate: 0.01\n",
      "Epoch [1595/20000], Loss: 156.8336944580078, Entropy -178.25686645507812, Learning Rate: 0.01\n",
      "Epoch [1596/20000], Loss: 173.3324432373047, Entropy -182.20057678222656, Learning Rate: 0.01\n",
      "Epoch [1597/20000], Loss: 173.8914031982422, Entropy -192.746337890625, Learning Rate: 0.01\n",
      "Epoch [1598/20000], Loss: 146.76454162597656, Entropy -163.81936645507812, Learning Rate: 0.01\n",
      "Epoch [1599/20000], Loss: 157.46041870117188, Entropy -176.30874633789062, Learning Rate: 0.01\n",
      "Epoch [1600/20000], Loss: 153.10382080078125, Entropy -183.08248901367188, Learning Rate: 0.01\n",
      "Epoch [1601/20000], Loss: 147.91925048828125, Entropy -163.3926544189453, Learning Rate: 0.01\n",
      "Epoch [1602/20000], Loss: 143.5077362060547, Entropy -161.39498901367188, Learning Rate: 0.01\n",
      "Epoch [1603/20000], Loss: 155.69981384277344, Entropy -180.54171752929688, Learning Rate: 0.01\n",
      "Epoch [1604/20000], Loss: 159.54788208007812, Entropy -178.79461669921875, Learning Rate: 0.01\n",
      "Epoch [1605/20000], Loss: 157.81080627441406, Entropy -159.98304748535156, Learning Rate: 0.01\n",
      "Epoch [1606/20000], Loss: 164.46566772460938, Entropy -194.0653839111328, Learning Rate: 0.01\n",
      "Epoch [1607/20000], Loss: 152.47317504882812, Entropy -164.60888671875, Learning Rate: 0.01\n",
      "Epoch [1608/20000], Loss: 162.59945678710938, Entropy -172.55551147460938, Learning Rate: 0.01\n",
      "Epoch [1609/20000], Loss: 164.748779296875, Entropy -188.94882202148438, Learning Rate: 0.01\n",
      "Epoch [1610/20000], Loss: 154.39199829101562, Entropy -185.07611083984375, Learning Rate: 0.01\n",
      "Epoch [1611/20000], Loss: 153.3673858642578, Entropy -162.078125, Learning Rate: 0.01\n",
      "Epoch [1612/20000], Loss: 168.83810424804688, Entropy -191.35598754882812, Learning Rate: 0.01\n",
      "Epoch [1613/20000], Loss: 159.30331420898438, Entropy -177.94851684570312, Learning Rate: 0.01\n",
      "Epoch [1614/20000], Loss: 155.050048828125, Entropy -166.67034912109375, Learning Rate: 0.01\n",
      "Epoch [1615/20000], Loss: 158.89035034179688, Entropy -171.57998657226562, Learning Rate: 0.01\n",
      "Epoch [1616/20000], Loss: 145.76878356933594, Entropy -164.43685913085938, Learning Rate: 0.01\n",
      "Epoch [1617/20000], Loss: 160.44064331054688, Entropy -172.3483123779297, Learning Rate: 0.01\n",
      "Epoch [1618/20000], Loss: 160.43130493164062, Entropy -179.82923889160156, Learning Rate: 0.01\n",
      "Epoch [1619/20000], Loss: 149.3244171142578, Entropy -177.32962036132812, Learning Rate: 0.01\n",
      "Epoch [1620/20000], Loss: 160.35812377929688, Entropy -175.82884216308594, Learning Rate: 0.01\n",
      "Epoch [1621/20000], Loss: 159.75782775878906, Entropy -184.23355102539062, Learning Rate: 0.01\n",
      "Epoch [1622/20000], Loss: 152.89920043945312, Entropy -171.44033813476562, Learning Rate: 0.01\n",
      "Epoch [1623/20000], Loss: 149.63624572753906, Entropy -165.64598083496094, Learning Rate: 0.01\n",
      "Epoch [1624/20000], Loss: 164.05630493164062, Entropy -177.61175537109375, Learning Rate: 0.01\n",
      "Epoch [1625/20000], Loss: 156.6432647705078, Entropy -173.660400390625, Learning Rate: 0.01\n",
      "Epoch [1626/20000], Loss: 153.2751922607422, Entropy -175.35647583007812, Learning Rate: 0.01\n",
      "Epoch [1627/20000], Loss: 171.19029235839844, Entropy -191.0894012451172, Learning Rate: 0.01\n",
      "Epoch [1628/20000], Loss: 153.4601287841797, Entropy -167.29571533203125, Learning Rate: 0.01\n",
      "Epoch [1629/20000], Loss: 160.75244140625, Entropy -170.482666015625, Learning Rate: 0.01\n",
      "Epoch [1630/20000], Loss: 185.6593780517578, Entropy -193.77664184570312, Learning Rate: 0.01\n",
      "Epoch [1631/20000], Loss: 146.8674774169922, Entropy -170.92483520507812, Learning Rate: 0.01\n",
      "Epoch [1632/20000], Loss: 162.323486328125, Entropy -180.30752563476562, Learning Rate: 0.01\n",
      "Epoch [1633/20000], Loss: 168.23611450195312, Entropy -186.06704711914062, Learning Rate: 0.01\n",
      "Epoch [1634/20000], Loss: 151.564453125, Entropy -162.8474884033203, Learning Rate: 0.01\n",
      "Epoch [1635/20000], Loss: 165.826904296875, Entropy -188.43214416503906, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1636/20000], Loss: 158.5450439453125, Entropy -168.73580932617188, Learning Rate: 0.01\n",
      "Epoch [1637/20000], Loss: 165.52166748046875, Entropy -169.98411560058594, Learning Rate: 0.01\n",
      "Epoch [1638/20000], Loss: 152.49734497070312, Entropy -162.70828247070312, Learning Rate: 0.01\n",
      "Epoch [1639/20000], Loss: 168.30894470214844, Entropy -191.87904357910156, Learning Rate: 0.01\n",
      "Epoch [1640/20000], Loss: 170.0406494140625, Entropy -169.76760864257812, Learning Rate: 0.01\n",
      "Epoch [1641/20000], Loss: 168.36293029785156, Entropy -175.10067749023438, Learning Rate: 0.01\n",
      "Epoch [1642/20000], Loss: 160.3864288330078, Entropy -174.60382080078125, Learning Rate: 0.01\n",
      "Epoch [1643/20000], Loss: 165.3563232421875, Entropy -182.21035766601562, Learning Rate: 0.01\n",
      "Epoch [1644/20000], Loss: 179.93386840820312, Entropy -186.37574768066406, Learning Rate: 0.01\n",
      "Epoch [1645/20000], Loss: 161.0172119140625, Entropy -168.373291015625, Learning Rate: 0.01\n",
      "Epoch [1646/20000], Loss: 146.5431671142578, Entropy -168.60684204101562, Learning Rate: 0.01\n",
      "Epoch [1647/20000], Loss: 158.08583068847656, Entropy -169.07659912109375, Learning Rate: 0.01\n",
      "Epoch [1648/20000], Loss: 155.95449829101562, Entropy -179.239990234375, Learning Rate: 0.01\n",
      "Epoch [1649/20000], Loss: 160.0009002685547, Entropy -183.2820281982422, Learning Rate: 0.01\n",
      "Epoch [1650/20000], Loss: 166.1572723388672, Entropy -182.37493896484375, Learning Rate: 0.01\n",
      "Epoch [1651/20000], Loss: 161.29052734375, Entropy -168.35089111328125, Learning Rate: 0.01\n",
      "Epoch [1652/20000], Loss: 169.70407104492188, Entropy -188.07603454589844, Learning Rate: 0.01\n",
      "Epoch [1653/20000], Loss: 154.64633178710938, Entropy -174.58860778808594, Learning Rate: 0.01\n",
      "Epoch [1654/20000], Loss: 149.05691528320312, Entropy -164.24517822265625, Learning Rate: 0.01\n",
      "Epoch [1655/20000], Loss: 163.0552215576172, Entropy -186.10475158691406, Learning Rate: 0.01\n",
      "Epoch [1656/20000], Loss: 163.8355712890625, Entropy -169.57693481445312, Learning Rate: 0.01\n",
      "Epoch [1657/20000], Loss: 160.49337768554688, Entropy -183.536376953125, Learning Rate: 0.01\n",
      "Epoch [1658/20000], Loss: 151.56280517578125, Entropy -160.97012329101562, Learning Rate: 0.01\n",
      "Epoch [1659/20000], Loss: 152.89161682128906, Entropy -164.97921752929688, Learning Rate: 0.01\n",
      "Epoch [1660/20000], Loss: 170.33815002441406, Entropy -175.12318420410156, Learning Rate: 0.01\n",
      "Epoch [1661/20000], Loss: 149.8606719970703, Entropy -162.2044219970703, Learning Rate: 0.01\n",
      "Epoch [1662/20000], Loss: 159.70993041992188, Entropy -169.34109497070312, Learning Rate: 0.01\n",
      "Epoch [1663/20000], Loss: 159.25428771972656, Entropy -174.87269592285156, Learning Rate: 0.01\n",
      "Epoch [1664/20000], Loss: 156.18017578125, Entropy -168.1629638671875, Learning Rate: 0.01\n",
      "Epoch [1665/20000], Loss: 155.75975036621094, Entropy -177.6962432861328, Learning Rate: 0.01\n",
      "Epoch [1666/20000], Loss: 160.34242248535156, Entropy -183.44671630859375, Learning Rate: 0.01\n",
      "Epoch [1667/20000], Loss: 170.8228759765625, Entropy -194.77877807617188, Learning Rate: 0.01\n",
      "Epoch [1668/20000], Loss: 160.63320922851562, Entropy -168.7261505126953, Learning Rate: 0.01\n",
      "Epoch [1669/20000], Loss: 173.42514038085938, Entropy -177.72193908691406, Learning Rate: 0.01\n",
      "Epoch [1670/20000], Loss: 162.00816345214844, Entropy -180.99215698242188, Learning Rate: 0.01\n",
      "Epoch [1671/20000], Loss: 161.8718719482422, Entropy -183.58421325683594, Learning Rate: 0.01\n",
      "Epoch [1672/20000], Loss: 167.1061248779297, Entropy -178.0513916015625, Learning Rate: 0.01\n",
      "Epoch [1673/20000], Loss: 160.04185485839844, Entropy -186.8016357421875, Learning Rate: 0.01\n",
      "Epoch [1674/20000], Loss: 162.62802124023438, Entropy -181.4156951904297, Learning Rate: 0.01\n",
      "Epoch [1675/20000], Loss: 157.0249481201172, Entropy -160.4825439453125, Learning Rate: 0.01\n",
      "Epoch [1676/20000], Loss: 165.20950317382812, Entropy -175.92074584960938, Learning Rate: 0.01\n",
      "Epoch [1677/20000], Loss: 155.37489318847656, Entropy -172.66836547851562, Learning Rate: 0.01\n",
      "Epoch [1678/20000], Loss: 163.69699096679688, Entropy -181.2866973876953, Learning Rate: 0.01\n",
      "Epoch [1679/20000], Loss: 169.695068359375, Entropy -174.04888916015625, Learning Rate: 0.01\n",
      "Epoch [1680/20000], Loss: 171.87600708007812, Entropy -191.18077087402344, Learning Rate: 0.01\n",
      "Epoch [1681/20000], Loss: 152.56301879882812, Entropy -161.979248046875, Learning Rate: 0.01\n",
      "Epoch [1682/20000], Loss: 166.2084503173828, Entropy -181.07345581054688, Learning Rate: 0.01\n",
      "Epoch [1683/20000], Loss: 152.32504272460938, Entropy -168.97933959960938, Learning Rate: 0.01\n",
      "Epoch [1684/20000], Loss: 151.77708435058594, Entropy -153.75613403320312, Learning Rate: 0.01\n",
      "Epoch [1685/20000], Loss: 147.53431701660156, Entropy -157.57101440429688, Learning Rate: 0.01\n",
      "Epoch [1686/20000], Loss: 160.79248046875, Entropy -174.19752502441406, Learning Rate: 0.01\n",
      "Epoch [1687/20000], Loss: 161.14944458007812, Entropy -157.12742614746094, Learning Rate: 0.01\n",
      "Epoch [1688/20000], Loss: 154.0579071044922, Entropy -165.92263793945312, Learning Rate: 0.01\n",
      "Epoch [1689/20000], Loss: 157.89158630371094, Entropy -166.1578826904297, Learning Rate: 0.01\n",
      "Epoch [1690/20000], Loss: 171.41815185546875, Entropy -180.55201721191406, Learning Rate: 0.01\n",
      "Epoch [1691/20000], Loss: 161.3555908203125, Entropy -172.64370727539062, Learning Rate: 0.01\n",
      "Epoch [1692/20000], Loss: 148.4436798095703, Entropy -165.64816284179688, Learning Rate: 0.01\n",
      "Epoch [1693/20000], Loss: 158.87632751464844, Entropy -175.30494689941406, Learning Rate: 0.01\n",
      "Epoch [1694/20000], Loss: 189.23284912109375, Entropy -180.10476684570312, Learning Rate: 0.01\n",
      "Epoch [1695/20000], Loss: 179.20509338378906, Entropy -167.2511444091797, Learning Rate: 0.01\n",
      "Epoch [1696/20000], Loss: 198.76272583007812, Entropy -197.2962188720703, Learning Rate: 0.01\n",
      "Epoch [1697/20000], Loss: 154.29656982421875, Entropy -165.71327209472656, Learning Rate: 0.01\n",
      "Epoch [1698/20000], Loss: 171.49386596679688, Entropy -152.54122924804688, Learning Rate: 0.01\n",
      "Epoch [1699/20000], Loss: 176.31927490234375, Entropy -164.4049072265625, Learning Rate: 0.01\n",
      "Epoch [1700/20000], Loss: 174.23126220703125, Entropy -162.77947998046875, Learning Rate: 0.01\n",
      "Epoch [1701/20000], Loss: 188.5918426513672, Entropy -177.41714477539062, Learning Rate: 0.01\n",
      "Epoch [1702/20000], Loss: 191.5499725341797, Entropy -165.92715454101562, Learning Rate: 0.01\n",
      "Epoch [1703/20000], Loss: 173.09149169921875, Entropy -166.11175537109375, Learning Rate: 0.01\n",
      "Epoch [1704/20000], Loss: 182.46412658691406, Entropy -179.01869201660156, Learning Rate: 0.01\n",
      "Epoch [1705/20000], Loss: 246.23291015625, Entropy -172.10296630859375, Learning Rate: 0.01\n",
      "Epoch [1706/20000], Loss: 220.95013427734375, Entropy -163.08999633789062, Learning Rate: 0.01\n",
      "Epoch [1707/20000], Loss: 170.16847229003906, Entropy -188.37716674804688, Learning Rate: 0.01\n",
      "Epoch [1708/20000], Loss: 188.90614318847656, Entropy -177.81228637695312, Learning Rate: 0.01\n",
      "Epoch [1709/20000], Loss: 190.72442626953125, Entropy -156.8457489013672, Learning Rate: 0.01\n",
      "Epoch [1710/20000], Loss: 169.17420959472656, Entropy -175.48336791992188, Learning Rate: 0.01\n",
      "Epoch [1711/20000], Loss: 160.03700256347656, Entropy -160.60238647460938, Learning Rate: 0.01\n",
      "Epoch [1712/20000], Loss: 158.32398986816406, Entropy -155.19329833984375, Learning Rate: 0.01\n",
      "Epoch [1713/20000], Loss: 165.08163452148438, Entropy -169.09310913085938, Learning Rate: 0.01\n",
      "Epoch [1714/20000], Loss: 160.7493438720703, Entropy -173.33505249023438, Learning Rate: 0.01\n",
      "Epoch [1715/20000], Loss: 159.73287963867188, Entropy -169.90866088867188, Learning Rate: 0.01\n",
      "Epoch [1716/20000], Loss: 163.8369598388672, Entropy -160.28353881835938, Learning Rate: 0.01\n",
      "Epoch [1717/20000], Loss: 178.6470947265625, Entropy -186.35784912109375, Learning Rate: 0.01\n",
      "Epoch [1718/20000], Loss: 181.81069946289062, Entropy -172.619140625, Learning Rate: 0.01\n",
      "Epoch [1719/20000], Loss: 171.32911682128906, Entropy -163.97457885742188, Learning Rate: 0.01\n",
      "Epoch [1720/20000], Loss: 173.29598999023438, Entropy -158.73516845703125, Learning Rate: 0.01\n",
      "Epoch [1721/20000], Loss: 196.46450805664062, Entropy -163.98065185546875, Learning Rate: 0.01\n",
      "Epoch [1722/20000], Loss: 181.5498809814453, Entropy -166.8876495361328, Learning Rate: 0.01\n",
      "Epoch [1723/20000], Loss: 226.36724853515625, Entropy -175.50445556640625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1724/20000], Loss: 242.39971923828125, Entropy -170.03904724121094, Learning Rate: 0.01\n",
      "Epoch [1725/20000], Loss: 212.67933654785156, Entropy -192.76028442382812, Learning Rate: 0.01\n",
      "Epoch [1726/20000], Loss: 218.92137145996094, Entropy -177.16714477539062, Learning Rate: 0.01\n",
      "Epoch [1727/20000], Loss: 230.85809326171875, Entropy -171.41241455078125, Learning Rate: 0.01\n",
      "Epoch [1728/20000], Loss: 187.87022399902344, Entropy -148.59127807617188, Learning Rate: 0.01\n",
      "Epoch [1729/20000], Loss: 186.90884399414062, Entropy -157.68167114257812, Learning Rate: 0.01\n",
      "Epoch [1730/20000], Loss: 186.69334411621094, Entropy -181.0009765625, Learning Rate: 0.01\n",
      "Epoch [1731/20000], Loss: 195.42434692382812, Entropy -162.71826171875, Learning Rate: 0.01\n",
      "Epoch [1732/20000], Loss: 178.20814514160156, Entropy -178.82931518554688, Learning Rate: 0.01\n",
      "Epoch [1733/20000], Loss: 171.22035217285156, Entropy -183.42771911621094, Learning Rate: 0.01\n",
      "Epoch [1734/20000], Loss: 190.0833282470703, Entropy -162.73617553710938, Learning Rate: 0.01\n",
      "Epoch [1735/20000], Loss: 161.3573455810547, Entropy -162.4133758544922, Learning Rate: 0.01\n",
      "Epoch [1736/20000], Loss: 163.31544494628906, Entropy -156.1861572265625, Learning Rate: 0.01\n",
      "Epoch [1737/20000], Loss: 206.50070190429688, Entropy -153.12332153320312, Learning Rate: 0.01\n",
      "Epoch [1738/20000], Loss: 162.45437622070312, Entropy -172.314697265625, Learning Rate: 0.01\n",
      "Epoch [1739/20000], Loss: 172.35519409179688, Entropy -176.58084106445312, Learning Rate: 0.01\n",
      "Epoch [1740/20000], Loss: 193.1910400390625, Entropy -173.43869018554688, Learning Rate: 0.01\n",
      "Epoch [1741/20000], Loss: 156.95127868652344, Entropy -172.27345275878906, Learning Rate: 0.01\n",
      "Epoch [1742/20000], Loss: 274.2726135253906, Entropy -171.31822204589844, Learning Rate: 0.01\n",
      "Epoch [1743/20000], Loss: 188.99412536621094, Entropy -159.66433715820312, Learning Rate: 0.01\n",
      "Epoch [1744/20000], Loss: 190.94618225097656, Entropy -172.3311767578125, Learning Rate: 0.01\n",
      "Epoch [1745/20000], Loss: 201.71685791015625, Entropy -165.3697509765625, Learning Rate: 0.01\n",
      "Epoch [1746/20000], Loss: 230.25778198242188, Entropy -175.69802856445312, Learning Rate: 0.01\n",
      "Epoch [1747/20000], Loss: 231.7251739501953, Entropy -170.10076904296875, Learning Rate: 0.01\n",
      "Epoch [1748/20000], Loss: 216.90426635742188, Entropy -175.53231811523438, Learning Rate: 0.01\n",
      "Epoch [1749/20000], Loss: 200.1895294189453, Entropy -184.81057739257812, Learning Rate: 0.01\n",
      "Epoch [1750/20000], Loss: 228.6078338623047, Entropy -171.86419677734375, Learning Rate: 0.01\n",
      "Epoch [1751/20000], Loss: 285.643310546875, Entropy -184.56434631347656, Learning Rate: 0.01\n",
      "Epoch [1752/20000], Loss: 315.34124755859375, Entropy -158.79586791992188, Learning Rate: 0.01\n",
      "Epoch [1753/20000], Loss: 285.0646667480469, Entropy -158.6478271484375, Learning Rate: 0.01\n",
      "Epoch [1754/20000], Loss: 258.1340637207031, Entropy -178.3031005859375, Learning Rate: 0.01\n",
      "Epoch [1755/20000], Loss: 232.70443725585938, Entropy -166.67340087890625, Learning Rate: 0.01\n",
      "Epoch [1756/20000], Loss: 233.70870971679688, Entropy -168.66009521484375, Learning Rate: 0.01\n",
      "Epoch [1757/20000], Loss: 238.86825561523438, Entropy -162.98934936523438, Learning Rate: 0.01\n",
      "Epoch [1758/20000], Loss: 236.81179809570312, Entropy -161.67767333984375, Learning Rate: 0.01\n",
      "Epoch [1759/20000], Loss: 235.00149536132812, Entropy -163.38735961914062, Learning Rate: 0.01\n",
      "Epoch [1760/20000], Loss: 244.8563995361328, Entropy -161.16278076171875, Learning Rate: 0.01\n",
      "Epoch [1761/20000], Loss: 202.90689086914062, Entropy -172.28607177734375, Learning Rate: 0.01\n",
      "Epoch [1762/20000], Loss: 211.813720703125, Entropy -164.0167236328125, Learning Rate: 0.01\n",
      "Epoch [1763/20000], Loss: 196.51673889160156, Entropy -160.49160766601562, Learning Rate: 0.01\n",
      "Epoch [1764/20000], Loss: 174.90859985351562, Entropy -164.42819213867188, Learning Rate: 0.01\n",
      "Epoch [1765/20000], Loss: 187.74880981445312, Entropy -181.3319549560547, Learning Rate: 0.01\n",
      "Epoch [1766/20000], Loss: 196.7751007080078, Entropy -178.74569702148438, Learning Rate: 0.01\n",
      "Epoch [1767/20000], Loss: 170.04019165039062, Entropy -178.85205078125, Learning Rate: 0.01\n",
      "Epoch [1768/20000], Loss: 211.90032958984375, Entropy -187.0865936279297, Learning Rate: 0.01\n",
      "Epoch [1769/20000], Loss: 185.05352783203125, Entropy -180.0771942138672, Learning Rate: 0.01\n",
      "Epoch [1770/20000], Loss: 160.61891174316406, Entropy -166.80181884765625, Learning Rate: 0.01\n",
      "Epoch [1771/20000], Loss: 190.90939331054688, Entropy -185.79461669921875, Learning Rate: 0.01\n",
      "Epoch [1772/20000], Loss: 190.3085479736328, Entropy -185.4042510986328, Learning Rate: 0.01\n",
      "Epoch [1773/20000], Loss: 213.0900115966797, Entropy -180.06500244140625, Learning Rate: 0.01\n",
      "Epoch [1774/20000], Loss: 221.09536743164062, Entropy -177.30694580078125, Learning Rate: 0.01\n",
      "Epoch [1775/20000], Loss: 175.44778442382812, Entropy -167.757080078125, Learning Rate: 0.01\n",
      "Epoch [1776/20000], Loss: 229.9801025390625, Entropy -162.81790161132812, Learning Rate: 0.01\n",
      "Epoch [1777/20000], Loss: 235.5342559814453, Entropy -169.97325134277344, Learning Rate: 0.01\n",
      "Epoch [1778/20000], Loss: 163.34210205078125, Entropy -168.607666015625, Learning Rate: 0.01\n",
      "Epoch [1779/20000], Loss: 206.4483642578125, Entropy -156.59597778320312, Learning Rate: 0.01\n",
      "Epoch [1780/20000], Loss: 191.4005126953125, Entropy -160.96090698242188, Learning Rate: 0.01\n",
      "Epoch [1781/20000], Loss: 179.9073028564453, Entropy -156.51438903808594, Learning Rate: 0.01\n",
      "Epoch [1782/20000], Loss: 163.0607147216797, Entropy -156.09918212890625, Learning Rate: 0.01\n",
      "Epoch [1783/20000], Loss: 159.7416229248047, Entropy -170.2556610107422, Learning Rate: 0.01\n",
      "Epoch [1784/20000], Loss: 177.31759643554688, Entropy -167.3508758544922, Learning Rate: 0.01\n",
      "Epoch [1785/20000], Loss: 173.1159210205078, Entropy -167.30441284179688, Learning Rate: 0.01\n",
      "Epoch [1786/20000], Loss: 171.0155029296875, Entropy -179.84725952148438, Learning Rate: 0.01\n",
      "Epoch [1787/20000], Loss: 159.09051513671875, Entropy -165.5171661376953, Learning Rate: 0.01\n",
      "Epoch [1788/20000], Loss: 179.55152893066406, Entropy -185.63174438476562, Learning Rate: 0.01\n",
      "Epoch [1789/20000], Loss: 159.7915802001953, Entropy -173.34852600097656, Learning Rate: 0.01\n",
      "Epoch [1790/20000], Loss: 164.0839385986328, Entropy -165.29241943359375, Learning Rate: 0.01\n",
      "Epoch [1791/20000], Loss: 157.211669921875, Entropy -171.50210571289062, Learning Rate: 0.01\n",
      "Epoch [1792/20000], Loss: 151.25872802734375, Entropy -163.50830078125, Learning Rate: 0.01\n",
      "Epoch [1793/20000], Loss: 155.5606689453125, Entropy -163.86581420898438, Learning Rate: 0.01\n",
      "Epoch [1794/20000], Loss: 159.8785858154297, Entropy -173.84754943847656, Learning Rate: 0.01\n",
      "Epoch [1795/20000], Loss: 146.41058349609375, Entropy -154.55313110351562, Learning Rate: 0.01\n",
      "Epoch [1796/20000], Loss: 156.1998748779297, Entropy -177.40231323242188, Learning Rate: 0.01\n",
      "Epoch [1797/20000], Loss: 155.4487762451172, Entropy -171.80661010742188, Learning Rate: 0.01\n",
      "Epoch [1798/20000], Loss: 169.4388427734375, Entropy -184.15869140625, Learning Rate: 0.01\n",
      "Epoch [1799/20000], Loss: 145.17388916015625, Entropy -164.63966369628906, Learning Rate: 0.01\n",
      "Epoch [1800/20000], Loss: 155.00433349609375, Entropy -167.80743408203125, Learning Rate: 0.01\n",
      "Epoch [1801/20000], Loss: 148.57447814941406, Entropy -169.14599609375, Learning Rate: 0.01\n",
      "Epoch [1802/20000], Loss: 144.9586639404297, Entropy -163.34605407714844, Learning Rate: 0.01\n",
      "Epoch [1803/20000], Loss: 147.97845458984375, Entropy -166.85035705566406, Learning Rate: 0.01\n",
      "Epoch [1804/20000], Loss: 142.51963806152344, Entropy -163.63363647460938, Learning Rate: 0.005\n",
      "Epoch [1805/20000], Loss: 160.2810516357422, Entropy -190.7314453125, Learning Rate: 0.005\n",
      "Epoch [1806/20000], Loss: 152.24899291992188, Entropy -181.25941467285156, Learning Rate: 0.005\n",
      "Epoch [1807/20000], Loss: 146.8213653564453, Entropy -167.35372924804688, Learning Rate: 0.005\n",
      "Epoch [1808/20000], Loss: 149.1513671875, Entropy -168.39324951171875, Learning Rate: 0.005\n",
      "Epoch [1809/20000], Loss: 145.4551544189453, Entropy -173.82882690429688, Learning Rate: 0.005\n",
      "Epoch [1810/20000], Loss: 146.69369506835938, Entropy -165.94082641601562, Learning Rate: 0.005\n",
      "Epoch [1811/20000], Loss: 144.9015350341797, Entropy -165.4517364501953, Learning Rate: 0.005\n",
      "Epoch [1812/20000], Loss: 147.80520629882812, Entropy -174.39480590820312, Learning Rate: 0.005\n",
      "Epoch [1813/20000], Loss: 139.4136962890625, Entropy -163.31048583984375, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1814/20000], Loss: 158.9794158935547, Entropy -184.32391357421875, Learning Rate: 0.005\n",
      "Epoch [1815/20000], Loss: 152.63858032226562, Entropy -163.3568115234375, Learning Rate: 0.005\n",
      "Epoch [1816/20000], Loss: 141.4870147705078, Entropy -170.70838928222656, Learning Rate: 0.005\n",
      "Epoch [1817/20000], Loss: 150.50050354003906, Entropy -173.0965118408203, Learning Rate: 0.005\n",
      "Epoch [1818/20000], Loss: 141.58212280273438, Entropy -163.18228149414062, Learning Rate: 0.005\n",
      "Epoch [1819/20000], Loss: 141.44979858398438, Entropy -161.64892578125, Learning Rate: 0.005\n",
      "Epoch [1820/20000], Loss: 146.7516326904297, Entropy -171.46121215820312, Learning Rate: 0.005\n",
      "Epoch [1821/20000], Loss: 149.58653259277344, Entropy -175.06060791015625, Learning Rate: 0.005\n",
      "Epoch [1822/20000], Loss: 155.39671325683594, Entropy -176.79220581054688, Learning Rate: 0.005\n",
      "Epoch [1823/20000], Loss: 144.1417694091797, Entropy -162.20623779296875, Learning Rate: 0.005\n",
      "Epoch [1824/20000], Loss: 145.45950317382812, Entropy -168.30825805664062, Learning Rate: 0.005\n",
      "Epoch [1825/20000], Loss: 149.55308532714844, Entropy -171.21697998046875, Learning Rate: 0.005\n",
      "Epoch [1826/20000], Loss: 155.65383911132812, Entropy -179.31338500976562, Learning Rate: 0.005\n",
      "Epoch [1827/20000], Loss: 137.91796875, Entropy -158.30679321289062, Learning Rate: 0.005\n",
      "Epoch [1828/20000], Loss: 143.60873413085938, Entropy -166.48880004882812, Learning Rate: 0.005\n",
      "Epoch [1829/20000], Loss: 154.57177734375, Entropy -177.2391815185547, Learning Rate: 0.005\n",
      "Epoch [1830/20000], Loss: 152.30410766601562, Entropy -179.3980712890625, Learning Rate: 0.005\n",
      "Epoch [1831/20000], Loss: 142.74530029296875, Entropy -157.7769775390625, Learning Rate: 0.005\n",
      "Epoch [1832/20000], Loss: 148.5604705810547, Entropy -173.88555908203125, Learning Rate: 0.005\n",
      "Epoch [1833/20000], Loss: 149.20455932617188, Entropy -171.09375, Learning Rate: 0.005\n",
      "Epoch [1834/20000], Loss: 143.5252227783203, Entropy -166.90762329101562, Learning Rate: 0.005\n",
      "Epoch [1835/20000], Loss: 150.8212432861328, Entropy -176.01300048828125, Learning Rate: 0.005\n",
      "Epoch [1836/20000], Loss: 130.13426208496094, Entropy -151.666015625, Learning Rate: 0.005\n",
      "Epoch [1837/20000], Loss: 145.4997100830078, Entropy -166.97216796875, Learning Rate: 0.005\n",
      "Epoch [1838/20000], Loss: 140.0686492919922, Entropy -168.19549560546875, Learning Rate: 0.005\n",
      "Epoch [1839/20000], Loss: 153.62338256835938, Entropy -174.18576049804688, Learning Rate: 0.005\n",
      "Epoch [1840/20000], Loss: 149.15638732910156, Entropy -172.4747772216797, Learning Rate: 0.005\n",
      "Epoch [1841/20000], Loss: 149.66160583496094, Entropy -171.36456298828125, Learning Rate: 0.005\n",
      "Epoch [1842/20000], Loss: 153.53656005859375, Entropy -181.89112854003906, Learning Rate: 0.005\n",
      "Epoch [1843/20000], Loss: 144.86166381835938, Entropy -170.33604431152344, Learning Rate: 0.005\n",
      "Epoch [1844/20000], Loss: 141.01194763183594, Entropy -162.6746826171875, Learning Rate: 0.005\n",
      "Epoch [1845/20000], Loss: 145.64801025390625, Entropy -166.21319580078125, Learning Rate: 0.005\n",
      "Epoch [1846/20000], Loss: 131.598876953125, Entropy -155.32431030273438, Learning Rate: 0.005\n",
      "Epoch [1847/20000], Loss: 138.46853637695312, Entropy -164.35525512695312, Learning Rate: 0.005\n",
      "Epoch [1848/20000], Loss: 142.10647583007812, Entropy -165.56158447265625, Learning Rate: 0.005\n",
      "Epoch [1849/20000], Loss: 156.0123748779297, Entropy -190.20584106445312, Learning Rate: 0.005\n",
      "Epoch [1850/20000], Loss: 140.17581176757812, Entropy -167.07293701171875, Learning Rate: 0.005\n",
      "Epoch [1851/20000], Loss: 143.00527954101562, Entropy -168.6064453125, Learning Rate: 0.005\n",
      "Epoch [1852/20000], Loss: 135.94229125976562, Entropy -149.29595947265625, Learning Rate: 0.005\n",
      "Epoch [1853/20000], Loss: 161.8452911376953, Entropy -193.0467987060547, Learning Rate: 0.005\n",
      "Epoch [1854/20000], Loss: 144.9483642578125, Entropy -169.34593200683594, Learning Rate: 0.005\n",
      "Epoch [1855/20000], Loss: 149.452880859375, Entropy -179.7559814453125, Learning Rate: 0.005\n",
      "Epoch [1856/20000], Loss: 144.83987426757812, Entropy -173.990478515625, Learning Rate: 0.005\n",
      "Epoch [1857/20000], Loss: 141.00961303710938, Entropy -158.99325561523438, Learning Rate: 0.005\n",
      "Epoch [1858/20000], Loss: 144.12081909179688, Entropy -171.4261474609375, Learning Rate: 0.005\n",
      "Epoch [1859/20000], Loss: 141.6425323486328, Entropy -168.0961456298828, Learning Rate: 0.005\n",
      "Epoch [1860/20000], Loss: 137.38519287109375, Entropy -156.62091064453125, Learning Rate: 0.005\n",
      "Epoch [1861/20000], Loss: 152.8626251220703, Entropy -171.0116729736328, Learning Rate: 0.005\n",
      "Epoch [1862/20000], Loss: 155.70260620117188, Entropy -190.08651733398438, Learning Rate: 0.005\n",
      "Epoch [1863/20000], Loss: 151.22897338867188, Entropy -166.3406982421875, Learning Rate: 0.005\n",
      "Epoch [1864/20000], Loss: 141.12591552734375, Entropy -162.3453369140625, Learning Rate: 0.005\n",
      "Epoch [1865/20000], Loss: 143.9076690673828, Entropy -167.1456298828125, Learning Rate: 0.005\n",
      "Epoch [1866/20000], Loss: 150.599609375, Entropy -177.47711181640625, Learning Rate: 0.005\n",
      "Epoch [1867/20000], Loss: 144.1967315673828, Entropy -157.43267822265625, Learning Rate: 0.005\n",
      "Epoch [1868/20000], Loss: 152.38192749023438, Entropy -171.01937866210938, Learning Rate: 0.005\n",
      "Epoch [1869/20000], Loss: 137.68455505371094, Entropy -158.8660888671875, Learning Rate: 0.005\n",
      "Epoch [1870/20000], Loss: 133.96694946289062, Entropy -148.63095092773438, Learning Rate: 0.005\n",
      "Epoch [1871/20000], Loss: 145.84568786621094, Entropy -172.11341857910156, Learning Rate: 0.005\n",
      "Epoch [1872/20000], Loss: 146.7769775390625, Entropy -164.93226623535156, Learning Rate: 0.005\n",
      "Epoch [1873/20000], Loss: 138.70120239257812, Entropy -161.7578582763672, Learning Rate: 0.005\n",
      "Epoch [1874/20000], Loss: 171.8392791748047, Entropy -200.99961853027344, Learning Rate: 0.005\n",
      "Epoch [1875/20000], Loss: 139.11900329589844, Entropy -160.08995056152344, Learning Rate: 0.005\n",
      "Epoch [1876/20000], Loss: 146.96058654785156, Entropy -170.92178344726562, Learning Rate: 0.005\n",
      "Epoch [1877/20000], Loss: 149.78536987304688, Entropy -176.29708862304688, Learning Rate: 0.005\n",
      "Epoch [1878/20000], Loss: 133.9478302001953, Entropy -153.03652954101562, Learning Rate: 0.005\n",
      "Epoch [1879/20000], Loss: 146.9654083251953, Entropy -162.26104736328125, Learning Rate: 0.005\n",
      "Epoch [1880/20000], Loss: 142.29408264160156, Entropy -157.27734375, Learning Rate: 0.005\n",
      "Epoch [1881/20000], Loss: 152.8365478515625, Entropy -172.76080322265625, Learning Rate: 0.005\n",
      "Epoch [1882/20000], Loss: 151.54083251953125, Entropy -167.79486083984375, Learning Rate: 0.005\n",
      "Epoch [1883/20000], Loss: 149.3656005859375, Entropy -171.78758239746094, Learning Rate: 0.005\n",
      "Epoch [1884/20000], Loss: 138.3897247314453, Entropy -164.64398193359375, Learning Rate: 0.005\n",
      "Epoch [1885/20000], Loss: 143.94552612304688, Entropy -161.4219512939453, Learning Rate: 0.005\n",
      "Epoch [1886/20000], Loss: 143.87210083007812, Entropy -164.70367431640625, Learning Rate: 0.005\n",
      "Epoch [1887/20000], Loss: 145.42730712890625, Entropy -168.31060791015625, Learning Rate: 0.005\n",
      "Epoch [1888/20000], Loss: 150.4729461669922, Entropy -173.1674346923828, Learning Rate: 0.005\n",
      "Epoch [1889/20000], Loss: 148.95579528808594, Entropy -171.73782348632812, Learning Rate: 0.005\n",
      "Epoch [1890/20000], Loss: 138.29383850097656, Entropy -156.67481994628906, Learning Rate: 0.005\n",
      "Epoch [1891/20000], Loss: 151.25086975097656, Entropy -175.4673614501953, Learning Rate: 0.005\n",
      "Epoch [1892/20000], Loss: 152.0458221435547, Entropy -181.0390625, Learning Rate: 0.005\n",
      "Epoch [1893/20000], Loss: 139.85670471191406, Entropy -166.59329223632812, Learning Rate: 0.005\n",
      "Epoch [1894/20000], Loss: 145.96560668945312, Entropy -166.71165466308594, Learning Rate: 0.005\n",
      "Epoch [1895/20000], Loss: 140.2509002685547, Entropy -168.71157836914062, Learning Rate: 0.005\n",
      "Epoch [1896/20000], Loss: 146.7462158203125, Entropy -166.9659423828125, Learning Rate: 0.005\n",
      "Epoch [1897/20000], Loss: 152.03663635253906, Entropy -173.63839721679688, Learning Rate: 0.005\n",
      "Epoch [1898/20000], Loss: 146.0208740234375, Entropy -174.76904296875, Learning Rate: 0.005\n",
      "Epoch [1899/20000], Loss: 134.2224884033203, Entropy -157.19369506835938, Learning Rate: 0.005\n",
      "Epoch [1900/20000], Loss: 142.59756469726562, Entropy -172.03372192382812, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1901/20000], Loss: 145.872802734375, Entropy -166.75804138183594, Learning Rate: 0.005\n",
      "Epoch [1902/20000], Loss: 150.63031005859375, Entropy -168.62945556640625, Learning Rate: 0.005\n",
      "Epoch [1903/20000], Loss: 137.16732788085938, Entropy -155.31546020507812, Learning Rate: 0.005\n",
      "Epoch [1904/20000], Loss: 143.71478271484375, Entropy -163.34466552734375, Learning Rate: 0.005\n",
      "Epoch [1905/20000], Loss: 140.52708435058594, Entropy -157.81558227539062, Learning Rate: 0.005\n",
      "Epoch [1906/20000], Loss: 136.17633056640625, Entropy -160.24520874023438, Learning Rate: 0.005\n",
      "Epoch [1907/20000], Loss: 145.33670043945312, Entropy -166.06613159179688, Learning Rate: 0.005\n",
      "Epoch [1908/20000], Loss: 154.4770050048828, Entropy -180.88128662109375, Learning Rate: 0.005\n",
      "Epoch [1909/20000], Loss: 134.3040313720703, Entropy -161.92129516601562, Learning Rate: 0.005\n",
      "Epoch [1910/20000], Loss: 164.0104522705078, Entropy -154.68307495117188, Learning Rate: 0.005\n",
      "Epoch [1911/20000], Loss: 131.2872314453125, Entropy -146.648193359375, Learning Rate: 0.005\n",
      "Epoch [1912/20000], Loss: 141.99490356445312, Entropy -162.63284301757812, Learning Rate: 0.005\n",
      "Epoch [1913/20000], Loss: 146.97616577148438, Entropy -156.85214233398438, Learning Rate: 0.005\n",
      "Epoch [1914/20000], Loss: 143.59483337402344, Entropy -154.85997009277344, Learning Rate: 0.005\n",
      "Epoch [1915/20000], Loss: 143.90982055664062, Entropy -172.79583740234375, Learning Rate: 0.005\n",
      "Epoch [1916/20000], Loss: 146.95816040039062, Entropy -167.57518005371094, Learning Rate: 0.005\n",
      "Epoch [1917/20000], Loss: 135.564208984375, Entropy -158.58621215820312, Learning Rate: 0.005\n",
      "Epoch [1918/20000], Loss: 144.10484313964844, Entropy -165.43148803710938, Learning Rate: 0.005\n",
      "Epoch [1919/20000], Loss: 150.4623260498047, Entropy -178.5845947265625, Learning Rate: 0.005\n",
      "Epoch [1920/20000], Loss: 134.71409606933594, Entropy -158.29837036132812, Learning Rate: 0.005\n",
      "Epoch [1921/20000], Loss: 138.1809844970703, Entropy -160.0611114501953, Learning Rate: 0.005\n",
      "Epoch [1922/20000], Loss: 138.89772033691406, Entropy -159.88046264648438, Learning Rate: 0.005\n",
      "Epoch [1923/20000], Loss: 148.52273559570312, Entropy -177.57492065429688, Learning Rate: 0.005\n",
      "Epoch [1924/20000], Loss: 135.93357849121094, Entropy -165.30764770507812, Learning Rate: 0.005\n",
      "Epoch [1925/20000], Loss: 138.9718780517578, Entropy -163.93453979492188, Learning Rate: 0.005\n",
      "Epoch [1926/20000], Loss: 132.3854522705078, Entropy -155.52496337890625, Learning Rate: 0.005\n",
      "Epoch [1927/20000], Loss: 150.1585235595703, Entropy -184.24188232421875, Learning Rate: 0.005\n",
      "Epoch [1928/20000], Loss: 145.5208740234375, Entropy -158.85150146484375, Learning Rate: 0.005\n",
      "Epoch [1929/20000], Loss: 153.87254333496094, Entropy -180.4586181640625, Learning Rate: 0.005\n",
      "Epoch [1930/20000], Loss: 134.73789978027344, Entropy -161.13430786132812, Learning Rate: 0.005\n",
      "Epoch [1931/20000], Loss: 152.9952392578125, Entropy -180.53253173828125, Learning Rate: 0.005\n",
      "Epoch [1932/20000], Loss: 141.6539306640625, Entropy -162.99493408203125, Learning Rate: 0.005\n",
      "Epoch [1933/20000], Loss: 138.350830078125, Entropy -156.37078857421875, Learning Rate: 0.005\n",
      "Epoch [1934/20000], Loss: 138.41497802734375, Entropy -160.29295349121094, Learning Rate: 0.005\n",
      "Epoch [1935/20000], Loss: 138.94932556152344, Entropy -158.53997802734375, Learning Rate: 0.005\n",
      "Epoch [1936/20000], Loss: 145.05264282226562, Entropy -174.89480590820312, Learning Rate: 0.005\n",
      "Epoch [1937/20000], Loss: 136.62901306152344, Entropy -162.80453491210938, Learning Rate: 0.005\n",
      "Epoch [1938/20000], Loss: 149.125732421875, Entropy -168.28839111328125, Learning Rate: 0.005\n",
      "Epoch [1939/20000], Loss: 148.65211486816406, Entropy -161.69866943359375, Learning Rate: 0.005\n",
      "Epoch [1940/20000], Loss: 145.6867218017578, Entropy -170.4663543701172, Learning Rate: 0.005\n",
      "Epoch [1941/20000], Loss: 133.03187561035156, Entropy -150.6576385498047, Learning Rate: 0.005\n",
      "Epoch [1942/20000], Loss: 129.0579376220703, Entropy -154.37550354003906, Learning Rate: 0.005\n",
      "Epoch [1943/20000], Loss: 148.37693786621094, Entropy -166.15444946289062, Learning Rate: 0.005\n",
      "Epoch [1944/20000], Loss: 158.96737670898438, Entropy -193.72113037109375, Learning Rate: 0.005\n",
      "Epoch [1945/20000], Loss: 131.27650451660156, Entropy -156.977783203125, Learning Rate: 0.005\n",
      "Epoch [1946/20000], Loss: 129.4849090576172, Entropy -147.49029541015625, Learning Rate: 0.005\n",
      "Epoch [1947/20000], Loss: 145.51596069335938, Entropy -167.64303588867188, Learning Rate: 0.005\n",
      "Epoch [1948/20000], Loss: 142.20156860351562, Entropy -164.87664794921875, Learning Rate: 0.005\n",
      "Epoch [1949/20000], Loss: 138.5884552001953, Entropy -159.42259216308594, Learning Rate: 0.005\n",
      "Epoch [1950/20000], Loss: 142.8156280517578, Entropy -165.84823608398438, Learning Rate: 0.005\n",
      "Epoch [1951/20000], Loss: 144.9274444580078, Entropy -173.93264770507812, Learning Rate: 0.005\n",
      "Epoch [1952/20000], Loss: 146.70849609375, Entropy -175.49057006835938, Learning Rate: 0.005\n",
      "Epoch [1953/20000], Loss: 138.61495971679688, Entropy -166.93228149414062, Learning Rate: 0.005\n",
      "Epoch [1954/20000], Loss: 152.09356689453125, Entropy -186.22381591796875, Learning Rate: 0.005\n",
      "Epoch [1955/20000], Loss: 134.07803344726562, Entropy -155.21905517578125, Learning Rate: 0.005\n",
      "Epoch [1956/20000], Loss: 143.56539916992188, Entropy -171.534912109375, Learning Rate: 0.005\n",
      "Epoch [1957/20000], Loss: 133.0730438232422, Entropy -158.78985595703125, Learning Rate: 0.005\n",
      "Epoch [1958/20000], Loss: 154.5076446533203, Entropy -182.4105224609375, Learning Rate: 0.005\n",
      "Epoch [1959/20000], Loss: 132.48907470703125, Entropy -154.18753051757812, Learning Rate: 0.005\n",
      "Epoch [1960/20000], Loss: 142.36978149414062, Entropy -165.69512939453125, Learning Rate: 0.005\n",
      "Epoch [1961/20000], Loss: 147.08377075195312, Entropy -170.49346923828125, Learning Rate: 0.005\n",
      "Epoch [1962/20000], Loss: 136.1782989501953, Entropy -160.68115234375, Learning Rate: 0.005\n",
      "Epoch [1963/20000], Loss: 136.82571411132812, Entropy -155.6929931640625, Learning Rate: 0.005\n",
      "Epoch [1964/20000], Loss: 142.7842254638672, Entropy -160.83419799804688, Learning Rate: 0.005\n",
      "Epoch [1965/20000], Loss: 148.39964294433594, Entropy -171.20738220214844, Learning Rate: 0.005\n",
      "Epoch [1966/20000], Loss: 143.8636932373047, Entropy -156.58480834960938, Learning Rate: 0.005\n",
      "Epoch [1967/20000], Loss: 140.773193359375, Entropy -157.48794555664062, Learning Rate: 0.005\n",
      "Epoch [1968/20000], Loss: 129.27783203125, Entropy -145.16525268554688, Learning Rate: 0.005\n",
      "Epoch [1969/20000], Loss: 141.7816925048828, Entropy -170.27517700195312, Learning Rate: 0.005\n",
      "Epoch [1970/20000], Loss: 139.49073791503906, Entropy -156.56964111328125, Learning Rate: 0.005\n",
      "Epoch [1971/20000], Loss: 146.95372009277344, Entropy -162.245361328125, Learning Rate: 0.005\n",
      "Epoch [1972/20000], Loss: 137.95880126953125, Entropy -167.6767578125, Learning Rate: 0.005\n",
      "Epoch [1973/20000], Loss: 139.494873046875, Entropy -160.0623016357422, Learning Rate: 0.005\n",
      "Epoch [1974/20000], Loss: 132.30108642578125, Entropy -153.4591522216797, Learning Rate: 0.005\n",
      "Epoch [1975/20000], Loss: 143.417724609375, Entropy -167.82211303710938, Learning Rate: 0.005\n",
      "Epoch [1976/20000], Loss: 144.4627227783203, Entropy -175.40147399902344, Learning Rate: 0.005\n",
      "Epoch [1977/20000], Loss: 133.3639678955078, Entropy -162.30764770507812, Learning Rate: 0.005\n",
      "Epoch [1978/20000], Loss: 147.3435516357422, Entropy -169.0018310546875, Learning Rate: 0.005\n",
      "Epoch [1979/20000], Loss: 141.4462432861328, Entropy -154.20245361328125, Learning Rate: 0.005\n",
      "Epoch [1980/20000], Loss: 144.2682647705078, Entropy -160.55357360839844, Learning Rate: 0.005\n",
      "Epoch [1981/20000], Loss: 140.36236572265625, Entropy -173.0870361328125, Learning Rate: 0.005\n",
      "Epoch [1982/20000], Loss: 139.9353790283203, Entropy -156.12355041503906, Learning Rate: 0.005\n",
      "Epoch [1983/20000], Loss: 141.85496520996094, Entropy -165.31591796875, Learning Rate: 0.005\n",
      "Epoch [1984/20000], Loss: 143.18936157226562, Entropy -170.12640380859375, Learning Rate: 0.005\n",
      "Epoch [1985/20000], Loss: 152.3582763671875, Entropy -171.30087280273438, Learning Rate: 0.005\n",
      "Epoch [1986/20000], Loss: 152.32077026367188, Entropy -178.59658813476562, Learning Rate: 0.005\n",
      "Epoch [1987/20000], Loss: 139.49693298339844, Entropy -158.4125518798828, Learning Rate: 0.005\n",
      "Epoch [1988/20000], Loss: 146.11898803710938, Entropy -173.814697265625, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1989/20000], Loss: 155.09202575683594, Entropy -173.89376831054688, Learning Rate: 0.005\n",
      "Epoch [1990/20000], Loss: 143.94818115234375, Entropy -170.9481658935547, Learning Rate: 0.005\n",
      "Epoch [1991/20000], Loss: 133.04193115234375, Entropy -155.3204345703125, Learning Rate: 0.005\n",
      "Epoch [1992/20000], Loss: 143.2860107421875, Entropy -163.04364013671875, Learning Rate: 0.005\n",
      "Epoch [1993/20000], Loss: 134.40386962890625, Entropy -159.81683349609375, Learning Rate: 0.005\n",
      "Epoch [1994/20000], Loss: 135.42453002929688, Entropy -156.26907348632812, Learning Rate: 0.005\n",
      "Epoch [1995/20000], Loss: 141.25982666015625, Entropy -168.0482940673828, Learning Rate: 0.005\n",
      "Epoch [1996/20000], Loss: 137.90151977539062, Entropy -161.97618103027344, Learning Rate: 0.005\n",
      "Epoch [1997/20000], Loss: 152.38772583007812, Entropy -171.511962890625, Learning Rate: 0.005\n",
      "Epoch [1998/20000], Loss: 132.146484375, Entropy -151.85926818847656, Learning Rate: 0.005\n",
      "Epoch [1999/20000], Loss: 143.08184814453125, Entropy -163.585693359375, Learning Rate: 0.005\n",
      "Epoch [2000/20000], Loss: 135.63230895996094, Entropy -159.1625213623047, Learning Rate: 0.005\n",
      "Epoch [2001/20000], Loss: 136.658935546875, Entropy -159.7865447998047, Learning Rate: 0.005\n",
      "Epoch [2002/20000], Loss: 138.21917724609375, Entropy -165.68585205078125, Learning Rate: 0.005\n",
      "Epoch [2003/20000], Loss: 147.1096954345703, Entropy -175.88743591308594, Learning Rate: 0.005\n",
      "Epoch [2004/20000], Loss: 137.4291229248047, Entropy -167.64453125, Learning Rate: 0.005\n",
      "Epoch [2005/20000], Loss: 129.66015625, Entropy -143.69223022460938, Learning Rate: 0.005\n",
      "Epoch [2006/20000], Loss: 146.6894989013672, Entropy -179.21173095703125, Learning Rate: 0.005\n",
      "Epoch [2007/20000], Loss: 145.94546508789062, Entropy -174.94366455078125, Learning Rate: 0.005\n",
      "Epoch [2008/20000], Loss: 145.673095703125, Entropy -170.02444458007812, Learning Rate: 0.005\n",
      "Epoch [2009/20000], Loss: 135.7353057861328, Entropy -161.26220703125, Learning Rate: 0.005\n",
      "Epoch [2010/20000], Loss: 150.2138214111328, Entropy -175.23695373535156, Learning Rate: 0.005\n",
      "Epoch [2011/20000], Loss: 138.2163543701172, Entropy -156.26992797851562, Learning Rate: 0.005\n",
      "Epoch [2012/20000], Loss: 132.25775146484375, Entropy -155.34213256835938, Learning Rate: 0.005\n",
      "Epoch [2013/20000], Loss: 130.02076721191406, Entropy -157.6537628173828, Learning Rate: 0.005\n",
      "Epoch [2014/20000], Loss: 136.38389587402344, Entropy -154.47634887695312, Learning Rate: 0.005\n",
      "Epoch [2015/20000], Loss: 145.7366485595703, Entropy -165.88204956054688, Learning Rate: 0.005\n",
      "Epoch [2016/20000], Loss: 137.451171875, Entropy -162.3305206298828, Learning Rate: 0.005\n",
      "Epoch [2017/20000], Loss: 134.0316619873047, Entropy -158.68508911132812, Learning Rate: 0.005\n",
      "Epoch [2018/20000], Loss: 142.36685180664062, Entropy -170.67901611328125, Learning Rate: 0.005\n",
      "Epoch [2019/20000], Loss: 138.64842224121094, Entropy -160.28285217285156, Learning Rate: 0.005\n",
      "Epoch [2020/20000], Loss: 133.0899200439453, Entropy -144.29122924804688, Learning Rate: 0.005\n",
      "Epoch [2021/20000], Loss: 135.34349060058594, Entropy -160.74661254882812, Learning Rate: 0.005\n",
      "Epoch [2022/20000], Loss: 163.22445678710938, Entropy -190.67181396484375, Learning Rate: 0.005\n",
      "Epoch [2023/20000], Loss: 122.28547668457031, Entropy -146.45614624023438, Learning Rate: 0.005\n",
      "Epoch [2024/20000], Loss: 139.37945556640625, Entropy -156.63565063476562, Learning Rate: 0.005\n",
      "Epoch [2025/20000], Loss: 137.83212280273438, Entropy -160.41085815429688, Learning Rate: 0.005\n",
      "Epoch [2026/20000], Loss: 147.6064910888672, Entropy -176.0497589111328, Learning Rate: 0.005\n",
      "Epoch [2027/20000], Loss: 134.16065979003906, Entropy -161.0715789794922, Learning Rate: 0.005\n",
      "Epoch [2028/20000], Loss: 141.63206481933594, Entropy -156.84901428222656, Learning Rate: 0.005\n",
      "Epoch [2029/20000], Loss: 143.80633544921875, Entropy -174.45240783691406, Learning Rate: 0.005\n",
      "Epoch [2030/20000], Loss: 143.1295928955078, Entropy -166.28689575195312, Learning Rate: 0.005\n",
      "Epoch [2031/20000], Loss: 143.25318908691406, Entropy -164.5229034423828, Learning Rate: 0.005\n",
      "Epoch [2032/20000], Loss: 130.51766967773438, Entropy -151.89540100097656, Learning Rate: 0.005\n",
      "Epoch [2033/20000], Loss: 134.00872802734375, Entropy -159.52798461914062, Learning Rate: 0.005\n",
      "Epoch [2034/20000], Loss: 140.67977905273438, Entropy -162.97637939453125, Learning Rate: 0.005\n",
      "Epoch [2035/20000], Loss: 144.29307556152344, Entropy -170.0758056640625, Learning Rate: 0.005\n",
      "Epoch [2036/20000], Loss: 143.59344482421875, Entropy -168.16412353515625, Learning Rate: 0.005\n",
      "Epoch [2037/20000], Loss: 144.63893127441406, Entropy -170.45758056640625, Learning Rate: 0.005\n",
      "Epoch [2038/20000], Loss: 136.08656311035156, Entropy -156.90611267089844, Learning Rate: 0.005\n",
      "Epoch [2039/20000], Loss: 138.81304931640625, Entropy -166.46060180664062, Learning Rate: 0.005\n",
      "Epoch [2040/20000], Loss: 141.79136657714844, Entropy -163.978271484375, Learning Rate: 0.005\n",
      "Epoch [2041/20000], Loss: 137.6476287841797, Entropy -152.28082275390625, Learning Rate: 0.005\n",
      "Epoch [2042/20000], Loss: 148.2758026123047, Entropy -171.69021606445312, Learning Rate: 0.005\n",
      "Epoch [2043/20000], Loss: 133.28038024902344, Entropy -157.72637939453125, Learning Rate: 0.005\n",
      "Epoch [2044/20000], Loss: 134.3187713623047, Entropy -160.18130493164062, Learning Rate: 0.005\n",
      "Epoch [2045/20000], Loss: 140.14854431152344, Entropy -167.00184631347656, Learning Rate: 0.005\n",
      "Epoch [2046/20000], Loss: 135.41310119628906, Entropy -156.80091857910156, Learning Rate: 0.005\n",
      "Epoch [2047/20000], Loss: 135.11231994628906, Entropy -164.3878173828125, Learning Rate: 0.005\n",
      "Epoch [2048/20000], Loss: 137.64666748046875, Entropy -168.73699951171875, Learning Rate: 0.005\n",
      "Epoch [2049/20000], Loss: 135.126953125, Entropy -144.0068359375, Learning Rate: 0.005\n",
      "Epoch [2050/20000], Loss: 138.9115753173828, Entropy -172.09640502929688, Learning Rate: 0.005\n",
      "Epoch [2051/20000], Loss: 145.79290771484375, Entropy -171.1320037841797, Learning Rate: 0.005\n",
      "Epoch [2052/20000], Loss: 138.95359802246094, Entropy -164.41748046875, Learning Rate: 0.005\n",
      "Epoch [2053/20000], Loss: 131.27474975585938, Entropy -142.56600952148438, Learning Rate: 0.005\n",
      "Epoch [2054/20000], Loss: 137.57086181640625, Entropy -162.33285522460938, Learning Rate: 0.005\n",
      "Epoch [2055/20000], Loss: 128.64324951171875, Entropy -148.7755126953125, Learning Rate: 0.005\n",
      "Epoch [2056/20000], Loss: 129.54234313964844, Entropy -149.56414794921875, Learning Rate: 0.005\n",
      "Epoch [2057/20000], Loss: 131.521484375, Entropy -151.28160095214844, Learning Rate: 0.005\n",
      "Epoch [2058/20000], Loss: 139.130615234375, Entropy -155.1808319091797, Learning Rate: 0.005\n",
      "Epoch [2059/20000], Loss: 142.02964782714844, Entropy -169.9290771484375, Learning Rate: 0.005\n",
      "Epoch [2060/20000], Loss: 141.03404235839844, Entropy -162.61203002929688, Learning Rate: 0.005\n",
      "Epoch [2061/20000], Loss: 130.9163360595703, Entropy -148.075927734375, Learning Rate: 0.005\n",
      "Epoch [2062/20000], Loss: 144.690673828125, Entropy -171.71209716796875, Learning Rate: 0.005\n",
      "Epoch [2063/20000], Loss: 148.21640014648438, Entropy -157.906982421875, Learning Rate: 0.005\n",
      "Epoch [2064/20000], Loss: 127.69894409179688, Entropy -147.2443389892578, Learning Rate: 0.005\n",
      "Epoch [2065/20000], Loss: 134.48162841796875, Entropy -152.8699951171875, Learning Rate: 0.005\n",
      "Epoch [2066/20000], Loss: 138.07179260253906, Entropy -167.26707458496094, Learning Rate: 0.005\n",
      "Epoch [2067/20000], Loss: 151.5434112548828, Entropy -176.88284301757812, Learning Rate: 0.005\n",
      "Epoch [2068/20000], Loss: 132.7234344482422, Entropy -147.18661499023438, Learning Rate: 0.005\n",
      "Epoch [2069/20000], Loss: 140.6514892578125, Entropy -155.2777099609375, Learning Rate: 0.005\n",
      "Epoch [2070/20000], Loss: 134.41529846191406, Entropy -146.93272399902344, Learning Rate: 0.005\n",
      "Epoch [2071/20000], Loss: 133.11700439453125, Entropy -151.11138916015625, Learning Rate: 0.005\n",
      "Epoch [2072/20000], Loss: 140.21739196777344, Entropy -162.54837036132812, Learning Rate: 0.005\n",
      "Epoch [2073/20000], Loss: 142.0183563232422, Entropy -160.63040161132812, Learning Rate: 0.005\n",
      "Epoch [2074/20000], Loss: 142.94895935058594, Entropy -160.5120849609375, Learning Rate: 0.005\n",
      "Epoch [2075/20000], Loss: 140.65206909179688, Entropy -160.4927520751953, Learning Rate: 0.005\n",
      "Epoch [2076/20000], Loss: 138.23931884765625, Entropy -160.8209686279297, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2077/20000], Loss: 148.076171875, Entropy -171.9048309326172, Learning Rate: 0.005\n",
      "Epoch [2078/20000], Loss: 141.03228759765625, Entropy -162.05377197265625, Learning Rate: 0.005\n",
      "Epoch [2079/20000], Loss: 128.7587432861328, Entropy -156.03524780273438, Learning Rate: 0.005\n",
      "Epoch [2080/20000], Loss: 136.85252380371094, Entropy -164.0962371826172, Learning Rate: 0.005\n",
      "Epoch [2081/20000], Loss: 137.0118408203125, Entropy -163.23114013671875, Learning Rate: 0.005\n",
      "Epoch [2082/20000], Loss: 138.74264526367188, Entropy -165.9788818359375, Learning Rate: 0.005\n",
      "Epoch [2083/20000], Loss: 144.2168731689453, Entropy -172.4713134765625, Learning Rate: 0.005\n",
      "Epoch [2084/20000], Loss: 133.5049591064453, Entropy -152.37896728515625, Learning Rate: 0.005\n",
      "Epoch [2085/20000], Loss: 144.76637268066406, Entropy -164.02590942382812, Learning Rate: 0.005\n",
      "Epoch [2086/20000], Loss: 130.42361450195312, Entropy -151.68527221679688, Learning Rate: 0.005\n",
      "Epoch [2087/20000], Loss: 134.18905639648438, Entropy -154.75247192382812, Learning Rate: 0.005\n",
      "Epoch [2088/20000], Loss: 134.93145751953125, Entropy -155.0624542236328, Learning Rate: 0.005\n",
      "Epoch [2089/20000], Loss: 138.45428466796875, Entropy -162.57789611816406, Learning Rate: 0.005\n",
      "Epoch [2090/20000], Loss: 136.44613647460938, Entropy -155.322021484375, Learning Rate: 0.005\n",
      "Epoch [2091/20000], Loss: 135.66844177246094, Entropy -154.09181213378906, Learning Rate: 0.005\n",
      "Epoch [2092/20000], Loss: 153.63710021972656, Entropy -166.19558715820312, Learning Rate: 0.005\n",
      "Epoch [2093/20000], Loss: 132.64151000976562, Entropy -150.89096069335938, Learning Rate: 0.005\n",
      "Epoch [2094/20000], Loss: 131.89315795898438, Entropy -148.93040466308594, Learning Rate: 0.005\n",
      "Epoch [2095/20000], Loss: 137.32566833496094, Entropy -157.099853515625, Learning Rate: 0.005\n",
      "Epoch [2096/20000], Loss: 135.3895263671875, Entropy -163.02224731445312, Learning Rate: 0.005\n",
      "Epoch [2097/20000], Loss: 130.3631591796875, Entropy -157.22207641601562, Learning Rate: 0.005\n",
      "Epoch [2098/20000], Loss: 142.47354125976562, Entropy -162.32998657226562, Learning Rate: 0.005\n",
      "Epoch [2099/20000], Loss: 128.83204650878906, Entropy -150.15432739257812, Learning Rate: 0.005\n",
      "Epoch [2100/20000], Loss: 140.43019104003906, Entropy -158.2144317626953, Learning Rate: 0.005\n",
      "Epoch [2101/20000], Loss: 142.5345458984375, Entropy -170.71987915039062, Learning Rate: 0.005\n",
      "Epoch [2102/20000], Loss: 137.8952178955078, Entropy -161.04934692382812, Learning Rate: 0.005\n",
      "Epoch [2103/20000], Loss: 138.38833618164062, Entropy -157.5870361328125, Learning Rate: 0.005\n",
      "Epoch [2104/20000], Loss: 136.2800750732422, Entropy -152.34765625, Learning Rate: 0.005\n",
      "Epoch [2105/20000], Loss: 130.43580627441406, Entropy -153.42837524414062, Learning Rate: 0.005\n",
      "Epoch [2106/20000], Loss: 158.5891571044922, Entropy -192.568603515625, Learning Rate: 0.005\n",
      "Epoch [2107/20000], Loss: 134.58279418945312, Entropy -160.2006378173828, Learning Rate: 0.005\n",
      "Epoch [2108/20000], Loss: 133.2559051513672, Entropy -153.8721923828125, Learning Rate: 0.005\n",
      "Epoch [2109/20000], Loss: 144.4488067626953, Entropy -168.4158935546875, Learning Rate: 0.005\n",
      "Epoch [2110/20000], Loss: 142.17384338378906, Entropy -160.8424072265625, Learning Rate: 0.005\n",
      "Epoch [2111/20000], Loss: 139.65087890625, Entropy -161.95452880859375, Learning Rate: 0.005\n",
      "Epoch [2112/20000], Loss: 149.85845947265625, Entropy -176.10585021972656, Learning Rate: 0.005\n",
      "Epoch [2113/20000], Loss: 145.7084503173828, Entropy -166.48448181152344, Learning Rate: 0.005\n",
      "Epoch [2114/20000], Loss: 151.18446350097656, Entropy -148.41818237304688, Learning Rate: 0.005\n",
      "Epoch [2115/20000], Loss: 151.99232482910156, Entropy -159.11947631835938, Learning Rate: 0.005\n",
      "Epoch [2116/20000], Loss: 146.65309143066406, Entropy -152.53005981445312, Learning Rate: 0.005\n",
      "Epoch [2117/20000], Loss: 137.3315887451172, Entropy -155.52572631835938, Learning Rate: 0.005\n",
      "Epoch [2118/20000], Loss: 130.61184692382812, Entropy -154.35275268554688, Learning Rate: 0.005\n",
      "Epoch [2119/20000], Loss: 137.32191467285156, Entropy -159.00033569335938, Learning Rate: 0.005\n",
      "Epoch [2120/20000], Loss: 139.7154998779297, Entropy -162.37939453125, Learning Rate: 0.005\n",
      "Epoch [2121/20000], Loss: 140.57508850097656, Entropy -166.00233459472656, Learning Rate: 0.005\n",
      "Epoch [2122/20000], Loss: 156.12020874023438, Entropy -186.0151824951172, Learning Rate: 0.005\n",
      "Epoch [2123/20000], Loss: 137.87539672851562, Entropy -164.5860137939453, Learning Rate: 0.005\n",
      "Epoch [2124/20000], Loss: 147.87220764160156, Entropy -166.86953735351562, Learning Rate: 0.005\n",
      "Epoch [2125/20000], Loss: 133.55136108398438, Entropy -147.16860961914062, Learning Rate: 0.005\n",
      "Epoch [2126/20000], Loss: 135.50035095214844, Entropy -161.16006469726562, Learning Rate: 0.005\n",
      "Epoch [2127/20000], Loss: 136.70530700683594, Entropy -166.48641967773438, Learning Rate: 0.005\n",
      "Epoch [2128/20000], Loss: 146.29981994628906, Entropy -170.41909790039062, Learning Rate: 0.005\n",
      "Epoch [2129/20000], Loss: 156.9760284423828, Entropy -185.58914184570312, Learning Rate: 0.005\n",
      "Epoch [2130/20000], Loss: 146.10354614257812, Entropy -175.86593627929688, Learning Rate: 0.005\n",
      "Epoch [2131/20000], Loss: 142.24774169921875, Entropy -165.8917694091797, Learning Rate: 0.005\n",
      "Epoch [2132/20000], Loss: 138.27134704589844, Entropy -162.61920166015625, Learning Rate: 0.005\n",
      "Epoch [2133/20000], Loss: 128.85357666015625, Entropy -151.77890014648438, Learning Rate: 0.005\n",
      "Epoch [2134/20000], Loss: 139.19659423828125, Entropy -162.11773681640625, Learning Rate: 0.005\n",
      "Epoch [2135/20000], Loss: 136.4614715576172, Entropy -151.97329711914062, Learning Rate: 0.005\n",
      "Epoch [2136/20000], Loss: 143.81185913085938, Entropy -167.71058654785156, Learning Rate: 0.005\n",
      "Epoch [2137/20000], Loss: 140.8798828125, Entropy -156.59085083007812, Learning Rate: 0.005\n",
      "Epoch [2138/20000], Loss: 136.45228576660156, Entropy -166.83555603027344, Learning Rate: 0.005\n",
      "Epoch [2139/20000], Loss: 128.3242950439453, Entropy -147.69131469726562, Learning Rate: 0.005\n",
      "Epoch [2140/20000], Loss: 144.0862579345703, Entropy -174.14584350585938, Learning Rate: 0.005\n",
      "Epoch [2141/20000], Loss: 158.2288055419922, Entropy -187.33285522460938, Learning Rate: 0.005\n",
      "Epoch [2142/20000], Loss: 130.71588134765625, Entropy -152.08314514160156, Learning Rate: 0.005\n",
      "Epoch [2143/20000], Loss: 138.4234161376953, Entropy -158.1865234375, Learning Rate: 0.005\n",
      "Epoch [2144/20000], Loss: 136.91363525390625, Entropy -158.79824829101562, Learning Rate: 0.005\n",
      "Epoch [2145/20000], Loss: 139.93389892578125, Entropy -157.04843139648438, Learning Rate: 0.005\n",
      "Epoch [2146/20000], Loss: 141.53517150878906, Entropy -171.73825073242188, Learning Rate: 0.005\n",
      "Epoch [2147/20000], Loss: 142.44248962402344, Entropy -157.20562744140625, Learning Rate: 0.005\n",
      "Epoch [2148/20000], Loss: 133.95094299316406, Entropy -150.76531982421875, Learning Rate: 0.005\n",
      "Epoch [2149/20000], Loss: 153.87103271484375, Entropy -177.79151916503906, Learning Rate: 0.005\n",
      "Epoch [2150/20000], Loss: 135.84449768066406, Entropy -152.56724548339844, Learning Rate: 0.005\n",
      "Epoch [2151/20000], Loss: 146.91880798339844, Entropy -169.66552734375, Learning Rate: 0.005\n",
      "Epoch [2152/20000], Loss: 143.64955139160156, Entropy -169.36373901367188, Learning Rate: 0.005\n",
      "Epoch [2153/20000], Loss: 136.31532287597656, Entropy -159.08285522460938, Learning Rate: 0.005\n",
      "Epoch [2154/20000], Loss: 140.68650817871094, Entropy -160.28192138671875, Learning Rate: 0.005\n",
      "Epoch [2155/20000], Loss: 141.70208740234375, Entropy -161.34002685546875, Learning Rate: 0.005\n",
      "Epoch [2156/20000], Loss: 128.44883728027344, Entropy -155.8182373046875, Learning Rate: 0.005\n",
      "Epoch [2157/20000], Loss: 148.05751037597656, Entropy -170.2725830078125, Learning Rate: 0.005\n",
      "Epoch [2158/20000], Loss: 143.87771606445312, Entropy -160.8696746826172, Learning Rate: 0.005\n",
      "Epoch [2159/20000], Loss: 143.4865264892578, Entropy -170.40908813476562, Learning Rate: 0.005\n",
      "Epoch [2160/20000], Loss: 146.43226623535156, Entropy -174.81964111328125, Learning Rate: 0.005\n",
      "Epoch [2161/20000], Loss: 127.53477478027344, Entropy -146.81503295898438, Learning Rate: 0.005\n",
      "Epoch [2162/20000], Loss: 125.76107788085938, Entropy -148.94129943847656, Learning Rate: 0.005\n",
      "Epoch [2163/20000], Loss: 142.81585693359375, Entropy -166.070068359375, Learning Rate: 0.005\n",
      "Epoch [2164/20000], Loss: 139.1269073486328, Entropy -161.18101501464844, Learning Rate: 0.005\n",
      "Epoch [2165/20000], Loss: 152.63693237304688, Entropy -164.96873474121094, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2166/20000], Loss: 128.7935028076172, Entropy -148.03561401367188, Learning Rate: 0.005\n",
      "Epoch [2167/20000], Loss: 138.10140991210938, Entropy -163.77667236328125, Learning Rate: 0.005\n",
      "Epoch [2168/20000], Loss: 131.246337890625, Entropy -158.28358459472656, Learning Rate: 0.005\n",
      "Epoch [2169/20000], Loss: 133.99330139160156, Entropy -153.640625, Learning Rate: 0.005\n",
      "Epoch [2170/20000], Loss: 142.78707885742188, Entropy -172.91510009765625, Learning Rate: 0.005\n",
      "Epoch [2171/20000], Loss: 129.12371826171875, Entropy -148.56195068359375, Learning Rate: 0.005\n",
      "Epoch [2172/20000], Loss: 145.416748046875, Entropy -170.2877655029297, Learning Rate: 0.005\n",
      "Epoch [2173/20000], Loss: 133.0763397216797, Entropy -157.23086547851562, Learning Rate: 0.005\n",
      "Epoch [2174/20000], Loss: 128.06248474121094, Entropy -149.56785583496094, Learning Rate: 0.005\n",
      "Epoch [2175/20000], Loss: 133.4903106689453, Entropy -155.86990356445312, Learning Rate: 0.005\n",
      "Epoch [2176/20000], Loss: 147.6289520263672, Entropy -170.53558349609375, Learning Rate: 0.005\n",
      "Epoch [2177/20000], Loss: 130.51052856445312, Entropy -153.71266174316406, Learning Rate: 0.005\n",
      "Epoch [2178/20000], Loss: 143.91592407226562, Entropy -166.32156372070312, Learning Rate: 0.005\n",
      "Epoch [2179/20000], Loss: 143.4919891357422, Entropy -169.48367309570312, Learning Rate: 0.005\n",
      "Epoch [2180/20000], Loss: 150.89442443847656, Entropy -175.55953979492188, Learning Rate: 0.005\n",
      "Epoch [2181/20000], Loss: 134.9740447998047, Entropy -157.10623168945312, Learning Rate: 0.005\n",
      "Epoch [2182/20000], Loss: 136.50393676757812, Entropy -157.68667602539062, Learning Rate: 0.005\n",
      "Epoch [2183/20000], Loss: 134.1658477783203, Entropy -162.2720947265625, Learning Rate: 0.005\n",
      "Epoch [2184/20000], Loss: 134.03775024414062, Entropy -160.96334838867188, Learning Rate: 0.005\n",
      "Epoch [2185/20000], Loss: 134.713623046875, Entropy -162.09994506835938, Learning Rate: 0.005\n",
      "Epoch [2186/20000], Loss: 136.63255310058594, Entropy -160.05743408203125, Learning Rate: 0.005\n",
      "Epoch [2187/20000], Loss: 141.2869415283203, Entropy -156.67385864257812, Learning Rate: 0.005\n",
      "Epoch [2188/20000], Loss: 141.08590698242188, Entropy -160.4528350830078, Learning Rate: 0.005\n",
      "Epoch [2189/20000], Loss: 142.97152709960938, Entropy -169.9862060546875, Learning Rate: 0.005\n",
      "Epoch [2190/20000], Loss: 145.60061645507812, Entropy -169.144775390625, Learning Rate: 0.005\n",
      "Epoch [2191/20000], Loss: 129.5673828125, Entropy -154.3699493408203, Learning Rate: 0.005\n",
      "Epoch [2192/20000], Loss: 137.90060424804688, Entropy -160.12313842773438, Learning Rate: 0.005\n",
      "Epoch [2193/20000], Loss: 142.35012817382812, Entropy -170.62774658203125, Learning Rate: 0.005\n",
      "Epoch [2194/20000], Loss: 144.9025115966797, Entropy -166.7037353515625, Learning Rate: 0.005\n",
      "Epoch [2195/20000], Loss: 139.76437377929688, Entropy -168.1925811767578, Learning Rate: 0.005\n",
      "Epoch [2196/20000], Loss: 139.7073974609375, Entropy -158.49874877929688, Learning Rate: 0.005\n",
      "Epoch [2197/20000], Loss: 145.75460815429688, Entropy -170.1009521484375, Learning Rate: 0.005\n",
      "Epoch [2198/20000], Loss: 133.51841735839844, Entropy -153.42379760742188, Learning Rate: 0.005\n",
      "Epoch [2199/20000], Loss: 130.25106811523438, Entropy -148.8704071044922, Learning Rate: 0.005\n",
      "Epoch [2200/20000], Loss: 126.80142211914062, Entropy -140.632568359375, Learning Rate: 0.005\n",
      "Epoch [2201/20000], Loss: 135.34185791015625, Entropy -158.15093994140625, Learning Rate: 0.005\n",
      "Epoch [2202/20000], Loss: 143.9683380126953, Entropy -159.85952758789062, Learning Rate: 0.005\n",
      "Epoch [2203/20000], Loss: 131.13304138183594, Entropy -154.71090698242188, Learning Rate: 0.005\n",
      "Epoch [2204/20000], Loss: 123.16127014160156, Entropy -140.04347229003906, Learning Rate: 0.005\n",
      "Epoch [2205/20000], Loss: 147.1768341064453, Entropy -165.8104248046875, Learning Rate: 0.005\n",
      "Epoch [2206/20000], Loss: 131.56065368652344, Entropy -156.3880615234375, Learning Rate: 0.005\n",
      "Epoch [2207/20000], Loss: 145.3699188232422, Entropy -173.76107788085938, Learning Rate: 0.005\n",
      "Epoch [2208/20000], Loss: 135.60769653320312, Entropy -157.44517517089844, Learning Rate: 0.005\n",
      "Epoch [2209/20000], Loss: 128.5768585205078, Entropy -156.48880004882812, Learning Rate: 0.005\n",
      "Epoch [2210/20000], Loss: 127.62654113769531, Entropy -147.62411499023438, Learning Rate: 0.005\n",
      "Epoch [2211/20000], Loss: 132.87786865234375, Entropy -152.9544677734375, Learning Rate: 0.005\n",
      "Epoch [2212/20000], Loss: 133.4696502685547, Entropy -151.90469360351562, Learning Rate: 0.005\n",
      "Epoch [2213/20000], Loss: 139.14016723632812, Entropy -166.45779418945312, Learning Rate: 0.005\n",
      "Epoch [2214/20000], Loss: 127.15351867675781, Entropy -151.92672729492188, Learning Rate: 0.005\n",
      "Epoch [2215/20000], Loss: 151.59036254882812, Entropy -166.80581665039062, Learning Rate: 0.005\n",
      "Epoch [2216/20000], Loss: 121.11116027832031, Entropy -144.85797119140625, Learning Rate: 0.005\n",
      "Epoch [2217/20000], Loss: 119.86431884765625, Entropy -143.84950256347656, Learning Rate: 0.005\n",
      "Epoch [2218/20000], Loss: 140.97938537597656, Entropy -157.05718994140625, Learning Rate: 0.005\n",
      "Epoch [2219/20000], Loss: 142.3306427001953, Entropy -167.7750244140625, Learning Rate: 0.005\n",
      "Epoch [2220/20000], Loss: 130.4038543701172, Entropy -155.04379272460938, Learning Rate: 0.005\n",
      "Epoch [2221/20000], Loss: 131.8526153564453, Entropy -147.0556182861328, Learning Rate: 0.005\n",
      "Epoch [2222/20000], Loss: 128.62562561035156, Entropy -145.56341552734375, Learning Rate: 0.005\n",
      "Epoch [2223/20000], Loss: 136.36648559570312, Entropy -153.9468994140625, Learning Rate: 0.005\n",
      "Epoch [2224/20000], Loss: 144.7579345703125, Entropy -164.6390380859375, Learning Rate: 0.005\n",
      "Epoch [2225/20000], Loss: 135.83042907714844, Entropy -164.44622802734375, Learning Rate: 0.005\n",
      "Epoch [2226/20000], Loss: 128.8284912109375, Entropy -152.03146362304688, Learning Rate: 0.005\n",
      "Epoch [2227/20000], Loss: 144.9582061767578, Entropy -168.16943359375, Learning Rate: 0.005\n",
      "Epoch [2228/20000], Loss: 137.0753631591797, Entropy -151.749755859375, Learning Rate: 0.005\n",
      "Epoch [2229/20000], Loss: 123.06321716308594, Entropy -144.13548278808594, Learning Rate: 0.005\n",
      "Epoch [2230/20000], Loss: 133.62335205078125, Entropy -162.85568237304688, Learning Rate: 0.005\n",
      "Epoch [2231/20000], Loss: 133.5695037841797, Entropy -154.35121154785156, Learning Rate: 0.005\n",
      "Epoch [2232/20000], Loss: 124.59550476074219, Entropy -146.56710815429688, Learning Rate: 0.005\n",
      "Epoch [2233/20000], Loss: 139.19517517089844, Entropy -167.72015380859375, Learning Rate: 0.005\n",
      "Epoch [2234/20000], Loss: 138.4176788330078, Entropy -167.44888305664062, Learning Rate: 0.005\n",
      "Epoch [2235/20000], Loss: 135.82846069335938, Entropy -154.82032775878906, Learning Rate: 0.005\n",
      "Epoch [2236/20000], Loss: 136.47512817382812, Entropy -159.23675537109375, Learning Rate: 0.005\n",
      "Epoch [2237/20000], Loss: 140.1025848388672, Entropy -168.69845581054688, Learning Rate: 0.005\n",
      "Epoch [2238/20000], Loss: 132.64447021484375, Entropy -153.89480590820312, Learning Rate: 0.005\n",
      "Epoch [2239/20000], Loss: 124.51132202148438, Entropy -147.22915649414062, Learning Rate: 0.005\n",
      "Epoch [2240/20000], Loss: 132.2826690673828, Entropy -158.2304229736328, Learning Rate: 0.005\n",
      "Epoch [2241/20000], Loss: 140.19198608398438, Entropy -174.53134155273438, Learning Rate: 0.005\n",
      "Epoch [2242/20000], Loss: 131.02130126953125, Entropy -147.80319213867188, Learning Rate: 0.005\n",
      "Epoch [2243/20000], Loss: 208.39266967773438, Entropy -149.6903076171875, Learning Rate: 0.005\n",
      "Epoch [2244/20000], Loss: 144.25787353515625, Entropy -150.5086669921875, Learning Rate: 0.005\n",
      "Epoch [2245/20000], Loss: 148.4384765625, Entropy -156.2576141357422, Learning Rate: 0.005\n",
      "Epoch [2246/20000], Loss: 156.53555297851562, Entropy -155.53062438964844, Learning Rate: 0.005\n",
      "Epoch [2247/20000], Loss: 172.35922241210938, Entropy -157.8326416015625, Learning Rate: 0.005\n",
      "Epoch [2248/20000], Loss: 166.57203674316406, Entropy -150.34262084960938, Learning Rate: 0.005\n",
      "Epoch [2249/20000], Loss: 163.44696044921875, Entropy -152.51405334472656, Learning Rate: 0.005\n",
      "Epoch [2250/20000], Loss: 155.29771423339844, Entropy -145.10400390625, Learning Rate: 0.005\n",
      "Epoch [2251/20000], Loss: 175.4161376953125, Entropy -174.681884765625, Learning Rate: 0.005\n",
      "Epoch [2252/20000], Loss: 150.44473266601562, Entropy -155.8148193359375, Learning Rate: 0.005\n",
      "Epoch [2253/20000], Loss: 145.5762939453125, Entropy -143.20510864257812, Learning Rate: 0.005\n",
      "Epoch [2254/20000], Loss: 169.246826171875, Entropy -154.99803161621094, Learning Rate: 0.005\n",
      "Epoch [2255/20000], Loss: 162.918212890625, Entropy -165.8687286376953, Learning Rate: 0.005\n",
      "Epoch [2256/20000], Loss: 162.0220184326172, Entropy -146.15528869628906, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2257/20000], Loss: 151.10513305664062, Entropy -156.09921264648438, Learning Rate: 0.005\n",
      "Epoch [2258/20000], Loss: 150.9903106689453, Entropy -156.42001342773438, Learning Rate: 0.005\n",
      "Epoch [2259/20000], Loss: 152.4140167236328, Entropy -161.13095092773438, Learning Rate: 0.005\n",
      "Epoch [2260/20000], Loss: 164.06341552734375, Entropy -170.7606964111328, Learning Rate: 0.005\n",
      "Epoch [2261/20000], Loss: 170.33221435546875, Entropy -148.1851043701172, Learning Rate: 0.005\n",
      "Epoch [2262/20000], Loss: 240.44223022460938, Entropy -165.77859497070312, Learning Rate: 0.005\n",
      "Epoch [2263/20000], Loss: 329.11334228515625, Entropy -142.05892944335938, Learning Rate: 0.005\n",
      "Epoch [2264/20000], Loss: 212.39378356933594, Entropy -171.45758056640625, Learning Rate: 0.005\n",
      "Epoch [2265/20000], Loss: 174.5503692626953, Entropy -164.77304077148438, Learning Rate: 0.005\n",
      "Epoch [2266/20000], Loss: 237.74746704101562, Entropy -158.6338653564453, Learning Rate: 0.005\n",
      "Epoch [2267/20000], Loss: 201.4974365234375, Entropy -153.82498168945312, Learning Rate: 0.005\n",
      "Epoch [2268/20000], Loss: 147.83734130859375, Entropy -144.60308837890625, Learning Rate: 0.005\n",
      "Epoch [2269/20000], Loss: 204.76995849609375, Entropy -163.63951110839844, Learning Rate: 0.005\n",
      "Epoch [2270/20000], Loss: 144.95919799804688, Entropy -151.50634765625, Learning Rate: 0.005\n",
      "Epoch [2271/20000], Loss: 162.01182556152344, Entropy -169.11212158203125, Learning Rate: 0.005\n",
      "Epoch [2272/20000], Loss: 175.0770263671875, Entropy -151.2448272705078, Learning Rate: 0.005\n",
      "Epoch [2273/20000], Loss: 162.53269958496094, Entropy -148.86827087402344, Learning Rate: 0.005\n",
      "Epoch [2274/20000], Loss: 153.59725952148438, Entropy -162.77236938476562, Learning Rate: 0.005\n",
      "Epoch [2275/20000], Loss: 144.35748291015625, Entropy -163.58541870117188, Learning Rate: 0.005\n",
      "Epoch [2276/20000], Loss: 161.99203491210938, Entropy -163.60787963867188, Learning Rate: 0.005\n",
      "Epoch [2277/20000], Loss: 143.83741760253906, Entropy -155.16790771484375, Learning Rate: 0.005\n",
      "Epoch [2278/20000], Loss: 144.2632598876953, Entropy -160.7580108642578, Learning Rate: 0.005\n",
      "Epoch [2279/20000], Loss: 139.87710571289062, Entropy -159.85110473632812, Learning Rate: 0.005\n",
      "Epoch [2280/20000], Loss: 135.7281951904297, Entropy -148.79092407226562, Learning Rate: 0.005\n",
      "Epoch [2281/20000], Loss: 147.07403564453125, Entropy -166.97047424316406, Learning Rate: 0.005\n",
      "Epoch [2282/20000], Loss: 139.80323791503906, Entropy -156.43328857421875, Learning Rate: 0.005\n",
      "Epoch [2283/20000], Loss: 140.41551208496094, Entropy -154.32901000976562, Learning Rate: 0.005\n",
      "Epoch [2284/20000], Loss: 145.39898681640625, Entropy -161.44696044921875, Learning Rate: 0.005\n",
      "Epoch [2285/20000], Loss: 180.71844482421875, Entropy -189.5147705078125, Learning Rate: 0.005\n",
      "Epoch [2286/20000], Loss: 144.9087677001953, Entropy -161.78436279296875, Learning Rate: 0.005\n",
      "Epoch [2287/20000], Loss: 155.26710510253906, Entropy -190.24417114257812, Learning Rate: 0.005\n",
      "Epoch [2288/20000], Loss: 151.02760314941406, Entropy -167.9988555908203, Learning Rate: 0.005\n",
      "Epoch [2289/20000], Loss: 151.79391479492188, Entropy -175.02728271484375, Learning Rate: 0.005\n",
      "Epoch [2290/20000], Loss: 141.50595092773438, Entropy -158.4318389892578, Learning Rate: 0.005\n",
      "Epoch [2291/20000], Loss: 136.1068572998047, Entropy -166.92648315429688, Learning Rate: 0.005\n",
      "Epoch [2292/20000], Loss: 155.51133728027344, Entropy -180.19261169433594, Learning Rate: 0.005\n",
      "Epoch [2293/20000], Loss: 134.49058532714844, Entropy -150.75437927246094, Learning Rate: 0.005\n",
      "Epoch [2294/20000], Loss: 136.33946228027344, Entropy -152.55477905273438, Learning Rate: 0.005\n",
      "Epoch [2295/20000], Loss: 131.32595825195312, Entropy -154.33807373046875, Learning Rate: 0.005\n",
      "Epoch [2296/20000], Loss: 134.81332397460938, Entropy -144.755615234375, Learning Rate: 0.005\n",
      "Epoch [2297/20000], Loss: 141.3321075439453, Entropy -166.5315704345703, Learning Rate: 0.005\n",
      "Epoch [2298/20000], Loss: 138.88186645507812, Entropy -159.045166015625, Learning Rate: 0.005\n",
      "Epoch [2299/20000], Loss: 138.65008544921875, Entropy -157.67759704589844, Learning Rate: 0.005\n",
      "Epoch [2300/20000], Loss: 144.44004821777344, Entropy -171.11636352539062, Learning Rate: 0.005\n",
      "Epoch [2301/20000], Loss: 137.2861328125, Entropy -160.89724731445312, Learning Rate: 0.005\n",
      "Epoch [2302/20000], Loss: 141.23968505859375, Entropy -157.46192932128906, Learning Rate: 0.005\n",
      "Epoch [2303/20000], Loss: 134.1747589111328, Entropy -153.77679443359375, Learning Rate: 0.005\n",
      "Epoch [2304/20000], Loss: 136.34820556640625, Entropy -157.5264892578125, Learning Rate: 0.005\n",
      "Epoch [2305/20000], Loss: 136.80764770507812, Entropy -152.61940002441406, Learning Rate: 0.005\n",
      "Epoch [2306/20000], Loss: 135.5418701171875, Entropy -149.30731201171875, Learning Rate: 0.005\n",
      "Epoch [2307/20000], Loss: 144.01025390625, Entropy -157.90371704101562, Learning Rate: 0.005\n",
      "Epoch [2308/20000], Loss: 135.8010711669922, Entropy -155.599853515625, Learning Rate: 0.005\n",
      "Epoch [2309/20000], Loss: 132.15869140625, Entropy -153.64955139160156, Learning Rate: 0.005\n",
      "Epoch [2310/20000], Loss: 126.08717346191406, Entropy -142.87515258789062, Learning Rate: 0.005\n",
      "Epoch [2311/20000], Loss: 137.60296630859375, Entropy -152.68385314941406, Learning Rate: 0.005\n",
      "Epoch [2312/20000], Loss: 137.85690307617188, Entropy -156.53953552246094, Learning Rate: 0.005\n",
      "Epoch [2313/20000], Loss: 138.43507385253906, Entropy -159.0183563232422, Learning Rate: 0.005\n",
      "Epoch [2314/20000], Loss: 134.79014587402344, Entropy -152.08688354492188, Learning Rate: 0.005\n",
      "Epoch [2315/20000], Loss: 132.3544921875, Entropy -154.44212341308594, Learning Rate: 0.005\n",
      "Epoch [2316/20000], Loss: 127.48658752441406, Entropy -146.85855102539062, Learning Rate: 0.005\n",
      "Epoch [2317/20000], Loss: 142.4038543701172, Entropy -164.47702026367188, Learning Rate: 0.005\n",
      "Epoch [2318/20000], Loss: 130.79493713378906, Entropy -153.484619140625, Learning Rate: 0.005\n",
      "Epoch [2319/20000], Loss: 146.08946228027344, Entropy -161.8870391845703, Learning Rate: 0.005\n",
      "Epoch [2320/20000], Loss: 135.21783447265625, Entropy -158.23501586914062, Learning Rate: 0.005\n",
      "Epoch [2321/20000], Loss: 140.2323455810547, Entropy -161.4224853515625, Learning Rate: 0.005\n",
      "Epoch [2322/20000], Loss: 131.80584716796875, Entropy -157.711181640625, Learning Rate: 0.005\n",
      "Epoch [2323/20000], Loss: 143.45262145996094, Entropy -169.32009887695312, Learning Rate: 0.005\n",
      "Epoch [2324/20000], Loss: 144.8509521484375, Entropy -171.476806640625, Learning Rate: 0.005\n",
      "Epoch [2325/20000], Loss: 138.53768920898438, Entropy -167.82176208496094, Learning Rate: 0.005\n",
      "Epoch [2326/20000], Loss: 156.01919555664062, Entropy -183.1620635986328, Learning Rate: 0.005\n",
      "Epoch [2327/20000], Loss: 127.25863647460938, Entropy -155.2330322265625, Learning Rate: 0.005\n",
      "Epoch [2328/20000], Loss: 127.92277526855469, Entropy -146.23947143554688, Learning Rate: 0.005\n",
      "Epoch [2329/20000], Loss: 134.05992126464844, Entropy -150.76571655273438, Learning Rate: 0.005\n",
      "Epoch [2330/20000], Loss: 139.11383056640625, Entropy -161.42059326171875, Learning Rate: 0.005\n",
      "Epoch [2331/20000], Loss: 118.18705749511719, Entropy -134.51181030273438, Learning Rate: 0.005\n",
      "Epoch [2332/20000], Loss: 131.9434814453125, Entropy -143.44070434570312, Learning Rate: 0.005\n",
      "Epoch [2333/20000], Loss: 123.95487976074219, Entropy -149.53501892089844, Learning Rate: 0.005\n",
      "Epoch [2334/20000], Loss: 133.81829833984375, Entropy -161.24740600585938, Learning Rate: 0.005\n",
      "Epoch [2335/20000], Loss: 129.40098571777344, Entropy -155.280517578125, Learning Rate: 0.005\n",
      "Epoch [2336/20000], Loss: 132.56089782714844, Entropy -149.91197204589844, Learning Rate: 0.005\n",
      "Epoch [2337/20000], Loss: 146.44529724121094, Entropy -161.73944091796875, Learning Rate: 0.005\n",
      "Epoch [2338/20000], Loss: 133.86158752441406, Entropy -153.64344787597656, Learning Rate: 0.005\n",
      "Epoch [2339/20000], Loss: 140.9250030517578, Entropy -161.71331787109375, Learning Rate: 0.005\n",
      "Epoch [2340/20000], Loss: 128.02696228027344, Entropy -146.39059448242188, Learning Rate: 0.005\n",
      "Epoch [2341/20000], Loss: 140.76785278320312, Entropy -163.11582946777344, Learning Rate: 0.005\n",
      "Epoch [2342/20000], Loss: 126.28770446777344, Entropy -147.7997283935547, Learning Rate: 0.005\n",
      "Epoch [2343/20000], Loss: 140.11729431152344, Entropy -168.01174926757812, Learning Rate: 0.005\n",
      "Epoch [2344/20000], Loss: 119.74346923828125, Entropy -137.99618530273438, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2345/20000], Loss: 123.06080627441406, Entropy -136.7933349609375, Learning Rate: 0.005\n",
      "Epoch [2346/20000], Loss: 130.0563201904297, Entropy -158.99615478515625, Learning Rate: 0.005\n",
      "Epoch [2347/20000], Loss: 132.21820068359375, Entropy -151.64505004882812, Learning Rate: 0.005\n",
      "Epoch [2348/20000], Loss: 149.76788330078125, Entropy -184.8932647705078, Learning Rate: 0.005\n",
      "Epoch [2349/20000], Loss: 142.8334503173828, Entropy -164.22608947753906, Learning Rate: 0.005\n",
      "Epoch [2350/20000], Loss: 135.59962463378906, Entropy -162.96990966796875, Learning Rate: 0.005\n",
      "Epoch [2351/20000], Loss: 132.6255645751953, Entropy -145.93798828125, Learning Rate: 0.005\n",
      "Epoch [2352/20000], Loss: 135.60800170898438, Entropy -158.159912109375, Learning Rate: 0.005\n",
      "Epoch [2353/20000], Loss: 140.019775390625, Entropy -164.82916259765625, Learning Rate: 0.005\n",
      "Epoch [2354/20000], Loss: 139.6636962890625, Entropy -154.7161865234375, Learning Rate: 0.005\n",
      "Epoch [2355/20000], Loss: 136.20266723632812, Entropy -158.16433715820312, Learning Rate: 0.005\n",
      "Epoch [2356/20000], Loss: 141.63792419433594, Entropy -160.81326293945312, Learning Rate: 0.005\n",
      "Epoch [2357/20000], Loss: 134.0895233154297, Entropy -162.4466552734375, Learning Rate: 0.005\n",
      "Epoch [2358/20000], Loss: 149.58714294433594, Entropy -175.38369750976562, Learning Rate: 0.005\n",
      "Epoch [2359/20000], Loss: 154.04531860351562, Entropy -179.92913818359375, Learning Rate: 0.005\n",
      "Epoch [2360/20000], Loss: 139.35569763183594, Entropy -162.16995239257812, Learning Rate: 0.005\n",
      "Epoch [2361/20000], Loss: 143.95541381835938, Entropy -169.36488342285156, Learning Rate: 0.005\n",
      "Epoch [2362/20000], Loss: 128.18411254882812, Entropy -142.64727783203125, Learning Rate: 0.005\n",
      "Epoch [2363/20000], Loss: 132.06741333007812, Entropy -146.96676635742188, Learning Rate: 0.005\n",
      "Epoch [2364/20000], Loss: 136.48731994628906, Entropy -162.0728302001953, Learning Rate: 0.005\n",
      "Epoch [2365/20000], Loss: 123.98933410644531, Entropy -150.03677368164062, Learning Rate: 0.005\n",
      "Epoch [2366/20000], Loss: 128.81175231933594, Entropy -151.25778198242188, Learning Rate: 0.005\n",
      "Epoch [2367/20000], Loss: 148.6188201904297, Entropy -173.9423370361328, Learning Rate: 0.005\n",
      "Epoch [2368/20000], Loss: 134.08108520507812, Entropy -156.83740234375, Learning Rate: 0.005\n",
      "Epoch [2369/20000], Loss: 132.35079956054688, Entropy -154.23568725585938, Learning Rate: 0.005\n",
      "Epoch [2370/20000], Loss: 124.42744445800781, Entropy -142.77560424804688, Learning Rate: 0.005\n",
      "Epoch [2371/20000], Loss: 133.31382751464844, Entropy -149.90066528320312, Learning Rate: 0.005\n",
      "Epoch [2372/20000], Loss: 134.3553009033203, Entropy -163.2671661376953, Learning Rate: 0.005\n",
      "Epoch [2373/20000], Loss: 128.95852661132812, Entropy -151.265380859375, Learning Rate: 0.005\n",
      "Epoch [2374/20000], Loss: 136.57015991210938, Entropy -163.35269165039062, Learning Rate: 0.005\n",
      "Epoch [2375/20000], Loss: 147.83421325683594, Entropy -168.28367614746094, Learning Rate: 0.005\n",
      "Epoch [2376/20000], Loss: 131.67816162109375, Entropy -152.98434448242188, Learning Rate: 0.005\n",
      "Epoch [2377/20000], Loss: 145.19744873046875, Entropy -175.77456665039062, Learning Rate: 0.005\n",
      "Epoch [2378/20000], Loss: 124.79302978515625, Entropy -151.741943359375, Learning Rate: 0.005\n",
      "Epoch [2379/20000], Loss: 123.89990234375, Entropy -152.16213989257812, Learning Rate: 0.005\n",
      "Epoch [2380/20000], Loss: 124.43226623535156, Entropy -137.87832641601562, Learning Rate: 0.005\n",
      "Epoch [2381/20000], Loss: 137.6758270263672, Entropy -164.4097137451172, Learning Rate: 0.005\n",
      "Epoch [2382/20000], Loss: 157.4593505859375, Entropy -178.86480712890625, Learning Rate: 0.005\n",
      "Epoch [2383/20000], Loss: 129.2812042236328, Entropy -148.49661254882812, Learning Rate: 0.005\n",
      "Epoch [2384/20000], Loss: 138.5713348388672, Entropy -169.9110107421875, Learning Rate: 0.005\n",
      "Epoch [2385/20000], Loss: 127.35467529296875, Entropy -151.7882080078125, Learning Rate: 0.005\n",
      "Epoch [2386/20000], Loss: 133.76763916015625, Entropy -145.8137969970703, Learning Rate: 0.005\n",
      "Epoch [2387/20000], Loss: 146.9072723388672, Entropy -168.57037353515625, Learning Rate: 0.005\n",
      "Epoch [2388/20000], Loss: 130.181640625, Entropy -153.56024169921875, Learning Rate: 0.005\n",
      "Epoch [2389/20000], Loss: 126.69889831542969, Entropy -138.92269897460938, Learning Rate: 0.005\n",
      "Epoch [2390/20000], Loss: 125.86138916015625, Entropy -147.88705444335938, Learning Rate: 0.005\n",
      "Epoch [2391/20000], Loss: 154.99107360839844, Entropy -177.00546264648438, Learning Rate: 0.005\n",
      "Epoch [2392/20000], Loss: 133.83645629882812, Entropy -156.68421936035156, Learning Rate: 0.005\n",
      "Epoch [2393/20000], Loss: 122.29466247558594, Entropy -147.35687255859375, Learning Rate: 0.005\n",
      "Epoch [2394/20000], Loss: 130.0400390625, Entropy -155.55064392089844, Learning Rate: 0.005\n",
      "Epoch [2395/20000], Loss: 130.0556182861328, Entropy -150.68360900878906, Learning Rate: 0.005\n",
      "Epoch [2396/20000], Loss: 127.261474609375, Entropy -143.58328247070312, Learning Rate: 0.005\n",
      "Epoch [2397/20000], Loss: 135.65182495117188, Entropy -151.074951171875, Learning Rate: 0.005\n",
      "Epoch [2398/20000], Loss: 142.21389770507812, Entropy -167.89146423339844, Learning Rate: 0.005\n",
      "Epoch [2399/20000], Loss: 137.94967651367188, Entropy -144.40138244628906, Learning Rate: 0.005\n",
      "Epoch [2400/20000], Loss: 136.042724609375, Entropy -158.03564453125, Learning Rate: 0.005\n",
      "Epoch [2401/20000], Loss: 138.3662567138672, Entropy -164.12474060058594, Learning Rate: 0.005\n",
      "Epoch [2402/20000], Loss: 137.11111450195312, Entropy -163.40884399414062, Learning Rate: 0.005\n",
      "Epoch [2403/20000], Loss: 138.18199157714844, Entropy -164.71383666992188, Learning Rate: 0.005\n",
      "Epoch [2404/20000], Loss: 126.13894653320312, Entropy -149.64215087890625, Learning Rate: 0.005\n",
      "Epoch [2405/20000], Loss: 122.73760986328125, Entropy -145.3477783203125, Learning Rate: 0.005\n",
      "Epoch [2406/20000], Loss: 135.19589233398438, Entropy -166.38418579101562, Learning Rate: 0.005\n",
      "Epoch [2407/20000], Loss: 131.78939819335938, Entropy -157.79345703125, Learning Rate: 0.005\n",
      "Epoch [2408/20000], Loss: 131.62258911132812, Entropy -145.94473266601562, Learning Rate: 0.005\n",
      "Epoch [2409/20000], Loss: 136.4162139892578, Entropy -162.61087036132812, Learning Rate: 0.005\n",
      "Epoch [2410/20000], Loss: 128.76547241210938, Entropy -147.56460571289062, Learning Rate: 0.005\n",
      "Epoch [2411/20000], Loss: 128.380126953125, Entropy -146.3508758544922, Learning Rate: 0.005\n",
      "Epoch [2412/20000], Loss: 133.19320678710938, Entropy -154.08541870117188, Learning Rate: 0.005\n",
      "Epoch [2413/20000], Loss: 150.0026092529297, Entropy -186.50137329101562, Learning Rate: 0.005\n",
      "Epoch [2414/20000], Loss: 131.440185546875, Entropy -155.09341430664062, Learning Rate: 0.005\n",
      "Epoch [2415/20000], Loss: 128.20718383789062, Entropy -156.93771362304688, Learning Rate: 0.005\n",
      "Epoch [2416/20000], Loss: 133.7824249267578, Entropy -157.15597534179688, Learning Rate: 0.005\n",
      "Epoch [2417/20000], Loss: 151.39048767089844, Entropy -179.1708984375, Learning Rate: 0.005\n",
      "Epoch [2418/20000], Loss: 138.9508819580078, Entropy -156.9527587890625, Learning Rate: 0.005\n",
      "Epoch [2419/20000], Loss: 130.50497436523438, Entropy -147.76043701171875, Learning Rate: 0.005\n",
      "Epoch [2420/20000], Loss: 122.39268493652344, Entropy -147.59530639648438, Learning Rate: 0.005\n",
      "Epoch [2421/20000], Loss: 127.97987365722656, Entropy -144.2299041748047, Learning Rate: 0.005\n",
      "Epoch [2422/20000], Loss: 119.16423034667969, Entropy -142.71856689453125, Learning Rate: 0.005\n",
      "Epoch [2423/20000], Loss: 141.4907684326172, Entropy -165.96795654296875, Learning Rate: 0.005\n",
      "Epoch [2424/20000], Loss: 135.96275329589844, Entropy -163.21322631835938, Learning Rate: 0.005\n",
      "Epoch [2425/20000], Loss: 122.13839721679688, Entropy -153.2562255859375, Learning Rate: 0.005\n",
      "Epoch [2426/20000], Loss: 132.26068115234375, Entropy -157.5882110595703, Learning Rate: 0.005\n",
      "Epoch [2427/20000], Loss: 131.03787231445312, Entropy -147.76248168945312, Learning Rate: 0.005\n",
      "Epoch [2428/20000], Loss: 123.7996826171875, Entropy -150.2061767578125, Learning Rate: 0.005\n",
      "Epoch [2429/20000], Loss: 129.3888702392578, Entropy -152.13668823242188, Learning Rate: 0.005\n",
      "Epoch [2430/20000], Loss: 133.97621154785156, Entropy -159.97293090820312, Learning Rate: 0.005\n",
      "Epoch [2431/20000], Loss: 125.640869140625, Entropy -151.45518493652344, Learning Rate: 0.005\n",
      "Epoch [2432/20000], Loss: 131.4840850830078, Entropy -155.55279541015625, Learning Rate: 0.005\n",
      "Epoch [2433/20000], Loss: 136.5547637939453, Entropy -163.25900268554688, Learning Rate: 0.005\n",
      "Epoch [2434/20000], Loss: 134.5183868408203, Entropy -163.7899169921875, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2435/20000], Loss: 124.88983154296875, Entropy -149.85751342773438, Learning Rate: 0.005\n",
      "Epoch [2436/20000], Loss: 122.80995178222656, Entropy -141.4385528564453, Learning Rate: 0.005\n",
      "Epoch [2437/20000], Loss: 136.13902282714844, Entropy -162.30618286132812, Learning Rate: 0.005\n",
      "Epoch [2438/20000], Loss: 137.08360290527344, Entropy -166.66949462890625, Learning Rate: 0.005\n",
      "Epoch [2439/20000], Loss: 127.33131408691406, Entropy -145.30569458007812, Learning Rate: 0.005\n",
      "Epoch [2440/20000], Loss: 136.60186767578125, Entropy -157.19784545898438, Learning Rate: 0.005\n",
      "Epoch [2441/20000], Loss: 133.9333038330078, Entropy -157.6221923828125, Learning Rate: 0.005\n",
      "Epoch [2442/20000], Loss: 121.78518676757812, Entropy -142.55819702148438, Learning Rate: 0.005\n",
      "Epoch [2443/20000], Loss: 135.56736755371094, Entropy -151.20477294921875, Learning Rate: 0.005\n",
      "Epoch [2444/20000], Loss: 139.95948791503906, Entropy -163.20770263671875, Learning Rate: 0.005\n",
      "Epoch [2445/20000], Loss: 133.84063720703125, Entropy -159.969970703125, Learning Rate: 0.005\n",
      "Epoch [2446/20000], Loss: 136.38143920898438, Entropy -160.6041259765625, Learning Rate: 0.005\n",
      "Epoch [2447/20000], Loss: 126.48826599121094, Entropy -150.6046600341797, Learning Rate: 0.005\n",
      "Epoch [2448/20000], Loss: 122.07754516601562, Entropy -145.64825439453125, Learning Rate: 0.005\n",
      "Epoch [2449/20000], Loss: 137.63111877441406, Entropy -168.80477905273438, Learning Rate: 0.005\n",
      "Epoch [2450/20000], Loss: 125.75363159179688, Entropy -145.53695678710938, Learning Rate: 0.005\n",
      "Epoch [2451/20000], Loss: 131.54449462890625, Entropy -156.52084350585938, Learning Rate: 0.005\n",
      "Epoch [2452/20000], Loss: 129.2383575439453, Entropy -149.81942749023438, Learning Rate: 0.005\n",
      "Epoch [2453/20000], Loss: 131.3398895263672, Entropy -159.44375610351562, Learning Rate: 0.005\n",
      "Epoch [2454/20000], Loss: 128.65631103515625, Entropy -151.9850311279297, Learning Rate: 0.005\n",
      "Epoch [2455/20000], Loss: 126.78575134277344, Entropy -147.4025421142578, Learning Rate: 0.005\n",
      "Epoch [2456/20000], Loss: 123.44613647460938, Entropy -143.40573120117188, Learning Rate: 0.005\n",
      "Epoch [2457/20000], Loss: 128.1815185546875, Entropy -156.17922973632812, Learning Rate: 0.005\n",
      "Epoch [2458/20000], Loss: 124.91580200195312, Entropy -147.90695190429688, Learning Rate: 0.005\n",
      "Epoch [2459/20000], Loss: 129.930908203125, Entropy -145.41722106933594, Learning Rate: 0.005\n",
      "Epoch [2460/20000], Loss: 135.3768310546875, Entropy -157.1166534423828, Learning Rate: 0.005\n",
      "Epoch [2461/20000], Loss: 141.56069946289062, Entropy -160.670166015625, Learning Rate: 0.005\n",
      "Epoch [2462/20000], Loss: 132.24871826171875, Entropy -156.76132202148438, Learning Rate: 0.005\n",
      "Epoch [2463/20000], Loss: 149.6232452392578, Entropy -156.1919708251953, Learning Rate: 0.005\n",
      "Epoch [2464/20000], Loss: 131.6051788330078, Entropy -149.927734375, Learning Rate: 0.005\n",
      "Epoch [2465/20000], Loss: 126.234130859375, Entropy -145.9160614013672, Learning Rate: 0.005\n",
      "Epoch [2466/20000], Loss: 138.53587341308594, Entropy -155.53744506835938, Learning Rate: 0.005\n",
      "Epoch [2467/20000], Loss: 145.46151733398438, Entropy -166.45159912109375, Learning Rate: 0.005\n",
      "Epoch [2468/20000], Loss: 139.64927673339844, Entropy -168.91415405273438, Learning Rate: 0.005\n",
      "Epoch [2469/20000], Loss: 125.72097778320312, Entropy -144.2431182861328, Learning Rate: 0.005\n",
      "Epoch [2470/20000], Loss: 128.28855895996094, Entropy -150.70938110351562, Learning Rate: 0.005\n",
      "Epoch [2471/20000], Loss: 129.37704467773438, Entropy -138.33541870117188, Learning Rate: 0.005\n",
      "Epoch [2472/20000], Loss: 142.20156860351562, Entropy -168.93048095703125, Learning Rate: 0.005\n",
      "Epoch [2473/20000], Loss: 136.50807189941406, Entropy -166.4735107421875, Learning Rate: 0.005\n",
      "Epoch [2474/20000], Loss: 133.67576599121094, Entropy -161.385986328125, Learning Rate: 0.005\n",
      "Epoch [2475/20000], Loss: 149.7103729248047, Entropy -176.68899536132812, Learning Rate: 0.005\n",
      "Epoch [2476/20000], Loss: 142.57110595703125, Entropy -162.27896118164062, Learning Rate: 0.005\n",
      "Epoch [2477/20000], Loss: 131.909912109375, Entropy -153.81912231445312, Learning Rate: 0.005\n",
      "Epoch [2478/20000], Loss: 143.39633178710938, Entropy -170.87857055664062, Learning Rate: 0.005\n",
      "Epoch [2479/20000], Loss: 145.1136016845703, Entropy -172.3048858642578, Learning Rate: 0.005\n",
      "Epoch [2480/20000], Loss: 130.89569091796875, Entropy -152.62789916992188, Learning Rate: 0.005\n",
      "Epoch [2481/20000], Loss: 129.65049743652344, Entropy -150.68536376953125, Learning Rate: 0.005\n",
      "Epoch [2482/20000], Loss: 140.2635955810547, Entropy -170.25685119628906, Learning Rate: 0.005\n",
      "Epoch [2483/20000], Loss: 152.7960205078125, Entropy -185.3302001953125, Learning Rate: 0.005\n",
      "Epoch [2484/20000], Loss: 143.87863159179688, Entropy -166.32672119140625, Learning Rate: 0.005\n",
      "Epoch [2485/20000], Loss: 127.53575134277344, Entropy -150.88967895507812, Learning Rate: 0.005\n",
      "Epoch [2486/20000], Loss: 135.5214080810547, Entropy -157.30921936035156, Learning Rate: 0.005\n",
      "Epoch [2487/20000], Loss: 147.1689453125, Entropy -177.22726440429688, Learning Rate: 0.005\n",
      "Epoch [2488/20000], Loss: 128.44204711914062, Entropy -143.70289611816406, Learning Rate: 0.005\n",
      "Epoch [2489/20000], Loss: 136.32374572753906, Entropy -158.52877807617188, Learning Rate: 0.005\n",
      "Epoch [2490/20000], Loss: 130.69207763671875, Entropy -152.31344604492188, Learning Rate: 0.005\n",
      "Epoch [2491/20000], Loss: 139.65394592285156, Entropy -167.68832397460938, Learning Rate: 0.005\n",
      "Epoch [2492/20000], Loss: 129.01419067382812, Entropy -144.58663940429688, Learning Rate: 0.005\n",
      "Epoch [2493/20000], Loss: 127.23184204101562, Entropy -153.4844970703125, Learning Rate: 0.005\n",
      "Epoch [2494/20000], Loss: 126.88212585449219, Entropy -143.7525177001953, Learning Rate: 0.005\n",
      "Epoch [2495/20000], Loss: 130.9044952392578, Entropy -154.7046661376953, Learning Rate: 0.005\n",
      "Epoch [2496/20000], Loss: 135.87445068359375, Entropy -160.1547088623047, Learning Rate: 0.005\n",
      "Epoch [2497/20000], Loss: 130.69764709472656, Entropy -163.58090209960938, Learning Rate: 0.005\n",
      "Epoch [2498/20000], Loss: 125.43241882324219, Entropy -155.9687042236328, Learning Rate: 0.005\n",
      "Epoch [2499/20000], Loss: 126.61456298828125, Entropy -146.59889221191406, Learning Rate: 0.005\n",
      "Epoch [2500/20000], Loss: 126.0380859375, Entropy -149.44094848632812, Learning Rate: 0.005\n",
      "Epoch [2501/20000], Loss: 132.7137451171875, Entropy -154.651123046875, Learning Rate: 0.005\n",
      "Epoch [2502/20000], Loss: 133.2020263671875, Entropy -154.36404418945312, Learning Rate: 0.005\n",
      "Epoch [2503/20000], Loss: 116.17558288574219, Entropy -136.1968994140625, Learning Rate: 0.005\n",
      "Epoch [2504/20000], Loss: 119.85595703125, Entropy -142.04702758789062, Learning Rate: 0.005\n",
      "Epoch [2505/20000], Loss: 135.9245147705078, Entropy -161.1357879638672, Learning Rate: 0.005\n",
      "Epoch [2506/20000], Loss: 136.36843872070312, Entropy -165.51107788085938, Learning Rate: 0.005\n",
      "Epoch [2507/20000], Loss: 128.14620971679688, Entropy -149.78848266601562, Learning Rate: 0.005\n",
      "Epoch [2508/20000], Loss: 133.26974487304688, Entropy -157.58824157714844, Learning Rate: 0.005\n",
      "Epoch [2509/20000], Loss: 147.1715850830078, Entropy -179.30221557617188, Learning Rate: 0.005\n",
      "Epoch [2510/20000], Loss: 134.8908233642578, Entropy -159.3226318359375, Learning Rate: 0.005\n",
      "Epoch [2511/20000], Loss: 135.58444213867188, Entropy -163.72927856445312, Learning Rate: 0.005\n",
      "Epoch [2512/20000], Loss: 128.10113525390625, Entropy -154.41683959960938, Learning Rate: 0.005\n",
      "Epoch [2513/20000], Loss: 132.74317932128906, Entropy -162.0137176513672, Learning Rate: 0.005\n",
      "Epoch [2514/20000], Loss: 118.17324829101562, Entropy -128.96551513671875, Learning Rate: 0.005\n",
      "Epoch [2515/20000], Loss: 119.42208862304688, Entropy -135.70753479003906, Learning Rate: 0.005\n",
      "Epoch [2516/20000], Loss: 127.68186950683594, Entropy -155.01995849609375, Learning Rate: 0.005\n",
      "Epoch [2517/20000], Loss: 127.02766418457031, Entropy -145.29794311523438, Learning Rate: 0.005\n",
      "Epoch [2518/20000], Loss: 138.7991485595703, Entropy -165.0618896484375, Learning Rate: 0.005\n",
      "Epoch [2519/20000], Loss: 126.15066528320312, Entropy -152.90280151367188, Learning Rate: 0.005\n",
      "Epoch [2520/20000], Loss: 114.48051452636719, Entropy -133.19500732421875, Learning Rate: 0.005\n",
      "Epoch [2521/20000], Loss: 138.19873046875, Entropy -165.7836456298828, Learning Rate: 0.005\n",
      "Epoch [2522/20000], Loss: 119.81974792480469, Entropy -136.22149658203125, Learning Rate: 0.005\n",
      "Epoch [2523/20000], Loss: 138.98744201660156, Entropy -160.57089233398438, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2524/20000], Loss: 127.38150024414062, Entropy -148.66204833984375, Learning Rate: 0.005\n",
      "Epoch [2525/20000], Loss: 134.98426818847656, Entropy -152.94642639160156, Learning Rate: 0.005\n",
      "Epoch [2526/20000], Loss: 125.91963195800781, Entropy -155.29425048828125, Learning Rate: 0.005\n",
      "Epoch [2527/20000], Loss: 130.40574645996094, Entropy -149.15191650390625, Learning Rate: 0.005\n",
      "Epoch [2528/20000], Loss: 129.06138610839844, Entropy -146.01809692382812, Learning Rate: 0.005\n",
      "Epoch [2529/20000], Loss: 134.3791961669922, Entropy -166.11160278320312, Learning Rate: 0.005\n",
      "Epoch [2530/20000], Loss: 117.57205200195312, Entropy -131.5096435546875, Learning Rate: 0.005\n",
      "Epoch [2531/20000], Loss: 134.2246856689453, Entropy -162.50131225585938, Learning Rate: 0.005\n",
      "Epoch [2532/20000], Loss: 130.78500366210938, Entropy -154.60400390625, Learning Rate: 0.005\n",
      "Epoch [2533/20000], Loss: 140.76345825195312, Entropy -167.07772827148438, Learning Rate: 0.005\n",
      "Epoch [2534/20000], Loss: 127.5257568359375, Entropy -151.52694702148438, Learning Rate: 0.005\n",
      "Epoch [2535/20000], Loss: 142.8360595703125, Entropy -166.98129272460938, Learning Rate: 0.005\n",
      "Epoch [2536/20000], Loss: 131.05694580078125, Entropy -154.86614990234375, Learning Rate: 0.005\n",
      "Epoch [2537/20000], Loss: 133.49029541015625, Entropy -159.82003784179688, Learning Rate: 0.005\n",
      "Epoch [2538/20000], Loss: 133.77464294433594, Entropy -159.77056884765625, Learning Rate: 0.005\n",
      "Epoch [2539/20000], Loss: 129.7447052001953, Entropy -152.7491912841797, Learning Rate: 0.005\n",
      "Epoch [2540/20000], Loss: 138.11695861816406, Entropy -157.09246826171875, Learning Rate: 0.005\n",
      "Epoch [2541/20000], Loss: 124.19084167480469, Entropy -140.73243713378906, Learning Rate: 0.005\n",
      "Epoch [2542/20000], Loss: 148.67196655273438, Entropy -169.77345275878906, Learning Rate: 0.005\n",
      "Epoch [2543/20000], Loss: 120.26087951660156, Entropy -132.14561462402344, Learning Rate: 0.005\n",
      "Epoch [2544/20000], Loss: 115.98936462402344, Entropy -137.77796936035156, Learning Rate: 0.005\n",
      "Epoch [2545/20000], Loss: 135.06838989257812, Entropy -158.8182373046875, Learning Rate: 0.005\n",
      "Epoch [2546/20000], Loss: 123.40830993652344, Entropy -142.69976806640625, Learning Rate: 0.005\n",
      "Epoch [2547/20000], Loss: 123.04437255859375, Entropy -141.33981323242188, Learning Rate: 0.005\n",
      "Epoch [2548/20000], Loss: 121.21440124511719, Entropy -140.22125244140625, Learning Rate: 0.005\n",
      "Epoch [2549/20000], Loss: 139.9089813232422, Entropy -164.62442016601562, Learning Rate: 0.005\n",
      "Epoch [2550/20000], Loss: 121.25120544433594, Entropy -146.5894775390625, Learning Rate: 0.005\n",
      "Epoch [2551/20000], Loss: 127.03385925292969, Entropy -152.60708618164062, Learning Rate: 0.005\n",
      "Epoch [2552/20000], Loss: 123.69047546386719, Entropy -143.38473510742188, Learning Rate: 0.005\n",
      "Epoch [2553/20000], Loss: 140.41131591796875, Entropy -162.28518676757812, Learning Rate: 0.005\n",
      "Epoch [2554/20000], Loss: 140.4163818359375, Entropy -157.71697998046875, Learning Rate: 0.005\n",
      "Epoch [2555/20000], Loss: 131.5001220703125, Entropy -144.61874389648438, Learning Rate: 0.005\n",
      "Epoch [2556/20000], Loss: 122.87623596191406, Entropy -140.61752319335938, Learning Rate: 0.005\n",
      "Epoch [2557/20000], Loss: 137.69692993164062, Entropy -157.74722290039062, Learning Rate: 0.005\n",
      "Epoch [2558/20000], Loss: 133.0946807861328, Entropy -153.16200256347656, Learning Rate: 0.005\n",
      "Epoch [2559/20000], Loss: 121.71441650390625, Entropy -134.30238342285156, Learning Rate: 0.005\n",
      "Epoch [2560/20000], Loss: 125.68142700195312, Entropy -145.679931640625, Learning Rate: 0.005\n",
      "Epoch [2561/20000], Loss: 125.02470397949219, Entropy -137.02999877929688, Learning Rate: 0.005\n",
      "Epoch [2562/20000], Loss: 127.03036499023438, Entropy -152.0887451171875, Learning Rate: 0.005\n",
      "Epoch [2563/20000], Loss: 128.82298278808594, Entropy -152.8056182861328, Learning Rate: 0.005\n",
      "Epoch [2564/20000], Loss: 121.36715698242188, Entropy -142.64700317382812, Learning Rate: 0.005\n",
      "Epoch [2565/20000], Loss: 125.88504028320312, Entropy -151.74508666992188, Learning Rate: 0.005\n",
      "Epoch [2566/20000], Loss: 125.58868408203125, Entropy -145.2341766357422, Learning Rate: 0.005\n",
      "Epoch [2567/20000], Loss: 124.57954406738281, Entropy -147.9090576171875, Learning Rate: 0.005\n",
      "Epoch [2568/20000], Loss: 130.43234252929688, Entropy -162.06777954101562, Learning Rate: 0.005\n",
      "Epoch [2569/20000], Loss: 124.76071166992188, Entropy -142.02548217773438, Learning Rate: 0.005\n",
      "Epoch [2570/20000], Loss: 121.97164916992188, Entropy -134.32077026367188, Learning Rate: 0.005\n",
      "Epoch [2571/20000], Loss: 129.02134704589844, Entropy -159.52645874023438, Learning Rate: 0.005\n",
      "Epoch [2572/20000], Loss: 128.99386596679688, Entropy -155.24676513671875, Learning Rate: 0.005\n",
      "Epoch [2573/20000], Loss: 144.2667999267578, Entropy -156.9070281982422, Learning Rate: 0.005\n",
      "Epoch [2574/20000], Loss: 125.37205505371094, Entropy -146.07553100585938, Learning Rate: 0.005\n",
      "Epoch [2575/20000], Loss: 125.90135192871094, Entropy -152.04840087890625, Learning Rate: 0.005\n",
      "Epoch [2576/20000], Loss: 128.72720336914062, Entropy -155.3543701171875, Learning Rate: 0.005\n",
      "Epoch [2577/20000], Loss: 133.5626220703125, Entropy -165.79579162597656, Learning Rate: 0.005\n",
      "Epoch [2578/20000], Loss: 133.40538024902344, Entropy -155.0847625732422, Learning Rate: 0.005\n",
      "Epoch [2579/20000], Loss: 134.0659637451172, Entropy -154.7149658203125, Learning Rate: 0.005\n",
      "Epoch [2580/20000], Loss: 128.33595275878906, Entropy -155.0950164794922, Learning Rate: 0.005\n",
      "Epoch [2581/20000], Loss: 123.82696533203125, Entropy -133.5437774658203, Learning Rate: 0.005\n",
      "Epoch [2582/20000], Loss: 135.89637756347656, Entropy -158.68972778320312, Learning Rate: 0.005\n",
      "Epoch [2583/20000], Loss: 126.84228515625, Entropy -146.79644775390625, Learning Rate: 0.005\n",
      "Epoch [2584/20000], Loss: 129.4965057373047, Entropy -154.34547424316406, Learning Rate: 0.005\n",
      "Epoch [2585/20000], Loss: 140.52529907226562, Entropy -166.97396850585938, Learning Rate: 0.005\n",
      "Epoch [2586/20000], Loss: 134.8435821533203, Entropy -151.7789306640625, Learning Rate: 0.005\n",
      "Epoch [2587/20000], Loss: 134.51760864257812, Entropy -149.20608520507812, Learning Rate: 0.005\n",
      "Epoch [2588/20000], Loss: 126.91546630859375, Entropy -148.03634643554688, Learning Rate: 0.005\n",
      "Epoch [2589/20000], Loss: 143.3055877685547, Entropy -148.84756469726562, Learning Rate: 0.005\n",
      "Epoch [2590/20000], Loss: 133.9273223876953, Entropy -153.51412963867188, Learning Rate: 0.005\n",
      "Epoch [2591/20000], Loss: 129.78077697753906, Entropy -147.93350219726562, Learning Rate: 0.005\n",
      "Epoch [2592/20000], Loss: 131.79959106445312, Entropy -151.0667724609375, Learning Rate: 0.005\n",
      "Epoch [2593/20000], Loss: 133.01263427734375, Entropy -156.07632446289062, Learning Rate: 0.005\n",
      "Epoch [2594/20000], Loss: 129.2639923095703, Entropy -154.3335723876953, Learning Rate: 0.005\n",
      "Epoch [2595/20000], Loss: 134.93431091308594, Entropy -153.11289978027344, Learning Rate: 0.005\n",
      "Epoch [2596/20000], Loss: 122.40724182128906, Entropy -138.71163940429688, Learning Rate: 0.005\n",
      "Epoch [2597/20000], Loss: 142.57525634765625, Entropy -161.502685546875, Learning Rate: 0.005\n",
      "Epoch [2598/20000], Loss: 124.78140258789062, Entropy -139.2528839111328, Learning Rate: 0.005\n",
      "Epoch [2599/20000], Loss: 150.43479919433594, Entropy -177.97076416015625, Learning Rate: 0.005\n",
      "Epoch [2600/20000], Loss: 133.35755920410156, Entropy -155.73374938964844, Learning Rate: 0.005\n",
      "Epoch [2601/20000], Loss: 127.1456298828125, Entropy -142.79708862304688, Learning Rate: 0.005\n",
      "Epoch [2602/20000], Loss: 124.45179748535156, Entropy -139.31712341308594, Learning Rate: 0.005\n",
      "Epoch [2603/20000], Loss: 139.82872009277344, Entropy -155.4508056640625, Learning Rate: 0.005\n",
      "Epoch [2604/20000], Loss: 135.16839599609375, Entropy -152.48605346679688, Learning Rate: 0.005\n",
      "Epoch [2605/20000], Loss: 138.98265075683594, Entropy -165.92593383789062, Learning Rate: 0.005\n",
      "Epoch [2606/20000], Loss: 127.20700073242188, Entropy -147.24209594726562, Learning Rate: 0.005\n",
      "Epoch [2607/20000], Loss: 130.42822265625, Entropy -142.55508422851562, Learning Rate: 0.005\n",
      "Epoch [2608/20000], Loss: 145.84954833984375, Entropy -171.1162109375, Learning Rate: 0.005\n",
      "Epoch [2609/20000], Loss: 143.94271850585938, Entropy -171.1156005859375, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2610/20000], Loss: 123.13818359375, Entropy -134.74020385742188, Learning Rate: 0.005\n",
      "Epoch [2611/20000], Loss: 124.92642211914062, Entropy -138.5352783203125, Learning Rate: 0.005\n",
      "Epoch [2612/20000], Loss: 134.4624481201172, Entropy -148.20571899414062, Learning Rate: 0.005\n",
      "Epoch [2613/20000], Loss: 129.8272247314453, Entropy -143.5419158935547, Learning Rate: 0.005\n",
      "Epoch [2614/20000], Loss: 141.5146484375, Entropy -159.2332763671875, Learning Rate: 0.005\n",
      "Epoch [2615/20000], Loss: 169.8324432373047, Entropy -167.86737060546875, Learning Rate: 0.005\n",
      "Epoch [2616/20000], Loss: 140.0706329345703, Entropy -155.43661499023438, Learning Rate: 0.005\n",
      "Epoch [2617/20000], Loss: 133.06961059570312, Entropy -152.94105529785156, Learning Rate: 0.005\n",
      "Epoch [2618/20000], Loss: 132.85565185546875, Entropy -159.20004272460938, Learning Rate: 0.005\n",
      "Epoch [2619/20000], Loss: 136.25289916992188, Entropy -155.46725463867188, Learning Rate: 0.005\n",
      "Epoch [2620/20000], Loss: 144.2389373779297, Entropy -159.88607788085938, Learning Rate: 0.005\n",
      "Epoch [2621/20000], Loss: 140.87646484375, Entropy -166.58392333984375, Learning Rate: 0.005\n",
      "Epoch [2622/20000], Loss: 137.6085968017578, Entropy -149.3078155517578, Learning Rate: 0.005\n",
      "Epoch [2623/20000], Loss: 136.70184326171875, Entropy -146.02572631835938, Learning Rate: 0.005\n",
      "Epoch [2624/20000], Loss: 135.80523681640625, Entropy -152.39620971679688, Learning Rate: 0.005\n",
      "Epoch [2625/20000], Loss: 137.54798889160156, Entropy -155.04605102539062, Learning Rate: 0.005\n",
      "Epoch [2626/20000], Loss: 137.15138244628906, Entropy -158.56820678710938, Learning Rate: 0.005\n",
      "Epoch [2627/20000], Loss: 144.7349395751953, Entropy -142.48397827148438, Learning Rate: 0.005\n",
      "Epoch [2628/20000], Loss: 137.9259033203125, Entropy -151.18646240234375, Learning Rate: 0.005\n",
      "Epoch [2629/20000], Loss: 138.51055908203125, Entropy -143.21163940429688, Learning Rate: 0.005\n",
      "Epoch [2630/20000], Loss: 153.5814208984375, Entropy -163.03314208984375, Learning Rate: 0.005\n",
      "Epoch [2631/20000], Loss: 144.8044891357422, Entropy -162.82823181152344, Learning Rate: 0.005\n",
      "Epoch [2632/20000], Loss: 140.93544006347656, Entropy -159.9667205810547, Learning Rate: 0.005\n",
      "Epoch [2633/20000], Loss: 150.43170166015625, Entropy -168.69418334960938, Learning Rate: 0.005\n",
      "Epoch [2634/20000], Loss: 141.88363647460938, Entropy -143.054443359375, Learning Rate: 0.005\n",
      "Epoch [2635/20000], Loss: 140.39303588867188, Entropy -154.32061767578125, Learning Rate: 0.005\n",
      "Epoch [2636/20000], Loss: 138.77035522460938, Entropy -156.20680236816406, Learning Rate: 0.005\n",
      "Epoch [2637/20000], Loss: 137.58668518066406, Entropy -153.8359832763672, Learning Rate: 0.005\n",
      "Epoch [2638/20000], Loss: 136.54258728027344, Entropy -155.46957397460938, Learning Rate: 0.005\n",
      "Epoch [2639/20000], Loss: 132.1194610595703, Entropy -142.65341186523438, Learning Rate: 0.005\n",
      "Epoch [2640/20000], Loss: 133.75648498535156, Entropy -145.79489135742188, Learning Rate: 0.005\n",
      "Epoch [2641/20000], Loss: 141.3782958984375, Entropy -155.5665283203125, Learning Rate: 0.005\n",
      "Epoch [2642/20000], Loss: 137.6355438232422, Entropy -145.62515258789062, Learning Rate: 0.005\n",
      "Epoch [2643/20000], Loss: 119.25520324707031, Entropy -143.8463134765625, Learning Rate: 0.005\n",
      "Epoch [2644/20000], Loss: 138.07937622070312, Entropy -156.66123962402344, Learning Rate: 0.005\n",
      "Epoch [2645/20000], Loss: 127.91392517089844, Entropy -150.61053466796875, Learning Rate: 0.005\n",
      "Epoch [2646/20000], Loss: 126.69094848632812, Entropy -155.26846313476562, Learning Rate: 0.005\n",
      "Epoch [2647/20000], Loss: 142.4746551513672, Entropy -153.13865661621094, Learning Rate: 0.005\n",
      "Epoch [2648/20000], Loss: 134.85452270507812, Entropy -155.29298400878906, Learning Rate: 0.005\n",
      "Epoch [2649/20000], Loss: 135.7401885986328, Entropy -151.73928833007812, Learning Rate: 0.005\n",
      "Epoch [2650/20000], Loss: 142.62942504882812, Entropy -160.91610717773438, Learning Rate: 0.005\n",
      "Epoch [2651/20000], Loss: 139.799072265625, Entropy -165.05287170410156, Learning Rate: 0.005\n",
      "Epoch [2652/20000], Loss: 135.08059692382812, Entropy -160.42501831054688, Learning Rate: 0.005\n",
      "Epoch [2653/20000], Loss: 128.649658203125, Entropy -153.3165283203125, Learning Rate: 0.005\n",
      "Epoch [2654/20000], Loss: 126.83935546875, Entropy -142.56854248046875, Learning Rate: 0.005\n",
      "Epoch [2655/20000], Loss: 131.93775939941406, Entropy -146.626953125, Learning Rate: 0.005\n",
      "Epoch [2656/20000], Loss: 133.3404541015625, Entropy -155.9200439453125, Learning Rate: 0.005\n",
      "Epoch [2657/20000], Loss: 144.0329132080078, Entropy -171.8082733154297, Learning Rate: 0.005\n",
      "Epoch [2658/20000], Loss: 124.47218322753906, Entropy -152.2470703125, Learning Rate: 0.005\n",
      "Epoch [2659/20000], Loss: 129.86767578125, Entropy -157.1824188232422, Learning Rate: 0.005\n",
      "Epoch [2660/20000], Loss: 133.0657501220703, Entropy -152.99476623535156, Learning Rate: 0.005\n",
      "Epoch [2661/20000], Loss: 141.2154083251953, Entropy -158.30270385742188, Learning Rate: 0.005\n",
      "Epoch [2662/20000], Loss: 143.39300537109375, Entropy -165.76931762695312, Learning Rate: 0.005\n",
      "Epoch [2663/20000], Loss: 138.88182067871094, Entropy -162.81259155273438, Learning Rate: 0.005\n",
      "Epoch [2664/20000], Loss: 130.89410400390625, Entropy -147.86305236816406, Learning Rate: 0.005\n",
      "Epoch [2665/20000], Loss: 127.26422119140625, Entropy -145.68267822265625, Learning Rate: 0.005\n",
      "Epoch [2666/20000], Loss: 131.2022705078125, Entropy -148.3245391845703, Learning Rate: 0.005\n",
      "Epoch [2667/20000], Loss: 131.80990600585938, Entropy -150.19847106933594, Learning Rate: 0.005\n",
      "Epoch [2668/20000], Loss: 131.64895629882812, Entropy -151.30099487304688, Learning Rate: 0.005\n",
      "Epoch [2669/20000], Loss: 137.37762451171875, Entropy -161.8534698486328, Learning Rate: 0.005\n",
      "Epoch [2670/20000], Loss: 140.18492126464844, Entropy -158.03392028808594, Learning Rate: 0.005\n",
      "Epoch [2671/20000], Loss: 127.06979370117188, Entropy -146.714111328125, Learning Rate: 0.005\n",
      "Epoch [2672/20000], Loss: 130.8470916748047, Entropy -136.71958923339844, Learning Rate: 0.005\n",
      "Epoch [2673/20000], Loss: 131.99880981445312, Entropy -140.99771118164062, Learning Rate: 0.005\n",
      "Epoch [2674/20000], Loss: 143.14065551757812, Entropy -155.15911865234375, Learning Rate: 0.005\n",
      "Epoch [2675/20000], Loss: 142.83010864257812, Entropy -159.5669403076172, Learning Rate: 0.005\n",
      "Epoch [2676/20000], Loss: 161.88880920410156, Entropy -159.8504180908203, Learning Rate: 0.005\n",
      "Epoch [2677/20000], Loss: 159.33775329589844, Entropy -151.86941528320312, Learning Rate: 0.005\n",
      "Epoch [2678/20000], Loss: 134.66065979003906, Entropy -143.597412109375, Learning Rate: 0.005\n",
      "Epoch [2679/20000], Loss: 156.0458221435547, Entropy -137.80535888671875, Learning Rate: 0.005\n",
      "Epoch [2680/20000], Loss: 156.1819610595703, Entropy -152.86508178710938, Learning Rate: 0.005\n",
      "Epoch [2681/20000], Loss: 143.19692993164062, Entropy -158.38247680664062, Learning Rate: 0.005\n",
      "Epoch [2682/20000], Loss: 171.9154052734375, Entropy -139.68067932128906, Learning Rate: 0.005\n",
      "Epoch [2683/20000], Loss: 165.38323974609375, Entropy -157.33700561523438, Learning Rate: 0.005\n",
      "Epoch [2684/20000], Loss: 129.08946228027344, Entropy -142.0435791015625, Learning Rate: 0.005\n",
      "Epoch [2685/20000], Loss: 158.08567810058594, Entropy -148.71876525878906, Learning Rate: 0.005\n",
      "Epoch [2686/20000], Loss: 140.15650939941406, Entropy -160.0748748779297, Learning Rate: 0.005\n",
      "Epoch [2687/20000], Loss: 152.22425842285156, Entropy -155.2209014892578, Learning Rate: 0.005\n",
      "Epoch [2688/20000], Loss: 144.65545654296875, Entropy -151.70269775390625, Learning Rate: 0.005\n",
      "Epoch [2689/20000], Loss: 142.9766845703125, Entropy -162.42611694335938, Learning Rate: 0.005\n",
      "Epoch [2690/20000], Loss: 154.99960327148438, Entropy -155.60020446777344, Learning Rate: 0.005\n",
      "Epoch [2691/20000], Loss: 139.15371704101562, Entropy -164.454833984375, Learning Rate: 0.005\n",
      "Epoch [2692/20000], Loss: 132.0161590576172, Entropy -134.11550903320312, Learning Rate: 0.005\n",
      "Epoch [2693/20000], Loss: 143.70050048828125, Entropy -148.22064208984375, Learning Rate: 0.005\n",
      "Epoch [2694/20000], Loss: 129.1675262451172, Entropy -145.16860961914062, Learning Rate: 0.005\n",
      "Epoch [2695/20000], Loss: 134.43328857421875, Entropy -149.12521362304688, Learning Rate: 0.005\n",
      "Epoch [2696/20000], Loss: 151.06430053710938, Entropy -168.6123046875, Learning Rate: 0.005\n",
      "Epoch [2697/20000], Loss: 131.7060546875, Entropy -144.19775390625, Learning Rate: 0.005\n",
      "Epoch [2698/20000], Loss: 140.3111572265625, Entropy -154.26495361328125, Learning Rate: 0.005\n",
      "Epoch [2699/20000], Loss: 126.91845703125, Entropy -132.95904541015625, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2700/20000], Loss: 135.2955322265625, Entropy -150.6246337890625, Learning Rate: 0.005\n",
      "Epoch [2701/20000], Loss: 121.17683410644531, Entropy -138.23194885253906, Learning Rate: 0.005\n",
      "Epoch [2702/20000], Loss: 142.85400390625, Entropy -162.69668579101562, Learning Rate: 0.005\n",
      "Epoch [2703/20000], Loss: 129.49351501464844, Entropy -150.06097412109375, Learning Rate: 0.005\n",
      "Epoch [2704/20000], Loss: 132.55857849121094, Entropy -154.5891571044922, Learning Rate: 0.005\n",
      "Epoch [2705/20000], Loss: 134.90899658203125, Entropy -145.8392333984375, Learning Rate: 0.005\n",
      "Epoch [2706/20000], Loss: 136.2933807373047, Entropy -145.76364135742188, Learning Rate: 0.005\n",
      "Epoch [2707/20000], Loss: 141.00527954101562, Entropy -163.54147338867188, Learning Rate: 0.005\n",
      "Epoch [2708/20000], Loss: 144.74740600585938, Entropy -162.18592834472656, Learning Rate: 0.005\n",
      "Epoch [2709/20000], Loss: 131.52386474609375, Entropy -151.75601196289062, Learning Rate: 0.005\n",
      "Epoch [2710/20000], Loss: 138.31219482421875, Entropy -151.76637268066406, Learning Rate: 0.005\n",
      "Epoch [2711/20000], Loss: 132.8382110595703, Entropy -140.97293090820312, Learning Rate: 0.005\n",
      "Epoch [2712/20000], Loss: 133.25157165527344, Entropy -157.6934051513672, Learning Rate: 0.005\n",
      "Epoch [2713/20000], Loss: 130.58084106445312, Entropy -135.31842041015625, Learning Rate: 0.005\n",
      "Epoch [2714/20000], Loss: 127.58551025390625, Entropy -145.43569946289062, Learning Rate: 0.005\n",
      "Epoch [2715/20000], Loss: 138.85569763183594, Entropy -160.94387817382812, Learning Rate: 0.005\n",
      "Epoch [2716/20000], Loss: 129.66445922851562, Entropy -137.85354614257812, Learning Rate: 0.005\n",
      "Epoch [2717/20000], Loss: 135.63327026367188, Entropy -150.4253387451172, Learning Rate: 0.005\n",
      "Epoch [2718/20000], Loss: 132.5189971923828, Entropy -152.04237365722656, Learning Rate: 0.005\n",
      "Epoch [2719/20000], Loss: 130.90664672851562, Entropy -147.83285522460938, Learning Rate: 0.005\n",
      "Epoch [2720/20000], Loss: 134.63766479492188, Entropy -149.58615112304688, Learning Rate: 0.005\n",
      "Epoch [2721/20000], Loss: 121.66879272460938, Entropy -127.37258911132812, Learning Rate: 0.005\n",
      "Epoch [2722/20000], Loss: 119.76884460449219, Entropy -137.17510986328125, Learning Rate: 0.0025\n",
      "Epoch [2723/20000], Loss: 131.38479614257812, Entropy -158.36778259277344, Learning Rate: 0.0025\n",
      "Epoch [2724/20000], Loss: 134.8712921142578, Entropy -156.27279663085938, Learning Rate: 0.0025\n",
      "Epoch [2725/20000], Loss: 130.51071166992188, Entropy -153.3936767578125, Learning Rate: 0.0025\n",
      "Epoch [2726/20000], Loss: 120.31053161621094, Entropy -131.4212646484375, Learning Rate: 0.0025\n",
      "Epoch [2727/20000], Loss: 128.20115661621094, Entropy -154.38621520996094, Learning Rate: 0.0025\n",
      "Epoch [2728/20000], Loss: 131.38308715820312, Entropy -154.732421875, Learning Rate: 0.0025\n",
      "Epoch [2729/20000], Loss: 144.38784790039062, Entropy -154.9563446044922, Learning Rate: 0.0025\n",
      "Epoch [2730/20000], Loss: 125.66157531738281, Entropy -144.74810791015625, Learning Rate: 0.0025\n",
      "Epoch [2731/20000], Loss: 124.61517333984375, Entropy -137.87313842773438, Learning Rate: 0.0025\n",
      "Epoch [2732/20000], Loss: 126.92024230957031, Entropy -151.72344970703125, Learning Rate: 0.0025\n",
      "Epoch [2733/20000], Loss: 125.65553283691406, Entropy -138.40972900390625, Learning Rate: 0.0025\n",
      "Epoch [2734/20000], Loss: 126.42201232910156, Entropy -149.25335693359375, Learning Rate: 0.0025\n",
      "Epoch [2735/20000], Loss: 126.051513671875, Entropy -142.6627197265625, Learning Rate: 0.0025\n",
      "Epoch [2736/20000], Loss: 128.90931701660156, Entropy -146.5981903076172, Learning Rate: 0.0025\n",
      "Epoch [2737/20000], Loss: 128.88751220703125, Entropy -150.13720703125, Learning Rate: 0.0025\n",
      "Epoch [2738/20000], Loss: 121.13615417480469, Entropy -139.77963256835938, Learning Rate: 0.0025\n",
      "Epoch [2739/20000], Loss: 132.75283813476562, Entropy -151.1240234375, Learning Rate: 0.0025\n",
      "Epoch [2740/20000], Loss: 121.27894592285156, Entropy -143.7608642578125, Learning Rate: 0.0025\n",
      "Epoch [2741/20000], Loss: 127.24275207519531, Entropy -152.88201904296875, Learning Rate: 0.0025\n",
      "Epoch [2742/20000], Loss: 125.34397888183594, Entropy -151.9158935546875, Learning Rate: 0.0025\n",
      "Epoch [2743/20000], Loss: 125.36898803710938, Entropy -142.3695068359375, Learning Rate: 0.0025\n",
      "Epoch [2744/20000], Loss: 140.4849853515625, Entropy -168.2325897216797, Learning Rate: 0.0025\n",
      "Epoch [2745/20000], Loss: 147.41998291015625, Entropy -176.50689697265625, Learning Rate: 0.0025\n",
      "Epoch [2746/20000], Loss: 115.47187805175781, Entropy -132.30462646484375, Learning Rate: 0.0025\n",
      "Epoch [2747/20000], Loss: 131.90066528320312, Entropy -152.60433959960938, Learning Rate: 0.0025\n",
      "Epoch [2748/20000], Loss: 128.8197021484375, Entropy -147.6974639892578, Learning Rate: 0.0025\n",
      "Epoch [2749/20000], Loss: 130.37313842773438, Entropy -153.9420623779297, Learning Rate: 0.0025\n",
      "Epoch [2750/20000], Loss: 133.95794677734375, Entropy -156.3155517578125, Learning Rate: 0.0025\n",
      "Epoch [2751/20000], Loss: 130.9390411376953, Entropy -151.71597290039062, Learning Rate: 0.0025\n",
      "Epoch [2752/20000], Loss: 129.59136962890625, Entropy -144.28375244140625, Learning Rate: 0.0025\n",
      "Epoch [2753/20000], Loss: 123.55366516113281, Entropy -134.794677734375, Learning Rate: 0.0025\n",
      "Epoch [2754/20000], Loss: 122.72869873046875, Entropy -147.1604461669922, Learning Rate: 0.0025\n",
      "Epoch [2755/20000], Loss: 115.93040466308594, Entropy -134.311279296875, Learning Rate: 0.0025\n",
      "Epoch [2756/20000], Loss: 144.1646728515625, Entropy -166.54795837402344, Learning Rate: 0.0025\n",
      "Epoch [2757/20000], Loss: 135.5552520751953, Entropy -161.02444458007812, Learning Rate: 0.0025\n",
      "Epoch [2758/20000], Loss: 123.63612365722656, Entropy -144.28123474121094, Learning Rate: 0.0025\n",
      "Epoch [2759/20000], Loss: 135.15147399902344, Entropy -160.96566772460938, Learning Rate: 0.0025\n",
      "Epoch [2760/20000], Loss: 131.2744598388672, Entropy -154.80474853515625, Learning Rate: 0.0025\n",
      "Epoch [2761/20000], Loss: 126.14018249511719, Entropy -144.8282012939453, Learning Rate: 0.0025\n",
      "Epoch [2762/20000], Loss: 119.79817199707031, Entropy -126.7833251953125, Learning Rate: 0.0025\n",
      "Epoch [2763/20000], Loss: 128.94638061523438, Entropy -148.83541870117188, Learning Rate: 0.0025\n",
      "Epoch [2764/20000], Loss: 113.76618957519531, Entropy -129.1958465576172, Learning Rate: 0.0025\n",
      "Epoch [2765/20000], Loss: 120.06253051757812, Entropy -132.235107421875, Learning Rate: 0.0025\n",
      "Epoch [2766/20000], Loss: 137.6739044189453, Entropy -153.2518310546875, Learning Rate: 0.0025\n",
      "Epoch [2767/20000], Loss: 125.40328979492188, Entropy -148.528564453125, Learning Rate: 0.0025\n",
      "Epoch [2768/20000], Loss: 133.40029907226562, Entropy -158.36367797851562, Learning Rate: 0.0025\n",
      "Epoch [2769/20000], Loss: 127.22218322753906, Entropy -143.34754943847656, Learning Rate: 0.0025\n",
      "Epoch [2770/20000], Loss: 125.42007446289062, Entropy -150.86273193359375, Learning Rate: 0.0025\n",
      "Epoch [2771/20000], Loss: 119.48298645019531, Entropy -136.4202423095703, Learning Rate: 0.0025\n",
      "Epoch [2772/20000], Loss: 130.4792938232422, Entropy -148.02545166015625, Learning Rate: 0.0025\n",
      "Epoch [2773/20000], Loss: 127.71951293945312, Entropy -148.63746643066406, Learning Rate: 0.0025\n",
      "Epoch [2774/20000], Loss: 133.08499145507812, Entropy -162.01028442382812, Learning Rate: 0.0025\n",
      "Epoch [2775/20000], Loss: 120.94694519042969, Entropy -143.5320281982422, Learning Rate: 0.0025\n",
      "Epoch [2776/20000], Loss: 133.20663452148438, Entropy -151.0023956298828, Learning Rate: 0.0025\n",
      "Epoch [2777/20000], Loss: 125.71711730957031, Entropy -148.68124389648438, Learning Rate: 0.0025\n",
      "Epoch [2778/20000], Loss: 135.3153076171875, Entropy -158.83114624023438, Learning Rate: 0.0025\n",
      "Epoch [2779/20000], Loss: 111.34233093261719, Entropy -121.85952758789062, Learning Rate: 0.0025\n",
      "Epoch [2780/20000], Loss: 123.36508178710938, Entropy -145.125732421875, Learning Rate: 0.0025\n",
      "Epoch [2781/20000], Loss: 131.97691345214844, Entropy -151.53311157226562, Learning Rate: 0.0025\n",
      "Epoch [2782/20000], Loss: 129.7700958251953, Entropy -152.54998779296875, Learning Rate: 0.0025\n",
      "Epoch [2783/20000], Loss: 133.2821502685547, Entropy -157.56338500976562, Learning Rate: 0.0025\n",
      "Epoch [2784/20000], Loss: 122.19760131835938, Entropy -141.9438934326172, Learning Rate: 0.0025\n",
      "Epoch [2785/20000], Loss: 120.61650085449219, Entropy -142.61251831054688, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2786/20000], Loss: 127.74681091308594, Entropy -150.64511108398438, Learning Rate: 0.0025\n",
      "Epoch [2787/20000], Loss: 124.78021240234375, Entropy -146.96279907226562, Learning Rate: 0.0025\n",
      "Epoch [2788/20000], Loss: 133.1950225830078, Entropy -152.253662109375, Learning Rate: 0.0025\n",
      "Epoch [2789/20000], Loss: 129.05149841308594, Entropy -155.4840545654297, Learning Rate: 0.0025\n",
      "Epoch [2790/20000], Loss: 121.06495666503906, Entropy -141.69937133789062, Learning Rate: 0.0025\n",
      "Epoch [2791/20000], Loss: 130.65505981445312, Entropy -153.2926788330078, Learning Rate: 0.0025\n",
      "Epoch [2792/20000], Loss: 127.72074890136719, Entropy -156.66990661621094, Learning Rate: 0.0025\n",
      "Epoch [2793/20000], Loss: 121.11009216308594, Entropy -141.44033813476562, Learning Rate: 0.0025\n",
      "Epoch [2794/20000], Loss: 131.3550567626953, Entropy -155.09857177734375, Learning Rate: 0.0025\n",
      "Epoch [2795/20000], Loss: 135.44659423828125, Entropy -162.01336669921875, Learning Rate: 0.0025\n",
      "Epoch [2796/20000], Loss: 120.47261047363281, Entropy -146.50840759277344, Learning Rate: 0.0025\n",
      "Epoch [2797/20000], Loss: 138.99093627929688, Entropy -163.65696716308594, Learning Rate: 0.0025\n",
      "Epoch [2798/20000], Loss: 123.79490661621094, Entropy -150.57113647460938, Learning Rate: 0.0025\n",
      "Epoch [2799/20000], Loss: 133.2203369140625, Entropy -159.32540893554688, Learning Rate: 0.0025\n",
      "Epoch [2800/20000], Loss: 133.6824951171875, Entropy -159.31976318359375, Learning Rate: 0.0025\n",
      "Epoch [2801/20000], Loss: 148.2986602783203, Entropy -159.92630004882812, Learning Rate: 0.0025\n",
      "Epoch [2802/20000], Loss: 120.11019897460938, Entropy -142.31814575195312, Learning Rate: 0.0025\n",
      "Epoch [2803/20000], Loss: 130.8509063720703, Entropy -153.7391357421875, Learning Rate: 0.0025\n",
      "Epoch [2804/20000], Loss: 132.9611358642578, Entropy -159.14309692382812, Learning Rate: 0.0025\n",
      "Epoch [2805/20000], Loss: 127.6865234375, Entropy -155.6061553955078, Learning Rate: 0.0025\n",
      "Epoch [2806/20000], Loss: 115.96429443359375, Entropy -139.22830200195312, Learning Rate: 0.0025\n",
      "Epoch [2807/20000], Loss: 132.33389282226562, Entropy -139.96090698242188, Learning Rate: 0.0025\n",
      "Epoch [2808/20000], Loss: 144.5406036376953, Entropy -167.072021484375, Learning Rate: 0.0025\n",
      "Epoch [2809/20000], Loss: 131.89093017578125, Entropy -160.38525390625, Learning Rate: 0.0025\n",
      "Epoch [2810/20000], Loss: 130.1737823486328, Entropy -154.11102294921875, Learning Rate: 0.0025\n",
      "Epoch [2811/20000], Loss: 123.53437805175781, Entropy -134.54449462890625, Learning Rate: 0.0025\n",
      "Epoch [2812/20000], Loss: 133.86822509765625, Entropy -163.38526916503906, Learning Rate: 0.0025\n",
      "Epoch [2813/20000], Loss: 129.45748901367188, Entropy -155.8282470703125, Learning Rate: 0.0025\n",
      "Epoch [2814/20000], Loss: 142.364501953125, Entropy -172.98370361328125, Learning Rate: 0.0025\n",
      "Epoch [2815/20000], Loss: 121.41815185546875, Entropy -145.1495361328125, Learning Rate: 0.0025\n",
      "Epoch [2816/20000], Loss: 131.08389282226562, Entropy -153.24627685546875, Learning Rate: 0.0025\n",
      "Epoch [2817/20000], Loss: 127.24490356445312, Entropy -156.58657836914062, Learning Rate: 0.0025\n",
      "Epoch [2818/20000], Loss: 130.24977111816406, Entropy -144.984375, Learning Rate: 0.0025\n",
      "Epoch [2819/20000], Loss: 124.09732055664062, Entropy -149.2189178466797, Learning Rate: 0.0025\n",
      "Epoch [2820/20000], Loss: 129.29937744140625, Entropy -153.01486206054688, Learning Rate: 0.0025\n",
      "Epoch [2821/20000], Loss: 126.85429382324219, Entropy -157.5352325439453, Learning Rate: 0.0025\n",
      "Epoch [2822/20000], Loss: 117.01907348632812, Entropy -139.98049926757812, Learning Rate: 0.0025\n",
      "Epoch [2823/20000], Loss: 131.45486450195312, Entropy -157.7506866455078, Learning Rate: 0.0025\n",
      "Epoch [2824/20000], Loss: 129.07394409179688, Entropy -147.29656982421875, Learning Rate: 0.0025\n",
      "Epoch [2825/20000], Loss: 127.302978515625, Entropy -152.512939453125, Learning Rate: 0.0025\n",
      "Epoch [2826/20000], Loss: 126.76277160644531, Entropy -154.00930786132812, Learning Rate: 0.0025\n",
      "Epoch [2827/20000], Loss: 128.78221130371094, Entropy -143.6116943359375, Learning Rate: 0.0025\n",
      "Epoch [2828/20000], Loss: 127.61268615722656, Entropy -153.81298828125, Learning Rate: 0.0025\n",
      "Epoch [2829/20000], Loss: 135.98692321777344, Entropy -160.85641479492188, Learning Rate: 0.0025\n",
      "Epoch [2830/20000], Loss: 129.68663024902344, Entropy -153.80409240722656, Learning Rate: 0.0025\n",
      "Epoch [2831/20000], Loss: 127.73561096191406, Entropy -145.65309143066406, Learning Rate: 0.0025\n",
      "Epoch [2832/20000], Loss: 138.51934814453125, Entropy -162.30374145507812, Learning Rate: 0.0025\n",
      "Epoch [2833/20000], Loss: 119.21839904785156, Entropy -139.62451171875, Learning Rate: 0.0025\n",
      "Epoch [2834/20000], Loss: 126.55868530273438, Entropy -141.39321899414062, Learning Rate: 0.0025\n",
      "Epoch [2835/20000], Loss: 120.90467834472656, Entropy -135.54864501953125, Learning Rate: 0.0025\n",
      "Epoch [2836/20000], Loss: 121.68812561035156, Entropy -132.83770751953125, Learning Rate: 0.0025\n",
      "Epoch [2837/20000], Loss: 118.70692443847656, Entropy -139.7767333984375, Learning Rate: 0.0025\n",
      "Epoch [2838/20000], Loss: 121.36701965332031, Entropy -147.7644805908203, Learning Rate: 0.0025\n",
      "Epoch [2839/20000], Loss: 132.32925415039062, Entropy -159.17926025390625, Learning Rate: 0.0025\n",
      "Epoch [2840/20000], Loss: 123.32380676269531, Entropy -145.55267333984375, Learning Rate: 0.0025\n",
      "Epoch [2841/20000], Loss: 136.4091796875, Entropy -164.95831298828125, Learning Rate: 0.0025\n",
      "Epoch [2842/20000], Loss: 123.81748962402344, Entropy -147.76177978515625, Learning Rate: 0.0025\n",
      "Epoch [2843/20000], Loss: 116.547119140625, Entropy -131.79823303222656, Learning Rate: 0.0025\n",
      "Epoch [2844/20000], Loss: 129.52255249023438, Entropy -144.6368408203125, Learning Rate: 0.0025\n",
      "Epoch [2845/20000], Loss: 117.86222839355469, Entropy -130.22406005859375, Learning Rate: 0.0025\n",
      "Epoch [2846/20000], Loss: 118.3770751953125, Entropy -138.84078979492188, Learning Rate: 0.0025\n",
      "Epoch [2847/20000], Loss: 115.21543884277344, Entropy -140.25814819335938, Learning Rate: 0.0025\n",
      "Epoch [2848/20000], Loss: 122.32414245605469, Entropy -137.15957641601562, Learning Rate: 0.0025\n",
      "Epoch [2849/20000], Loss: 128.12673950195312, Entropy -151.09161376953125, Learning Rate: 0.0025\n",
      "Epoch [2850/20000], Loss: 126.52862548828125, Entropy -138.7044677734375, Learning Rate: 0.0025\n",
      "Epoch [2851/20000], Loss: 148.4750213623047, Entropy -150.01248168945312, Learning Rate: 0.0025\n",
      "Epoch [2852/20000], Loss: 120.47154235839844, Entropy -137.59207153320312, Learning Rate: 0.0025\n",
      "Epoch [2853/20000], Loss: 120.20451354980469, Entropy -137.9599609375, Learning Rate: 0.0025\n",
      "Epoch [2854/20000], Loss: 117.50663757324219, Entropy -137.14517211914062, Learning Rate: 0.0025\n",
      "Epoch [2855/20000], Loss: 123.82574462890625, Entropy -136.3095245361328, Learning Rate: 0.0025\n",
      "Epoch [2856/20000], Loss: 125.11567687988281, Entropy -148.97406005859375, Learning Rate: 0.0025\n",
      "Epoch [2857/20000], Loss: 125.82015991210938, Entropy -144.78494262695312, Learning Rate: 0.0025\n",
      "Epoch [2858/20000], Loss: 131.34364318847656, Entropy -149.10488891601562, Learning Rate: 0.0025\n",
      "Epoch [2859/20000], Loss: 126.84458923339844, Entropy -143.0525665283203, Learning Rate: 0.0025\n",
      "Epoch [2860/20000], Loss: 119.11715698242188, Entropy -135.71664428710938, Learning Rate: 0.0025\n",
      "Epoch [2861/20000], Loss: 123.74559020996094, Entropy -134.19387817382812, Learning Rate: 0.0025\n",
      "Epoch [2862/20000], Loss: 129.42970275878906, Entropy -144.44119262695312, Learning Rate: 0.0025\n",
      "Epoch [2863/20000], Loss: 115.30010986328125, Entropy -139.92738342285156, Learning Rate: 0.0025\n",
      "Epoch [2864/20000], Loss: 123.28335571289062, Entropy -148.62692260742188, Learning Rate: 0.0025\n",
      "Epoch [2865/20000], Loss: 125.62733459472656, Entropy -153.50982666015625, Learning Rate: 0.0025\n",
      "Epoch [2866/20000], Loss: 123.68879699707031, Entropy -145.64865112304688, Learning Rate: 0.0025\n",
      "Epoch [2867/20000], Loss: 132.02377319335938, Entropy -156.15072631835938, Learning Rate: 0.0025\n",
      "Epoch [2868/20000], Loss: 126.91851806640625, Entropy -133.9941864013672, Learning Rate: 0.0025\n",
      "Epoch [2869/20000], Loss: 130.939208984375, Entropy -151.17233276367188, Learning Rate: 0.0025\n",
      "Epoch [2870/20000], Loss: 137.23321533203125, Entropy -148.98268127441406, Learning Rate: 0.0025\n",
      "Epoch [2871/20000], Loss: 124.71437072753906, Entropy -138.30319213867188, Learning Rate: 0.0025\n",
      "Epoch [2872/20000], Loss: 123.81111145019531, Entropy -154.79998779296875, Learning Rate: 0.0025\n",
      "Epoch [2873/20000], Loss: 131.3582763671875, Entropy -148.83303833007812, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2874/20000], Loss: 118.82856750488281, Entropy -136.49981689453125, Learning Rate: 0.0025\n",
      "Epoch [2875/20000], Loss: 115.29171752929688, Entropy -134.7852783203125, Learning Rate: 0.0025\n",
      "Epoch [2876/20000], Loss: 125.26165771484375, Entropy -150.2055206298828, Learning Rate: 0.0025\n",
      "Epoch [2877/20000], Loss: 129.13397216796875, Entropy -148.6232452392578, Learning Rate: 0.0025\n",
      "Epoch [2878/20000], Loss: 130.30679321289062, Entropy -148.2140655517578, Learning Rate: 0.0025\n",
      "Epoch [2879/20000], Loss: 130.34986877441406, Entropy -158.60028076171875, Learning Rate: 0.0025\n",
      "Epoch [2880/20000], Loss: 132.62460327148438, Entropy -156.39242553710938, Learning Rate: 0.0025\n",
      "Epoch [2881/20000], Loss: 133.64279174804688, Entropy -157.02175903320312, Learning Rate: 0.0025\n",
      "Epoch [2882/20000], Loss: 122.18988037109375, Entropy -141.9349365234375, Learning Rate: 0.0025\n",
      "Epoch [2883/20000], Loss: 113.23503112792969, Entropy -135.2256622314453, Learning Rate: 0.0025\n",
      "Epoch [2884/20000], Loss: 130.37449645996094, Entropy -150.00978088378906, Learning Rate: 0.0025\n",
      "Epoch [2885/20000], Loss: 137.94163513183594, Entropy -164.16238403320312, Learning Rate: 0.0025\n",
      "Epoch [2886/20000], Loss: 113.41337585449219, Entropy -134.11819458007812, Learning Rate: 0.0025\n",
      "Epoch [2887/20000], Loss: 129.01934814453125, Entropy -154.10145568847656, Learning Rate: 0.0025\n",
      "Epoch [2888/20000], Loss: 128.99957275390625, Entropy -148.44606018066406, Learning Rate: 0.0025\n",
      "Epoch [2889/20000], Loss: 127.76150512695312, Entropy -151.5005340576172, Learning Rate: 0.0025\n",
      "Epoch [2890/20000], Loss: 134.34571838378906, Entropy -164.51226806640625, Learning Rate: 0.0025\n",
      "Epoch [2891/20000], Loss: 126.11585998535156, Entropy -158.36900329589844, Learning Rate: 0.0025\n",
      "Epoch [2892/20000], Loss: 119.50863647460938, Entropy -141.1558074951172, Learning Rate: 0.0025\n",
      "Epoch [2893/20000], Loss: 124.15086364746094, Entropy -151.4703369140625, Learning Rate: 0.0025\n",
      "Epoch [2894/20000], Loss: 126.88516235351562, Entropy -154.8118438720703, Learning Rate: 0.0025\n",
      "Epoch [2895/20000], Loss: 128.71873474121094, Entropy -154.89471435546875, Learning Rate: 0.0025\n",
      "Epoch [2896/20000], Loss: 127.32095336914062, Entropy -155.89059448242188, Learning Rate: 0.0025\n",
      "Epoch [2897/20000], Loss: 118.03654479980469, Entropy -142.057373046875, Learning Rate: 0.0025\n",
      "Epoch [2898/20000], Loss: 121.8685302734375, Entropy -135.9700927734375, Learning Rate: 0.0025\n",
      "Epoch [2899/20000], Loss: 128.7357635498047, Entropy -151.77529907226562, Learning Rate: 0.0025\n",
      "Epoch [2900/20000], Loss: 125.54641723632812, Entropy -151.02066040039062, Learning Rate: 0.0025\n",
      "Epoch [2901/20000], Loss: 123.46769714355469, Entropy -144.7013397216797, Learning Rate: 0.0025\n",
      "Epoch [2902/20000], Loss: 138.0994873046875, Entropy -153.80804443359375, Learning Rate: 0.0025\n",
      "Epoch [2903/20000], Loss: 131.22552490234375, Entropy -150.619384765625, Learning Rate: 0.0025\n",
      "Epoch [2904/20000], Loss: 119.97117614746094, Entropy -139.2649383544922, Learning Rate: 0.0025\n",
      "Epoch [2905/20000], Loss: 122.82655334472656, Entropy -147.5321502685547, Learning Rate: 0.0025\n",
      "Epoch [2906/20000], Loss: 125.75466918945312, Entropy -146.12547302246094, Learning Rate: 0.0025\n",
      "Epoch [2907/20000], Loss: 126.851318359375, Entropy -148.2850799560547, Learning Rate: 0.0025\n",
      "Epoch [2908/20000], Loss: 118.4150390625, Entropy -129.57205200195312, Learning Rate: 0.0025\n",
      "Epoch [2909/20000], Loss: 110.51058959960938, Entropy -130.89190673828125, Learning Rate: 0.0025\n",
      "Epoch [2910/20000], Loss: 120.49070739746094, Entropy -143.88116455078125, Learning Rate: 0.0025\n",
      "Epoch [2911/20000], Loss: 118.02578735351562, Entropy -140.81759643554688, Learning Rate: 0.0025\n",
      "Epoch [2912/20000], Loss: 130.67071533203125, Entropy -154.93955993652344, Learning Rate: 0.0025\n",
      "Epoch [2913/20000], Loss: 139.2515106201172, Entropy -160.96853637695312, Learning Rate: 0.0025\n",
      "Epoch [2914/20000], Loss: 116.9935302734375, Entropy -130.53713989257812, Learning Rate: 0.0025\n",
      "Epoch [2915/20000], Loss: 122.83439636230469, Entropy -143.28753662109375, Learning Rate: 0.0025\n",
      "Epoch [2916/20000], Loss: 124.90083312988281, Entropy -144.31381225585938, Learning Rate: 0.0025\n",
      "Epoch [2917/20000], Loss: 120.15008544921875, Entropy -137.609130859375, Learning Rate: 0.0025\n",
      "Epoch [2918/20000], Loss: 124.51602172851562, Entropy -153.38192749023438, Learning Rate: 0.0025\n",
      "Epoch [2919/20000], Loss: 123.29286193847656, Entropy -147.72003173828125, Learning Rate: 0.0025\n",
      "Epoch [2920/20000], Loss: 130.57916259765625, Entropy -151.26358032226562, Learning Rate: 0.0025\n",
      "Epoch [2921/20000], Loss: 132.16810607910156, Entropy -160.7684326171875, Learning Rate: 0.0025\n",
      "Epoch [2922/20000], Loss: 117.72824096679688, Entropy -140.71571350097656, Learning Rate: 0.0025\n",
      "Epoch [2923/20000], Loss: 115.91127014160156, Entropy -135.58042907714844, Learning Rate: 0.0025\n",
      "Epoch [2924/20000], Loss: 139.86428833007812, Entropy -167.6819305419922, Learning Rate: 0.0025\n",
      "Epoch [2925/20000], Loss: 121.04318237304688, Entropy -141.9814453125, Learning Rate: 0.0025\n",
      "Epoch [2926/20000], Loss: 125.11012268066406, Entropy -143.4542999267578, Learning Rate: 0.0025\n",
      "Epoch [2927/20000], Loss: 124.41387939453125, Entropy -154.6133270263672, Learning Rate: 0.0025\n",
      "Epoch [2928/20000], Loss: 121.9957275390625, Entropy -137.0896453857422, Learning Rate: 0.0025\n",
      "Epoch [2929/20000], Loss: 119.57438659667969, Entropy -133.71615600585938, Learning Rate: 0.0025\n",
      "Epoch [2930/20000], Loss: 126.25723266601562, Entropy -151.53936767578125, Learning Rate: 0.0025\n",
      "Epoch [2931/20000], Loss: 119.25761413574219, Entropy -132.48997497558594, Learning Rate: 0.0025\n",
      "Epoch [2932/20000], Loss: 123.59220886230469, Entropy -152.442138671875, Learning Rate: 0.0025\n",
      "Epoch [2933/20000], Loss: 123.84297180175781, Entropy -144.8298797607422, Learning Rate: 0.0025\n",
      "Epoch [2934/20000], Loss: 125.48391723632812, Entropy -154.4667205810547, Learning Rate: 0.0025\n",
      "Epoch [2935/20000], Loss: 126.2666015625, Entropy -146.10809326171875, Learning Rate: 0.0025\n",
      "Epoch [2936/20000], Loss: 122.80490112304688, Entropy -145.06710815429688, Learning Rate: 0.0025\n",
      "Epoch [2937/20000], Loss: 113.73394775390625, Entropy -140.37254333496094, Learning Rate: 0.0025\n",
      "Epoch [2938/20000], Loss: 115.32489013671875, Entropy -135.8739776611328, Learning Rate: 0.0025\n",
      "Epoch [2939/20000], Loss: 126.84477233886719, Entropy -152.61607360839844, Learning Rate: 0.0025\n",
      "Epoch [2940/20000], Loss: 128.42684936523438, Entropy -149.46734619140625, Learning Rate: 0.0025\n",
      "Epoch [2941/20000], Loss: 121.05752563476562, Entropy -143.18643188476562, Learning Rate: 0.0025\n",
      "Epoch [2942/20000], Loss: 127.53730773925781, Entropy -146.846435546875, Learning Rate: 0.0025\n",
      "Epoch [2943/20000], Loss: 125.200439453125, Entropy -143.9929656982422, Learning Rate: 0.0025\n",
      "Epoch [2944/20000], Loss: 111.49955749511719, Entropy -128.16165161132812, Learning Rate: 0.0025\n",
      "Epoch [2945/20000], Loss: 117.51687622070312, Entropy -148.44815063476562, Learning Rate: 0.0025\n",
      "Epoch [2946/20000], Loss: 132.7189178466797, Entropy -155.9875030517578, Learning Rate: 0.0025\n",
      "Epoch [2947/20000], Loss: 135.5182342529297, Entropy -162.67935180664062, Learning Rate: 0.0025\n",
      "Epoch [2948/20000], Loss: 137.0152587890625, Entropy -172.3291015625, Learning Rate: 0.0025\n",
      "Epoch [2949/20000], Loss: 118.83920288085938, Entropy -125.524169921875, Learning Rate: 0.0025\n",
      "Epoch [2950/20000], Loss: 120.72750854492188, Entropy -140.50137329101562, Learning Rate: 0.0025\n",
      "Epoch [2951/20000], Loss: 113.24110412597656, Entropy -139.20217895507812, Learning Rate: 0.0025\n",
      "Epoch [2952/20000], Loss: 122.66380310058594, Entropy -135.958984375, Learning Rate: 0.0025\n",
      "Epoch [2953/20000], Loss: 117.05845642089844, Entropy -137.7607421875, Learning Rate: 0.0025\n",
      "Epoch [2954/20000], Loss: 127.79055786132812, Entropy -145.52247619628906, Learning Rate: 0.0025\n",
      "Epoch [2955/20000], Loss: 121.54318237304688, Entropy -140.10360717773438, Learning Rate: 0.0025\n",
      "Epoch [2956/20000], Loss: 117.42677307128906, Entropy -136.90158081054688, Learning Rate: 0.0025\n",
      "Epoch [2957/20000], Loss: 119.79605102539062, Entropy -136.2757568359375, Learning Rate: 0.0025\n",
      "Epoch [2958/20000], Loss: 127.65675354003906, Entropy -140.9976806640625, Learning Rate: 0.0025\n",
      "Epoch [2959/20000], Loss: 122.15147399902344, Entropy -143.6876983642578, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2960/20000], Loss: 118.39009094238281, Entropy -140.62213134765625, Learning Rate: 0.0025\n",
      "Epoch [2961/20000], Loss: 132.72544860839844, Entropy -157.031494140625, Learning Rate: 0.0025\n",
      "Epoch [2962/20000], Loss: 127.33644104003906, Entropy -146.16497802734375, Learning Rate: 0.0025\n",
      "Epoch [2963/20000], Loss: 119.22097778320312, Entropy -132.98507690429688, Learning Rate: 0.0025\n",
      "Epoch [2964/20000], Loss: 128.3844757080078, Entropy -146.24432373046875, Learning Rate: 0.0025\n",
      "Epoch [2965/20000], Loss: 120.65264892578125, Entropy -145.3352813720703, Learning Rate: 0.0025\n",
      "Epoch [2966/20000], Loss: 122.88923645019531, Entropy -136.6890411376953, Learning Rate: 0.0025\n",
      "Epoch [2967/20000], Loss: 120.70481872558594, Entropy -146.27413940429688, Learning Rate: 0.0025\n",
      "Epoch [2968/20000], Loss: 122.3494873046875, Entropy -132.95303344726562, Learning Rate: 0.0025\n",
      "Epoch [2969/20000], Loss: 131.34222412109375, Entropy -154.8813934326172, Learning Rate: 0.0025\n",
      "Epoch [2970/20000], Loss: 123.87478637695312, Entropy -135.67083740234375, Learning Rate: 0.0025\n",
      "Epoch [2971/20000], Loss: 121.04193115234375, Entropy -142.93399047851562, Learning Rate: 0.0025\n",
      "Epoch [2972/20000], Loss: 124.03184509277344, Entropy -152.27774047851562, Learning Rate: 0.0025\n",
      "Epoch [2973/20000], Loss: 113.86773681640625, Entropy -139.2034149169922, Learning Rate: 0.0025\n",
      "Epoch [2974/20000], Loss: 125.50788879394531, Entropy -148.085693359375, Learning Rate: 0.0025\n",
      "Epoch [2975/20000], Loss: 116.93258666992188, Entropy -132.70762634277344, Learning Rate: 0.0025\n",
      "Epoch [2976/20000], Loss: 115.38221740722656, Entropy -131.68252563476562, Learning Rate: 0.0025\n",
      "Epoch [2977/20000], Loss: 124.26493835449219, Entropy -155.09518432617188, Learning Rate: 0.0025\n",
      "Epoch [2978/20000], Loss: 121.99554443359375, Entropy -149.00296020507812, Learning Rate: 0.0025\n",
      "Epoch [2979/20000], Loss: 124.44607543945312, Entropy -141.61029052734375, Learning Rate: 0.0025\n",
      "Epoch [2980/20000], Loss: 121.58543395996094, Entropy -135.76441955566406, Learning Rate: 0.0025\n",
      "Epoch [2981/20000], Loss: 114.47300720214844, Entropy -127.7841796875, Learning Rate: 0.0025\n",
      "Epoch [2982/20000], Loss: 120.29194641113281, Entropy -143.11734008789062, Learning Rate: 0.0025\n",
      "Epoch [2983/20000], Loss: 121.75517272949219, Entropy -142.90684509277344, Learning Rate: 0.0025\n",
      "Epoch [2984/20000], Loss: 118.945556640625, Entropy -135.8366241455078, Learning Rate: 0.0025\n",
      "Epoch [2985/20000], Loss: 135.13211059570312, Entropy -155.35598754882812, Learning Rate: 0.0025\n",
      "Epoch [2986/20000], Loss: 121.80067443847656, Entropy -144.52980041503906, Learning Rate: 0.0025\n",
      "Epoch [2987/20000], Loss: 123.8984375, Entropy -144.79605102539062, Learning Rate: 0.0025\n",
      "Epoch [2988/20000], Loss: 130.07855224609375, Entropy -151.95643615722656, Learning Rate: 0.0025\n",
      "Epoch [2989/20000], Loss: 128.34861755371094, Entropy -151.73617553710938, Learning Rate: 0.0025\n",
      "Epoch [2990/20000], Loss: 136.04800415039062, Entropy -160.16941833496094, Learning Rate: 0.0025\n",
      "Epoch [2991/20000], Loss: 119.55340576171875, Entropy -142.65487670898438, Learning Rate: 0.0025\n",
      "Epoch [2992/20000], Loss: 120.42967224121094, Entropy -145.30255126953125, Learning Rate: 0.0025\n",
      "Epoch [2993/20000], Loss: 128.6460418701172, Entropy -154.30194091796875, Learning Rate: 0.0025\n",
      "Epoch [2994/20000], Loss: 117.36131286621094, Entropy -136.59500122070312, Learning Rate: 0.0025\n",
      "Epoch [2995/20000], Loss: 116.11927795410156, Entropy -135.981689453125, Learning Rate: 0.0025\n",
      "Epoch [2996/20000], Loss: 116.07666015625, Entropy -138.32260131835938, Learning Rate: 0.0025\n",
      "Epoch [2997/20000], Loss: 130.1572265625, Entropy -159.5609130859375, Learning Rate: 0.0025\n",
      "Epoch [2998/20000], Loss: 115.60546875, Entropy -134.40603637695312, Learning Rate: 0.0025\n",
      "Epoch [2999/20000], Loss: 108.4886474609375, Entropy -127.6973876953125, Learning Rate: 0.0025\n",
      "Epoch [3000/20000], Loss: 127.982421875, Entropy -149.8513946533203, Learning Rate: 0.0025\n",
      "Epoch [3001/20000], Loss: 128.00938415527344, Entropy -158.815673828125, Learning Rate: 0.0025\n",
      "Epoch [3002/20000], Loss: 131.12911987304688, Entropy -150.92327880859375, Learning Rate: 0.0025\n",
      "Epoch [3003/20000], Loss: 126.22665405273438, Entropy -147.38333129882812, Learning Rate: 0.0025\n",
      "Epoch [3004/20000], Loss: 121.19853210449219, Entropy -145.2857208251953, Learning Rate: 0.0025\n",
      "Epoch [3005/20000], Loss: 125.534423828125, Entropy -144.54678344726562, Learning Rate: 0.0025\n",
      "Epoch [3006/20000], Loss: 117.03871154785156, Entropy -135.28138732910156, Learning Rate: 0.0025\n",
      "Epoch [3007/20000], Loss: 144.00242614746094, Entropy -173.02188110351562, Learning Rate: 0.0025\n",
      "Epoch [3008/20000], Loss: 123.65538024902344, Entropy -141.53805541992188, Learning Rate: 0.0025\n",
      "Epoch [3009/20000], Loss: 141.52774047851562, Entropy -166.44549560546875, Learning Rate: 0.0025\n",
      "Epoch [3010/20000], Loss: 121.82661437988281, Entropy -143.87596130371094, Learning Rate: 0.0025\n",
      "Epoch [3011/20000], Loss: 123.4312744140625, Entropy -143.78509521484375, Learning Rate: 0.0025\n",
      "Epoch [3012/20000], Loss: 118.17778015136719, Entropy -139.49754333496094, Learning Rate: 0.0025\n",
      "Epoch [3013/20000], Loss: 128.35585021972656, Entropy -154.77105712890625, Learning Rate: 0.0025\n",
      "Epoch [3014/20000], Loss: 123.46653747558594, Entropy -144.52816772460938, Learning Rate: 0.0025\n",
      "Epoch [3015/20000], Loss: 115.70649719238281, Entropy -140.49444580078125, Learning Rate: 0.0025\n",
      "Epoch [3016/20000], Loss: 120.62373352050781, Entropy -142.1021728515625, Learning Rate: 0.0025\n",
      "Epoch [3017/20000], Loss: 123.78706359863281, Entropy -149.38381958007812, Learning Rate: 0.0025\n",
      "Epoch [3018/20000], Loss: 124.830078125, Entropy -143.74844360351562, Learning Rate: 0.0025\n",
      "Epoch [3019/20000], Loss: 121.66073608398438, Entropy -146.12661743164062, Learning Rate: 0.0025\n",
      "Epoch [3020/20000], Loss: 118.98846435546875, Entropy -141.10398864746094, Learning Rate: 0.0025\n",
      "Epoch [3021/20000], Loss: 117.74197387695312, Entropy -138.00265502929688, Learning Rate: 0.0025\n",
      "Epoch [3022/20000], Loss: 122.41912841796875, Entropy -141.7911834716797, Learning Rate: 0.0025\n",
      "Epoch [3023/20000], Loss: 120.06974792480469, Entropy -145.87527465820312, Learning Rate: 0.0025\n",
      "Epoch [3024/20000], Loss: 119.23588562011719, Entropy -143.1475372314453, Learning Rate: 0.0025\n",
      "Epoch [3025/20000], Loss: 125.49613952636719, Entropy -149.60714721679688, Learning Rate: 0.0025\n",
      "Epoch [3026/20000], Loss: 132.46011352539062, Entropy -153.40811157226562, Learning Rate: 0.0025\n",
      "Epoch [3027/20000], Loss: 118.90557861328125, Entropy -147.29490661621094, Learning Rate: 0.0025\n",
      "Epoch [3028/20000], Loss: 131.83201599121094, Entropy -148.7799072265625, Learning Rate: 0.0025\n",
      "Epoch [3029/20000], Loss: 124.67825317382812, Entropy -151.1016082763672, Learning Rate: 0.0025\n",
      "Epoch [3030/20000], Loss: 123.41389465332031, Entropy -144.57342529296875, Learning Rate: 0.0025\n",
      "Epoch [3031/20000], Loss: 118.23580932617188, Entropy -140.46803283691406, Learning Rate: 0.0025\n",
      "Epoch [3032/20000], Loss: 118.35679626464844, Entropy -132.36497497558594, Learning Rate: 0.0025\n",
      "Epoch [3033/20000], Loss: 121.05781555175781, Entropy -146.231201171875, Learning Rate: 0.0025\n",
      "Epoch [3034/20000], Loss: 123.07081604003906, Entropy -143.65626525878906, Learning Rate: 0.0025\n",
      "Epoch [3035/20000], Loss: 137.2391357421875, Entropy -151.90162658691406, Learning Rate: 0.0025\n",
      "Epoch [3036/20000], Loss: 130.17767333984375, Entropy -148.26730346679688, Learning Rate: 0.0025\n",
      "Epoch [3037/20000], Loss: 124.75520324707031, Entropy -138.50267028808594, Learning Rate: 0.0025\n",
      "Epoch [3038/20000], Loss: 115.52171325683594, Entropy -142.2091064453125, Learning Rate: 0.0025\n",
      "Epoch [3039/20000], Loss: 123.11289978027344, Entropy -149.7825164794922, Learning Rate: 0.0025\n",
      "Epoch [3040/20000], Loss: 124.15925598144531, Entropy -145.73086547851562, Learning Rate: 0.0025\n",
      "Epoch [3041/20000], Loss: 127.97622680664062, Entropy -154.59291076660156, Learning Rate: 0.0025\n",
      "Epoch [3042/20000], Loss: 127.06477355957031, Entropy -150.04653930664062, Learning Rate: 0.0025\n",
      "Epoch [3043/20000], Loss: 128.63902282714844, Entropy -157.10916137695312, Learning Rate: 0.0025\n",
      "Epoch [3044/20000], Loss: 135.6442413330078, Entropy -157.16946411132812, Learning Rate: 0.0025\n",
      "Epoch [3045/20000], Loss: 126.64773559570312, Entropy -153.8643798828125, Learning Rate: 0.0025\n",
      "Epoch [3046/20000], Loss: 125.15158081054688, Entropy -135.43890380859375, Learning Rate: 0.0025\n",
      "Epoch [3047/20000], Loss: 114.94845581054688, Entropy -130.91470336914062, Learning Rate: 0.0025\n",
      "Epoch [3048/20000], Loss: 116.54559326171875, Entropy -140.34388732910156, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3049/20000], Loss: 125.15501403808594, Entropy -145.4899139404297, Learning Rate: 0.0025\n",
      "Epoch [3050/20000], Loss: 125.73098754882812, Entropy -151.18186950683594, Learning Rate: 0.0025\n",
      "Epoch [3051/20000], Loss: 126.02870178222656, Entropy -156.703857421875, Learning Rate: 0.0025\n",
      "Epoch [3052/20000], Loss: 133.31723022460938, Entropy -160.96661376953125, Learning Rate: 0.0025\n",
      "Epoch [3053/20000], Loss: 125.36546325683594, Entropy -150.2217254638672, Learning Rate: 0.0025\n",
      "Epoch [3054/20000], Loss: 128.14341735839844, Entropy -141.16329956054688, Learning Rate: 0.0025\n",
      "Epoch [3055/20000], Loss: 131.6314697265625, Entropy -159.1787109375, Learning Rate: 0.0025\n",
      "Epoch [3056/20000], Loss: 115.97605895996094, Entropy -137.9413604736328, Learning Rate: 0.0025\n",
      "Epoch [3057/20000], Loss: 118.81021118164062, Entropy -138.54971313476562, Learning Rate: 0.0025\n",
      "Epoch [3058/20000], Loss: 132.28846740722656, Entropy -152.84689331054688, Learning Rate: 0.0025\n",
      "Epoch [3059/20000], Loss: 124.45672607421875, Entropy -152.21543884277344, Learning Rate: 0.0025\n",
      "Epoch [3060/20000], Loss: 135.38232421875, Entropy -160.26467895507812, Learning Rate: 0.0025\n",
      "Epoch [3061/20000], Loss: 117.41293334960938, Entropy -139.82388305664062, Learning Rate: 0.0025\n",
      "Epoch [3062/20000], Loss: 123.6212158203125, Entropy -144.98895263671875, Learning Rate: 0.0025\n",
      "Epoch [3063/20000], Loss: 120.746337890625, Entropy -143.27601623535156, Learning Rate: 0.0025\n",
      "Epoch [3064/20000], Loss: 128.7486114501953, Entropy -151.57400512695312, Learning Rate: 0.0025\n",
      "Epoch [3065/20000], Loss: 118.89053344726562, Entropy -135.61444091796875, Learning Rate: 0.0025\n",
      "Epoch [3066/20000], Loss: 121.95794677734375, Entropy -143.80966186523438, Learning Rate: 0.0025\n",
      "Epoch [3067/20000], Loss: 126.52169799804688, Entropy -155.0689239501953, Learning Rate: 0.0025\n",
      "Epoch [3068/20000], Loss: 121.65998840332031, Entropy -145.578369140625, Learning Rate: 0.0025\n",
      "Epoch [3069/20000], Loss: 123.18533325195312, Entropy -143.013916015625, Learning Rate: 0.0025\n",
      "Epoch [3070/20000], Loss: 123.85612487792969, Entropy -150.08242797851562, Learning Rate: 0.0025\n",
      "Epoch [3071/20000], Loss: 121.13101196289062, Entropy -144.054931640625, Learning Rate: 0.0025\n",
      "Epoch [3072/20000], Loss: 121.93496704101562, Entropy -145.31488037109375, Learning Rate: 0.0025\n",
      "Epoch [3073/20000], Loss: 117.6915283203125, Entropy -139.09326171875, Learning Rate: 0.0025\n",
      "Epoch [3074/20000], Loss: 129.6884765625, Entropy -157.3027801513672, Learning Rate: 0.0025\n",
      "Epoch [3075/20000], Loss: 124.58830261230469, Entropy -143.37315368652344, Learning Rate: 0.0025\n",
      "Epoch [3076/20000], Loss: 117.78683471679688, Entropy -140.42758178710938, Learning Rate: 0.0025\n",
      "Epoch [3077/20000], Loss: 130.8598175048828, Entropy -150.89642333984375, Learning Rate: 0.0025\n",
      "Epoch [3078/20000], Loss: 130.0244598388672, Entropy -153.31593322753906, Learning Rate: 0.0025\n",
      "Epoch [3079/20000], Loss: 118.05657958984375, Entropy -140.36123657226562, Learning Rate: 0.0025\n",
      "Epoch [3080/20000], Loss: 171.1131591796875, Entropy -151.802001953125, Learning Rate: 0.0025\n",
      "Epoch [3081/20000], Loss: 121.78536987304688, Entropy -138.4048614501953, Learning Rate: 0.0025\n",
      "Epoch [3082/20000], Loss: 127.620361328125, Entropy -135.671875, Learning Rate: 0.0025\n",
      "Epoch [3083/20000], Loss: 126.01045227050781, Entropy -148.15249633789062, Learning Rate: 0.0025\n",
      "Epoch [3084/20000], Loss: 118.69789123535156, Entropy -141.7645721435547, Learning Rate: 0.0025\n",
      "Epoch [3085/20000], Loss: 109.32307434082031, Entropy -131.75405883789062, Learning Rate: 0.0025\n",
      "Epoch [3086/20000], Loss: 132.41751098632812, Entropy -154.1353759765625, Learning Rate: 0.0025\n",
      "Epoch [3087/20000], Loss: 122.23065185546875, Entropy -143.4038543701172, Learning Rate: 0.0025\n",
      "Epoch [3088/20000], Loss: 136.75482177734375, Entropy -160.2788543701172, Learning Rate: 0.0025\n",
      "Epoch [3089/20000], Loss: 126.90087890625, Entropy -143.12603759765625, Learning Rate: 0.0025\n",
      "Epoch [3090/20000], Loss: 127.91448974609375, Entropy -148.43463134765625, Learning Rate: 0.0025\n",
      "Epoch [3091/20000], Loss: 116.41351318359375, Entropy -142.56993103027344, Learning Rate: 0.0025\n",
      "Epoch [3092/20000], Loss: 123.53657531738281, Entropy -143.2508544921875, Learning Rate: 0.0025\n",
      "Epoch [3093/20000], Loss: 123.13616943359375, Entropy -147.69003295898438, Learning Rate: 0.0025\n",
      "Epoch [3094/20000], Loss: 121.58583068847656, Entropy -148.40513610839844, Learning Rate: 0.0025\n",
      "Epoch [3095/20000], Loss: 119.77088928222656, Entropy -135.42593383789062, Learning Rate: 0.0025\n",
      "Epoch [3096/20000], Loss: 117.04930114746094, Entropy -132.6505126953125, Learning Rate: 0.0025\n",
      "Epoch [3097/20000], Loss: 119.51614379882812, Entropy -137.27239990234375, Learning Rate: 0.0025\n",
      "Epoch [3098/20000], Loss: 126.03495788574219, Entropy -150.25448608398438, Learning Rate: 0.0025\n",
      "Epoch [3099/20000], Loss: 125.46382141113281, Entropy -139.80364990234375, Learning Rate: 0.0025\n",
      "Epoch [3100/20000], Loss: 130.3696746826172, Entropy -148.3936767578125, Learning Rate: 0.0025\n",
      "Epoch [3101/20000], Loss: 121.98170471191406, Entropy -128.5799560546875, Learning Rate: 0.0025\n",
      "Epoch [3102/20000], Loss: 130.21929931640625, Entropy -155.9280242919922, Learning Rate: 0.0025\n",
      "Epoch [3103/20000], Loss: 124.50697326660156, Entropy -151.38265991210938, Learning Rate: 0.0025\n",
      "Epoch [3104/20000], Loss: 121.09440612792969, Entropy -135.49026489257812, Learning Rate: 0.0025\n",
      "Epoch [3105/20000], Loss: 145.4640350341797, Entropy -168.80026245117188, Learning Rate: 0.0025\n",
      "Epoch [3106/20000], Loss: 131.79904174804688, Entropy -147.8297576904297, Learning Rate: 0.0025\n",
      "Epoch [3107/20000], Loss: 131.5568084716797, Entropy -162.90695190429688, Learning Rate: 0.0025\n",
      "Epoch [3108/20000], Loss: 127.60458374023438, Entropy -148.51434326171875, Learning Rate: 0.0025\n",
      "Epoch [3109/20000], Loss: 126.67041015625, Entropy -147.18165588378906, Learning Rate: 0.0025\n",
      "Epoch [3110/20000], Loss: 113.224609375, Entropy -132.44647216796875, Learning Rate: 0.0025\n",
      "Epoch [3111/20000], Loss: 133.5489501953125, Entropy -154.41180419921875, Learning Rate: 0.0025\n",
      "Epoch [3112/20000], Loss: 167.96458435058594, Entropy -138.4110107421875, Learning Rate: 0.0025\n",
      "Epoch [3113/20000], Loss: 125.57490539550781, Entropy -156.53408813476562, Learning Rate: 0.0025\n",
      "Epoch [3114/20000], Loss: 135.77157592773438, Entropy -156.37152099609375, Learning Rate: 0.0025\n",
      "Epoch [3115/20000], Loss: 121.857666015625, Entropy -134.84161376953125, Learning Rate: 0.0025\n",
      "Epoch [3116/20000], Loss: 118.56167602539062, Entropy -131.28912353515625, Learning Rate: 0.0025\n",
      "Epoch [3117/20000], Loss: 135.5145263671875, Entropy -166.6456298828125, Learning Rate: 0.0025\n",
      "Epoch [3118/20000], Loss: 141.7521209716797, Entropy -159.28280639648438, Learning Rate: 0.0025\n",
      "Epoch [3119/20000], Loss: 124.57269287109375, Entropy -144.12713623046875, Learning Rate: 0.0025\n",
      "Epoch [3120/20000], Loss: 128.58682250976562, Entropy -141.23776245117188, Learning Rate: 0.0025\n",
      "Epoch [3121/20000], Loss: 132.2246856689453, Entropy -148.510986328125, Learning Rate: 0.0025\n",
      "Epoch [3122/20000], Loss: 134.69241333007812, Entropy -154.04225158691406, Learning Rate: 0.0025\n",
      "Epoch [3123/20000], Loss: 128.08035278320312, Entropy -152.6717987060547, Learning Rate: 0.0025\n",
      "Epoch [3124/20000], Loss: 128.8682861328125, Entropy -140.919189453125, Learning Rate: 0.0025\n",
      "Epoch [3125/20000], Loss: 134.0479736328125, Entropy -159.92230224609375, Learning Rate: 0.0025\n",
      "Epoch [3126/20000], Loss: 142.23887634277344, Entropy -170.56704711914062, Learning Rate: 0.0025\n",
      "Epoch [3127/20000], Loss: 136.52406311035156, Entropy -160.30807495117188, Learning Rate: 0.0025\n",
      "Epoch [3128/20000], Loss: 145.77256774902344, Entropy -167.67874145507812, Learning Rate: 0.0025\n",
      "Epoch [3129/20000], Loss: 129.4221649169922, Entropy -153.467529296875, Learning Rate: 0.0025\n",
      "Epoch [3130/20000], Loss: 133.43612670898438, Entropy -141.77447509765625, Learning Rate: 0.0025\n",
      "Epoch [3131/20000], Loss: 123.161376953125, Entropy -145.7674560546875, Learning Rate: 0.0025\n",
      "Epoch [3132/20000], Loss: 131.23524475097656, Entropy -155.71893310546875, Learning Rate: 0.0025\n",
      "Epoch [3133/20000], Loss: 124.23635864257812, Entropy -142.472900390625, Learning Rate: 0.0025\n",
      "Epoch [3134/20000], Loss: 120.91334533691406, Entropy -143.52890014648438, Learning Rate: 0.0025\n",
      "Epoch [3135/20000], Loss: 129.21083068847656, Entropy -149.56246948242188, Learning Rate: 0.0025\n",
      "Epoch [3136/20000], Loss: 125.73358154296875, Entropy -142.40618896484375, Learning Rate: 0.0025\n",
      "Epoch [3137/20000], Loss: 122.09010314941406, Entropy -143.44100952148438, Learning Rate: 0.0025\n",
      "Epoch [3138/20000], Loss: 133.7264404296875, Entropy -168.71542358398438, Learning Rate: 0.0025\n",
      "Epoch [3139/20000], Loss: 119.91119384765625, Entropy -136.4960174560547, Learning Rate: 0.0025\n",
      "Epoch [3140/20000], Loss: 117.28083801269531, Entropy -133.4451141357422, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3141/20000], Loss: 124.03298950195312, Entropy -140.4762420654297, Learning Rate: 0.0025\n",
      "Epoch [3142/20000], Loss: 119.02178955078125, Entropy -146.19952392578125, Learning Rate: 0.0025\n",
      "Epoch [3143/20000], Loss: 135.82745361328125, Entropy -166.42404174804688, Learning Rate: 0.0025\n",
      "Epoch [3144/20000], Loss: 125.31510925292969, Entropy -145.87655639648438, Learning Rate: 0.0025\n",
      "Epoch [3145/20000], Loss: 122.59637451171875, Entropy -138.02500915527344, Learning Rate: 0.0025\n",
      "Epoch [3146/20000], Loss: 125.51376342773438, Entropy -146.12925720214844, Learning Rate: 0.0025\n",
      "Epoch [3147/20000], Loss: 132.61329650878906, Entropy -153.39370727539062, Learning Rate: 0.0025\n",
      "Epoch [3148/20000], Loss: 125.42823791503906, Entropy -143.32701110839844, Learning Rate: 0.0025\n",
      "Epoch [3149/20000], Loss: 129.57061767578125, Entropy -150.01670837402344, Learning Rate: 0.0025\n",
      "Epoch [3150/20000], Loss: 134.0171661376953, Entropy -151.94119262695312, Learning Rate: 0.0025\n",
      "Epoch [3151/20000], Loss: 116.49336242675781, Entropy -141.66851806640625, Learning Rate: 0.0025\n",
      "Epoch [3152/20000], Loss: 126.60079956054688, Entropy -148.87179565429688, Learning Rate: 0.0025\n",
      "Epoch [3153/20000], Loss: 130.24368286132812, Entropy -140.33840942382812, Learning Rate: 0.0025\n",
      "Epoch [3154/20000], Loss: 126.67680358886719, Entropy -144.90530395507812, Learning Rate: 0.0025\n",
      "Epoch [3155/20000], Loss: 116.29875183105469, Entropy -145.9655303955078, Learning Rate: 0.0025\n",
      "Epoch [3156/20000], Loss: 125.46664428710938, Entropy -143.0478515625, Learning Rate: 0.0025\n",
      "Epoch [3157/20000], Loss: 129.81671142578125, Entropy -149.76272583007812, Learning Rate: 0.0025\n",
      "Epoch [3158/20000], Loss: 135.69229125976562, Entropy -159.2816162109375, Learning Rate: 0.0025\n",
      "Epoch [3159/20000], Loss: 122.129150390625, Entropy -142.83920288085938, Learning Rate: 0.0025\n",
      "Epoch [3160/20000], Loss: 126.34738159179688, Entropy -146.47283935546875, Learning Rate: 0.0025\n",
      "Epoch [3161/20000], Loss: 120.22062683105469, Entropy -146.97994995117188, Learning Rate: 0.0025\n",
      "Epoch [3162/20000], Loss: 124.09385681152344, Entropy -147.12405395507812, Learning Rate: 0.0025\n",
      "Epoch [3163/20000], Loss: 114.54067993164062, Entropy -139.304931640625, Learning Rate: 0.0025\n",
      "Epoch [3164/20000], Loss: 123.41867065429688, Entropy -146.68898010253906, Learning Rate: 0.0025\n",
      "Epoch [3165/20000], Loss: 120.51724243164062, Entropy -137.4508514404297, Learning Rate: 0.0025\n",
      "Epoch [3166/20000], Loss: 138.52989196777344, Entropy -164.30865478515625, Learning Rate: 0.0025\n",
      "Epoch [3167/20000], Loss: 131.08334350585938, Entropy -151.19024658203125, Learning Rate: 0.0025\n",
      "Epoch [3168/20000], Loss: 133.70033264160156, Entropy -160.94061279296875, Learning Rate: 0.0025\n",
      "Epoch [3169/20000], Loss: 114.88377380371094, Entropy -130.3929443359375, Learning Rate: 0.0025\n",
      "Epoch [3170/20000], Loss: 123.0391845703125, Entropy -147.93649291992188, Learning Rate: 0.0025\n",
      "Epoch [3171/20000], Loss: 107.00486755371094, Entropy -126.19558715820312, Learning Rate: 0.0025\n",
      "Epoch [3172/20000], Loss: 130.6991424560547, Entropy -152.31814575195312, Learning Rate: 0.0025\n",
      "Epoch [3173/20000], Loss: 135.96852111816406, Entropy -165.8607635498047, Learning Rate: 0.0025\n",
      "Epoch [3174/20000], Loss: 129.39353942871094, Entropy -155.69654846191406, Learning Rate: 0.0025\n",
      "Epoch [3175/20000], Loss: 121.94772338867188, Entropy -147.06484985351562, Learning Rate: 0.0025\n",
      "Epoch [3176/20000], Loss: 115.87913513183594, Entropy -131.8159942626953, Learning Rate: 0.0025\n",
      "Epoch [3177/20000], Loss: 129.88763427734375, Entropy -159.14328002929688, Learning Rate: 0.0025\n",
      "Epoch [3178/20000], Loss: 119.561279296875, Entropy -148.9880828857422, Learning Rate: 0.0025\n",
      "Epoch [3179/20000], Loss: 126.98970031738281, Entropy -151.20858764648438, Learning Rate: 0.0025\n",
      "Epoch [3180/20000], Loss: 118.86839294433594, Entropy -143.8858642578125, Learning Rate: 0.0025\n",
      "Epoch [3181/20000], Loss: 123.4564208984375, Entropy -152.31573486328125, Learning Rate: 0.0025\n",
      "Epoch [3182/20000], Loss: 130.14524841308594, Entropy -153.79843139648438, Learning Rate: 0.0025\n",
      "Epoch [3183/20000], Loss: 126.25407409667969, Entropy -145.29702758789062, Learning Rate: 0.0025\n",
      "Epoch [3184/20000], Loss: 127.51727294921875, Entropy -147.44454956054688, Learning Rate: 0.0025\n",
      "Epoch [3185/20000], Loss: 112.28216552734375, Entropy -135.05093383789062, Learning Rate: 0.0025\n",
      "Epoch [3186/20000], Loss: 124.07403564453125, Entropy -144.8196258544922, Learning Rate: 0.0025\n",
      "Epoch [3187/20000], Loss: 115.55281066894531, Entropy -126.18507385253906, Learning Rate: 0.0025\n",
      "Epoch [3188/20000], Loss: 127.92219543457031, Entropy -155.14076232910156, Learning Rate: 0.0025\n",
      "Epoch [3189/20000], Loss: 118.9466552734375, Entropy -136.96131896972656, Learning Rate: 0.0025\n",
      "Epoch [3190/20000], Loss: 130.21482849121094, Entropy -148.4977569580078, Learning Rate: 0.0025\n",
      "Epoch [3191/20000], Loss: 132.28994750976562, Entropy -157.28427124023438, Learning Rate: 0.0025\n",
      "Epoch [3192/20000], Loss: 123.16093444824219, Entropy -141.2681884765625, Learning Rate: 0.0025\n",
      "Epoch [3193/20000], Loss: 130.56271362304688, Entropy -152.15480041503906, Learning Rate: 0.0025\n",
      "Epoch [3194/20000], Loss: 119.64767456054688, Entropy -142.82025146484375, Learning Rate: 0.0025\n",
      "Epoch [3195/20000], Loss: 124.1455078125, Entropy -146.90927124023438, Learning Rate: 0.0025\n",
      "Epoch [3196/20000], Loss: 139.2911376953125, Entropy -169.4364471435547, Learning Rate: 0.0025\n",
      "Epoch [3197/20000], Loss: 118.61564636230469, Entropy -138.14297485351562, Learning Rate: 0.0025\n",
      "Epoch [3198/20000], Loss: 136.40463256835938, Entropy -161.63616943359375, Learning Rate: 0.0025\n",
      "Epoch [3199/20000], Loss: 127.76617431640625, Entropy -153.73443603515625, Learning Rate: 0.0025\n",
      "Epoch [3200/20000], Loss: 133.3103485107422, Entropy -152.29483032226562, Learning Rate: 0.0025\n",
      "Epoch [3201/20000], Loss: 122.420654296875, Entropy -133.0183868408203, Learning Rate: 0.0025\n",
      "Epoch [3202/20000], Loss: 122.34706115722656, Entropy -144.16009521484375, Learning Rate: 0.0025\n",
      "Epoch [3203/20000], Loss: 126.8150634765625, Entropy -137.60671997070312, Learning Rate: 0.0025\n",
      "Epoch [3204/20000], Loss: 120.37348937988281, Entropy -142.44088745117188, Learning Rate: 0.0025\n",
      "Epoch [3205/20000], Loss: 127.50041198730469, Entropy -142.51046752929688, Learning Rate: 0.0025\n",
      "Epoch [3206/20000], Loss: 126.24771118164062, Entropy -145.03549194335938, Learning Rate: 0.0025\n",
      "Epoch [3207/20000], Loss: 127.1671142578125, Entropy -139.5171661376953, Learning Rate: 0.0025\n",
      "Epoch [3208/20000], Loss: 124.27458190917969, Entropy -141.36170959472656, Learning Rate: 0.0025\n",
      "Epoch [3209/20000], Loss: 117.03807067871094, Entropy -137.92349243164062, Learning Rate: 0.0025\n",
      "Epoch [3210/20000], Loss: 118.69190979003906, Entropy -128.62698364257812, Learning Rate: 0.0025\n",
      "Epoch [3211/20000], Loss: 125.40960693359375, Entropy -145.9508056640625, Learning Rate: 0.0025\n",
      "Epoch [3212/20000], Loss: 140.40951538085938, Entropy -173.95724487304688, Learning Rate: 0.0025\n",
      "Epoch [3213/20000], Loss: 117.58378601074219, Entropy -143.38250732421875, Learning Rate: 0.0025\n",
      "Epoch [3214/20000], Loss: 129.7276611328125, Entropy -144.8135986328125, Learning Rate: 0.0025\n",
      "Epoch [3215/20000], Loss: 119.81263732910156, Entropy -140.4573211669922, Learning Rate: 0.0025\n",
      "Epoch [3216/20000], Loss: 123.36811828613281, Entropy -142.63211059570312, Learning Rate: 0.0025\n",
      "Epoch [3217/20000], Loss: 123.83479309082031, Entropy -146.38320922851562, Learning Rate: 0.0025\n",
      "Epoch [3218/20000], Loss: 122.35641479492188, Entropy -147.71954345703125, Learning Rate: 0.0025\n",
      "Epoch [3219/20000], Loss: 131.4818115234375, Entropy -154.47659301757812, Learning Rate: 0.0025\n",
      "Epoch [3220/20000], Loss: 128.66358947753906, Entropy -145.96310424804688, Learning Rate: 0.0025\n",
      "Epoch [3221/20000], Loss: 118.83192443847656, Entropy -143.95040893554688, Learning Rate: 0.0025\n",
      "Epoch [3222/20000], Loss: 127.29942321777344, Entropy -146.7830810546875, Learning Rate: 0.0025\n",
      "Epoch [3223/20000], Loss: 135.6820068359375, Entropy -156.8580322265625, Learning Rate: 0.0025\n",
      "Epoch [3224/20000], Loss: 117.20686340332031, Entropy -140.6240997314453, Learning Rate: 0.0025\n",
      "Epoch [3225/20000], Loss: 124.08412170410156, Entropy -133.4925994873047, Learning Rate: 0.0025\n",
      "Epoch [3226/20000], Loss: 127.44364929199219, Entropy -147.11846923828125, Learning Rate: 0.0025\n",
      "Epoch [3227/20000], Loss: 123.96128845214844, Entropy -134.94351196289062, Learning Rate: 0.0025\n",
      "Epoch [3228/20000], Loss: 132.98056030273438, Entropy -166.2364501953125, Learning Rate: 0.0025\n",
      "Epoch [3229/20000], Loss: 121.15458679199219, Entropy -146.41558837890625, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3230/20000], Loss: 141.3225555419922, Entropy -164.83421325683594, Learning Rate: 0.0025\n",
      "Epoch [3231/20000], Loss: 122.71281433105469, Entropy -147.10592651367188, Learning Rate: 0.0025\n",
      "Epoch [3232/20000], Loss: 118.88943481445312, Entropy -135.64730834960938, Learning Rate: 0.0025\n",
      "Epoch [3233/20000], Loss: 124.00942993164062, Entropy -143.81011962890625, Learning Rate: 0.0025\n",
      "Epoch [3234/20000], Loss: 119.2760009765625, Entropy -138.01007080078125, Learning Rate: 0.0025\n",
      "Epoch [3235/20000], Loss: 145.70916748046875, Entropy -145.69979858398438, Learning Rate: 0.0025\n",
      "Epoch [3236/20000], Loss: 134.8194122314453, Entropy -166.60096740722656, Learning Rate: 0.0025\n",
      "Epoch [3237/20000], Loss: 125.48603820800781, Entropy -147.65414428710938, Learning Rate: 0.0025\n",
      "Epoch [3238/20000], Loss: 123.96209716796875, Entropy -144.21908569335938, Learning Rate: 0.0025\n",
      "Epoch [3239/20000], Loss: 120.90737915039062, Entropy -139.36483764648438, Learning Rate: 0.0025\n",
      "Epoch [3240/20000], Loss: 135.12423706054688, Entropy -158.39254760742188, Learning Rate: 0.0025\n",
      "Epoch [3241/20000], Loss: 135.66311645507812, Entropy -158.3789825439453, Learning Rate: 0.0025\n",
      "Epoch [3242/20000], Loss: 125.27053833007812, Entropy -145.15884399414062, Learning Rate: 0.0025\n",
      "Epoch [3243/20000], Loss: 124.00831604003906, Entropy -148.33912658691406, Learning Rate: 0.0025\n",
      "Epoch [3244/20000], Loss: 117.64059448242188, Entropy -134.1707305908203, Learning Rate: 0.0025\n",
      "Epoch [3245/20000], Loss: 133.52093505859375, Entropy -153.59707641601562, Learning Rate: 0.0025\n",
      "Epoch [3246/20000], Loss: 134.20701599121094, Entropy -165.23898315429688, Learning Rate: 0.0025\n",
      "Epoch [3247/20000], Loss: 121.56483459472656, Entropy -142.8451385498047, Learning Rate: 0.0025\n",
      "Epoch [3248/20000], Loss: 124.28456115722656, Entropy -134.52005004882812, Learning Rate: 0.0025\n",
      "Epoch [3249/20000], Loss: 128.3673858642578, Entropy -149.88583374023438, Learning Rate: 0.0025\n",
      "Epoch [3250/20000], Loss: 131.0335235595703, Entropy -146.81069946289062, Learning Rate: 0.0025\n",
      "Epoch [3251/20000], Loss: 127.77778625488281, Entropy -155.73065185546875, Learning Rate: 0.0025\n",
      "Epoch [3252/20000], Loss: 119.57998657226562, Entropy -146.55938720703125, Learning Rate: 0.0025\n",
      "Epoch [3253/20000], Loss: 122.60287475585938, Entropy -140.6779327392578, Learning Rate: 0.0025\n",
      "Epoch [3254/20000], Loss: 123.69743347167969, Entropy -144.96969604492188, Learning Rate: 0.0025\n",
      "Epoch [3255/20000], Loss: 122.50746154785156, Entropy -140.0133056640625, Learning Rate: 0.0025\n",
      "Epoch [3256/20000], Loss: 124.28819274902344, Entropy -145.13278198242188, Learning Rate: 0.0025\n",
      "Epoch [3257/20000], Loss: 121.82965087890625, Entropy -145.50074768066406, Learning Rate: 0.0025\n",
      "Epoch [3258/20000], Loss: 126.831787109375, Entropy -154.12481689453125, Learning Rate: 0.0025\n",
      "Epoch [3259/20000], Loss: 126.35940551757812, Entropy -150.32533264160156, Learning Rate: 0.0025\n",
      "Epoch [3260/20000], Loss: 124.77578735351562, Entropy -149.66754150390625, Learning Rate: 0.0025\n",
      "Epoch [3261/20000], Loss: 124.84019470214844, Entropy -159.1903839111328, Learning Rate: 0.0025\n",
      "Epoch [3262/20000], Loss: 129.00967407226562, Entropy -153.34031677246094, Learning Rate: 0.0025\n",
      "Epoch [3263/20000], Loss: 117.92233276367188, Entropy -139.6389923095703, Learning Rate: 0.0025\n",
      "Epoch [3264/20000], Loss: 135.54168701171875, Entropy -164.17581176757812, Learning Rate: 0.0025\n",
      "Epoch [3265/20000], Loss: 125.26132202148438, Entropy -145.87100219726562, Learning Rate: 0.0025\n",
      "Epoch [3266/20000], Loss: 124.45265197753906, Entropy -134.56210327148438, Learning Rate: 0.0025\n",
      "Epoch [3267/20000], Loss: 132.12448120117188, Entropy -152.68292236328125, Learning Rate: 0.0025\n",
      "Epoch [3268/20000], Loss: 116.42005920410156, Entropy -140.19985961914062, Learning Rate: 0.0025\n",
      "Epoch [3269/20000], Loss: 123.07655334472656, Entropy -142.42184448242188, Learning Rate: 0.0025\n",
      "Epoch [3270/20000], Loss: 117.78602600097656, Entropy -141.7162628173828, Learning Rate: 0.0025\n",
      "Epoch [3271/20000], Loss: 124.73269653320312, Entropy -148.25975036621094, Learning Rate: 0.0025\n",
      "Epoch [3272/20000], Loss: 115.1783447265625, Entropy -130.22291564941406, Learning Rate: 0.0025\n",
      "Epoch [3273/20000], Loss: 135.4313507080078, Entropy -159.03932189941406, Learning Rate: 0.0025\n",
      "Epoch [3274/20000], Loss: 119.91952514648438, Entropy -139.5631103515625, Learning Rate: 0.0025\n",
      "Epoch [3275/20000], Loss: 123.32148742675781, Entropy -148.99710083007812, Learning Rate: 0.0025\n",
      "Epoch [3276/20000], Loss: 118.71678161621094, Entropy -133.43435668945312, Learning Rate: 0.0025\n",
      "Epoch [3277/20000], Loss: 124.04046630859375, Entropy -146.87420654296875, Learning Rate: 0.0025\n",
      "Epoch [3278/20000], Loss: 127.19184875488281, Entropy -139.04776000976562, Learning Rate: 0.0025\n",
      "Epoch [3279/20000], Loss: 136.90078735351562, Entropy -157.8852996826172, Learning Rate: 0.0025\n",
      "Epoch [3280/20000], Loss: 127.42381286621094, Entropy -149.55392456054688, Learning Rate: 0.0025\n",
      "Epoch [3281/20000], Loss: 111.88662719726562, Entropy -127.88711547851562, Learning Rate: 0.0025\n",
      "Epoch [3282/20000], Loss: 116.40496826171875, Entropy -143.89779663085938, Learning Rate: 0.0025\n",
      "Epoch [3283/20000], Loss: 129.27732849121094, Entropy -156.04025268554688, Learning Rate: 0.0025\n",
      "Epoch [3284/20000], Loss: 120.63258361816406, Entropy -130.74769592285156, Learning Rate: 0.0025\n",
      "Epoch [3285/20000], Loss: 121.37066650390625, Entropy -145.08615112304688, Learning Rate: 0.0025\n",
      "Epoch [3286/20000], Loss: 131.43063354492188, Entropy -146.3317413330078, Learning Rate: 0.0025\n",
      "Epoch [3287/20000], Loss: 123.88380432128906, Entropy -145.1306610107422, Learning Rate: 0.0025\n",
      "Epoch [3288/20000], Loss: 125.78302001953125, Entropy -148.55850219726562, Learning Rate: 0.0025\n",
      "Epoch [3289/20000], Loss: 132.66075134277344, Entropy -147.74310302734375, Learning Rate: 0.0025\n",
      "Epoch [3290/20000], Loss: 115.00198364257812, Entropy -137.06927490234375, Learning Rate: 0.0025\n",
      "Epoch [3291/20000], Loss: 117.35696411132812, Entropy -136.57159423828125, Learning Rate: 0.0025\n",
      "Epoch [3292/20000], Loss: 136.11341857910156, Entropy -156.11416625976562, Learning Rate: 0.0025\n",
      "Epoch [3293/20000], Loss: 133.66348266601562, Entropy -157.94198608398438, Learning Rate: 0.0025\n",
      "Epoch [3294/20000], Loss: 113.39874267578125, Entropy -120.51112365722656, Learning Rate: 0.0025\n",
      "Epoch [3295/20000], Loss: 125.90110778808594, Entropy -150.68771362304688, Learning Rate: 0.0025\n",
      "Epoch [3296/20000], Loss: 126.51170349121094, Entropy -149.23541259765625, Learning Rate: 0.0025\n",
      "Epoch [3297/20000], Loss: 132.474365234375, Entropy -156.787109375, Learning Rate: 0.0025\n",
      "Epoch [3298/20000], Loss: 127.86924743652344, Entropy -154.4117889404297, Learning Rate: 0.0025\n",
      "Epoch [3299/20000], Loss: 116.75294494628906, Entropy -136.86570739746094, Learning Rate: 0.0025\n",
      "Epoch [3300/20000], Loss: 130.67337036132812, Entropy -155.9977569580078, Learning Rate: 0.0025\n",
      "Epoch [3301/20000], Loss: 117.13737487792969, Entropy -138.48876953125, Learning Rate: 0.0025\n",
      "Epoch [3302/20000], Loss: 118.81814575195312, Entropy -140.9180908203125, Learning Rate: 0.0025\n",
      "Epoch [3303/20000], Loss: 130.352783203125, Entropy -152.5099639892578, Learning Rate: 0.0025\n",
      "Epoch [3304/20000], Loss: 119.87779235839844, Entropy -138.94537353515625, Learning Rate: 0.0025\n",
      "Epoch [3305/20000], Loss: 131.2799530029297, Entropy -153.53797912597656, Learning Rate: 0.0025\n",
      "Epoch [3306/20000], Loss: 121.25007629394531, Entropy -145.681884765625, Learning Rate: 0.0025\n",
      "Epoch [3307/20000], Loss: 122.51492309570312, Entropy -134.01771545410156, Learning Rate: 0.0025\n",
      "Epoch [3308/20000], Loss: 122.98347473144531, Entropy -144.34527587890625, Learning Rate: 0.0025\n",
      "Epoch [3309/20000], Loss: 117.73306274414062, Entropy -131.82766723632812, Learning Rate: 0.0025\n",
      "Epoch [3310/20000], Loss: 133.7649688720703, Entropy -155.10302734375, Learning Rate: 0.0025\n",
      "Epoch [3311/20000], Loss: 128.49386596679688, Entropy -150.7869873046875, Learning Rate: 0.0025\n",
      "Epoch [3312/20000], Loss: 134.3040313720703, Entropy -156.32516479492188, Learning Rate: 0.0025\n",
      "Epoch [3313/20000], Loss: 116.03691101074219, Entropy -137.17880249023438, Learning Rate: 0.0025\n",
      "Epoch [3314/20000], Loss: 129.40634155273438, Entropy -156.61248779296875, Learning Rate: 0.0025\n",
      "Epoch [3315/20000], Loss: 126.25547790527344, Entropy -149.923828125, Learning Rate: 0.0025\n",
      "Epoch [3316/20000], Loss: 124.76300048828125, Entropy -144.9041748046875, Learning Rate: 0.0025\n",
      "Epoch [3317/20000], Loss: 119.00044250488281, Entropy -130.5321807861328, Learning Rate: 0.0025\n",
      "Epoch [3318/20000], Loss: 116.91841125488281, Entropy -131.11151123046875, Learning Rate: 0.0025\n",
      "Epoch [3319/20000], Loss: 111.01469421386719, Entropy -130.3973388671875, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3320/20000], Loss: 118.80426025390625, Entropy -135.47393798828125, Learning Rate: 0.0025\n",
      "Epoch [3321/20000], Loss: 128.9669189453125, Entropy -141.9149627685547, Learning Rate: 0.0025\n",
      "Epoch [3322/20000], Loss: 116.69203186035156, Entropy -134.6971435546875, Learning Rate: 0.0025\n",
      "Epoch [3323/20000], Loss: 124.24752807617188, Entropy -149.4829864501953, Learning Rate: 0.0025\n",
      "Epoch [3324/20000], Loss: 113.93440246582031, Entropy -137.02938842773438, Learning Rate: 0.0025\n",
      "Epoch [3325/20000], Loss: 124.02058410644531, Entropy -154.22813415527344, Learning Rate: 0.0025\n",
      "Epoch [3326/20000], Loss: 122.57754516601562, Entropy -148.13040161132812, Learning Rate: 0.0025\n",
      "Epoch [3327/20000], Loss: 131.85643005371094, Entropy -164.07521057128906, Learning Rate: 0.0025\n",
      "Epoch [3328/20000], Loss: 121.33999633789062, Entropy -131.14126586914062, Learning Rate: 0.0025\n",
      "Epoch [3329/20000], Loss: 124.78660583496094, Entropy -148.6207275390625, Learning Rate: 0.0025\n",
      "Epoch [3330/20000], Loss: 132.6009979248047, Entropy -144.9186553955078, Learning Rate: 0.0025\n",
      "Epoch [3331/20000], Loss: 122.89933776855469, Entropy -144.2982177734375, Learning Rate: 0.0025\n",
      "Epoch [3332/20000], Loss: 122.39045715332031, Entropy -138.65415954589844, Learning Rate: 0.0025\n",
      "Epoch [3333/20000], Loss: 127.18075561523438, Entropy -152.83274841308594, Learning Rate: 0.0025\n",
      "Epoch [3334/20000], Loss: 125.41075134277344, Entropy -145.30032348632812, Learning Rate: 0.0025\n",
      "Epoch [3335/20000], Loss: 117.56500244140625, Entropy -139.26296997070312, Learning Rate: 0.0025\n",
      "Epoch [3336/20000], Loss: 124.77146911621094, Entropy -143.4859619140625, Learning Rate: 0.0025\n",
      "Epoch [3337/20000], Loss: 119.94821166992188, Entropy -141.70849609375, Learning Rate: 0.0025\n",
      "Epoch [3338/20000], Loss: 118.14381408691406, Entropy -143.7616424560547, Learning Rate: 0.0025\n",
      "Epoch [3339/20000], Loss: 119.18989562988281, Entropy -142.31692504882812, Learning Rate: 0.0025\n",
      "Epoch [3340/20000], Loss: 140.47064208984375, Entropy -171.29608154296875, Learning Rate: 0.0025\n",
      "Epoch [3341/20000], Loss: 120.04872131347656, Entropy -139.85789489746094, Learning Rate: 0.0025\n",
      "Epoch [3342/20000], Loss: 134.25892639160156, Entropy -157.16761779785156, Learning Rate: 0.0025\n",
      "Epoch [3343/20000], Loss: 116.66545104980469, Entropy -139.36024475097656, Learning Rate: 0.0025\n",
      "Epoch [3344/20000], Loss: 126.51994323730469, Entropy -147.73150634765625, Learning Rate: 0.0025\n",
      "Epoch [3345/20000], Loss: 119.04570007324219, Entropy -145.5872802734375, Learning Rate: 0.0025\n",
      "Epoch [3346/20000], Loss: 124.47140502929688, Entropy -151.30050659179688, Learning Rate: 0.0025\n",
      "Epoch [3347/20000], Loss: 130.11289978027344, Entropy -147.2357940673828, Learning Rate: 0.0025\n",
      "Epoch [3348/20000], Loss: 123.6688232421875, Entropy -143.1883544921875, Learning Rate: 0.0025\n",
      "Epoch [3349/20000], Loss: 113.988037109375, Entropy -138.55120849609375, Learning Rate: 0.0025\n",
      "Epoch [3350/20000], Loss: 124.97462463378906, Entropy -136.5174560546875, Learning Rate: 0.0025\n",
      "Epoch [3351/20000], Loss: 124.006103515625, Entropy -142.55517578125, Learning Rate: 0.0025\n",
      "Epoch [3352/20000], Loss: 123.19509887695312, Entropy -147.55804443359375, Learning Rate: 0.0025\n",
      "Epoch [3353/20000], Loss: 126.76649475097656, Entropy -149.8314666748047, Learning Rate: 0.0025\n",
      "Epoch [3354/20000], Loss: 127.66154479980469, Entropy -155.68711853027344, Learning Rate: 0.0025\n",
      "Epoch [3355/20000], Loss: 116.03021240234375, Entropy -137.95901489257812, Learning Rate: 0.0025\n",
      "Epoch [3356/20000], Loss: 127.20716857910156, Entropy -143.71136474609375, Learning Rate: 0.0025\n",
      "Epoch [3357/20000], Loss: 124.10728454589844, Entropy -150.1103515625, Learning Rate: 0.0025\n",
      "Epoch [3358/20000], Loss: 127.20779418945312, Entropy -144.53009033203125, Learning Rate: 0.0025\n",
      "Epoch [3359/20000], Loss: 127.23863220214844, Entropy -145.8380126953125, Learning Rate: 0.0025\n",
      "Epoch [3360/20000], Loss: 124.06727600097656, Entropy -144.5579833984375, Learning Rate: 0.0025\n",
      "Epoch [3361/20000], Loss: 123.70712280273438, Entropy -146.6930389404297, Learning Rate: 0.0025\n",
      "Epoch [3362/20000], Loss: 128.576904296875, Entropy -154.7511444091797, Learning Rate: 0.0025\n",
      "Epoch [3363/20000], Loss: 129.70278930664062, Entropy -148.5835723876953, Learning Rate: 0.0025\n",
      "Epoch [3364/20000], Loss: 120.18963623046875, Entropy -138.6348114013672, Learning Rate: 0.0025\n",
      "Epoch [3365/20000], Loss: 118.4871826171875, Entropy -138.2520294189453, Learning Rate: 0.0025\n",
      "Epoch [3366/20000], Loss: 120.56475830078125, Entropy -143.34092712402344, Learning Rate: 0.0025\n",
      "Epoch [3367/20000], Loss: 126.9107666015625, Entropy -159.75930786132812, Learning Rate: 0.0025\n",
      "Epoch [3368/20000], Loss: 129.11888122558594, Entropy -152.84190368652344, Learning Rate: 0.0025\n",
      "Epoch [3369/20000], Loss: 131.45310974121094, Entropy -159.5342254638672, Learning Rate: 0.0025\n",
      "Epoch [3370/20000], Loss: 121.67886352539062, Entropy -144.159912109375, Learning Rate: 0.0025\n",
      "Epoch [3371/20000], Loss: 129.06057739257812, Entropy -140.2119598388672, Learning Rate: 0.0025\n",
      "Epoch [3372/20000], Loss: 120.45039367675781, Entropy -131.08197021484375, Learning Rate: 0.0025\n",
      "Epoch [3373/20000], Loss: 118.2674560546875, Entropy -133.64501953125, Learning Rate: 0.00125\n",
      "Epoch [3374/20000], Loss: 131.9366455078125, Entropy -154.15032958984375, Learning Rate: 0.00125\n",
      "Epoch [3375/20000], Loss: 117.1226806640625, Entropy -135.18408203125, Learning Rate: 0.00125\n",
      "Epoch [3376/20000], Loss: 125.54020690917969, Entropy -146.05682373046875, Learning Rate: 0.00125\n",
      "Epoch [3377/20000], Loss: 126.47135925292969, Entropy -141.77679443359375, Learning Rate: 0.00125\n",
      "Epoch [3378/20000], Loss: 121.04850769042969, Entropy -151.2508544921875, Learning Rate: 0.00125\n",
      "Epoch [3379/20000], Loss: 121.26396179199219, Entropy -140.78514099121094, Learning Rate: 0.00125\n",
      "Epoch [3380/20000], Loss: 130.00363159179688, Entropy -156.40663146972656, Learning Rate: 0.00125\n",
      "Epoch [3381/20000], Loss: 114.37535095214844, Entropy -138.97222900390625, Learning Rate: 0.00125\n",
      "Epoch [3382/20000], Loss: 127.04034423828125, Entropy -152.40945434570312, Learning Rate: 0.00125\n",
      "Epoch [3383/20000], Loss: 132.92466735839844, Entropy -163.77194213867188, Learning Rate: 0.00125\n",
      "Epoch [3384/20000], Loss: 118.80679321289062, Entropy -146.978271484375, Learning Rate: 0.00125\n",
      "Epoch [3385/20000], Loss: 125.40290832519531, Entropy -148.7182159423828, Learning Rate: 0.00125\n",
      "Epoch [3386/20000], Loss: 122.84718322753906, Entropy -142.8273162841797, Learning Rate: 0.00125\n",
      "Epoch [3387/20000], Loss: 117.90754699707031, Entropy -141.77186584472656, Learning Rate: 0.00125\n",
      "Epoch [3388/20000], Loss: 160.1944580078125, Entropy -131.94789123535156, Learning Rate: 0.00125\n",
      "Epoch [3389/20000], Loss: 126.82078552246094, Entropy -155.53106689453125, Learning Rate: 0.00125\n",
      "Epoch [3390/20000], Loss: 123.80218505859375, Entropy -139.7095947265625, Learning Rate: 0.00125\n",
      "Epoch [3391/20000], Loss: 123.54403686523438, Entropy -145.555908203125, Learning Rate: 0.00125\n",
      "Epoch [3392/20000], Loss: 126.83404541015625, Entropy -141.70404052734375, Learning Rate: 0.00125\n",
      "Epoch [3393/20000], Loss: 125.63641357421875, Entropy -143.89361572265625, Learning Rate: 0.00125\n",
      "Epoch [3394/20000], Loss: 115.23104858398438, Entropy -137.0408935546875, Learning Rate: 0.00125\n",
      "Epoch [3395/20000], Loss: 122.30799865722656, Entropy -139.57118225097656, Learning Rate: 0.00125\n",
      "Epoch [3396/20000], Loss: 131.418212890625, Entropy -148.49874877929688, Learning Rate: 0.00125\n",
      "Epoch [3397/20000], Loss: 118.53997802734375, Entropy -129.74688720703125, Learning Rate: 0.00125\n",
      "Epoch [3398/20000], Loss: 125.04115295410156, Entropy -141.7376708984375, Learning Rate: 0.00125\n",
      "Epoch [3399/20000], Loss: 138.47572326660156, Entropy -162.78448486328125, Learning Rate: 0.00125\n",
      "Epoch [3400/20000], Loss: 141.07302856445312, Entropy -165.8664093017578, Learning Rate: 0.00125\n",
      "Epoch [3401/20000], Loss: 124.41963195800781, Entropy -137.1634521484375, Learning Rate: 0.00125\n",
      "Epoch [3402/20000], Loss: 117.32121276855469, Entropy -139.81082153320312, Learning Rate: 0.00125\n",
      "Epoch [3403/20000], Loss: 124.98638916015625, Entropy -143.63116455078125, Learning Rate: 0.00125\n",
      "Epoch [3404/20000], Loss: 118.72813415527344, Entropy -130.88320922851562, Learning Rate: 0.00125\n",
      "Epoch [3405/20000], Loss: 128.9707489013672, Entropy -149.06448364257812, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3406/20000], Loss: 126.32173156738281, Entropy -151.4908447265625, Learning Rate: 0.00125\n",
      "Epoch [3407/20000], Loss: 110.39753723144531, Entropy -128.39939880371094, Learning Rate: 0.00125\n",
      "Epoch [3408/20000], Loss: 120.60157775878906, Entropy -141.8099365234375, Learning Rate: 0.00125\n",
      "Epoch [3409/20000], Loss: 135.62655639648438, Entropy -165.44581604003906, Learning Rate: 0.00125\n",
      "Epoch [3410/20000], Loss: 123.25535583496094, Entropy -147.67613220214844, Learning Rate: 0.00125\n",
      "Epoch [3411/20000], Loss: 137.70806884765625, Entropy -163.59555053710938, Learning Rate: 0.00125\n",
      "Epoch [3412/20000], Loss: 120.40765380859375, Entropy -144.6522979736328, Learning Rate: 0.00125\n",
      "Epoch [3413/20000], Loss: 126.41720581054688, Entropy -144.1259002685547, Learning Rate: 0.00125\n",
      "Epoch [3414/20000], Loss: 125.72103881835938, Entropy -149.98370361328125, Learning Rate: 0.00125\n",
      "Epoch [3415/20000], Loss: 119.02554321289062, Entropy -136.84561157226562, Learning Rate: 0.00125\n",
      "Epoch [3416/20000], Loss: 129.5028076171875, Entropy -151.02285766601562, Learning Rate: 0.00125\n",
      "Epoch [3417/20000], Loss: 124.11007690429688, Entropy -146.73748779296875, Learning Rate: 0.00125\n",
      "Epoch [3418/20000], Loss: 121.26127624511719, Entropy -142.08995056152344, Learning Rate: 0.00125\n",
      "Epoch [3419/20000], Loss: 121.79191589355469, Entropy -146.86434936523438, Learning Rate: 0.00125\n",
      "Epoch [3420/20000], Loss: 128.24351501464844, Entropy -158.14877319335938, Learning Rate: 0.00125\n",
      "Epoch [3421/20000], Loss: 113.99467468261719, Entropy -136.95748901367188, Learning Rate: 0.00125\n",
      "Epoch [3422/20000], Loss: 131.2887725830078, Entropy -161.24227905273438, Learning Rate: 0.00125\n",
      "Epoch [3423/20000], Loss: 126.14590454101562, Entropy -153.05880737304688, Learning Rate: 0.00125\n",
      "Epoch [3424/20000], Loss: 125.00181579589844, Entropy -149.34716796875, Learning Rate: 0.00125\n",
      "Epoch [3425/20000], Loss: 142.93307495117188, Entropy -173.63644409179688, Learning Rate: 0.00125\n",
      "Epoch [3426/20000], Loss: 125.37527465820312, Entropy -147.59158325195312, Learning Rate: 0.00125\n",
      "Epoch [3427/20000], Loss: 117.32322692871094, Entropy -133.8982391357422, Learning Rate: 0.00125\n",
      "Epoch [3428/20000], Loss: 120.56282043457031, Entropy -138.80789184570312, Learning Rate: 0.00125\n",
      "Epoch [3429/20000], Loss: 112.58816528320312, Entropy -129.51368713378906, Learning Rate: 0.00125\n",
      "Epoch [3430/20000], Loss: 121.54705810546875, Entropy -143.40106201171875, Learning Rate: 0.00125\n",
      "Epoch [3431/20000], Loss: 126.92869567871094, Entropy -150.84841918945312, Learning Rate: 0.00125\n",
      "Epoch [3432/20000], Loss: 116.10746765136719, Entropy -139.66070556640625, Learning Rate: 0.00125\n",
      "Epoch [3433/20000], Loss: 116.56791687011719, Entropy -135.09336853027344, Learning Rate: 0.00125\n",
      "Epoch [3434/20000], Loss: 122.88761901855469, Entropy -143.56536865234375, Learning Rate: 0.00125\n",
      "Epoch [3435/20000], Loss: 121.63934326171875, Entropy -136.58078002929688, Learning Rate: 0.00125\n",
      "Epoch [3436/20000], Loss: 123.45257568359375, Entropy -144.58016967773438, Learning Rate: 0.00125\n",
      "Epoch [3437/20000], Loss: 134.49679565429688, Entropy -153.04946899414062, Learning Rate: 0.00125\n",
      "Epoch [3438/20000], Loss: 122.5513916015625, Entropy -143.1441650390625, Learning Rate: 0.00125\n",
      "Epoch [3439/20000], Loss: 116.96287536621094, Entropy -133.02713012695312, Learning Rate: 0.00125\n",
      "Epoch [3440/20000], Loss: 111.9193115234375, Entropy -132.40225219726562, Learning Rate: 0.00125\n",
      "Epoch [3441/20000], Loss: 113.31526184082031, Entropy -134.8319091796875, Learning Rate: 0.00125\n",
      "Epoch [3442/20000], Loss: 124.90617370605469, Entropy -147.20184326171875, Learning Rate: 0.00125\n",
      "Epoch [3443/20000], Loss: 126.98495483398438, Entropy -140.55810546875, Learning Rate: 0.00125\n",
      "Epoch [3444/20000], Loss: 120.77081298828125, Entropy -148.8565673828125, Learning Rate: 0.00125\n",
      "Epoch [3445/20000], Loss: 116.60214233398438, Entropy -138.77456665039062, Learning Rate: 0.00125\n",
      "Epoch [3446/20000], Loss: 120.71717834472656, Entropy -146.87326049804688, Learning Rate: 0.00125\n",
      "Epoch [3447/20000], Loss: 127.39314270019531, Entropy -148.93878173828125, Learning Rate: 0.00125\n",
      "Epoch [3448/20000], Loss: 126.82823181152344, Entropy -151.05543518066406, Learning Rate: 0.00125\n",
      "Epoch [3449/20000], Loss: 122.48231506347656, Entropy -149.9671630859375, Learning Rate: 0.00125\n",
      "Epoch [3450/20000], Loss: 121.2872314453125, Entropy -141.79135131835938, Learning Rate: 0.00125\n",
      "Epoch [3451/20000], Loss: 128.88131713867188, Entropy -147.4598388671875, Learning Rate: 0.00125\n",
      "Epoch [3452/20000], Loss: 128.83334350585938, Entropy -155.7476043701172, Learning Rate: 0.00125\n",
      "Epoch [3453/20000], Loss: 124.08140563964844, Entropy -153.355712890625, Learning Rate: 0.00125\n",
      "Epoch [3454/20000], Loss: 134.87144470214844, Entropy -161.23129272460938, Learning Rate: 0.00125\n",
      "Epoch [3455/20000], Loss: 127.34342956542969, Entropy -151.73666381835938, Learning Rate: 0.00125\n",
      "Epoch [3456/20000], Loss: 121.65591430664062, Entropy -143.13339233398438, Learning Rate: 0.00125\n",
      "Epoch [3457/20000], Loss: 121.00062561035156, Entropy -144.4282989501953, Learning Rate: 0.00125\n",
      "Epoch [3458/20000], Loss: 127.62345886230469, Entropy -147.21292114257812, Learning Rate: 0.00125\n",
      "Epoch [3459/20000], Loss: 123.49081420898438, Entropy -145.82867431640625, Learning Rate: 0.00125\n",
      "Epoch [3460/20000], Loss: 125.48818969726562, Entropy -148.8466796875, Learning Rate: 0.00125\n",
      "Epoch [3461/20000], Loss: 115.56599426269531, Entropy -134.56146240234375, Learning Rate: 0.00125\n",
      "Epoch [3462/20000], Loss: 126.91680908203125, Entropy -147.69143676757812, Learning Rate: 0.00125\n",
      "Epoch [3463/20000], Loss: 120.53140258789062, Entropy -129.78521728515625, Learning Rate: 0.00125\n",
      "Epoch [3464/20000], Loss: 123.88809204101562, Entropy -142.96893310546875, Learning Rate: 0.00125\n",
      "Epoch [3465/20000], Loss: 128.37782287597656, Entropy -153.50906372070312, Learning Rate: 0.00125\n",
      "Epoch [3466/20000], Loss: 113.91702270507812, Entropy -138.45578002929688, Learning Rate: 0.00125\n",
      "Epoch [3467/20000], Loss: 125.55117797851562, Entropy -145.0245361328125, Learning Rate: 0.00125\n",
      "Epoch [3468/20000], Loss: 114.724853515625, Entropy -140.188232421875, Learning Rate: 0.00125\n",
      "Epoch [3469/20000], Loss: 109.64923095703125, Entropy -118.71575927734375, Learning Rate: 0.00125\n",
      "Epoch [3470/20000], Loss: 115.92442321777344, Entropy -127.12228393554688, Learning Rate: 0.00125\n",
      "Epoch [3471/20000], Loss: 121.19125366210938, Entropy -142.7696533203125, Learning Rate: 0.00125\n",
      "Epoch [3472/20000], Loss: 123.7232666015625, Entropy -150.85250854492188, Learning Rate: 0.00125\n",
      "Epoch [3473/20000], Loss: 124.52102661132812, Entropy -152.00762939453125, Learning Rate: 0.00125\n",
      "Epoch [3474/20000], Loss: 120.88179016113281, Entropy -143.1905517578125, Learning Rate: 0.00125\n",
      "Epoch [3475/20000], Loss: 122.91964721679688, Entropy -143.06947326660156, Learning Rate: 0.00125\n",
      "Epoch [3476/20000], Loss: 121.83099365234375, Entropy -138.76156616210938, Learning Rate: 0.00125\n",
      "Epoch [3477/20000], Loss: 117.66914367675781, Entropy -139.78323364257812, Learning Rate: 0.00125\n",
      "Epoch [3478/20000], Loss: 119.72193908691406, Entropy -145.70664978027344, Learning Rate: 0.00125\n",
      "Epoch [3479/20000], Loss: 134.09814453125, Entropy -160.56246948242188, Learning Rate: 0.00125\n",
      "Epoch [3480/20000], Loss: 124.91621398925781, Entropy -142.55422973632812, Learning Rate: 0.00125\n",
      "Epoch [3481/20000], Loss: 113.72555541992188, Entropy -133.6100616455078, Learning Rate: 0.00125\n",
      "Epoch [3482/20000], Loss: 117.82208251953125, Entropy -143.17816162109375, Learning Rate: 0.00125\n",
      "Epoch [3483/20000], Loss: 128.7923583984375, Entropy -140.64385986328125, Learning Rate: 0.00125\n",
      "Epoch [3484/20000], Loss: 128.67308044433594, Entropy -152.98898315429688, Learning Rate: 0.00125\n",
      "Epoch [3485/20000], Loss: 117.68040466308594, Entropy -138.9893798828125, Learning Rate: 0.00125\n",
      "Epoch [3486/20000], Loss: 121.17698669433594, Entropy -133.26083374023438, Learning Rate: 0.00125\n",
      "Epoch [3487/20000], Loss: 111.66519165039062, Entropy -129.34271240234375, Learning Rate: 0.00125\n",
      "Epoch [3488/20000], Loss: 118.86592102050781, Entropy -145.29685974121094, Learning Rate: 0.00125\n",
      "Epoch [3489/20000], Loss: 125.57225036621094, Entropy -145.17703247070312, Learning Rate: 0.00125\n",
      "Epoch [3490/20000], Loss: 121.91923522949219, Entropy -140.46298217773438, Learning Rate: 0.00125\n",
      "Epoch [3491/20000], Loss: 129.54823303222656, Entropy -152.11460876464844, Learning Rate: 0.00125\n",
      "Epoch [3492/20000], Loss: 114.94354248046875, Entropy -132.75567626953125, Learning Rate: 0.00125\n",
      "Epoch [3493/20000], Loss: 111.90827941894531, Entropy -128.83160400390625, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3494/20000], Loss: 128.9147186279297, Entropy -160.27569580078125, Learning Rate: 0.00125\n",
      "Epoch [3495/20000], Loss: 113.81968688964844, Entropy -142.48052978515625, Learning Rate: 0.00125\n",
      "Epoch [3496/20000], Loss: 130.70889282226562, Entropy -157.80853271484375, Learning Rate: 0.00125\n",
      "Epoch [3497/20000], Loss: 126.11723327636719, Entropy -147.2210693359375, Learning Rate: 0.00125\n",
      "Epoch [3498/20000], Loss: 128.5693817138672, Entropy -156.3443603515625, Learning Rate: 0.00125\n",
      "Epoch [3499/20000], Loss: 128.11651611328125, Entropy -152.81625366210938, Learning Rate: 0.00125\n",
      "Epoch [3500/20000], Loss: 116.83705139160156, Entropy -119.34443664550781, Learning Rate: 0.00125\n",
      "Epoch [3501/20000], Loss: 122.87669372558594, Entropy -146.73809814453125, Learning Rate: 0.00125\n",
      "Epoch [3502/20000], Loss: 114.4471435546875, Entropy -133.53192138671875, Learning Rate: 0.00125\n",
      "Epoch [3503/20000], Loss: 116.94088745117188, Entropy -137.91885375976562, Learning Rate: 0.00125\n",
      "Epoch [3504/20000], Loss: 118.70658874511719, Entropy -141.6248321533203, Learning Rate: 0.00125\n",
      "Epoch [3505/20000], Loss: 123.09178161621094, Entropy -145.44302368164062, Learning Rate: 0.00125\n",
      "Epoch [3506/20000], Loss: 122.63523864746094, Entropy -144.51199340820312, Learning Rate: 0.00125\n",
      "Epoch [3507/20000], Loss: 118.04782104492188, Entropy -137.72634887695312, Learning Rate: 0.00125\n",
      "Epoch [3508/20000], Loss: 122.17555236816406, Entropy -150.64117431640625, Learning Rate: 0.00125\n",
      "Epoch [3509/20000], Loss: 121.31959533691406, Entropy -141.64138793945312, Learning Rate: 0.00125\n",
      "Epoch [3510/20000], Loss: 129.81466674804688, Entropy -157.25143432617188, Learning Rate: 0.00125\n",
      "Epoch [3511/20000], Loss: 119.31355285644531, Entropy -148.62704467773438, Learning Rate: 0.00125\n",
      "Epoch [3512/20000], Loss: 118.98036193847656, Entropy -141.38963317871094, Learning Rate: 0.00125\n",
      "Epoch [3513/20000], Loss: 115.54055786132812, Entropy -135.60426330566406, Learning Rate: 0.00125\n",
      "Epoch [3514/20000], Loss: 133.06494140625, Entropy -146.66046142578125, Learning Rate: 0.00125\n",
      "Epoch [3515/20000], Loss: 120.21174621582031, Entropy -144.75930786132812, Learning Rate: 0.00125\n",
      "Epoch [3516/20000], Loss: 123.3125, Entropy -150.1634521484375, Learning Rate: 0.00125\n",
      "Epoch [3517/20000], Loss: 111.03912353515625, Entropy -127.33583068847656, Learning Rate: 0.00125\n",
      "Epoch [3518/20000], Loss: 116.99949645996094, Entropy -129.6570587158203, Learning Rate: 0.00125\n",
      "Epoch [3519/20000], Loss: 129.4180145263672, Entropy -158.94131469726562, Learning Rate: 0.00125\n",
      "Epoch [3520/20000], Loss: 120.09881591796875, Entropy -137.61550903320312, Learning Rate: 0.00125\n",
      "Epoch [3521/20000], Loss: 117.99380493164062, Entropy -135.29336547851562, Learning Rate: 0.00125\n",
      "Epoch [3522/20000], Loss: 142.468017578125, Entropy -174.39154052734375, Learning Rate: 0.00125\n",
      "Epoch [3523/20000], Loss: 114.24942016601562, Entropy -133.80093383789062, Learning Rate: 0.00125\n",
      "Epoch [3524/20000], Loss: 122.6912841796875, Entropy -146.77182006835938, Learning Rate: 0.00125\n",
      "Epoch [3525/20000], Loss: 134.72161865234375, Entropy -159.43418884277344, Learning Rate: 0.00125\n",
      "Epoch [3526/20000], Loss: 117.47895812988281, Entropy -129.7047119140625, Learning Rate: 0.00125\n",
      "Epoch [3527/20000], Loss: 136.9813995361328, Entropy -165.49234008789062, Learning Rate: 0.00125\n",
      "Epoch [3528/20000], Loss: 113.29566955566406, Entropy -132.7620391845703, Learning Rate: 0.00125\n",
      "Epoch [3529/20000], Loss: 126.17860412597656, Entropy -149.4929962158203, Learning Rate: 0.00125\n",
      "Epoch [3530/20000], Loss: 125.77566528320312, Entropy -148.2646484375, Learning Rate: 0.00125\n",
      "Epoch [3531/20000], Loss: 113.67642211914062, Entropy -138.47669982910156, Learning Rate: 0.00125\n",
      "Epoch [3532/20000], Loss: 132.739501953125, Entropy -153.64027404785156, Learning Rate: 0.00125\n",
      "Epoch [3533/20000], Loss: 119.32830810546875, Entropy -134.84063720703125, Learning Rate: 0.00125\n",
      "Epoch [3534/20000], Loss: 127.40335083007812, Entropy -160.98382568359375, Learning Rate: 0.00125\n",
      "Epoch [3535/20000], Loss: 124.025634765625, Entropy -145.36732482910156, Learning Rate: 0.00125\n",
      "Epoch [3536/20000], Loss: 120.34231567382812, Entropy -137.5591583251953, Learning Rate: 0.00125\n",
      "Epoch [3537/20000], Loss: 119.02500915527344, Entropy -143.84231567382812, Learning Rate: 0.00125\n",
      "Epoch [3538/20000], Loss: 122.07846069335938, Entropy -137.14764404296875, Learning Rate: 0.00125\n",
      "Epoch [3539/20000], Loss: 120.33547973632812, Entropy -147.60415649414062, Learning Rate: 0.00125\n",
      "Epoch [3540/20000], Loss: 123.92921447753906, Entropy -154.39059448242188, Learning Rate: 0.00125\n",
      "Epoch [3541/20000], Loss: 117.18992614746094, Entropy -139.20526123046875, Learning Rate: 0.00125\n",
      "Epoch [3542/20000], Loss: 124.90229797363281, Entropy -153.40118408203125, Learning Rate: 0.00125\n",
      "Epoch [3543/20000], Loss: 118.63873291015625, Entropy -134.20281982421875, Learning Rate: 0.00125\n",
      "Epoch [3544/20000], Loss: 127.63298034667969, Entropy -144.98489379882812, Learning Rate: 0.00125\n",
      "Epoch [3545/20000], Loss: 110.96734619140625, Entropy -133.68321228027344, Learning Rate: 0.00125\n",
      "Epoch [3546/20000], Loss: 128.44436645507812, Entropy -149.66485595703125, Learning Rate: 0.00125\n",
      "Epoch [3547/20000], Loss: 130.6923370361328, Entropy -153.31475830078125, Learning Rate: 0.00125\n",
      "Epoch [3548/20000], Loss: 126.82867431640625, Entropy -148.67514038085938, Learning Rate: 0.00125\n",
      "Epoch [3549/20000], Loss: 123.15492248535156, Entropy -134.15234375, Learning Rate: 0.00125\n",
      "Epoch [3550/20000], Loss: 119.01872253417969, Entropy -140.8560791015625, Learning Rate: 0.00125\n",
      "Epoch [3551/20000], Loss: 121.45918273925781, Entropy -146.953125, Learning Rate: 0.00125\n",
      "Epoch [3552/20000], Loss: 114.59336853027344, Entropy -142.10299682617188, Learning Rate: 0.00125\n",
      "Epoch [3553/20000], Loss: 109.03196716308594, Entropy -128.00164794921875, Learning Rate: 0.00125\n",
      "Epoch [3554/20000], Loss: 122.41300964355469, Entropy -140.22647094726562, Learning Rate: 0.00125\n",
      "Epoch [3555/20000], Loss: 120.54997253417969, Entropy -137.49221801757812, Learning Rate: 0.00125\n",
      "Epoch [3556/20000], Loss: 111.22761535644531, Entropy -131.5448760986328, Learning Rate: 0.00125\n",
      "Epoch [3557/20000], Loss: 128.0577850341797, Entropy -153.81777954101562, Learning Rate: 0.00125\n",
      "Epoch [3558/20000], Loss: 136.12229919433594, Entropy -168.75485229492188, Learning Rate: 0.00125\n",
      "Epoch [3559/20000], Loss: 126.76092529296875, Entropy -155.05751037597656, Learning Rate: 0.00125\n",
      "Epoch [3560/20000], Loss: 118.82698059082031, Entropy -130.8909912109375, Learning Rate: 0.00125\n",
      "Epoch [3561/20000], Loss: 124.53858947753906, Entropy -147.19735717773438, Learning Rate: 0.00125\n",
      "Epoch [3562/20000], Loss: 120.84616088867188, Entropy -143.62911987304688, Learning Rate: 0.00125\n",
      "Epoch [3563/20000], Loss: 133.55897521972656, Entropy -154.820068359375, Learning Rate: 0.00125\n",
      "Epoch [3564/20000], Loss: 134.34539794921875, Entropy -161.21954345703125, Learning Rate: 0.00125\n",
      "Epoch [3565/20000], Loss: 117.09768676757812, Entropy -143.12039184570312, Learning Rate: 0.00125\n",
      "Epoch [3566/20000], Loss: 122.97738647460938, Entropy -139.2371826171875, Learning Rate: 0.00125\n",
      "Epoch [3567/20000], Loss: 116.10623168945312, Entropy -147.79705810546875, Learning Rate: 0.00125\n",
      "Epoch [3568/20000], Loss: 122.10691833496094, Entropy -144.03012084960938, Learning Rate: 0.00125\n",
      "Epoch [3569/20000], Loss: 115.35641479492188, Entropy -141.7002410888672, Learning Rate: 0.00125\n",
      "Epoch [3570/20000], Loss: 111.5064697265625, Entropy -138.7728729248047, Learning Rate: 0.00125\n",
      "Epoch [3571/20000], Loss: 122.11758422851562, Entropy -145.60313415527344, Learning Rate: 0.00125\n",
      "Epoch [3572/20000], Loss: 113.69375610351562, Entropy -140.634765625, Learning Rate: 0.00125\n",
      "Epoch [3573/20000], Loss: 122.47470092773438, Entropy -146.0648651123047, Learning Rate: 0.00125\n",
      "Epoch [3574/20000], Loss: 124.46522521972656, Entropy -147.47879028320312, Learning Rate: 0.000625\n",
      "Epoch [3575/20000], Loss: 146.5169677734375, Entropy -169.195068359375, Learning Rate: 0.000625\n",
      "Epoch [3576/20000], Loss: 125.01849365234375, Entropy -148.87759399414062, Learning Rate: 0.000625\n",
      "Epoch [3577/20000], Loss: 129.08607482910156, Entropy -156.19825744628906, Learning Rate: 0.000625\n",
      "Epoch [3578/20000], Loss: 117.71746826171875, Entropy -149.4858856201172, Learning Rate: 0.000625\n",
      "Epoch [3579/20000], Loss: 130.07798767089844, Entropy -142.48529052734375, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3580/20000], Loss: 115.03857421875, Entropy -137.62530517578125, Learning Rate: 0.000625\n",
      "Epoch [3581/20000], Loss: 123.6817626953125, Entropy -134.76199340820312, Learning Rate: 0.000625\n",
      "Epoch [3582/20000], Loss: 121.01181030273438, Entropy -150.91123962402344, Learning Rate: 0.000625\n",
      "Epoch [3583/20000], Loss: 128.41358947753906, Entropy -153.92990112304688, Learning Rate: 0.000625\n",
      "Epoch [3584/20000], Loss: 119.89991760253906, Entropy -150.5194549560547, Learning Rate: 0.000625\n",
      "Epoch [3585/20000], Loss: 122.2840576171875, Entropy -142.65582275390625, Learning Rate: 0.000625\n",
      "Epoch [3586/20000], Loss: 131.8156280517578, Entropy -167.74514770507812, Learning Rate: 0.000625\n",
      "Epoch [3587/20000], Loss: 129.3652801513672, Entropy -151.9224853515625, Learning Rate: 0.000625\n",
      "Epoch [3588/20000], Loss: 128.18048095703125, Entropy -150.48260498046875, Learning Rate: 0.000625\n",
      "Epoch [3589/20000], Loss: 111.84059143066406, Entropy -135.22869873046875, Learning Rate: 0.000625\n",
      "Epoch [3590/20000], Loss: 108.07026672363281, Entropy -127.94342041015625, Learning Rate: 0.000625\n",
      "Epoch [3591/20000], Loss: 130.22354125976562, Entropy -164.68157958984375, Learning Rate: 0.000625\n",
      "Epoch [3592/20000], Loss: 123.06895446777344, Entropy -146.2087860107422, Learning Rate: 0.000625\n",
      "Epoch [3593/20000], Loss: 118.75035095214844, Entropy -144.64158630371094, Learning Rate: 0.000625\n",
      "Epoch [3594/20000], Loss: 116.2816162109375, Entropy -134.77711486816406, Learning Rate: 0.000625\n",
      "Epoch [3595/20000], Loss: 123.79220581054688, Entropy -149.9434814453125, Learning Rate: 0.000625\n",
      "Epoch [3596/20000], Loss: 119.70791625976562, Entropy -145.20199584960938, Learning Rate: 0.000625\n",
      "Epoch [3597/20000], Loss: 116.07481384277344, Entropy -141.87222290039062, Learning Rate: 0.000625\n",
      "Epoch [3598/20000], Loss: 122.63801574707031, Entropy -144.780029296875, Learning Rate: 0.000625\n",
      "Epoch [3599/20000], Loss: 124.42158508300781, Entropy -145.50640869140625, Learning Rate: 0.000625\n",
      "Epoch [3600/20000], Loss: 108.14573669433594, Entropy -123.16380310058594, Learning Rate: 0.000625\n",
      "Epoch [3601/20000], Loss: 111.77018737792969, Entropy -134.03916931152344, Learning Rate: 0.000625\n",
      "Epoch [3602/20000], Loss: 124.8941650390625, Entropy -146.99989318847656, Learning Rate: 0.000625\n",
      "Epoch [3603/20000], Loss: 118.80830383300781, Entropy -142.79653930664062, Learning Rate: 0.000625\n",
      "Epoch [3604/20000], Loss: 120.34852600097656, Entropy -138.74493408203125, Learning Rate: 0.000625\n",
      "Epoch [3605/20000], Loss: 109.87977600097656, Entropy -130.9742431640625, Learning Rate: 0.000625\n",
      "Epoch [3606/20000], Loss: 123.88336181640625, Entropy -150.8373565673828, Learning Rate: 0.000625\n",
      "Epoch [3607/20000], Loss: 115.58729553222656, Entropy -123.06500244140625, Learning Rate: 0.000625\n",
      "Epoch [3608/20000], Loss: 111.88978576660156, Entropy -136.55206298828125, Learning Rate: 0.000625\n",
      "Epoch [3609/20000], Loss: 125.17042541503906, Entropy -156.715576171875, Learning Rate: 0.000625\n",
      "Epoch [3610/20000], Loss: 113.92398071289062, Entropy -136.832763671875, Learning Rate: 0.000625\n",
      "Epoch [3611/20000], Loss: 119.33090209960938, Entropy -131.25558471679688, Learning Rate: 0.000625\n",
      "Epoch [3612/20000], Loss: 123.77427673339844, Entropy -154.31881713867188, Learning Rate: 0.000625\n",
      "Epoch [3613/20000], Loss: 121.8642578125, Entropy -138.935546875, Learning Rate: 0.000625\n",
      "Epoch [3614/20000], Loss: 115.56582641601562, Entropy -139.69598388671875, Learning Rate: 0.000625\n",
      "Epoch [3615/20000], Loss: 116.64045715332031, Entropy -138.6471710205078, Learning Rate: 0.000625\n",
      "Epoch [3616/20000], Loss: 139.55345153808594, Entropy -173.58364868164062, Learning Rate: 0.000625\n",
      "Epoch [3617/20000], Loss: 130.5523223876953, Entropy -147.20445251464844, Learning Rate: 0.000625\n",
      "Epoch [3618/20000], Loss: 122.99809265136719, Entropy -145.34759521484375, Learning Rate: 0.000625\n",
      "Epoch [3619/20000], Loss: 113.05058288574219, Entropy -140.7158203125, Learning Rate: 0.000625\n",
      "Epoch [3620/20000], Loss: 121.49700927734375, Entropy -143.17623901367188, Learning Rate: 0.000625\n",
      "Epoch [3621/20000], Loss: 116.77742004394531, Entropy -141.65689086914062, Learning Rate: 0.000625\n",
      "Epoch [3622/20000], Loss: 122.29537963867188, Entropy -145.5682830810547, Learning Rate: 0.000625\n",
      "Epoch [3623/20000], Loss: 120.50509643554688, Entropy -144.14736938476562, Learning Rate: 0.000625\n",
      "Epoch [3624/20000], Loss: 126.24954223632812, Entropy -152.63931274414062, Learning Rate: 0.000625\n",
      "Epoch [3625/20000], Loss: 122.00711059570312, Entropy -147.09861755371094, Learning Rate: 0.000625\n",
      "Epoch [3626/20000], Loss: 122.9327392578125, Entropy -141.06280517578125, Learning Rate: 0.000625\n",
      "Epoch [3627/20000], Loss: 113.73307800292969, Entropy -134.99945068359375, Learning Rate: 0.000625\n",
      "Epoch [3628/20000], Loss: 131.96969604492188, Entropy -159.44908142089844, Learning Rate: 0.000625\n",
      "Epoch [3629/20000], Loss: 111.73414611816406, Entropy -129.9761962890625, Learning Rate: 0.000625\n",
      "Epoch [3630/20000], Loss: 118.86346435546875, Entropy -141.21287536621094, Learning Rate: 0.000625\n",
      "Epoch [3631/20000], Loss: 118.48722839355469, Entropy -142.62789916992188, Learning Rate: 0.000625\n",
      "Epoch [3632/20000], Loss: 129.23582458496094, Entropy -154.6815643310547, Learning Rate: 0.000625\n",
      "Epoch [3633/20000], Loss: 121.81599426269531, Entropy -141.43499755859375, Learning Rate: 0.000625\n",
      "Epoch [3634/20000], Loss: 134.20143127441406, Entropy -166.12054443359375, Learning Rate: 0.000625\n",
      "Epoch [3635/20000], Loss: 119.25309753417969, Entropy -149.89776611328125, Learning Rate: 0.000625\n",
      "Epoch [3636/20000], Loss: 120.3116455078125, Entropy -142.67063903808594, Learning Rate: 0.000625\n",
      "Epoch [3637/20000], Loss: 122.751220703125, Entropy -151.25469970703125, Learning Rate: 0.000625\n",
      "Epoch [3638/20000], Loss: 115.00164794921875, Entropy -139.590576171875, Learning Rate: 0.000625\n",
      "Epoch [3639/20000], Loss: 119.73930358886719, Entropy -135.68487548828125, Learning Rate: 0.000625\n",
      "Epoch [3640/20000], Loss: 123.10025024414062, Entropy -133.41162109375, Learning Rate: 0.000625\n",
      "Epoch [3641/20000], Loss: 130.17152404785156, Entropy -150.28785705566406, Learning Rate: 0.000625\n",
      "Epoch [3642/20000], Loss: 117.84461975097656, Entropy -128.57130432128906, Learning Rate: 0.000625\n",
      "Epoch [3643/20000], Loss: 122.18400573730469, Entropy -144.57135009765625, Learning Rate: 0.000625\n",
      "Epoch [3644/20000], Loss: 119.91841125488281, Entropy -138.61257934570312, Learning Rate: 0.000625\n",
      "Epoch [3645/20000], Loss: 110.64920043945312, Entropy -132.15069580078125, Learning Rate: 0.000625\n",
      "Epoch [3646/20000], Loss: 120.77642822265625, Entropy -145.04696655273438, Learning Rate: 0.000625\n",
      "Epoch [3647/20000], Loss: 116.83230590820312, Entropy -142.44720458984375, Learning Rate: 0.000625\n",
      "Epoch [3648/20000], Loss: 139.03909301757812, Entropy -169.91966247558594, Learning Rate: 0.000625\n",
      "Epoch [3649/20000], Loss: 123.3304443359375, Entropy -152.38763427734375, Learning Rate: 0.000625\n",
      "Epoch [3650/20000], Loss: 126.4642333984375, Entropy -151.7950439453125, Learning Rate: 0.000625\n",
      "Epoch [3651/20000], Loss: 114.00640869140625, Entropy -131.7776641845703, Learning Rate: 0.000625\n",
      "Epoch [3652/20000], Loss: 122.406494140625, Entropy -146.1862030029297, Learning Rate: 0.000625\n",
      "Epoch [3653/20000], Loss: 135.58895874023438, Entropy -164.1234588623047, Learning Rate: 0.000625\n",
      "Epoch [3654/20000], Loss: 123.63471984863281, Entropy -148.19210815429688, Learning Rate: 0.000625\n",
      "Epoch [3655/20000], Loss: 106.16108703613281, Entropy -121.67282104492188, Learning Rate: 0.000625\n",
      "Epoch [3656/20000], Loss: 116.27207946777344, Entropy -145.3387908935547, Learning Rate: 0.000625\n",
      "Epoch [3657/20000], Loss: 114.34780883789062, Entropy -132.06954956054688, Learning Rate: 0.000625\n",
      "Epoch [3658/20000], Loss: 122.07508850097656, Entropy -147.11126708984375, Learning Rate: 0.000625\n",
      "Epoch [3659/20000], Loss: 119.25550842285156, Entropy -143.835693359375, Learning Rate: 0.000625\n",
      "Epoch [3660/20000], Loss: 131.4176483154297, Entropy -160.71893310546875, Learning Rate: 0.000625\n",
      "Epoch [3661/20000], Loss: 127.75262451171875, Entropy -151.81661987304688, Learning Rate: 0.000625\n",
      "Epoch [3662/20000], Loss: 119.93049621582031, Entropy -139.734130859375, Learning Rate: 0.000625\n",
      "Epoch [3663/20000], Loss: 112.44757080078125, Entropy -133.936279296875, Learning Rate: 0.000625\n",
      "Epoch [3664/20000], Loss: 124.70021057128906, Entropy -145.3690643310547, Learning Rate: 0.000625\n",
      "Epoch [3665/20000], Loss: 117.29667663574219, Entropy -134.82440185546875, Learning Rate: 0.000625\n",
      "Epoch [3666/20000], Loss: 118.55206298828125, Entropy -146.75418090820312, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3667/20000], Loss: 123.073486328125, Entropy -152.8917694091797, Learning Rate: 0.000625\n",
      "Epoch [3668/20000], Loss: 129.46975708007812, Entropy -156.92999267578125, Learning Rate: 0.000625\n",
      "Epoch [3669/20000], Loss: 127.031494140625, Entropy -158.52410888671875, Learning Rate: 0.000625\n",
      "Epoch [3670/20000], Loss: 131.8363037109375, Entropy -145.75572204589844, Learning Rate: 0.000625\n",
      "Epoch [3671/20000], Loss: 119.91717529296875, Entropy -145.42068481445312, Learning Rate: 0.000625\n",
      "Epoch [3672/20000], Loss: 128.56536865234375, Entropy -155.2744598388672, Learning Rate: 0.000625\n",
      "Epoch [3673/20000], Loss: 113.34788513183594, Entropy -136.37298583984375, Learning Rate: 0.000625\n",
      "Epoch [3674/20000], Loss: 134.4195098876953, Entropy -169.24899291992188, Learning Rate: 0.000625\n",
      "Epoch [3675/20000], Loss: 119.92642211914062, Entropy -130.7822723388672, Learning Rate: 0.000625\n",
      "Epoch [3676/20000], Loss: 127.56025695800781, Entropy -153.2293701171875, Learning Rate: 0.000625\n",
      "Epoch [3677/20000], Loss: 123.14903259277344, Entropy -149.3448486328125, Learning Rate: 0.000625\n",
      "Epoch [3678/20000], Loss: 129.97769165039062, Entropy -148.86537170410156, Learning Rate: 0.000625\n",
      "Epoch [3679/20000], Loss: 123.01605224609375, Entropy -155.8909912109375, Learning Rate: 0.000625\n",
      "Epoch [3680/20000], Loss: 124.85247802734375, Entropy -154.96151733398438, Learning Rate: 0.000625\n",
      "Epoch [3681/20000], Loss: 124.54971313476562, Entropy -148.51231384277344, Learning Rate: 0.000625\n",
      "Epoch [3682/20000], Loss: 116.302978515625, Entropy -133.57931518554688, Learning Rate: 0.000625\n",
      "Epoch [3683/20000], Loss: 115.630615234375, Entropy -130.51675415039062, Learning Rate: 0.000625\n",
      "Epoch [3684/20000], Loss: 119.70858764648438, Entropy -137.485595703125, Learning Rate: 0.000625\n",
      "Epoch [3685/20000], Loss: 118.0616455078125, Entropy -137.2271728515625, Learning Rate: 0.000625\n",
      "Epoch [3686/20000], Loss: 128.0808868408203, Entropy -151.70065307617188, Learning Rate: 0.000625\n",
      "Epoch [3687/20000], Loss: 124.98716735839844, Entropy -142.8406982421875, Learning Rate: 0.000625\n",
      "Epoch [3688/20000], Loss: 116.16539001464844, Entropy -136.66580200195312, Learning Rate: 0.000625\n",
      "Epoch [3689/20000], Loss: 122.04222106933594, Entropy -135.80340576171875, Learning Rate: 0.000625\n",
      "Epoch [3690/20000], Loss: 129.33319091796875, Entropy -161.40008544921875, Learning Rate: 0.000625\n",
      "Epoch [3691/20000], Loss: 127.83523559570312, Entropy -143.611328125, Learning Rate: 0.000625\n",
      "Epoch [3692/20000], Loss: 117.15794372558594, Entropy -137.93057250976562, Learning Rate: 0.000625\n",
      "Epoch [3693/20000], Loss: 115.15574645996094, Entropy -138.36126708984375, Learning Rate: 0.000625\n",
      "Epoch [3694/20000], Loss: 108.706298828125, Entropy -131.4748992919922, Learning Rate: 0.000625\n",
      "Epoch [3695/20000], Loss: 123.46067810058594, Entropy -143.93173217773438, Learning Rate: 0.000625\n",
      "Epoch [3696/20000], Loss: 123.4761962890625, Entropy -148.73599243164062, Learning Rate: 0.000625\n",
      "Epoch [3697/20000], Loss: 124.87800598144531, Entropy -143.81240844726562, Learning Rate: 0.000625\n",
      "Epoch [3698/20000], Loss: 120.11320495605469, Entropy -141.53787231445312, Learning Rate: 0.000625\n",
      "Epoch [3699/20000], Loss: 115.849853515625, Entropy -135.73680114746094, Learning Rate: 0.000625\n",
      "Epoch [3700/20000], Loss: 120.131591796875, Entropy -144.30181884765625, Learning Rate: 0.000625\n",
      "Epoch [3701/20000], Loss: 130.36636352539062, Entropy -157.25442504882812, Learning Rate: 0.000625\n",
      "Epoch [3702/20000], Loss: 117.62413024902344, Entropy -131.45574951171875, Learning Rate: 0.000625\n",
      "Epoch [3703/20000], Loss: 122.45344543457031, Entropy -147.18702697753906, Learning Rate: 0.000625\n",
      "Epoch [3704/20000], Loss: 115.60945129394531, Entropy -133.7860870361328, Learning Rate: 0.000625\n",
      "Epoch [3705/20000], Loss: 120.94862365722656, Entropy -143.23463439941406, Learning Rate: 0.000625\n",
      "Epoch [3706/20000], Loss: 123.52171325683594, Entropy -151.42491149902344, Learning Rate: 0.000625\n",
      "Epoch [3707/20000], Loss: 125.57890319824219, Entropy -151.66534423828125, Learning Rate: 0.000625\n",
      "Epoch [3708/20000], Loss: 119.14118957519531, Entropy -141.43463134765625, Learning Rate: 0.000625\n",
      "Epoch [3709/20000], Loss: 121.16506958007812, Entropy -139.76995849609375, Learning Rate: 0.000625\n",
      "Epoch [3710/20000], Loss: 125.80772399902344, Entropy -143.10255432128906, Learning Rate: 0.000625\n",
      "Epoch [3711/20000], Loss: 114.87887573242188, Entropy -136.4544677734375, Learning Rate: 0.000625\n",
      "Epoch [3712/20000], Loss: 128.02479553222656, Entropy -153.4908447265625, Learning Rate: 0.000625\n",
      "Epoch [3713/20000], Loss: 111.34114074707031, Entropy -134.5854949951172, Learning Rate: 0.000625\n",
      "Epoch [3714/20000], Loss: 113.92791748046875, Entropy -135.2931671142578, Learning Rate: 0.000625\n",
      "Epoch [3715/20000], Loss: 118.03153991699219, Entropy -135.64852905273438, Learning Rate: 0.000625\n",
      "Epoch [3716/20000], Loss: 114.36795043945312, Entropy -135.95233154296875, Learning Rate: 0.000625\n",
      "Epoch [3717/20000], Loss: 115.74696350097656, Entropy -139.75323486328125, Learning Rate: 0.000625\n",
      "Epoch [3718/20000], Loss: 126.46876525878906, Entropy -155.06570434570312, Learning Rate: 0.000625\n",
      "Epoch [3719/20000], Loss: 117.64791870117188, Entropy -135.76712036132812, Learning Rate: 0.000625\n",
      "Epoch [3720/20000], Loss: 122.92184448242188, Entropy -150.62893676757812, Learning Rate: 0.000625\n",
      "Epoch [3721/20000], Loss: 110.78096008300781, Entropy -126.16250610351562, Learning Rate: 0.000625\n",
      "Epoch [3722/20000], Loss: 121.36000061035156, Entropy -144.6398162841797, Learning Rate: 0.000625\n",
      "Epoch [3723/20000], Loss: 118.57341003417969, Entropy -134.5102081298828, Learning Rate: 0.000625\n",
      "Epoch [3724/20000], Loss: 122.47894287109375, Entropy -144.9830322265625, Learning Rate: 0.000625\n",
      "Epoch [3725/20000], Loss: 130.89401245117188, Entropy -146.86795043945312, Learning Rate: 0.000625\n",
      "Epoch [3726/20000], Loss: 115.66606140136719, Entropy -140.19195556640625, Learning Rate: 0.000625\n",
      "Epoch [3727/20000], Loss: 111.5074462890625, Entropy -134.8985595703125, Learning Rate: 0.000625\n",
      "Epoch [3728/20000], Loss: 120.10203552246094, Entropy -142.0453338623047, Learning Rate: 0.000625\n",
      "Epoch [3729/20000], Loss: 123.31109619140625, Entropy -152.38983154296875, Learning Rate: 0.000625\n",
      "Epoch [3730/20000], Loss: 112.57196044921875, Entropy -135.15713500976562, Learning Rate: 0.000625\n",
      "Epoch [3731/20000], Loss: 125.24331665039062, Entropy -142.9272918701172, Learning Rate: 0.000625\n",
      "Epoch [3732/20000], Loss: 127.49186706542969, Entropy -152.87408447265625, Learning Rate: 0.000625\n",
      "Epoch [3733/20000], Loss: 126.87898254394531, Entropy -147.20391845703125, Learning Rate: 0.000625\n",
      "Epoch [3734/20000], Loss: 118.23922729492188, Entropy -136.61009216308594, Learning Rate: 0.000625\n",
      "Epoch [3735/20000], Loss: 112.3216552734375, Entropy -135.0121307373047, Learning Rate: 0.000625\n",
      "Epoch [3736/20000], Loss: 123.93724060058594, Entropy -147.9725341796875, Learning Rate: 0.000625\n",
      "Epoch [3737/20000], Loss: 121.11380004882812, Entropy -145.1661376953125, Learning Rate: 0.000625\n",
      "Epoch [3738/20000], Loss: 115.84947204589844, Entropy -139.786376953125, Learning Rate: 0.000625\n",
      "Epoch [3739/20000], Loss: 122.88917541503906, Entropy -140.50674438476562, Learning Rate: 0.000625\n",
      "Epoch [3740/20000], Loss: 125.84407043457031, Entropy -146.12603759765625, Learning Rate: 0.000625\n",
      "Epoch [3741/20000], Loss: 112.34904479980469, Entropy -141.2468719482422, Learning Rate: 0.000625\n",
      "Epoch [3742/20000], Loss: 124.14442443847656, Entropy -149.4681396484375, Learning Rate: 0.000625\n",
      "Epoch [3743/20000], Loss: 118.93789672851562, Entropy -140.69546508789062, Learning Rate: 0.000625\n",
      "Epoch [3744/20000], Loss: 114.30900573730469, Entropy -138.64462280273438, Learning Rate: 0.000625\n",
      "Epoch [3745/20000], Loss: 118.74971008300781, Entropy -146.49835205078125, Learning Rate: 0.000625\n",
      "Epoch [3746/20000], Loss: 113.78184509277344, Entropy -132.1764678955078, Learning Rate: 0.000625\n",
      "Epoch [3747/20000], Loss: 115.8519287109375, Entropy -134.73182678222656, Learning Rate: 0.000625\n",
      "Epoch [3748/20000], Loss: 128.4868621826172, Entropy -154.83407592773438, Learning Rate: 0.000625\n",
      "Epoch [3749/20000], Loss: 117.84686279296875, Entropy -134.53323364257812, Learning Rate: 0.000625\n",
      "Epoch [3750/20000], Loss: 118.27955627441406, Entropy -142.7303466796875, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3751/20000], Loss: 124.65318298339844, Entropy -149.96444702148438, Learning Rate: 0.000625\n",
      "Epoch [3752/20000], Loss: 114.70256042480469, Entropy -137.19094848632812, Learning Rate: 0.000625\n",
      "Epoch [3753/20000], Loss: 121.15953063964844, Entropy -150.97265625, Learning Rate: 0.000625\n",
      "Epoch [3754/20000], Loss: 116.34602355957031, Entropy -134.63119506835938, Learning Rate: 0.000625\n",
      "Epoch [3755/20000], Loss: 117.30413818359375, Entropy -134.23529052734375, Learning Rate: 0.000625\n",
      "Epoch [3756/20000], Loss: 117.21875, Entropy -140.63009643554688, Learning Rate: 0.000625\n",
      "Epoch [3757/20000], Loss: 132.2783203125, Entropy -154.25698852539062, Learning Rate: 0.000625\n",
      "Epoch [3758/20000], Loss: 115.31315612792969, Entropy -137.83258056640625, Learning Rate: 0.000625\n",
      "Epoch [3759/20000], Loss: 123.49026489257812, Entropy -152.55545043945312, Learning Rate: 0.000625\n",
      "Epoch [3760/20000], Loss: 119.03434753417969, Entropy -139.4432373046875, Learning Rate: 0.000625\n",
      "Epoch [3761/20000], Loss: 123.53469848632812, Entropy -147.2035369873047, Learning Rate: 0.000625\n",
      "Epoch [3762/20000], Loss: 120.14041137695312, Entropy -144.79635620117188, Learning Rate: 0.000625\n",
      "Epoch [3763/20000], Loss: 120.3096923828125, Entropy -151.32444763183594, Learning Rate: 0.000625\n",
      "Epoch [3764/20000], Loss: 124.5819091796875, Entropy -142.95944213867188, Learning Rate: 0.000625\n",
      "Epoch [3765/20000], Loss: 120.88250732421875, Entropy -128.51736450195312, Learning Rate: 0.000625\n",
      "Epoch [3766/20000], Loss: 133.91171264648438, Entropy -156.50904846191406, Learning Rate: 0.000625\n",
      "Epoch [3767/20000], Loss: 124.18235778808594, Entropy -148.8533935546875, Learning Rate: 0.000625\n",
      "Epoch [3768/20000], Loss: 123.499755859375, Entropy -146.22901916503906, Learning Rate: 0.000625\n",
      "Epoch [3769/20000], Loss: 120.67210388183594, Entropy -142.18490600585938, Learning Rate: 0.000625\n",
      "Epoch [3770/20000], Loss: 110.7288818359375, Entropy -127.584228515625, Learning Rate: 0.000625\n",
      "Epoch [3771/20000], Loss: 121.86048889160156, Entropy -147.1790771484375, Learning Rate: 0.000625\n",
      "Epoch [3772/20000], Loss: 126.07192993164062, Entropy -154.73744201660156, Learning Rate: 0.000625\n",
      "Epoch [3773/20000], Loss: 120.32948303222656, Entropy -136.24502563476562, Learning Rate: 0.000625\n",
      "Epoch [3774/20000], Loss: 122.43617248535156, Entropy -147.46051025390625, Learning Rate: 0.000625\n",
      "Epoch [3775/20000], Loss: 129.14401245117188, Entropy -160.615478515625, Learning Rate: 0.000625\n",
      "Epoch [3776/20000], Loss: 125.18315124511719, Entropy -147.60769653320312, Learning Rate: 0.000625\n",
      "Epoch [3777/20000], Loss: 122.24122619628906, Entropy -137.90753173828125, Learning Rate: 0.000625\n",
      "Epoch [3778/20000], Loss: 121.62678527832031, Entropy -145.12449645996094, Learning Rate: 0.000625\n",
      "Epoch [3779/20000], Loss: 127.90127563476562, Entropy -147.91543579101562, Learning Rate: 0.000625\n",
      "Epoch [3780/20000], Loss: 119.54548645019531, Entropy -140.84140014648438, Learning Rate: 0.000625\n",
      "Epoch [3781/20000], Loss: 116.59182739257812, Entropy -142.8529815673828, Learning Rate: 0.000625\n",
      "Epoch [3782/20000], Loss: 103.22830200195312, Entropy -119.71514892578125, Learning Rate: 0.000625\n",
      "Epoch [3783/20000], Loss: 116.19013977050781, Entropy -135.22979736328125, Learning Rate: 0.000625\n",
      "Epoch [3784/20000], Loss: 130.92381286621094, Entropy -153.30284118652344, Learning Rate: 0.000625\n",
      "Epoch [3785/20000], Loss: 127.07792663574219, Entropy -152.5386962890625, Learning Rate: 0.000625\n",
      "Epoch [3786/20000], Loss: 128.93154907226562, Entropy -151.67617797851562, Learning Rate: 0.000625\n",
      "Epoch [3787/20000], Loss: 111.66120910644531, Entropy -132.68569946289062, Learning Rate: 0.000625\n",
      "Epoch [3788/20000], Loss: 114.29444885253906, Entropy -136.0609893798828, Learning Rate: 0.000625\n",
      "Epoch [3789/20000], Loss: 109.98558044433594, Entropy -128.42327880859375, Learning Rate: 0.000625\n",
      "Epoch [3790/20000], Loss: 133.97230529785156, Entropy -162.54501342773438, Learning Rate: 0.000625\n",
      "Epoch [3791/20000], Loss: 121.39564514160156, Entropy -149.06298828125, Learning Rate: 0.000625\n",
      "Epoch [3792/20000], Loss: 123.74284362792969, Entropy -140.56039428710938, Learning Rate: 0.000625\n",
      "Epoch [3793/20000], Loss: 121.00242614746094, Entropy -154.36495971679688, Learning Rate: 0.000625\n",
      "Epoch [3794/20000], Loss: 124.64129638671875, Entropy -156.04812622070312, Learning Rate: 0.000625\n",
      "Epoch [3795/20000], Loss: 119.788818359375, Entropy -142.9417724609375, Learning Rate: 0.000625\n",
      "Epoch [3796/20000], Loss: 110.10415649414062, Entropy -132.90335083007812, Learning Rate: 0.000625\n",
      "Epoch [3797/20000], Loss: 111.85884094238281, Entropy -130.16854858398438, Learning Rate: 0.000625\n",
      "Epoch [3798/20000], Loss: 123.97782897949219, Entropy -144.41751098632812, Learning Rate: 0.000625\n",
      "Epoch [3799/20000], Loss: 124.21449279785156, Entropy -144.232666015625, Learning Rate: 0.000625\n",
      "Epoch [3800/20000], Loss: 121.38798522949219, Entropy -146.211181640625, Learning Rate: 0.000625\n",
      "Epoch [3801/20000], Loss: 126.85263061523438, Entropy -154.6488800048828, Learning Rate: 0.000625\n",
      "Epoch [3802/20000], Loss: 128.8955078125, Entropy -151.8860321044922, Learning Rate: 0.000625\n",
      "Epoch [3803/20000], Loss: 126.95993041992188, Entropy -145.65631103515625, Learning Rate: 0.000625\n",
      "Epoch [3804/20000], Loss: 117.51168823242188, Entropy -134.14801025390625, Learning Rate: 0.000625\n",
      "Epoch [3805/20000], Loss: 130.4977264404297, Entropy -156.56521606445312, Learning Rate: 0.000625\n",
      "Epoch [3806/20000], Loss: 117.38450622558594, Entropy -147.37197875976562, Learning Rate: 0.000625\n",
      "Epoch [3807/20000], Loss: 125.10636901855469, Entropy -154.5091552734375, Learning Rate: 0.000625\n",
      "Epoch [3808/20000], Loss: 116.41523742675781, Entropy -133.6717529296875, Learning Rate: 0.000625\n",
      "Epoch [3809/20000], Loss: 116.75166320800781, Entropy -141.88705444335938, Learning Rate: 0.000625\n",
      "Epoch [3810/20000], Loss: 125.46220397949219, Entropy -148.82147216796875, Learning Rate: 0.000625\n",
      "Epoch [3811/20000], Loss: 119.66787719726562, Entropy -138.2100372314453, Learning Rate: 0.000625\n",
      "Epoch [3812/20000], Loss: 107.8414306640625, Entropy -119.13728332519531, Learning Rate: 0.000625\n",
      "Epoch [3813/20000], Loss: 123.42131042480469, Entropy -139.7053680419922, Learning Rate: 0.000625\n",
      "Epoch [3814/20000], Loss: 132.77035522460938, Entropy -143.48446655273438, Learning Rate: 0.000625\n",
      "Epoch [3815/20000], Loss: 119.245361328125, Entropy -135.14202880859375, Learning Rate: 0.000625\n",
      "Epoch [3816/20000], Loss: 115.31260681152344, Entropy -128.95126342773438, Learning Rate: 0.000625\n",
      "Epoch [3817/20000], Loss: 121.91946411132812, Entropy -151.2774658203125, Learning Rate: 0.000625\n",
      "Epoch [3818/20000], Loss: 118.06307983398438, Entropy -145.50650024414062, Learning Rate: 0.000625\n",
      "Epoch [3819/20000], Loss: 116.70198059082031, Entropy -138.8033905029297, Learning Rate: 0.000625\n",
      "Epoch [3820/20000], Loss: 126.08853149414062, Entropy -153.71426391601562, Learning Rate: 0.000625\n",
      "Epoch [3821/20000], Loss: 131.31228637695312, Entropy -160.68690490722656, Learning Rate: 0.000625\n",
      "Epoch [3822/20000], Loss: 119.50981140136719, Entropy -137.11851501464844, Learning Rate: 0.000625\n",
      "Epoch [3823/20000], Loss: 121.11477661132812, Entropy -148.32534790039062, Learning Rate: 0.000625\n",
      "Epoch [3824/20000], Loss: 118.44856262207031, Entropy -138.96728515625, Learning Rate: 0.000625\n",
      "Epoch [3825/20000], Loss: 114.73887634277344, Entropy -131.26373291015625, Learning Rate: 0.000625\n",
      "Epoch [3826/20000], Loss: 109.60084533691406, Entropy -133.90367126464844, Learning Rate: 0.000625\n",
      "Epoch [3827/20000], Loss: 131.43829345703125, Entropy -161.72715759277344, Learning Rate: 0.000625\n",
      "Epoch [3828/20000], Loss: 119.27249145507812, Entropy -142.45880126953125, Learning Rate: 0.000625\n",
      "Epoch [3829/20000], Loss: 122.89605712890625, Entropy -139.42449951171875, Learning Rate: 0.000625\n",
      "Epoch [3830/20000], Loss: 116.92686462402344, Entropy -144.79576110839844, Learning Rate: 0.000625\n",
      "Epoch [3831/20000], Loss: 112.68301391601562, Entropy -127.369873046875, Learning Rate: 0.000625\n",
      "Epoch [3832/20000], Loss: 120.35858154296875, Entropy -141.70184326171875, Learning Rate: 0.000625\n",
      "Epoch [3833/20000], Loss: 119.10543823242188, Entropy -146.02920532226562, Learning Rate: 0.000625\n",
      "Epoch [3834/20000], Loss: 109.60169982910156, Entropy -137.73931884765625, Learning Rate: 0.000625\n",
      "Epoch [3835/20000], Loss: 123.69502258300781, Entropy -150.65667724609375, Learning Rate: 0.000625\n",
      "Epoch [3836/20000], Loss: 114.64356994628906, Entropy -133.07203674316406, Learning Rate: 0.000625\n",
      "Epoch [3837/20000], Loss: 123.34117126464844, Entropy -140.22071838378906, Learning Rate: 0.000625\n",
      "Epoch [3838/20000], Loss: 128.2008819580078, Entropy -147.181640625, Learning Rate: 0.000625\n",
      "Epoch [3839/20000], Loss: 121.24571228027344, Entropy -143.1446075439453, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3840/20000], Loss: 121.02226257324219, Entropy -145.3733367919922, Learning Rate: 0.000625\n",
      "Epoch [3841/20000], Loss: 118.6663818359375, Entropy -148.92745971679688, Learning Rate: 0.000625\n",
      "Epoch [3842/20000], Loss: 115.275634765625, Entropy -137.08941650390625, Learning Rate: 0.000625\n",
      "Epoch [3843/20000], Loss: 134.19378662109375, Entropy -158.60504150390625, Learning Rate: 0.000625\n",
      "Epoch [3844/20000], Loss: 126.30854797363281, Entropy -151.671142578125, Learning Rate: 0.000625\n",
      "Epoch [3845/20000], Loss: 123.40310668945312, Entropy -139.75494384765625, Learning Rate: 0.000625\n",
      "Epoch [3846/20000], Loss: 113.54519653320312, Entropy -133.0656280517578, Learning Rate: 0.000625\n",
      "Epoch [3847/20000], Loss: 122.66212463378906, Entropy -144.1748046875, Learning Rate: 0.000625\n",
      "Epoch [3848/20000], Loss: 114.91256713867188, Entropy -139.29629516601562, Learning Rate: 0.000625\n",
      "Epoch [3849/20000], Loss: 128.4231414794922, Entropy -155.46875, Learning Rate: 0.000625\n",
      "Epoch [3850/20000], Loss: 141.9385223388672, Entropy -145.69476318359375, Learning Rate: 0.000625\n",
      "Epoch [3851/20000], Loss: 128.1645050048828, Entropy -153.78817749023438, Learning Rate: 0.000625\n",
      "Epoch [3852/20000], Loss: 119.91827392578125, Entropy -143.90814208984375, Learning Rate: 0.000625\n",
      "Epoch [3853/20000], Loss: 111.8822021484375, Entropy -134.6168212890625, Learning Rate: 0.000625\n",
      "Epoch [3854/20000], Loss: 112.91856384277344, Entropy -142.65048217773438, Learning Rate: 0.000625\n",
      "Epoch [3855/20000], Loss: 108.15670776367188, Entropy -128.22378540039062, Learning Rate: 0.000625\n",
      "Epoch [3856/20000], Loss: 128.74111938476562, Entropy -148.98876953125, Learning Rate: 0.000625\n",
      "Epoch [3857/20000], Loss: 120.46873474121094, Entropy -141.69497680664062, Learning Rate: 0.000625\n",
      "Epoch [3858/20000], Loss: 125.45254516601562, Entropy -147.86331176757812, Learning Rate: 0.000625\n",
      "Epoch [3859/20000], Loss: 132.25970458984375, Entropy -153.95697021484375, Learning Rate: 0.000625\n",
      "Epoch [3860/20000], Loss: 113.62532043457031, Entropy -131.17794799804688, Learning Rate: 0.000625\n",
      "Epoch [3861/20000], Loss: 124.48991394042969, Entropy -152.13327026367188, Learning Rate: 0.000625\n",
      "Epoch [3862/20000], Loss: 115.14933776855469, Entropy -134.154052734375, Learning Rate: 0.000625\n",
      "Epoch [3863/20000], Loss: 127.94122314453125, Entropy -156.4698944091797, Learning Rate: 0.000625\n",
      "Epoch [3864/20000], Loss: 119.74113464355469, Entropy -135.15150451660156, Learning Rate: 0.000625\n",
      "Epoch [3865/20000], Loss: 113.25927734375, Entropy -131.0767059326172, Learning Rate: 0.000625\n",
      "Epoch [3866/20000], Loss: 115.97076416015625, Entropy -144.73971557617188, Learning Rate: 0.000625\n",
      "Epoch [3867/20000], Loss: 121.97425842285156, Entropy -144.8602294921875, Learning Rate: 0.000625\n",
      "Epoch [3868/20000], Loss: 120.16415405273438, Entropy -134.74427795410156, Learning Rate: 0.000625\n",
      "Epoch [3869/20000], Loss: 120.38264465332031, Entropy -143.50624084472656, Learning Rate: 0.000625\n",
      "Epoch [3870/20000], Loss: 125.00440979003906, Entropy -151.0972137451172, Learning Rate: 0.000625\n",
      "Epoch [3871/20000], Loss: 108.86761474609375, Entropy -123.6414794921875, Learning Rate: 0.000625\n",
      "Epoch [3872/20000], Loss: 119.98907470703125, Entropy -144.62112426757812, Learning Rate: 0.000625\n",
      "Epoch [3873/20000], Loss: 118.62330627441406, Entropy -140.99769592285156, Learning Rate: 0.000625\n",
      "Epoch [3874/20000], Loss: 119.86715698242188, Entropy -134.82296752929688, Learning Rate: 0.000625\n",
      "Epoch [3875/20000], Loss: 123.74711608886719, Entropy -144.88133239746094, Learning Rate: 0.000625\n",
      "Epoch [3876/20000], Loss: 126.956298828125, Entropy -154.35694885253906, Learning Rate: 0.000625\n",
      "Epoch [3877/20000], Loss: 119.963134765625, Entropy -141.28887939453125, Learning Rate: 0.000625\n",
      "Epoch [3878/20000], Loss: 119.11111450195312, Entropy -136.75489807128906, Learning Rate: 0.000625\n",
      "Epoch [3879/20000], Loss: 135.82992553710938, Entropy -163.694091796875, Learning Rate: 0.000625\n",
      "Epoch [3880/20000], Loss: 132.41110229492188, Entropy -167.85617065429688, Learning Rate: 0.000625\n",
      "Epoch [3881/20000], Loss: 117.81488037109375, Entropy -139.22216796875, Learning Rate: 0.000625\n",
      "Epoch [3882/20000], Loss: 118.55210876464844, Entropy -135.78111267089844, Learning Rate: 0.000625\n",
      "Epoch [3883/20000], Loss: 113.46954345703125, Entropy -131.13572692871094, Learning Rate: 0.000625\n",
      "Epoch [3884/20000], Loss: 114.41297912597656, Entropy -131.23284912109375, Learning Rate: 0.000625\n",
      "Epoch [3885/20000], Loss: 122.31846618652344, Entropy -140.14923095703125, Learning Rate: 0.000625\n",
      "Epoch [3886/20000], Loss: 113.60261535644531, Entropy -131.8704071044922, Learning Rate: 0.000625\n",
      "Epoch [3887/20000], Loss: 120.26890563964844, Entropy -136.46347045898438, Learning Rate: 0.000625\n",
      "Epoch [3888/20000], Loss: 119.49247741699219, Entropy -144.9150848388672, Learning Rate: 0.000625\n",
      "Epoch [3889/20000], Loss: 119.25146484375, Entropy -145.17909240722656, Learning Rate: 0.000625\n",
      "Epoch [3890/20000], Loss: 114.281982421875, Entropy -128.162841796875, Learning Rate: 0.000625\n",
      "Epoch [3891/20000], Loss: 113.25494384765625, Entropy -138.92990112304688, Learning Rate: 0.000625\n",
      "Epoch [3892/20000], Loss: 118.38763427734375, Entropy -145.33023071289062, Learning Rate: 0.000625\n",
      "Epoch [3893/20000], Loss: 128.56640625, Entropy -160.15011596679688, Learning Rate: 0.000625\n",
      "Epoch [3894/20000], Loss: 114.66033935546875, Entropy -132.3011932373047, Learning Rate: 0.000625\n",
      "Epoch [3895/20000], Loss: 107.93357849121094, Entropy -128.6358642578125, Learning Rate: 0.000625\n",
      "Epoch [3896/20000], Loss: 112.07559204101562, Entropy -133.48287963867188, Learning Rate: 0.000625\n",
      "Epoch [3897/20000], Loss: 112.23612976074219, Entropy -137.7987060546875, Learning Rate: 0.000625\n",
      "Epoch [3898/20000], Loss: 125.21287536621094, Entropy -149.16806030273438, Learning Rate: 0.000625\n",
      "Epoch [3899/20000], Loss: 133.4241485595703, Entropy -159.22836303710938, Learning Rate: 0.000625\n",
      "Epoch [3900/20000], Loss: 120.53761291503906, Entropy -144.60935974121094, Learning Rate: 0.000625\n",
      "Epoch [3901/20000], Loss: 124.28382873535156, Entropy -147.2305908203125, Learning Rate: 0.000625\n",
      "Epoch [3902/20000], Loss: 120.2650146484375, Entropy -148.10809326171875, Learning Rate: 0.000625\n",
      "Epoch [3903/20000], Loss: 120.18359375, Entropy -140.377197265625, Learning Rate: 0.000625\n",
      "Epoch [3904/20000], Loss: 120.38229370117188, Entropy -145.0859375, Learning Rate: 0.000625\n",
      "Epoch [3905/20000], Loss: 120.08729553222656, Entropy -137.38079833984375, Learning Rate: 0.000625\n",
      "Epoch [3906/20000], Loss: 122.76602172851562, Entropy -142.50489807128906, Learning Rate: 0.000625\n",
      "Epoch [3907/20000], Loss: 126.22416687011719, Entropy -142.98846435546875, Learning Rate: 0.000625\n",
      "Epoch [3908/20000], Loss: 117.51510620117188, Entropy -134.0325927734375, Learning Rate: 0.000625\n",
      "Epoch [3909/20000], Loss: 118.45346069335938, Entropy -141.531005859375, Learning Rate: 0.000625\n",
      "Epoch [3910/20000], Loss: 115.54154968261719, Entropy -141.9173126220703, Learning Rate: 0.000625\n",
      "Epoch [3911/20000], Loss: 120.12651062011719, Entropy -142.237548828125, Learning Rate: 0.000625\n",
      "Epoch [3912/20000], Loss: 117.91569519042969, Entropy -132.91287231445312, Learning Rate: 0.000625\n",
      "Epoch [3913/20000], Loss: 127.439208984375, Entropy -147.47610473632812, Learning Rate: 0.000625\n",
      "Epoch [3914/20000], Loss: 120.33917236328125, Entropy -141.33541870117188, Learning Rate: 0.000625\n",
      "Epoch [3915/20000], Loss: 118.55723571777344, Entropy -142.9837188720703, Learning Rate: 0.000625\n",
      "Epoch [3916/20000], Loss: 134.9955596923828, Entropy -164.258544921875, Learning Rate: 0.000625\n",
      "Epoch [3917/20000], Loss: 133.1141357421875, Entropy -159.939208984375, Learning Rate: 0.000625\n",
      "Epoch [3918/20000], Loss: 128.91152954101562, Entropy -151.37460327148438, Learning Rate: 0.000625\n",
      "Epoch [3919/20000], Loss: 111.99269104003906, Entropy -124.47793579101562, Learning Rate: 0.000625\n",
      "Epoch [3920/20000], Loss: 130.68614196777344, Entropy -158.68560791015625, Learning Rate: 0.000625\n",
      "Epoch [3921/20000], Loss: 113.09706115722656, Entropy -136.33169555664062, Learning Rate: 0.000625\n",
      "Epoch [3922/20000], Loss: 117.35118103027344, Entropy -129.1861572265625, Learning Rate: 0.000625\n",
      "Epoch [3923/20000], Loss: 120.09414672851562, Entropy -140.92242431640625, Learning Rate: 0.000625\n",
      "Epoch [3924/20000], Loss: 115.58821105957031, Entropy -136.78390502929688, Learning Rate: 0.000625\n",
      "Epoch [3925/20000], Loss: 125.83219909667969, Entropy -148.4537811279297, Learning Rate: 0.000625\n",
      "Epoch [3926/20000], Loss: 126.25607299804688, Entropy -134.6999969482422, Learning Rate: 0.000625\n",
      "Epoch [3927/20000], Loss: 122.12484741210938, Entropy -141.174560546875, Learning Rate: 0.000625\n",
      "Epoch [3928/20000], Loss: 117.19369506835938, Entropy -135.3581085205078, Learning Rate: 0.000625\n",
      "Epoch [3929/20000], Loss: 122.97642517089844, Entropy -144.78794860839844, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3930/20000], Loss: 123.19645690917969, Entropy -148.3883056640625, Learning Rate: 0.000625\n",
      "Epoch [3931/20000], Loss: 124.26840209960938, Entropy -140.15103149414062, Learning Rate: 0.000625\n",
      "Epoch [3932/20000], Loss: 121.66595458984375, Entropy -145.89321899414062, Learning Rate: 0.000625\n",
      "Epoch [3933/20000], Loss: 124.15240478515625, Entropy -140.48553466796875, Learning Rate: 0.000625\n",
      "Epoch [3934/20000], Loss: 113.69087219238281, Entropy -131.43936157226562, Learning Rate: 0.000625\n",
      "Epoch [3935/20000], Loss: 114.67799377441406, Entropy -140.02792358398438, Learning Rate: 0.000625\n",
      "Epoch [3936/20000], Loss: 109.52053833007812, Entropy -141.74795532226562, Learning Rate: 0.000625\n",
      "Epoch [3937/20000], Loss: 120.69535827636719, Entropy -144.22666931152344, Learning Rate: 0.000625\n",
      "Epoch [3938/20000], Loss: 131.3977508544922, Entropy -160.953125, Learning Rate: 0.000625\n",
      "Epoch [3939/20000], Loss: 130.02142333984375, Entropy -154.4704132080078, Learning Rate: 0.000625\n",
      "Epoch [3940/20000], Loss: 129.88922119140625, Entropy -153.95437622070312, Learning Rate: 0.000625\n",
      "Epoch [3941/20000], Loss: 123.10981750488281, Entropy -152.2789306640625, Learning Rate: 0.000625\n",
      "Epoch [3942/20000], Loss: 118.72320556640625, Entropy -147.61505126953125, Learning Rate: 0.000625\n",
      "Epoch [3943/20000], Loss: 119.74435424804688, Entropy -134.53555297851562, Learning Rate: 0.000625\n",
      "Epoch [3944/20000], Loss: 116.71392822265625, Entropy -144.04322814941406, Learning Rate: 0.000625\n",
      "Epoch [3945/20000], Loss: 128.221435546875, Entropy -146.4520263671875, Learning Rate: 0.000625\n",
      "Epoch [3946/20000], Loss: 126.89797973632812, Entropy -156.4423065185547, Learning Rate: 0.000625\n",
      "Epoch [3947/20000], Loss: 119.80233764648438, Entropy -130.56240844726562, Learning Rate: 0.000625\n",
      "Epoch [3948/20000], Loss: 130.4506378173828, Entropy -162.51171875, Learning Rate: 0.000625\n",
      "Epoch [3949/20000], Loss: 134.10154724121094, Entropy -158.15423583984375, Learning Rate: 0.000625\n",
      "Epoch [3950/20000], Loss: 118.54682922363281, Entropy -139.27471923828125, Learning Rate: 0.000625\n",
      "Epoch [3951/20000], Loss: 127.00115966796875, Entropy -150.30795288085938, Learning Rate: 0.000625\n",
      "Epoch [3952/20000], Loss: 113.38816833496094, Entropy -139.2911834716797, Learning Rate: 0.000625\n",
      "Epoch [3953/20000], Loss: 116.61927795410156, Entropy -130.80816650390625, Learning Rate: 0.000625\n",
      "Epoch [3954/20000], Loss: 121.29450988769531, Entropy -145.5479736328125, Learning Rate: 0.000625\n",
      "Epoch [3955/20000], Loss: 109.57286071777344, Entropy -134.71200561523438, Learning Rate: 0.000625\n",
      "Epoch [3956/20000], Loss: 118.57575988769531, Entropy -140.17283630371094, Learning Rate: 0.000625\n",
      "Epoch [3957/20000], Loss: 127.28706359863281, Entropy -149.5660858154297, Learning Rate: 0.000625\n",
      "Epoch [3958/20000], Loss: 125.60032653808594, Entropy -145.30050659179688, Learning Rate: 0.000625\n",
      "Epoch [3959/20000], Loss: 114.98770141601562, Entropy -129.90896606445312, Learning Rate: 0.000625\n",
      "Epoch [3960/20000], Loss: 119.07107543945312, Entropy -144.4920196533203, Learning Rate: 0.000625\n",
      "Epoch [3961/20000], Loss: 113.50822448730469, Entropy -137.33876037597656, Learning Rate: 0.000625\n",
      "Epoch [3962/20000], Loss: 125.55322265625, Entropy -149.5611572265625, Learning Rate: 0.000625\n",
      "Epoch [3963/20000], Loss: 127.68551635742188, Entropy -152.8817138671875, Learning Rate: 0.000625\n",
      "Epoch [3964/20000], Loss: 119.1783447265625, Entropy -141.11947631835938, Learning Rate: 0.000625\n",
      "Epoch [3965/20000], Loss: 129.01834106445312, Entropy -147.9700164794922, Learning Rate: 0.000625\n",
      "Epoch [3966/20000], Loss: 124.58100891113281, Entropy -148.62448120117188, Learning Rate: 0.000625\n",
      "Epoch [3967/20000], Loss: 131.89035034179688, Entropy -152.6083984375, Learning Rate: 0.000625\n",
      "Epoch [3968/20000], Loss: 118.30459594726562, Entropy -140.5897979736328, Learning Rate: 0.000625\n",
      "Epoch [3969/20000], Loss: 124.886474609375, Entropy -153.3430938720703, Learning Rate: 0.000625\n",
      "Epoch [3970/20000], Loss: 110.19795227050781, Entropy -119.52130126953125, Learning Rate: 0.000625\n",
      "Epoch [3971/20000], Loss: 112.97384643554688, Entropy -141.365234375, Learning Rate: 0.000625\n",
      "Epoch [3972/20000], Loss: 115.99250793457031, Entropy -139.342041015625, Learning Rate: 0.000625\n",
      "Epoch [3973/20000], Loss: 117.95600891113281, Entropy -144.19163513183594, Learning Rate: 0.000625\n",
      "Epoch [3974/20000], Loss: 125.19465637207031, Entropy -154.72427368164062, Learning Rate: 0.000625\n",
      "Epoch [3975/20000], Loss: 128.1688690185547, Entropy -149.70022583007812, Learning Rate: 0.000625\n",
      "Epoch [3976/20000], Loss: 119.37730407714844, Entropy -135.70782470703125, Learning Rate: 0.000625\n",
      "Epoch [3977/20000], Loss: 113.67327880859375, Entropy -129.1949462890625, Learning Rate: 0.000625\n",
      "Epoch [3978/20000], Loss: 129.72535705566406, Entropy -163.48910522460938, Learning Rate: 0.000625\n",
      "Epoch [3979/20000], Loss: 112.4990234375, Entropy -137.09173583984375, Learning Rate: 0.000625\n",
      "Epoch [3980/20000], Loss: 116.56828308105469, Entropy -138.31207275390625, Learning Rate: 0.000625\n",
      "Epoch [3981/20000], Loss: 116.90556335449219, Entropy -147.88497924804688, Learning Rate: 0.000625\n",
      "Epoch [3982/20000], Loss: 118.94532775878906, Entropy -136.44012451171875, Learning Rate: 0.000625\n",
      "Epoch [3983/20000], Loss: 125.69256591796875, Entropy -146.2318572998047, Learning Rate: 0.000625\n",
      "Epoch [3984/20000], Loss: 114.94831848144531, Entropy -134.72755432128906, Learning Rate: 0.0003125\n",
      "Epoch [3985/20000], Loss: 132.0754852294922, Entropy -153.47998046875, Learning Rate: 0.0003125\n",
      "Epoch [3986/20000], Loss: 128.21817016601562, Entropy -150.65455627441406, Learning Rate: 0.0003125\n",
      "Epoch [3987/20000], Loss: 125.7860107421875, Entropy -144.98052978515625, Learning Rate: 0.0003125\n",
      "Epoch [3988/20000], Loss: 132.9080810546875, Entropy -153.29534912109375, Learning Rate: 0.0003125\n",
      "Epoch [3989/20000], Loss: 123.89889526367188, Entropy -147.91616821289062, Learning Rate: 0.0003125\n",
      "Epoch [3990/20000], Loss: 131.00625610351562, Entropy -154.1619873046875, Learning Rate: 0.0003125\n",
      "Epoch [3991/20000], Loss: 120.93173217773438, Entropy -144.26931762695312, Learning Rate: 0.0003125\n",
      "Epoch [3992/20000], Loss: 136.4979705810547, Entropy -166.57391357421875, Learning Rate: 0.0003125\n",
      "Epoch [3993/20000], Loss: 117.42204284667969, Entropy -141.01329040527344, Learning Rate: 0.0003125\n",
      "Epoch [3994/20000], Loss: 126.78993225097656, Entropy -153.24880981445312, Learning Rate: 0.0003125\n",
      "Epoch [3995/20000], Loss: 117.94654846191406, Entropy -140.53851318359375, Learning Rate: 0.0003125\n",
      "Epoch [3996/20000], Loss: 123.74769592285156, Entropy -145.6334228515625, Learning Rate: 0.0003125\n",
      "Epoch [3997/20000], Loss: 127.94583129882812, Entropy -154.99386596679688, Learning Rate: 0.0003125\n",
      "Epoch [3998/20000], Loss: 127.97604370117188, Entropy -149.6999969482422, Learning Rate: 0.0003125\n",
      "Epoch [3999/20000], Loss: 120.19647216796875, Entropy -137.62615966796875, Learning Rate: 0.0003125\n",
      "Epoch [4000/20000], Loss: 112.15850830078125, Entropy -133.69085693359375, Learning Rate: 0.0003125\n",
      "Epoch [4001/20000], Loss: 121.25259399414062, Entropy -147.65939331054688, Learning Rate: 0.0003125\n",
      "Epoch [4002/20000], Loss: 119.9610595703125, Entropy -141.13037109375, Learning Rate: 0.0003125\n",
      "Epoch [4003/20000], Loss: 123.96546936035156, Entropy -144.23385620117188, Learning Rate: 0.0003125\n",
      "Epoch [4004/20000], Loss: 117.24253845214844, Entropy -137.1695556640625, Learning Rate: 0.0003125\n",
      "Epoch [4005/20000], Loss: 107.49296569824219, Entropy -122.16885375976562, Learning Rate: 0.0003125\n",
      "Epoch [4006/20000], Loss: 125.46031188964844, Entropy -150.50857543945312, Learning Rate: 0.0003125\n",
      "Epoch [4007/20000], Loss: 117.31990051269531, Entropy -138.1262969970703, Learning Rate: 0.0003125\n",
      "Epoch [4008/20000], Loss: 115.37278747558594, Entropy -126.46153259277344, Learning Rate: 0.0003125\n",
      "Epoch [4009/20000], Loss: 116.72312927246094, Entropy -139.2909393310547, Learning Rate: 0.0003125\n",
      "Epoch [4010/20000], Loss: 122.65299987792969, Entropy -144.85198974609375, Learning Rate: 0.0003125\n",
      "Epoch [4011/20000], Loss: 128.4665069580078, Entropy -146.5048828125, Learning Rate: 0.0003125\n",
      "Epoch [4012/20000], Loss: 124.96372985839844, Entropy -151.77297973632812, Learning Rate: 0.0003125\n",
      "Epoch [4013/20000], Loss: 122.89741516113281, Entropy -144.42605590820312, Learning Rate: 0.0003125\n",
      "Epoch [4014/20000], Loss: 117.10916137695312, Entropy -135.52044677734375, Learning Rate: 0.0003125\n",
      "Epoch [4015/20000], Loss: 117.10130310058594, Entropy -137.11541748046875, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4016/20000], Loss: 124.30085754394531, Entropy -149.3187255859375, Learning Rate: 0.0003125\n",
      "Epoch [4017/20000], Loss: 118.96902465820312, Entropy -138.63014221191406, Learning Rate: 0.0003125\n",
      "Epoch [4018/20000], Loss: 130.5436553955078, Entropy -153.3525390625, Learning Rate: 0.0003125\n",
      "Epoch [4019/20000], Loss: 116.883544921875, Entropy -134.08743286132812, Learning Rate: 0.0003125\n",
      "Epoch [4020/20000], Loss: 113.66957092285156, Entropy -129.11984252929688, Learning Rate: 0.0003125\n",
      "Epoch [4021/20000], Loss: 120.18753051757812, Entropy -144.6103973388672, Learning Rate: 0.0003125\n",
      "Epoch [4022/20000], Loss: 122.73307800292969, Entropy -147.534912109375, Learning Rate: 0.0003125\n",
      "Epoch [4023/20000], Loss: 130.68875122070312, Entropy -160.57742309570312, Learning Rate: 0.0003125\n",
      "Epoch [4024/20000], Loss: 115.38296508789062, Entropy -131.29522705078125, Learning Rate: 0.0003125\n",
      "Epoch [4025/20000], Loss: 121.76181030273438, Entropy -142.8223114013672, Learning Rate: 0.0003125\n",
      "Epoch [4026/20000], Loss: 124.40962219238281, Entropy -145.08432006835938, Learning Rate: 0.0003125\n",
      "Epoch [4027/20000], Loss: 117.23475646972656, Entropy -139.8854522705078, Learning Rate: 0.0003125\n",
      "Epoch [4028/20000], Loss: 118.21566772460938, Entropy -136.66766357421875, Learning Rate: 0.0003125\n",
      "Epoch [4029/20000], Loss: 112.64608764648438, Entropy -134.88916015625, Learning Rate: 0.0003125\n",
      "Epoch [4030/20000], Loss: 112.20281982421875, Entropy -123.58084106445312, Learning Rate: 0.0003125\n",
      "Epoch [4031/20000], Loss: 119.65570068359375, Entropy -136.5572509765625, Learning Rate: 0.0003125\n",
      "Epoch [4032/20000], Loss: 122.54371643066406, Entropy -148.9066162109375, Learning Rate: 0.0003125\n",
      "Epoch [4033/20000], Loss: 132.31056213378906, Entropy -152.23114013671875, Learning Rate: 0.0003125\n",
      "Epoch [4034/20000], Loss: 116.27239990234375, Entropy -133.31997680664062, Learning Rate: 0.0003125\n",
      "Epoch [4035/20000], Loss: 120.75038146972656, Entropy -141.77066040039062, Learning Rate: 0.0003125\n",
      "Epoch [4036/20000], Loss: 119.29466247558594, Entropy -142.5923309326172, Learning Rate: 0.0003125\n",
      "Epoch [4037/20000], Loss: 130.77120971679688, Entropy -164.26974487304688, Learning Rate: 0.0003125\n",
      "Epoch [4038/20000], Loss: 116.6815185546875, Entropy -141.3013916015625, Learning Rate: 0.0003125\n",
      "Epoch [4039/20000], Loss: 115.55229187011719, Entropy -134.0102996826172, Learning Rate: 0.0003125\n",
      "Epoch [4040/20000], Loss: 120.87646484375, Entropy -144.95863342285156, Learning Rate: 0.0003125\n",
      "Epoch [4041/20000], Loss: 121.04814147949219, Entropy -139.79257202148438, Learning Rate: 0.0003125\n",
      "Epoch [4042/20000], Loss: 128.6269989013672, Entropy -140.35946655273438, Learning Rate: 0.0003125\n",
      "Epoch [4043/20000], Loss: 122.29960632324219, Entropy -139.15533447265625, Learning Rate: 0.0003125\n",
      "Epoch [4044/20000], Loss: 108.50718688964844, Entropy -127.41830444335938, Learning Rate: 0.0003125\n",
      "Epoch [4045/20000], Loss: 113.83338928222656, Entropy -123.01547241210938, Learning Rate: 0.0003125\n",
      "Epoch [4046/20000], Loss: 117.3626708984375, Entropy -130.37606811523438, Learning Rate: 0.0003125\n",
      "Epoch [4047/20000], Loss: 116.67401123046875, Entropy -143.44268798828125, Learning Rate: 0.0003125\n",
      "Epoch [4048/20000], Loss: 126.52847290039062, Entropy -153.71929931640625, Learning Rate: 0.0003125\n",
      "Epoch [4049/20000], Loss: 128.36058044433594, Entropy -155.80453491210938, Learning Rate: 0.0003125\n",
      "Epoch [4050/20000], Loss: 117.47979736328125, Entropy -139.51531982421875, Learning Rate: 0.0003125\n",
      "Epoch [4051/20000], Loss: 126.10234069824219, Entropy -144.51797485351562, Learning Rate: 0.0003125\n",
      "Epoch [4052/20000], Loss: 123.99937438964844, Entropy -145.6915283203125, Learning Rate: 0.0003125\n",
      "Epoch [4053/20000], Loss: 118.42088317871094, Entropy -140.1239013671875, Learning Rate: 0.0003125\n",
      "Epoch [4054/20000], Loss: 138.09124755859375, Entropy -162.55931091308594, Learning Rate: 0.0003125\n",
      "Epoch [4055/20000], Loss: 138.54879760742188, Entropy -164.07171630859375, Learning Rate: 0.0003125\n",
      "Epoch [4056/20000], Loss: 113.82987976074219, Entropy -132.76873779296875, Learning Rate: 0.0003125\n",
      "Epoch [4057/20000], Loss: 117.27507019042969, Entropy -135.83291625976562, Learning Rate: 0.0003125\n",
      "Epoch [4058/20000], Loss: 120.94772338867188, Entropy -142.49578857421875, Learning Rate: 0.0003125\n",
      "Epoch [4059/20000], Loss: 122.9949951171875, Entropy -144.45327758789062, Learning Rate: 0.0003125\n",
      "Epoch [4060/20000], Loss: 118.97233581542969, Entropy -138.77008056640625, Learning Rate: 0.0003125\n",
      "Epoch [4061/20000], Loss: 114.28213500976562, Entropy -139.21920776367188, Learning Rate: 0.0003125\n",
      "Epoch [4062/20000], Loss: 112.45643615722656, Entropy -132.57733154296875, Learning Rate: 0.0003125\n",
      "Epoch [4063/20000], Loss: 121.4534912109375, Entropy -144.92681884765625, Learning Rate: 0.0003125\n",
      "Epoch [4064/20000], Loss: 123.11477661132812, Entropy -149.66810607910156, Learning Rate: 0.0003125\n",
      "Epoch [4065/20000], Loss: 116.07789611816406, Entropy -145.04185485839844, Learning Rate: 0.0003125\n",
      "Epoch [4066/20000], Loss: 112.1971435546875, Entropy -135.83331298828125, Learning Rate: 0.0003125\n",
      "Epoch [4067/20000], Loss: 119.90548706054688, Entropy -142.3423614501953, Learning Rate: 0.0003125\n",
      "Epoch [4068/20000], Loss: 114.30850219726562, Entropy -128.38633728027344, Learning Rate: 0.0003125\n",
      "Epoch [4069/20000], Loss: 120.5107421875, Entropy -143.5070343017578, Learning Rate: 0.0003125\n",
      "Epoch [4070/20000], Loss: 121.41352844238281, Entropy -149.7754364013672, Learning Rate: 0.0003125\n",
      "Epoch [4071/20000], Loss: 115.56716918945312, Entropy -137.2273712158203, Learning Rate: 0.0003125\n",
      "Epoch [4072/20000], Loss: 121.06234741210938, Entropy -138.62161254882812, Learning Rate: 0.0003125\n",
      "Epoch [4073/20000], Loss: 117.32473754882812, Entropy -131.51605224609375, Learning Rate: 0.0003125\n",
      "Epoch [4074/20000], Loss: 114.82420349121094, Entropy -131.66006469726562, Learning Rate: 0.0003125\n",
      "Epoch [4075/20000], Loss: 120.25981140136719, Entropy -143.1985626220703, Learning Rate: 0.0003125\n",
      "Epoch [4076/20000], Loss: 129.11680603027344, Entropy -147.28265380859375, Learning Rate: 0.0003125\n",
      "Epoch [4077/20000], Loss: 121.67887878417969, Entropy -144.36105346679688, Learning Rate: 0.0003125\n",
      "Epoch [4078/20000], Loss: 118.44728088378906, Entropy -144.11160278320312, Learning Rate: 0.0003125\n",
      "Epoch [4079/20000], Loss: 122.33270263671875, Entropy -149.7493896484375, Learning Rate: 0.0003125\n",
      "Epoch [4080/20000], Loss: 124.68060302734375, Entropy -145.58151245117188, Learning Rate: 0.0003125\n",
      "Epoch [4081/20000], Loss: 116.00444030761719, Entropy -147.45562744140625, Learning Rate: 0.0003125\n",
      "Epoch [4082/20000], Loss: 107.88761901855469, Entropy -125.41448974609375, Learning Rate: 0.0003125\n",
      "Epoch [4083/20000], Loss: 126.17410278320312, Entropy -147.9588165283203, Learning Rate: 0.0003125\n",
      "Epoch [4084/20000], Loss: 118.27568054199219, Entropy -145.97540283203125, Learning Rate: 0.0003125\n",
      "Epoch [4085/20000], Loss: 121.09596252441406, Entropy -138.02023315429688, Learning Rate: 0.0003125\n",
      "Epoch [4086/20000], Loss: 116.58262634277344, Entropy -139.90884399414062, Learning Rate: 0.0003125\n",
      "Epoch [4087/20000], Loss: 124.82933044433594, Entropy -152.41598510742188, Learning Rate: 0.0003125\n",
      "Epoch [4088/20000], Loss: 121.13673400878906, Entropy -152.25820922851562, Learning Rate: 0.0003125\n",
      "Epoch [4089/20000], Loss: 112.89622497558594, Entropy -135.4168701171875, Learning Rate: 0.0003125\n",
      "Epoch [4090/20000], Loss: 123.55404663085938, Entropy -143.6333770751953, Learning Rate: 0.0003125\n",
      "Epoch [4091/20000], Loss: 120.51040649414062, Entropy -148.30386352539062, Learning Rate: 0.0003125\n",
      "Epoch [4092/20000], Loss: 118.92349243164062, Entropy -145.37290954589844, Learning Rate: 0.0003125\n",
      "Epoch [4093/20000], Loss: 109.01753234863281, Entropy -131.97421264648438, Learning Rate: 0.0003125\n",
      "Epoch [4094/20000], Loss: 121.3876953125, Entropy -148.93637084960938, Learning Rate: 0.0003125\n",
      "Epoch [4095/20000], Loss: 119.76957702636719, Entropy -135.46560668945312, Learning Rate: 0.0003125\n",
      "Epoch [4096/20000], Loss: 110.86390686035156, Entropy -131.79006958007812, Learning Rate: 0.0003125\n",
      "Epoch [4097/20000], Loss: 113.44322204589844, Entropy -136.0345458984375, Learning Rate: 0.0003125\n",
      "Epoch [4098/20000], Loss: 108.95921325683594, Entropy -130.910888671875, Learning Rate: 0.0003125\n",
      "Epoch [4099/20000], Loss: 118.17605590820312, Entropy -140.42800903320312, Learning Rate: 0.0003125\n",
      "Epoch [4100/20000], Loss: 130.48817443847656, Entropy -152.93392944335938, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4101/20000], Loss: 127.94990539550781, Entropy -160.28445434570312, Learning Rate: 0.0003125\n",
      "Epoch [4102/20000], Loss: 136.2539825439453, Entropy -162.62966918945312, Learning Rate: 0.0003125\n",
      "Epoch [4103/20000], Loss: 123.82234191894531, Entropy -146.42803955078125, Learning Rate: 0.0003125\n",
      "Epoch [4104/20000], Loss: 130.55874633789062, Entropy -156.44741821289062, Learning Rate: 0.0003125\n",
      "Epoch [4105/20000], Loss: 113.38302612304688, Entropy -139.03305053710938, Learning Rate: 0.0003125\n",
      "Epoch [4106/20000], Loss: 120.64781188964844, Entropy -148.6903076171875, Learning Rate: 0.0003125\n",
      "Epoch [4107/20000], Loss: 124.577880859375, Entropy -153.55752563476562, Learning Rate: 0.0003125\n",
      "Epoch [4108/20000], Loss: 118.41464233398438, Entropy -134.1505126953125, Learning Rate: 0.0003125\n",
      "Epoch [4109/20000], Loss: 114.8546142578125, Entropy -138.42056274414062, Learning Rate: 0.0003125\n",
      "Epoch [4110/20000], Loss: 112.83580017089844, Entropy -133.01885986328125, Learning Rate: 0.0003125\n",
      "Epoch [4111/20000], Loss: 120.50639343261719, Entropy -143.85736083984375, Learning Rate: 0.0003125\n",
      "Epoch [4112/20000], Loss: 126.1075439453125, Entropy -151.1753692626953, Learning Rate: 0.0003125\n",
      "Epoch [4113/20000], Loss: 114.77078247070312, Entropy -140.3765869140625, Learning Rate: 0.0003125\n",
      "Epoch [4114/20000], Loss: 121.20318603515625, Entropy -141.97091674804688, Learning Rate: 0.0003125\n",
      "Epoch [4115/20000], Loss: 117.13204956054688, Entropy -148.4214324951172, Learning Rate: 0.0003125\n",
      "Epoch [4116/20000], Loss: 130.6896209716797, Entropy -158.9342041015625, Learning Rate: 0.0003125\n",
      "Epoch [4117/20000], Loss: 118.17414855957031, Entropy -138.55206298828125, Learning Rate: 0.0003125\n",
      "Epoch [4118/20000], Loss: 118.36056518554688, Entropy -135.42825317382812, Learning Rate: 0.0003125\n",
      "Epoch [4119/20000], Loss: 117.26551818847656, Entropy -140.34683227539062, Learning Rate: 0.0003125\n",
      "Epoch [4120/20000], Loss: 129.89381408691406, Entropy -157.56802368164062, Learning Rate: 0.0003125\n",
      "Epoch [4121/20000], Loss: 126.34719848632812, Entropy -152.45492553710938, Learning Rate: 0.0003125\n",
      "Epoch [4122/20000], Loss: 122.749755859375, Entropy -145.64944458007812, Learning Rate: 0.0003125\n",
      "Epoch [4123/20000], Loss: 112.54292297363281, Entropy -130.71414184570312, Learning Rate: 0.0003125\n",
      "Epoch [4124/20000], Loss: 121.47489929199219, Entropy -145.48275756835938, Learning Rate: 0.0003125\n",
      "Epoch [4125/20000], Loss: 110.04220581054688, Entropy -133.9245147705078, Learning Rate: 0.0003125\n",
      "Epoch [4126/20000], Loss: 132.45095825195312, Entropy -157.1207275390625, Learning Rate: 0.0003125\n",
      "Epoch [4127/20000], Loss: 120.62666320800781, Entropy -135.15904235839844, Learning Rate: 0.0003125\n",
      "Epoch [4128/20000], Loss: 118.04798889160156, Entropy -140.02145385742188, Learning Rate: 0.0003125\n",
      "Epoch [4129/20000], Loss: 115.47557067871094, Entropy -138.3751220703125, Learning Rate: 0.0003125\n",
      "Epoch [4130/20000], Loss: 108.92153930664062, Entropy -135.55276489257812, Learning Rate: 0.0003125\n",
      "Epoch [4131/20000], Loss: 119.86065673828125, Entropy -137.14703369140625, Learning Rate: 0.0003125\n",
      "Epoch [4132/20000], Loss: 121.04972839355469, Entropy -143.7582244873047, Learning Rate: 0.0003125\n",
      "Epoch [4133/20000], Loss: 114.71917724609375, Entropy -139.27749633789062, Learning Rate: 0.0003125\n",
      "Epoch [4134/20000], Loss: 113.83802795410156, Entropy -139.41493225097656, Learning Rate: 0.0003125\n",
      "Epoch [4135/20000], Loss: 118.65007019042969, Entropy -143.4639129638672, Learning Rate: 0.0003125\n",
      "Epoch [4136/20000], Loss: 121.21168518066406, Entropy -138.4956817626953, Learning Rate: 0.0003125\n",
      "Epoch [4137/20000], Loss: 127.76956176757812, Entropy -151.43002319335938, Learning Rate: 0.0003125\n",
      "Epoch [4138/20000], Loss: 120.494873046875, Entropy -146.0470428466797, Learning Rate: 0.0003125\n",
      "Epoch [4139/20000], Loss: 115.15275573730469, Entropy -137.79373168945312, Learning Rate: 0.0003125\n",
      "Epoch [4140/20000], Loss: 117.97175598144531, Entropy -137.61912536621094, Learning Rate: 0.0003125\n",
      "Epoch [4141/20000], Loss: 117.84048461914062, Entropy -139.49713134765625, Learning Rate: 0.0003125\n",
      "Epoch [4142/20000], Loss: 121.91552734375, Entropy -136.9267578125, Learning Rate: 0.0003125\n",
      "Epoch [4143/20000], Loss: 122.39585876464844, Entropy -152.7142791748047, Learning Rate: 0.0003125\n",
      "Epoch [4144/20000], Loss: 119.95515441894531, Entropy -145.04766845703125, Learning Rate: 0.0003125\n",
      "Epoch [4145/20000], Loss: 113.21665954589844, Entropy -125.14309692382812, Learning Rate: 0.0003125\n",
      "Epoch [4146/20000], Loss: 120.09129333496094, Entropy -144.21218872070312, Learning Rate: 0.0003125\n",
      "Epoch [4147/20000], Loss: 112.76072692871094, Entropy -134.59207153320312, Learning Rate: 0.0003125\n",
      "Epoch [4148/20000], Loss: 108.08857727050781, Entropy -125.853515625, Learning Rate: 0.0003125\n",
      "Epoch [4149/20000], Loss: 119.82652282714844, Entropy -140.30397033691406, Learning Rate: 0.0003125\n",
      "Epoch [4150/20000], Loss: 124.20478820800781, Entropy -141.6209716796875, Learning Rate: 0.0003125\n",
      "Epoch [4151/20000], Loss: 128.01058959960938, Entropy -154.781494140625, Learning Rate: 0.0003125\n",
      "Epoch [4152/20000], Loss: 109.57759094238281, Entropy -127.50437927246094, Learning Rate: 0.0003125\n",
      "Epoch [4153/20000], Loss: 112.28988647460938, Entropy -134.09555053710938, Learning Rate: 0.0003125\n",
      "Epoch [4154/20000], Loss: 109.3638916015625, Entropy -127.2430419921875, Learning Rate: 0.0003125\n",
      "Epoch [4155/20000], Loss: 123.74174499511719, Entropy -154.50096130371094, Learning Rate: 0.0003125\n",
      "Epoch [4156/20000], Loss: 123.56443786621094, Entropy -143.50132751464844, Learning Rate: 0.0003125\n",
      "Epoch [4157/20000], Loss: 138.71707153320312, Entropy -163.03195190429688, Learning Rate: 0.0003125\n",
      "Epoch [4158/20000], Loss: 111.16134643554688, Entropy -127.39437866210938, Learning Rate: 0.0003125\n",
      "Epoch [4159/20000], Loss: 118.44383239746094, Entropy -142.77288818359375, Learning Rate: 0.0003125\n",
      "Epoch [4160/20000], Loss: 115.0467529296875, Entropy -135.53359985351562, Learning Rate: 0.0003125\n",
      "Epoch [4161/20000], Loss: 141.94850158691406, Entropy -166.1126708984375, Learning Rate: 0.0003125\n",
      "Epoch [4162/20000], Loss: 130.96510314941406, Entropy -163.21202087402344, Learning Rate: 0.0003125\n",
      "Epoch [4163/20000], Loss: 117.75811767578125, Entropy -140.37130737304688, Learning Rate: 0.0003125\n",
      "Epoch [4164/20000], Loss: 110.57147216796875, Entropy -129.575439453125, Learning Rate: 0.0003125\n",
      "Epoch [4165/20000], Loss: 120.76361083984375, Entropy -137.99188232421875, Learning Rate: 0.0003125\n",
      "Epoch [4166/20000], Loss: 120.46998596191406, Entropy -135.2494659423828, Learning Rate: 0.0003125\n",
      "Epoch [4167/20000], Loss: 117.2724609375, Entropy -135.76683044433594, Learning Rate: 0.0003125\n",
      "Epoch [4168/20000], Loss: 128.15576171875, Entropy -152.2848663330078, Learning Rate: 0.0003125\n",
      "Epoch [4169/20000], Loss: 122.666015625, Entropy -145.797119140625, Learning Rate: 0.0003125\n",
      "Epoch [4170/20000], Loss: 120.18263244628906, Entropy -140.07611083984375, Learning Rate: 0.0003125\n",
      "Epoch [4171/20000], Loss: 112.53146362304688, Entropy -133.00286865234375, Learning Rate: 0.0003125\n",
      "Epoch [4172/20000], Loss: 123.45266723632812, Entropy -144.1934814453125, Learning Rate: 0.0003125\n",
      "Epoch [4173/20000], Loss: 118.37271118164062, Entropy -140.48838806152344, Learning Rate: 0.0003125\n",
      "Epoch [4174/20000], Loss: 114.62823486328125, Entropy -136.37509155273438, Learning Rate: 0.0003125\n",
      "Epoch [4175/20000], Loss: 120.13520812988281, Entropy -139.74310302734375, Learning Rate: 0.0003125\n",
      "Epoch [4176/20000], Loss: 117.98854064941406, Entropy -137.85232543945312, Learning Rate: 0.0003125\n",
      "Epoch [4177/20000], Loss: 125.55616760253906, Entropy -138.43234252929688, Learning Rate: 0.0003125\n",
      "Epoch [4178/20000], Loss: 113.11140441894531, Entropy -132.80740356445312, Learning Rate: 0.0003125\n",
      "Epoch [4179/20000], Loss: 106.13009643554688, Entropy -120.81602478027344, Learning Rate: 0.0003125\n",
      "Epoch [4180/20000], Loss: 118.52445983886719, Entropy -136.3077392578125, Learning Rate: 0.0003125\n",
      "Epoch [4181/20000], Loss: 131.20791625976562, Entropy -153.8214111328125, Learning Rate: 0.0003125\n",
      "Epoch [4182/20000], Loss: 122.13348388671875, Entropy -133.40927124023438, Learning Rate: 0.0003125\n",
      "Epoch [4183/20000], Loss: 110.85807800292969, Entropy -129.76901245117188, Learning Rate: 0.0003125\n",
      "Epoch [4184/20000], Loss: 113.93309020996094, Entropy -141.54849243164062, Learning Rate: 0.0003125\n",
      "Epoch [4185/20000], Loss: 128.42630004882812, Entropy -157.16790771484375, Learning Rate: 0.00015625\n",
      "Epoch [4186/20000], Loss: 120.30526733398438, Entropy -140.1556396484375, Learning Rate: 0.00015625\n",
      "Epoch [4187/20000], Loss: 126.99967956542969, Entropy -150.935546875, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4188/20000], Loss: 121.01472473144531, Entropy -149.91519165039062, Learning Rate: 0.00015625\n",
      "Epoch [4189/20000], Loss: 116.28834533691406, Entropy -132.13990783691406, Learning Rate: 0.00015625\n",
      "Epoch [4190/20000], Loss: 131.0917510986328, Entropy -167.77491760253906, Learning Rate: 0.00015625\n",
      "Epoch [4191/20000], Loss: 121.84797668457031, Entropy -145.50357055664062, Learning Rate: 0.00015625\n",
      "Epoch [4192/20000], Loss: 121.30880737304688, Entropy -146.05715942382812, Learning Rate: 0.00015625\n",
      "Epoch [4193/20000], Loss: 110.44873046875, Entropy -135.32716369628906, Learning Rate: 0.00015625\n",
      "Epoch [4194/20000], Loss: 119.54588317871094, Entropy -142.6183624267578, Learning Rate: 0.00015625\n",
      "Epoch [4195/20000], Loss: 121.47943115234375, Entropy -146.46551513671875, Learning Rate: 0.00015625\n",
      "Epoch [4196/20000], Loss: 116.10845947265625, Entropy -135.05728149414062, Learning Rate: 0.00015625\n",
      "Epoch [4197/20000], Loss: 126.38009643554688, Entropy -149.188720703125, Learning Rate: 0.00015625\n",
      "Epoch [4198/20000], Loss: 129.4770965576172, Entropy -145.03323364257812, Learning Rate: 0.00015625\n",
      "Epoch [4199/20000], Loss: 118.55947875976562, Entropy -143.24749755859375, Learning Rate: 0.00015625\n",
      "Epoch [4200/20000], Loss: 123.99028015136719, Entropy -145.870849609375, Learning Rate: 0.00015625\n",
      "Epoch [4201/20000], Loss: 114.17843627929688, Entropy -136.41265869140625, Learning Rate: 0.00015625\n",
      "Epoch [4202/20000], Loss: 114.70889282226562, Entropy -132.61618041992188, Learning Rate: 0.00015625\n",
      "Epoch [4203/20000], Loss: 110.45417785644531, Entropy -126.96458435058594, Learning Rate: 0.00015625\n",
      "Epoch [4204/20000], Loss: 119.76853942871094, Entropy -142.1729278564453, Learning Rate: 0.00015625\n",
      "Epoch [4205/20000], Loss: 115.95843505859375, Entropy -124.43292236328125, Learning Rate: 0.00015625\n",
      "Epoch [4206/20000], Loss: 124.45713806152344, Entropy -145.8292999267578, Learning Rate: 0.00015625\n",
      "Epoch [4207/20000], Loss: 113.00465393066406, Entropy -136.02674865722656, Learning Rate: 0.00015625\n",
      "Epoch [4208/20000], Loss: 109.69023132324219, Entropy -132.2941131591797, Learning Rate: 0.00015625\n",
      "Epoch [4209/20000], Loss: 122.71034240722656, Entropy -144.0220489501953, Learning Rate: 0.00015625\n",
      "Epoch [4210/20000], Loss: 115.67567443847656, Entropy -136.4438018798828, Learning Rate: 0.00015625\n",
      "Epoch [4211/20000], Loss: 119.46009826660156, Entropy -140.09378051757812, Learning Rate: 0.00015625\n",
      "Epoch [4212/20000], Loss: 109.61366271972656, Entropy -135.00588989257812, Learning Rate: 0.00015625\n",
      "Epoch [4213/20000], Loss: 117.44244384765625, Entropy -133.48422241210938, Learning Rate: 0.00015625\n",
      "Epoch [4214/20000], Loss: 120.38212585449219, Entropy -143.88626098632812, Learning Rate: 0.00015625\n",
      "Epoch [4215/20000], Loss: 112.76158142089844, Entropy -133.25050354003906, Learning Rate: 0.00015625\n",
      "Epoch [4216/20000], Loss: 125.1751708984375, Entropy -150.26229858398438, Learning Rate: 0.00015625\n",
      "Epoch [4217/20000], Loss: 116.20030212402344, Entropy -138.3193817138672, Learning Rate: 0.00015625\n",
      "Epoch [4218/20000], Loss: 112.86602783203125, Entropy -134.03042602539062, Learning Rate: 0.00015625\n",
      "Epoch [4219/20000], Loss: 119.06309509277344, Entropy -134.88406372070312, Learning Rate: 0.00015625\n",
      "Epoch [4220/20000], Loss: 116.64851379394531, Entropy -139.5729522705078, Learning Rate: 0.00015625\n",
      "Epoch [4221/20000], Loss: 113.63900756835938, Entropy -136.16281127929688, Learning Rate: 0.00015625\n",
      "Epoch [4222/20000], Loss: 123.84242248535156, Entropy -157.1476287841797, Learning Rate: 0.00015625\n",
      "Epoch [4223/20000], Loss: 119.79792785644531, Entropy -151.74990844726562, Learning Rate: 0.00015625\n",
      "Epoch [4224/20000], Loss: 107.94036865234375, Entropy -127.51702880859375, Learning Rate: 0.00015625\n",
      "Epoch [4225/20000], Loss: 109.65142822265625, Entropy -130.66827392578125, Learning Rate: 0.00015625\n",
      "Epoch [4226/20000], Loss: 125.7484130859375, Entropy -147.18502807617188, Learning Rate: 0.00015625\n",
      "Epoch [4227/20000], Loss: 118.51577758789062, Entropy -137.26275634765625, Learning Rate: 0.00015625\n",
      "Epoch [4228/20000], Loss: 116.49372863769531, Entropy -135.6769256591797, Learning Rate: 0.00015625\n",
      "Epoch [4229/20000], Loss: 122.71340942382812, Entropy -145.26971435546875, Learning Rate: 0.00015625\n",
      "Epoch [4230/20000], Loss: 116.63117980957031, Entropy -139.3291473388672, Learning Rate: 0.00015625\n",
      "Epoch [4231/20000], Loss: 118.07354736328125, Entropy -142.90151977539062, Learning Rate: 0.00015625\n",
      "Epoch [4232/20000], Loss: 115.71304321289062, Entropy -137.0315704345703, Learning Rate: 0.00015625\n",
      "Epoch [4233/20000], Loss: 126.08261108398438, Entropy -140.56729125976562, Learning Rate: 0.00015625\n",
      "Epoch [4234/20000], Loss: 112.24050903320312, Entropy -133.70252990722656, Learning Rate: 0.00015625\n",
      "Epoch [4235/20000], Loss: 126.71156311035156, Entropy -155.39369201660156, Learning Rate: 0.00015625\n",
      "Epoch [4236/20000], Loss: 122.39291381835938, Entropy -150.756103515625, Learning Rate: 0.00015625\n",
      "Epoch [4237/20000], Loss: 116.56771850585938, Entropy -140.33816528320312, Learning Rate: 0.00015625\n",
      "Epoch [4238/20000], Loss: 118.32733154296875, Entropy -141.3502655029297, Learning Rate: 0.00015625\n",
      "Epoch [4239/20000], Loss: 121.90753173828125, Entropy -135.90460205078125, Learning Rate: 0.00015625\n",
      "Epoch [4240/20000], Loss: 119.32225036621094, Entropy -141.322998046875, Learning Rate: 0.00015625\n",
      "Epoch [4241/20000], Loss: 120.41949462890625, Entropy -152.06488037109375, Learning Rate: 0.00015625\n",
      "Epoch [4242/20000], Loss: 121.3160400390625, Entropy -144.8281707763672, Learning Rate: 0.00015625\n",
      "Epoch [4243/20000], Loss: 124.92633056640625, Entropy -150.9889678955078, Learning Rate: 0.00015625\n",
      "Epoch [4244/20000], Loss: 114.89642333984375, Entropy -143.29515075683594, Learning Rate: 0.00015625\n",
      "Epoch [4245/20000], Loss: 112.60533142089844, Entropy -132.95065307617188, Learning Rate: 0.00015625\n",
      "Epoch [4246/20000], Loss: 117.11358642578125, Entropy -136.14039611816406, Learning Rate: 0.00015625\n",
      "Epoch [4247/20000], Loss: 115.21702575683594, Entropy -137.45953369140625, Learning Rate: 0.00015625\n",
      "Epoch [4248/20000], Loss: 120.84930419921875, Entropy -144.36309814453125, Learning Rate: 0.00015625\n",
      "Epoch [4249/20000], Loss: 121.76376342773438, Entropy -140.82589721679688, Learning Rate: 0.00015625\n",
      "Epoch [4250/20000], Loss: 119.92549133300781, Entropy -141.55850219726562, Learning Rate: 0.00015625\n",
      "Epoch [4251/20000], Loss: 118.28096008300781, Entropy -146.6314239501953, Learning Rate: 0.00015625\n",
      "Epoch [4252/20000], Loss: 104.3812255859375, Entropy -128.63385009765625, Learning Rate: 0.00015625\n",
      "Epoch [4253/20000], Loss: 116.467529296875, Entropy -146.0481719970703, Learning Rate: 0.00015625\n",
      "Epoch [4254/20000], Loss: 118.2271728515625, Entropy -136.8212432861328, Learning Rate: 0.00015625\n",
      "Epoch [4255/20000], Loss: 114.80027770996094, Entropy -145.3331298828125, Learning Rate: 0.00015625\n",
      "Epoch [4256/20000], Loss: 109.23605346679688, Entropy -134.23802185058594, Learning Rate: 0.00015625\n",
      "Epoch [4257/20000], Loss: 116.84800720214844, Entropy -146.95578002929688, Learning Rate: 0.00015625\n",
      "Epoch [4258/20000], Loss: 112.77348327636719, Entropy -138.22549438476562, Learning Rate: 0.00015625\n",
      "Epoch [4259/20000], Loss: 114.796142578125, Entropy -134.26675415039062, Learning Rate: 0.00015625\n",
      "Epoch [4260/20000], Loss: 107.44354248046875, Entropy -125.62417602539062, Learning Rate: 0.00015625\n",
      "Epoch [4261/20000], Loss: 112.68647766113281, Entropy -136.29013061523438, Learning Rate: 0.00015625\n",
      "Epoch [4262/20000], Loss: 117.09628295898438, Entropy -132.93048095703125, Learning Rate: 0.00015625\n",
      "Epoch [4263/20000], Loss: 114.91073608398438, Entropy -138.2023468017578, Learning Rate: 0.00015625\n",
      "Epoch [4264/20000], Loss: 118.43475341796875, Entropy -137.91445922851562, Learning Rate: 0.00015625\n",
      "Epoch [4265/20000], Loss: 110.98611450195312, Entropy -133.9688720703125, Learning Rate: 0.00015625\n",
      "Epoch [4266/20000], Loss: 117.30558776855469, Entropy -142.02371215820312, Learning Rate: 0.00015625\n",
      "Epoch [4267/20000], Loss: 105.7275390625, Entropy -124.17214965820312, Learning Rate: 0.00015625\n",
      "Epoch [4268/20000], Loss: 131.68836975097656, Entropy -156.4610137939453, Learning Rate: 0.00015625\n",
      "Epoch [4269/20000], Loss: 119.03279113769531, Entropy -135.66915893554688, Learning Rate: 0.00015625\n",
      "Epoch [4270/20000], Loss: 129.93345642089844, Entropy -162.38473510742188, Learning Rate: 0.00015625\n",
      "Epoch [4271/20000], Loss: 128.8145294189453, Entropy -153.3463592529297, Learning Rate: 0.00015625\n",
      "Epoch [4272/20000], Loss: 116.4822998046875, Entropy -141.34547424316406, Learning Rate: 0.00015625\n",
      "Epoch [4273/20000], Loss: 119.73249816894531, Entropy -139.4408721923828, Learning Rate: 0.00015625\n",
      "Epoch [4274/20000], Loss: 115.86561584472656, Entropy -132.1012725830078, Learning Rate: 0.00015625\n",
      "Epoch [4275/20000], Loss: 119.66108703613281, Entropy -140.0286865234375, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4276/20000], Loss: 117.27879333496094, Entropy -138.70355224609375, Learning Rate: 0.00015625\n",
      "Epoch [4277/20000], Loss: 123.26364135742188, Entropy -145.94500732421875, Learning Rate: 0.00015625\n",
      "Epoch [4278/20000], Loss: 117.57861328125, Entropy -141.28741455078125, Learning Rate: 0.00015625\n",
      "Epoch [4279/20000], Loss: 119.86187744140625, Entropy -137.69097900390625, Learning Rate: 0.00015625\n",
      "Epoch [4280/20000], Loss: 110.82002258300781, Entropy -128.8818359375, Learning Rate: 0.00015625\n",
      "Epoch [4281/20000], Loss: 120.48744201660156, Entropy -143.59849548339844, Learning Rate: 0.00015625\n",
      "Epoch [4282/20000], Loss: 124.90635681152344, Entropy -149.61520385742188, Learning Rate: 0.00015625\n",
      "Epoch [4283/20000], Loss: 111.92814636230469, Entropy -135.47686767578125, Learning Rate: 0.00015625\n",
      "Epoch [4284/20000], Loss: 104.53707885742188, Entropy -124.06703186035156, Learning Rate: 0.00015625\n",
      "Epoch [4285/20000], Loss: 120.70556640625, Entropy -142.25498962402344, Learning Rate: 0.00015625\n",
      "Epoch [4286/20000], Loss: 118.33512878417969, Entropy -139.8690185546875, Learning Rate: 0.00015625\n",
      "Epoch [4287/20000], Loss: 125.27632141113281, Entropy -151.302734375, Learning Rate: 0.00015625\n",
      "Epoch [4288/20000], Loss: 118.93243408203125, Entropy -143.8572540283203, Learning Rate: 0.00015625\n",
      "Epoch [4289/20000], Loss: 110.4266357421875, Entropy -131.35336303710938, Learning Rate: 0.00015625\n",
      "Epoch [4290/20000], Loss: 125.78436279296875, Entropy -153.03485107421875, Learning Rate: 0.00015625\n",
      "Epoch [4291/20000], Loss: 119.21101379394531, Entropy -145.36904907226562, Learning Rate: 0.00015625\n",
      "Epoch [4292/20000], Loss: 114.85426330566406, Entropy -125.8797607421875, Learning Rate: 0.00015625\n",
      "Epoch [4293/20000], Loss: 118.31716918945312, Entropy -146.2631378173828, Learning Rate: 0.00015625\n",
      "Epoch [4294/20000], Loss: 127.42167663574219, Entropy -153.5186767578125, Learning Rate: 0.00015625\n",
      "Epoch [4295/20000], Loss: 105.87503051757812, Entropy -129.58218383789062, Learning Rate: 0.00015625\n",
      "Epoch [4296/20000], Loss: 125.40834045410156, Entropy -148.129638671875, Learning Rate: 0.00015625\n",
      "Epoch [4297/20000], Loss: 154.90289306640625, Entropy -139.95733642578125, Learning Rate: 0.00015625\n",
      "Epoch [4298/20000], Loss: 122.82400512695312, Entropy -143.4383544921875, Learning Rate: 0.00015625\n",
      "Epoch [4299/20000], Loss: 117.17828369140625, Entropy -140.65618896484375, Learning Rate: 0.00015625\n",
      "Epoch [4300/20000], Loss: 126.23292541503906, Entropy -146.697265625, Learning Rate: 0.00015625\n",
      "Epoch [4301/20000], Loss: 119.25344848632812, Entropy -144.21978759765625, Learning Rate: 0.00015625\n",
      "Epoch [4302/20000], Loss: 126.86001586914062, Entropy -152.21954345703125, Learning Rate: 0.00015625\n",
      "Epoch [4303/20000], Loss: 114.24403381347656, Entropy -139.60830688476562, Learning Rate: 0.00015625\n",
      "Epoch [4304/20000], Loss: 118.25672912597656, Entropy -140.5791015625, Learning Rate: 0.00015625\n",
      "Epoch [4305/20000], Loss: 121.43832397460938, Entropy -136.59707641601562, Learning Rate: 0.00015625\n",
      "Epoch [4306/20000], Loss: 127.02507019042969, Entropy -148.53982543945312, Learning Rate: 0.00015625\n",
      "Epoch [4307/20000], Loss: 117.55467224121094, Entropy -145.9737548828125, Learning Rate: 0.00015625\n",
      "Epoch [4308/20000], Loss: 122.03590393066406, Entropy -149.05950927734375, Learning Rate: 0.00015625\n",
      "Epoch [4309/20000], Loss: 132.91162109375, Entropy -162.50210571289062, Learning Rate: 0.00015625\n",
      "Epoch [4310/20000], Loss: 119.5712890625, Entropy -142.00128173828125, Learning Rate: 0.00015625\n",
      "Epoch [4311/20000], Loss: 119.52134704589844, Entropy -138.98338317871094, Learning Rate: 0.00015625\n",
      "Epoch [4312/20000], Loss: 113.30558776855469, Entropy -132.41876220703125, Learning Rate: 0.00015625\n",
      "Epoch [4313/20000], Loss: 128.9133758544922, Entropy -156.35757446289062, Learning Rate: 0.00015625\n",
      "Epoch [4314/20000], Loss: 121.99696350097656, Entropy -145.50428771972656, Learning Rate: 0.00015625\n",
      "Epoch [4315/20000], Loss: 134.06028747558594, Entropy -159.55908203125, Learning Rate: 0.00015625\n",
      "Epoch [4316/20000], Loss: 101.80171203613281, Entropy -116.35812377929688, Learning Rate: 0.00015625\n",
      "Epoch [4317/20000], Loss: 123.9097900390625, Entropy -148.8261260986328, Learning Rate: 0.00015625\n",
      "Epoch [4318/20000], Loss: 123.51943969726562, Entropy -150.12518310546875, Learning Rate: 0.00015625\n",
      "Epoch [4319/20000], Loss: 120.20661926269531, Entropy -142.929931640625, Learning Rate: 0.00015625\n",
      "Epoch [4320/20000], Loss: 125.28523254394531, Entropy -144.07373046875, Learning Rate: 0.00015625\n",
      "Epoch [4321/20000], Loss: 117.78938293457031, Entropy -138.99427795410156, Learning Rate: 0.00015625\n",
      "Epoch [4322/20000], Loss: 115.90042114257812, Entropy -127.67657470703125, Learning Rate: 0.00015625\n",
      "Epoch [4323/20000], Loss: 118.78083801269531, Entropy -138.8265380859375, Learning Rate: 0.00015625\n",
      "Epoch [4324/20000], Loss: 119.50325012207031, Entropy -142.91604614257812, Learning Rate: 0.00015625\n",
      "Epoch [4325/20000], Loss: 111.14817810058594, Entropy -128.17623901367188, Learning Rate: 0.00015625\n",
      "Epoch [4326/20000], Loss: 113.85986328125, Entropy -134.70449829101562, Learning Rate: 0.00015625\n",
      "Epoch [4327/20000], Loss: 114.66793823242188, Entropy -138.58621215820312, Learning Rate: 0.00015625\n",
      "Epoch [4328/20000], Loss: 117.73751831054688, Entropy -139.10458374023438, Learning Rate: 0.00015625\n",
      "Epoch [4329/20000], Loss: 116.24896240234375, Entropy -141.90042114257812, Learning Rate: 0.00015625\n",
      "Epoch [4330/20000], Loss: 117.03366088867188, Entropy -135.60601806640625, Learning Rate: 0.00015625\n",
      "Epoch [4331/20000], Loss: 121.166259765625, Entropy -142.03782653808594, Learning Rate: 0.00015625\n",
      "Epoch [4332/20000], Loss: 125.75958251953125, Entropy -146.821044921875, Learning Rate: 0.00015625\n",
      "Epoch [4333/20000], Loss: 107.4488525390625, Entropy -131.1553955078125, Learning Rate: 0.00015625\n",
      "Epoch [4334/20000], Loss: 114.35044860839844, Entropy -139.3294677734375, Learning Rate: 0.00015625\n",
      "Epoch [4335/20000], Loss: 113.77665710449219, Entropy -138.818115234375, Learning Rate: 0.00015625\n",
      "Epoch [4336/20000], Loss: 125.80461120605469, Entropy -149.01638793945312, Learning Rate: 0.00015625\n",
      "Epoch [4337/20000], Loss: 116.99966430664062, Entropy -134.17391967773438, Learning Rate: 0.00015625\n",
      "Epoch [4338/20000], Loss: 115.67015075683594, Entropy -138.04373168945312, Learning Rate: 0.00015625\n",
      "Epoch [4339/20000], Loss: 120.64289855957031, Entropy -151.13824462890625, Learning Rate: 0.00015625\n",
      "Epoch [4340/20000], Loss: 124.31036376953125, Entropy -159.10870361328125, Learning Rate: 0.00015625\n",
      "Epoch [4341/20000], Loss: 112.29829406738281, Entropy -133.82305908203125, Learning Rate: 0.00015625\n",
      "Epoch [4342/20000], Loss: 114.43238830566406, Entropy -136.74063110351562, Learning Rate: 0.00015625\n",
      "Epoch [4343/20000], Loss: 111.40617370605469, Entropy -131.08363342285156, Learning Rate: 0.00015625\n",
      "Epoch [4344/20000], Loss: 117.4739990234375, Entropy -136.70010375976562, Learning Rate: 0.00015625\n",
      "Epoch [4345/20000], Loss: 119.593017578125, Entropy -146.0727996826172, Learning Rate: 0.00015625\n",
      "Epoch [4346/20000], Loss: 116.26065063476562, Entropy -140.75917053222656, Learning Rate: 0.00015625\n",
      "Epoch [4347/20000], Loss: 115.9989013671875, Entropy -134.16632080078125, Learning Rate: 0.00015625\n",
      "Epoch [4348/20000], Loss: 114.94296264648438, Entropy -135.97750854492188, Learning Rate: 0.00015625\n",
      "Epoch [4349/20000], Loss: 114.187255859375, Entropy -142.89060974121094, Learning Rate: 0.00015625\n",
      "Epoch [4350/20000], Loss: 115.01490783691406, Entropy -136.23306274414062, Learning Rate: 0.00015625\n",
      "Epoch [4351/20000], Loss: 128.98455810546875, Entropy -154.49981689453125, Learning Rate: 0.00015625\n",
      "Epoch [4352/20000], Loss: 117.04306030273438, Entropy -135.54347229003906, Learning Rate: 0.00015625\n",
      "Epoch [4353/20000], Loss: 124.60795593261719, Entropy -151.9820098876953, Learning Rate: 0.00015625\n",
      "Epoch [4354/20000], Loss: 119.25453186035156, Entropy -139.0086212158203, Learning Rate: 0.00015625\n",
      "Epoch [4355/20000], Loss: 126.79287719726562, Entropy -157.75289916992188, Learning Rate: 0.00015625\n",
      "Epoch [4356/20000], Loss: 123.4774169921875, Entropy -146.83279418945312, Learning Rate: 0.00015625\n",
      "Epoch [4357/20000], Loss: 115.82591247558594, Entropy -140.08181762695312, Learning Rate: 0.00015625\n",
      "Epoch [4358/20000], Loss: 117.139404296875, Entropy -145.57257080078125, Learning Rate: 0.00015625\n",
      "Epoch [4359/20000], Loss: 117.86433410644531, Entropy -144.2581787109375, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4360/20000], Loss: 125.45262145996094, Entropy -145.10317993164062, Learning Rate: 0.00015625\n",
      "Epoch [4361/20000], Loss: 119.58293151855469, Entropy -140.98788452148438, Learning Rate: 0.00015625\n",
      "Epoch [4362/20000], Loss: 108.55128479003906, Entropy -125.96298217773438, Learning Rate: 0.00015625\n",
      "Epoch [4363/20000], Loss: 125.67366027832031, Entropy -149.88636779785156, Learning Rate: 0.00015625\n",
      "Epoch [4364/20000], Loss: 130.1080780029297, Entropy -155.66883850097656, Learning Rate: 0.00015625\n",
      "Epoch [4365/20000], Loss: 115.55204772949219, Entropy -134.56275939941406, Learning Rate: 0.00015625\n",
      "Epoch [4366/20000], Loss: 108.79325866699219, Entropy -121.74114990234375, Learning Rate: 0.00015625\n",
      "Epoch [4367/20000], Loss: 121.09976196289062, Entropy -145.09197998046875, Learning Rate: 0.00015625\n",
      "Epoch [4368/20000], Loss: 118.27754211425781, Entropy -135.25115966796875, Learning Rate: 0.00015625\n",
      "Epoch [4369/20000], Loss: 123.02627563476562, Entropy -145.03952026367188, Learning Rate: 0.00015625\n",
      "Epoch [4370/20000], Loss: 114.31047058105469, Entropy -137.58554077148438, Learning Rate: 0.00015625\n",
      "Epoch [4371/20000], Loss: 133.09075927734375, Entropy -160.07830810546875, Learning Rate: 0.00015625\n",
      "Epoch [4372/20000], Loss: 114.51243591308594, Entropy -136.92303466796875, Learning Rate: 0.00015625\n",
      "Epoch [4373/20000], Loss: 115.32664489746094, Entropy -148.43942260742188, Learning Rate: 0.00015625\n",
      "Epoch [4374/20000], Loss: 123.04440307617188, Entropy -150.08721923828125, Learning Rate: 0.00015625\n",
      "Epoch [4375/20000], Loss: 114.01097106933594, Entropy -138.9883575439453, Learning Rate: 0.00015625\n",
      "Epoch [4376/20000], Loss: 111.56698608398438, Entropy -130.24615478515625, Learning Rate: 0.00015625\n",
      "Epoch [4377/20000], Loss: 116.43263244628906, Entropy -138.86636352539062, Learning Rate: 0.00015625\n",
      "Epoch [4378/20000], Loss: 113.07655334472656, Entropy -134.3186798095703, Learning Rate: 0.00015625\n",
      "Epoch [4379/20000], Loss: 122.30207824707031, Entropy -153.66021728515625, Learning Rate: 0.00015625\n",
      "Epoch [4380/20000], Loss: 118.59475708007812, Entropy -144.32394409179688, Learning Rate: 0.00015625\n",
      "Epoch [4381/20000], Loss: 125.28756713867188, Entropy -153.22955322265625, Learning Rate: 0.00015625\n",
      "Epoch [4382/20000], Loss: 119.56851196289062, Entropy -140.287353515625, Learning Rate: 0.00015625\n",
      "Epoch [4383/20000], Loss: 119.4847412109375, Entropy -141.04263305664062, Learning Rate: 0.00015625\n",
      "Epoch [4384/20000], Loss: 107.88478088378906, Entropy -129.38677978515625, Learning Rate: 0.00015625\n",
      "Epoch [4385/20000], Loss: 117.76919555664062, Entropy -132.23602294921875, Learning Rate: 0.00015625\n",
      "Epoch [4386/20000], Loss: 112.44758605957031, Entropy -140.15191650390625, Learning Rate: 0.00015625\n",
      "Epoch [4387/20000], Loss: 120.51463317871094, Entropy -149.5115509033203, Learning Rate: 0.00015625\n",
      "Epoch [4388/20000], Loss: 111.59263610839844, Entropy -133.65304565429688, Learning Rate: 0.00015625\n",
      "Epoch [4389/20000], Loss: 114.48208618164062, Entropy -130.41757202148438, Learning Rate: 0.00015625\n",
      "Epoch [4390/20000], Loss: 125.91947937011719, Entropy -141.1986083984375, Learning Rate: 0.00015625\n",
      "Epoch [4391/20000], Loss: 138.51156616210938, Entropy -176.00527954101562, Learning Rate: 0.00015625\n",
      "Epoch [4392/20000], Loss: 124.43547058105469, Entropy -148.13967895507812, Learning Rate: 0.00015625\n",
      "Epoch [4393/20000], Loss: 128.7615966796875, Entropy -155.5780029296875, Learning Rate: 0.00015625\n",
      "Epoch [4394/20000], Loss: 127.44361877441406, Entropy -138.05401611328125, Learning Rate: 0.00015625\n",
      "Epoch [4395/20000], Loss: 123.33491516113281, Entropy -148.0095672607422, Learning Rate: 0.00015625\n",
      "Epoch [4396/20000], Loss: 114.00321960449219, Entropy -130.84320068359375, Learning Rate: 0.00015625\n",
      "Epoch [4397/20000], Loss: 139.72064208984375, Entropy -176.63311767578125, Learning Rate: 0.00015625\n",
      "Epoch [4398/20000], Loss: 114.08984375, Entropy -126.4171142578125, Learning Rate: 0.00015625\n",
      "Epoch [4399/20000], Loss: 117.8597412109375, Entropy -134.1953125, Learning Rate: 0.00015625\n",
      "Epoch [4400/20000], Loss: 114.54884338378906, Entropy -139.89382934570312, Learning Rate: 0.00015625\n",
      "Epoch [4401/20000], Loss: 119.36546325683594, Entropy -147.01234436035156, Learning Rate: 0.00015625\n",
      "Epoch [4402/20000], Loss: 133.8736114501953, Entropy -158.33319091796875, Learning Rate: 0.00015625\n",
      "Epoch [4403/20000], Loss: 128.36534118652344, Entropy -147.939453125, Learning Rate: 0.00015625\n",
      "Epoch [4404/20000], Loss: 127.03607177734375, Entropy -151.49319458007812, Learning Rate: 0.00015625\n",
      "Epoch [4405/20000], Loss: 115.4267578125, Entropy -135.34060668945312, Learning Rate: 0.00015625\n",
      "Epoch [4406/20000], Loss: 126.09275817871094, Entropy -145.82550048828125, Learning Rate: 0.00015625\n",
      "Epoch [4407/20000], Loss: 117.54350280761719, Entropy -133.91702270507812, Learning Rate: 0.00015625\n",
      "Epoch [4408/20000], Loss: 126.49269104003906, Entropy -156.956298828125, Learning Rate: 0.00015625\n",
      "Epoch [4409/20000], Loss: 120.64923095703125, Entropy -143.43679809570312, Learning Rate: 0.00015625\n",
      "Epoch [4410/20000], Loss: 113.27044677734375, Entropy -140.10601806640625, Learning Rate: 0.00015625\n",
      "Epoch [4411/20000], Loss: 131.37864685058594, Entropy -158.65501403808594, Learning Rate: 0.00015625\n",
      "Epoch [4412/20000], Loss: 120.45236206054688, Entropy -138.16751098632812, Learning Rate: 0.00015625\n",
      "Epoch [4413/20000], Loss: 121.17927551269531, Entropy -145.89991760253906, Learning Rate: 0.00015625\n",
      "Epoch [4414/20000], Loss: 112.18408203125, Entropy -122.53497314453125, Learning Rate: 0.00015625\n",
      "Epoch [4415/20000], Loss: 111.28802490234375, Entropy -133.7091064453125, Learning Rate: 0.00015625\n",
      "Epoch [4416/20000], Loss: 113.87442016601562, Entropy -132.45272827148438, Learning Rate: 0.00015625\n",
      "Epoch [4417/20000], Loss: 113.38063049316406, Entropy -136.46823120117188, Learning Rate: 0.00015625\n",
      "Epoch [4418/20000], Loss: 114.27320861816406, Entropy -134.92428588867188, Learning Rate: 0.00015625\n",
      "Epoch [4419/20000], Loss: 117.38630676269531, Entropy -147.11282348632812, Learning Rate: 0.00015625\n",
      "Epoch [4420/20000], Loss: 116.86148071289062, Entropy -140.20167541503906, Learning Rate: 0.00015625\n",
      "Epoch [4421/20000], Loss: 120.26411437988281, Entropy -146.95932006835938, Learning Rate: 0.00015625\n",
      "Epoch [4422/20000], Loss: 116.65139770507812, Entropy -139.74520874023438, Learning Rate: 0.00015625\n",
      "Epoch [4423/20000], Loss: 131.4415740966797, Entropy -147.90283203125, Learning Rate: 0.00015625\n",
      "Epoch [4424/20000], Loss: 130.615234375, Entropy -154.55152893066406, Learning Rate: 0.00015625\n",
      "Epoch [4425/20000], Loss: 116.90577697753906, Entropy -147.41006469726562, Learning Rate: 0.00015625\n",
      "Epoch [4426/20000], Loss: 120.83969116210938, Entropy -139.00399780273438, Learning Rate: 0.00015625\n",
      "Epoch [4427/20000], Loss: 118.04481506347656, Entropy -142.28131103515625, Learning Rate: 0.00015625\n",
      "Epoch [4428/20000], Loss: 114.748046875, Entropy -140.4808349609375, Learning Rate: 0.00015625\n",
      "Epoch [4429/20000], Loss: 121.40089416503906, Entropy -148.80252075195312, Learning Rate: 0.00015625\n",
      "Epoch [4430/20000], Loss: 111.59295654296875, Entropy -133.51693725585938, Learning Rate: 0.00015625\n",
      "Epoch [4431/20000], Loss: 114.73980712890625, Entropy -133.5463409423828, Learning Rate: 0.00015625\n",
      "Epoch [4432/20000], Loss: 121.06234741210938, Entropy -149.1253662109375, Learning Rate: 0.00015625\n",
      "Epoch [4433/20000], Loss: 125.07478332519531, Entropy -141.53924560546875, Learning Rate: 0.00015625\n",
      "Epoch [4434/20000], Loss: 117.9404296875, Entropy -146.56838989257812, Learning Rate: 0.00015625\n",
      "Epoch [4435/20000], Loss: 111.77684020996094, Entropy -137.6229248046875, Learning Rate: 0.00015625\n",
      "Epoch [4436/20000], Loss: 114.25042724609375, Entropy -133.38580322265625, Learning Rate: 0.00015625\n",
      "Epoch [4437/20000], Loss: 121.64712524414062, Entropy -147.141845703125, Learning Rate: 0.00015625\n",
      "Epoch [4438/20000], Loss: 111.65739440917969, Entropy -137.2144317626953, Learning Rate: 0.00015625\n",
      "Epoch [4439/20000], Loss: 118.50907897949219, Entropy -142.24124145507812, Learning Rate: 0.00015625\n",
      "Epoch [4440/20000], Loss: 129.69728088378906, Entropy -152.04714965820312, Learning Rate: 0.00015625\n",
      "Epoch [4441/20000], Loss: 126.55323791503906, Entropy -153.7643585205078, Learning Rate: 0.00015625\n",
      "Epoch [4442/20000], Loss: 118.75079345703125, Entropy -137.1529541015625, Learning Rate: 0.00015625\n",
      "Epoch [4443/20000], Loss: 115.83340454101562, Entropy -137.8990936279297, Learning Rate: 0.00015625\n",
      "Epoch [4444/20000], Loss: 119.11282348632812, Entropy -143.47381591796875, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4445/20000], Loss: 114.34738159179688, Entropy -136.6758270263672, Learning Rate: 0.00015625\n",
      "Epoch [4446/20000], Loss: 122.19749450683594, Entropy -141.41851806640625, Learning Rate: 0.00015625\n",
      "Epoch [4447/20000], Loss: 119.27908325195312, Entropy -138.8597412109375, Learning Rate: 0.00015625\n",
      "Epoch [4448/20000], Loss: 123.00088500976562, Entropy -152.7660675048828, Learning Rate: 0.00015625\n",
      "Epoch [4449/20000], Loss: 117.68692016601562, Entropy -147.8688201904297, Learning Rate: 0.00015625\n",
      "Epoch [4450/20000], Loss: 117.55778503417969, Entropy -139.46621704101562, Learning Rate: 0.00015625\n",
      "Epoch [4451/20000], Loss: 117.19741821289062, Entropy -131.08811950683594, Learning Rate: 0.00015625\n",
      "Epoch [4452/20000], Loss: 112.05120849609375, Entropy -133.28271484375, Learning Rate: 0.00015625\n",
      "Epoch [4453/20000], Loss: 119.85466003417969, Entropy -141.58348083496094, Learning Rate: 0.00015625\n",
      "Epoch [4454/20000], Loss: 115.59269714355469, Entropy -141.43019104003906, Learning Rate: 0.00015625\n",
      "Epoch [4455/20000], Loss: 130.4353790283203, Entropy -144.12869262695312, Learning Rate: 0.00015625\n",
      "Epoch [4456/20000], Loss: 109.42912292480469, Entropy -124.23478698730469, Learning Rate: 0.00015625\n",
      "Epoch [4457/20000], Loss: 115.98066711425781, Entropy -139.50827026367188, Learning Rate: 0.00015625\n",
      "Epoch [4458/20000], Loss: 151.4238739013672, Entropy -142.55029296875, Learning Rate: 0.00015625\n",
      "Epoch [4459/20000], Loss: 138.2449951171875, Entropy -172.16192626953125, Learning Rate: 0.00015625\n",
      "Epoch [4460/20000], Loss: 118.49171447753906, Entropy -142.79498291015625, Learning Rate: 0.00015625\n",
      "Epoch [4461/20000], Loss: 111.09556579589844, Entropy -139.0255126953125, Learning Rate: 0.00015625\n",
      "Epoch [4462/20000], Loss: 119.33470153808594, Entropy -139.7442626953125, Learning Rate: 0.00015625\n",
      "Epoch [4463/20000], Loss: 115.59400939941406, Entropy -134.26113891601562, Learning Rate: 0.00015625\n",
      "Epoch [4464/20000], Loss: 117.30848693847656, Entropy -137.28616333007812, Learning Rate: 0.00015625\n",
      "Epoch [4465/20000], Loss: 122.686767578125, Entropy -149.12881469726562, Learning Rate: 0.00015625\n",
      "Epoch [4466/20000], Loss: 125.19551086425781, Entropy -153.80459594726562, Learning Rate: 0.00015625\n",
      "Epoch [4467/20000], Loss: 117.84675598144531, Entropy -146.18264770507812, Learning Rate: 0.00015625\n",
      "Epoch [4468/20000], Loss: 119.36534118652344, Entropy -137.97601318359375, Learning Rate: 0.00015625\n",
      "Epoch [4469/20000], Loss: 114.83784484863281, Entropy -143.46775817871094, Learning Rate: 0.00015625\n",
      "Epoch [4470/20000], Loss: 122.94137573242188, Entropy -147.11764526367188, Learning Rate: 0.00015625\n",
      "Epoch [4471/20000], Loss: 116.4923095703125, Entropy -142.75843811035156, Learning Rate: 0.00015625\n",
      "Epoch [4472/20000], Loss: 124.27864074707031, Entropy -143.81422424316406, Learning Rate: 0.00015625\n",
      "Epoch [4473/20000], Loss: 113.42068481445312, Entropy -136.03878784179688, Learning Rate: 0.00015625\n",
      "Epoch [4474/20000], Loss: 125.63349914550781, Entropy -151.00924682617188, Learning Rate: 0.00015625\n",
      "Epoch [4475/20000], Loss: 139.0492706298828, Entropy -167.84912109375, Learning Rate: 0.00015625\n",
      "Epoch [4476/20000], Loss: 127.46919250488281, Entropy -158.03973388671875, Learning Rate: 0.00015625\n",
      "Epoch [4477/20000], Loss: 119.10824584960938, Entropy -154.36248779296875, Learning Rate: 0.00015625\n",
      "Epoch [4478/20000], Loss: 123.64895629882812, Entropy -146.04248046875, Learning Rate: 0.00015625\n",
      "Epoch [4479/20000], Loss: 121.66960144042969, Entropy -143.84547424316406, Learning Rate: 0.00015625\n",
      "Epoch [4480/20000], Loss: 113.45857238769531, Entropy -134.44369506835938, Learning Rate: 0.00015625\n",
      "Epoch [4481/20000], Loss: 115.37519836425781, Entropy -137.8272247314453, Learning Rate: 0.00015625\n",
      "Epoch [4482/20000], Loss: 126.79327392578125, Entropy -153.71726989746094, Learning Rate: 0.00015625\n",
      "Epoch [4483/20000], Loss: 115.65829467773438, Entropy -135.93243408203125, Learning Rate: 0.00015625\n",
      "Epoch [4484/20000], Loss: 111.36357116699219, Entropy -136.19158935546875, Learning Rate: 0.00015625\n",
      "Epoch [4485/20000], Loss: 123.86224365234375, Entropy -151.58506774902344, Learning Rate: 0.00015625\n",
      "Epoch [4486/20000], Loss: 114.912353515625, Entropy -132.70074462890625, Learning Rate: 0.00015625\n",
      "Epoch [4487/20000], Loss: 117.69270324707031, Entropy -123.3714599609375, Learning Rate: 0.00015625\n",
      "Epoch [4488/20000], Loss: 114.51715087890625, Entropy -138.18096923828125, Learning Rate: 0.00015625\n",
      "Epoch [4489/20000], Loss: 119.06585693359375, Entropy -144.20867919921875, Learning Rate: 0.00015625\n",
      "Epoch [4490/20000], Loss: 117.05854797363281, Entropy -141.9541015625, Learning Rate: 0.00015625\n",
      "Epoch [4491/20000], Loss: 112.47166442871094, Entropy -134.4456787109375, Learning Rate: 0.00015625\n",
      "Epoch [4492/20000], Loss: 126.912353515625, Entropy -147.28953552246094, Learning Rate: 0.00015625\n",
      "Epoch [4493/20000], Loss: 129.08203125, Entropy -149.48361206054688, Learning Rate: 0.00015625\n",
      "Epoch [4494/20000], Loss: 118.97175598144531, Entropy -142.2644500732422, Learning Rate: 0.00015625\n",
      "Epoch [4495/20000], Loss: 122.01870727539062, Entropy -148.74205017089844, Learning Rate: 0.00015625\n",
      "Epoch [4496/20000], Loss: 116.82681274414062, Entropy -140.04141235351562, Learning Rate: 0.00015625\n",
      "Epoch [4497/20000], Loss: 116.79866027832031, Entropy -139.4818572998047, Learning Rate: 0.00015625\n",
      "Epoch [4498/20000], Loss: 117.03764343261719, Entropy -141.8311767578125, Learning Rate: 0.00015625\n",
      "Epoch [4499/20000], Loss: 117.6982421875, Entropy -153.1968994140625, Learning Rate: 0.00015625\n",
      "Epoch [4500/20000], Loss: 116.26780700683594, Entropy -128.08863830566406, Learning Rate: 0.00015625\n",
      "Epoch [4501/20000], Loss: 115.99867248535156, Entropy -141.09278869628906, Learning Rate: 0.00015625\n",
      "Epoch [4502/20000], Loss: 122.57374572753906, Entropy -145.09063720703125, Learning Rate: 0.00015625\n",
      "Epoch [4503/20000], Loss: 119.88142395019531, Entropy -149.64260864257812, Learning Rate: 0.00015625\n",
      "Epoch [4504/20000], Loss: 124.61428833007812, Entropy -156.51034545898438, Learning Rate: 0.00015625\n",
      "Epoch [4505/20000], Loss: 121.98951721191406, Entropy -150.396240234375, Learning Rate: 0.00015625\n",
      "Epoch [4506/20000], Loss: 112.22174072265625, Entropy -136.96604919433594, Learning Rate: 0.00015625\n",
      "Epoch [4507/20000], Loss: 112.29164123535156, Entropy -130.33338928222656, Learning Rate: 0.00015625\n",
      "Epoch [4508/20000], Loss: 120.21401977539062, Entropy -147.86273193359375, Learning Rate: 0.00015625\n",
      "Epoch [4509/20000], Loss: 115.478515625, Entropy -138.18084716796875, Learning Rate: 0.00015625\n",
      "Epoch [4510/20000], Loss: 115.61457824707031, Entropy -147.25035095214844, Learning Rate: 0.00015625\n",
      "Epoch [4511/20000], Loss: 130.6088104248047, Entropy -154.07212829589844, Learning Rate: 0.00015625\n",
      "Epoch [4512/20000], Loss: 122.11512756347656, Entropy -144.78504943847656, Learning Rate: 0.00015625\n",
      "Epoch [4513/20000], Loss: 120.10514831542969, Entropy -145.53012084960938, Learning Rate: 0.00015625\n",
      "Epoch [4514/20000], Loss: 118.92791748046875, Entropy -137.15003967285156, Learning Rate: 0.00015625\n",
      "Epoch [4515/20000], Loss: 119.79800415039062, Entropy -141.32003784179688, Learning Rate: 0.00015625\n",
      "Epoch [4516/20000], Loss: 117.72836303710938, Entropy -140.64541625976562, Learning Rate: 0.00015625\n",
      "Epoch [4517/20000], Loss: 115.38055419921875, Entropy -146.090087890625, Learning Rate: 0.00015625\n",
      "Epoch [4518/20000], Loss: 122.09681701660156, Entropy -144.26898193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [4519/20000], Loss: 119.17710876464844, Entropy -131.32022094726562, Learning Rate: 7.8125e-05\n",
      "Epoch [4520/20000], Loss: 118.67367553710938, Entropy -139.0980224609375, Learning Rate: 7.8125e-05\n",
      "Epoch [4521/20000], Loss: 116.02655029296875, Entropy -146.05569458007812, Learning Rate: 7.8125e-05\n",
      "Epoch [4522/20000], Loss: 129.60935974121094, Entropy -156.73211669921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4523/20000], Loss: 115.55581665039062, Entropy -136.09683227539062, Learning Rate: 7.8125e-05\n",
      "Epoch [4524/20000], Loss: 114.81158447265625, Entropy -142.05633544921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4525/20000], Loss: 113.47099304199219, Entropy -137.77317810058594, Learning Rate: 7.8125e-05\n",
      "Epoch [4526/20000], Loss: 123.85006713867188, Entropy -139.0904541015625, Learning Rate: 7.8125e-05\n",
      "Epoch [4527/20000], Loss: 116.71661376953125, Entropy -133.01080322265625, Learning Rate: 7.8125e-05\n",
      "Epoch [4528/20000], Loss: 126.08370971679688, Entropy -156.81094360351562, Learning Rate: 7.8125e-05\n",
      "Epoch [4529/20000], Loss: 116.96968078613281, Entropy -141.33819580078125, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4530/20000], Loss: 117.4014892578125, Entropy -140.94589233398438, Learning Rate: 7.8125e-05\n",
      "Epoch [4531/20000], Loss: 110.318359375, Entropy -131.7786865234375, Learning Rate: 7.8125e-05\n",
      "Epoch [4532/20000], Loss: 117.16143798828125, Entropy -136.12962341308594, Learning Rate: 7.8125e-05\n",
      "Epoch [4533/20000], Loss: 116.084228515625, Entropy -138.21627807617188, Learning Rate: 7.8125e-05\n",
      "Epoch [4534/20000], Loss: 114.10549926757812, Entropy -139.6046142578125, Learning Rate: 7.8125e-05\n",
      "Epoch [4535/20000], Loss: 115.71516418457031, Entropy -139.94094848632812, Learning Rate: 7.8125e-05\n",
      "Epoch [4536/20000], Loss: 122.58511352539062, Entropy -140.5634002685547, Learning Rate: 7.8125e-05\n",
      "Epoch [4537/20000], Loss: 109.04541015625, Entropy -133.94900512695312, Learning Rate: 7.8125e-05\n",
      "Epoch [4538/20000], Loss: 112.59341430664062, Entropy -131.03842163085938, Learning Rate: 7.8125e-05\n",
      "Epoch [4539/20000], Loss: 113.5882568359375, Entropy -132.59689331054688, Learning Rate: 7.8125e-05\n",
      "Epoch [4540/20000], Loss: 124.08262634277344, Entropy -148.17910766601562, Learning Rate: 7.8125e-05\n",
      "Epoch [4541/20000], Loss: 118.77348327636719, Entropy -142.89010620117188, Learning Rate: 7.8125e-05\n",
      "Epoch [4542/20000], Loss: 124.35545349121094, Entropy -138.65982055664062, Learning Rate: 7.8125e-05\n",
      "Epoch [4543/20000], Loss: 123.96170043945312, Entropy -141.781494140625, Learning Rate: 7.8125e-05\n",
      "Epoch [4544/20000], Loss: 125.96246337890625, Entropy -145.9190673828125, Learning Rate: 7.8125e-05\n",
      "Epoch [4545/20000], Loss: 111.72665405273438, Entropy -133.69837951660156, Learning Rate: 7.8125e-05\n",
      "Epoch [4546/20000], Loss: 113.53474426269531, Entropy -137.0413055419922, Learning Rate: 7.8125e-05\n",
      "Epoch [4547/20000], Loss: 110.51618957519531, Entropy -133.74609375, Learning Rate: 7.8125e-05\n",
      "Epoch [4548/20000], Loss: 130.18006896972656, Entropy -149.61068725585938, Learning Rate: 7.8125e-05\n",
      "Epoch [4549/20000], Loss: 131.648681640625, Entropy -155.06982421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4550/20000], Loss: 123.13748168945312, Entropy -148.303955078125, Learning Rate: 7.8125e-05\n",
      "Epoch [4551/20000], Loss: 122.18222045898438, Entropy -136.3752899169922, Learning Rate: 7.8125e-05\n",
      "Epoch [4552/20000], Loss: 119.35357666015625, Entropy -139.62210083007812, Learning Rate: 7.8125e-05\n",
      "Epoch [4553/20000], Loss: 114.314697265625, Entropy -136.5159149169922, Learning Rate: 7.8125e-05\n",
      "Epoch [4554/20000], Loss: 123.40206909179688, Entropy -141.42184448242188, Learning Rate: 7.8125e-05\n",
      "Epoch [4555/20000], Loss: 116.8115234375, Entropy -137.10958862304688, Learning Rate: 7.8125e-05\n",
      "Epoch [4556/20000], Loss: 128.11668395996094, Entropy -151.32623291015625, Learning Rate: 7.8125e-05\n",
      "Epoch [4557/20000], Loss: 114.21836853027344, Entropy -140.2823028564453, Learning Rate: 7.8125e-05\n",
      "Epoch [4558/20000], Loss: 111.88829040527344, Entropy -132.20726013183594, Learning Rate: 7.8125e-05\n",
      "Epoch [4559/20000], Loss: 119.03651428222656, Entropy -139.68252563476562, Learning Rate: 7.8125e-05\n",
      "Epoch [4560/20000], Loss: 119.58924865722656, Entropy -145.7479248046875, Learning Rate: 7.8125e-05\n",
      "Epoch [4561/20000], Loss: 123.79216003417969, Entropy -137.80552673339844, Learning Rate: 7.8125e-05\n",
      "Epoch [4562/20000], Loss: 134.52513122558594, Entropy -163.7185821533203, Learning Rate: 7.8125e-05\n",
      "Epoch [4563/20000], Loss: 124.66241455078125, Entropy -152.32066345214844, Learning Rate: 7.8125e-05\n",
      "Epoch [4564/20000], Loss: 114.38548278808594, Entropy -135.69007873535156, Learning Rate: 7.8125e-05\n",
      "Epoch [4565/20000], Loss: 117.41053771972656, Entropy -141.0166015625, Learning Rate: 7.8125e-05\n",
      "Epoch [4566/20000], Loss: 115.45219421386719, Entropy -133.92098999023438, Learning Rate: 7.8125e-05\n",
      "Epoch [4567/20000], Loss: 115.89590454101562, Entropy -141.3968505859375, Learning Rate: 7.8125e-05\n",
      "Epoch [4568/20000], Loss: 111.45481872558594, Entropy -134.122802734375, Learning Rate: 7.8125e-05\n",
      "Epoch [4569/20000], Loss: 124.52769470214844, Entropy -148.52432250976562, Learning Rate: 7.8125e-05\n",
      "Epoch [4570/20000], Loss: 121.51301574707031, Entropy -136.290771484375, Learning Rate: 7.8125e-05\n",
      "Epoch [4571/20000], Loss: 126.40548706054688, Entropy -154.90444946289062, Learning Rate: 7.8125e-05\n",
      "Epoch [4572/20000], Loss: 119.39590454101562, Entropy -138.8006134033203, Learning Rate: 7.8125e-05\n",
      "Epoch [4573/20000], Loss: 120.02432250976562, Entropy -146.40036010742188, Learning Rate: 7.8125e-05\n",
      "Epoch [4574/20000], Loss: 118.84431457519531, Entropy -141.2803955078125, Learning Rate: 7.8125e-05\n",
      "Epoch [4575/20000], Loss: 120.21778869628906, Entropy -139.01675415039062, Learning Rate: 7.8125e-05\n",
      "Epoch [4576/20000], Loss: 124.19087219238281, Entropy -137.56361389160156, Learning Rate: 7.8125e-05\n",
      "Epoch [4577/20000], Loss: 106.47328186035156, Entropy -125.61026000976562, Learning Rate: 7.8125e-05\n",
      "Epoch [4578/20000], Loss: 120.72772216796875, Entropy -142.888916015625, Learning Rate: 7.8125e-05\n",
      "Epoch [4579/20000], Loss: 124.47897338867188, Entropy -136.8931121826172, Learning Rate: 7.8125e-05\n",
      "Epoch [4580/20000], Loss: 121.81448364257812, Entropy -144.27769470214844, Learning Rate: 7.8125e-05\n",
      "Epoch [4581/20000], Loss: 117.94430541992188, Entropy -140.57778930664062, Learning Rate: 7.8125e-05\n",
      "Epoch [4582/20000], Loss: 114.58145141601562, Entropy -138.43075561523438, Learning Rate: 7.8125e-05\n",
      "Epoch [4583/20000], Loss: 120.85017395019531, Entropy -141.01968383789062, Learning Rate: 7.8125e-05\n",
      "Epoch [4584/20000], Loss: 127.02311706542969, Entropy -149.74935913085938, Learning Rate: 7.8125e-05\n",
      "Epoch [4585/20000], Loss: 123.73014831542969, Entropy -151.73635864257812, Learning Rate: 7.8125e-05\n",
      "Epoch [4586/20000], Loss: 125.28338623046875, Entropy -147.82186889648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4587/20000], Loss: 112.3912353515625, Entropy -136.6016082763672, Learning Rate: 7.8125e-05\n",
      "Epoch [4588/20000], Loss: 118.03253173828125, Entropy -144.95498657226562, Learning Rate: 7.8125e-05\n",
      "Epoch [4589/20000], Loss: 115.5394287109375, Entropy -138.14645385742188, Learning Rate: 7.8125e-05\n",
      "Epoch [4590/20000], Loss: 114.45834350585938, Entropy -139.1884765625, Learning Rate: 7.8125e-05\n",
      "Epoch [4591/20000], Loss: 119.6353759765625, Entropy -133.8878173828125, Learning Rate: 7.8125e-05\n",
      "Epoch [4592/20000], Loss: 125.0115966796875, Entropy -145.57723999023438, Learning Rate: 7.8125e-05\n",
      "Epoch [4593/20000], Loss: 129.00819396972656, Entropy -154.07766723632812, Learning Rate: 7.8125e-05\n",
      "Epoch [4594/20000], Loss: 113.49934387207031, Entropy -131.26388549804688, Learning Rate: 7.8125e-05\n",
      "Epoch [4595/20000], Loss: 120.4495849609375, Entropy -144.39666748046875, Learning Rate: 7.8125e-05\n",
      "Epoch [4596/20000], Loss: 120.65101623535156, Entropy -152.47422790527344, Learning Rate: 7.8125e-05\n",
      "Epoch [4597/20000], Loss: 120.31251525878906, Entropy -139.66661071777344, Learning Rate: 7.8125e-05\n",
      "Epoch [4598/20000], Loss: 116.02284240722656, Entropy -131.4382781982422, Learning Rate: 7.8125e-05\n",
      "Epoch [4599/20000], Loss: 121.58639526367188, Entropy -153.35452270507812, Learning Rate: 7.8125e-05\n",
      "Epoch [4600/20000], Loss: 121.13438415527344, Entropy -144.45230102539062, Learning Rate: 7.8125e-05\n",
      "Epoch [4601/20000], Loss: 114.1859130859375, Entropy -139.4215545654297, Learning Rate: 7.8125e-05\n",
      "Epoch [4602/20000], Loss: 109.22837829589844, Entropy -130.06924438476562, Learning Rate: 7.8125e-05\n",
      "Epoch [4603/20000], Loss: 119.07992553710938, Entropy -147.14527893066406, Learning Rate: 7.8125e-05\n",
      "Epoch [4604/20000], Loss: 117.16502380371094, Entropy -143.5869903564453, Learning Rate: 7.8125e-05\n",
      "Epoch [4605/20000], Loss: 107.86427307128906, Entropy -126.45188903808594, Learning Rate: 7.8125e-05\n",
      "Epoch [4606/20000], Loss: 125.76190185546875, Entropy -154.16860961914062, Learning Rate: 7.8125e-05\n",
      "Epoch [4607/20000], Loss: 112.20413208007812, Entropy -123.64219665527344, Learning Rate: 7.8125e-05\n",
      "Epoch [4608/20000], Loss: 111.3905029296875, Entropy -137.36456298828125, Learning Rate: 7.8125e-05\n",
      "Epoch [4609/20000], Loss: 116.16230773925781, Entropy -148.3387451171875, Learning Rate: 7.8125e-05\n",
      "Epoch [4610/20000], Loss: 117.87797546386719, Entropy -135.18243408203125, Learning Rate: 7.8125e-05\n",
      "Epoch [4611/20000], Loss: 113.29757690429688, Entropy -133.49496459960938, Learning Rate: 7.8125e-05\n",
      "Epoch [4612/20000], Loss: 117.68008422851562, Entropy -144.76620483398438, Learning Rate: 7.8125e-05\n",
      "Epoch [4613/20000], Loss: 126.56752014160156, Entropy -158.15130615234375, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4614/20000], Loss: 120.93984985351562, Entropy -147.21310424804688, Learning Rate: 7.8125e-05\n",
      "Epoch [4615/20000], Loss: 123.91189575195312, Entropy -149.29344177246094, Learning Rate: 7.8125e-05\n",
      "Epoch [4616/20000], Loss: 112.08189392089844, Entropy -126.95257568359375, Learning Rate: 7.8125e-05\n",
      "Epoch [4617/20000], Loss: 121.46963500976562, Entropy -144.05661010742188, Learning Rate: 7.8125e-05\n",
      "Epoch [4618/20000], Loss: 112.0721435546875, Entropy -127.32559204101562, Learning Rate: 7.8125e-05\n",
      "Epoch [4619/20000], Loss: 122.20332336425781, Entropy -144.442138671875, Learning Rate: 7.8125e-05\n",
      "Epoch [4620/20000], Loss: 127.60267639160156, Entropy -146.65798950195312, Learning Rate: 7.8125e-05\n",
      "Epoch [4621/20000], Loss: 129.2761688232422, Entropy -158.94924926757812, Learning Rate: 7.8125e-05\n",
      "Epoch [4622/20000], Loss: 115.96307373046875, Entropy -137.11065673828125, Learning Rate: 7.8125e-05\n",
      "Epoch [4623/20000], Loss: 132.2779083251953, Entropy -140.65513610839844, Learning Rate: 7.8125e-05\n",
      "Epoch [4624/20000], Loss: 118.71665954589844, Entropy -139.6947784423828, Learning Rate: 7.8125e-05\n",
      "Epoch [4625/20000], Loss: 112.9149169921875, Entropy -127.34921264648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4626/20000], Loss: 123.77925109863281, Entropy -148.9349365234375, Learning Rate: 7.8125e-05\n",
      "Epoch [4627/20000], Loss: 129.8174591064453, Entropy -159.67135620117188, Learning Rate: 7.8125e-05\n",
      "Epoch [4628/20000], Loss: 128.90875244140625, Entropy -156.53106689453125, Learning Rate: 7.8125e-05\n",
      "Epoch [4629/20000], Loss: 112.5203857421875, Entropy -129.61904907226562, Learning Rate: 7.8125e-05\n",
      "Epoch [4630/20000], Loss: 117.15989685058594, Entropy -136.07164001464844, Learning Rate: 7.8125e-05\n",
      "Epoch [4631/20000], Loss: 118.98065185546875, Entropy -135.87911987304688, Learning Rate: 7.8125e-05\n",
      "Epoch [4632/20000], Loss: 117.37745666503906, Entropy -142.36505126953125, Learning Rate: 7.8125e-05\n",
      "Epoch [4633/20000], Loss: 118.7694091796875, Entropy -137.25003051757812, Learning Rate: 7.8125e-05\n",
      "Epoch [4634/20000], Loss: 113.63002014160156, Entropy -139.3257598876953, Learning Rate: 7.8125e-05\n",
      "Epoch [4635/20000], Loss: 118.91311645507812, Entropy -139.81101989746094, Learning Rate: 7.8125e-05\n",
      "Epoch [4636/20000], Loss: 116.47807312011719, Entropy -144.47018432617188, Learning Rate: 7.8125e-05\n",
      "Epoch [4637/20000], Loss: 111.43693542480469, Entropy -128.8158416748047, Learning Rate: 7.8125e-05\n",
      "Epoch [4638/20000], Loss: 123.44342041015625, Entropy -149.87481689453125, Learning Rate: 7.8125e-05\n",
      "Epoch [4639/20000], Loss: 119.31745910644531, Entropy -151.0159454345703, Learning Rate: 7.8125e-05\n",
      "Epoch [4640/20000], Loss: 115.0611572265625, Entropy -134.04656982421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4641/20000], Loss: 121.00166320800781, Entropy -142.19747924804688, Learning Rate: 7.8125e-05\n",
      "Epoch [4642/20000], Loss: 114.00247192382812, Entropy -136.69793701171875, Learning Rate: 7.8125e-05\n",
      "Epoch [4643/20000], Loss: 108.57086181640625, Entropy -131.2019805908203, Learning Rate: 7.8125e-05\n",
      "Epoch [4644/20000], Loss: 121.31988525390625, Entropy -145.35806274414062, Learning Rate: 7.8125e-05\n",
      "Epoch [4645/20000], Loss: 113.19248962402344, Entropy -135.44944763183594, Learning Rate: 7.8125e-05\n",
      "Epoch [4646/20000], Loss: 118.24552917480469, Entropy -132.77279663085938, Learning Rate: 7.8125e-05\n",
      "Epoch [4647/20000], Loss: 119.29811096191406, Entropy -140.78402709960938, Learning Rate: 7.8125e-05\n",
      "Epoch [4648/20000], Loss: 122.66828918457031, Entropy -152.87864685058594, Learning Rate: 7.8125e-05\n",
      "Epoch [4649/20000], Loss: 118.45173645019531, Entropy -144.47328186035156, Learning Rate: 7.8125e-05\n",
      "Epoch [4650/20000], Loss: 124.89297485351562, Entropy -146.8189697265625, Learning Rate: 7.8125e-05\n",
      "Epoch [4651/20000], Loss: 119.28459167480469, Entropy -145.91427612304688, Learning Rate: 7.8125e-05\n",
      "Epoch [4652/20000], Loss: 126.0338134765625, Entropy -158.51327514648438, Learning Rate: 7.8125e-05\n",
      "Epoch [4653/20000], Loss: 124.97352600097656, Entropy -148.97943115234375, Learning Rate: 7.8125e-05\n",
      "Epoch [4654/20000], Loss: 120.61477661132812, Entropy -148.2027587890625, Learning Rate: 7.8125e-05\n",
      "Epoch [4655/20000], Loss: 136.19606018066406, Entropy -158.67428588867188, Learning Rate: 7.8125e-05\n",
      "Epoch [4656/20000], Loss: 120.30970764160156, Entropy -142.8115234375, Learning Rate: 7.8125e-05\n",
      "Epoch [4657/20000], Loss: 121.07896423339844, Entropy -139.37258911132812, Learning Rate: 7.8125e-05\n",
      "Epoch [4658/20000], Loss: 109.11466979980469, Entropy -128.92593383789062, Learning Rate: 7.8125e-05\n",
      "Epoch [4659/20000], Loss: 122.93359375, Entropy -145.61807250976562, Learning Rate: 7.8125e-05\n",
      "Epoch [4660/20000], Loss: 128.54098510742188, Entropy -157.44752502441406, Learning Rate: 7.8125e-05\n",
      "Epoch [4661/20000], Loss: 135.33438110351562, Entropy -167.54222106933594, Learning Rate: 7.8125e-05\n",
      "Epoch [4662/20000], Loss: 109.4410400390625, Entropy -134.83172607421875, Learning Rate: 7.8125e-05\n",
      "Epoch [4663/20000], Loss: 116.46621704101562, Entropy -142.29739379882812, Learning Rate: 7.8125e-05\n",
      "Epoch [4664/20000], Loss: 118.03123474121094, Entropy -138.498046875, Learning Rate: 7.8125e-05\n",
      "Epoch [4665/20000], Loss: 116.0867919921875, Entropy -142.91180419921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4666/20000], Loss: 114.80502319335938, Entropy -134.78732299804688, Learning Rate: 7.8125e-05\n",
      "Epoch [4667/20000], Loss: 134.55291748046875, Entropy -161.5399169921875, Learning Rate: 7.8125e-05\n",
      "Epoch [4668/20000], Loss: 118.16192626953125, Entropy -142.228271484375, Learning Rate: 7.8125e-05\n",
      "Epoch [4669/20000], Loss: 117.90975952148438, Entropy -136.1396484375, Learning Rate: 7.8125e-05\n",
      "Epoch [4670/20000], Loss: 127.38861083984375, Entropy -151.42401123046875, Learning Rate: 7.8125e-05\n",
      "Epoch [4671/20000], Loss: 116.316650390625, Entropy -140.8123321533203, Learning Rate: 7.8125e-05\n",
      "Epoch [4672/20000], Loss: 116.00796508789062, Entropy -138.3745574951172, Learning Rate: 7.8125e-05\n",
      "Epoch [4673/20000], Loss: 114.01588439941406, Entropy -138.81814575195312, Learning Rate: 7.8125e-05\n",
      "Epoch [4674/20000], Loss: 118.30633544921875, Entropy -140.23336791992188, Learning Rate: 7.8125e-05\n",
      "Epoch [4675/20000], Loss: 124.94505310058594, Entropy -155.2132110595703, Learning Rate: 7.8125e-05\n",
      "Epoch [4676/20000], Loss: 112.347412109375, Entropy -136.74679565429688, Learning Rate: 7.8125e-05\n",
      "Epoch [4677/20000], Loss: 120.97573852539062, Entropy -143.42153930664062, Learning Rate: 7.8125e-05\n",
      "Epoch [4678/20000], Loss: 133.12757873535156, Entropy -162.1769561767578, Learning Rate: 7.8125e-05\n",
      "Epoch [4679/20000], Loss: 121.73336791992188, Entropy -151.7945556640625, Learning Rate: 7.8125e-05\n",
      "Epoch [4680/20000], Loss: 125.33140563964844, Entropy -153.11183166503906, Learning Rate: 7.8125e-05\n",
      "Epoch [4681/20000], Loss: 115.16567993164062, Entropy -138.87527465820312, Learning Rate: 7.8125e-05\n",
      "Epoch [4682/20000], Loss: 114.81483459472656, Entropy -141.1671600341797, Learning Rate: 7.8125e-05\n",
      "Epoch [4683/20000], Loss: 116.36795043945312, Entropy -136.13418579101562, Learning Rate: 7.8125e-05\n",
      "Epoch [4684/20000], Loss: 116.29544067382812, Entropy -133.98072814941406, Learning Rate: 7.8125e-05\n",
      "Epoch [4685/20000], Loss: 124.85960388183594, Entropy -152.04859924316406, Learning Rate: 7.8125e-05\n",
      "Epoch [4686/20000], Loss: 130.73692321777344, Entropy -158.19894409179688, Learning Rate: 7.8125e-05\n",
      "Epoch [4687/20000], Loss: 130.32748413085938, Entropy -156.05398559570312, Learning Rate: 7.8125e-05\n",
      "Epoch [4688/20000], Loss: 117.73295593261719, Entropy -135.86355590820312, Learning Rate: 7.8125e-05\n",
      "Epoch [4689/20000], Loss: 118.68495178222656, Entropy -141.6485595703125, Learning Rate: 7.8125e-05\n",
      "Epoch [4690/20000], Loss: 121.9569091796875, Entropy -152.1997833251953, Learning Rate: 7.8125e-05\n",
      "Epoch [4691/20000], Loss: 115.7823486328125, Entropy -136.5836639404297, Learning Rate: 7.8125e-05\n",
      "Epoch [4692/20000], Loss: 120.13795471191406, Entropy -148.65936279296875, Learning Rate: 7.8125e-05\n",
      "Epoch [4693/20000], Loss: 116.84774780273438, Entropy -139.58033752441406, Learning Rate: 7.8125e-05\n",
      "Epoch [4694/20000], Loss: 117.57028198242188, Entropy -147.01376342773438, Learning Rate: 7.8125e-05\n",
      "Epoch [4695/20000], Loss: 118.24241638183594, Entropy -134.7908935546875, Learning Rate: 7.8125e-05\n",
      "Epoch [4696/20000], Loss: 111.81752014160156, Entropy -129.78509521484375, Learning Rate: 7.8125e-05\n",
      "Epoch [4697/20000], Loss: 109.84068298339844, Entropy -124.91249084472656, Learning Rate: 7.8125e-05\n",
      "Epoch [4698/20000], Loss: 119.13323974609375, Entropy -148.51473999023438, Learning Rate: 7.8125e-05\n",
      "Epoch [4699/20000], Loss: 118.59100341796875, Entropy -146.59951782226562, Learning Rate: 7.8125e-05\n",
      "Epoch [4700/20000], Loss: 111.00794982910156, Entropy -133.94192504882812, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4701/20000], Loss: 124.569091796875, Entropy -142.5976104736328, Learning Rate: 7.8125e-05\n",
      "Epoch [4702/20000], Loss: 112.57545471191406, Entropy -129.8480682373047, Learning Rate: 7.8125e-05\n",
      "Epoch [4703/20000], Loss: 109.3043212890625, Entropy -128.94564819335938, Learning Rate: 7.8125e-05\n",
      "Epoch [4704/20000], Loss: 127.47508239746094, Entropy -150.92103576660156, Learning Rate: 7.8125e-05\n",
      "Epoch [4705/20000], Loss: 117.14981079101562, Entropy -143.2401885986328, Learning Rate: 7.8125e-05\n",
      "Epoch [4706/20000], Loss: 117.96488952636719, Entropy -145.02789306640625, Learning Rate: 7.8125e-05\n",
      "Epoch [4707/20000], Loss: 112.66555786132812, Entropy -132.0570526123047, Learning Rate: 7.8125e-05\n",
      "Epoch [4708/20000], Loss: 126.52064514160156, Entropy -153.91493225097656, Learning Rate: 7.8125e-05\n",
      "Epoch [4709/20000], Loss: 129.88026428222656, Entropy -157.75363159179688, Learning Rate: 7.8125e-05\n",
      "Epoch [4710/20000], Loss: 115.1690673828125, Entropy -140.4059295654297, Learning Rate: 7.8125e-05\n",
      "Epoch [4711/20000], Loss: 124.94673156738281, Entropy -144.52410888671875, Learning Rate: 7.8125e-05\n",
      "Epoch [4712/20000], Loss: 124.62739562988281, Entropy -149.93899536132812, Learning Rate: 7.8125e-05\n",
      "Epoch [4713/20000], Loss: 114.71730041503906, Entropy -134.82199096679688, Learning Rate: 7.8125e-05\n",
      "Epoch [4714/20000], Loss: 119.61112976074219, Entropy -144.2078094482422, Learning Rate: 7.8125e-05\n",
      "Epoch [4715/20000], Loss: 117.97111511230469, Entropy -139.98196411132812, Learning Rate: 7.8125e-05\n",
      "Epoch [4716/20000], Loss: 113.45756530761719, Entropy -138.98304748535156, Learning Rate: 7.8125e-05\n",
      "Epoch [4717/20000], Loss: 119.73416137695312, Entropy -142.5138702392578, Learning Rate: 7.8125e-05\n",
      "Epoch [4718/20000], Loss: 128.60272216796875, Entropy -146.9324493408203, Learning Rate: 7.8125e-05\n",
      "Epoch [4719/20000], Loss: 121.75527954101562, Entropy -139.98867797851562, Learning Rate: 3.90625e-05\n",
      "Epoch [4720/20000], Loss: 123.02369689941406, Entropy -146.66680908203125, Learning Rate: 3.90625e-05\n",
      "Epoch [4721/20000], Loss: 124.13311767578125, Entropy -147.06663513183594, Learning Rate: 3.90625e-05\n",
      "Epoch [4722/20000], Loss: 111.00003051757812, Entropy -135.43287658691406, Learning Rate: 3.90625e-05\n",
      "Epoch [4723/20000], Loss: 110.85552978515625, Entropy -133.09262084960938, Learning Rate: 3.90625e-05\n",
      "Epoch [4724/20000], Loss: 122.00161743164062, Entropy -144.35858154296875, Learning Rate: 3.90625e-05\n",
      "Epoch [4725/20000], Loss: 127.11888122558594, Entropy -143.98486328125, Learning Rate: 3.90625e-05\n",
      "Epoch [4726/20000], Loss: 118.00654602050781, Entropy -145.59619140625, Learning Rate: 3.90625e-05\n",
      "Epoch [4727/20000], Loss: 133.94374084472656, Entropy -156.55569458007812, Learning Rate: 3.90625e-05\n",
      "Epoch [4728/20000], Loss: 114.56282043457031, Entropy -126.01400756835938, Learning Rate: 3.90625e-05\n",
      "Epoch [4729/20000], Loss: 126.92332458496094, Entropy -144.97833251953125, Learning Rate: 3.90625e-05\n",
      "Epoch [4730/20000], Loss: 116.46868896484375, Entropy -142.38409423828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4731/20000], Loss: 122.39825439453125, Entropy -152.35733032226562, Learning Rate: 3.90625e-05\n",
      "Epoch [4732/20000], Loss: 120.28839111328125, Entropy -143.39852905273438, Learning Rate: 3.90625e-05\n",
      "Epoch [4733/20000], Loss: 116.07608032226562, Entropy -140.5199737548828, Learning Rate: 3.90625e-05\n",
      "Epoch [4734/20000], Loss: 112.85870361328125, Entropy -139.0350341796875, Learning Rate: 3.90625e-05\n",
      "Epoch [4735/20000], Loss: 113.417236328125, Entropy -134.1801300048828, Learning Rate: 3.90625e-05\n",
      "Epoch [4736/20000], Loss: 111.61976623535156, Entropy -134.85015869140625, Learning Rate: 3.90625e-05\n",
      "Epoch [4737/20000], Loss: 119.34841918945312, Entropy -140.49337768554688, Learning Rate: 3.90625e-05\n",
      "Epoch [4738/20000], Loss: 111.33247375488281, Entropy -135.47894287109375, Learning Rate: 3.90625e-05\n",
      "Epoch [4739/20000], Loss: 119.41171264648438, Entropy -142.53109741210938, Learning Rate: 3.90625e-05\n",
      "Epoch [4740/20000], Loss: 112.71458435058594, Entropy -134.10865783691406, Learning Rate: 3.90625e-05\n",
      "Epoch [4741/20000], Loss: 125.90505981445312, Entropy -148.03277587890625, Learning Rate: 3.90625e-05\n",
      "Epoch [4742/20000], Loss: 118.6383056640625, Entropy -139.995849609375, Learning Rate: 3.90625e-05\n",
      "Epoch [4743/20000], Loss: 107.96855163574219, Entropy -128.5101318359375, Learning Rate: 3.90625e-05\n",
      "Epoch [4744/20000], Loss: 115.64805603027344, Entropy -139.03421020507812, Learning Rate: 3.90625e-05\n",
      "Epoch [4745/20000], Loss: 109.03250122070312, Entropy -133.52435302734375, Learning Rate: 3.90625e-05\n",
      "Epoch [4746/20000], Loss: 119.17247009277344, Entropy -142.86553955078125, Learning Rate: 3.90625e-05\n",
      "Epoch [4747/20000], Loss: 113.13026428222656, Entropy -132.06161499023438, Learning Rate: 3.90625e-05\n",
      "Epoch [4748/20000], Loss: 119.9482421875, Entropy -144.2940673828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4749/20000], Loss: 133.99539184570312, Entropy -153.21591186523438, Learning Rate: 3.90625e-05\n",
      "Epoch [4750/20000], Loss: 119.90411376953125, Entropy -147.02871704101562, Learning Rate: 3.90625e-05\n",
      "Epoch [4751/20000], Loss: 121.9122314453125, Entropy -145.257080078125, Learning Rate: 3.90625e-05\n",
      "Epoch [4752/20000], Loss: 107.3834228515625, Entropy -130.50405883789062, Learning Rate: 3.90625e-05\n",
      "Epoch [4753/20000], Loss: 115.57867431640625, Entropy -138.71873474121094, Learning Rate: 3.90625e-05\n",
      "Epoch [4754/20000], Loss: 132.05877685546875, Entropy -159.63998413085938, Learning Rate: 3.90625e-05\n",
      "Epoch [4755/20000], Loss: 111.1209716796875, Entropy -127.51651000976562, Learning Rate: 3.90625e-05\n",
      "Epoch [4756/20000], Loss: 128.22557067871094, Entropy -158.13894653320312, Learning Rate: 3.90625e-05\n",
      "Epoch [4757/20000], Loss: 116.09986877441406, Entropy -131.43637084960938, Learning Rate: 3.90625e-05\n",
      "Epoch [4758/20000], Loss: 137.4284210205078, Entropy -156.58407592773438, Learning Rate: 3.90625e-05\n",
      "Epoch [4759/20000], Loss: 111.53451538085938, Entropy -129.1192169189453, Learning Rate: 3.90625e-05\n",
      "Epoch [4760/20000], Loss: 117.98774719238281, Entropy -138.24969482421875, Learning Rate: 3.90625e-05\n",
      "Epoch [4761/20000], Loss: 115.41427612304688, Entropy -133.7377471923828, Learning Rate: 3.90625e-05\n",
      "Epoch [4762/20000], Loss: 128.22760009765625, Entropy -148.1897430419922, Learning Rate: 3.90625e-05\n",
      "Epoch [4763/20000], Loss: 117.62600708007812, Entropy -147.69692993164062, Learning Rate: 3.90625e-05\n",
      "Epoch [4764/20000], Loss: 115.99142456054688, Entropy -140.31884765625, Learning Rate: 3.90625e-05\n",
      "Epoch [4765/20000], Loss: 112.56887817382812, Entropy -131.41502380371094, Learning Rate: 3.90625e-05\n",
      "Epoch [4766/20000], Loss: 126.69935607910156, Entropy -144.62718200683594, Learning Rate: 3.90625e-05\n",
      "Epoch [4767/20000], Loss: 129.84104919433594, Entropy -165.73577880859375, Learning Rate: 3.90625e-05\n",
      "Epoch [4768/20000], Loss: 123.09013366699219, Entropy -149.400634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [4769/20000], Loss: 117.56712341308594, Entropy -143.18321228027344, Learning Rate: 3.90625e-05\n",
      "Epoch [4770/20000], Loss: 126.773681640625, Entropy -161.590576171875, Learning Rate: 3.90625e-05\n",
      "Epoch [4771/20000], Loss: 112.11570739746094, Entropy -132.5911865234375, Learning Rate: 3.90625e-05\n",
      "Epoch [4772/20000], Loss: 114.74005126953125, Entropy -136.70321655273438, Learning Rate: 3.90625e-05\n",
      "Epoch [4773/20000], Loss: 126.13066101074219, Entropy -155.3939208984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4774/20000], Loss: 112.12942504882812, Entropy -133.77511596679688, Learning Rate: 3.90625e-05\n",
      "Epoch [4775/20000], Loss: 122.31666564941406, Entropy -151.97535705566406, Learning Rate: 3.90625e-05\n",
      "Epoch [4776/20000], Loss: 129.1602020263672, Entropy -149.20132446289062, Learning Rate: 3.90625e-05\n",
      "Epoch [4777/20000], Loss: 115.2010498046875, Entropy -138.52821350097656, Learning Rate: 3.90625e-05\n",
      "Epoch [4778/20000], Loss: 122.12193298339844, Entropy -149.9285888671875, Learning Rate: 3.90625e-05\n",
      "Epoch [4779/20000], Loss: 110.51173400878906, Entropy -128.33616638183594, Learning Rate: 3.90625e-05\n",
      "Epoch [4780/20000], Loss: 123.540771484375, Entropy -145.4034423828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4781/20000], Loss: 112.06785583496094, Entropy -132.21006774902344, Learning Rate: 3.90625e-05\n",
      "Epoch [4782/20000], Loss: 115.19839477539062, Entropy -136.9593505859375, Learning Rate: 3.90625e-05\n",
      "Epoch [4783/20000], Loss: 121.56640625, Entropy -149.65652465820312, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4784/20000], Loss: 117.58282470703125, Entropy -142.11952209472656, Learning Rate: 3.90625e-05\n",
      "Epoch [4785/20000], Loss: 117.28694152832031, Entropy -145.97293090820312, Learning Rate: 3.90625e-05\n",
      "Epoch [4786/20000], Loss: 120.61686706542969, Entropy -143.2906494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [4787/20000], Loss: 109.27629089355469, Entropy -125.90670776367188, Learning Rate: 3.90625e-05\n",
      "Epoch [4788/20000], Loss: 127.08810424804688, Entropy -150.46670532226562, Learning Rate: 3.90625e-05\n",
      "Epoch [4789/20000], Loss: 123.21908569335938, Entropy -140.70516967773438, Learning Rate: 3.90625e-05\n",
      "Epoch [4790/20000], Loss: 115.89234924316406, Entropy -136.21343994140625, Learning Rate: 3.90625e-05\n",
      "Epoch [4791/20000], Loss: 122.37881469726562, Entropy -148.129638671875, Learning Rate: 3.90625e-05\n",
      "Epoch [4792/20000], Loss: 126.93461608886719, Entropy -162.01705932617188, Learning Rate: 3.90625e-05\n",
      "Epoch [4793/20000], Loss: 126.99537658691406, Entropy -146.45425415039062, Learning Rate: 3.90625e-05\n",
      "Epoch [4794/20000], Loss: 114.69343566894531, Entropy -134.56298828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4795/20000], Loss: 121.07743835449219, Entropy -147.95327758789062, Learning Rate: 3.90625e-05\n",
      "Epoch [4796/20000], Loss: 112.94070434570312, Entropy -142.2548828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4797/20000], Loss: 128.65988159179688, Entropy -149.21331787109375, Learning Rate: 3.90625e-05\n",
      "Epoch [4798/20000], Loss: 118.55216979980469, Entropy -151.4293212890625, Learning Rate: 3.90625e-05\n",
      "Epoch [4799/20000], Loss: 109.73065185546875, Entropy -129.28378295898438, Learning Rate: 3.90625e-05\n",
      "Epoch [4800/20000], Loss: 113.30203247070312, Entropy -139.97630310058594, Learning Rate: 3.90625e-05\n",
      "Epoch [4801/20000], Loss: 127.31964111328125, Entropy -158.20404052734375, Learning Rate: 3.90625e-05\n",
      "Epoch [4802/20000], Loss: 115.80342102050781, Entropy -140.27679443359375, Learning Rate: 3.90625e-05\n",
      "Epoch [4803/20000], Loss: 128.5589141845703, Entropy -139.0336151123047, Learning Rate: 3.90625e-05\n",
      "Epoch [4804/20000], Loss: 118.90423583984375, Entropy -146.01791381835938, Learning Rate: 3.90625e-05\n",
      "Epoch [4805/20000], Loss: 119.09690856933594, Entropy -138.3287811279297, Learning Rate: 3.90625e-05\n",
      "Epoch [4806/20000], Loss: 115.94187927246094, Entropy -145.33042907714844, Learning Rate: 3.90625e-05\n",
      "Epoch [4807/20000], Loss: 120.15065002441406, Entropy -148.4849395751953, Learning Rate: 3.90625e-05\n",
      "Epoch [4808/20000], Loss: 126.57603454589844, Entropy -150.52261352539062, Learning Rate: 3.90625e-05\n",
      "Epoch [4809/20000], Loss: 109.1231689453125, Entropy -128.48902893066406, Learning Rate: 3.90625e-05\n",
      "Epoch [4810/20000], Loss: 128.21939086914062, Entropy -154.36672973632812, Learning Rate: 3.90625e-05\n",
      "Epoch [4811/20000], Loss: 112.6019287109375, Entropy -136.93667602539062, Learning Rate: 3.90625e-05\n",
      "Epoch [4812/20000], Loss: 110.60000610351562, Entropy -136.63040161132812, Learning Rate: 3.90625e-05\n",
      "Epoch [4813/20000], Loss: 115.84770202636719, Entropy -133.665771484375, Learning Rate: 3.90625e-05\n",
      "Epoch [4814/20000], Loss: 109.59664916992188, Entropy -132.46157836914062, Learning Rate: 3.90625e-05\n",
      "Epoch [4815/20000], Loss: 120.38357543945312, Entropy -154.2611083984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4816/20000], Loss: 121.13273620605469, Entropy -148.87576293945312, Learning Rate: 3.90625e-05\n",
      "Epoch [4817/20000], Loss: 123.94204711914062, Entropy -150.1588134765625, Learning Rate: 3.90625e-05\n",
      "Epoch [4818/20000], Loss: 122.48941040039062, Entropy -144.03750610351562, Learning Rate: 3.90625e-05\n",
      "Epoch [4819/20000], Loss: 118.94306945800781, Entropy -141.65673828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4820/20000], Loss: 113.68537902832031, Entropy -133.29800415039062, Learning Rate: 3.90625e-05\n",
      "Epoch [4821/20000], Loss: 108.41058349609375, Entropy -134.48680114746094, Learning Rate: 3.90625e-05\n",
      "Epoch [4822/20000], Loss: 117.24978637695312, Entropy -146.6090850830078, Learning Rate: 3.90625e-05\n",
      "Epoch [4823/20000], Loss: 125.87275695800781, Entropy -152.67457580566406, Learning Rate: 3.90625e-05\n",
      "Epoch [4824/20000], Loss: 126.29853820800781, Entropy -147.87692260742188, Learning Rate: 3.90625e-05\n",
      "Epoch [4825/20000], Loss: 115.22724914550781, Entropy -138.38131713867188, Learning Rate: 3.90625e-05\n",
      "Epoch [4826/20000], Loss: 126.69552612304688, Entropy -145.782958984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4827/20000], Loss: 113.48292541503906, Entropy -128.9042510986328, Learning Rate: 3.90625e-05\n",
      "Epoch [4828/20000], Loss: 124.47193908691406, Entropy -141.4029083251953, Learning Rate: 3.90625e-05\n",
      "Epoch [4829/20000], Loss: 110.31784057617188, Entropy -130.83663940429688, Learning Rate: 3.90625e-05\n",
      "Epoch [4830/20000], Loss: 112.52925109863281, Entropy -135.884521484375, Learning Rate: 3.90625e-05\n",
      "Epoch [4831/20000], Loss: 117.7740478515625, Entropy -140.72421264648438, Learning Rate: 3.90625e-05\n",
      "Epoch [4832/20000], Loss: 112.48440551757812, Entropy -129.86611938476562, Learning Rate: 3.90625e-05\n",
      "Epoch [4833/20000], Loss: 121.83905029296875, Entropy -143.11123657226562, Learning Rate: 3.90625e-05\n",
      "Epoch [4834/20000], Loss: 118.94564819335938, Entropy -135.12255859375, Learning Rate: 3.90625e-05\n",
      "Epoch [4835/20000], Loss: 123.52644348144531, Entropy -146.90933227539062, Learning Rate: 3.90625e-05\n",
      "Epoch [4836/20000], Loss: 116.8084716796875, Entropy -140.82371520996094, Learning Rate: 3.90625e-05\n",
      "Epoch [4837/20000], Loss: 141.90013122558594, Entropy -175.5896759033203, Learning Rate: 3.90625e-05\n",
      "Epoch [4838/20000], Loss: 112.83303833007812, Entropy -129.84564208984375, Learning Rate: 3.90625e-05\n",
      "Epoch [4839/20000], Loss: 124.88807678222656, Entropy -147.78781127929688, Learning Rate: 3.90625e-05\n",
      "Epoch [4840/20000], Loss: 113.65812683105469, Entropy -128.65574645996094, Learning Rate: 3.90625e-05\n",
      "Epoch [4841/20000], Loss: 130.85076904296875, Entropy -150.44834899902344, Learning Rate: 3.90625e-05\n",
      "Epoch [4842/20000], Loss: 116.90176391601562, Entropy -138.240966796875, Learning Rate: 3.90625e-05\n",
      "Epoch [4843/20000], Loss: 113.60235595703125, Entropy -133.23208618164062, Learning Rate: 3.90625e-05\n",
      "Epoch [4844/20000], Loss: 128.56263732910156, Entropy -155.56967163085938, Learning Rate: 3.90625e-05\n",
      "Epoch [4845/20000], Loss: 112.5262451171875, Entropy -130.73394775390625, Learning Rate: 3.90625e-05\n",
      "Epoch [4846/20000], Loss: 112.25285339355469, Entropy -135.81494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [4847/20000], Loss: 116.19064331054688, Entropy -134.19662475585938, Learning Rate: 3.90625e-05\n",
      "Epoch [4848/20000], Loss: 124.56507873535156, Entropy -149.27764892578125, Learning Rate: 3.90625e-05\n",
      "Epoch [4849/20000], Loss: 115.87016296386719, Entropy -136.02281188964844, Learning Rate: 3.90625e-05\n",
      "Epoch [4850/20000], Loss: 126.85548400878906, Entropy -152.216552734375, Learning Rate: 3.90625e-05\n",
      "Epoch [4851/20000], Loss: 119.68913269042969, Entropy -139.0537109375, Learning Rate: 3.90625e-05\n",
      "Epoch [4852/20000], Loss: 127.83615112304688, Entropy -151.02407836914062, Learning Rate: 3.90625e-05\n",
      "Epoch [4853/20000], Loss: 125.73480224609375, Entropy -145.66993713378906, Learning Rate: 3.90625e-05\n",
      "Epoch [4854/20000], Loss: 118.87120056152344, Entropy -153.06451416015625, Learning Rate: 3.90625e-05\n",
      "Epoch [4855/20000], Loss: 115.59613037109375, Entropy -138.28599548339844, Learning Rate: 3.90625e-05\n",
      "Epoch [4856/20000], Loss: 118.57115173339844, Entropy -143.6219482421875, Learning Rate: 3.90625e-05\n",
      "Epoch [4857/20000], Loss: 117.32002258300781, Entropy -142.13394165039062, Learning Rate: 3.90625e-05\n",
      "Epoch [4858/20000], Loss: 117.77403259277344, Entropy -142.7803955078125, Learning Rate: 3.90625e-05\n",
      "Epoch [4859/20000], Loss: 112.021240234375, Entropy -132.7511444091797, Learning Rate: 3.90625e-05\n",
      "Epoch [4860/20000], Loss: 110.98616027832031, Entropy -129.24557495117188, Learning Rate: 3.90625e-05\n",
      "Epoch [4861/20000], Loss: 118.68638610839844, Entropy -143.74972534179688, Learning Rate: 3.90625e-05\n",
      "Epoch [4862/20000], Loss: 123.58842468261719, Entropy -143.00518798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [4863/20000], Loss: 128.5798797607422, Entropy -140.18023681640625, Learning Rate: 3.90625e-05\n",
      "Epoch [4864/20000], Loss: 117.15483093261719, Entropy -134.94544982910156, Learning Rate: 3.90625e-05\n",
      "Epoch [4865/20000], Loss: 117.80996704101562, Entropy -147.03024291992188, Learning Rate: 3.90625e-05\n",
      "Epoch [4866/20000], Loss: 126.81605529785156, Entropy -154.83558654785156, Learning Rate: 3.90625e-05\n",
      "Epoch [4867/20000], Loss: 113.01261901855469, Entropy -135.60394287109375, Learning Rate: 3.90625e-05\n",
      "Epoch [4868/20000], Loss: 126.99339294433594, Entropy -156.04916381835938, Learning Rate: 3.90625e-05\n",
      "Epoch [4869/20000], Loss: 118.18804931640625, Entropy -137.2692413330078, Learning Rate: 3.90625e-05\n",
      "Epoch [4870/20000], Loss: 110.00315856933594, Entropy -127.24261474609375, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4871/20000], Loss: 122.41287231445312, Entropy -149.62216186523438, Learning Rate: 3.90625e-05\n",
      "Epoch [4872/20000], Loss: 102.97097778320312, Entropy -119.10548400878906, Learning Rate: 3.90625e-05\n",
      "Epoch [4873/20000], Loss: 128.525146484375, Entropy -148.89508056640625, Learning Rate: 3.90625e-05\n",
      "Epoch [4874/20000], Loss: 110.0198974609375, Entropy -132.07716369628906, Learning Rate: 3.90625e-05\n",
      "Epoch [4875/20000], Loss: 120.54945373535156, Entropy -144.72378540039062, Learning Rate: 3.90625e-05\n",
      "Epoch [4876/20000], Loss: 121.30587768554688, Entropy -141.530517578125, Learning Rate: 3.90625e-05\n",
      "Epoch [4877/20000], Loss: 132.5565643310547, Entropy -162.84762573242188, Learning Rate: 3.90625e-05\n",
      "Epoch [4878/20000], Loss: 129.93858337402344, Entropy -157.16192626953125, Learning Rate: 3.90625e-05\n",
      "Epoch [4879/20000], Loss: 119.17196655273438, Entropy -132.97219848632812, Learning Rate: 3.90625e-05\n",
      "Epoch [4880/20000], Loss: 122.39321899414062, Entropy -140.02252197265625, Learning Rate: 3.90625e-05\n",
      "Epoch [4881/20000], Loss: 129.19442749023438, Entropy -153.29071044921875, Learning Rate: 3.90625e-05\n",
      "Epoch [4882/20000], Loss: 127.68595886230469, Entropy -155.39706420898438, Learning Rate: 3.90625e-05\n",
      "Epoch [4883/20000], Loss: 124.33076477050781, Entropy -131.26937866210938, Learning Rate: 3.90625e-05\n",
      "Epoch [4884/20000], Loss: 116.15299987792969, Entropy -143.73435974121094, Learning Rate: 3.90625e-05\n",
      "Epoch [4885/20000], Loss: 117.55169677734375, Entropy -140.53524780273438, Learning Rate: 3.90625e-05\n",
      "Epoch [4886/20000], Loss: 124.1982421875, Entropy -147.33633422851562, Learning Rate: 3.90625e-05\n",
      "Epoch [4887/20000], Loss: 116.46308898925781, Entropy -130.5504608154297, Learning Rate: 3.90625e-05\n",
      "Epoch [4888/20000], Loss: 120.62290954589844, Entropy -143.81097412109375, Learning Rate: 3.90625e-05\n",
      "Epoch [4889/20000], Loss: 128.2107391357422, Entropy -148.89747619628906, Learning Rate: 3.90625e-05\n",
      "Epoch [4890/20000], Loss: 123.34925842285156, Entropy -139.91868591308594, Learning Rate: 3.90625e-05\n",
      "Epoch [4891/20000], Loss: 124.00804138183594, Entropy -154.25833129882812, Learning Rate: 3.90625e-05\n",
      "Epoch [4892/20000], Loss: 122.2562255859375, Entropy -142.98248291015625, Learning Rate: 3.90625e-05\n",
      "Epoch [4893/20000], Loss: 116.38348388671875, Entropy -141.19009399414062, Learning Rate: 3.90625e-05\n",
      "Epoch [4894/20000], Loss: 113.20388793945312, Entropy -135.53717041015625, Learning Rate: 3.90625e-05\n",
      "Epoch [4895/20000], Loss: 122.49801635742188, Entropy -148.23187255859375, Learning Rate: 3.90625e-05\n",
      "Epoch [4896/20000], Loss: 125.24125671386719, Entropy -137.57485961914062, Learning Rate: 3.90625e-05\n",
      "Epoch [4897/20000], Loss: 114.81068420410156, Entropy -141.04562377929688, Learning Rate: 3.90625e-05\n",
      "Epoch [4898/20000], Loss: 113.94766235351562, Entropy -134.46832275390625, Learning Rate: 3.90625e-05\n",
      "Epoch [4899/20000], Loss: 142.76007080078125, Entropy -175.2620086669922, Learning Rate: 3.90625e-05\n",
      "Epoch [4900/20000], Loss: 118.81727600097656, Entropy -137.04200744628906, Learning Rate: 3.90625e-05\n",
      "Epoch [4901/20000], Loss: 122.4166259765625, Entropy -142.65975952148438, Learning Rate: 3.90625e-05\n",
      "Epoch [4902/20000], Loss: 115.30714416503906, Entropy -131.84866333007812, Learning Rate: 3.90625e-05\n",
      "Epoch [4903/20000], Loss: 120.5146484375, Entropy -147.387939453125, Learning Rate: 3.90625e-05\n",
      "Epoch [4904/20000], Loss: 125.39598083496094, Entropy -141.02090454101562, Learning Rate: 3.90625e-05\n",
      "Epoch [4905/20000], Loss: 122.63720703125, Entropy -148.96054077148438, Learning Rate: 3.90625e-05\n",
      "Epoch [4906/20000], Loss: 122.17143249511719, Entropy -143.32237243652344, Learning Rate: 3.90625e-05\n",
      "Epoch [4907/20000], Loss: 116.97348022460938, Entropy -144.0792236328125, Learning Rate: 3.90625e-05\n",
      "Epoch [4908/20000], Loss: 129.9736328125, Entropy -162.8988800048828, Learning Rate: 3.90625e-05\n",
      "Epoch [4909/20000], Loss: 120.55018615722656, Entropy -145.1109619140625, Learning Rate: 3.90625e-05\n",
      "Epoch [4910/20000], Loss: 117.27656555175781, Entropy -140.22796630859375, Learning Rate: 3.90625e-05\n",
      "Epoch [4911/20000], Loss: 125.72093200683594, Entropy -147.63314819335938, Learning Rate: 3.90625e-05\n",
      "Epoch [4912/20000], Loss: 117.84426879882812, Entropy -134.69424438476562, Learning Rate: 3.90625e-05\n",
      "Epoch [4913/20000], Loss: 111.53630065917969, Entropy -131.26824951171875, Learning Rate: 3.90625e-05\n",
      "Epoch [4914/20000], Loss: 120.04254150390625, Entropy -148.3558349609375, Learning Rate: 3.90625e-05\n",
      "Epoch [4915/20000], Loss: 117.13619995117188, Entropy -139.65115356445312, Learning Rate: 3.90625e-05\n",
      "Epoch [4916/20000], Loss: 125.22218322753906, Entropy -144.42013549804688, Learning Rate: 3.90625e-05\n",
      "Epoch [4917/20000], Loss: 112.00372314453125, Entropy -133.0697021484375, Learning Rate: 3.90625e-05\n",
      "Epoch [4918/20000], Loss: 126.64227294921875, Entropy -156.95326232910156, Learning Rate: 3.90625e-05\n",
      "Epoch [4919/20000], Loss: 136.48533630371094, Entropy -170.19818115234375, Learning Rate: 3.90625e-05\n",
      "Epoch [4920/20000], Loss: 124.68009948730469, Entropy -153.46461486816406, Learning Rate: 1.953125e-05\n",
      "Epoch [4921/20000], Loss: 119.41770935058594, Entropy -142.90403747558594, Learning Rate: 1.953125e-05\n",
      "Epoch [4922/20000], Loss: 117.50143432617188, Entropy -142.25743103027344, Learning Rate: 1.953125e-05\n",
      "Epoch [4923/20000], Loss: 123.64729309082031, Entropy -141.01307678222656, Learning Rate: 1.953125e-05\n",
      "Epoch [4924/20000], Loss: 118.75799560546875, Entropy -150.87408447265625, Learning Rate: 1.953125e-05\n",
      "Epoch [4925/20000], Loss: 127.39057922363281, Entropy -156.1387939453125, Learning Rate: 1.953125e-05\n",
      "Epoch [4926/20000], Loss: 118.61476135253906, Entropy -141.6572265625, Learning Rate: 1.953125e-05\n",
      "Epoch [4927/20000], Loss: 106.55136108398438, Entropy -126.27607727050781, Learning Rate: 1.953125e-05\n",
      "Epoch [4928/20000], Loss: 125.49441528320312, Entropy -143.25875854492188, Learning Rate: 1.953125e-05\n",
      "Epoch [4929/20000], Loss: 113.06935119628906, Entropy -127.36064147949219, Learning Rate: 1.953125e-05\n",
      "Epoch [4930/20000], Loss: 111.74288940429688, Entropy -131.15638732910156, Learning Rate: 1.953125e-05\n",
      "Epoch [4931/20000], Loss: 110.88337707519531, Entropy -130.64108276367188, Learning Rate: 1.953125e-05\n",
      "Epoch [4932/20000], Loss: 123.50871276855469, Entropy -148.20248413085938, Learning Rate: 1.953125e-05\n",
      "Epoch [4933/20000], Loss: 114.89094543457031, Entropy -128.48910522460938, Learning Rate: 1.953125e-05\n",
      "Epoch [4934/20000], Loss: 109.14254760742188, Entropy -129.40097045898438, Learning Rate: 1.953125e-05\n",
      "Epoch [4935/20000], Loss: 131.20388793945312, Entropy -158.56146240234375, Learning Rate: 1.953125e-05\n",
      "Epoch [4936/20000], Loss: 111.88265991210938, Entropy -132.63217163085938, Learning Rate: 1.953125e-05\n",
      "Epoch [4937/20000], Loss: 124.78152465820312, Entropy -145.04617309570312, Learning Rate: 1.953125e-05\n",
      "Epoch [4938/20000], Loss: 121.07142639160156, Entropy -142.50650024414062, Learning Rate: 1.953125e-05\n",
      "Epoch [4939/20000], Loss: 118.14155578613281, Entropy -136.1866455078125, Learning Rate: 1.953125e-05\n",
      "Epoch [4940/20000], Loss: 121.10702514648438, Entropy -142.17904663085938, Learning Rate: 1.953125e-05\n",
      "Epoch [4941/20000], Loss: 113.98689270019531, Entropy -135.72836303710938, Learning Rate: 1.953125e-05\n",
      "Epoch [4942/20000], Loss: 133.1887664794922, Entropy -155.07028198242188, Learning Rate: 1.953125e-05\n",
      "Epoch [4943/20000], Loss: 116.915283203125, Entropy -140.8666229248047, Learning Rate: 1.953125e-05\n",
      "Epoch [4944/20000], Loss: 125.15699768066406, Entropy -134.5796661376953, Learning Rate: 1.953125e-05\n",
      "Epoch [4945/20000], Loss: 124.21066284179688, Entropy -146.16635131835938, Learning Rate: 1.953125e-05\n",
      "Epoch [4946/20000], Loss: 115.82759094238281, Entropy -141.30563354492188, Learning Rate: 1.953125e-05\n",
      "Epoch [4947/20000], Loss: 113.3734130859375, Entropy -137.35287475585938, Learning Rate: 1.953125e-05\n",
      "Epoch [4948/20000], Loss: 113.15786743164062, Entropy -137.16590881347656, Learning Rate: 1.953125e-05\n",
      "Epoch [4949/20000], Loss: 124.36795043945312, Entropy -148.71853637695312, Learning Rate: 1.953125e-05\n",
      "Epoch [4950/20000], Loss: 119.9066162109375, Entropy -139.3428955078125, Learning Rate: 1.953125e-05\n",
      "Epoch [4951/20000], Loss: 116.99226379394531, Entropy -139.93182373046875, Learning Rate: 1.953125e-05\n",
      "Epoch [4952/20000], Loss: 116.57200622558594, Entropy -140.30352783203125, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4953/20000], Loss: 116.78285217285156, Entropy -148.25970458984375, Learning Rate: 1.953125e-05\n",
      "Epoch [4954/20000], Loss: 120.77616882324219, Entropy -152.21383666992188, Learning Rate: 1.953125e-05\n",
      "Epoch [4955/20000], Loss: 120.64547729492188, Entropy -145.42189025878906, Learning Rate: 1.953125e-05\n",
      "Epoch [4956/20000], Loss: 114.74610900878906, Entropy -137.12814331054688, Learning Rate: 1.953125e-05\n",
      "Epoch [4957/20000], Loss: 126.6851806640625, Entropy -150.88661193847656, Learning Rate: 1.953125e-05\n",
      "Epoch [4958/20000], Loss: 121.83305358886719, Entropy -142.02882385253906, Learning Rate: 1.953125e-05\n",
      "Epoch [4959/20000], Loss: 120.43998718261719, Entropy -152.10125732421875, Learning Rate: 1.953125e-05\n",
      "Epoch [4960/20000], Loss: 111.92813110351562, Entropy -119.64788818359375, Learning Rate: 1.953125e-05\n",
      "Epoch [4961/20000], Loss: 117.87872314453125, Entropy -144.72128295898438, Learning Rate: 1.953125e-05\n",
      "Epoch [4962/20000], Loss: 126.13166809082031, Entropy -149.8072509765625, Learning Rate: 1.953125e-05\n",
      "Epoch [4963/20000], Loss: 111.86148071289062, Entropy -140.1230010986328, Learning Rate: 1.953125e-05\n",
      "Epoch [4964/20000], Loss: 113.15977478027344, Entropy -145.21273803710938, Learning Rate: 1.953125e-05\n",
      "Epoch [4965/20000], Loss: 120.14959716796875, Entropy -147.75933837890625, Learning Rate: 1.953125e-05\n",
      "Epoch [4966/20000], Loss: 111.29252624511719, Entropy -126.1285400390625, Learning Rate: 1.953125e-05\n",
      "Epoch [4967/20000], Loss: 117.55540466308594, Entropy -137.11276245117188, Learning Rate: 1.953125e-05\n",
      "Epoch [4968/20000], Loss: 125.560791015625, Entropy -156.99229431152344, Learning Rate: 1.953125e-05\n",
      "Epoch [4969/20000], Loss: 117.77325439453125, Entropy -133.42161560058594, Learning Rate: 1.953125e-05\n",
      "Epoch [4970/20000], Loss: 110.85760498046875, Entropy -126.14913940429688, Learning Rate: 1.953125e-05\n",
      "Epoch [4971/20000], Loss: 119.74708557128906, Entropy -146.10678100585938, Learning Rate: 1.953125e-05\n",
      "Epoch [4972/20000], Loss: 131.3585968017578, Entropy -153.35177612304688, Learning Rate: 1.953125e-05\n",
      "Epoch [4973/20000], Loss: 124.67462158203125, Entropy -146.9136962890625, Learning Rate: 1.953125e-05\n",
      "Epoch [4974/20000], Loss: 139.32977294921875, Entropy -165.18484497070312, Learning Rate: 1.953125e-05\n",
      "Epoch [4975/20000], Loss: 130.20726013183594, Entropy -160.93687438964844, Learning Rate: 1.953125e-05\n",
      "Epoch [4976/20000], Loss: 127.01559448242188, Entropy -153.14617919921875, Learning Rate: 1.953125e-05\n",
      "Epoch [4977/20000], Loss: 115.4033203125, Entropy -130.1922149658203, Learning Rate: 1.953125e-05\n",
      "Epoch [4978/20000], Loss: 114.33824157714844, Entropy -138.75765991210938, Learning Rate: 1.953125e-05\n",
      "Epoch [4979/20000], Loss: 128.4326934814453, Entropy -156.0225372314453, Learning Rate: 1.953125e-05\n",
      "Epoch [4980/20000], Loss: 122.01834106445312, Entropy -150.05111694335938, Learning Rate: 1.953125e-05\n",
      "Epoch [4981/20000], Loss: 120.19172668457031, Entropy -140.17282104492188, Learning Rate: 1.953125e-05\n",
      "Epoch [4982/20000], Loss: 110.25749206542969, Entropy -136.8031005859375, Learning Rate: 1.953125e-05\n",
      "Epoch [4983/20000], Loss: 127.89254760742188, Entropy -152.42239379882812, Learning Rate: 1.953125e-05\n",
      "Epoch [4984/20000], Loss: 114.81771850585938, Entropy -137.58778381347656, Learning Rate: 1.953125e-05\n",
      "Epoch [4985/20000], Loss: 131.8095703125, Entropy -161.83306884765625, Learning Rate: 1.953125e-05\n",
      "Epoch [4986/20000], Loss: 113.16239929199219, Entropy -133.9483184814453, Learning Rate: 1.953125e-05\n",
      "Epoch [4987/20000], Loss: 125.87803649902344, Entropy -152.54388427734375, Learning Rate: 1.953125e-05\n",
      "Epoch [4988/20000], Loss: 117.16378784179688, Entropy -135.93746948242188, Learning Rate: 1.953125e-05\n",
      "Epoch [4989/20000], Loss: 117.18820190429688, Entropy -142.0526123046875, Learning Rate: 1.953125e-05\n",
      "Epoch [4990/20000], Loss: 122.65316772460938, Entropy -146.12071228027344, Learning Rate: 1.953125e-05\n",
      "Epoch [4991/20000], Loss: 109.64407348632812, Entropy -125.40119934082031, Learning Rate: 1.953125e-05\n",
      "Epoch [4992/20000], Loss: 115.44505310058594, Entropy -132.1802978515625, Learning Rate: 1.953125e-05\n",
      "Epoch [4993/20000], Loss: 123.36573791503906, Entropy -146.27224731445312, Learning Rate: 1.953125e-05\n",
      "Epoch [4994/20000], Loss: 123.93023681640625, Entropy -138.87257385253906, Learning Rate: 1.953125e-05\n",
      "Epoch [4995/20000], Loss: 115.69868469238281, Entropy -137.3876953125, Learning Rate: 1.953125e-05\n",
      "Epoch [4996/20000], Loss: 119.92312622070312, Entropy -140.41195678710938, Learning Rate: 1.953125e-05\n",
      "Epoch [4997/20000], Loss: 118.19961547851562, Entropy -143.3812255859375, Learning Rate: 1.953125e-05\n",
      "Epoch [4998/20000], Loss: 118.37933349609375, Entropy -141.30905151367188, Learning Rate: 1.953125e-05\n",
      "Epoch [4999/20000], Loss: 126.06594848632812, Entropy -147.08204650878906, Learning Rate: 1.953125e-05\n",
      "Epoch [5000/20000], Loss: 114.61526489257812, Entropy -141.8167724609375, Learning Rate: 1.953125e-05\n",
      "Epoch [5001/20000], Loss: 117.52459716796875, Entropy -133.9324188232422, Learning Rate: 1.953125e-05\n",
      "Epoch [5002/20000], Loss: 115.32856750488281, Entropy -139.789794921875, Learning Rate: 1.953125e-05\n",
      "Epoch [5003/20000], Loss: 116.59579467773438, Entropy -138.0647735595703, Learning Rate: 1.953125e-05\n",
      "Epoch [5004/20000], Loss: 126.21072387695312, Entropy -147.2605743408203, Learning Rate: 1.953125e-05\n",
      "Epoch [5005/20000], Loss: 119.26313781738281, Entropy -146.41696166992188, Learning Rate: 1.953125e-05\n",
      "Epoch [5006/20000], Loss: 118.21243286132812, Entropy -131.24884033203125, Learning Rate: 1.953125e-05\n",
      "Epoch [5007/20000], Loss: 117.41636657714844, Entropy -141.40565490722656, Learning Rate: 1.953125e-05\n",
      "Epoch [5008/20000], Loss: 126.11439514160156, Entropy -144.38330078125, Learning Rate: 1.953125e-05\n",
      "Epoch [5009/20000], Loss: 116.63890075683594, Entropy -139.8012237548828, Learning Rate: 1.953125e-05\n",
      "Epoch [5010/20000], Loss: 121.60649108886719, Entropy -147.2396240234375, Learning Rate: 1.953125e-05\n",
      "Epoch [5011/20000], Loss: 120.35452270507812, Entropy -146.16915893554688, Learning Rate: 1.953125e-05\n",
      "Epoch [5012/20000], Loss: 127.40414428710938, Entropy -142.3839569091797, Learning Rate: 1.953125e-05\n",
      "Epoch [5013/20000], Loss: 130.74136352539062, Entropy -161.65478515625, Learning Rate: 1.953125e-05\n",
      "Epoch [5014/20000], Loss: 111.21591186523438, Entropy -124.72740173339844, Learning Rate: 1.953125e-05\n",
      "Epoch [5015/20000], Loss: 105.44685363769531, Entropy -125.05485534667969, Learning Rate: 1.953125e-05\n",
      "Epoch [5016/20000], Loss: 126.70649719238281, Entropy -154.67269897460938, Learning Rate: 1.953125e-05\n",
      "Epoch [5017/20000], Loss: 121.112548828125, Entropy -146.45291137695312, Learning Rate: 1.953125e-05\n",
      "Epoch [5018/20000], Loss: 118.46022033691406, Entropy -143.23599243164062, Learning Rate: 1.953125e-05\n",
      "Epoch [5019/20000], Loss: 122.02259826660156, Entropy -148.6212158203125, Learning Rate: 1.953125e-05\n",
      "Epoch [5020/20000], Loss: 115.97810363769531, Entropy -134.1962890625, Learning Rate: 1.953125e-05\n",
      "Epoch [5021/20000], Loss: 124.79286193847656, Entropy -144.33773803710938, Learning Rate: 1.953125e-05\n",
      "Epoch [5022/20000], Loss: 134.2391357421875, Entropy -156.8433074951172, Learning Rate: 1.953125e-05\n",
      "Epoch [5023/20000], Loss: 113.99739074707031, Entropy -141.491943359375, Learning Rate: 1.953125e-05\n",
      "Epoch [5024/20000], Loss: 114.25877380371094, Entropy -133.9354248046875, Learning Rate: 1.953125e-05\n",
      "Epoch [5025/20000], Loss: 126.11528015136719, Entropy -150.1650390625, Learning Rate: 1.953125e-05\n",
      "Epoch [5026/20000], Loss: 112.19416809082031, Entropy -136.7886199951172, Learning Rate: 1.953125e-05\n",
      "Epoch [5027/20000], Loss: 114.46391296386719, Entropy -132.13656616210938, Learning Rate: 1.953125e-05\n",
      "Epoch [5028/20000], Loss: 120.56797790527344, Entropy -148.81588745117188, Learning Rate: 1.953125e-05\n",
      "Epoch [5029/20000], Loss: 115.30181884765625, Entropy -143.06887817382812, Learning Rate: 1.953125e-05\n",
      "Epoch [5030/20000], Loss: 121.17474365234375, Entropy -146.39337158203125, Learning Rate: 1.953125e-05\n",
      "Epoch [5031/20000], Loss: 114.18818664550781, Entropy -132.46206665039062, Learning Rate: 1.953125e-05\n",
      "Epoch [5032/20000], Loss: 117.62455749511719, Entropy -138.23309326171875, Learning Rate: 1.953125e-05\n",
      "Epoch [5033/20000], Loss: 120.44731140136719, Entropy -133.94296264648438, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5034/20000], Loss: 127.45393371582031, Entropy -157.142333984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5035/20000], Loss: 117.02442932128906, Entropy -138.4775390625, Learning Rate: 1.953125e-05\n",
      "Epoch [5036/20000], Loss: 118.41024780273438, Entropy -132.56057739257812, Learning Rate: 1.953125e-05\n",
      "Epoch [5037/20000], Loss: 126.43315124511719, Entropy -152.29833984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5038/20000], Loss: 115.695068359375, Entropy -135.74346923828125, Learning Rate: 1.953125e-05\n",
      "Epoch [5039/20000], Loss: 129.31765747070312, Entropy -153.98544311523438, Learning Rate: 1.953125e-05\n",
      "Epoch [5040/20000], Loss: 114.21099853515625, Entropy -136.570068359375, Learning Rate: 1.953125e-05\n",
      "Epoch [5041/20000], Loss: 123.54191589355469, Entropy -146.32275390625, Learning Rate: 1.953125e-05\n",
      "Epoch [5042/20000], Loss: 118.56474304199219, Entropy -133.53749084472656, Learning Rate: 1.953125e-05\n",
      "Epoch [5043/20000], Loss: 114.40583801269531, Entropy -141.18460083007812, Learning Rate: 1.953125e-05\n",
      "Epoch [5044/20000], Loss: 122.08352661132812, Entropy -142.8563232421875, Learning Rate: 1.953125e-05\n",
      "Epoch [5045/20000], Loss: 111.98246765136719, Entropy -138.8819122314453, Learning Rate: 1.953125e-05\n",
      "Epoch [5046/20000], Loss: 139.68360900878906, Entropy -167.2985382080078, Learning Rate: 1.953125e-05\n",
      "Epoch [5047/20000], Loss: 113.75325012207031, Entropy -134.55120849609375, Learning Rate: 1.953125e-05\n",
      "Epoch [5048/20000], Loss: 108.75811767578125, Entropy -127.30123901367188, Learning Rate: 1.953125e-05\n",
      "Epoch [5049/20000], Loss: 126.87673950195312, Entropy -151.447021484375, Learning Rate: 1.953125e-05\n",
      "Epoch [5050/20000], Loss: 113.53861999511719, Entropy -135.86593627929688, Learning Rate: 1.953125e-05\n",
      "Epoch [5051/20000], Loss: 124.40611267089844, Entropy -142.076416015625, Learning Rate: 1.953125e-05\n",
      "Epoch [5052/20000], Loss: 119.72076416015625, Entropy -141.51400756835938, Learning Rate: 1.953125e-05\n",
      "Epoch [5053/20000], Loss: 124.6474609375, Entropy -150.93409729003906, Learning Rate: 1.953125e-05\n",
      "Epoch [5054/20000], Loss: 118.50830078125, Entropy -147.0048828125, Learning Rate: 1.953125e-05\n",
      "Epoch [5055/20000], Loss: 119.68812561035156, Entropy -139.71951293945312, Learning Rate: 1.953125e-05\n",
      "Epoch [5056/20000], Loss: 117.75210571289062, Entropy -144.7589569091797, Learning Rate: 1.953125e-05\n",
      "Epoch [5057/20000], Loss: 119.63304138183594, Entropy -138.08975219726562, Learning Rate: 1.953125e-05\n",
      "Epoch [5058/20000], Loss: 124.69145202636719, Entropy -143.03857421875, Learning Rate: 1.953125e-05\n",
      "Epoch [5059/20000], Loss: 114.08915710449219, Entropy -136.382568359375, Learning Rate: 1.953125e-05\n",
      "Epoch [5060/20000], Loss: 112.11114501953125, Entropy -126.56280517578125, Learning Rate: 1.953125e-05\n",
      "Epoch [5061/20000], Loss: 131.20230102539062, Entropy -163.96951293945312, Learning Rate: 1.953125e-05\n",
      "Epoch [5062/20000], Loss: 125.21047973632812, Entropy -155.01678466796875, Learning Rate: 1.953125e-05\n",
      "Epoch [5063/20000], Loss: 115.39570617675781, Entropy -129.67578125, Learning Rate: 1.953125e-05\n",
      "Epoch [5064/20000], Loss: 116.69398498535156, Entropy -135.82713317871094, Learning Rate: 1.953125e-05\n",
      "Epoch [5065/20000], Loss: 113.60368347167969, Entropy -137.3370819091797, Learning Rate: 1.953125e-05\n",
      "Epoch [5066/20000], Loss: 122.43939208984375, Entropy -140.49595642089844, Learning Rate: 1.953125e-05\n",
      "Epoch [5067/20000], Loss: 128.70103454589844, Entropy -153.42620849609375, Learning Rate: 1.953125e-05\n",
      "Epoch [5068/20000], Loss: 137.67819213867188, Entropy -166.5409393310547, Learning Rate: 1.953125e-05\n",
      "Epoch [5069/20000], Loss: 116.78257751464844, Entropy -142.21231079101562, Learning Rate: 1.953125e-05\n",
      "Epoch [5070/20000], Loss: 107.35685729980469, Entropy -127.48249816894531, Learning Rate: 1.953125e-05\n",
      "Epoch [5071/20000], Loss: 113.21047973632812, Entropy -129.188232421875, Learning Rate: 1.953125e-05\n",
      "Epoch [5072/20000], Loss: 114.36332702636719, Entropy -132.81192016601562, Learning Rate: 1.953125e-05\n",
      "Epoch [5073/20000], Loss: 113.81660461425781, Entropy -139.3667449951172, Learning Rate: 1.953125e-05\n",
      "Epoch [5074/20000], Loss: 109.31338500976562, Entropy -133.333251953125, Learning Rate: 1.953125e-05\n",
      "Epoch [5075/20000], Loss: 116.78274536132812, Entropy -148.73907470703125, Learning Rate: 1.953125e-05\n",
      "Epoch [5076/20000], Loss: 124.54298400878906, Entropy -153.64071655273438, Learning Rate: 1.953125e-05\n",
      "Epoch [5077/20000], Loss: 126.07691955566406, Entropy -152.3728790283203, Learning Rate: 1.953125e-05\n",
      "Epoch [5078/20000], Loss: 109.60885620117188, Entropy -133.2113494873047, Learning Rate: 1.953125e-05\n",
      "Epoch [5079/20000], Loss: 123.87571716308594, Entropy -136.0054931640625, Learning Rate: 1.953125e-05\n",
      "Epoch [5080/20000], Loss: 111.03962707519531, Entropy -133.3535919189453, Learning Rate: 1.953125e-05\n",
      "Epoch [5081/20000], Loss: 127.369384765625, Entropy -158.62649536132812, Learning Rate: 1.953125e-05\n",
      "Epoch [5082/20000], Loss: 138.04769897460938, Entropy -159.4324188232422, Learning Rate: 1.953125e-05\n",
      "Epoch [5083/20000], Loss: 117.49580383300781, Entropy -148.26483154296875, Learning Rate: 1.953125e-05\n",
      "Epoch [5084/20000], Loss: 110.75782775878906, Entropy -134.1158447265625, Learning Rate: 1.953125e-05\n",
      "Epoch [5085/20000], Loss: 114.30825805664062, Entropy -134.9506072998047, Learning Rate: 1.953125e-05\n",
      "Epoch [5086/20000], Loss: 113.90461730957031, Entropy -135.87826538085938, Learning Rate: 1.953125e-05\n",
      "Epoch [5087/20000], Loss: 112.78419494628906, Entropy -136.7770233154297, Learning Rate: 1.953125e-05\n",
      "Epoch [5088/20000], Loss: 117.23306274414062, Entropy -145.42959594726562, Learning Rate: 1.953125e-05\n",
      "Epoch [5089/20000], Loss: 117.24021911621094, Entropy -136.79574584960938, Learning Rate: 1.953125e-05\n",
      "Epoch [5090/20000], Loss: 113.39208984375, Entropy -140.29812622070312, Learning Rate: 1.953125e-05\n",
      "Epoch [5091/20000], Loss: 120.45207214355469, Entropy -140.90147399902344, Learning Rate: 1.953125e-05\n",
      "Epoch [5092/20000], Loss: 134.588134765625, Entropy -160.06283569335938, Learning Rate: 1.953125e-05\n",
      "Epoch [5093/20000], Loss: 119.84530639648438, Entropy -149.1907958984375, Learning Rate: 1.953125e-05\n",
      "Epoch [5094/20000], Loss: 121.29879760742188, Entropy -139.99327087402344, Learning Rate: 1.953125e-05\n",
      "Epoch [5095/20000], Loss: 108.14649963378906, Entropy -126.92601013183594, Learning Rate: 1.953125e-05\n",
      "Epoch [5096/20000], Loss: 108.79985046386719, Entropy -125.55819702148438, Learning Rate: 1.953125e-05\n",
      "Epoch [5097/20000], Loss: 112.64704895019531, Entropy -131.59649658203125, Learning Rate: 1.953125e-05\n",
      "Epoch [5098/20000], Loss: 118.47526550292969, Entropy -144.7845916748047, Learning Rate: 1.953125e-05\n",
      "Epoch [5099/20000], Loss: 126.37094116210938, Entropy -153.02012634277344, Learning Rate: 1.953125e-05\n",
      "Epoch [5100/20000], Loss: 120.03379821777344, Entropy -143.4667510986328, Learning Rate: 1.953125e-05\n",
      "Epoch [5101/20000], Loss: 123.89582824707031, Entropy -143.75070190429688, Learning Rate: 1.953125e-05\n",
      "Epoch [5102/20000], Loss: 120.34153747558594, Entropy -141.69186401367188, Learning Rate: 1.953125e-05\n",
      "Epoch [5103/20000], Loss: 113.16557312011719, Entropy -139.28968811035156, Learning Rate: 1.953125e-05\n",
      "Epoch [5104/20000], Loss: 130.81333923339844, Entropy -157.2818145751953, Learning Rate: 1.953125e-05\n",
      "Epoch [5105/20000], Loss: 121.60130310058594, Entropy -150.00765991210938, Learning Rate: 1.953125e-05\n",
      "Epoch [5106/20000], Loss: 120.80961608886719, Entropy -151.74081420898438, Learning Rate: 1.953125e-05\n",
      "Epoch [5107/20000], Loss: 127.05661010742188, Entropy -162.1876983642578, Learning Rate: 1.953125e-05\n",
      "Epoch [5108/20000], Loss: 127.22384643554688, Entropy -153.87759399414062, Learning Rate: 1.953125e-05\n",
      "Epoch [5109/20000], Loss: 118.43574523925781, Entropy -145.36013793945312, Learning Rate: 1.953125e-05\n",
      "Epoch [5110/20000], Loss: 118.68096923828125, Entropy -140.74441528320312, Learning Rate: 1.953125e-05\n",
      "Epoch [5111/20000], Loss: 120.92633056640625, Entropy -144.18374633789062, Learning Rate: 1.953125e-05\n",
      "Epoch [5112/20000], Loss: 119.76411437988281, Entropy -143.50238037109375, Learning Rate: 1.953125e-05\n",
      "Epoch [5113/20000], Loss: 112.62184143066406, Entropy -136.48289489746094, Learning Rate: 1.953125e-05\n",
      "Epoch [5114/20000], Loss: 131.48214721679688, Entropy -154.9761199951172, Learning Rate: 1.953125e-05\n",
      "Epoch [5115/20000], Loss: 117.58172607421875, Entropy -133.59080505371094, Learning Rate: 1.953125e-05\n",
      "Epoch [5116/20000], Loss: 114.3282470703125, Entropy -126.37884521484375, Learning Rate: 1.953125e-05\n",
      "Epoch [5117/20000], Loss: 110.10792541503906, Entropy -129.489990234375, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5118/20000], Loss: 115.47613525390625, Entropy -138.23228454589844, Learning Rate: 1.953125e-05\n",
      "Epoch [5119/20000], Loss: 126.05648803710938, Entropy -149.23526000976562, Learning Rate: 1.953125e-05\n",
      "Epoch [5120/20000], Loss: 117.77925109863281, Entropy -137.55462646484375, Learning Rate: 1.953125e-05\n",
      "Epoch [5121/20000], Loss: 116.81765747070312, Entropy -143.6905517578125, Learning Rate: 9.765625e-06\n",
      "4316 [tensor(101.8017, device='cuda:0'), tensor(-116.3581, device='cuda:0'), tensor(-163.6185, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "k_MC=100#size_sample\n",
    "\n",
    "#sample, = ax.scatter([],[],color='red',alpha=0.07)\n",
    "#fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "'''\n",
    "def show(GeN,n,alpha=0.07):\n",
    "    Z=GeN(n).detach().clone().cpu()\n",
    "    plt.pcolormesh(grid_x.numpy(),grid_y.numpy(),p.exp().numpy())\n",
    "    plt.scatter(Z[:,0],Z[:,1],color='red',alpha=alpha) \n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "''' \n",
    "\n",
    "def show(GeN,n):\n",
    "    #Z=GeN(200).detach()\n",
    "    #fig=setup.makePlot(Z,device)\n",
    "    #plt.show()\n",
    "    return\n",
    "    \n",
    "#lr =.03 for lat_dim 5\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    optimizer = GeNPredVI(loglikelihood, logprior, projection, k_MC,\n",
    "\t\t                                    0, 100, 1000, 50, 50,\n",
    "\t\t                                    20000, .01, .00001, 200, .5,\n",
    "\t\t                                    device, True, temp_dir, save_best=True)\n",
    "    best_epoch, scores=optimizer.run(GeN,show)\n",
    "print(best_epoch,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c7a407910>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_entropy\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('KL divergence')\n",
    "plt.plot(time, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c7a41f6d0>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=torch.as_tensor(optimizer.score_elbo)\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.title('ELBO')\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c7a381dd0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y=optimizer.score_lr\n",
    "time=torch.arange(0,len(y),1.)\n",
    "plt.plot(time, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(101.8017, device='cuda:0'),\n",
       " tensor(-116.3581, device='cuda:0'),\n",
       " tensor(-163.6185, device='cuda:0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show(GeN,n):\n",
    "    Z=GeN(n).detach()\n",
    "    fig=setup.makePlot(Z,device)\n",
    "    plt.title('Predictive VI: GeNVI lat_dim='+str(lat_dim))\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "\n",
    "    \n",
    "show(GeN,1000)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLPP_train, nLPP_validation, nLPP_test, RSE_train, RSE_validation, RSE_test=setup.evaluate_metrics(GeN(1000).detach(),'\n",
    "                                                                                                   cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nLPP_valid: (tensor(-0.8727), tensor(0.7151))\n",
      "SE_valid: (tensor(0.0102), tensor(0.0145))\n",
      "nLPP_test: (tensor(0.6314), tensor(1.3946))\n",
      "SE_test: (tensor(0.2434), tensor(0.3485))\n"
     ]
    }
   ],
   "source": [
    "print('nLPP_valid: '+str(nLPP_validation))\n",
    "print('SE_valid: '+str(RSE_validation))\n",
    "print('nLPP_test: '+str(nLPP_test))\n",
    "print('SE_test: '+str(RSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un choix de points $x_0,...,x_{n-1}$, on dfinit:\n",
    "$$\n",
    "d(\\theta,\\theta')=\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert\n",
    "$$\n",
    "ou\n",
    "$$\n",
    "d_2(\\theta,\\theta')=\\biggl(\\frac{1}{n}\\sum_{i<n}\\vert f_\\theta(x_i)-f_{\\theta'}(x_i)\\vert^2\\biggr)^{\\frac{1}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(f\\in A)=P(\\{\\theta \\mid f_\\theta\\in A\\})$\n",
    "\n",
    "$\\theta \\mapsto f_\\theta$ (is it continuous?)\n",
    "\n",
    "relation entre $d(\\theta,\\theta')$ et $d(f_\\theta,f_\\theta')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
