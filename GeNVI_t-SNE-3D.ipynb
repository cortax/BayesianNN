{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "from Inference.GeNVI_method import GeNVariationalInference, GeNetEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from Experiments.foong import Setup\n",
    "#setup=Setup(device, layerwidth=50)\n",
    "\n",
    "from Experiments.boston import Setup\n",
    "setup=Setup(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target density #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logtarget= setup.logposterior\n",
    "param_count=setup.param_count\n",
    "model=setup._model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE-Variational Distribution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation = nn.Tanh()#nn.ReLU()\n",
    "init_b = .001\n",
    "\n",
    "GeN = GeNetEns(1, 3, 50, param_count, activation, 0.2, init_b, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Tools import logmvn01pdf\n",
    "\n",
    "x=torch.arange(-3.,3., 0.2).to(device)\n",
    "\n",
    "grid_X,grid_Y, grid_Z=torch.meshgrid(x, x, x)\n",
    "\n",
    "P=[]\n",
    "C=[]\n",
    "\n",
    "for i in range(grid_X.shape[0]):\n",
    "    for j in range(grid_X.shape[1]):\n",
    "        for k in range(grid_X.shape[2]):\n",
    "            p=torch.Tensor([grid_X[i,j,k],grid_Y[i,j,k],grid_Z[i,j,k]]).to(device)\n",
    "            P.append(p.cpu())\n",
    "            C.append(logmvn01pdf(p.unsqueeze(0),device).exp().cpu())\n",
    "len(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27000, 3]), torch.Size([27000]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise=torch.stack(P)\n",
    "colors=torch.stack(C)\n",
    "\n",
    "noise.shape, colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAtAAAALQCAYAAAC5V0ecAAAgAElEQVR4nOzdaZBjd3kG+pOQCmDHrLbDVkkKqlIBCmyI7QoJDk5VPlAhIR8oEgpSIUVWQhJCUZBQoYDkhntDDCQE7/Z49rX3Vfu+S0f7Lh1tLalbarW2nqXbZmae++G0NK2Wetxu94xGM8+v6lQxtEY6LWms57x6/+9fEIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiGiEgYiIiGhEDDs3EQmCwABNREREo2PYuYlIEAQGaCIiIhodw85NRIIgMEATERHR6Bh2biISBIEBmoiIiEbHsHMTkSAIDNBEREQ0Ooadm4gEQWCAJiIiotEx7NxEJAgCAzQRERGNjmHnJiJBEBigiYiIaHQMOzcRCYLAAE1ERESjY9i5iUgQBAZoIiIiGh3Dzk1EgiAwQBMREdHoGHZuIhIEgQGaiIiIRsewcxORIAgM0ERERDQ6hp2biARBYIAmIiKi0THs3EQkCAIDNBEREY2OYecmIkEQGKCJiIhodAw7NxEJgsAATURERKNj2LmJSBAEBmgiIiIaHcPOTUSCIDBAExER0egYdm4iEgSBAZqIiIhGx7BzE5EgCAzQRERENDqGnZuIBEFggCYiIqLRMezcRCQIAgM0ERERjY5h5yYiQRAYoImIiGh0DDs3EQmCwABNREREo2PYuYlIEAQGaCIiIhodw85NRIIgMEATERHR6Bh2biISBIEBmoj255Of/CSOHDky7NPo8f3vfx9/+Zd/OezTIKIbaNi5iUgQBAZoolFx+vRpPPLII7jrrrtw33334ZFHHsGTTz6Jq1evDvvUiIhummHnJiJBEBigiUbBD3/4Q9x///0YGxvD+vo6rl69Cp/Ph89//vPY3Nwc9ukREd00w85NRIIgMEAT3eparRbuuusujI+PX/d28/PzePDBB3HPPffgPe95D7773e92f2YwGPDud7+75/a/+qu/Co1GAwBwuVz4zd/8Tdxzzz24//778bWvfQ0AsLGxgS984Qt429vehje/+c146KGHUKlUAACf+MQn8PzzzwMAJEnC7/3e7+Ftb3sb3v72t+Pzn/88ms1mz2M9/vjj+NCHPoQ3velN+JM/+RNsbGwM/D0OHz6M3/md38HXv/51vOUtb8Gv/dqvYXFxsfvzcrmMP/qjP8Jb3/pWvO9978Nzzz3X/dl3v/tdfOELX3jFc2+1WvjSl76Ed7zjHXjXu96Ff/u3f8Ply5ev+/wS0a1h2LmJSBAEBmiiW51CocDrXvc6/OxnP7vu7QwGA0KhEK5cuYJgMIj7778fU1NT3Z9dL0D/1m/9Fo4dOwYAOH/+PBwOBwDgmWeewR/+4R/i4sWLuHz5MkRRRLvdBtAboNPpNNRqNTY3N7G6uopHH30UX/3qV3se6+GHH0a5XEa9Xsdv/MZv4Omnnx74exw+fBi/8Au/gOeeew6XL1/GU089hXe+853dVpXf/d3fxZe//GVsbGzA7/fj3nvvhVarBdAboK937n/8x3+Mv/mbv8GFCxdQrVbx8MMP45lnntnLy0FEQzbs3EQkCAIDNNGt7vjx4/jlX/7lnv/vYx/7GN785jfjDW94A0wm08C/99WvfhX//M//DOCVA/Sjjz6K73znO6jVaj23OXToED72sY8hGAz23f/2AL3T1NQUHnzwwZ7HOn78ePfP3/jGN/C3f/u3A//u4cOH8b73va/754sXL0IQBKysrGBpaQk///M/j/X19e7P//Vf/xVf/OIXAfQG6N3OvVKp4Bd/8Rdx6dKl7v936tQpPPbYYwPPh4huLcPOTUSCIDBAE93qFhcXd61Av/vd74bBYAAAOJ1OPPbYY7j33nvxpje9Ca9//evxZ3/2ZwBeOUCnUil87nOfw9vf/nY89NBDmJubAwC8/PLL+N73vof3v//9eOc734lvfOMbePnllwH0BuhqtYo//dM/xbve9S7cc889uPvuu/Ge97xn4GMBvUF3p04Lx3aCICCdTsPpdOLee+/t+dnTTz+N3//93++7393O3eVy4ed+7ufw5je/uXvcc889+MAHPrDbS0BEt5Bh5yYiQRAYoIludc1mc9ce6O0B+r3vfS9+/OMfd3uLv/rVr3bDpNvtxlvf+tbu37t8+TLuuuuunlALAFeuXMHY2Bhe//rX48KFCz0/y+VyeP/7348XXngBQG+A/tKXvoTPfe5zWFtbAyBXoLcH9oMK0IMq0N/61rcGVqB3O/fl5WW84Q1veMWWGCK6NQ07NxEJgsAATTQKfvCDH3SncJw/fx5XrlyB3+/HW97ylm6Avu+++7pzmV0uF+67775umGy1WnjjG9+I+fn5bmX2da97XTfUHj9+HKurqwAAjUaD17/+9djY2IBer0coFMLly5dRr9fx4Q9/GIcPHwbQG6A/+9nP4q/+6q9w+fJllEol/PZv//YNCdAA8PGPfxxf+cpXsLGx0e31VqvVffd7vXP/9Kc/jX/6p39Cu93GlStXIEkSjEbjq39hiOimG3ZuIhIEgQGaaFScOHECDz/8MN74xjfi3nvvxSOPPIJnn30WL730EgBgbGwMv/Irv4Jf+qVfwqc+9Sl85Stf6Qmphw8fxjve8Q7cd999ePzxx3tC7Re+8AXcd999uPvuu/GBD3ygu/jw1KlT+PVf/3XcdddduP/++/GP//iP3crt9gAdiUTw0Y9+FHfffTceeOAB/PCHP7xhAbpYLOJTn/oU3vrWt+K9731vz2LE7fd7vXNvtVr4u7/7O7z73e/Gm970Jjz44IM4ffr0q31JiGgIhp2biARBYIAmIiKi0THs3EQkCAIDNBEREY2OYecmIkEQGKCJiIhodAw7NxEJgsAATURERKNj2LmJSBAEBmgiIiIaHcPOTUSCIDBAExHRjXX16lVcvXoVV65cwZUrV3D58mVcvnwZP/vZz/Dyyy/j5ZdfxksvvYSXXnoJGxsb2NjYwKVLl3Dx4kVcuHAB58+fx/r6OtrtNi5cuNDd1p3uTMPOTUSCIDBAExGR7CCDbrvdRqvVgiRJqFaraDabezoajUbPn1utVs+xvr6OK1euDPupoiEadm4iEgSBAZqIaNQcVNDthN1Wq7XngLvXoNsJ0Xa7HcvLy93He63HhQsXcPny5WG/BDREw85NRIIgMEATEd0o1wu6nbC7l6Bbq9VQLpdvaNDtHAcVdDuH1WpFtVo90AD98ssvD/ulpSEadm4iEgSBAZqI6KCC7o2q6GYyGfj9/hsadG/UYTabsba2dqABenNzc9hvGRqiYecmIkEQGKCJaHS8mqC7ubnZE3TPnz+PSqVy01oXDjLoZjIZBIPBoYfh/RxGoxGNRuPA7u/SpUu4dOkSFxLewYadm4gEQWCAJqKD91qC7oULF3DhwoW+oPtqw+7OoNtoNKDX629a68JBHpIkIRQKDf089nN0nvODur/Oe4ULCe9cw85NRIIgMEAT3cn2EnQ7YbcTdNvt9g0NujeqottqtWAwGIYeKPdzpFIpRCKRoZ/Hfg6dTnegFyidCjQXEt65hp2biARBYIAmGgWdoNsJu3sJuhsbGzck6Gq12oFh91av6DabzZEN0MlkEtFodOjnsZ9Dq9Ve9+ftdhvNZhNra2uoVqtYXl5GsVhELpdDJpNBMplELBZDJBJBIBBAqVTCpUuXuJDwDjbs3EQkCAIDNNFBupWC7m5V3dcadHU63dBD2X6OZrMJo9E49PPYzxGPxxGLxYZ6DrsF3Xw+j0wmg1QqhXg8jkgkgmAwCJ/PB4/Hg/n5edhsNpjNZhgMBmi1Wuh0Omi12u7/NhgMMJvNsNlscDqd8Hg88Pl8CAaDiEQiiMfjSKVSSCaTsNls2NjY4ELCO9iwcxORIAgM0HRnOoigu33TiFcbdE0mE2q12g0NujfqGNUA3Wg0RjZAx2IxJBKJPd12v0HX6XT2BN2dIffVBN1MJoN8Po9isQi1Wo1qtYq1tTU0m83X9F5ut9vQ6XTdPmguJLwzDTs3EQmCwABNt7ZhB90bVdE1mUyo1+tDD2b7OUY5QJtMpqGfR+fovB/r9Tqq1SpWVlZQKpWQz+eRzWZ7gq7FYoHFYnnFoNs59hN0l5eXDyzo3sj3i9VqRavV4kLCO9iwcxORIAgM0HQwhhF0nU5n98P+ZrQuHORx0LNxb+YxqgG6Xq/vO0B3gu7q6mo36BYKBWSzWaTTaSQSCUSjUYRCIfj9foiiCJfLBbvdDovFAqPR2A262wOvXq+HyWSC1WqFw+GA2+2G1+tFIBBAOBxGLBZDMpmEw+GAz+frBt1KpXLgQXdU3i+hUAhLS0twu91otVrD/k8fDcGwcxORIAgM0Heagw66+5mle1BBd5SruBaLBbVabejncSsEooM8rhd04/E4NBrNnoLuzvaFvQZdSZKQy+WwtLSEcrmMSqWCWq2GRqPxmoJuKBSCJElDf37383ro9foDvc98Po9wOAy73Y52uz3s/6TSEAw7NxEJgsAAfTuyWq1YXFzcU9D1er1DW4z2Wo9RDqFWqxWrq6tDP4/9HAcRoFutFhqNBmq1GlZWVlAul7tBV5KkV1XR3V7VvV7QDQQC0Gg0NzTo3qgjEAggk8kM/Txe7XEj+s6bzSZsNhssFgvW19eH/Z9bGoJh5yYiQRAYoG9Hx48fx/e+9709Bd2DntF6Mw+bzYZqtTr087idz73dbneDbqVSQblchkqlQi6XgyRJ3RFj4XAYgUAAXq8XbrcbDocDVqsVJpMJer1+4OQFo9EIi8UCu90Ol8sFURTh9/sRCoUQjUaRSCQgSRKy2SwKhUJf0H21m3PUarVu6Bq1w+/3I5fLDf08Xu2xtrYGs9l8YPd3/vx5bGxsdN8/58+f50LCO9CwcxORIAgM0LeyjY0NPPzww/jwhz+MD3zgA/jOd76zp783NTWFf/mXf9nTB5Jer0ez2Rz6B+1+DofDgZWVlaGfx34Ou93es630az0GBd2lpaV9Bd3tx6Cgu7Cw0Bd00+l0N+iWSiWsrKxgdXUV9Xr9QHehey1HrVaD1Wod+nns5/D5fMjn80M/j1d7rK6uHuhzfv78eWxubsJqtUKr1eLixYtcSHgHGnZuIhIEgQH6Vnb16lWcP38eAPDyyy/jkUcegcPheMW/p1ar8Q//8A97+kAa5T5il8uFcrk89PN4NUdnxJjVakU2m0W5XO5uGrHfoNvp2d1LRfcggu6t3AN9veOgw9zNPERRRKFQGPp5vNpjZWUFdrv9wO6vE6BDoRBUKhV3JLxDDTs3EQmCwAA9Ki5evIiPfOQjcDqdr3hbu92Ov/iLv9jTB9Io9+J6PB4Ui8Ubct+vdZauyWTqbhqxvX2hM0tXoVDAZDL1jRiLRqPdEWPZbBb5fL4bdKvVajfoDrPtZlTbflZXV2Gz2YZ+Hvs5buR7/UYe5XIZLpfrwO6vE6Dz+TwUCgV3JLxDDTs3EQmCwAB9q7t8+TIeeOAB3H333fjmN7+5p78TCoXw2c9+dk8fSKPcBuH1epHP5w9s04j97o62n1m6brcbpVJp6M/hfo5RDdDVanVkA/Sovl+KxSI8Hs+B3d+FCxewubmJZrOJ+fl57kh4hxp2biISBIEBelQ0m0089thjCIfDr3jbXC6HT33qU7fUB3OnotvZNGJ5ebm7acR+d0dbXFyESqW6pTaN2OsxqhXF9XU5QN8qfc2v5qhWqwfaTnAzD6fTieXl5aGfx6s9CoUCvF7vgd1fJ0BvbGxgdnaWOxLeoYadm4gEQWCAHiXf+9738Pjjj7/i7VZXV/HYY4/t6QPJ6/X29Va+1k0jBm0DPGjEmMfj6Y4Yi0Qi3Vm6ew26wWBwJEd7ra/LPa1LS0tDP4/9HHq9fiQDdKVSGdkAParfFOVyOfj9/gO7v+0Bem5ujjsS3qGGnZuIBEFggL6Vra6uotlsAgAuXbqEj3/845ibm+u5zdWrV7G0tIR4PA6PxwODwYDJyUk89NBD+M///E9861vfwvz8/K6zdBcXF6FUKve1O9qwZ+mGw2Gk0+mhh4T9HIMuXEblGOUA7XA4hn4e+zkOemrLzTokSUIwGDyw++sE6IsXL0KpVGJpaYkLCe9Aw85NRIIgMEDfyoLBIB588EF86EMfwgc/+EH8+7//e99trl69ik9/+tP4/Oc/j7/+67/G1772NXz729/GBz/4QXz729/Gf/3Xf8FisewadIPB4EjucLa+vo5oNIpkMjn089jP4fP5RnKu7/r66AbolZWVkQ3Qo7rYN5VKIRKJHNj9Xbx4EZubm1hfX4dWq0UkEuFCwjvQsHMTkSAIDNC3o6tXr+LBBx/c0wfSKIfQeDyOeDw+9PPYzxEIBJDNZod+Hvs5DAbDSM4OX1lZgdPpHPp57OcY1V03E4kEYrHYgd1fJ0A3m01YLBbYbDYuJLwDDTs3EQmCwAB9O+oE6L20URz0B9zNPJLJJKLR6NDPYz/HKPdvj2qAXl5eHtkAParz2mOxGBKJxNYi4tc+frEToNfW1uB0OqHT6biQ8A407NxEJAgCA/Tt6oEHHtjTh1U6nUY4HB76B+1+jlE+91AoNLKtM6MaoA96JvHNPIxGIxqNxk19zFarhXqtjkZ998etrzVQzJWxJBVRq671/TwSiSASiiIVlJDwppAOSaiv7f/36AToarUKURRhsVjQbre5kPAOM+zcRCQIAgP07eojH/nInj5ws9ksAoHA0APCfo5MJnOgC5Ru5jHKCyANBsNND3MHcYxygN7rRUu73UatUkOtUkOzObhPvdloYkkqQopkUcyVB/azN+oNpMMZxL1JxMUkirn+HT8b9QaS/hSS/hRSQQkxTwK1Sm+bid/nh0PnghTJIp8sIB3OIB2S9l2JvnTpEjY3N7GystLdZZMLCe88w85NRIIgMEDfrh599NE9zRnO5/MHOqf1Zh4HPSLrZh6RSASpVGro57GfYxjV0IM4SqUS3G73TX/cVqt13UWX7XYbqys1rBQrA6u46+vr0Gq0WJKKSPjTSIekgbdrtVrIxnKIeZOIe5NIh6S+6nG73YYUySHhSyETzSLuSyGf6p8Gk0sUkApKyCcLyCXyiHuTfY9ZLiwj4U0inyx0w3Eu0XtfHpcHDp27e5t8soC4mESzsb9vMDoBulQqIRQKIZ/PcyHhHWjYuYlIEAQG6NvVJz/5SSQSiVf8QDroncJu5nHQmzTczGOUF2+OcoDe63u92WiiXqtfN/hWylUsSUWUC8sDq73tdhvFXBlxbwpxbwpLUnFg5XVJKiImJpDwpRATk1he6p/3PDs+h5g3iVwiDymSRdyb6gvHK8UKYtsCbdKfQiHdO2u8Xqsjvu02+WQBCW+q7/xTQQnZeO5a6PWlUC1Xe25TLiwj4UtdN0C7XR64DB5kY/J9ZaJZJAPp11yBLhQKiEajaDQasNvtXEh4hxl2biISBIEB+nb1mc98Zk/hcpQXVo1y+I/FYiM7QcRoNN6SC9oa9QZqlRrqtcHnViwWYTPbkI3lkYvn+9oNOsfy0griYgpxbxKpoDTw/sqFZcTEBNIhCXFfClIk1xe2K+UqYqIcevPJAmJiEuVC726C9bVGT6DNxnOIe1N9AXPs2GRPoI15k6gu9461K+WXkfRfC7RSOINsLN//eOK1x5Ory6m+cy+kl5Dwp6+dk5jE2mrv87CXFg6Px4NUPI24N4WET77tblX2vRydAJ3NZhGPx7GxscGFhHegYecmIkEQGKBvV1/84hdhMple8QOpWq3CZrMNPfzs5xjlntZRnn6y14kQe5m80Kg3sFKsoFqu7lrtrVXXkI5kkfCnsZQpDbxddXkVia2QFh8QVNfX1yGlMlgcU0EKZ5AOZxDzJPpCYSdgdsJqeuu2fa+fP90XaHeGx2K21G2D2K1Cu7Za76ni5pOFgYF24uQUpHDm2uOJ/Y9Xq64h5kkgG8shl8gjJiYGVrOXpCJink7FOzHwuWo25XaQxFb1vFIavIlLfa2BYraEbDyPlWKl77V2Op0ol8to1BtYyhSRTy2hUuq/3V6PTqU5nU4jlUphc3OTCwnvQMPOTUSCIDBA367+/u//HgsLC6/4gbS2tgaz2Tz0ULafY5Q3xrhVR/C1Wi3U1xrX7VHV6/TIpwsoZkt9AbRz1Gt1uTrbmbwwoIpbr8nhMeFNIuZNQork+loJGvUG4t6UXE3dqs7uXNDWbreR8KeRiWavVVXFZN+0h5AYgXpG0w2hqaCEYrbUc5tapdbX4jCoIrwzQMd9qb5Au1KsIO5N9dymlO8Nq61WC+lIFkm/3JMc8yYH9iSrFCr54sAnV8bzqcLAEFopVZAMSEj40yjllwfeptNznU8VUMqWd52y0W63UcyXIUWyKKSXBk7PaLfbWMqUEBflvutsrPc17OygmE/JoT8VlBATE1iSXnl9xqCjE6ATiQQymQw2NzcRDAZRLBa5kPAOMuzcRCQIAgP07eqb3/wmxsbGXvEDqdlswmAwDD247ecY5er5Qe7Q1mq1UKuuoVZd27Wy12w0sZQpIRvLo1wYHKw6kxfkKm5qcGWy0cTUyRmE3TEkA2nExf7FZa1WC6mg1K2YpsMZpIJSX1U1lyggHZJ6qrg7K53V5VV5odu2FodUsHf8X7PZ6gmqcljtbzmI+KJQT18L0IkBgbZRbyDhTXV7dlNBCdlY/46RcguHvFAv4UshHcn2/X7tdnsrgA8Ol9uf00J6CelwBoVMcWCFXafToVFvoJxfxlKmhOry6q6vdaVcRTokIRWUBlagO+cfF5NbFzCpvnaQ7b+jFMkiFZSQDKT7LqxWShX4rWEkgxJyiTwSvhSWMtcuSqxWK5ZyRThVHvjNoe7FyX4XEnZaOKLRKPL5PDY3N7mQ8A407NxEJAgCA/Tt6j/+4z9w5MiRV/xAarfb0Ol0Ny04HuRRq9VgsViGfh6Djlbr+q0LyWQSosuLarm6awWw2WwhnyogGZCQSxQG3q7ZlCuYsW0hbWcA217llMIZxMQklnZUXtfX15GN5XonL4jJvsrx8tIKpk7OIBWRdm1L2NnX2wmRO88/E811x5t1Au3OwFer1BDb1rMrhTOQIv2BNhvLdft/pXBGDns7wmomnYFqSoOEN4mEN4lkID3wOa0ur3aDZTqS3fX1qZSryCbyyKeWsLbLbON2u41KqYJcIo9ibvdqb61SQ8Iv9wpnY7m+cKnT6VBdXpVbL7xJxMTEwCp0rVJD1JOAFMnIEznEBCo7Fv/V1+oIWMKIiwmkI1m5VcPfu7Cv2WzBo/PBqRThN4cgbb3HtgftZqOJgCUE07QNTqUHAXMI6XAGmei118egNyDoCMMy44Co88OhcCMuJvYdoDsV6HA4jGKxiM3NTS4kvAMNOzcRCYLAAH27+tGPfoQnn3xyTx9Koxqg6/X6nvq893o06tdvXWi1WlgpVlDMlbG6MngBWrPZQi4hV9gS/vTAyl6r1YLLJEIzq0fcJ/ft7gyq7XZbDja+VLfqOqjKWcyVu4u9OlXclWJvFbdWXeuZztCpFPa1JfhS3QVvnZaDnb9nubDcH6Dj+b7nIOG7VsXt/B59i+xKFUQ9CWSiWUjhDBLewc9D5+v/znM1qG2k2Wgilygg4U0iHckObBkpFArwuDwo55dRSC9hdaX/tek+Z6tryMZzyMbzfQG0c6yt1uUqvFeu5A66v7XVOhJeefFcwpcaGNob9QaingSSgTRyiTyS/lTfRYlOp0PQHkHAFkFcTHR7nLc/F+12GxFPHJYZB5wqERF3HOlwBvnUUs9tUkEJhgkLnCoRTqWIZFBCXOydxJGN5WCbd8Gj88Kl9sKj9yPijve8HwrpJYTsEdgXXfCbgnAoPPBbwj0tNqpFNcKuKPzmEJxKD1wqDyxzzoFtKns5OiE5EAhgeXkZm5ubXEh4Bxp2biISBIEB+nb17LPP4gc/+MGePpS0Wu2BhdCbeTQaDWhUGqyt7j5urNVqoVxYRi5RQCm/PPB2rVar+7VyXEwOHDfWbreRjcsTC5KB9K6Lrwrppe6isGwsN7CKWy1XYVM7YNZY5RAakvpDaKPZMy2hU6HdeV+5rRB7vb7etdV636SHhL9/E5dcooBkoHfyws7Ha9QbmDo5g4gnJvc4i8mBFxPV5VV5fJsvifguLQLr63JFOx3JQopkd53O0G63US1XUUgvYXmXkXGdc8vG80gFJSxJxb7b5fN5uF0euQ/Xm5Qr8QNe6850iU4bSkxM9LWWtNttxL3y2Ll0JItMNIuEb/A4OLfGh4AljFRIbo/Z+b7JJfIwTspVXI/eDymSRcKb7Dmvucl5+TYqEQ6FBwFLCDGxd+pFubAMj94Ph9IDnykAh8KNkD3a01JRq9QQccXgVnsh6vwQdX7YFt09bSqd917Cl4Rj0QOXSqWYcBQAACAASURBVIRx0tp3EdT5BiHijMGp9MA8ZUPEFeu5jWJeiagnjmw8h4g7BrfWB58puO+dLDc3N7G5uQmv14tqtdr9MxcS3lmGnZuIBEFggL5dnTp1Ct/97nf39KF0kAH6lVbXd3ZKqy6v7rqlb6vVQjFX7gbLQdXEdruNXLKAc0fGEffJIWZQ9TifkiupUjiDuC+FbDzfd47lwnJPn+2gwDQwhA6q4g5YXLYzPK4UK3DoXDCqzd3ZuFIk2/ccxL2p7n11WioGzv7dqkhm4/JX9jsfr91uy1XxrUpoTOyvUneCkxTJdadZ7DZ5wag3Ih2VIEVzfbOBe56zWh0FqYiCVNx1sWGz0ZQvNLYWG+5WXe6Mi4ttbRCy87VutVpIh+Q+3c5rs7OKm8vloJs3IOyIIulPIxvPD5xmUcqV5eqr1oeQMwYpkul7fSqlCkyTdrmKq/Ag6kkg7u294KhVanAqPXAoPPBo5XaIiCve03ddr9URskdhW3DCbwrK1V6dH+ltj9dqtXDuyAQCVrmK6zMEYJl1IOqO9wT2XDyPVCANUe+HU+GBadoOnznU81xVl1fl5zCcgUfnh33RBadK7LnN9vdeOiQhZA/DqfRgpdTbXtPpkc4l8kj4k7AtuJAKSj3vP7VKjXRE3rAl4ozCNGlDyBbZ9zi7TgXa7XajVqt1AzQXEt5Zhp2biARBYIC+Xc3MzODrX//6nj6UXilAt9ttVMpVlPLLu7YudFbjJ3wpJPzpgeGr7+t47+AP0aVMqdsL2glFOwNTdXkVMTGJ6bOzu24aMaiKG/f2T2fIJQo9I8IGTmeoriHu65+fuzNAd865c5uYmOj7Heu1OpwGD7TzerlP1TN43NhKsSJXxbc22Ni54K3znBZzZfl5H1Dd3B6KVooryCULWN5lEeH6+joajSYKUhGZeB7LSysDb2cympAIJLsjzgY9ZqvVghTJIb41+zcu9s8tXl9fl3fDE5PIxOQNQpL+/ipuIVOC3xRE2BXvVnF3TuKolKuwzrngVIpyAA1nEN+xQUg6mca55yZhW3TDqRQh6gOIehI9FwGNegMBSxjWWQd8xgAcCg98llBPX2+73Ubcl4JT4YGo88NnCsA270LEsyPQJguIuuNygNb4YJ1zwKMP9ITsziLJiDMGh8IDh9IN84yj5zbNZhPnjowjG88h7IjCo/PBtuDqu3jp/PuTvz1IwKXxIRfvXbjYqDfkRY9bCzttiy74zKG+8YCd917YFYN5xgG3zi9/O7Pt30Xn33zEFYd5xoGgNSyPBxST3bYXnU6HZrOFUr4Ml9qLkCOKTCwvb6ji72/r2WuAdjgcaDQa3QDNhYR3lmHnJiJBEBigb1c6nQ5f/vKX9/ShpNfrr/tBVkgvISYmtqqXg1sXSvllxL1yD22ndWFnNbFWXeup4kqRLNIhqe++dvbiJgaMCCsX5E0jOgFaimR7Qo4cPFqIizv6egdUcfdSge4sxEv4092v9XeGuPV1eQFdMpDuLuobtFhPDnMStAt6pELSrlMxOs/ZUqaEYra8a392q9XCklSUg3uqMPB2nW2e49dZbNjpu45vBaxOi8PO+1qYUsBvCSAVyiATy8lV3B0XCSulCjx6P/zmECJuOfimd1Rx6/UGHAoPnEoRToWIkDPWNz2j1WrBZwzBMuuASy1XeyPOWM95dcbYWWYc8JuC8mI1pYi42NsG4XMGMHNsHk6liIA5BPuiG15jf6CNehLw6PzyeSndME7aet5/zWZLXmAYzsCt8cKpFGGasqOc770IyqeWuheAAUsIDoUH2Xjve7Req3fnTqcCaXh0XoTskb7nYG5iHjExiaQ/BfuiG/ZFN1I7xgM2G02kI1lE3DFYZh1wLMqV8Z0V+7XVOtLhDByLLojG4K5beq+tyosNvcZAd8rGoAvCdDgD66wDot6PZED+99H5t9hZX5FNFGCctMKp8sCt8cn/lnypXb+F2u3oBGar1Yp2u939c2chYbvdRi6XG/Z/fukGG3ZuIhIEgQH6duVyufDnf/7ne/pQut7OcjsnKnRaCXaGL2mrD3R76N3ZJrC6UusJqvJXv/29uKmg1HNfgz60O9MZpk7PdGf1DqrQLmVLcvjfWuw1KBDupQe6E5yKuTIy0RxKufJ1q7jFbAmF9NKuX1Pn83kYVCZ50VtIGrgrXqf1IuZNdiu5g9pZcgm5VSQbyyEZSA9cbFguLCNoj3arj/EB1eq11TWIej88Oj/8piBSW3Oct99Xu93GmefGYJyydnt2o+44KqXeamjCn4Jx0ioHUZUInyHQd7FUkIqwzDjg1QfgNwdhW3AhaA33hKrq8iqCtggcCje8+gBcGi8sc86+aRBxMYmwPQqHwi23L0za+r5FEG0+6OYMCFjCcKo8sMzY+0J9rVJDbOsCI+yKQtT5EXRE+15rKSIv7JSiGXgNfjhVbhTzve8Jue0nhbiYgEPhhnnajog71ve8Ly+tIOpJwDbvhHXOiag70bOrX7PZhF6vR7mwDNEgPwfpiLzwcmfFvjNC0KXyygs0Y/mB4/qK2TLM0/Jiw6At0u3v3/5aV0oVmKfssCvkNpSIO97XklQpVSDqfbDNOyHq5NYR+fnLdwN0pVSB1xiEZdYBj84Hj9YHUeffVwW6E5hNJhMuXLjQ/XNnIeHq6ipcLhcXEt7mhp2biARBYIC+XUWjUXzmM5/Z04eSxWLB6urgRV71Wr1/JJnY/zV7LnltAVpnp7SdX9k3G81ugOtsirF9gdP20BQXk9cd19UJHueOTsj3s0vobbfbWClVkEsWUMoO3sWuEzyWMkXkEru3LrRa8li5TuvCbi0VuUShWy2Mi/2zjdfX1xHxxzB/TgEpkoUU2ZpAsaMaV11eRcAWloOLmEAqmB448UI0BOBUe7uTF3b24q6vryPilr9md6pEOBbdCNkjfRcT+VQBhnELvAY5RDuUHkRc0Z7nrLq8ihNPnoFlzo6AOQSnygOnytNzAdCoNxB1xeFWe7uL1QxjFixlex9PimQRFxNwKj1wKuXQmwym+56DzuYhHp2v2waw83XpTP1I+FMIWEMQdX6srfZevEQCUaindZAiGfjNIVjnnH29853XL+KOwaFwwzhhQ9AWRTae73ke5JnZWdgXXLDO2BHd2khk5/u5Xqsj4o7DoRK3pmvkB1bsi7kSHItu+M0hJHwp+duZrXBfr9dhNBqxulKTJ2woRbjUXqRCmb6K/dpqHW61F9Z5J5wqER6tT97BcdtrXa/VEbCGYZl1IGAOwaH0wG8N9/T0NxoN+M1BWOadsMzY4TcHYZ93IeyKdd9bzUYTot4P84wDymM6WGadsMw6IBr83d9PrVIjZI/CMGmFZcYBxQkdrPMuWOecr7oH+vz5893AbDAYuu0c2xcSFotFiKLIhYS3uWHnJiJBEBigb1eFQgGf/OQn9/TBZLfbsbIyeMOFdrstLyzzp+XAM+Cr3k6gSAW3FnqJCeSTg0Pv2modmahcvdttW2b5dmsoSkUUM2U0rtO6MDs+h3QkI09dGHC7Tt91t3VhRxDqvY28kG231oVSfrnbjiBFsoh6En094WurdQRtEfmwR5EMSgOr7FaVE2eeHpf7aPUBRN3xvguObCwL44QVLrU8eUHUB/q2lV4pVWCYsEA0+OE3y6PEfMZgTxivrzXgMwblgGYKwmvwwzhh7fuGIBlIw7u1AM2j8cI4aYUU7q3QlgvLmDwxA4dS7je2zTsRsIR6Q/1WRVgKZxCwhuE1BiHqA32vT6dnV4pkEHJE4dKIKGXLffeVDKQR9yXhMwZgnLQiYA33Vew7F11OlQjjhBWiIdBXsc9kMnBY5MWBcqU3jqS/fxOUdrsNKZqFW+NFxC1XcWPe/u3BV1dW4VC64dH7EbRHIUVzfX3XjXoDjq2WC6fCg6A9irg30fPcNxtNBO0RmKds8Gh9cCg8iLrj3Yr92toaTEYTou44TFM2uLU+eaGgSkTUE+95raPuOKyzDqhPGeHR+uQ2FUOg+95qt9tIBiWYJqzQnDJCdUIP27wT5ml790JP/jefhXHCBofCA8UxHfTjFlim7Sjlrl0gZGM5uNTye8Wl8UI/boV9wYlMNId2u412u43Z8Tn5AmJRXvxoW3TDNGVF0B5BuTB4Ks5eArRer+8Jz52FhNFoFH6/nwsJb3PDzk1EgiAwQN+u6vU6Hn300T19MLlcLpTL/f283Q/4ZgtLmRKkSBbFXHnXD71u64JU7Kv+bQ+9S5kSEn651WDQ1IVrUyPk0JsMpAf2SuZTBZw9Mt5dfDaodWGlWEHEGUPSn5bn3Xr7F+M16g2E7FG5f1bv33Wjh5goTxrozM8N2iJ991XOlWEct8KjlaulTpUchrZfTNTXGtCcM+DccxMImENwqb1wKHqruO12G2FXHPZFF7x6P3zGIAxjFuSSvRcvxWwJfktIbl1QemCecSBk763QdiaIhB3RbsXYo/H3XZikI1mkgvKIPr85CI/O1zcDuVZdw9TJWUS8UYQdUTiUbiSDUt/F0pJURNQTh6j3wzRpg0st9vWMN5stZKJZOFUeGMatcOt8Ayv29bUGIq6YvFDPFdsa89ZfsS8XluHSeBGwRZAMSn3jASVJgs8XkHuplfJkjM57YmfPsd8cgnnGDqdShFvj29o+u3eectyXhnHSutXCIcJnCva1QUiRLKyzDlhmHXIVd9GNoKX3AqAgFWGecUBxTAfTlPxcWWad3cBeq9WgnFfBNGmDecaO+RdUMM/YYZyworDtQq9cWIZlTq48m6asUB7TwTTlQGbbiLpKqYKANdSd3WyedsAy50DEEe2uDVhbrSPqicNrDMKlFOHR+6A+oYdL5UEmnkd9rdGd1JEOZ+De+vewcFgDw7h1ayOXHOprdUyfnd1a0JmESyVCcVgLzVlTd9OYXGLwhfZ+AnQ+n4fL5UIoFOJCwtvcsHMTkSAIDNC3q5deegkf/ehH9/TBJIoilpaWdv15p3Uhfp3xZttbFxJeuZd4UF/vklRETExAiua62yAPmrARdkQR8yTkMOtL9wXHVquFsCOGY0+clHdBs4QQ9ST6Ank2lodlVv7a26GQq3E776u6vArThA0enR+iXt4tzW8M9o328mi9sC+6EDCH5GrohLVvekYmmoND4YZb7YVX74dpwoq4L9lzm9WVGtx6L848Mwan0gO7wg23WuwJEp05wwl/Cm6tDy6VCLfWh9UBiynjPnlmcdAWhmgIIL9jGkmnLzYVTCPkiMC24ELAEup73mvVNcTFJNxqEYZxK+wLLkiRTF+7jlapg3neAcO4FR6dDxF3vO9bCbmKmYFd4UbQFoYUzfZMZ7j2mDW4tD74zUFE3HFIW/OUdz4XoiEA+4I8PSPoiCLuTfZMoWi320j4kjBubRDiUHgQdcV6+q4lSYJFZ4Nh3AL31mstj5aL9VSqS/ll2Bdc0J0zw631yfen8vRUjavLq7DOOaE6rofiqA52pXwRsD1k12t12OacMM86sHhUA9VJPYwTFkjbvkWo1+rwm0KwzTnhUotQnTDANGVB0B7pPgfL5WVMnZiFUyn3gbs1ItRnTPDo/D3PZyooIeqJw7HohqjzQ3PKCN1Zc8/zXsyWkAykEbSG4VC6oTqpw/whFcLOOOJeebFuZ+OdTDSLgCUM/bgFM88okNiajd2ZipMMSFstSFn4TAHMH1Ih5Ix1N4PJxLNQLaoQExNbuyLGMf3sIhyLbkTc8a1JNv1TcQYdnYr29QJ0o9GAXq9HNBrljoS3uWHnJiJBEBigb1dXr17FAw88sKcA7ff7kcv1b4/cDb0ZeSFeOpKVq0mDJmxUaog4Ywi74gg5ot15vTvvK+KMdScXuDU+hOzRvjaIpWxpq/rnkau9KhHJQG8bRKPegHnKhuNPnIK4VQF0Kj19vb8hZwzWWXk6Q8AcGljFLeXLcG3N8/VofLDMOeE3h/oeL+qWq3Kd2b4utYi1nRubJOQFlAFrWF6Qp/ehlO+tvNZrdXgtAcyPLyLsiMJnDCDuS/U/79kSop6EPFZtzgGn0oPqjt3u5HFxWTjVIvQTFljmXYgN2NGvvtZA0BaGacoGUe+XNwAJZ/oq9qVcGS61KLefbF3g7Kwcm00W2FUuiFtTNjrviZ3TTYKOKKyzju5iw5iY7FvYl03kYZiQK/byBiDBvkWqy0srME3ZYVuQp2Y4FG74jIGe902tugan0gP1SQPMsw549D6YJm09U1CSiSRmjs1Dd86MueeV0I9bYJiwIrXtfdpstuC3hGGatkF3zoT551UwTFoRsl0LtK1WCwlvEpZZO7yGAExTdmjOGODW+lDf9hzk4nl4jQF5O2xTELpzZpgmbShIxe7vVy4sI+qOw63xwqUUoRszY/Y5JQJWuUe91WqhWChi9syCvCmLSoR+zIKJ/5uDzxjsmQaTCkrdSSt2hRvTzy4gaIsgs3XxUqvUUClVEPfKs5sj7hjmX1TDqRK7m8EkA9K1iTNbC1fnD6mgPm2Ezxjo2dK7Vl1DwpdCxBWH5pQBymNaOJQeeA1+xANJBJwhGAwGpOMSnHoP5o+rMPb0NBbPajB9ZB6qSS1UUxo4HS64XC7Y7XZYLBYYjUbodLqeQ6vVYnFxsTv7eVCA3tjYgFKpRCKR4I6Et7lh5yYiQRAYoG9XV69exYMPPrinr0eDwSAkqT/sdo7O16+d1gXREOjrn10pVuTQq5KDsX3BhbAj0ldFcmxt3BAwywu9TFO2vlAoRTIwT9vhMwTgNwVhGrciGegNmLXqGkRjAEd/chK2BZfcwqAS+37fuC+FkD0ih3GFBy6Nd+DGJlExgYg7Bp8pCJ8piOyOxXo9VVxnFKLeh6A90hdAa9U1xDwJeA0BmKdssEzb+xbPra+vI5PM4vTT52DcWlwVcsT6qrPtdhvJQAqWOSe8Bv/WJJFBiw2rEHUBBCwhxL1JpILpnp3lOvflt4Th1njh1shV45i3fzFbMpiGecrW3SAk4op1Jyp0Do1CC+VJrXyBsFWhDTtjPQG6Vl2DfdEt9/Xq/HKbymJvFbfVkhdAKk/ooDllgEPlhWnSikw023PeIUcUhnELFl5UY/GIFsYJC4L23skYqZAE44QNtgU3Fo9ooTllhEsl9ux453X4MHFoFqLOD7dGhOaMAbY5J1a2faNSLVcRsEXgWHTDZwjANG3HwiENYuK1SmlnMk1n6odpwoqxn8zCpZWnY3Seh3Q4Aymcgd8UhHHCgsmfzsGlFrequ/IYwUqp0q32+oxBLLyognXB1Z0zXsovo1wqY35sEVI4g3RIguK4FtozJsQ8ie6OkY16Q74vMYmEPwX1SSPmXlDDqfBsLUCVZ5u32225vcYdh2HcjOlnF2GetcM0Y0PAHoTbKCKbzSKVTMFjEzF3Sonj/3MOk0dnMXF4FuMvTmPm9Dz0GgNMJhO0Gi1OHzqH5//7KJ77f1/E8SdP4fD/HMepZ89hcUoBhUIBp9MJzbweZ56awKn/O4dzT09i4ZQKM0cW4XP4USgUUC6XUalUUKvV0Gg0Bv53KxaLQZIkbGxsDAzQm5ubUKvV3QDNhYS3r2HnJiJBEBigb2cPPPDAngJ0NBpFMpnc9ec+g7xRRMAcgt8chHHcgvKO3t9SrgzzlB0ejQ8+QwDmWQeCtt4A3Ww0EbJFu1MXnEoP3BpvfxU3WUDIGYVbLcKl8kDU+/vmKXemg0ydmoFb70XQFh5cxZWKiIoJhOwReLQ+ePR+rNV6Q2Oz2UIqnIFTLcI0YYVxwgYpku177uq1OkS9H8ZxK6xzLgRtkYGzoPOpJThVcjU1EUwN3O2uXCzj7KEJ+M1BhJxRpEOZgYsNw84Y7Fuzkn2mYN/GH/LjFWCcsG5Vxt3wmYJ9FftadQ2mSSucKi+8Rr+82NAU6PkmoTNVQXfWBMeiCx6dH8ZJa99zP3VyDrMvKjD3ggr6CQtMk1ZE3Yme5ysTy0F/zgzlcR3mnlNCd84Ml8bbc8FRLixDP26BS+2B7pwZiiNa2BVu1KrbKsuVGjx6v7wYTh+AYcIC7Wkjssl8z3lH3XG4tT641V7Y5l2YfmoRbq2356LEYXBBvyAHa+OEBRM/nYNp0tZtXVhfl3uEE1u99+YZO2aeU0A3ZkYykEbSn0Kj3pDni2/t1BdxxaA+pYfujAmprc1JOhcvpby8U18mloXmtBGLhzXwbqvi1io1NJvyhjNRTwKGCSumnpyHbc4Jnykoz9mO5lAul2ExWRHzJmCaseHM/05CN26A6qwO5kUbrGo7IqEIotEoRJcXi2MqHP3xKZx88izGDk3i+E9P49yL45ifXuhWdKfPzeL5Hx7GM98/hGP/dxqnnxvH6afHoFnQwefzIRgMwmXzYOKFWcwcmseZn0xCeUaHxRMaBOwhVCoV1Ot1LC+twDbvgm3BBd05C9Qn9DBNWhF2xlAuleFwOLBSrMBr8MMy64TX6Id+3AzbghNeQwCNxt7nQJdKJfh8Ply6dAlGo3FggDaZTAgGg9yR8DY37NxEJAgCA/TtbK8BOh6PIxaL7R6wXVttF6rrV3HDjih8JnnxWWDH7m2dimPSL38tHNqaVBF2xvp6bKvLq4i44whYQt3e5Uq5f8xeIVPEiSfPQn1GD9OkDTFPou++5F7pKEwTVjgW3QjaIgMXLpXyyxB1fgS2xnnFxGRff3Oj3kDQFoF3q0qd8Kf6pi6sr8sVe9uCC06lRx675oz1LTbMpXJ48YfHthYaylX7QYsNLXMO2OZd3akLDoWnr+UlZI9AfcoI46QVLo0Pxklr33OfjeehPWPC3PNKKI5oYZy0wmcM9jzeSlHenlp31ozZ55VYPKqFQ+FGfe1ayK7X6jj5xBkYZ8ywzjuhPKaHYdKKleK156rZbHW3p/YaArDNOzB/WI2IO9bzeFIku7XBiBuWGQemnpiHfsyMpa1KqRxoq4h54nIVd9yCmWcXsXBEg4j72pbY3akfkSzcWh8WD2ugOqFD3Jfsmacs2r0wLJqQCqahO2OA6qQBYUcMmai8QU673e7u1JcKSjBOWjH7vAKWWQfiXrm3v1NBr5Tknfrs8y5M/GQOxkm5ap8IpOVe/LU1VCoVJMMpmOetOPmjMSycUGHxlAoLp5TQTOvgdnjg9XrhdLqgmFbhyI9P4IX/OowTT53Bkf85jqM/PYnpczNQq9VYWFiAWqHGsZ+exuH/PoajPz6JiSMzOPP0BAyLpu5FcDyagOK0BoqTakw8NQvFCS3UZw0IWEPdRaP1Wh1+cxjmabktRnFEC+OUHW6dr9sXX1+rI2iPwDTtgGgIwLaw9W2CxofqsnxR0mg0IRoCsMzJ/eI+UwCmKRtM03akQhIyqQzsNrt8mxk7lMd0MI5bYJywYfGoDgFLGEl/Cqsrg0do7jza7TaMRiPOnz8Pi8UyMEA7HA64XC7uSHibG3ZuIhIEgQH6dvbQQw9hbe2VZ62mUilEIpFdf55LFBAV4wg7ovBbQwjaIn09to16A3ExIW9ZPOuAddaJUq5/TvLqyiqcSg+MW5XeoC08cBFR3JeCdc4Jt9aHsCOKdEjqa5eolCoYe3ESTq2841rC1z9XutlsIeSIwWsIwKP1IeyK93wdfy3M5boTDJwKD/yWUN/W4NVyFcYJedSYZ2vTiKA13LMYr9lswaX2wjRtg0vthVvrh2na3hfGI54Ynv1/DkF9Qg/zjAOGCStiYu+3AMtLKzBMWDH/ggrzz6ugPmOEU+nZEbLrsMw4YJq2QnFEi9nnlbDM2Lshp3MR4TMFYZtzwq32wjBmgfK4HtlEb8hOhzOwL7rh0fjgXHRj/pAKTpXY05qxUqxg8tg0jDMWmCasmH1OgdlDaqS3LTaU3wvyDG/jpAWzzykx+7wSAVu45+IlF88jFZIXPyqP66A8pUPEHUNMvDYybm1V3qkvHZFgGLdAdUIHp1qUR8Zt67tekoqIe5Owzjkx/cwC1Kf0CNoiSAauzUCORWOwaOSxgBP/Nwf1GSMscw54TX74LAEU8gUUCgUk4ylYVFYc/+FZnHtmCvOnFBh/YRqzpxZg0Bphs9lgNpuhmFPg0I+O4Kn/eB5Hf3Icx544hRd/dBTTZ+dgNpths9lgt9kxdmgKJ35yFkd+cBIzx+Yx9cIcTIsWSGkJhUIBS4Ul2FVuaM4asHhUg4XDGpin7fDo/Gg2migWi3C7PYh7EzBO2eDReqE5bYJ+3AynsrcPP7H1HFjmXPK4wnELbAsuLGXkfmp5ekgSpml56odtwQ3rvAua0wYE7WGU8stoNptIBtMwjFthnLRg8YgW5hk7pp5cgGi4tqV3JpqVx+ppvNCeMUF90oCpZxbh0vqQDklwGUTMn1PAZwzCpfJCNMiLaudfVMO64O5u6R339i8kHnRcvHgRer2+u+vgoADt8XhgNBq7M6Lp9jTs3EQkCAID9O3sE5/4BPL5/Ct+MGUyGQSDwV1/Xl+ry0FwQq4u+Y3BgZsgSJEsXBq5RSDiiu46YSNgCyFgCcuLDcXkLhM2ot3tlH3GACLueN/CxXyygJNPnIFh0iRPvtB4e/pn5QC2BtOkDU61d2vChgduna8vQPst8pg4x6Ibbq0PxnFrX4AuZIpQnzJg/kUNNFsVX78l3HOb2upad+rC3AtKLBzRwDrv7GkbabVacCjdeOG/j0J3xoTFIxpoz5r6FhumghLM03aIOvmiRHlc17eJyEqxAvfWFtf2BRcWjmigOalHdVuVur7W2OrL9kM3ZsHc80pMPjmPsCvacyGUjmSRDKRgW3Bi7nkl5l9QQdT75a2gt8JxdXkVs2fm4bUEoDljgO6MCW61D4lt88Hb7fbWfaVhnrZBeUIL/ZilOzKu897p7NRnW3Bh8sl5LB6Vw3HCn+6poC8vrcCj8+Ls/05h/rAKujEDTLNW2DVOxKMJJJNJRKNR2Ix2nPifMzj641OYODyDU0+N4cyz57A4o4Ber4dCocD83DwO/+9xPPHdZ/H8fx/FqWfOAy2p8AAAIABJREFU4sj/nsTc2CJcLhe8Xi/8fj9UExqMPTOF4z88i8nn5jB3TAHzgh3FpSKq1SpqtRriviT04xboJ6yYf14F44QFtjlnT8U+lyzAOGGBW+uFddYB1Ul9X9/1UqYI24ITurNmuLVe+YJq0opUWN6Cu1AowKy3wDRlh+qEAeoTetgX3Zh9VgG3xotcQt6+faW4stUH7sLCYQ3Up42YemoB1jlHdxJGKV/eGpvolmc8H5UvukwzdkiRDOLeFJJBCSFHRJ7dbAzCNu/E3CElNKeNSIUyyCXyCNmjCNoiCNk7u0T6MXdIhdlnF+DW+ZH0pyFafTjzzAQy0Wz3397CITXGfzIL24ILLrW4tStm/6Lk3QK0y+XC0tISnE7nwAAtiiLUajU2Nja4kPA2NuzcRCQIAgP07ewP/uAPEI1GX/GDKZ/Pw+fz7frz1ZUagrZItwc66on3bYHcbrcRdsbg1vi6O6UF7dG+3t/uhI2tqRl2had/wkajCcu0HQ6lCI/eD6dahH3B1Vf1jotJHHn8BBSnNHAsuqEfs/TMvF1fX0elXIVuzIy555RYOKyB5qy8wcT2Km6r1YJdIY/0mntBidnnFDDP2PsWN0bcMRgmrLDM2qE+bYTqhBZStHdjk2K2BNO0Ax6tH/Z5J1SnDLArPT3V83qtDq8pgCP/ewLmKTuUR7WYfnqxb7FhZzSd7pwFc4eUmHxqAR69r6d9ZqVYQcwTh0frxfyLKmhO6mGbd/csNmw25Z36Ev4k9OfMMIxbYZ62IxFI92zMsry0gpiYhGXWAeUxDRRHdQg6It2pC53XWTmrhnHOhokn5rHwohrWeReinnh3gkO9XsdyeQVeawAnHx/DxLNzUJzRYvGUGrpZI/yiH8FgED6fD1azDcefOIPnvv8iTjx5BsefOIUXf3wUM2OzPVMYzh4aw7P/+SJe+P+O4OyzYzj1xDkoxlUIBOTNMxKJBBxGF6YPLeDcT6cw9uQs1Gd0MM3YUK2sypMzEgk4LW7oxy3dxYbK4zrY5p19z6lt3gXLnAtOtQjNaQOMk7aeUX3VlRqcKhHqkwb5mwu1BwtHtAhYQ90wWF+rwzrvhHHCitnnlTCMmzH7jAKmSRsS/jRq1TXU1xrwaL0wz9j/f/be5LexxDz71T+S1QcDgYOgkSyzyiZZGsgmiwRZZHGNey8Q+MZ27PbQbnd3Dd01q0pSaRbFeZ6Hc0iegfPhTIqTqHkulWZVI+0gAfz7FofFLrq63Q3cD2i4oBeohXQOVapTlPicl8/ze0g6UgRnY3ifR4hbVDplvYJ+tdMnbI+RCxepqU2SzjS+qQgxk8RGR79RWW9t0q30qSh1HaGoNgjOxAjOC7SKXbZ6ehnMSqFDr7am5w/iVaLLSaz3veTCGs18h+3VHZ2iUe3TKffQhApJRwrjbQfpQGFY6d3SutTTKzrNQ+uSi2i4n4ZQvFldLEdL5CUNz1KQ9ZUNtnrb1DNNgvMCkjtNcdBQWUzWWK2uvUVw+ToB3ev1aLfblMvlrxTQpVIJRVF49erVTZDwHZ7vWjfdzM2MjY3dCOh3ef7xH/+RUqn0jS9M+/v7lMvlrz1+uHNE2qdbEsrJGvlwkXax95aAzkeK5KJFiokapXiNlDc7sgl99eoVm90dEhYZ2ZVB9eWQnBl69dHw39nJOelggdCsQHhBJLqkh8v+0GtcTTVZvm/FOeEnNCeSsKtvtcVtre4guTLkY0VUTxbBJNHSRv3epy/Php7lXFhDcqiIVmXkRf36+ppOsUdRrCA7M4QXRLwTIfr1UWbx/tYB7WIPxZUhNCsSGIjxN7+v87MLOuVVrDN2RLOE5EiR8uVol7ojNxw7a7t0ij1S3iyKN4PsSOsV5wO/7qtXul2i31gnE8gRWYoTmhN1P3V5tDnv5dEJZamO51mYyIJIyp+jmmrQKLR48eIFh4eH7O3t0aysYH3kwvrMQ8gcw7cUJmSOkM/o3tJCoUA4FGb5mZWJ30yz8NCIadLK3GcGPBYfsiyTSqXIZrNEPDEMD0zM3zFin3LjngsQc8bpdXtsbm6ys7NDp9kjZk4SWhDwPQ+TdKRI+fIjG/vT41PS/gL5WJmkI014QSTjz3O4+6Ut5vz0nHKyhuzOoMWrpH054haV1TfoLZ1Oh5hDJG5TSFhk8rEy0aUEuUiRF/vHQ9ZwM99G9WaJGhKEFkQC0zEEU5J2eXVY875aW0P15vRN8FwM19MgoTmBbuVL3/VWd5t8RC/CKcbLuMcDBBd0LvLGABO3u75Hc7DFralNYsYktkd+iokq661N+o11iqkyoj9JI9OiECshO9MsfGDS7URynfX2Fu1Sj06xx2Zni6pSJ+3PY/zYTsKmUhD0FstebY1WQWdjr7c2qSp1PFMhRKNEPd0cMrZbWofOgPDRb64RWUoQNSbJ+AeV3pESLa3D+mBj3av2iRqTxEwS0WWJdKCgM7KdEvm0xvrKBu1il6QjjWiWyIY0YssSuXCRlDf3Fn3mjwnow8NDNE2jVqt9rQe6Uqmwv79/EyR8h+e71k03czNjY2M3AvpPYfb29vjbv/1b/vzP/5zvf//7PHny5Fs97l//9V+H25g/9ufo6AhN0772+N7mAQmrgmiSSVhVElaFtja62b68uEQTK/pb/wsioTmRbEh7e2tcXRtsb2UiSwlEs8x2f9Rm8mL/GMWdQRNLZAJ5EnZdBLwpVC8vdQSac85HxCiSsKWILiVG3hp/9UoPz5WSVeI2hdCsgHcqTC3VHNkInx6f0i52SfvzhOZjRJdEEjb1LQtHv6FvhBN2BdWTRfFmaWTbI8UyJy9OaWkdUoEssjuDaJFpZFtvhQ131/eYu2cgOCcQnIuh+nJ0yqsjnOTLyyvaxS6eiRD+mQhxu0I6lKekVNna3GJzc5O1tTUa1SaWp06WH1hxz/twznmxz7hIihLpdBpFUZAkCdu8k4kPZpm5u4jxmZmF+0Z81hD5fJ5isUilUiEtZ7E8c7F014J13EPAEEFwSGxvbXNwcMCLFy+QEzJRc5ykXSU0JxJblkj5cyNb3IvzCzSxQiZYIBPUA2SSO83O+pdb9uvra1ZyLSRHimxIIxspIpiS1NMrI/8/q7U14rY0oXmBpD1FeDFOwp5iZ21veN7W6g6KO0vcquB/HsU7Ecb/PEJL67C3sc/19TWlfBn3bIBSQt+qWu+5Cc7EaGmdoe/6+OCY8sBuUJUb+GdjeJ4FqabqbHa3hk2Jb1I/Ut4syx/bUdwZuuVVNlqbg7bEPmvNDTShTMqbZf43FqJLCTShords1nR83Vpzg25llWxIw3rfg386qodLBR15V1RLxAMS26s7dEo9oksJXE+DlGXd119M1uhV19ho6SSXjc4mSbuqP2csMhW5Ti5cpJ5ucbT7gtXaGp3KgPoxHUO0SMQtMrlIkUxI4/jgmBf7Oi86HdSILMbJx8oIg0rvtC/P/vYh19fXOmEj1URyZSgIFUrJKpIjTS6skVeKtFqtQSlQn0xIG5bTFIQyKX+eRqbF8cHxt6r0/uKLL/j8889JJpM0m82vFNC5XI719XU6nc5NkPAdnu9aN93MzYyNjd0I6D+FOTo6olqtAvDq1Su+973v0el0vvFx//Zv/0Y4HP7GF6bj42NyudzXHt/p75K0q8iOFEm7Qtyi0K2sjpxzfnZO2pcnHyuSCRRQvRkUT+6tuuhOeZVMqEDKnSVhlgktiOz8gQf6xf4xFbmGaJEJzemWikwgPyJALy+v6Jb7eOYDWJ+4iVtkkjb1rVrp/e1DaqkmsitN2p9D8WSppVZGtrM6lkz3s0oOFcEoocWrb5WDnB6fko+UCMzGCM0JJO0qK/n2UGhfX19zcXHBarOPfdyHZypEeFlAdEiokTTddpdut8vKygqVSpWp2zPM31nGPGHH8tzBwn0jYV94xLrgNnuZ+HCWmVuLmJ7ZMD6xErRFhqixdrtNrVTDtxDC8tiF/YmHsEEg7pA5Ojzi7OyMy8tLLs4vdDuBN0NkUSQ0K6B6MhztfSn+r6+vWcm3UbxZsmENyZVGMMlvMbijPpHQkqBf00CemClJPloaCbMdbh+iuDOE50RC8yLBOQH/8yj95sbQF//y6ISUN4fqy+GfjmL+zI3nWZia2hxyks9OzimKOs4wGy5gf+jF8yxILbVCt9pnd32Py4tLWoUuhajuxRXMErZ7HtLBPJvdHbqVPicvTkmLWRIBRedTe7MYPrYRnItRTzcHnu0NDnaO6NX61NQmmWCe5Y9suB77h+2N3Wqfw50jelWd+lGV6/ieR7B+5hlWsq8UOoOGvu3htldypbE/8JINFqilGuQjuhXixcFLuuVV1lubZMManmf6JjsbLpKPligmqrSbHfKqTgLJR4p4noWImxXCC/pNqurJcbBzyOWl3hhakRtEFkRy0SKSO4tgklF92WHW4OL8grXmul4H7s1SSzVQvTkywQLtN0g2B9uHZEMFknaVtC9LRakTt6mUpBq7m/sjvutsWPddpwMFBGNSp21E0mTlAnub+xRE3aOfDmoIJom4RSFuVuhW+t+60vuLL77gv/7rvxBFkVar9bUYu5OTEwqFwk2Q8B2e71o33czNjI2N3QjoP8X5wQ9+QDwe/8bz3n//fex2+zcK6NPTUzKZzNce3+rtkA7kiVsUoktx/a3q6qiAPjs5p55ZIW7SfcTheZGkLcXpyWjYcL29RSFWQjTLSI40SUeadrE3uhF+eUZFaaC6s6QDeRR3lmK8+hZhY6e/i/WpC9eUn8hSgpQ/T6fcG9l6X15eUUrWCUzrolcwSZSlGhudLc7Pz3n58iVHR0estvvYn3hwTHjxzYfxL4WJ2EWqlRq1Wo1yuYymadhmXEx/PMf8AyPLz8zMfrY04tdVVZVYQGDu7jLzdwwYx+3YJ1xEbDHa7Tarq6tsbGzQ7/WZubuAZyqIZypEaEFA8WZGGMhXV1d6oNGXI2FRCM0JxO0qe5ujXul+c4OEPUU2XEQZ2FSaudF3CA53j5A9GaLLemAxalKI25QRWsfpyRmZYJGYMYlvMoxzPID7WYjGG9SVy8sr7DMuRJtEzJDAdNuJ87GfglBmbSCOr6+vaWtdskGd+uGdCOF46CMX0eg31tlo6z717d4OxUSVUryK7Exju+chupRgtb5Ot9ofbkJbWldnN7uzmG7Zsdz3oAllPYBWXeNswATvVfvkwkWsn3kw3XGS8ucpJ3U84MvDl2SSeTLJPJ1Sl/BCHPNnLvIRvdinqjRYa25w8uJUD9z1tslGNGyP/MSMElW1SS5SopltcXZyxvbqLr2aXrPuehrENR5EcqYoxMr6FvfwJednF6yvbFBVGjr1w6LoPxeDRsLXleunx6d0K31Eo0TKp1eoC8sSKZ+Og3tNyTncfV0xnqKYqOmWFleaembljZKXc/LREpIzjWBMUhx4uDPBAhvtTc5Ozjk/PaeUqJAOFBDNMqJZIm6RiC4naGld+o11jg+OaWRbZAIFiokqollCNCcJzuo/+/36Gp3XhUH+HAWxQjFRRbKniCyKrBQ65JUCSjhF3CKT8muIZolSskbKn8M7GSX/B5XeXxVM/ioBrSjK126gZVnmiy++QJKkmyDhOzzftW66mZsZGxu7EdB/arO9vc2f/dmfcX19/Y3n3rp1i4WFhW8U0BcXF6iq+rXHD3aOyAY1knYVxZNBdqepqM23NsKNzAqKW/c2y640mWDxLRvE8eFLElaF2MBfGreprBQ6b6Xw28UuvsnokGSRCuRpVzocHh6yu7vL9vY23U6X2dsG5u8u43zuxTXvx7XgI5fNj9QCW+fsTH44y9ynBgxPTMzeWcTvCA5RY5qmkVEyGB/ZWLxrxvTIgWvah+BIsLGxwc7ODvv7++zv76P6soQX9a14aE4k4yu8xcRuF7uonoxeDrIsIZplNv6ADrK/dcDzT+bJ+PMonixxm0IhXn3rRiIT0gjNi0QW40QWRYKzsRGbx/X1NaVEhbhFxjcVxnzXifNxgHKyPsLX7ZRXUT1Zkg4V010ntvte0oGCHjYciOOdtT1S/gKlRI3QvIjjkZe4VaHf2GCtqQcEXx6d4F70InvTyM4U9id+7I98ejitqtsgLs516kc9vYLqy2C568J0y4niydKrrLI6sLNsDEgdJamO/ZEH4y0nkiOFFiuzonU53D3i5dGJXju+skHCLmP51E3cplCRdJtFr9ofUj/WmhuUpSqucT+uJ0GK8Sr5iM7QPjs5p15tkBayuvf3aRjHIx/hhTjZcAnFleFowLI+3D2imevgnYwgGCViywmihiSKJ8v26s7w5mZ3fQ/Vq9/clJI14nYV2ZMZyQecn59TStZI2BRSfp21nLCl0BKVoff36uqKemYF1ZMlNCeieLIkrCqCWdar3KtNWq0WnVJfxz96dbShYJLxToRYyXd1a8nhS1Yb6yjeHCWphurNE16K45+J0Na6rLc2Wa2usVLokAkWUFwZqmoD2ZHCNxWmLNXZ7Ohb83S4gOrJEVtOIrsz5CNFHA99SM409fQKa60N0v4ccYtMJlggshAn5cvjfhIgvJhAE8qErTGi1jjBuRgVpY7qy5G0KQTmYkSX4np9e6xMs9D5ylbMrxPQhULha0OErxsK0+n08DE3QcJ3b75r3XQzNzM2NnYjoP+U5vPPP+ev//qv8Xg83+r8J0+e8PTp028U0NfX10iS9LXHz8/OUT0ZwovxYcFGPbMyInqvr69ZbazhnQzhmQrjnwsj2JKU0tWhV7fX69FsNLE+c2F6YsMy4cQy5WR53IqUkJBlebjJdRrcTPx2lpnb8yw9MrHw6TJRrzBEjTUaDSrFKksPzUx/uIj1iRv3dIC4S+bg4GCkFrgYryBaZCKL+ou55Ey/5ZXe6GyTdGRQvDkSNt3G0S2PcplPXpzq2DJXmoQ9RdyeQvVkRlB9V1dXlJM1PWQ4GcY9HsQzGWZ9ZZTW0ams8vzjObyTIZY/sWG97yEdGOVF76ztongypPxZHI+82B94SNjUkXKQkxen5GMlNKFCdCGOb1L3/vaqfR0jeHnF5cUl7cEWN2lXcT0JYL7rIh8t0nuDnb3Z2aZV7JLy5THfdWG67SC6nKSZa9OtrHJxfsHLoxNCjghasoT7WRDrPQ+RpYTebJhusr91MCzM2Whvkg7kcDzyEZyNUUzWyIU02oPCGL16Whfa3okQprsuVE+OvFChEC1zdnLO9fU126u7NLIreKfCOB/78U1FkJwZUt4cB4MmyIvzC9ZXNvXAmyFJ3KoQmhORHGnWVvSa+k6nQ6vZoiBUEEwS+UGBS8KqvuWLbxd7JOy6Vz8vlInbFNLe3ND7qz9ntlBcGWJGiYghQdyi4J+K0My3h2UwO+t7KJ6MjowzJAk8j+GZCFFTm3QrqxzsHLG3dUAurJENlyglKoSXRDyTISpyja3uNsrACpENacTNCrmozm62P/KSDuboD9oPq2oT1ZNFdmUIL8TJBDWsn7kJzYto8Sr9xjpVtUHcomPwRItMzJDA/SyA52lwUPxToZFZQTBKOhNc0sV/ZEHEMxWmmKxSHLQ9Ju0pMv78ICRZ1X8/LAoongy1VAPXrA/npJ98tEghVqKcqBJeEPA9jyA5UshOHe+X9udZa65/ow/6tSWjWq2SzWb/qIBuNps3QcJ3eL5r3XQzNzM2NnYjoP9U5r//+7/5+7//ex4+fPitH7OwsMDdu3ffeiG6urri4uKC09NTXrx4wcHBAaIosrW1xfr6Oqurq3Q6HVZWVqjX6xSLJUxPbSw+sLD8yMTSExNz95YQo+KIX9dn9TN9e5G5T40sP7RieGQlEUgOvbq9Xo9Oq0PIKGB74sH5TPcJq74spyenIy+gjUG7XnQpQXhBJG5V3uIk723s43zuwzXnJ+lIE7cq1FKNPxD/F+TCGgmLQswoETPq6LKTl6N0kHahQ8QQxz0ewnzXieOxn5Y22py3v7mPZE/hn4livOXAeNuJaJFH6rz1yuwcmWAez0QI13iA8FKCZq493DheXl5RS60wf88wEPVRHA/91FJNepUv2dkb7S3Kcg3RLON45MN424FoluhW++ys6Zv9l4cvaRe75GMlTHdcWD5z434aoizX6ZRXOT/7snp6tbFGcE7A/sCLfzpKLqxRTn5pjdnfPqRb7aPFy7jGA3gmghSiJbJhjZV8h6urKy4vr4h5RbLRAv7pCMuf2AkvxslFS6T9+eFN1etgZmA6hns8gGciNNxmvmlBOdo9QnFnCc4LyO4s0aUEcasycvNyfX3NitZBMElkggVykSJxq0IxXuX8DY/6ztoekjtNaCGO7M6QcKQRjBJb3R09kNluUys1SHkHyLiZGMEFEfd4kIpSZ3t1d7hlzwQK5KM68s752I/raZBSoka30mdnbZeT41NKiRqqO0MxUSVukXE+8pGLFNnqbdOtrLKzua/fvJllElaFbLSE5a6LmClJq9jRq8BLPfKxEqovR2QxTtwkYbvvxvUkQC5aYkXrIodS+JciZAIFcpESoXkB77Mg5k+dFGJlHS1X7CG7M2RDBWpqk3y4iH86iv2hj2xEL1XRYmUkV5piXG/3rKeaxEwSzvEAgkmimNApOwmrXtjzmt0smmUsn3mQHCmiS0k0oUzCqpDyZlitrVFKVJFdaaz3vaj+3IC2IWN95sT1PKBvvmt9NLGMdyqM4stSVetIzgzZUJ5ivPKtMHavBfTKygrJZPKPCujt7e2bIOE7PN+1brqZmxkbG7sR0H8K8/vf/55/+Zd/4Uc/+tHXnrO2tsaPf/xjfvjDH/JP//RP/OAHP+Av/uIv+F//63/xve99j+9///tDoSvLMqqqks1mKRQKlEolIpEIjUaDVqtFt9ul3++zsbHB9vY2W5vbJNwKrokA/ukIgZko6WD+rTKSbnmVuHUgVJeTiOa32+5eHLxEcqZRvVmS9hQJu0o+VhoRqtfX15SkCrHlBIGZGIHpGOGlxFuIus3eNtanbiZ/tYDxEwfWzzxof2CDOB60B4bnRcx3XJjuOAkvxEfKW66urijGy6ieNP7pKIHpCN7JIFW1MbIR1nFx+UFhRAzbAy/5sEa3vDoUAMcHL6mnmogmCes9N5ZP3bifhQZeT/3vfF09bZy0YL7rxPbAg+uxXxeqhS/LTbb7u/RqfQRTEscjH4HpKJlAnly4OGQSn5/prX9luYZzPIjzsY/kgILw5lb1cPeIerqJbyqC8ZYD15MAGX8O1Zsb+q6vrq7YWt0mNB/H+cSPezxIaF4k6UyNXK98roASzBCeE1A9aRI2FdEkv1XystXfRTTLJJ26PzthT5EJ5jl5A9V3fHCM6i0Qno8TMyRJ2FL4p2L0ql8GOM/PLvTAm0/nKbvGgzjGA3oRR3uLyws9JFmW66T8OXKRAp5nQRyP/GRDGqu1NTba26ysrCAFVBJ2VQ/f+bJY73mQHKqOZKutsb99SEvrDGrPRRR3Fut9N57JEFVVtzh0K33apa4u0u0pgrMCzsc+DB/ZyIQK1NQGq40NqmqDlDdHWaqSsKk4HvlZ+q2NbFhDEyo0si2K8QqaWKYoVqnKDcLzMSyfukjYVGqpBoVYmaAxTNQWpyhWKCdqqN4cpltOAoNwbVWto7gz5CIa3UpP92EHCyz9xkrMmCQ8L5Ly5VC8WRR3ho32Jq1Ch2xIw/bQi2CSSAfyhBfjpPx5JFeaTkkvXmlrHYLzIjFDQq/kDmqo3iy5SJF6ZoX11ibrKxuEF0QdyehMU1UbpAMFHM/dpGM5mrk27WIPwSQjWmREk4LkSpMJFRHNElW1wfrKxlvM+K+zcLRaLURRHArqrxLQ5+fnN0HCd3i+a910MzczNjZ2I6D/FCaTyTA2NsZf/uVf8t577/Hee+8RiURGzjk7O0OWZUqlEt1ul729Pex2Oz/60Y++cbPz6tWrP2rhODs9Q/VmUVwZRItCwq6S8uW5vBwlbLSKPaKLSdzPQtgf+vFPx9hdG/VAH+0fE7ep2O55Wb5lx3jbierOjIjey8vLoVC1P/TieOjD8yzM2h8QNtrFLq7pAPO3jV82nIWLI0L7aO8F2WCBwIxAYDqC/aGPqEGiW1l9I3h1QUvrkLCpWO66sT/wYnvgoaI2hqL39Ua4mWtju+/B8dCLZzyI7EzTyLSGovd1IExypnGNBwjMxkjYVdL+wpA2cn19zVZvB+MzM65nQez3vQTnRDJBjbJUG16L87ML2sUu/pkYxlv6DYJokVE92RHf9cmLE5KOFJ6nITzPwgRnYwgWha3e6M3Laq1PaF5E9WQHdAZdvLx5TV8cHKN4MsSMSVRvjqQ9Q9wqc3zwZdgwl82TdCp6i91MDP9MFPfTIPV0c7iBvrrSMYMpn+6jtd33YH/oIxXI02+sD699t7KqI9BiZULzAtZ7XiRXhn5jXQ8lXl6x0dki6UiRsKpI7gz2hz5CCwK9ap9+XWcp728doLjTRBbihOfj2O57Md1yUoiWhg2IWTmPby5EOlAgOCdgvutk4TcWFFeGYrzKan2ddmmVglCmlNC3tM7xAHO/NA3O0Yt9GtkWVVUXt1WlgeRKYfjQRnA2SlVpoIkViskaFalOM9eiECuTD2ssf2zD8ShAwqpQTtZIeXMUYiXWmutUlTqZUIHl2w78UxHCC3E9fOfN4lsKoUYyrLc2KUt1fFMRXE8DFIQK0eUkkjNNPlKkpXXZ6m6ztrJBwqrimQiRj5b1DbE7Q0Eos1pfo1tZZX1lA8WTwTcTI7qcoCBUyIYKSK4MrVJvUHm/SsqXIzgnkHSmiCwlyAQKBGcESlKVlUKHZr5NMVFFMOmBRcmRJm6RCc7FsM94qGTqNHNtSsnaAGmoUVUbqJ4Mgkki5c+z1dMrvb+pUOW1GG40GqiqysXFxYh4/t3vfjcU0L/73e9ugoTv8HzXuulmbmZsbOxGQL/Lo6oqP/zhD/9/C+jTl2corjTWe25Mt50YbzkQTRJnf7CBripA+YC0AAAgAElEQVQNAjMCnmchvJMhHI/8tArtEYG23d9FMEoEZwWiS3G8EyHiNoWDnTeKRk7PKSWr+KbCeCbCOB/58UyEWdE6I1vvfmOd4GKUxz99jv2+B8s9N9lQga3el1zpF/s6TcD1xI/naRDf8wgxQ5KKXB+K3qurK/qNdRRPRi+7mBOJGhIo7gxbbzQbHh++pKo28TwLYP7MjXs8gOrOogmVoei9vr5me22X0FwM810n5rsuQnMCijvLizdE6OXlFYtPjHinIvimwgTnBGLLSfrNjZFruru+R3RZQnVnUDxZRItKPlYeCXCenZyRDWt6fbNFJm5VCS+I7G+OMpcrcp24RSYwE8H2wIdj3I8mlkfChqu1Poori2RPYbnnxnzXSdKu0qusDUNeUkwmuCiQDWmEF+PY7nsQTDKr9TX6dd2C8uLgJSl/nshSAsEk4XgcwPHQSyOzwlpzne3+LmcnekgybpEJTEcxfGTF8LGdpD1Fp7w6JHFoYpl0oEDcIrP0kY2Z941El5MUoiU6pR79lU1W8vpGtSrXiSyIPP/5EpFFkcqgDr6ldUgEZOIuiVK8Sj5cZPEjC9ZP3bo/dxBo65R04VgUK+RCRUy3nRh+ayU0K5CLlFC9WZq59oD6sUohWsI9HsDwkY2YIUl4IY7izVJKVumUVtnsbtEqdhDNEqa7DvKxIkm7StKmoolltlZ3Bhi3HXIRDdd4gIRNpSzVUT0ZssECqUSOvKSxWu1TFCu4nwYIzEZJOtIUhBLCcpJmvs1GZ4tetU8xXsE3FUb1ZonM6z7wwLROvehWVlmtr9HMtYlbZLKRIvlIiehSguC0gOrPsdZcp13s0tL0sKHsylCR62TDGrHlBHFbivX2Flu9bb28xpUh6UgRtyqUpToxQxL/bAz3opdGvkkz38Y/HSEXKQ5tPKJZwvMsSC6sUYxXWVvR3wE4efH1W+jXArpWq1GpVNjZ2RkR0P/5n/9JKpUafnwTJHx357vWTTdzM2NjYzcC+l2eSqXCP//zP39rAf11HNaXRycIRonQTIzIYhzfVBj/TGxE9F5fX1NPNfFORXA9CmB94MX12K8L1TdE7/7WAao3i/lTJ/YHPuwPvYhmmc03RO/52QUruTaeiSDeyTCh+RjBOYFCrDTytfY2DwguRnn+wfyAiiGQtClsdr4UvZeXV7S0Dq7HAcx3nNjueRDMMgWhMvLvPTs5J7IYx/ypbvPwTkb0sOH+aNiwXezim4kQmo0RMcSJGpJ0y6NIv5MXp4hWFcmeRnIOwobe/Mh27erqiuWnZkILom4JmYsRmI2OVGu/eqWHDRN2Veck33Fhf+Al5c2OlLfsru8hu9Io7hz2B15Mt50Iy0k65d5QkJwen6L6siieDMF5Ade4H9/zCJ1Sd7j5u7i4REtUCC/E8U3HsN7z6Ki3wRZ3s7PN9fU13mU/oaUYgZkY0+8vs/RbG+FFcRg2PHlxQq/S173ggTzG204mf7KIdypMIVamnm2x3t5iZ22XTLBARaqTtKk8//kSrvEAWqKi0xmybXbX92mkmxRiJfKREtbP3Mz+wojqyVGR66QDhSEGrZFpkYsUsT/wM/v+Mu5nISRXGtWTpVftkwwpFJQyZVmvuV780KIH32YFZGeKklRjf/uAXk0vJUkFs5ju6mSQTCCvBwqjRY4PjunX1/Q2v1Qd9zP9eVoQyqQCBSRHis3uFoe7R/QqfWpqA89kCN+0vlnOhDRCswKleIWdtV12+rs0sm38z6NIjhSCSSK8EMc7GSblzSH6EhRTZTa6myjeLLIrRVmqIZpk/NNR4jZ1iPTrtzYoCGUSdoVsME9JqhKcjRE1JOgN8HwrhQ6qN0vKl9dbHYMFBLOM+4kfbVDV3auvETMmSflzyK4MkcU4SVsK8x0XaV8OLVamkWshmGUS9pTuaXbplhbPRAjZk8E+6ybuUIiZkngnw6QDeSpKHcmhN3nqfmy90rucrNEpr/5REsdrYVwul+n3+6ysrIwI6FevXo2ECxuNxk2Q8B2d71o33czNjI2N3Qjod3l6vR7/8A//8K0E9Ou3RL9yA318iurNYrvvxf7Qi/tpEP/zyFsWgV5lFc9EmMBslMgAn5X2jwrH05dnyO40zid+fJMhfFNhooYEm3+AedvobuMc97N8y4HptpPQnEAhWhqxelxdXREyCDz+6XNMd1y4n4UQrSov9l/8wdfa0ivBDQkEUxLBLNHMtUfOOT89J+XPEbfKxC26KEjaUiPlIK9evaKRXSGyKOJ/HsX1yI97IkSnMlprvrO2R9KqEJyLYbrjwHzXRcKqjFZrvzhh+vYCqjeL80kA230vwXmRlXzny7DhxaUeQrMq+KYieCZDuB4FqGVW6FX6w5uJltYhupzEMx5k8UMLptsuEnaF1foaG239um52t5EcKSKLcZ7/dJG5X5lwPvFTkRu6cDk+5WD7ENWbpRiv4HziZ+rHizgf+3WRKzdYb21yenyKe8FH0qOS8uVY+LUJw0d2cpHS0NLw8uiETrFHKVElG9JwPvIx8e8LhOYFiskaqjvL/vYB6+0tepVVNKGMa9zP7C+WMX/q0hvvXFnapR5Hey+G217BlMR4y453Ijz03GpimbPTM3rVNTY7W5SlGo7HXgIzMTJhjbhNJR3SOD48Jp/WyMbztPJtAjMxbPc8emlMRC8BWW2sc3Z6zlZ3m5VCG+9UBO9UFP90FNEi45vSg3ybnS1eHp3Qb6wjmiVipiSyMzMkbOhFQ3022tscH7wcUGAUiskqaV8e55MAMZPMWmuD1doaW70dGrkVJJcevismq4TmdFpFI9dGiankErq9J+XN6kFYY5K4RcXwiZ1MIE8js8JGZ4uUL4/qyVEQKkQW9aZP0yd2JGdavynJtUl5s8QHN5HFeIWYUcLzNIhokqipDQrREgmbjHdKx/gVkzXS/hyeiRCCWSITKlKW6wRmIrie+IksisTNMrmwhvOJn4ghScwoYXhsxTUZxHzXheRME11OorgyeJ+FCS/pNxIxQ5JcuIjqyY747P/YBlrTNI6Ojt4icVxeXlIoFIYf3wQJ3935rnXTzdzM2NjYjYB+l+fg4IC/+7u/+1YCOpPJcHr61W+fXl5ekQ7msD3w4H4axPkkQGAu9hbb+GjvGO9ECMPHNox3HLieBimIpbfwVFq8gv2RH+t9D55nYQTz24SNg+0jBJOEaFUQTRJxq0JFabz1fSXdKnN3lokuxYkuJ4iZkhwfjm6NV+trRJcSeJ7pL+a2Bz7qmeao93fvBbIzQ3AQNjTechBeFNl9wwZxeXFJJqSRdKg4HwdwPg3gnQxTz6yMbIRbhTaCUcLxyIvzqR5mK8TKI6J3d32Pyd/O4nzsZ+b9ZRY+tOCfigyEl35djw9eonqyJGwpnv9sief/YcD8qZt8tMhKocvp8SnnZxfkIyUKsRLB6SgzP1tm+baDtD+HJpRZa21yfX1NS+uSj+gtkcaPHcz9ykTcIut+X6nG+em5jotLr5AJFbDf9zL57/MY7zrJRYqo7gx7W/u8PDoh4hJIR3J4pyIsfmhh7lcmQnMCkksvxXlN/VhvbZL25zB/5sbxyEdkMUFkKYEWr3JxcTmkfrS0Dt6pMI7HPlRfHsmZRvFkOdp7weXFJWvNDVpah8iCiPGWk/C8SDqoEZ4TaeZanJ/peL1ueZWoIYF3MoT/eZTAbAzPsxCSM8Nac51KqUKjuqJbT+ZFUoEcgdkY9odeooYE3coqa80Nzs/OaRe7iGZ5QL4o4hz3E16I06+vDctgNjpbKO4soYU4qi9HyJDAdt9LKVnTbw5qa3SrOn9bcmUIzsSIGuLMf2Ah6VApy3XW21uU5Pqgur6C7M4QmI6w9JEVwZikIJTxG8MkvCoJRxrVlaEs1UnaUzge+/HPRKmnm2hihVxIwzcZGfqii8kqtgcegjNRku40tVSThF3F+ciP7M4MrEUZXONBPM/Cg8dlSDhSmO66kN2Z4Zba/zyKazxALqIRXYoTMSSxPfDq1espHZ8XWUoQnBUoCBU0scKzD2ZwPQ0gLCcpinrNd3gxTnghTsKRopTUy2AyIY16usnJ8ekfbSN8LaBzuRyXl5dDj/NrwXx2dkapVBp+fBMkfHfnu9ZNN3MzY2NjNwL6XZ7r62v+5m/+5lsJ6Hw+z/Hx8dcebxY6+J5HcD7x450MI5rktxrxXuwfk7ClEG16wCxhV9GEtwkbZalK1BDHPxMlMBMlYnibsKF7f5M4HnlZ/tiB+a6TglD+A9vFGaJVYvLDBYy3XZjuOPA9j4x4oF+9ekVNbSBaFJyP9Y2x+2kQLVEdIWxsre4QXU5ivOvEcteF7YGXpCM1InpfvjhF9eZxPvbz/GdLzP7CiOWeh2a+PbSNXF5e6W1xjjSzv1xm6j8MLH5kQ/Ho3tnXb1G3tC7z9w2EFwQWfmNm8UMLgkUmGy6yNmBG767vUYiWyfjzLN9yMP8rE67xIPkBuuz87IKTF6esFLrkoyXsD7zM/HyZ6Z8tIbnSyO7MkMvcq67Rq/YJzcVY+sjC7C+W8UyEiVsV2sUur17plpjVWp9isor9vgf7Ez+hBQHBoAu587Nzzs8uiHlENLlEcE63ecRMeuBQNEvsb+k3Qoe7R3TKq0QXRcyfuXA+DiBaFIIzMUpSlbOTc66urtju7yA507jHA/if62FE52MfoklmtbbG2ck5lxeXNPNtgrMCmaCGYJQxf+omYkjQLnVZra1xfnbBzvoekiOtI+NCmm6tmIqwUujoddphhVajQ9qXI7qUJGpIElpMsHzLPgw3rg4QgWlfnpRfF4/eiTBzvzIRM0hoYoV+Y52VQhdNLJPy59EE/VosfmQlMBOlGK+iiRVWci1Ub5aETSUf1shFNSyfuXA88lGSapSTNTSxSnhBJOFIE5wTyAQLuMcDOB/7iBmTlKQatgkXlgduJIdK3CITmhfxP49huuNEMOr/jnQwj+Ohj7hFpSLXEC16YYnptoNctIRoVogZE7jHw8Qtsm6bkHRB65kMoXj0gpmkPYV/OorsSlOIlahIdUSLgvtpEMEokQnkqch1/DNR4naFQqxCLlokYVexfObWhfRinHRQY+KDGRyPfWQCeVLeHElnGvdEkHRAv7ax5SSKO0NsKUGr0KVX1RGBXyei3/Q2f/7552SzWa6uroaff/nyJdVqdSRUeBMkfDfnu9ZNN3MzY2NjNwL6XZ7/+Z//4a/+6q++lYDWNI3Dw8OvPd7MtQgtCLifhXA8DhCYiY2E1F690gkbokXFet+D6ZYd4y0HKW9u5AXx6uqKTFgjMCNgue/Bdt+DczzEWms0PNdvrBOaF3TLyLMQrvEg2WBhRPS+PDohvBTn7v/9EMNHVox3XHifR+iUe0PbyOXlJdloEde4b7DFXWL5EztaosL2G0J7pdBGsqdZ/NDK/K9NzP/aRMyQHCFL7G7sk/LlCC3EWfqtFeNtJ54p3dv5emt8+vKMitpA8WQx3Xaw+KGZpd9ayQTz5CLFYdV1t9LH/NyG7b6X2feXmfz3RQLTMSRHmoOBCN3b2KdX7ZOwqSx9ZGX+NyZsDzzEliVWijoy7vz0nF6lT7PQxvnYj+eZvhUXTDK5SHEYlNzb2Kdd7BFdTmL+1IV7IojkThNdTLA1aNe7vLhkfWWDuF3Bct+D+VOXbh15GiYTLAwxY/lMHsmn4hoPEpiN4Xzsx/yZi/C8QLfSH563vbZLZCmB4soQt8hY77kJzcVoF3Xf9fnpOSfHp2TCmh4uc2bwPo9gf+SjouqWkbXmBhcXlxSiOvs5NCvgHPdj+NhOzCjpft1qn72tA2pqA9WTJW5VcTzyMfv+8sB3XaJTXiXuT6KG9YZILV4lYVWZ/aUR5yOfLnpjZVYKHUrJGpJdD8VlIyVs970Yb9nJhXWeciFWQvXndEvMUkKvPp+KMv8bE77pKPlIkVykiGCRSNpSZIMFQvMCnskQ8782E11KEpoVSfkLBGcFEjaFqlwnH9HwT0VY+tiO6skMC1FmPzEQMcUpxErU1AZxm4r1gZfwUpyKXEf1ZnXWtF1/l0YTKmSCeYy37Hrbp1mmLDcG4lugmmqgxcpkgwWMt5zETTIxY5KEVSFpV3WfvU9/vhZiJVxPQ8StKkVRp34kbAqOR14SdnXACS8QntctNQVRt4VIzjTjv3iO5EhREMqoniz2hz7iVhXBpFd6p4MFwksi2bBGr9pne3Vn4KH/6nfCXgtjRVH44osvWFlZYW9vb/j5o6Mj6vX6iK3jJkj4bs53rZtu5mbGxsZuBPS7PL///e957733vpWALpfL7O/vf+3xilzHMxnG/tCPczyA86GPXmU0PLe3sU9wVt9KOh75cY4HES3KiL3h/OwC1Ztl8UMLCx9amP+1CdeTAI1ca6TRr5Fr4Xzi5/l/GHj+syXmf2VC9WVGfJK763tElkXu/j8PMXxsY/G3FjxPg1SVxlA4np2ckwtrBOcEjB/bsN53Y7rtQnGnh1vj6+trVgpd0v4cho/szP/KzMwvjCQsugh9TbzY29hnpdDG8djL9C8NTP50Ees9D7IzxeEgUHl2ck6n3CMTymO+68B0y87yJw7CCyKtNzjJW91tHIsu3E/1AJrzcRDBmCTlyw0F+9mJLo4Fk4T5UxeWwdY1vCAO2/Veb3vT/gL2+54h7s7xyE/Cnhqpi+7V1/BNRYgsxLE/8rF8y0FgTqCldYdYvJcvTvWmRYeKaEpif+jX66ILbbrlVc5OzimVysj+FJHFBLHlJK7xANYHHnJhTS/NqK8PrmlHLyyZEzDetrP4oQXvVJhGtjWs/V5b2UDxZEn58zgeB5j88SL2B15yYY1mrs1qdY2t/i6SM002VEDxZJj7wITprhNN0Dfx9VSTfmNNr8JeEJGcaZzjIaZ/ZkByqFSUOrlwkaA5QnApSsKeIjQXwzUeZOYXy9geeFHcWfKRIulAAcWTpRArk7Sn9a3+L4z4Z6IE52IkHWmSVpVcuEA+WqQq14kZE3ogcRDIiy7GkewpMsEcpWSNcqJGPlrE+IkDx2M/+VgZTSiRsKVIWBW6lVW9ECVSwnTbietJgOCcQD5aIuFIMXvLgORL0cis6HaSJ/rPVsKmEloQSVhlvBNhEnaVUqJKLdMgakjgHA9QlmsknGmiS3F80xFkly7oNaGEaNNDiLInS1VtIDlT+GciAzJHkbQ/R2BGwD8bI7qYQPFk0YQy7qchHYsXLZENaXgmw/imo2SCecLzcVKBPL6pCI9/MUkuUtRtT3YV55MApWSVlD+PYJaJGBKE5kXyMd2C1Cx0WK32eXn48q3fP59//vlbrOednR3a7fbw8/v7+7RarREB3Wg0ODg44OhI//m8mXdjvmvddDM3MzY2diOg3+V5LaD/mK9waHOo1djZ2fna45pQZvE3VmZ/aWTmZ0sY7zipqs0RnNpWbxvnYz/TPzcw+4tlpn9mILwojlg9Tl6ckLAqGD6xY77jxHTHifmOC02sDAX09fU1VbWB73kY4yd2bPc9GD+xE1tKjAQXd9Z2kT0Zbv9f95l938D0zw24ngbIR7+0jZy+PKNd7OF7HtG/p58vM/+BmbhFHopefeO9QTFewXLPheWeG8MndgIzMRpvhA2PD1/SzLcJTEdwTwSxPfASNSaRnamh6L2+vmanv4toUTDdcbL8iR330wD+5xE6b9A6Ls4vsM44sD7wsPyxHcNHdqyfuRGMyZEbjsPdI4LzIpGlOI5HPp0TPK2L0NfnXV5eoQllRJNEeFHANR7A9SRIRW3Qq/SH31u72CNsSBCYjmL+1IX1noeEVWV95UvRu9PfHTTOxVn80Mbcr4zYH/qoKHW6FV30puUMgYUYmXAR3/Mwz340j+UzvYpcr6juc3z4cuAXT6G40hg+sbPwGwvpQB5NrFCS6uxu7pOPFPW2yUUR51M/Uz9dIjgboyzXyQY12sUeWqKK4s4QnhexfOpm+ufLLH1sQzDLpIMFspEitXSTbCBPPlbE/TTA5E+WcDzyEZoTEE0SKW+OgCWCYE9Qkepkg3kWPrRgf+gjE9YQTTKyW8e1NfNt8tEipXgF22duFj+0DrfWcYtCIaKxkm9RU5vkIkXc40EWP7Lim46SdKh6mdBykkwwT6/ap6I0CM2LwzBfcE5nL3snIyierF6AUu3rOYN7bjIhjVy4QGBWDxLaZz0IFr16PC+UcD8LEV6MUxyUqujP+SJVtU4mWCBmlPBN6gHAiCFBLlrCds+LYJaoyHVKiZqeCZgIDiwxEqJJwjsRxj0RohAro8XK5KNFvBMhUn69DCZukYkt648riLrPWfFk8U6GdMEfK1OMVxGMScLzArOfLlJPN0nYFJwP/fimwkQMCTRRb2f0z0SQnfqmvarWyYVLtEu94c3vNwnoi4sL8vn88PM7Ozt0Op0RAf06SNhoNDg6OvqufyXfzP+h+a51083czNjY2I2Aftfn2wroZrPJ5ubmVx67vr5G9mRZ+siil4g88mL40IrqzY0EBNdbm7ifBlj62I7lUzeGj6y4nwWGtdO6gD4lHyth+K2V6Z8ZmHnfwNJHFgqx0sjf16v2Cc8LzP1ymdmfG5j7lYnIUnyEsHG4e0QuqnH//3uK45EP0129hKKqNofnXF5e0av0CcxEcT32Yb3vwT8dJWFVRxrxTo9PUT1ZTHecLP3WgvETB56JMM3CKK2j31zH+STI8m0H8x+YMd52El4URjzcF+cXugg1JLA98GD7zI3rWZB6ejRs6FhwEloQ8E7rNAP30wB5oTwienfX9xBNMt6JEAsfWjDdceKfjrHaWKff0LfQLw9foriyxK0KC78xM/XTJcx33eSjJVqlHi/2j/VK85BG2p8nMCcw+ZNFlj6xo7gyQ4TY1dUVVbVBbFlCNMkYPrYx9wsjokVGE6sUhArHB8eEHTE80wFCcwJLt+xM/GQB010XmlAh5cuzWltjrbU5sG4omD91M/GTBaZ/ZtCLXLxZ8tESW/0dFG+WilQjZkwy9eNFzHddBOZiRBYTpLxZnawxqJQuCmXMnzqZ/8Csl7w40kj2FN1an05Zp35oQhnvRITJnywSmImRi5URLTLFeJmIPUZRLVMUK/pz61cmnOMBwgtxossSoQWRYrxKe1AiIrsyGD6yIRologY9hOqdClNKVFG9OVbrfSpKXa9rX4yjxauE5vTgYkWpUUrUSPny1AYNkO7xIKo3RzaiYb7nIh3QBXY+UkLxZPFMhIeMdNmVxnbPTWgmhm3GTVGuoHpyhOZFFHdGtxLNCbgnwlg/0/+vNbFCPb1CYE7Qt9HJKilfntDsoDUzVqKUqJGLFvFPxwgbEiQG4VzBJOnZBpv+cTZUxDmuh4WjSwmSzjRJh4rtgZe4RUU0SeQiRRwPfbjGg6T9eSILcZL2FPYHPlR3hsnfzhKaE7+0wETLpAN6jbp/JobszlCWasRtKoonS9pfGPn5+CYB/drj/Przm5ubrK6ujgjo10HCarXK8fHxd/3r+Gb+D813rZtu5mbGxsZuBPS7Pu+9995bFIyv+tNut1lbW/vKY5eXV5TlOssf23j+H4tM/3yJuQ9M5MKjAcG9jX2iS7o/eOEDMwsfmPFNR0d8y+dnF5STNZyPfXieBrE+8OAeD1KW6yN/5+7mPsG5GI6HXsyfunE88iOYkkNLwmtbQjFe4fb/+5D5X5uY/aUR6wMP9XRz5Gsd7R0RmhMwf+pi7gMzyx/bCcwK7G8djIj2vFAmspTEet+LczyA64mfklQbeVFfb28SM0o4HvmwPfDhfOzXOcOV/nBzdnxwjORM43kWZOb9ZRZ/Y+F/s/cez20deLY//6tZT816Zvuq35vU3U5t2cqBokRRiTki5wxcpItwkS9yBkgwihSDcqayRHW3x7vPb3Fpynpu/3qqZuF6Kp4qLlxAwTItFg++OOdzAlMRNhY2ub0fvXj37j3OOQFZKGMf9CqG9rLypuRGR4lU7O3tsdJYoxisI5mzGM8qr/UTvu0n/vTt9Ttk3SWSVhnroAfzBQ8RbZL5/cGQl7uveHL/GaVgjaRNxjboRXXUgvGck2qsTSXSZGf1Di92X1KNNKnFO4RmJVRHTOhO2AhrkhSCVTrZHi+fvyJiiyOHy9RjLYzn3FgGPUQNmX1z3OLpw2esdzYV05tfIqpNYjjjIOVQpqJlX5mdG3e4vX53f6lvgaQ5h/60Hc9IiEq0Rc5Topnqcm/rPltL26w21sm6y9iHfDivB5FMaeVCq0uz1rqpYNw27iqfIoyFEbVJ8r4y/skoYXWSpcoqYWucRrbN5uI2CUsO/3SEVrJDxpknNBOlm19ie/kWtWib1eYNxXhORknb81RibXxjIYr+isKcbq1Ti7bJOApIxhxJq6xwxEdEQnNxOpkeN3vb9EpLFAM1sq4SnVyPlP2n+EyAVmaBzv64iewrU/BXaCY6zOcXkYxZvGNhGok2QUuESlzJOf/0/7mZ6FAI1hHGI6Qdebr5ZeYLyyStMpIxQylYJ2nNURbrOC75yHnLJG0yrfQ8MV2KwKxEN9+jEKgdjOEoE9sK8zk8F8c9HKQUUEqJpVCNqD5F1llQmM+hOp6RMI4rASK6JM1kl0ZqHlGfRvaVKYcauDVegrNxnFf9RPQpktYc9VgLUaPElWRvhdI+faQUrrPSuMHD24/+2xfoH3/8kUajwd7eHj/++CO3bt3izp07v1gnLJVKLCws8OLFi8Mi4Wei39o3HepQfX19hwb6c9c//MM/8PLly79pjH/+tbW1xdbW1q8+vtbcIDgTI6ZLIkyJhKZjdOWlT57z+uVr0vY8vvEw7it+XNcCZJyFX4yRbK/u4B0LY+x3oj/lwHU9yHxx8dPXevWGvLeCb1LEetGN61qIqD7Nw9ufToOvNm8wO6DDNyESVicIq+K0MwufGO0nD56S9ZRwDwdxXw8hTIlk3UU2F7cPyoZv37ylkVCW4IxnXRjPOfEOB1murR4UBPeVEucAACAASURBVD98+MBK/QalUBXrgAf9WQeW8x5kocJaa+Og/HT35n3yvjJRXQrDOQeuq37ihjTt1AKbizsHcRDrmJOQSsl5WwbcuIdDtHMLNJJdXr14zevXb2lIXbLuEuaLbqa+1KM9ZiXjKFAK1bmzfo/379+zUFyiHu8QN2aYO2pi7lsDwlQU2aNQI/b29ri5sEUz0aGdnsdxZT+aMRVTzGG0xfOnL3h4+xELxSXamR4xXRpjvwvfhEgl1iLnKbO1sqNg7EI5itEqaYeM+YIH/WknGVdRWW+MNHn66DnbSwrurRyu4boWwH5ZIKROEJqViOyTMTaXdthZvc165+Y+HjFGzlvCPxEhPCvRK61wo32TteY628s7ZF1FPKMhCr4KGZfyvGZ6njsbypX6RmeDnLdEYFJhlec8RTwjQdL2PDfmN5HjBUqxKrVok4guSdZVIm7M4LjixzemXHFvdDdZ724yn18kbc/TzixQDv9kFgWaiQ6d7ALr85u0M/OUQnUl1pFbJGXPY7/spxSss1RdUYp6qXnynhJZp1I2rESaOPaz4K1kV1mHFCrETWlaqXlSVpmss4DjskDCkiVpkXHO+oibM0Q0CepSh3ZGwfD5p2PEjVnq8TYpi0zGmcczEiLj/Gmau0tEkySmTR0wuaP69EEmP+0s0MkqS4qSJUPWozCfc94S1kEfKUeBpDVH3qdwyGP6NMVAlayriOwrY73gRVRL5DwlEpYcSbtMzJCmK/fIC1VmzmrwjijLpcr3Ok3SmiPrLtFMdFiqrlIM1CiF6hQDVXbW7nBr7c4BVeXnP+d/+ctf/qaBXltb4/Hjx/z4449sbW1x7969Twz0T0XCVqvF69evD4uEn4l+a990qEP19fUdGujPXf/4j//IvXv3ftUYH0QTdnbY2Nj41ccf339KcDaK/rQD7UkbjiEfrUzvk+e8f/+earSFMCliG/TiGQ0RUknc2/k0W33rxl3ipjS+ccX0hubiVKKNT9r3r168phSs7eeD/XiGA8R0SW72tj/JXc8Xlhg/NoPxnAP9aQfWS166ud4nZcNbN+6ScRWwXPJhGfBgHfAgGbOfEDZePHtJMVAjNCdhOKNkvP3T0YNp4w8fFEpFO7tATJdGd8KK7pQN60UPZbFBI9E++KW/2rhB3lfCOuhl8gsdM3/SE1JJFAM17u8TL26v38U+4UGyZNCftDH7rRH7kEDakWc+v7R/Od+lkejQTi/gHQ5jG/LhuCyQdRUohxu8ePaS1y/fKFfczAKSMYNlvwCZF8rInhI3e1tKJGZxh/X2TWR3CdslD9oTNoIzcRKmLLKvyu6T5zy6+4StpR0Wikt4RsO4rvvxjofxjolEdWlW6us8uf+ErCjTrS6SsssEZmPEjBkCM3GCM3EWiitsLe5wa+02W0u3KIbqeMdEIjplrtw/FaciNri9fpeNhS22l3aoSS2CMzECMzEiuhSe4SDiXEKZ/b5xl63eNkvVNaK6NHlvWVlAPOfGPRykGmuz2lhXzPjabWRfhbLYoB7v4Nv/xKEutenmeiSFNM1cm0ZCmRivRBrkfBWM51xkPUWWqqu0Mwv0SiuUQ3VK4bqyOOkq4BgS8I6GqEQa9MorlMJ18kKFeqJLKVgjpk9hGxIIzkRJWHIU/FXlumuTKYdqdPNLFIM1vKNhhMmIQuawyeT9FfxTUbKuInlBKQGGVRL+mahS9pMXMF6z4hkOkvOWSFllisEakimNb0IkYc7RSnZoJDt4R4JKKVBskLLISOasckUO1UlaZCWSctWPdzSsjAX5qyQsWfyTMZqpLtVoi4RVxn1diWAlLTKyp4xkyhDVpygGa/TKK1RjLQKTUfyTEbKuAllnUaHpzMQORogWKytMnVbjGQ2R8xWVsqkmgfWS5wBhVwrXKYfrSPo01UhTGevZuMf20s4v3nT/ZKB/+OEHKpXKLzLOP/74IxsbG59QOX5eJCyXy7x79+5wkfAz0W/tmw51qL6+vkMD/bnrn//5n7lx48bfNdB37txhbW3tVx9/ePsxMUMaYVwkNBsnNCOR91c+md59++YtlYhC2HAM+bBe9CLOSax1Nj6Jetxc2ESYimI658R0zoV5wHPALD64Gt9/RsZVxHbRh3XQi/2yQHAmzlJ19ZOrcTPZZfibSXQn7Tiv+nFdDZD31z6Z877RVlblVEdNzH5rRH/KTtqZp5HoHphxZT2wiuOywPTXesa/0GIb8lEQqjy+83jfZL+gGm2SF8pY+l1ojpnRn3USN2dYrKwc/JkWyyu0kl2ECRH3cADjWRcpe55SsH7wJmF75RYBk0hQE8c84EZ3yk5EmyTlzLOxsL1/OX/GxvwmFbGBY0hAd8qGZcBNYDZOyl7g2ePdA4zdzd4WgakYwv7F3nk1gKhKsFJb4/mTF9zffsjm4jbFQI2wSiIwFcM/HSE4E6OdW2JrcYdnD3fZXr5FM9nBNyEq0+fTUQLTcXKeMjvrd9havEWt1KQUrRKck/BNKLlyJZ8t0ists7N6m7s373Nv+wGSJYfsq5C0yehO2nFdC1AJ1ffLhts8efCMRqKL7CtTj7fxz0iYzjmV0p68yFJljVtrt1koLZNxFci4SmRcRYznXITVCRZKK7QzCyxVVumVVhXzaFPYxtZBL5aLHmRvhW5+Ca8qSFGsUA43aKa6SKYs5gsuXNeCSOYsGVeJstigHGkoC4ZSm3qig3c8jPN6kLrUJONUliwzjgI5X5mkJaeMqFhy2Id85H0V5uVFSuEaSauyfqng97KkbDKWC24iuhSlYI1WZoHgTAxRnaCdmSfvqxDVJrANein4qiStMrJQYeKoCu9oiJRNVkZg7DK+cVH578r1SNny+KciCBMREhaZjKOA7Cvv/3NWoX7IPaK6JMJ4hHKoTtZVIGbIYL3oIedWpsM7uUVkT1EpTQZrFP0VUjYZw1kHeV+FYrBG2lmgGmlhHnARM6TJeUoUA2Ucl/1IlhyLlRUKgRqyUGH86CzCpEjOUyJpyeIdFQlMx6lFFepHJdJUjHSgxkJhiV5RyY3f7G3/qoH+y1/+Qr1e/0XG+adr9JMnT35hoO/du4csy3z48OFwkfAz0W/tmw51qL6+vkMD/bnrd7/7HZ1O5+8a6Pv377OysvLrj+88RBgNYzjrwnjejemsi5Rd5vmTj1GJ1y9fI3tLmC+4sQ96cVwP4LoWYKG49EkOe6m6huOyH80xC9aLHmyXfKSseR7e+UjreHjnEZIxw9x3Jia/0jP3nRH/dIRO5uOYysvdl1TEBte+nGTmWwOTf1SjPWkn6y0eEDaUnHSPnKeIddCD8ZwT1fcWIuoky7WPy4Y7q7epx9sI4xFc1wMYz9gRNQoq7OWuEoHZffycpeoqCUsWU78L3Sk75gE3SZvMWnudDx+UjPfm4jZduYfzih/jWQeqo2bcIyESlhzP9kuQ9zbvI/mTBGajBKejmM65sV7yEpyJsVRZ5fnTF7x68ZqtxR2q0aZC4LgewDMSIqSKU0+02Vrc4dWL1zy6+0RZd5yM4rwawD4kEJiKEjdm2Vq9xfayMlG9vXQLUZ1CmIzhuhbCeNaBezhEK73A1rIyIPLy+SuKoTo5V5GUK4/2hBXroI+8UDkoG853Fqgm62SdRcpiA/9UDOM5J2m7UsJbyC9xf+sB26u3leytJUdUl8J0zol7NEQ3t0grs8BybY1bN+5QDjWQvWXCagnjgAv9aQdJa45Wep5KpMXW6g7FQJ1meoGCUMHY78Y+5COmz5C05SmF6izV16jG2shexYiL6gTmAQ/FkDLJnvOUEPQhUu4cWWeBtCNP2pnHdM5NVJ+mne1RFhsUAnVy7iJ1qU3KlkfUJLBc8BCYiimDJVKXuCGNZMpSizVoZ+eJGzJYLniImzJkHAUSlhyhOYmgKk7CkqOV6tJMtHFdDyFqUswXlsl5yoRVCQKTIsVglYQ5Sy3eRhgTCU5HKYaUpb6EMcP497NUo02KgSpxYxrvaJCwSiJpzVEK1SgEajiu+MnY89SlNgVfBfc1P6Jaoi51SFplisEq9ks+QnNxct4StXgb/2SU4EyMbmGJZqpL2plH1CYJqSQyDuV7FFJJeIZDZN1FeiWF3Zyw5Ehac6Ttyvqn66ryc5605pC9ZdrZBaK6FLpLZlLWHGlnAd9kBOdlPzlPiYyrQFVskjDnSJr30X+OPO30PLVYi5u9nU+Qlh8+fOCvf/0rP/74I3t7e7RarV9knH/88UeWl5fZ3d39hYF+8+YNqVSKH3744XCR8DPRb+2bDnWovr6+QwP9ueuLL76gVCr9XQP96NEjFhcXf/Xx2xt3sQx60ByzYjjtwHTBTUgt8fTBz4ZNdl+SdhSY+ZORyS91TH+lxzroYb7wMSu9t7dHO9PDdS3A3BEjM9/omfmTgZRdZvdnZb2d1dskbTKOSwL2S140J2wIk2GWax+v5M+fPKeR7DL67TTOIT/mAQ/OKz7y/grP97nGb9+8ZaO7SdZVxNTvwnDGjvq4mbAqwVr7Y2Tl3uYDVqqreEaCGM85mPuTEcuAh4Q5x9P9mfFXz1+xPr+plM6mY5jOKtnlwGSEXmmZ509fsLe3x73N+zTTXQLTURxX/NiGfEQ0Ccpi84Cw8eb1W6JuCc94CNslL4YzdrzjIuFZic3eFtvLt9jb22P38XOStjxhlYR10Iv+lB37ZYFatM3NhS0e33+6v+64TNZZJGWVMZxxYb3gJeUsMF9YZmNBGZZRCpAFZG8Z92gI80UvYW2Kbn6RVqbHozuPefrgGcVgnYRVRpiMoj/jwHTeTS3RoZXuslRfo1XvkHTJVKJtoro0mhM2NMesiOoE1ViTaqTJk3tPaaUXlEEQsYl10IvhvIuwWiJlkSkGqmyv3mKhsEjaVaAYqBIzZjGcdpKw5qiITXKeMouVFXqlFSVuYM4S1aQxnXfhvBagLrWpRFoUQzW68qIymR2sE9ZIGPqd2IYEJHOOvL9K3JjFNu5BsmVYLK1QDCojKt6pMDlPmag+RVidIG7KKqMukSa9wrJCkLjqp5nsUg7WCExFiRkzVKN1UtYc1WiTiCaJ9ZKHlFWZsY7qU0S0ScrhOq10l4Q5h2TKYrvkJWnNkbLlyXnLOK74ie/zk2tSi6guiedakGaiQ9ZdJGWTsQ8JzJ7XETemaUhtkpYcvnGR0v4UdtZTJDQXRzJl9guGOVLWLPYhH8l9Uz5fWCKkSpCwZCmH6uQ8ZfxTUSyDXuU6bJWpxlrEDRmi2hRpR56Cv0LMmFYu+L4yZbH5yZuDuqTQXOL6NLZLXkSVRK+8QllskvdVCGsk3GofrVSX4HQU26AXx2U/pVBdWUr0lMk6CpTFOr3SCs2UwuBeKK3w8vkvOxs/Gei3b9/S7XY/Mci1Wo0///nP9Ho9Xr58+QsD/V//9V8kEonDRcLPSL+1bzrUofr6+g4N9OeuY8eOIUnS3zXQT58+ZX5+/lcf31zawXlVQHPMguaYmZk/6RHV0sEAx08X2rS9gP2SgGNIwNjvwnrJy0rjY4Tk3dt39EoreCdE7Jd8mM8rV+GMs8CLZx+v2Xdv3qcYqmHqd6I5YWHmWwPua/5PuMwvd1+xUr/BxNFZLANuVEeMaI5biJsyB1i5vb09ZV1PqBCYVqauTf1OApMROrnewWreq+ev6Mo9ZRnwvAvjOYUjLAslNhe3D/LN97YfKHnXS17mjpixXvQgTCpz3j8RNt6+fUddaitX135lcMUy4KHor3Kjs3nw8XQmkiNqTBI3ZTCcc2Md9O6XsJbYmN/k/fv37D55TsFfIWGRsQ/6sF7yKYi63ALNRIcnD5/x+tUbGlKXtKOAeyTE3BETutMOJaMbb7PWXuft23fMFxapiA3ipizqo1bmjpjwTcbI+2vUYm1evnjNjc5NCkKFqtjAdS2A4awTz6hIwqLECe5tP6CYLBHSxkjZ8oTUCYz9brwTIuWIQopYrK5yf+cB5aBCeAjNShjOOdGesFMUqorJCtTYXtmhEmnSTndJWnJoT9ox9jsRtSkkU5aIJkUj2aEabbGQX6KVmsdxPYD1koesu0hYnSQwHVMIFsEapXCDxdIycXMWwyk7srdMJdLCPxUj4y4i6EIk7Fmq0SYZZwFDvwP/dIyy2CCiTxPSpKhGmnTkRWRPiay7iP2il4g2iWTKEjNmcFwS9tf4qnSyC+Q8JXxjYTKOIpVIg6gujeWCh4yrtJ9/rlMMVAjMRInoknTkJSrhBr6xMDGtUiRMmHOknAWcVwRixjQZh8JKDs7ECM7GMY3aqUabiNok9iHl359xFMm5i8T0aYTJiHJlDtTICyXsQwJJa45uvkfGkUcyZXAPh5SrulUm6y7ivOonMKNkn+fziyRtBUR1klqswbzcQzJlcVzyIUyIJCzKG4OCv0JUlyLvLdHO9qjFWjivCvinIqRsMjl3kVKwjn86StaTx3DZRilYwzMSwnk1QM5bQjJnKQgVorok5XCDaqxFxpGnkeyScxVZrq2xtXTrEyzkzw30q1evWFhY+MQgr6ys8PTpU7rdLm/evPmFgf7xxx9JJpN8+HC4SPi56Lf2TYc6VF9f36GB/tx14cIFfD7f3zXQz58/p91u/+rj28u38I6HMQ+40J+xoTtpI2rIfGKgXzx7STXWwnzeifp7E9Pf6NGftnOjtX7wnPfv37Mxv0lEm8B83o3qexPq702EVRLPHn68Zj97tEsxVMM3EcbUr5he71iYdmr+oPj3/v17NhY2GftuFu1JK7rjFrxjYVI2ma2lWwf55tev3pB25LFc8DDzJz26UzZc1wKK0fv5nHfrJnFjGt1pO4YzDkz9TlK2PGvtmwfZ5WcPn5F1K6MT+rN2nFcCBGYlGql5bi5sHcQ4mqkOcUMa/VkHxnPO/TnvDvV4++C1Ik6JmCmJ+1qAqS+VmIq0vwy30VNe69baHQr+Cim7jOa4lakvddgvC+TcZRqJLq9fv+Xx/cfI3hKFQBXnNT/G826sgwKSKUvOW+Hh3cc8f/qCcrhB0pxDGI9gPOvAPOCmEFCGP5aqa7x+9ZparEXBXyWsklAdMzH3nYmILkXeXyHjLPLozmMi9gRZf56K2EB/2ob2lA3fWJTgnERoLkE3v8R8YUkZIyksIe5j7CK6JGF1Au+YSDFUp5Hs0k516WR7yL4KhjN2hMmowhuejpF1lViqrimZ5WSXYqCGbdCD9YKHlLNASJ0kMBWjW1CIE/V4h1q8jfNaAGFMKdj5pqLKcI5QwTHloxCu0Ep2iRnShOYkalKHqDaF4ayLlCNPJdIi6y5Ri7WQrFl8EyLlcJ16ooPrWpDwjMTCTxdUV0HBMGqTxI0ZSuE6wdkYntEQpWCd+fwSGXuRwGRUYTOH6vtxFoXpnbBkkX0VarEmwrhI3Jylm1+iIjaJ6tI4rwhUxQaqAYMyhT4dIbKP55svLCF7SgRn4uS9FRaKS2TdJQIzUYLTEdJ2mbxQpRprK4VAm3Jl7haWCM1G8YyEqYQV1F0pWMUzEkL2lEnb8pTFOqI6jnnARXqfFZ125H82Eb+AZM7hGQ0y+70J59UAGWeelC1H3JRG9paoJZq45wTsQwqX3DrgQlQnienS+KZECkIF2Vc+uD4XA3WqkSa3btzZn/Te+YSk85OBfv78OUtLS5+Y47t377K1tUWrpXDp/5aBzmQyPHnyhB9++OGwSPgZ6Lf2TYc6VF9f36GB/tw1OjqK2Wz+uwb61atXNBqNX89A33pIWJ3ANOBEc9yC+rgZ31T0E8bzu7fvaEgtXFcEjOccmPpduK4HqMc7n2CpHt19QmA6iuqYGfVRE7ZBD3FDms3F7YN8897eHvVEG+N5B1Nf6VEdM2O96KWbW/ikbHhv6wFz/Tr0p20YzjownXcR0aVYa24c8GTfvHpDRWwQmImiP23HNRzEMxyiGm19Mom9WF4hakihPW5Ge8KKZcCjlMninYPXun3jDrKvjOuqn6kvtEx/pcM3HqYYqB281pMHzygGq6TdRTSnbMx8o8Nwxk7SItPKzvPu3TvevHqDoA0h6uPYL/mwDHrQn7YhmRVT9VOGuy0vkrLKeEdDzH1vwnDWjbRvvJaqN3j//j1r7Q3KoTqSIYP6mIXpr/W4rgdJOWTSjgJPH+5y68YdarEmrVQX+2Uf6uMKQUQYFwlOx+gVV7i1fpd2WlngS1pzmAfcOK8FCM3G8YyKlEINVurrRB0J5GCRUrCK/bIPwxkldhGci5O05bnZ26IabrJcW6MSaeK+HkB/xkl4No5vIoJvPEI312M+v0xdarNUXSM4K+EZCREzZLBfFrBc9JD1lGhnelTEBsvVVfJCBd9EhLxQJWFUuNEJS45urkcpWKMsNigFlDddcWOGSqSF62oQ32iE+cIygj5E3JxRVg/nJKKGDCl7gcB0HOOAm6y7RK+0QincIGWTiRvSVGNNUrY8wqQSeYjo02ScBeqJ/cvxPtu6mZ4npk9hvehVRnT2y45pu0zSkiGxz8guiy2cV/0kLDkWCksUgjWS1hzhOYlSsE7ClKUSqislUHWCvK+CS+sjYcnhGglQibUp+GskzFk8o2FihgxZZwHZWyJpyWE67yKoSlCNtcgLFcIqiYg2QVdeJOsqENYkmDtixHrRS0gtUQrXEFUJEqYsjUSXheIS4TkJzTEL7pEg3pEQEW0S73CImCFN2lGgkeiQ85TQnbbiHg4RVkkEZ+LYhwTCcwlq8TZhrYTxsh3HkA/DGQeiOkFgOoZ/KopnOEgn16MWa5LZR+LFTGmFlpLtsbGwxa21O5/8nP+UX3769Cmrq6ufmONXr14xPz9PvV7/hBf98y9Zltnc3OSHH344LBJ+BvqtfdOhDtXX13dooD93aTQaZmZm/q6BfvPmDdVq9dcN9svXRHQp5o4YUX1vQnfSSkSVYHv19ifPW2tvYDrvYvYbI+qjZoz9LirRJi9+dk169miXpCWHYZ/CYR30IkxHWW2sH1yN379/Tyszj/t6EN0phd7gvOpH9lY/RdSt3WbmrJbZbw2ojprRnXIgmbO0Uh8JG7uPdikHaziv+pn6SsfEHzWYBtwUhAqP9ouLb9+8pRZvk3Hk0Z+yofrezOx3ZuL6FN38x+LiSn0Nab9EaDznQHfCRkQtUfCVD1YS76zfJesq4h0NM/21HtVRE57hEDlPiaXq6sGbCM9cgKA+hu6EjYk/atGetCGqkyRteZ4+3OXV81fU4m06uR7eURH9KTtzR004rgQQJiN084s8ffCUldoanewCGVcJ+2XlzYtnJIx/MkopWGNrcYeV5jrL1VXK4TqOywKaExbcwyFC6gRRQ4at5R3mC0vcaN+kIy/iGQlj7HdhH/RiG/ThHgnTSHS5ubBNQB+hU5onZZMRxsMI0xHM+/i8pC1Pr7hMM9llpb5GQ2ojTESIGlNKVOW0k4g+RSfXo5tbpCw2aKXmCUzF8I1HyLgKOIZDOK74aWd6dOUlKpEWtXgbUZUgqk8TN2VxXg+iP21HMufoykvU4m0ayS5Jq4JrK/gVZJzhrANRlSBly+NW+Ul7ZMpiA9lTppmcJ+MqYTjnJOkskPdVSdryFPw1ZY7bXSLlKFAKN3Bc9e8TS3pUIm2yvgpJa5ZarEnanidlk3FdDeIZCZOyyrRzi+TcJUIqCdlbop2ZJ2mR8Y6G8Y6EyboKpKw5ct4SpvMuPKNhZG+JVrpDaDaOdzRM62c8ZdUxM67hEO6rAWSfgvLzT8UOyp05TxHdKRvusRChGWUEJTwbwzcWJuVQrtGtVAfDWSf2QR8ZR35/5CSAY0igLrVJ2/Pk3EUcV5WCb3hWImZIIUxFsA8KVOMtJe5hyeKbCGM851QM9Gwc11U/9isCkilDV16iIFZQndXjnwjjGQsRViu0GcsFN2GVRMKWYz6vRIoS++uUDanNSn1NMdHdzU9IHD8Z6EePHrG+vv6JOf7hhx8ol8tUKpWD5/3fjxeLRTqdDv/1X/91WCT8DPRb+6ZDHaqvr+/QQH/ucjgcXL9+/e8a6Pfv3///lg1fv3xNyiFj2r/y2i8LuK4FWP1ZPOPDhw8s19cwD3jQnrJhveDBdslLyi7z7GeZxsf3nxAzpJn5k4G5b42ovjfjGw8f8I8/fPjA69dvqUZa2C/7mfxSx8SXGtTHLGS9JZ7+LOqxUr+B+oIB1fcmVN8bmTtiwj8dPTCqP+WWU/Y8hjMONMesaE9YlBiBv3rwMfHzpy8o7zOLJ7/SMfWlDu1pK2m7zEpz/WcX9jayUMFw1s74H9WMfaHGfT1Ayprj2aNd9vb2WKqt0Uh2CM7GsV70MPmlGuNZB8J4mI68yMvdl9zdvI9oiSEaE9iHBPSn7RjO2QnOxsn7qtzs7fDozmNutNapxdo4rgTQnbQze8RESCURmpW4ubDNxsIWG91NbnQ3CEzHsA16UR8zYzjjwDYkUBEbbK3cYqm8sj9s0iAwIeIbDaM7bUN/zknUkGKhsMJyfZ2V+g16pWUC0xEC0wqb2djvJDgXo5PrsVBYJu5MUorXENVJvMNhRE0C25AP04CLaqzFfGGZdloZG4kaMko5zZDCNOBBfcxKSJWgkexSi7VZ79ykJrXJeZWimnskjPakHe+YSNKSoxxq0Mn26JVWFOpHqEFeqGI45ySiS1HwV/cXEJWyXDFQIWHOkXUWcV0LYrssUIk2aSS6WMdcyKEylUiTYqCGZMziuBbANOAhbspSkxSKR8KmIOdamQVKoRqe4RD2ywIZZ4GkOUfaXlRiIpMRItqEgsQzZ3AM+ahF21SjbURNEvtlAc9IGO9oSBl28VWwDXpJmDK0MgtUxAaWi17c10OkbXlc1wOE5iRsgz6SVlnB1qUXGPrPEawXPcr4iT2P66of55BAQaiR85bJOAoIY2G0J634xkQS5iyiKom5303WXWBhv4QZUiXQnbIRmFYYzsHpKPpTdiWPvD+rnbIVcFwSCKniRDQJvCMhVEfNhObipCw5KpEmlXADVl3QnAAAIABJREFU2wUfoj5BaDaGqJFQfW9GmBQpheqkrHkSzhxTx7QEZ6KE5yR842EMZ51YB72UI01q8TalQI2kLbeP41PecFTEBuVwg43eFru7uzx79ozHjx8flAMfPHjA5ubmL0xytVr9ZNb7519//vOfqdVqlEqlwyLhZ6Lf2jcd6lB9fX2HBvpzVygUYmBg4O8a6A8fPlAsFn/9Av3iNZI5y/TXBma+NjDzjR7zBS+rPysIfvjwgW5+EdtFD1Nf6Zn8Wsf0NzpSdvnTguDWA0SNhOa4hbkjRua+N+O6Gvi0IPj8FbJQRn/Shvp7E6rvjJjPeygEqgeEjb29PVqZeSZPaBQz+wc1E19pETUSN35G2NiY3yTvr2A572bmGz0j/zqD7pQNyZw5IH88uP2YWqxFVJPAdsnL9Nd6Zr4x4B0N0c71eP3yDa+ev6JXXibvr2C95EV/xsHkVzqCKomMu6Rg5V6+VlBv+SXcI0F0J62M/kGF81qAwEyUtdY62yu3ub/zEDleQJgVcVwWmP1Wz9y3RiwXPRT8VW72trm9cY/NxR3m84sEpmN4R8PMfmfC1O9GVClZ4/XuFrc37rLSWEdUJ/CMiNgGfZguuJXMeHqedmaR7ZVbbC1tEzem8VwPK9fZM3ZM/W5koUJHXqSb6/Hk/hPKoQZxY5a4Lo3+jIO5IyY8oyEqYpNypEU136CaqpN1F5XhnKko2uNWZT3PnEUWqixV1ri7eZ+cu0zGWSRlz2M878IzJpIXKqTtBRqJLrfX71IONUjb8sT0GeWyfMpOPlBRimWeCjc6G5TCDeqJDml7EcugD8M5B6E5ibygrBIWg/WDEZVqrIV/Ooqp30XSphAwovo0qn4jnvEgwdk4BaFKzlfBcMZJyp6nnugiqhIEZ+L4p5Q8t386SsquTJ97x0QqkSZlsYF7OIRvKkLaWSQ0ozC1LQNuwnMSSYtMwV/DeUXAPuQjoklR9FfwT8dwXBKIaBJUI00kY5bgTAzdSQv+6ShRbZKss4DxnJOQSqKd7VGX2sSMKQb+1zUkUxr/RARxLoH+lB3fqEjKnqcjL5LzVbBf9BGajZO25xHGRfQnbDiu+Mi5FWZ1LdbGftmHd0QkrEmQssvoTzswX/DQTM+TdZeQvWWEyQjesRCBqTih2TimC270p23InjILxSUKQpWkOUtInSBpk3GPBJk7akJ1zIhj2I8cLJILFrCNuNFfMeOa8OEY9zH65QxjX8+gPmvEcNmGa9bL3Hk96otGdJdNmMccuHU+zGN2BGOAfCZPo9Gk2+2yuLh4YI7v3r3Lzs7OL0zy8vIy+Xz+bxro9+/f02q1qNVqB9fswyLh/9v6rX3ToQ7V19d3aKA/d2WzWY4ePfo/NtDPn75A1CTQHLUwd0Qp/hn73dzsfZz/fv/+Pc1UF+1xK6rvjEx9rUV70krGWeDl848rg9srtwhMRZn+Rs/EH7Rc/7dp3NeCn7zWk/vPyPsqOK74mDtiZPjfZpn4QkPCnDngMr95/ZZOdgHtgBlDvw3VEQOjv5/DdT1AV+4d5K43FraoinWsgz7Ux82M/16FdyxI2pZXyoZv3/H43hNWmjfwT0bRnLQx+h9zaE5YESYiLNfWuL1xj9cv33Czt01FbOC+HmT6Gz3jX2gwn3ORdhZZ3//Y+d7mfRbLK4RVEt7RIJNfaLFc8CBMRelkF1mf3+LV81fkxDzuiSDu60FUR82YB1w4rwaoSR2ayS4P7zzi2aNdsu4S3rEw1otepr41ojlhI2HO0kovsFBc4c2bt6w0bpAwZYnp0mjP2hWE4CUfBX+NSrjJ0wfPeHTvMRlngUKgin8qhv60A9OAW0G3eUqsdzd5/uwlFbFF0iIT1acxXXBjHfSRdhXJuss0Uwt0ml2SnhyyoFAZjP1O1McsSMYMNalN1l3i1o07dPNL+8MzFayXfKiPW/CMhEja8kiWLJVom1aqu0/LaBI3ZtCfdhCalUiY8wSmYsTNWTL7tImUNU/GUVS+lxMi1UgLUZUgokspVA6VREyXIqZNYrnkw9jvJucpIfsqeMdFtINWwlqJlE1GMqQxnnNjv6yg5BKWHO5rIXxjIhF1krxQIWHO4h4N4bwWpBptkLTKuIdDmAc8RPUpQnNxZE8J75jypqUUqtNKLyDqEsrQiDF98DzXtQCmfhdxQ5pKpHHAbvaOhij4q4iaJI4rAvpTdmShQtKi4PecVwSufDGuEGG8JdzDyicRlUidWrRJwpzFNxEhpIrjGxcRJiN4RoKoj5mRzBnmC8tUIg1EbYqgKk7GU8A5LKA9bWXsCzWOER8BTYS0kMN23YNt2IVr2odrSmDi+zmG/n0c7UUjmgtGDNesqM7rmDqpQjNoRHPJhOqCkSu/H2f2jA7PrID5uhP7mBfNgBHXrA/fTAjrZTeqEyZmv9cT1sSJGVOkHDkS1hw1qUWvtEzOVaQcrpNyFLjRvsnW0g63N+4d8KCr1Sp/+ctfuHXrFnfu3PmFSb5z5w7ZbPZvGug3b97Q7XZZXV09LBJ+JvqtfdOhDtXX13dooD93NRoN/vjHP/6PDfTTh7uEVRJT3+gY/4OK6/97Bs1xCzurtw6e8+7deyrhBo7LAnNHjIz+xyzD/2eWqDbFqxcfDfT6/BZRfRLzeRezfzIw/kc1lkEv89nFg1+YTx48pZFoY77oYfIrLeN/1GDsd5Iw57i1dpu9vT3evHrDzYUttOfNTHytYuQ/Zpn4gwbX9QALheWDfPPdm/dpprp4xsJMf61j7A9qtCcVE7reucmrF6959eI1q411RE0C51WBsf9UYRrw4B0N00jNs9lT1gEf3n5Eyi7jvOJn/AstutN2bEM+isEajUSH509f8O7tO+bziwhjIoazTib+oEb1nYnQbJxarHVwaa8VmwizIjFjFu0pOxNf6tGfdZJxFalE27zcVaa6y2KDnKeEZzSM8bwb7QkLUX2GjKvIztod9vb26MqLJK0yYVUC3UkbhvOKMc77K3TkHm9ev2G1tUHBXyVuzqE/ZWf2WyPekTClUJOsq8S97QdsrdymEKxRjjRxXA0yc8SE6bwbUZPcx5y1KMSLBHVxZF+FuDmD4awb13CQiCGtIO+sMp1cj5StSMIqEzdksF70YjyvXLvD6iRhTZJWboGwOknOreDNjGddCt1FlyZmzCBMRsn7q6T2M8alQO0AjxjVphA1CeyXBQIzMeKmLGlHgZy7SNKaw3DaSV6oknOXsVzwKtGQiyb8M1ESFpmEOYvxnBNRm6aR6CBqk9gGfcRNWTLOAhF1UomvnHfjn44p6LpAFcsFL4GZmMLctucJTEcx9isEj7Q9j2TJYRsS8E9G8IyEyHmLBObiWAe8JMwZOtkeaXse90iQoEoirJFwXQ8SmpPQnrISmpOoRJrUU218EyLO0QCmCTvOUT+6s1ZGfj+Dc9SLfcRLwBDFeMWBpt+IZdiJa9bH3Dk9g/82zOQpNYZrFub69aguGhj7dhr9ZQv6KzYckx6Gv5pm+piGgC6Edy6IZzqI8aKThDuLaJTwz4roTlmZ+U6HdzxEzlsi7SgQM6YphWosVVaU0uI5F/pTdhxDAqImSUSbRNQmCOpjBA0RKtEm9ssC5gEPwngEYTJCaE7CflmgHKrv4/+atFLzZD0lKtEmGwtb3N18wPbyLR7fVxjsS0tL7O7usrW1xb17935hkl++fEk6nf6bBvrly5f0ej3u3bt3WCT8TPRb+6ZDHaqvr+/QQH/uWl5e5ne/+93/2EDvPtpVrpsn7cx8q2f6GwOq41a6cu9gZfDtm7f0SktYL7oZ/6OayS+1zHxrRNRI3P0ZLu7Oxj3Sjjwz3+gVk/2vs5jOO+lkF3m+H6l4ufuKrryIdyzEzDc6xn+vRnPUjKhJsN69ybu379jb2+PW2h10Fy2ojpsZ/b0Kw2kHzqt+KpEGdzfvH1yqK+EG9iGB4X+bZWY/KpFxFWkkfkbYWL9HeC6O/pSd0d/PMfW1HtcVP8VQjVtrCmHj9as3FIQqcXMW9TELU19qUR0zEzdlaCS7vHnzlr29PRaKy2QcBRyXBYznnWiOWQnOxMjsG9UPHz5QSJbxzYkEZ6KojpjQn3Lgm4qQF8p080u8e/eeh7cfU/DXSNoK6E87mPpKh6HfRcZVIO0q8uDWI148e0khUKcSbeEZE1EdNaM5acU7GiEwFaUmtXh8/wk1qaOMsmgTmAZcGM+7EKajuIaDJKx5buzTPLKeIjFdat/Q2gnNSYQ1CcKzCZab6zgmfIjGJLK3jOGci9nvTbiGg/inYvgmIpTCDWqxDnFjlnZmgfBsfP/PoxA/TAMuQnMSsq9C2lEk7ytTDNUw9DsJzSbI+koYzjjxjolkPSUSlhxxY5a8UMY+5MNywUsxWCOiS+6vDVbJOPIkLDmi+iTu4SD2IQHJkiNhyWEe8BBSSxiu2JAsGWL6FMKkiDARIectE1EnMQ248YyGCc9JxI0Zoro0/ukYwlSEutShGKhjv+zHPxkh48zjHQ0TmpOwXPTiGg0h6pMUxSqesQDGCw5SvhwBdQRtv5mJ79ToB21Yhl1YrjvQXbIy+qdZ1BeNWKdd6IbMXPtynInjc1innagvGlCd1zPy9TSmaw6mzqgQDCLTxzXMHtcjzAWJu9P4ZkXMg04SjixplzJfbrnkQXfaiuOKQMaRpxisEZqVyLjyzBeWKAXruK8F0R6zIIyJeIZDSKYcnutBZabcXaKdW8C3//coYkgTnpXwT0awXvQge8vkvGVStjy+yQjT3xiwDXqJGVOIqgTOK37ipgxpv4xrzIf1ggvVcQsTX2mVvx9jIp6RMCFVnGq0Sa+0TClQo+CvkPOWaafn6cqLLJZX2Vm7w4Nbj/jw4QO3bt1iZ2eHjY0NHj58+AuT/Ne//pVEIvE3DfTu7i7Ly8u8fv2abrd7WCT8DPRb+6ZDHaqvr+/QQH/uun37Nv/yL//y3zLQpVLpgDbxf3+9ePaSnK/E9Dd6xn6vYvT3c8wdMdFMdQ+4zHt7e6w1b+C+HmDmGwOTX2qZ+9aAMC6yMb/5Md+8+5KEKYv6mJnxP2rQnLBgHfKS91V48uBj2XCluY5l0MvI/5lm6kst+lM2oroknexH0/786XMsw26mvtEy/O+zTH6hw3Teheyp8OD2o49Z6fQCcWOGue/NzPzJwMyf9ITVSdrZj4SN7dXbpGwypvNOdCdsygT3cADZU+LxfQWp9fTBM2RPCf94hOlvlfKiddCL7KswX1phb2+PVy9fU4k0yXhK6E7ZGf+9GtX3JsJqiaSjwJP7T3n37j2SK0VAF8U9qhTApr82YLvkwzsm0kh0lKt4awPJKiP+dFnuV4pYnlGRpC3PxsIW652bCgrMkEZ3ysHsESOmfg+iKk5IJbHa3qCTXaQQqFGPt3Fe8TP9tR7dKTvWywKesTD5QJXV5gYxY5b5/BJpe0HBAg54cF4LYDjrIjAbo5WaxzUbQDQkqEtdHJcDmC74kKw5jP1uPGMi1WhLuQZ7K5SCdbxjEbQnrET1KQIzcYz9LkrhBrKvStpeQBaqBGbjWC74lAzyTBz9WQfCeJRyuI5kUmgVaWcez1iYpD1PVJdEf9qBfchP3JxT4hLaFFlXAe+YSNpRUK7oQwKuUZGsu8jcOSOOYQFhSsRxXcA1EiBmTeIYFZg+aiBkjOM3RDBesqM+Z0QzYMJ83YH2opmZMzou/ccYkyfVmMccmEZsTBybY+KkCvuMB9uEG9U5E6NfzWIbdmEd9hDURzFddqM7a8E17ifnLyDZMpgH3cRMaUrhOpI5g38iivGME+9omMB0nGqii3s4QESbop3tYZ10IExE0Bw3Ezdl8VwPEdwndYjaBEmLTDs9T9SQZOZbI8HZGBmHjOd6AMcVgaguRSlYU95gGFOM/UGF+pgFUZMkYcliG/IRmokxX1ymEKzhHROZ+dbA9DcGzANuBVF3WcAzFiTvr9ItLiOqJHRnbejP2jH2u3Be82M4bcd5LUBUn8KnCuOdDWI578J+yYf1khfbJS/Gfie2S979OXCZSrihrB4aMpTFOrK3RK+8SiuzwGpz/WPJ9/lzFhcXWVtb48mTJ3/TQCeTyQNe9M+/Hj9+zNra2sHs92GR8P99/da+6VCH6uvrOzTQn7t2d3f5p3/6p/+Wga5UKrx9+/ZvPvb+/XuKwTrjv1cx/oWama8NmPpdZN2lT/LND+88xjbk4+r/mmLsP1XMHTHjGQ2x1vxI63j79i2lYA31CQvD/z7LxFda1MdtyN4yu08+lg3X5zeJaBLMHjEopvdbPd7R8CfLhk8fPsM24mHmWx3qoxbUxxRDm/eVDn75vnn9hlqshX8iwtTXeqa/1KE9YSVhzbFcv3FgsnulVbKuPLrTdia+1DD2n2qcVwXSjgLP9pFaWyu3ybhLuEdCqI/ZmPxKi+p7M56RMK3MPG9eveHpg2cHmVzVd2a0J63MfGtAmIySsOW5ubjNk/tPCRujeKdD6E/bmfxCw+RXGnzjIuE5iZX6DTYWtqjHO7QzCwSmI0rc5QsFd+e4GiDnLrG5vEM53KCdnqcYrGEd9KA77UB3yorxjAv/RJSOvLiPCevQkDoKou6sE9c1P6YLbpzXgtSkDpVIk4K/Rjs9j38qpsRTLgk4rirjLFlPhVZqHut1N7lQgaRVxnktiO2KH9dwEPVxC44rAeqJLklrjmJQGUvxT8cRtSlEXRrNcRumAQ8xk5JtFjVJZe55Jk5wOkYhUMVxxY91yItkzRLWSvhmIkQtKZyjAqYhN56pIKYrTka+msM5KSDowlhGXJhHHajOG9ANmVFdMDL63SyD/zrM6JFZjMM2dNdM/H/svcePXOd6vcuB/wPDgAEPf/DIAxtnYhjw0Pf6/I7to3OURQWSEnPuJjvnUDnnXLtqV845V1fn3Mw5SCQlkSIPg4JlyAPDzx1sipYsy8fXE0F2L6BANL7NZoFokKve713Psow4cU768KtDRO0pXBMCyn1GnGNBgqoYMXOGoDKOfzpKWJOkHGjQTs7jGwuTNBSZL65QcNWJG/L4RsMkDHmiqjTNaIeoKkVIkWI2t8JyZYOkoYB7MEjGXiZlLBBVpYmoU4iyBHlXjdn0EtVgE9MxCVFXDc6QMhYQJqNEVCnmMosUXDVMQ3aUuyUKjTAWpRqaQRiPEpInWSpK+/JZWxn9ITumYy4cPQLCRIyQPIl7IETZ32KltkknOY/ttID1pIeQMimx2gdErN1eKkKTkrfObHqBwEQM2ykvoak4wekEzv4A1i4vJV+TZnSWgrNGVJvGfMJDYCqKdziEsy+ItdtHTJNlrbGJqInhGQ/iGw0jTMQJTsTQ77djPunB2R+kEZ5hq3OWdmqBWrDNTHKBs/PnpZ/B6BzzueXv4Sq//vprZmdnOXv2LJ999tkPTPJXX31FrVbj4cOHPzi7e/cuV65c+V7t93aQ8Oetn9o3bWtbO3bs2DbQ/9P19ddf85d/+Zf/JQO9sLDAkydPfvR8ubaO+YQP5S4Dmr1W9Adt1MQZnjxfgfjqKwkZlzBkMTxf8zAeceEfi3D97I0Xzzx9/JROagHLCS/m4y6MR1y4+4O0YnPf25Xemj1PWJVCs9+Oeq8F7T4LGUvxe2HD21c+wq8MoztiRbXXjPwdA+YTXuqBGX738HcvpuetyCzB6QSGQ040e20o95gRp5OsNaS962dPn7FYXCVpLGA86kB3wIZit4GoKk3RW+fa2Zs8e/qMM7PnaYQ7uAdElLstjL2mwT0cJmkosDV7nlsXb3N16wZz2WXy9irWbg/Tb+tRPw8SVoUWV7euc2n9Kjl/iYwnj38iiqs/iOxdA/aeAGFlhtXaJmfmLrDRPsdScZWYNoNnWGpSdA2IBMbjzOaWWKluMJ9b5uLKZTK2Cs5+EWu3H8tJL85BkaK7znpTaqm7uHKZuewyIUUS/0QEV38Q3SEn7qEQ87kVWrFZZjNLnF+6RNJUJGkqENPnsHT5sPb4ydgqNCJzCOoYrWyHrL1CcDpBxl7CNxbFdtpH3JwnbsqRsOaoJ9sIigj2IR+eqSD6LgcT72uxjvgIGKM4pwQCxhAOuQ/TsAPbqBvFUT2Db8mY3qfDKfPh14bxqkRijgwBTYSEM0vEkER9yIpzOEDEkCJqSBPTZ8g6SiQtBQruKu3kAqI8RVCeZD63QtHTQNdlIWbIkjIWSZkKFFw1aYe5L0gt1GGxtEbaVCCizpI05cm7aqRNRaJqiXOded7EVw40cfYHEafjZO3SvnZEncY3EmUmuUjZ16ToqmM45sZx2o+7XyRjLRPT5PCORWiEO6zWtih5m1i6vBiPufCPx3D2BoipUlhOeMnaKlIDY3Wdsd1ydAftpK1S0NDVK6A/4qDia1J015lJLRBWprB1e/EOhUmbCngGgxiOOsnYSizkVyl7GiQMOSxdXnwjUTyDIsJEFO1BG8HpOIsVqRo+Yy3hGw4TU2cQJqJYTnhR7zHjHQpRcNVYb5+hEZYMfNJUIGur4BsJI3/PiDAeJWerSDc0thTmUy4ylpKEsjMVMJ90E5yKUQu1KPkbzCTnyT1HEXZSi9TFNuvNM8wkFzi3eJF7tz7m8SPp36NvvvmGTqfD5ubmC6Tdd1+ff/45MzMz3Lx58wdnH374IdevX/9e7fd2kPDnrZ/aN21rWzt27Ng20P/T9S//8i/8+Z//+X/JQC8vL/Po0aP/8OzbZkDTMRfG4040+61Yutw0Qh2ePQ/+ffXVV9y+9BFhZQr1Piuq963IdxkJTsa48Z3Gv4f3f0ctOIO9x4/qfTPTb+tQ7TFREdo8ffJvNd0rlQ2EsRj6Qw4U7xmRvaPHOxJhc/bcixWOS2vXcI4JTO/RI39Pz/ibGoSJGAV3jVuXPuTLL7/k7s17NKOz+EbDKPdYGH1Zie6wk5g2y9bMWe7evMejB4+YzSxRC7Zw9ASQva1j/HUt9lMCRW+dy2tXeHDvAVudc8znlwlMxvEMiIy+osR+2ocoS7L6vEXt8sY1Ntpb0r5vr8D0u5KpF8ajzCTmWKmsc3H1Cp3SHFFjEvdAEP1hB7JdJpw9AVKmEivVTRbLa1xev8qZufPENFmC8jjag3bUH1hw9gZpx+aYSS1yZv4Cl9aukndVSehzCOMxrKekFZS0pfS80W+dK5vXKXrr+MYj+CdjWE55MXa5EKYjRPQpko48C60lIpYUlgE35gE3sgN6ht+SozxqxKUSsE14EOwRQq4ohkE71kkv6pNmht6UM/W+FtdUAL8mTMgYZ6Y8R9SUJGnPk7Dl0Z9w4ugPEDflCKvTJAxSlXbFJ02zK0KbiCqNo0/6MJX3NAirMrTic88LZhqUvA2C0wks3QJpa5nZzCIJfYGCpybtLltLVIQmEVUae69ATJ+l7GuSspRQHDYiKlJENTlS1hJFXxPbqQBFv7RuEjcUcPYFcA6K+MYihOQp4tosvtEIMb20vtKIzOIcELF3C1I74XAY32gUa49AWJWmLLRYrGwgypIYj7mJ6TIk9QVc/SKGoy5ihixVoUnF3yZlLmI+7sbVFyBtLBBVp9EetBOWS7zwaqBF2lKg//VJxOkkjl6BqCqD8gMzntEwM6kFVp83DDp6BVLWImGFdKOh3mfFflog76gym1liPr9KYDJGRJ2SuNHqDOp9Vpw9Ao3wLEVXjbnMIuJ0HFEWJ67NUPI1cPQGsHb5qYU7dBILVIUWaWuRmDpDylRAnE7g7BUwHXMSnIzRis/Tjs/hV4aI6JNU/A0S+hyGI07sp/1Yu7zE9TmKXonyUo/O0kktsjV7nrncMvP5ZZrRDle3bnDzwm2ubl7n8cPHfPPNN2xsbLC0tMSTJ09+YJKfPHnC4uIiW1tbPzi7efMmt27d4p//+Z+3g4T/Q/RT+6ZtbWvHjh3bBvrnpD179vBHf/RH/Nmf/dl/+ff867/+63/ZQK+trfHgwYMfNdCd5ALWLjey90xM7dQy/baOsq/xPQN9dfM6/tEImv02Jt/UMvWWDkevnwvf4TI/+PgzCs6q9MwbWsZfV2M64aboqnDv+d7yk8dPmUsvE5iOI3/PwOjLcibe0hKSJVlvbvHZJw9fhPVCuhiaQ2Zk7xgY/a0SwxEneWeNKxvXePrkGbcvf8R8fgVxKoH9tI/RlxUYjjoJTMRYLq1z4/wtHt1/xPmFC2TtZRyn/Iy/oUG+y4h/LExNnGGptM79u/e5unmd1doG3qEw+kN2Rl5WYT4uFbPMF1Y4u3CRj67f5cLKJVLmAiFVEsVuM/JdJswnfZR9LTrpJT6+/QlzlQVCujgxjWT2zCc8mI64iOlylHxNziyc5/a1D6mFW3hGg1j7fMjfN6I9asfa70XUxIha0iwvrJCPlDD2OdGftjK+W0nvyxOM7VLgmPJhHXGRFNOUCxXs4168qiCGHjsjbykY36XFORZAUEaJ23KcWTtLWayTtufJ2IpYewWsp/3EjXnCyjQpc5litEbOXaIaaFH01glMxrH1Bsg6KmSdNSLaHIvlVanKOtCmJs4QnEpgPu5GnE5Q9reI6fNUxTatxDxxncRlzljLWLq8CJNxCq6qVEKizpJ31QmrMtJus9jCNRQiqslRj3YIyVK4BoLEdDmCU0lEWZKwMkVwOiHVaqeWaMbmcPQGUB414p+OE1akESZiuAdE3INhcs4aM4kFQooU9j6BsCpDxlpGlKewnfIhTMSoBtoUPXUShjyWE148QyEiqjRpYx5blx/PYJD5/Aqd5BIJfR57jx9RJq0/iLIkpuMeLCe8lNx1lqsb1MNSIDKiTpOxlnD1BrCc9KA9YKfkqVMRWswX1xAmo0zt11AWGuTsZRx9ApoDNmZzS1QDLWrBFjFVhqgqTWAqTtlXJzAdQ3fYTsFVZbm6TjXQJmMtkTQVyNiKBCbjBCajqD6w4h4UKfkbLBZWybuq5BwVOulF8o4K9h4/2gM2qdJ9Ik7eXSNnK1Hw1KmFJAZ4XJ/Hdso8MDKVAAAgAElEQVSLdzRCQp8jps4hKpJYh1yUAlVKnjpZexnPkIily0vWUSFlLpIyFRHlCRYKq8wkpDWO+dwyZaFJKz7PZvssN87f4talD7lz7S7ffPMN169fZ2Zmhi+++OIHJvnRo0dsbm4yOzv7g7Pvkju2g4T/M/RT+6ZtbWvHjh3bBvrnpPn5ec6cOfPfMtA/Fg787mtzc5NPPvnkPzx79uxz2vE51PusjL+hZvx1Fao9RtKW/AtyxldffcX5pYuI8jjTO7WMv65i9DcKHL0Cm+0zL8KGd2/eoyq0cfQGkL2rZ+w1JYpdRrK2Elee4+IeP3rCan0TUZFEf9DB+Ota5O8Z8Y5KTWb3PvyEL7/8kisb14kYkyg/0DP6iorxtzRSNbO3xmp1k2dPn/Hx7U/Ymj1HWJ5Cf8DK0G8UKPeYCEzEaCfmuHnhFk8fP+Xy2lWJq6tIMfWOnumdegxHHOSdFeZzKzx5In2vmcQCUVUGy3E3mn02DIcd+MYjZBxlzq9f4s5Hd5ivLOEcCqA7bmP0LRXyvQY0hy14lSEi1hSLC4sUM0W0vRY03WaGdk5z6u9HGXpjGuOgDduom1K6zML8IqI5gV8VxjrgZmKXlrG3NVj6ffhlEfLeCrdu3GKptkraXiRjL2HvCWDvCyBMxgjJkqTNZc4vXebC6iUaYoeiu45vJIz1lI/AVJKUuUhMl2OlvsVKfZPac2RbSJ1Gf8iJvTdIVJ8lpstREzuUY3WcoxImruCpY+sVcA2FpCDgcJiwKs1seom0pUhQlqTsb+KfiOEeClMJtvGPRHEPhyn5G4TlKaKaLDFdFv9oTCq48dSoBWdw9gXI2CpEVFnihjxxbRbvSATrKYGEvkBZaCHKkniHwySMBRL6AklDHlGRwtYTJO+uP59YJ7GdDjC1V4OoSBLTZAmrUjhOCRR99efFK3lcAyLi88p4YTKOeyiE7bSPqCpDJ7VIO7WIZyhM0lgg6yjjH4vgGghiPOoiYytTdNdpRucIypMvAn6VQIugLI7lpJeSt8FMcpGiq0ZEnSaqyRKSJ8lYisT1WQxHHIRVaRZLa8ymF0kaCoiKJE6Zj+BknJAihXyXEU9/kJg2x2JpnYK7Tlwn4RHrkQ7+iSjqfRa8I2FEeZKYWmomjOuylH0N5vPLNEIdLN0eHH0CZX+DsCpFWJVEnE4wl1mi5G1QFzu4BkU0+6wkjQVKnjpRXQ7/aITZvFS7HdfncA+JaPZaMZ9wEzfkiWkziLIEjjEfs/lFyv4Gjl4BR38AwxEH/rEIvtEw/rEISX2eqtCSbnUKKzRjc7STCyyX1zgze461+hZXz97ko6t3+Oabb3jw4AH1ep2vvvrqByb5wYMHnDt3jk6n84M67++SO7aDhP8z9FP7pm1ta8eOHdsG+uemO3fu/P8y0MB/2UCfPXuWu3fv/odnT588pRWdxdLlZuodHVNv65l4TU1Ul32BZfvqK6n1L6xMMv2ugam3dEy/o8fZE6CTWHhRgPLp3QfMphcxH3Mz/LKcyZ0a9IccpMxFtmbPP//znnFh6RIpQx7lHhMjLysZf0ODa0ikEZnl0zsPXpjxqDGJqdfF9E4dY6+q0O23EdfnWGtsvvhea60tRFkCzQcWpnZq0OyzYD3lIWXPc+HMRW7dusXG0ibuiQCKfQb6fzvOyE45E3s0OCZ8hG0xOp0OrWYLt8KPtttC/2uTnPqHEXpfnsDQY8M55Wem3mFra4tqqoGgjmAf8DO9R8fUe3q0xxx4x0PUYjN8+sl9VufX8aui5OxlzF1Srbb5pI/AVIKMtczl9auSYU8uUPI18AxH0B+W8IFRbZakPs9qY4vLa1cldnNqgZgui+6gC/0hKUwZ02apCG2ubl2n6G1Qez5JdQ4GsZ4SECbi2PuCiPIUS5UNaTqsy1HwNvCMhrH1BV7wkD0jEerhWXzTIu4JkYKrhn8siuGYm6A8ScZWwjkQIu+WaqjDqix5Z42EvoDhmAf3SJisrYp7NIp3NErZ2ySmy5MwFikJTRy9QSLqNCWhiXNQlNYilGkS+gKBqQRZewXfRAz/eIyZ1AIJYwFHf5CEIU9gKkFYkUKYShCQJXH0i88ReXO4B0JkbWUMfXaCsgRBWYLAZJygLEHBXSPnqiFMxhAmEy9KVRLGvNQeqZHMadnXRJiIS5QJW5WYNk/aUsB62odvLEwzOstieY2EsYAoS9DJLJAw5hFlSTT77dh7BELyFK3YLGW/ZKrbiXmWyuvEDXkpBzAYJGUqEJIlqfga+MdiZKxFvGqRpfIalm4/lm4fZaFFxlJEnIojTMSeF680aEbnpOr4Azb84xGqgTYJQw7fWJhGeJblyjo5Z5XAeBTFbiPWLh/+sSgZq8Rkz9qrLJfXWCyu4h+PYTzmxNUn4uwL4B+L4DgVIK7NUnDX6KQWiajTGI448I2Fpan2eATrSS8xdQbXpEBYlUQYi6I7ZMd8wo1/IoZ/JIxrUCqwqYVmaMfnaIRmqIkSM3yxuErF32SxuMZCcZVzC5d4/PDxi0ru/4y0cfHiRTY2Nn6wI/3vyR3bQcKfv35q37Stbe3YsWPbQP/c9N8x0H/xF3/xYmf4P3udP3+eDz/88D+eQD99xlpjC/0RB8OvKJh8S4PsPQMhefIFI/nbUF/KXESx28DYKwrGX1NhPOqkEZnlye+evAgRzmWW8A4FmXxLmlQr37cgyhNc2bj2Ygf6+oUbCFMxpt7WMPq6CtluHZrDVpL2LOfPXuDy5cucPXsO17SP0XdlnP67EXp/O8bgG1OYBmyEnDFmZmaYmZkh6o2j77Uy+Pokvb8Zo+c346iOmBDUEdZW1rl06RLrSxtETCmcwwEU7xuR79aj+sCIdyzMcmWVJ0+e8vjRYzrpRbLmknQt3+1F+b4F/2SCjL3M9bM3efr0GcvVDSqBFp6hMOoPLMh3mxAmE6SMBdabW9y6eJt2fo6oMUHKJJFGFHvM6I+5nrf1Nbh27hartQ0qviZ5d1UiKJz2oz9kx3Y6gDCVYKW6yWpji7yzSsFdwzMYwtLtx9Er4OwP4hsJUw91mMsuk9QXaEbmCClSaA/YsXT7nk+GQ2TsVeYLq4SVaZqxWcpCC2u3H3OXj5A8haXLh2swTDu5gHNMwDUmMp9fITAVxzUQImUrYz0dwNztJ2kukjQWCSnTVAJt6Zq/RyDvqRM3F7H3BEmYCkRUGWK6PClTkYSxiLMvQFyfp+CRkHhJU4FKoElYlSZjKVNw1QlMJ0nbymRtZdzDYZx9YWqhGQquGgljkYKzSug5P7oZmcMzFME3FiFjq2DotRGUJwhOx/GNRUmZi8znVsjYyvhGIrQS85R8DUKyJNZuH47eAGGVVAxTF9t4hiOU/U2WqxsU3HVcAyGcA0Gy9gpxXY6MtYx3RJpQ18MdlqsbeIZDOPoCZGxlCu46UVUa/2SMkq9JRWhRFdqEFZLJdg+IZGxlco4K3uEQeUeFxdIKrik/IWWa6bd1eIfDOHoE0uYS9m4/CUOOmeQ8640tEvos2r0WPCNhiZzSK+DoEwhOJaj4m7Ri8+TsZXQH7BiOuYipMwSm4lKwcCzMXGaRvLNKVJ1Gf8iB8n0zli4fojyJ/ZQfZ79AJdBmobhKcDKGtcuD/rAD60kPli4f+sMSGjEwFSdojBLXZ/CMhPGPRnAPBPEOh1HuMeLo8eMfjVBwVllrbNGMdKiJbWZSC6xUN1lvbtFOLrLW2OL+c6zlt+a3WCz+YML8XdLG9evXf9BU+O/JHdtBwp+/fmrftK1t7dixY9tA/9z03zHQf/VXf8Vnn332ew30pUuXuHnz5o+en1u6iLXLw+RbWsZeVyF/z4h/LMKH1+7w5MkTHj16xEe37iAq44y+KmfwN9OMvC5HttdA1JzizNZZzpw5w8bGBklvmvH35HT97QBdvxqm5zej6LpMJMU0MzMzdDodKrkq5iEnQ29O0/vSBH0vTTC9R0vElODihYvcvHmT61dvELOm0R43o/zAjHyXgal3dPjGIpyZv/Bi8r7RPkvKXMR0zIV6n4WpnTr8YxFy9iq3L3/El19+yY3zN6kFZ/AMhlC+b2bsdQ22UwIpQ4G11hnuXL/HJx9+SiPcIWOvYDjsYOptPbJ3jXhHI5S9Da5uXefDa3doxefIOSpYuj1YTvkYe12D9ZQf/0SU5eoGF1cvk/OWEZRhvCMRNAftaPbbMJ/04BuNUA22WWueoexvMZddJm0poj3gQL3XivawA/dwiKQxz1pjk6y9Sjs+z2x2Cc9QGPNxN7ZTfnQHHTj7JOZy0Vsna6uyXFknpsvhGgrhG49h6/ahP+ImYchT9DVJGPLMZpZJWcvYewL4JyKEVGmcfSJhVUZqTez3krbnKQttvCNSw2BUn8f5fJLdSiwQ0+Wo+NvM51cJq7NEVFlytgq23gC2ngBloUUj0iGiTtPJLJE0FUiZSjQicxKRYkAkZSlRcDcIK9PEtXnCqgwhZZqGOEveXcPWG6AcbFEVZwirMggTcVzDUmV63lUj66jgGggRNxRZLK1hGZYKX0SFNNXOOWtkLCWcA0FCyjQlocVMahFRkSI4lSSuzZGxlyl46nhHY8R1eYnC4W0QVqYwHnXjG48QlqdJW0qI8gQRdYqVygat2DxhdRrl+xYC4xHcgyFC8hTuwRDCZJyyv8lKfZOir4F6vx1Xv0BMm8XRF8DeG8DVH6T8vPnPqxJRf2BGs9cqTcUNOcwnPVi7fMzll6kG22TtZdT7rVLI9H0LgckYth4B0zEXRU+N9dZZcs4qlpMezMfcOPsCaPbZMB51of7AQkieYCY5Tzu5IJn00z7CihSu/gCqvRY0+2xE1GnyzirlQIuIQtoPD0xECU4ncA0E0R91EtNlacdnMfU7CCuTOHsDBCZjuPuDmE+4cfUHcA+K1MMztGISJ7zkazCbWWa5vE7F12SxtEYrNs9m5xw3zt/i07sPXuwsl8tlnj59+qOkjW9LU757trm5yePHj198vR0k/Pnrp/ZN29rWjh07tg30z03/HQP9N3/zN9y6dYvPP/+cR48e8eTJEx4+fMj9+/f5+OOPuXPnDrdv32Z1dZXV1VUuXrzIuXPn2NraYn19nZWVFRYXF8nFC4y8M82Jv+3nxC8H6P7VEPLDWoqZMgsLCywvLzM/u4hbFmT8bSX9L00y+PIUozsVZN1Fbt++zb179/j000+ZLy7hGRZR7zUzuVPH1Js6PMNhrp69/m/T7MsfkTYXMRxyINulZ+w1FY4+gYKz+qLY5MHHD8m6iigOGJDvMjL6igLVXhMxXZaN5hnu33vAs6fPmMsuk7GV0R50MPG6hrFXldhO+6n4G1zZvM7jR0/Y6pwj66hi7fKiP+Rg6CU5hsNO/ONx1hpbXN28zpWta9QCLfxjUbT77Yy+okL5gQXvaISK0GK9scX55YvMJBeoBFqYjrmkEORralz9QWKaLMu1deZzy+T9FZKuPIHJGI7TAlNv61G9b8bWLdCMztKOzdGOz7NS2ZDwYuMxDEfdGI970B10ElFJTXpZe5Wtznkq/hbO/hDWU17sPUGcA9JVeckjVXyvN7aYL6wRmEzg6A/iGYti7vLjGYnQiEqlJhWhzcW1ayRNRWK6LFFtFkuXD+MJLzlHjXZiAdeYQDlap+itE1GlyblrCNMJbKcF4voCOUeNuLFAwd0ka68QkqXJOaokTEXsfSIpa4WS0CSkyJAwSdPqqDZD0d0gYShg7xfxjcWYSS6Qc1VImgsUfQ0iyjSVQIuSt4n1lIB7OELB06DkbRJWZcjaK0T1eaLqDNVgm+B0nMBUgmpwhpyzimyvFvdwiMBEjLAiRViVIW7M4RkI0Ukv0cksIirSWE758Y1GCE4lEOUpvCMhXIPS+57LrVAPdTAeceHsEYio0gRl0oTW0Ruk7G1K6xTxWQxH3aj3WrCf9hPVZnEPiRiPe2hGZplJLJF3VbF0edHss6HZZ8PS5cEzEkazz0bWVmalukE52GD6Aw26A3aCsjjqDyyYj7uY2qkjpstR9jVZqm4QnE5gOuYiokwTUaRQ77Uif1dPTJemGmxTDbSJaTNYT3lx9QeJqjP4RyNo91kJTMdYKG9QC7ZJGvI4egSC0xJWz9HrR3vIjq3bS8FdY7G4QsFZJzAZI6bLktBlMB11ot5rxdblw9kfpOCoYuq34x+PkLWXyDkqiPIkmv1W3AOi9Hc7HSdlLBBRSzceVaHNSnWDtcYWs+ll2vF5rp69wUfX7nDtzE0e3ZcMcK1W486dOz9K2vj666+Zm5v73tna2hrPnj37HrFjO0j489ZP7Zu2ta0dO3ZsG+ifm36fgfZ4PPzyl7/kr//6r/nFL37BL37xC/7wD/+Q//N//g9/+qd/yqFDh1hcXGRlZYX19XW2trY4d+4cFy9eZHV1lZWVFW7fvs2dO3f4+OOPuX//Pg8fPuTx48dcPXMd50AQ1R4TE29oGH9Djf10gDvf2YF+eP8ROWcV7X4bUzslo6o9aKforvH4eeHKl19+yUJhBfeQyOSbOkZeUTLxlgpRlmBr5tyLsOGltSukLQXU++wM/1bJ8G8UaA/YKPsbXN28zhdffMG92x8TM6WZeE+N7D0d/X83hXK3Ce9wiOXKBh9du8ujB4+Yic8TkqfR7LPR+38nGH9TjXc4RMlbZ62xycNPHz6vbJ7F1u1laqeB3l+OYz7hQZxOMp9f4ezCBc4tXGSxsEJUmcI1GGLoJRmTO/UYj3moBtt00otcWLnMevMMRU8Nz3AI9T4b07sM6A86ECbjVIQ2y5UNFusrhExJ3IMhrN0+ZO8ZJYzagEjR26AR7nB24SLnly4T0WTxjUXRHfGgO+TE1hugGmjRCHdYLKxyZeM6FX+bhKEg7a8edaE74CSuy1MLdSgHWpxfukQrtkBIkSGuy+Edjz5fBYlLRtZQYC6/TCe5SFSdJa7LEVKmcPSJBGQpcq4qojyDqE2QchdJGgsUPQ1SljKmkz7sPQHKQvtFacpKc5OIKkVVbFMVO9h6BKy9wRc12WFNlmZsjoy9gjiVoCw0iBvzOPqDlHwNUuayNEHWFwgpUsT1OUSZ9Ku1R6DgrtNJL+EfiyFMJQlMSEG7sDqDfzyK/bSfiCpNKzFH0ddkeKcC72gE/3gUUZ5EmIhj7RbI2iqUPA0Krjqu/iDag04cPQLe0Qi+iRjWbh9pc4n53AoFVw3XYAjNfhumEx7MJzxYu33oDjoIyZN00lJ5TFAWR3fIQXBKChDqDzuZekdPWJmk6K4zm1kiYy1hOu4mMBmX6B4nvSj2GPGPR+lklim66yTNOUbekuHqDxKcTJDQ55G9a8DR52exvM5sZom8s4LtpJeYLouzN4BvJIxytxnjERdxXY6F4ppUBjMcIa7PkndUcPYFkO82od1nQ5iIElanacUXEafihFVJCs4qeXcF7QEbhkNOouo0YXmKmDaLOBVDlCWIqtIkDDmc/QEMRx14RkJU/E1S5gKyA1pCyiRFVxXfWBTzSRf2Xj+afVYS+gJpS0kKhuqyzOdXWGtsUhWkNY6K0GImOc9abZMLK1f46Ood7lyVQoCNRoMLFy78p6SNfx8kXF5e5ssvv3zx9XaQ8Oevn9o3bWtbO3bs2DbQPye9+eab/PEf/zF/8Ad/wJ/8yZ/g9Xp/8MzTp0959OgR//RP//TiP4a3336bpaWl37vCcfv2bS5evPij55c3r+HsDzLyipKRVxSMvqzE3R/k/OKlF6sS9+99RsZaZHq3nsF/mGboNzImd2opepvcuX7vxT71TGoRy0kPw6+o6PvVJBNvqHAPiiyW1nj0QAobrjXPENVmUO4x0/O34wz+WobttI+co8LW7HlpT/rsDbLuMvL9eibeUNPz/44he09PcCpOOz7HR1fu8Ond+yzkV0gYcth7BYZekjHwD9PoDzoouKrMZ5d5eP8R5xYvUAm08QyKqD+wMvSSAv0hB77hMFWhya1LUknKRvsMvtEo5hNeRl5TYTrhxnrKR95dY6G4wkfX7nJ5/So5e5nAZBzV+9IOtPG4i6K7Ti00w/WzN1mb3SRiSRLTZvGMRlDts6HZa8M/IYXbOukl7ty4x1p9k5AyTWAqgbXbi6MvgKM/iKhIE9fnObdwgQsrl0kaCoSVaYTJOJYuP47BEDFDjog6SzMqVXUXfU2qgRYpawnjUTfGEx5i2ixJY5G8o8al9avk3TVKPomN7BwSMR33EFZm8E8kCCkzZHwFIqYMojxFxdckrMni7A8SNxaIaDLY+kQytsrzAGGOmDYvTbJP+REVaRrRDu7BCFFdjqytjDARJ2nIkzAUMHcLOAdDlPxtkqYSjr4gKXMR93AE/1iMmFYKNAbkKYq+BnFDAUdvANvpAN4hEUdfENdACN94FP94hE5mibLQxN4bZORtJYZjHpx9QUwn3Fi6vdhPC5QDbRbyK0TUaWynpYm8eyAk8ZT3WHCPSKi7arBD0V3DeNxNUJYgqs7iGwmjPejA0R9kNrNIxd8i56hh6fLhHQ7jHY2SNBTQH7SjO+qgGZ1lqbxG0dPANRgkrJCCdu6BIIajLqbeMRJWpmnF5pgvrOIaEdEes1APzSBMxDAccTDyqpqoOos4HacebhPT5Qg8n+jWQ20c/QEmd+qI63NkbSWCk3Gi6jRxbYawLElMkyE4FUf2ngF7t4+q0CbnqCJMxohqMzTCHcSpOM7+ANrDDlT7zHhHwuTddcKKJKI8STu5QDs+h2sgiLXLg/mk9GFCmIzhn4gwtU9L2pSnlZglaSni7BfwjITxDIl4h8O4+oP4xsJk7RXy9goLhVUWCis0wh0WcsvMppc4t3CB1domVzZv8PEtKQTYbrdZXFz8gYH+LmljfX39eysb8/PzfP311997/tsg4ZUrV7bXOH6G+ql907a2tWPHjm0D/b9B+/fvp9ls/l4DfefOHc6dO/ej5xeWLqE/4mTgpWn6/26Sod9MYelys1Jd5/PnLOi7Nz8mYcwx9baOvl+N0//308h3m0gaC1w7I7UR/u6zx7RjcwhjYUZ+q6D/76fo/7sp3ENBmtFZHt5/xOeff8FW5zwZSxHLSQ+Dv5bR+8txlO9biOsybHWk93nz4m0qoSbTH2iZ3Kml/+8nUOw24uoVqAbbfPbJQz775CHnFi4QVqXRH3Ey/LKS6bcNWE56KbiqrLfO8OzpM66duUkrNoc4nUSx28TYaypUe60kdBnqoTaf3vmUjz/6lJXqOnFNFvdQiOl3Daj2WrCe8pEyF1korfP0yVMubVwjrs9KbW8H7Nh6BHSHXAgTMeKGAlc3r3H10jU8cpGoOoNrQER3yIX5uBthKkZMk2MmvcjNC7dZrq5TEVqkLCUMR12o99twPA/c5Z01rpy5wUJhRTLH4gzOgRCmLi+O3iDOgRCiTCJsrNY3SRiKlH3N56SKEN7nRAxHn0jWUWUuu0Jcn6fo+Zae4cXeGyRtqeIaChPV5ojbM1h6PCTMBfKuCuZuH6ZuH2lrGd9EAnd/mFqoQ1CexNknkjSXCcgSOPpFsq4qoiKF6aSXwHQCYTyOs0/EPRwmKE9g6xEo+RuUhDbW0wHcI1GsXT68oxFspwO4+kXMXT5i2gKt5+xm32iEwFQcR7+IZziCvTeI7ZSPhKlIydckaS5hOy0gP6xDlKcQJuP4J2KYT/go+5s0orPEDXmc/SLugTAhRVpq9usJSOUnuhwLxVXqkQ7eYek8ok7jHQlhPull+m0DwkSUgqfBfH6VkDxNSJmi6K0T0+WwnfIx8bqGwHSciDJNzlkjqs0iylJEVBlqgRYhWZzpd/X4R8MUvQ1C8hRRbQbveBjroIeQLEncmGPsVS2m424y1hLVYBthTCpHmS+skNAXEMaiyN41oD9ox3FaIG0uElGnCYxHacZmWSqvE9Nm0R9zoT1gxT8awdkjEJiO4+wVyLuqNEIztKIdHL1+dIfsBKbiBKZiuAaDuPqDZKxlSp661Hg4HEK914qzL4AoS+Abi+I8LaA6rmcmvUhYkcI9FMR8woXugA1Xv4i1y4t7KIh7UKToqbFW36QZn6MVn5NoIdUN6qEZmvE55rNLnF+8xFdf/Fsb4bfT4x8jbVy7do0PP/zwxdns7OwPnv82SDg7O7ttoH+G+ql907a2tWPHjm0D/b9B3d3dZLPZ32ug7927x9bW1o+eb8ycxTUgMvSSgoFfy+n7v+MYjjiZzSy8mEDfuXGPvKOK7oCN/l9N0/urCUZfUxNSprh9RSJ8PH74mPXmJq7BIKOvKuj/Bxmjr6gwH3fTSS/y9PFTvvjiC65u3Xi+DmJl+BUlw6+o0B6wk7eXX9A6Prlzn2ZyDvUxE/L3TIz8VoHsXQOB8RjN2Cy/e/iYz599zsWVyyR0eRx9AuOvqVB+YEaz30ZEmWZrTkLnffbpQ/LuGr7RMPL3DBgOOVHsMeIZDJM0F/no6h2++OILNtpnSOgL2Lql/VXFLhPOvgAxbZaF4ip3b9zj1pUPKfsl06s/4kSxx4J6r42YJkvR0+DK1g0258/gV4Up+urYTwtYur0oPrBhPx3ENx5jpbrBuaXL1MOdFzxjwwkP5i4flpN+XIMhcs4aG+2z5OwVauIMSWsR/WE32sNOXMMh3ENhIqosy5UN6dpcX5Amsn0BDIdd+KcSWE8LuIfDtBMLZGwlHP0iBXsVYSqOvVdEVKTxjMXQH3YTVGRwjQXRHLURkiUR5WksXT6C8hRZZxVbTwDPWExqqOsP4Z+IE9XmMB7z4BgQKQfaCNNJfONREoY8jt4gwkSctE0KLfom4hQ8DYTpJNbeADFdjrg+h3c0RsJYRJhIEJQlacXmiesLWE4HCEwlCSkzhBVpnINh3KNhbKcFGpFZWskFnIMiSX0BxVETgckkllM+9EdcWLv9ZBwVGpEOoipNSJWWPjgYcjj6BLSHnFhP+0mYClJdtyaLdzhK2lwi56wSUiTQ7LdhOeWTSmSsZcIqCaVX8M4PEvoAACAASURBVNaJqDMkDFmm3tZiPOIkJE9Q9DSIarIEJ+PMZpaoi21CshSKXcbnO8JBKSioy+EaEElaciTcaWpiW/r52GUiqsng7AsQmk5gPOIm765T9rVYLK3jHgoj323GPRAkoc/j7BGwn/aRtpSohzsUXFX8Y2FUey3o99vxj0UIyRKYT7gRZQlWKuuUvHXcgyKGww4sx93oDjhw9AgYDjtx9Ysv2g29Y2EsJ324BkO4B0VMx1wo91hwD4hM7dOQthYIjEsYO9dAQKKfTEbRH7ZL70+XpeCsMZ9doiq0qAgtWgkpyHhm7hxz2RU2Z87y4OPP+Oabb/j666+Zn59neXn5B2Uq3yVt3L9/n3Pnzr0463Q6P5hYf/TRR1y7do2ZmZltA/0z1E/tm7a1rR07dmwb6P8NGh0dJRQK/V4D/emnn7K+vv6j51fWr+EdCUsrEL+eYuDXcvSHHCyWVr+zwvGARqSD6gMzI68qGf6tHPkeI2lzgTs3pBWOz599zpm584SVSWTv6Bl5Wc7462rsPX5mM4t8/rk0zb5/9wEZawnzcRejL6uY2KlB9p6RwFSc6+dvvcDdzWYXmHxfxfQ7OhS7jUy8ocN+ykfeWX2Bwbp74x5ZewXzSQ+KXWZGX9OgP+wgoc+zXFnnwcef8fjRE1oxqRFPc8CO7B0DUzt1BCYTUp33xnU++/Qhy5UN8q4K1m4fphMuRl9TYzrmwjcSYa25xdWtG2zOnqfsbyJOJ9EecKLca0a934p7METOUeXM3AUaiQ4+ZZico4zhmBvl+1YUe0z4RiOElBmWKxs04/Nk7VWp+rxXwHjcjf6IG80hJ84+kWZsjpnEIoGJOAV3jcBkHGuPgO2UgOW0gOaAnaAs/RzpJuHqYoY8usNO7D0BRHkaa28A50CYtK2Ms18kYSpS8Tcxd3nRHXVJJSODYdzjMfLuGtrjdkynPXRSSwiTSaynAiRMBVzDYYwnfSQtJdKWCsJUkoK7RtpSxtojkHfVSZpKmLr9BKZTRHV5oto8/okEMW0OyymBuKFANTyLcyhMRJsjbSnjHYviHgzhGQ5j7wkQ0WYoeJoE5Uk8I1FaiXkimoz0zEgU2ylBCtgJLYJTCRwDQTKOCqYhB56RCI7+EPbeAMHpBEVvg5S5hGtYmvzm7FVCshSaA3bMxzz4xmPE9Tny7hruwRD16Cwz6UUSxgKqvXY0+6z4J2IEpxOIshSuIZGksch8YZXZ3DKu/iCy3SYiyoy03jAeRXfYSdYu7V3P5VeIqDMod5mxdEl7zL5xaT0opstTEqq4p4LEdTmm3jagO+iQWMu6PJr9VjwjIRZL68xllglOJVDsNuEcDKHdZ8N8woPugA1Lt5e0tSzdnGiz6A45sJz0EFam0O63ofnAgvWEl5SlSNFVI6bNodtvR3fAhm88SlieRHfIhvmEm7yrSsnXwDccwn7Kj2qfFdNRF+4BEdspP/bTfukmYcJNcCqBe0jE2Stg7XJjPelF9b4Z96CI7ZSPrL3ETHKBVqRDIzzDfH6FrdlzNMIdZlILNEIzEonj3G3u3fiEp0+esrS0xMWLF/n4449/QNr4lv/8j//4j8zPz/+nBvrbIOG3Z9v6eemn9k3b2taOHTu2DfT/BqnVahwOx+810J999hmrq6s/ev7R9bsEJqJMva1j6DdyRl+Woz9kZ6W2+eKZL774glZ0Fs1eKyO/VTD0koyJN9QI4xHu3f63lsNblz/ENxZl8g0No68pGH1FjvG4i7Kv8YIX/fjRYxqRDtaTXqZ26hh5RYHyfTNRTZqN9lmePn7Kl19+yXxhBWOvHdVeM2Ovqhl7bsYr/ibXtm7y+bPPuX72BnlHFVu3D9VeMwMvyVHukcKG660z3Lxwm0/v3KchzhCcjqM9aGf0VTWTb2rxDkXIO6psdM7z4VUJUVf01jAedaPYZWTg13Jc/SJheYql4hrrjS1mU4sUPXUcvQKm4x7GX9ei3G3C0u2jGZmV+MP2As5xPyFFCv0RF/ojTpTvW1DvsxGYjNNJLUrtf+EZsvYqukMuNAdtGI67sfcEsJ32k3c1iKgyFFw15rJLuIZCaA46sPcJmE/6cQ2FyblqxA1F6f2V1khaSjj7RZzDYex9AbSH3cQ0OerhDsHpJNVgm5KvgWswgm88Rlibw3TSj3s4QsZRxdznwTkuSuUuIzHsAyIZZxXXcAT/VIKit4lrIIx/PEbKXMI/EUOYSpCyV/CMxrD1i9TDs6TMRWy9AVLWMq7BEKIiKTUVTsSxnPaTNJepiB3cg2GE6STCRAxbT4Cip0HO08DWEyRlq1IS2giTCcxdvufFJhJ9I++s4RoJk3VUmMksoeq2oj/mxtLlwzcaI6rN4R+PSsHCyQTt1AJzuRU8QxEMx934xqKE5GlEeRpzt5+wMk3B06AVnydpzqPYbZam5uNRQooUtm4fIVmS2ewyJV+TjL2G7B0DhiMuzCe9CONx9EecuAZEOqlFFoprZKwllHvM2Hv8mE96MRx2oTtoQ3/YSc5RI++vEDTEUR+wod5nI6RIYT7pRbXPhuJ9C7XQDEV3nZKvge6gE9U+C6bjbuL6AtqDNnT77RS9NRbyy8R1WYzHXM8DppIhdvQKaPZZ8I1GmS+sUPLUcA+JWLslRJ3+gB31Bxb0Bx04+wOEFWmy9jLiZBRHj0BYnkKUJTEccqE9ZMPVFyQwGWd8lwLvaAjbKS+B8SjuIalAxd7jx9MXIKHPEtNKQdWIIsVMYp5GuEMrOstqfYuZxDyzmQWubl7j7o2PuXP1HjcvSaSgu3fvcvny5R+QNr6Lt/vumsd/ZKC/XQf5NnC4HST8eemn9k3b2taOHTu2DfT/BtlsNnQ63e810L/73e/+07DhwwePiKjSTLyhZeg3MoZeVqD+wMxMYv57RS1L5TUsJ72Mvqpk5FU5k2+qCUzHubR69cVzNy/cJm7Mo9xtYuglOWOvKNEcsNMIzfDhlTsvViqq/haWEx6md2ro//tpJt5U4xuJsN6WEHVPnz6jk1xAcViPcq+Z3l+OM/yyEmefQM5e5uz8BZ4+fspm+ywlbw3DEScTr2s4/f+MYzzmRpSnmMstc3n9GtfO3qTgka6vNXutDP7DNCOvqDAdc1MVW8yml7h+7hZVoUVEnUJ7yIFil/T+1Xut+EYiEhWjuEo7sUAtOIP1lA/F+xZGXlVj6fZiPukl66hSCbQo+utE7UlEWRLTcQ+yXSbU+23Yuv2krWUqQouCu8ZqbZOSr4l/LIr+uAfdYRfqAw6C00la8XmiuixLlTVa0Xk8IxFsfQGcgyGp3bA3SMpSRlSkKXmbzGWX8U8msPcEEKbj2PtDuEYipG1VhMk4vrEYrcQCUW2eoCxFSJXG1idiPOkjY6+StVfRHrcR0sUJKTMEp1NkHRUC8hT6Y16CygxZW5XAdIqEvkBcn8Ny0kfSXCLnqmHrFwlrcuQ9DXzjMbzjUYTpBL5Ryaz/f+y913Mbd5qvr/9oay+2Tp2zk2ecxpPs8TgpJ4pijmAASIAkiJwaaHSj0YiNnJgA5hwkKmeHcbYcZcu2pAk7N7vP7wIand3f2rtbdS5cLvNThQvWt4uowtWDL973+VSCs4SHsiSsJVaK22Sdk/U5bksZVZ+m4Jki7agQNmQQ+5LMaqusFLdQ9BkS4wUixizx0QIZ1yRhfYaIMceEPE81voKlxYOvI4Kq1wgPZurz38YcykCK5eI286lVMq5JnKdDuE8ryH0asi5BoDtGoCtGLbbMdvUc1egSrtMhvG315dFAZxTnySCeJoWKWGNeW2NzahdfaxjnqSCh/iTBnjieZoXxIwKL6XVmY0vUYssEOqLYTwbwNoWIDNVtLLbDApNy3dmddZewnfDiOCkidkZxNUgogxrG551ETTmWsutsVc8RN2bxNEpkHZX6Te/xAKMvuQkNJNDMeWZjy2TtJaSeGNGhDOXADL4WBesRH4EOhaJ3kvholoQxg9wbJTKYImpIExlK4W4K4mlWKPimmZJmkfviBHtiaJZ6jbrntISvNYS3RUbsVKnFlrA1eRA7VZLmPFOhefztYVyng4T1KZwnRSLDKdK2EjlnmaJvmvn0GpfWr7GS32SjvMNSdp218g67Cxe5sn6d2299xI3zr3D+/Hm+/PJLzp49+x+A+P8/1rG7u/sIqL8OoP++SLi6urrXSPgdzLfNTXvZy759+/YA+vsQTdMYHR39bwH6iy++YHNz85tvqD/4lJJ3ipEXXQz+xozhmbrCbTGzxp2P7tTHM766x8bEGXwtIYZ+b6X/qRGGf28lote4tHqVL+5+WV9I3L1FylJkdL8b3eMj9D89htCmMBWa49b5+nzz+2/eZkZdQGhT0D09gu5JI6MvuUiaC6wUN/ng3Q/57NPPWUitYDpqxXZEoPcxI7onR3A3Skyr82zPnOPu3S/Ymj5D3jP5sEnRRvcvjNiO+gn1JZiNL/PGzbe5sHqVldwGob4EtiMBeh4zYj8ewNem1jVmU2e5ufsqW1NnKfmrBLtjmP5Q1/l5mhRy3kkWtFUurl1jd/4iC5k1osMZ/B0qw8+7cJwMEhpIUdNWWNDWObNwDs2XI27KIfdpjB/yI3bF8LVFSTsnKHimWMltcHXnJhnHBKGBFL6OCJ5WlWBfgqS1hDZeJu+eYmt6lwVtlay9jDqcwd8Vwd2sEB8rUhKrZJyTLKRXmVLmSVnL5FyTREdyeFpUFEMGzVYh656kGluiGltG1mlkHBNkfdMog2lUY7beFjigERiIkXTliY0WiI8XqUizBPvqN9rV5AqRkRwRY45afJmoKU/BO82kMk9oMI2vM0pFnmNaXUDq15gMzaPZSkQMGTKOCTKOCSRdkkKgxkRogYgph2JIEzfliQ5lUfo1NFsJSacxoy6ykNkgOlJA7E3gbY2gDmWR+1KIXfF6FbhzgvXKGWaiixgOWAh0xfG0hpF643hbwnhawmScE8zGllnIbxLWp/G1KAS7YnhbFCRdHGeDRClQfViZvUR0OMf4YQGxO4rUHUfsimI/ESBlK7FdPcdSboP4SAHbMZHQQBKhLUygQ8X4oouwXqOqLrBTO09RmMZ1WkIbLxAbzuJulDA+78Dbotb92vIsGW+Z0SMuwv1JSr5pIsMZjC/YcZ4QmVYXSFmKFL1T+NojJEbq7YNZW5mxA24sh33kHHV3tjZeROyKkHNPoo3lCHbHsB3xYznqI9AWoeibpqou4m9T0cwFFpIrpMx5rEd9eJtl/C1h5J669zo0kEDsipFzV5iSagitCoEOldBAAmVQI6LXMLxcV+9FhtNEhzPIfQkCnWHErgjaeBHNXEA1pIiP5JiJLFKNLbGYXmOttMW8tsxaaYvF9BoXV69yYfkqt869xq1Lr3Hp0qVHGrp/D8NbW1v86U9/evT3K6+8wrvvvvvopvnrAPrKlSssLS3tNRJ+B/Ntc9Ne9rJv3749gP4+pFKp0NfX998C9L1791hbW/vmGel3PybrLKP/jRXdU6P0PT2G+aCXCWmWDx8Wm3z5xZcs5dbxtsh0/myYvqdG6H/ajGrQWCtv8+UXdYC+tHaFyFCGkZeddP7EQPfPh7Ed8VEUprh17lUePHjAH6+9QSUwg/u0zMDTo7T9YBDTi07EzihLmVXufPwZt9/+kOXsBqajNiwHvHT+Yoj+X4/jaZIp+2a4uHqVz+/cZWt6l1p0CbknwdBzdnS/HMV6LEDaUWYxs8Httz/g+s5N1ktbRIczCG1hdE+NYj0s4O9QmQ7Pc3b+In+8/iaX1q+SspQI9sQYes5Wb4A7JT1ajLu6c4Nb51+lFltCNaTxNMtYDgt4mhWkviQpa4n55AqbM2dJSXnyrikipiyOk0HsDUF87TGK3inK4ixn5i6wWtom56iQsZcRe+J421Q8bSqqIU3aUWFjYoetqbMkzQWS5iJJSwlRl0TSaYSH08h9KTKOKc7OXagvtnmmKYtVhO4Yvq4YWfcUYUOG6Eie1fIWBaFK2l5v5lOGsjiaFJK2MklrhZA+TdpbIjqeJdSvkfdOkhdmEHVJEuMVioEa/t4kEWOOslgjNpxDGUiTdVWQBlKkbBVq2irSgIakSxAx5QkNaPXSl5E8QZ2G3JdiPrPBZGgOqU8jMpzF2SgT7ImjDKQQe+Oow1kmw4tMRZYIGdKEh3IPTSchgt1xlIdwNp/ZZDq8iGrK0fvsCGJvDGUwjbdFQWhXkXUaS/ktVio7pKxlhDYVsav+TLArzth+H0KbSjk4y1pxm9nkMt6Wurs5MZoj2B3H9KIT+1GRnGeKyeAcs4mVekGNMU3aXkYzlxg74GH0JReVQJWSv0olUEXqjhMfyaMOaqQsZWwnRAzP2kiO5KhFl8h7pxG6FLxdEuVAlVB/AqFZof/XY8j9CTRzkdn4CnJvnPBQmvnkMhWxiq85hPH3NmRdAmVAIzmaI2pMEeqLkTQXqEYXCOtTOI758ZyWyTkr9YbAAY2wQSPrrJAYzaEa0nibQjiOBYgOpSh6plD6E0SHUpSFaUq+mbpW8aGtw9NUb74UdTFMR2xoliLzyVViI1nkvhjKgIbYFSHYE8VxQqy/Z3+SvHuCC6tX2ajssJRbZ720xbmFi6xX6i2L29O73Nx9jdvv3X60HLi1tcWDB/+34nt9ff0/uJ8/+OADrl+/zp///Ge2tra+FqDffPNNFhcX9xoJv4P5trlpL3vZt2/fHkB/H7K0tERLS8t/C9D3799ndXX1G89vv/0h8ZEcA7810/YTPR0/MTD0rJWCd/LRst5nd+4ypy3jORWk53Ej7T8coO+pUfytClvVc9y7d4/79+9zZvYCGXsR4/MOep800fVzPbajAiVhmjduvMWDBw+4ef5VarFlQr0xDM9Y6H3MiOl5O4mRLGvFLe5+fpfb73zIdnWX0RMO3I0SvY+bMP7BhutUkJJ/mpvnX+HzO3e5ce4VysEagXaV4T/YGXrOgeWID6k3SkWa5aP3PuL1q2+yUztH3JTBeUpk+HknliN18E3bSmxUdnjz1ttc3rhGwTtFYjTP2Msuxg/7sBwWyDgnmAjWuHbmFle2blAJ1kiOF3E1hvC2KlgO+RB74iTNBXYXLnB+9RJBk0rSXCAylMXTGkZojeBpDiP3aeS901w/c5PF7DoT8hxFoYq/M4r7dAh/V4SwPk10JM/m1C4r+U2yjgnmtJV64UpTmKAuidiroQ5lmE+tsVbeQR3KMhGskXFOIg9oSP0pEmNF3M0KEVOe5fwW0ZEsidECZaFG4CFMVqQ5JF0Sf3eM8EgKR2sQdShD0T9Vv/1tj1KW5si6p5AH02RdU/g743ha6zeaifECYk+Cgn+Ggr+G1J9Ec0yg6uswG+iOkrSUkfs1JpV5piPLSP0pAjqNYF+S6FgBb1uEoC6OvydO0T/DanEHzVYmZEgj6zTkgRRSv4a9QcZ1OkTaVmFOW2MmukygJ4Gl1UN0OIeoS+I6JTN6yEfaVmEmVm9MVAbThAZS5F3TRE31uePRl73EjFkmQ/NMheYJ6TOEDSlS1jLJ8QLuZoWh39sJ9WuUhPpNu2YtEhvNUgnWSJgLyL1xep8cJdSfJD6So+SfIWLMkrQUKQdrTEXqc8f9vx4n0KWSGK+PtEQMaTztEmJ/mLJYJe+ZYORFF7ajPrLOMvHRHCF9Cqknzry2QtJcdzRbDgs4TgQQWsMUfTOEdHGknhjVyALL2Q1ixgzeZgVng4S3KYTQHCIynMbfqhAfy7M+scNksFZfkm0JER2ug7TrlIS7SUY1pCi4J5lSZlEGkzgbJML6FGl7qW4KOebDfNJB3j1J3JRBHUrhaZIRWhVUQ90FHeyJoho0JuV5FrPrLOc3mY0sM6+tsjF5hlpsifPLl9mc3uXyxjXufHiHd995jxs3bvwHDd03LQo+ePCA7e1t7t27x5kzZ74WoD/66CPm5+f3Ggm/g/m2uWkve9m3b98eQH8fcubMGY4ePfrfAvSDBw/+S4B++9V3yTnKGJ4ZR/fkKF2/0DP0jIWKWOWTDz7hwYMH3Pn4Dsu5DYLdUQy/GafvlyPonjQR6k+wO3/hkYXj2vZN0tYSliM+ep80MfDLUcYPCeRcFd5/83b9/V55l+XcBkKLwtCzFnRPjzL8eyv+NpXZxDJf3P2CTz+6w8W1y5gbXTiO+dE/a0X/Wwv2owFSjhIXlq/w+Wd3+eP1t5gIVkmM5Bh+zsHQszZMzztJjOWpqvU674/f/5il7DqxkSyOkwHGD/sxPW+v13mP5rm4epXXLv2R67u3yDgrhAZS9Tnooz5GX/YS6ktQEma4vvsK18++Qi2xTFmsIXSo2E+IjLzkqo8jjBXYmNplu3qW0GiUOW0V1VCHGutxEVejTFhfh96d2jkKwjTToTnynkn8XXH8HVGEjgj2UyHU4Rxb1XOkrCUKvhkm5DmE9ihCRxR1OIu/uz4SMinPkbaVCRvSVGNLyAMpHA0y0dEi4eEs8mCGvGeK+FgB1+kQBc8Umq1MoDdJdKSAZi0jdMbRbBVCpgTmEz7Cg2myzgrB3gQJS4mKPEegO0mwT0OzVVCHc0i6BJq9jK89ityXYk7bIGmfQB5MkxgvEeiKIw3UPdCelhDKQIYpdZFCoIY8mKIUqBEbKeBtjRDUJXE3hwn2adTi9c9W7NeIGPMUvFXUoUz9S0hbBOcpmYnQHLOpdaT+FLGxIuZGDyl7Bc/pEPaTIq6mMMnxIlPhBTKOSTR7mZJQJW2v1G+WX3LhOiWh2eqLcilHhagpx5S6wIQ0R8yUY/gPDpwng2iWImlbpb6cqU9TCc5SEmYoi1VML7kZe8ldt6tYS0QNGYSOCKvFHcr+KlnnBJajASyHfPjaFLTxYn2UpDVM0pmjEp2h6J3C365iPuhF7IziaZSJDKcZP+hDMxdYLW2xOXkGqS+J+ZCPuDFDsCuG/YSI9ZhA1Jipqw7Ta0QMKVwnA3iaQuQ9UwS7IliP+gkPJFhIrZD3TBLWa3hOy7gbZYTWMInRLJ4mGak3TjWySDWyiNQTe1gbH8PfquBtCSG0hAj2RBk75qDknyE0kMDXFkY1pIkZs8h9cZzHA0SG6qU3mqVALb5CLbrISn6TleImF1ausDl5htXiJsu5Da5v3+StG+9ybu0CVy5e4W9/+xtvv/02r7322n9p2lhdXX1k2/g6gL579y61Wm2vkfA7mG+bm/ayl3379u0B9Pch169f5/nnn/9/Bujbb39AyTvJ6AsOeh430f34MIZnrOTcFT57WNP9+Z27nJ07j9gRYeDXY+ieHKHnMSOuhiAbEzvcv3+f+/fv89rVNygLU9iPCgz+xkz3z4cZP+AjbS1y69yr3L9/n88//ZwFbQXVoKH/3Ti9jxsZ/oOVUF+CueQK77z6Lvfv3+f67i1GTzqxHRYYetaK/hkL44d8xE05Lq1f5f03b/PJB58wFZ5H7otjOxZg6HcWhp61I/XGqQRrXNu5yccffMrm9BkmpVm8zTKWQ150T40h9caJm/NsTp3l2vYtLq1doxqpj2c4G+rNcOYDXiRdkjlthe2ZXc7MX6CmLpJ3T+FtVnA3SYy86MF+QiLy0Hgwpc4RGA4zFZpH7IrhOhXCeixIoDOKt1mhEqwyHV4gZS2zmFkjrE/jaAzhaVMR2lWkviRZ1yQT0hxKv8akNEfGMYHYqyG0q4QG0rhaIkRH88yn1gj2amSsFSqB2Yde5hRpxwTe9ihCV4KSPEt4KE1kOMe0uoDYk8DdrJIXZoiOFZEG0mSFaRwtQcaOCRSEKtGRHL62KDnPDAlbGVGXohiskbSWcTeHiQzVF/l8HTFKYo1ScB6hK0F0pEDh4U2s0BkhMpzFekwkbS8zn1lHNmSImkvkvDNERvP42qMEe5J4WhSCuiRTkQWy3mkiphyz2hpRcwlvWwR3cxhno0R0tEDKWkGzlZEGUlTjy3gHZUIDGvaTQewng8gDGjlvXdEXGkxTCtSYiSyR80zVf1U46kfsjterv+0lxJ4oc9oac4kVSr4qrtNKfaSoJ0Z4UEMdSuNpCTMRrLEze4FafBmpN8HIyy7EnhhCRwS5O874IYHkWIn51Bpn5i6SshYYO+BD6k0g9ybwNocYP+Sr6/HsedLeEkVhEusRH55GiehwhlC/xvgBL8GuGNvVc9Qii6QsRSxHBYROFeeJusnFdsyPvz3KtDrPTu0cMVMW56kgUm8cuTeB44SIu1FCaFWIG7NUI4to5jzuRglnQ5CscwK5N4b1iJ9AR5iYMU1Il0DsjOBvU7CfDCD2RNFG8/haVQKdKnJ/DFujF9dJEW+TjKdRQmhTEFrrNhJ5IIm/PUzOPcGEVB9nybkmWStvs17ZoRpdZGfmHCu5dVaLW9zcfZX3Xnufi9uX2V7c4V/+5V/4/PPPOX/+/H8J0GfPnuX27dtcvHjxawH6s88+Y25ujj/96U97i4TfsXzb3LSXvezbt28PoL8Peeedd3j66af/nwH6808/Z0qZxXzATd/TY3T9YgjjczaS5jzvvfn+ozGQy5tXkXVx+n9lputnBgy/rc8kL+XX+fTDTx8ZNvKuKcYPeNE9aWLg6TGMv7eTGM1xdfsGn9+pq+w2p3cJ6zXGXvbQ96SR/qfHCHSqVNV5bp2vWz1uXXwVT28Ad0OQoWdt9DxhwnVSJDmWZ2PyDG/depsP3vmQWnSRyFAa6xEf/U+bGX7GSqAjwnxqlY2JM9x++0NWCpvkPZN4m0OYD7rpecKE7bgf1ZBmpbjF+eUrrE/sUIstIfbUYbz/V2YcDSK+1jAlYZqFzDrrE9vMxZeJGXM4GyXG9nuxHvHj74yiWcpUo0uUpVmEQZmCdwpfu4qnWcF2QsTRICMPpFnKrZN1TzIpzzKlLCB0RPG1qXjbVHztUTwtKhPSLFn3JAlzgbXKNqqxPksd7Esg9WsEdSlSjgniY0V8bRGq0SVK/hkCPXEknYY6lEPoTpC0lcl6pxHaoyTMBfLuqXpByluztQAAIABJREFUhiFLzjODuyWCrE9TCs7hapNwtUrk3FN4WlTE3gRT6iKhoSwhfYZKaAGxpz5SkbKXkXR18C1LcyRtFUL6LNXECin7BLZTEjFTDrErQWhAI22voFkrCN1xisFZFnKbCJ2xenlMZ+zR0l/aPUGgVyPlmmQ2tUZemMZ6QkJorRfNhAbTpJ0VpMEUpcAsC5kNnDoJf1ecsUM+RF28bvLojiP2JEjZJtiYOstCboOwPo31hIinSSHUX/cb20+KRI05qtFlNqbOUQrUsB0NILSH8bdFCPbEsR4JoOrTLKTXqEWXqcaWGT8cQOhQkXrqbm778QBCm8r2zC7L2U2KwgyWwwK+tjC+5jBST/2LlLNBZEKcYzJWI2HP4WyQcJ2SUPVpnKeCuE/LWA75yNgrTIXmmEut4G4IYjtcVzPGTDmsh32Y93tJWUr1m++hDEJrGPfpEM6TARIjWbzNMs4TAcTOGFPKPFJPFFeDSKAjTLA3hvOkiNCm4GsO4WqUSNvLpB1l/G0KniYJzVxA1sWxHfER6FTxd4ZxNIiMHXeiGjRcp0TknhhJc74O3a0hosa6bSSkSxAbyZAy5ykJM0zKs5xfvsL2TL3We7W0xcbkGa5sXOfSyjXOru6ys3SWv/zlr/z1r3/9D9D8dQB969YtXnnlFa5cufK1AP3JJ5+wurrKRx99tLdI+B3Lt81Ne9nLvn379gD6+5DPPvuMn/zkJ/9jgP57KcrXzUgvZNYwveCg+xfD9D5uwvA7C/GRHLcuvProudeu/JGwPo3hWRu9jxvpe2oUZ2OQucQy771RB+2P3/+YWmwJd2OQ7l8Mo/vlKCMPdXebU2f47JPP+OrLr1iv7BAdTjN+wEPXL4bo++UI3kaZWnSJ80uXuH//PhfXrmJt8+FpCqH/7TitP+zHctiLMphkIb3Ke2+8z+tX32Q2tkiwJ8b4IQ9dPx/C9JwDb1OIomeK7eld3vnju8zGFkmOF7Ed92N8zs7g78ZxNgSJj+SYjS1x/cwtFtKrFIVpvC0KrpMS/b82YzsRINgbZz61ymJmnZX8JgvaGlJfAmdDkKEXXNgbJNzN9WroslSjIlZJeNLknJO4m+pKMfspCbErgTqcQ7PUf8qfT62xmFlHNdR/1ne1KrhbFOSBNAXvNKGBZN2iEF2qWysGNCR9CleLitCdIGUrExvLk7JWmJTrbYHB7jgxc4nQUAZRp5Fx1WeXZZ1WX34cyiJ2x0k5JomYcgT6kxSDs8QtZUwHXfj7I8THCsi99f+fcU/jbouStFaoJlfr5Sz6DDFTDtdphYgxSzk4i6hLopqKzMRX0OwT+DpiqMNZfO0RAj0x0vYJ1NECCWuF2dQGOe8MQncCX0fs4XJgBlmnoegzyIMpFvMbLOa3kAfT+HtiOE/JyP1JJF0cb1sUaSDFhLLAcm4bR3cQX1ddSedqlAh2x/G1RZAHNGa1VarxZSZCc7iawwgdESRdAk+zgr9dxdsSZjG/zmrlDBVpFsfDG1qpN0FIV7/JtR7zU/JV6zepk2dwtyjYjvkRO6MIHTHcjTLG553kXBNMijVWCluI3XGsRwWCXVGUAQ3XKYmh5+zER7IUfTNIgxFcLSL2EyLeZgWxI4KsizP8eztCe4RpZZ6ss4K/M4yzQSRpzuN8+GVu9AUnniaJxEh9TCnYE8NzSkIzF9HGC1iP+bEfF/A0ikg98UfaOudxkWB3lLyzgtgVwX7cX59f1qcI6eL4mkL4mhWE9jBSbwyxM4LQFkZoDiHp4qjGNMMvWXE3yqiDGuGBJPbjAYI9cWRdHM9pmZgxS2IkR3Q4TWIsz7S6wFppi1p0iZXCBvPJVVaLW8zGl9mdv8TVjRvMFxa5uH35EQBvbGzw5z//+RtNG7dv3+bcuXNcv379awH6gw8+4MyZM7z22mt7i4TfsXzb3LSXvezbt28PoL8P+etf/8o//dM//Y8Aen19/VET4NdZOpaya9iOBWj/mYH+X42h/50F9WEZyd+fu372FmF9Ev0zFjp/OkTXY0ZsRwUmpVnefrXueP7gnY8o+6dxNgTofXKY1v89wNAzVkJ9cVaLW9z97C6fffIZS9l15L44+mcsdPxUT+8TRjyNMjnXBDd2X+Wrr+6xOXkG82kXtqN+ep8aoecJE2MHPMRGsixl1vn0oztcWr9GJTBTB4v9btp/YsD0ogtvm0o1usSFlcu8cvF1FrNrRIbT2I+L9D4xiul5J64GifhIlhllnqs7t1iv7FCLL+JrVxk94MXwrKNeltEZIzFaeFhqcob1yg6xkSxid4zh553YH94cphwVUrYK05FFlPEoKUsZRZ9h/Kgf+6kwjlMSiiFNxjVBUaiyUthEs5aQ+zXE7hhCZxR/VxypL4Wir49cLGQ2yHumiJpyqENZpH4NX2ccxZhF0aeQ++tauoo0S1CXRLOViVlLuJrCyIYMac80ij5N0lIk751BaIsi9SUpibNI+hRin0YhOIc0oOHsCBEe0/B3xxHao/UWwuEcYWOBqcgScUsJX3sUzVomNJBGeViEohiy+LqSVMKLzMRXkAbThE15hK44/p4Ewb4ksbEivq44WW+VmraBZp8kbMoh96Vwnwrha1WJGnOIfRolaY651Dpp1xSBXg1/T4KQIY23LYzQHiXQmyDvr7Fa3qESmmNwvw3naYVATxxFn8bRKOM8JZO0llnIbrAxuYtiSONuCuFuUvC2hPF1RDC+4CQ+XmBaXWJOWyNhLmI5LCL1JRDaVVyNMoZnbUi6GJPyPDPhBRLmIubDArIuQbAnjtCuMPDrcVynQ5SEGSrBWZKjRZwNEnFjDqknhtCqMvSMFfsJP4mRHBWxhqdTxnLcR2Q4RdY5ib81zMh+FyMvuoiZcqiGFFlHGethH6G+JElzkdR4ntEXnJj3ewgPJkmM5pB7YjhOBlAGEij9SaLDGaxHfLhP1dsU865JYiNZ7Mf9KH0JCt5JpN44juMi/nYF16kgvlaFlK2Eq1FEaFVImvOkrSUcJwJI3TGC3RECbQr2hgDDL1lxNUp4m2SiQ2nk3ihCWxilP0F8JEu4X8N1UkIZSBIdTpGxldmunWejvM1yboPNqbPsVM9zYekSS+k1dqbPsVBa5u233n4EwJcvX+aTTz7hr3/9K+vr6/8JkO/du8fq6up/Kl35++u9997jypUrnDt3bm+R8DuWb5ub9rKXffv27QH09yH/+q//yj/8wz/8jwB6c3OTu3fvfu3Zl198yVxyBct+L50/1dP6gwF6nzAhtIS5snnt0XMX164QHkzS8/gwbT8coOPHesb3eygKM3z40Nbx5o23yLkmGD/kpeunBtp/akD/23GiQxk2p87w1Vf3+Oj9T6jFFvC3qRhfcNDyz33onhrBfTrIlDzHH6+/yed37rJW3MLe4sF+IkD34ya6fj6E5ZCPcH+Sufgyn3z8KbvzF1nOrhPsjWPe76LnCSOjL7qxnxRJjOU5WzvPtZ2bbM/skjTnkXriDPx6rL4Att9b9+36pjk7d4ELK1coeqdQ+pKMvexhdL+bsYNeAp0qGecEq+VtVkvbLGbWkfuT+NojmA8KuFvC2I8HCA2kyDgnWMlvEjAqZOwTRE25ejlHSxhHYwipN446lGFKnWc2sULMmCfrmkDqS+I8reBtVxG746jGHCVxlmpsiVCfhjqcIe2oEOxP4e2IETbV7RWRkTwrxS0ixhxid5RysIasTyHqkmj2SSR9GldzmFKwStY1hairGzPi42UcTRHilhIFsUawX0PQRfF2K3jbIqj6DDlhGqE3iTKcZyKyRMiYJ24uk7KV8TSr+FojpB31xcG4tcJsch11tIS/N0nMUkLqTyF0RggPpJEGU4T0GRbzW0yEFhF1GlJfCk9rGFmv4e1U8bRFkAfTTEWXWcxuoZryBPUpPM0q9lN1A4fzVAixN8FMbIXp6Aop+yS9z5kJDabwtUUwH/YzdlDA2SgzEZpnLr1O0l7B0aTg74wTMeXwtIQY/L2D8SN+EpYyFWmBCWUed7NK2FC3cYT6EvQ/Y2HsoJeEuUTONUlRmMHXoZIw58lYy6iGNKYX60VAKUupfgNsKdXtFYMpEiM5svY6BPc9PYqsS5CylokNZzAetOPpDJMcyxMdTuNultA/M46rIUjSXCRtK+NvC+NrDlGNLZEYrVeFj+73EGhXcTdIJMeL+NvDuJvkei19dAFPUwjrMQFfq4IyoGE/LuLvCONpkvG3hcnYSygDSbxNofo89VgBZVDDcSKAr01BGUiiDGgEdXFCfXFcJyWCXRE0SxF3cxDTfiuqPkXBM4nYGUEdSCJ1R/A2hxC7VPwdEVR9GrknzmSwyvbMbn1pMLvBUnadndp5quoCW9NnOTNznqtbNzmzfpa33vi/AP3GG2/wxhtv8Kc//Ynt7e2vbRtcWFjg1Vdf/VqA/vsi4t9bC/cWCb87+ba5aS972bdv3x5Afx/yb//2b/9jgN7Z2eHOnTtfe3b3s7tUI4uYXnDR+RM9bT/W0/UzA3JfjBvnXnn03NnZ8wQ6Iwz82kzLP/fT9qNBLId9TIZm+eSD+gz0zXOvUPbPYD3qp+exIVp/NIjht2bErijbM2d48OAB7/7xfZaza0QNaYzPO+h+wkjXz4axHPSSMOe5dfE1Pvvkc3YXL2Jt9RLoUOl7eozOx4YY/r2D6EiWqfA8b9x4k1vnXmVOW0HuS2B60YnuqRGMz9nxNMqk7UUuLF3m/OoVLq9dJW7K4mlWGH7egXm/B9OLbsSeOKVA3St9Zu4CFbGGZilgPuRj/KifwWesBLvjRIYzrFW2Wa+cYUqeI22rIHSo2E5KjB8RsJ8QiRizTCsLbEztYmvzETPlSZgLeNtVvG0RHCeDeFoUIiN5tqq7dR3aWIGCdwapX8PTESHQFcfbFsHZGKYSnGNWWyWoS1BLrBAfL+I4rRDsTxE25RF7k8RMeUqBGv7OCJq1RMEzQ7BPQ+iMk3ZNE+hJEDblmVDm8HfFkHQaFXGWYH8K2ZClIM4SGszibY8RHs9ib5GQepOkHBOEBtN4uxKUlUXy4ix+nUbMXMSvS+BpiyD1JVBH8njbo+SEKhPRJcLDOeL2usHDciKI7YSE1Fsf1SiIs1Tjq6ijBYL9acKGDMG+JGMH/VhPBLEdFdHsFZYK2yStEwR0SYTuOOpYHm9bhJEDHsaPBQn2aVSkOWa1FQJ9GqYGF6HBNFJfktH9PkwvuYia8mjWCgX/DMpQhshonrR9EsWQYWS/j/5fjxPsi5PzTBMfLRAcSBHoSZBxTZB2TOBqCdP9hAlPS5jYSJ6MdxKxO0ZYnybjmCA5XkAe0Oh+3ISnKYSqTz9S2/m7okyG5sl5JlH0KQZ+M46zQURoj6IOphA6VEyHnMj6ODPqIlFTBtOLLmzHBEIDGp7TIfztKrZjARLmHGl7mbyrguWowPhBL+H+JDFjFvvRAM6GIBl3hYJ3mshQBqFVwdsi42oIEjNlCXZFcRwPEDWmWS1uETflETpUPM0hZF0MxwkRqSeKry2M3Ben6JuiJEwR6IzgapSIDGcI61O4GiQsx33YmwVCA3FCfQki+hSuxiByXwzNnCM8mMTbJBMxpIiPZEmYspTFGSaCMyzl1pnXVtmZ2eX80iXWStvszJzn5tlXWZpe4dLWFe58+Dl/+9vf+PTTT7l06RL37t37T82Ef3+trKzwyiuvfO3ZG2+8wVtvvcXm5ubeIuF3LN82N+1lL/v27dsD6O9D/g7Q3zTb/O9fu7u7fPLJJ197dufjz6gqC5gPuOn86RBtP9LT9oMBvE0yrzxsD/zqq3ucmT1PzJRF/4yV3ieNNP2vXox/sJG2l/jgnY8ezUlPyjW8pyV6HzPS+n/66f/VOHJPhMWHYxcfvvcxO7VdZF0c43MOOn9mQPfLUSyHBFK2Epc3r/Phux9zY/cWzk4Bd6PE0MOWQcMzVgLtKrXIIrfOv8Yfr73JnLZCcqzI2H4PhmetdD9uwtscImbMsF3d5dr2Tbar59CsxXrl98tuDM/YML7gQjWkqUWX6j8rL18m65ggMpTGcbI+BtD/GyvuphCR4Qw71V1Wi1tUI0uUxSpSTxJXY4iR/V7sx0XcTQplscZSfh1Hl5/Z5AqJ8QLO0yHsxyTcTSH8XfH60pq6RGIsTzFQoyzW6m7ltgj+njpAywNpptUl4qMFYqMFpsPzSLokvu44ynAOX1cMd0uEcnCOYqCK2BVnOrxIZCyPvSlM2FQgZqkQ6NGIj5fRbBXsDRJRY6aun+tMEDJkyAlVggNp4tYJREOcgT9YsR4PohgyBPo0IqYC09EVAvoM4kAazTWJryPC+DGRQFcM6/EgYr/GbGqNhGMCf59GzFxCHNDwtUfwtqlYjkvYToYoy/NMxZaRDFkSjgrqSA7naQXn6TC2k0Hc7SqJ8RKFwByKqUjMUiLnm0bsSTJ20MfY4QDjR0Tyvhk0WwXZkCFkyGJpFch5q7gaFQzPORg96EUZTJH3TBEeyhIfL6HZKmRc0yj6DP2/sWE56kfRp1ANGRRDGkWfYSa6TN47TXQkz9AfnBifdxIa0FD1aYQ2FW9rmHJwlglpnqxnEtNLbkZeciG0q4i9cbytYaxHA0yEZin4ZigFaliP+DEf8CB1x5B0CbxNCuZDAsHhGGWlRtY1ib8jivWY/2FTYgRJF2f8gAd1OMV27Ty16BJiRxTzQS9hQwZXY70W3nzQR3hQoyTUWClsogwksR/zE+iIkBzL4zwZxNUQJKiLoVlKJMdyhPUa3mYZ96k6YEcMGrZjAoEulbS1iNQVwXnCj9Cu4msL42qQCPUmCLRHcDT4sZzwEOpPYD0SYPyQF7knSqg/8bD2O0zUmMHXEkYzF5iJLFAOVMm7J1kpbHJh6RK1yCKbU2dZzKyzXtrhyvp1ZosLvHr1Nd668S5/+fNf+Mtf/sL6+jpffPHFN6rqtre3uXbt2teevfrqq7z77rtcuXJlb5HwO5Zvm5v2spd9+/btAfT3Jf9TgL5w4QIffvjhN1o4VvKbOI/76fypgdb/00/Xz4fwNIc4M3eBr766x71797i+c5PYcIbB35hp+eEAHT8xYPy9jYxjglcvvs79+/e5/dYH1KILuJsl+n81Rss/99PzuAlvs8Jieo23br3DF59/wdm5CyTNeUZfctH5cwNdjxmxHvURH8myUzvHh+9/xDuvv4uzVcDdEGTwN2P0/MKI4XdWpN4EtfgyZxcu8MlHnzKbWCUynMF6LMDw8y66HxvGdtRPxJhmrbzN9TO3uLR2hcngLP6uunmh+wkTphecuJvDlAP1eeRLm9epxZZJW8vYjgcZO+Bh+A8OPE0hIqYMM+oCy4VNarFFKmINoS2CuymM6WUPrtMKYleMamSRSXkejy7ItLqAPJjG0xzCcUrGfiqEs0mhIFSZTawQMWaYS64SHys80tj5uuIIXfVRg4Iwg9AeJW2rkHdNIfTEcbdFCBnzCD0JlKEsBf8M1uMi3pZ6wYivI4rYl0RzTuLrqgN3PlBF6IjiPB0mOpLD1RTC2RQm45smYa0g9GiknFPYGoMYDzqJjuTxd8cYOegn5Z4i66shGbKk3dNEx4pYTtRbFcP6LI5GGWUww0R4iWB/moilTEGYxdeVYOyIiL8zxuhBH+pwlqI4R1CfRR7KkROqZDxTWE4GcTYqjB0ScDWHSTsnSDonUYx5ivICCVsFsS/F6CEB6wmRQE+ckD6NMpwj2J9mPruJszuAYsgydtDP0HMOAr1xoiN5vG0q/q44eX+NmrZGQagyfjTIyEseLMdFgroEge4ojlMSk+F6yctUeAGhRcW034fYncDbHCbQGcV8SKAi11idOMOkskBoMI3xRTfB7jjB3gTe1hDmQ16iQ1k2J3dZnTxD1Jhh5GU3ga4o/o4o/o4I4we8yLo40nCMmfg8aUcZ27EArsYgyqCG0BbGfsyP53SIUqBG3jVJxl7GfjxQH5PoUIkZs4y+7MFxLEDKViHnrOA5LWE/ESDYE8PdKBHsiT4qSPG1KhR9U3gaJUZfcuE+JaNZizhPinUY74nibQkR7IgQaA9jO+Rl7AUHMWOamDGD/WgAsSeCu9mP4blxxg96cDUFMe93YT7oRe5LIHfHCXSEUfo1osY04cEEUUOa9HiBCWmWSqDKxsQOO7MX6nsEE9vsVM9xY+dV8qEy187e4O2b7/KnB39+ZN/4+03010HyuXPnvhGub968ye3btx+NcuwtEn538m1z0172sm/fvj2A/r7kH//xH/nyyy//W4C+fPky77///teeffXlV+xUz+E6JdLz82Fa/llHx48NOE6KbFR2+PyhC/qtW2+TGMsx9Kydlv/dR8cvhjD+wUF8NMfF9St89dU9vvzyK+biy7hOynQ/ZqT9xwMM/GYMX4tCLb7ErQuv8+DBA26cuUnclGH8oAfd4ybafzTI6EsuIsMplvMbfPTex7z/1geIw2G8rQrm/V7af6Sn72kznuYQJf8MO9VzfH7nLkvpNTKOMuOHfOh/Z6XnyVHsJwJEhtJMqwu8ceMttqbPUgnWENrD2I770T01guWwgLc5zEx0gbXKDmfnL1KLLaEMargbJQzP2jG97MbZqJC2lZmNrbCU36QWXyFlK2M7KWE+HGD0oA+hLYI8kCLnmybtmMDRLjARrCG0RXG3KFgaJNytYfw9cVK2ClJ/Erk3SdlfQ9JpeDqieDoiuJujuFpUNGuZ2GgeX5tKwTtDaLBekCL2JgkOZvB1x4mO1hf43M0hCr4ZEmNFnE1h/N0J4pYy4kCayHiJuKWM9biIvyNGxjmJu1XF1xGjKM3h7UkiGXKU5HlGjvgYPuQhMpzFcUrG2SBTkuYIGQv4dSkq4SWUoRzO5jDSQBpnY5jxo0FiowWyviryUJZSaIGMewZnk4KvNYKnLYKnRUHq14iNlxD60lTCi8ymN/B2xLGclLAcEXA1KoT0GeTBNEJPkoR9isXcNqXQAtYGGfPRAKMHvPg66p+z0BUj551hJrGGz6AQ6E9hOSLi76obOzzNKu5WlYx7ktWJs9SSq8TMRUYOCggdEZShDL4WFctxkdBgivnsBpvT58j5ZrAeE3GekhE6oiiDKUb2e/F3xZhWF1jIbDCnrTJ+xI/QEUFoUxE66oUllqN+pkILTMqzlMUaliMBPC1hgj0xAl1RzAcFRl7ykLKVkYajSP0xbMeCuE9J+LvqYxSuRpmR551IPXFK/hkSYznMB9yMH/QSM2Xxd6g4T9ZLVPxdMVR9ioghjeWQF/NBN/6WMClbifEDXtwNQTxNMmG9hv2YH2eDiPWwD/tRP2KHiq9VwdMk426QCPXH8bcpWA54cJ0MIrQq2E/4cTVKKP1xfG1hxg45sRxz42oIYt7vRuyO4m+L4DgZQO6JER1O4W2WkXpjKP3xunZvJEvRO8V2dZfF9BprxU2W85tsTu6wnNlgs3KGfLjEzux5br/54aOlvwsXLvDWW299o6ru0qVLbGxsfO3ZtWvX+Oijjx45pfcWCb87+ba5aS972bdv3x5Af1/ygx/84Btvlv/969q1a7zzzjvfeH79zC2cJwK0/J8+Wn84QM8TJhzH/MzGl/n0o/rs9Me3PyHnnGDsBRetPxyg40eDDPx6nIghxU7tPPfv3+fLL79iOb9BoCdC/69GafnBAJ0/N+A8ESTvmeSNm/U67wsrV8jY69Db+bMhOn4+xNhLLpQBjeXsOnc/+4I3rr2JMCDjOh1k5CUX7T/Wo/+tBc9pmRl1gcub17n99ofMp1aJDqdxngjQ9ZgR3VOjOBuCJEZzLKRWeef191hIrVEUprEcCTDyshvd02PYT4j4WlXSjgrLuXVWcltMBuvzxI5TEoPP2B76m0Wipjxpa4W8Z5JabImoKY+rUcZ0wIv5kB97g4zcp5F1TxAZTuPuDVDyTuM6rdTnexsVfO0RfB0xoqMFgn0pKv4qJWEGeUDD3aIgdEXxdsYI9NatE+7meilKRZ7F3xFD7tNQhrK422MInXES1jK+7nqDYcpWbxR0ngoRGSsQGs7h7UyQ9kwj9qfwtKrkPNP4uxLYjgdRhrLE7ROIgxk01zQZ7zSGF51YGwNER/I4Tsn4OmNkPNP4epLEHFNUtVUEXRJ7QwihM46tQcLbFkGzVxD60sjDeaqpNQrSHK7WKJ62CKMHfLhOK4QGM4THiqijJabia5TDi4iDaQJ9Gq42FVeTgqclUndOD2dZKmwzm95AMRWxNym4m8OoxhyB7hjuZhWxT2Mqssxq5Sz23iDutijOxhCu02FC/Rr2kzK+7hgToQVmtXXm0us4mlT8XTF8bRGcp0M4TgQZ2S8wEZpjTltjIrSAuzmM/YSIok8jdsUZO+hn8Fk7EWOOCXmO6egiziaZ8cMCvvYIwb4E9gYR3W/GUQY0ss5JSsEqruYQliMBgl0qgY56gU7/r8eR+pJo40VcHQHMB9w4Tor42yL1MYimEMN/cGI57CNtLSH1RvE2hRh90YnUm8B7OoTYHWH0ZTeWIwKh3gSJ0TyO4wHG9nuQdXGC3XUrh/2EgNAexn0qiKpPIbSFGXvZg+d0iJS9gu2YH/dpCbEzitQZxXbMj6sxiPWwgOWwD2+TTKAtgq9VxtcSQtbFsZ8W6P+dGethL65TQcwHPVgO+YgOZwh0hPF3hElZisRMWbxNMkpfEs1cIOussJTfYKWwyZy2zGJ+lZq2xOX1q6yXdoh70lzduclf/vyXRxD8+uuvc+3atW9U1V2+fJmlpaVvPLtz584jDd7eIuF3J982N+1lL/v27dsD6O9LnnjiCV5//fX/FqBv3LjBm2+++c0AffYWwa4IHT/T0/rP/XT8WM/oy26q6gJ3P6vbO95/8za5/4+993qS6zzsNvG32FWu3Vp//j7p00pWpCVSTCKInCfn0D2he6ZzzrnPOX06nM65JwcMgEGOBEAQJJgzRYpZzMEyDVe56tmLpriWJZpbe0OzNL8DkH8PAAAgAElEQVSr6XnP6ZqLuXjqrV+ILOE6GGHiF22A1t/vRDFVeOTsrbYd5L0P2KycQ1QpmB70MPFzE5pf2ogMyhzNbfL6y2/w6aefcnntGhXPHO7DcSbvMDPxczOejih5a50LS5f5+OOPeeziE0j6DJ6uGIYHPUz/kxXbngChgQQ13wJPXn+WF594mbX0cZIzRfzdIpq7bFh3+XHsD5OzNlgUj/LYhSfYrJ2lEVoiNqpg2ulDf78Ld2ecqCpLM7TEZvUsq5kTnG6eR5jM4e+RMO30ExpK4+kSyduatCIrrCknOFY4Q9k7j6wtYT8YJTySIdAnI07nSeor1IPLxHVJys4WWWud0FCK4FCG4IhCbFyhYJ8jbaixnDpGztokoSmTmi0Tm8ojTBXagTZNgZShxqK0QdW/RHRcIW1qB/8kXZWMrYlibRIYUUgZ68wLRwmPZkmaatQi60SmSqQsTeakEwgzJaLqPDlHi9BIhuBwuu19tjQRtBWWcmcoeJcIjKcJqVL4+pJ4+2XKvgUK/hVkS4PFzEnqsQ0SuhqV4CrSdKk9v22otps39A2W82dYr15ANtaRTU3k2SppU/u2OOtoIWgrNIQNTs1fpSkeI21utW+Mx7LEpovIuirCTIl6/BjHaxdYUU6SNDZIfRnwCwym8XQnCAzIVAMrnGpdZiV3BnNPmOBgmpSpSmK2jP1gFPuhOKK2zGLyOKfnL5M21vENJAkPZ0jMlomMpNE/4CdtqFMLLrOQ2CDvmcfXnyShLREdVYios8zc60aYyNKMrlILLpPUl/H0SCjmOqnZEuGRFLr73bgOx6j42u0Z4lQO58EYiqlGerZEQlvEstOPbX+k3a/tX8LRGcJxMIxiLFN0NImpsrg74ng74kiTOXKmOhljGU9HlNhwilZ4ieRsCdeRKN5OkZSuQnQ4TWI6h+tQlOiwjDiRpexs4e2MExlKEBtLU3K2CPRKuDviREZSJKZybbAeTSFNtT3OOUudkr2BfV+IUH97IEWayLZr7GbzREdkgn0i7sEYtsN+rPu92A8FCY0KODpDODtDeIcjOHpCmA94MO5z4OwPYDnsxj8aIR8tk3bnULxFsv4ijdQ8SUeWlrzE1fUb1JMtfvfiG3zw7od88cUX3L59m7fffpurV69+bVDw5s2bXLhwgc8+++zPzm7cuMGHH37I7du3uXTpEn/4wx+2goTfEX3b3LSlLW3btm0LoP9atGfPHh577LFvBOhnn332vwTtR8/fIjqaQnuXDdVP9Kh+asTTHeNE+Swffti2iLz89G9pBBex7Qmg+qme8Z/oMT7oQTGWeeLq03z++ee8++bvWctuEh1JMv0rC+o7jEz9kxlvp0AztMybr73Nhx98yLm5yyjGMu6O9s2y+mdGjNu9ZE1VNvKneP/3H/DQxsMkzVkCgyL6+12ofqzHvNNHaEimGVrixplbXD/5COcXL6MYqvh7JDR3OzA+6MV+IIRiqLGqbHJ57TrnFy4zH1shPVvGsjOAbX8E4w4fojpH1lJns3GeE+UzrKaPkzFWCQwkMe8O4ukWcR+Jk7c1aITXOJo7yUryBIqxhjxTxN0pEB1XcHcJCJN5iq45VtMnCE9L5OwNcvYmUXXbThBV5YiMKkTGslQDi6xmjiNN5al4F1HsTSLqAhF1jqSuRnyiQEJXoxldRVDniKvz1ELLyMY6sakSBd8Ssr5K0linGV8noSkQHE4yF18n65wnYaxR8C+T9ywQ15ZpxNYoexYJjykUXPPUo+tEp0sU/MssKScRZqpENAUkYwFxpkhCW6IlrCNoK6Rtc6xXL1Dyr5C2zlHyLRFRZQmrsmRtTVKWJln3POvl89RiG8jmFuVAe0zF3Svj608SGc+SNNY40brMcv4MoqGOpKuRmK0iaEt4eyQ8fQkCgykWEsc5vXiVnGcZQVMmNJ4lqs7h7U3g6pGIqLOUvIsspjZpiRvMHvCRNNSIjuVwd0sYdwUI9MvMSRvUI6uU/UsERrIkjVUKzjkioxm093qw7A2RtTaZF9bJ21sERzMkZsrkHHNkHQ0MD/oxPOglqa+StzRpxlfxdssUnC3y9haKqYa7M45+u4fUbJmcuU7e2sDbJSDPFqn5lyi5WriOxND9xoU0kWsv9enLTN9vJTjYXsKseBcJDMg4DoQJ9UtkDBUEdZ7goIz7SPs2Om+pI05k8XbHiY1mSM0UKTibuA9HcR+JkrfWqPgX8PUK+HqihIdlPJ0RAiMS3t4oxt0eLPv9SPoM1kM+LAfdGHY78Q7F0O20o9/rwHzAhWGfA+N+J/ZOH/ZOH7rdDtz9ISJTErM7bVgP+Qmr2t9pP+gnqpIJjSaIjCRIaLKkZ4uIk23bStU3Tz2wxHx0hQVxnbPzlzjTuMCZ5gUuH79GOdbk+smbNNJzvPrs73jlyVd587fv8K//+q/88z//M2fOnOH555//Wg/0o48+yptvvvkXp74/+eQTbt++za1bt3jnnXe2goTfEX3b3LSlLW3btm0LoP9a1NXVxeXLl78RoF944QWee+65rz2/euxhQkMyU780o/6JnpEfzGDb7Wcjt8nHH7cHWJ579EWKjia2fQHUPzcy+L1ppu+0k9QUubZ5g08//ZTfvfwG68oJoiNJZu91MPy/Z5i4w4y/S2A+usozj7zAu2+9y4Xlh6h55vB1C2jvsjH6Iz2mHX5kTY7TzQs8d/MFbp6/heIuE1OlsewKMPlLK1N32gkNyOStDW6cfoyrGw9zef1qG3r7JWZ/7UD3GxeO/SFSxior6ROcnbvItc1HqHjnSUwXsO0P4zwcQ/+Ah7gqR8k5x7mFK2zkT7GmbFL2zhMaSOLtS2LdH8F5WCA6lmU5dYz17EnmomvUfEuk9GV8/e2qNnenRFydI62vcTR3CtdgmJy1TsWzQHyqQHyyQFilEFHlkbQlVuTjVAOLyLNl5oWj5BzzCNoigraMNFMmqi5QDSxzNHeS+ESBlfQJWrE1Iuoikq5K3r2MMF0gY22ymjlJcrZKxlRjXtxA0leJTpVpSsdJWZskTQ0WkieITbZtDrXgCmlrE8lYpyVvkvcsETfUUDxzuPtFPL0S8ck88ekisZkSC+lN5lObRGcqKK4FUqY6weE0gcEk4nQRR5dMNbrOsdol0s55su4FJF0VT5+Mu1siPl0iOJwhZWqwVjhHNb5Byj5Hylwnrili2R/FdjCKs0uk4FmkGVunGl5D1NVI6GoUvYuER3MYHgxg3h8mos7REjeohVdIGGuYe8JkbXPk3XOY9kaYedBHQlNCMTephpaRZirknC2K7jkUWxP/oMzknTYSmradJqWrEFXnkGYrLEgblD0LhEbSTN7lwNstktKVKdib+HslImMZ6sFl6qEVMuYq2rtdBAeTxMcVkjNlIsNJAv0J5uLrNALLFBwNDA96iY6myejKSFN5/N0iMw/YSZvLNGJLRFUZjDu92A8E8fbH8fTFcHSGMOxy4eqLIBrS+MZizGy3MPlrM/YeP4b9bnT7HMw8aMM1GMIzGMY7HMF6yIf5gAfb4QCCVsG634e7O0x0XCZjLhHoF4iMJomNpoiMJBHVWdKGEtHhNMJEjqKt0c4cdEYJD8nkLDXiY2miYym8g1Fi6hShoSTiRJbYeAbXgQhJTZ6ye464SkFUZyk550hoCqQNFZblDZbkDRbFdY5XzvDo+cc51bjAucXLJF25toUjXuXp68/zxitv88pTr/H5p59z+/ZtTp48yYsvvvgXAfrq1au89NJLf/GG+sqVK3z++ed/0gm9FST8bujb5qYtbWnbtm1bAP3XotHRUU6cOPGNAP3yyy/z9NNPf+35heWHEFQZpv7JwuAPNAz/YAbH3gCLwhpvv94eSXnq+rO0oiu4DoZR/9zE0A+0TN1pRVArXF6/zntvv8frr7zJqfo5ZE0O43YXYz+eRfVjPZ7DMSqueR6/8hRvvfYOj118gpKziaerbeEY+7EO8w4fSW2R46XTPHbxSZ69+TxZd4XgcALb3iBTd9qYvtNKaECm4m5xYfkhHr3wOJfWr1H1zRPol7HtC6L5lRXTDj/x8QzryianW22ArgUWSevL2PdHcRyKoL/PTXg4RcZYZaNwinOLl5kX17/0N6cID6ew7AkTGkoRU+VYlo5zNHeK1ewm8+JRFEuD6HgOb1+7Xi08mqHiW2Szeh6/WmAjf4pGdIXIeJbgaJbASIaYuj0WcjR/mrJngapvmZX0CURNhdhEHtlYR5qtIOnaMKeYG8TVeRYTx1GsTSRdhbSlhWypI2gq1KLr5BztBoqspUHW1iIyWSRja1IOt60cinuRcnAZT5dEVKWQ1FXxDaSRjXWWlJNkXIuk7XPI1iqzu7x4umVSxirB0QzRiQKrxbNkPIuk7AuUI2uEx7JY9kXbIcpembAqy3ziOLX4BrGZGjnvEmlbE/9gEleXhO1gDEenRMm3wqKySco6T9a1QNa1gKyvYT8i4ugQcPfKpI0NSr4lsq4FSqFVKuE1ZEMdT7+MYVcAd7dE0bNAylBD0FVJWloEtDL1yCr+kQyz2wPotvuRdRUKrjlCYwpJa4uyf4m5xAnyrnn02wM4jwiEhjOIU0XiEznEmSJLqU3qkTWqgWXsh6I4O2KkjRVCoym8vRKOrji1+DLl4DwJQ4HZ7R60Dzhw9UTxDYuY9/vRbncSnpaJ6dJEZ2Um7rOivtuEYb8b40EvxoMepu434xgOEtelkYwKjiMBLPu8eHpjBEclXF1hLAcChEdkmvFl0qYqwqSCtytGQltCUGXJGCq4DkcJD6Woeuap+Rfw9wh4OwVSuhLydIHYeLpt1dC01wLz9jrx8TSuwxFC/QkagUViQ+3O6KShiDSdx98jEupPEB6QcR+JIk3kyVtqxEdS2DoChIcTuA5FMe304e2IERmS8XbGiY2mUAxVsqYa0kSWsmuOkrNF3t6k7l9gXTnBavoEp2pneWjjYS6sXqUQqXBx+SFqyRaPnXuC5x55kVeeevUrgD537tzXjqVcvnyZ999/n+vXr//Z2YULF76ygmwFCb9b+ra5aUtb2rZt2xZA/7VodnaWxcXFbwToV199lSeeeOIvnn366ac8fOpRUpoCmjutDH5fy/D/rcW000sjtMjLz7z6ZQvHqyyJ67gOhRn90SzDP9Aye6+TuErhZO08b772Fr9/6/dcWb+GrC1g2O5l5IezTP7ChPNAmJpvgYsrV3nv3fd58uozNAKLBHtEZu9zMvLDWXR3O4mPKaxlTvDYhSd45413ydhLhMdlzA/6mLnbwdSvrPi7RTKGMseKp3n95Te5uH6NkqNFsE/CfSSK9i47joMRomNplhLrXFy5yjM3n2NZ3kAxVgmPpDDuCGDc4SM4kKDsXmCzco6b525xvHyGRWmd4EAKb4+McWeAyGiGhLbISuYER/NnWM+dZD19su0DHsvh6ooTGlGITeRoBFeo+hZx9odZy5yk4Jwjps4RGlMIj2eJqAtkbU3qwRXCIxkq3gUqgUUiKoXIeJaErkpUXSJlrFMJLhMeyZDQ5lFMNaITeSLqPAXfMkljA9nQoBpawdufxNefpOhs4R9KE58qUI2sI1taiMYGDeEYvv40to444lSJ0EgGZ5dMJbjaBuKpCpXYUSKaLDO7vcQmigSH05j3x0joaywoJ0na5sn5lykFlvENZvAPp5Fnq9g7BKIThfZkuGORQmCNlnQC2dTAdkjE25/GcTiOOF0i52iRtM2RsLZoyZvMScfwDqZxHBHQ7wriH0yR0tfIWFqkbHO0pE3qwlFy7iUcXRL2w3HcvTLCdAFRWyRhrHG0dh6/RqbgWcTVJWHeFyY+rRAcTeLojuMZSlAKL1EVl5HMJXT7fKjvtWE8EMAzLGI5FGR6u4OQNonkyCNaFHQHPKjuMqLd7cK414NrIMrUfXbiugw5f4Osr0FkMolut4fweBL/kISvT8Cww0dgOMGCvMFS+hiKpYr9QARhIk9qpkxiOo9tX4RAXwL/mMCCsIY8U8LfKxIbSZHQFBAncwQHEgQHJPLmGlX/AtJkDk9HjMhwCsVcbdfhdQmEhmUyxhoZfYXoaArnoQiRoRTR4Qx5aw1PZ4z4aIbwgNweGtoXxLIniK8rjjiRbTeNqLOktUXCw+0avGCfiGWnH+f+IAltEWE8Q3hAImep4OwNY9/nx3M4RqBXwLzDh7dbIDaWRhzPIk0oZE1VUjNFpIkciaksBVuNgrNJ2dPi8vo1Li5f4dLqdS6tXqUpL3CsfBLZluHR809wffNR3njpza/g98qVKzz++ON/EaD/CMnnzp37s7Pz589/9fMXX3yxFST8Dunb5qYtbWnbtm1bAP3XIpfLRblc/kaAfv311/9Lr/TTDz+PYqiivdvC8A9mGPuRDsN2D1XfHM/ebHun33vnfZalo3i744z/VMfg96aZ+mW77m5d2eTt373DZ599xvXNR0jOFDDe72L0H2eZ/IUB654AWXOFiyvtOe/XXvodjcASgR4Rw2+8TNxhQnevk8hQkiV5g+duvsD7v/+ASqyFMJnG3ysxfaeV6V/Z8fWIVF3znG5d5O3X3+HK0essJY7j7RaxHQwx/U9W/D0igjrLknSUh0/d5Oa5W6xlTpCarRDoTaJ/wIu7I05wIEXR0aQVXuHC2jWO5k9R9S4SGcngOCBg3R/BN5gkps5TDy1T9y8xF11jPr5GaCSDvz+J7VCMqCpHdDxL0TVP3jWHrdNHxbdAfKpIZDxLYFQhNlkkOlEkba6T0lXaXmjfEnF1juhknthUEUFTITZTbrdoTBVwdUrkHS1S+hruLhFxpkzaNk94skTWtUDG0sDdkyBlrJIyVnF0iIRGs9SFdWT7HEnbHPX4UZxdCULDGYreRXz9KZxdCVqJ4yTMTRTXEovZU7gHkmh2ehGmiwSG0jg7BPLueRTvElFdg6X8WYr+FfwjCt7+DM4OEfuROIKmRDW2jmSZo5HYpJXcRJipEp0s4uuTsR2JEVFlSVmaJMxzLOROsVY+j2So4+hL4uyRcHRF8Q4k8I4kcI9kEK1VqslVEo4KugNBpra70OxwYe0NY+4MoN3vxa2SkFxFwtY0lr4wU9udGPZ7MB7wYe0Oo9vrI6JRqIrLVOLLyPYqxv0hIpocEZWCp0fEtC+EfyjFcuY4J5uXqMfWcXWJBAdTyIYKSWMF0+4wvp4EVf8yC9IxVtIn8PUmiIxniI5lyOgreLoE7Aei1MMrNMIrFNxN3F0i8akc6dkywkQOX6+MaYePnK1OQC2S0OQx7w4SGJCRpgokNAX8ve0bXl+PSMU7T2QkjetQBOuuAGl9u5daGM8SGpaJDCWRJnNI6iz2fQGse/yEh2UyhgreLoGYSiGhKRAdSbdr7joEHPsC2PcGSOmKBPvb/dN/7I227wti3xvAfTiG82AI58EwglohrS8jqNJYDvuJjaZw7G0/F+yXcB4I4esR2t3PhgriuELe2g4lylN5ktoiNf8CK6njbFbOcG7+EqebF7iweJk5aZmTC2fI+go8fPIxXnj0Jf7lX774E5/zX7ph/o+Q/Me1wa8D6Nu3b3Px4sWtIOF3RN82N21pS9u2bdsC6L8WRSIRUqnUNwL0W2+9xSOPPPK152+88iY5Y4XpX5oZ+v404z81Mnu3g6ylyotPtNs7Pv7oY05WzhLoaXcyq39qZPIOE8F+mY38KX7/zvtfVdQV7Q0cB0Kof2JA/RMD7kNhyu45rm+2/4aXnnqZZfkowX6Z2XtcTPzchGmHj8hIkkXpKL994TXefv0dSsEm0XEZT7eA5i4rs/c4cR6MohgrrGc3ef2VtzjVuEAjuEh4KIVph4+pu2zY94cJDSap+5e4sPwQp5sXWEkeJzCQxN0lov21A0+niLtDoOBosiBvsCgdZT62RkpfIjiQxLI/jKdHxNUTR5zKkbM2qHjnqHgWKDrmCI9l8fRIuHoTBEcUfL3t+rOYKot3NErJ0SI6qhAYSuEbSBJVF4hOlUho22uDGVOdenCJ8JhCZCxHQl9F1FcRZiqkLQ0CA2miEzka4RWCIxnCo1nS1iaCroYwW6McXCOkzuLsksiY68Qm89gPx0mbGyiuBULTZcqxDYr+ZbwDKURtmdCwgvVgjJg6R13cQLLMkQ+ssJA5ibM/gWtIRJop4zgi4B9IUY+vETc0ULxLLBbPEJutYOtJEFQpWA6HsXZECU4reCcyeCayZKMLSO4qusMRZvf7mdruRL/fjfGwH8tQBNuwSNxRJOGt4hyRMHdHMRzwYzgUxNwRxjEg4J9QaKSO0kxvkHS2cA+nCKlziDMl3P1J7Idi+AYyzKdOcGbpGgGdQnCiSGAwg6gpktbXsB2I4umXyTvmmU+d4PTiQ4RUOWJT+XZH9WQBT4+A9UCUZmydRnSdeniV8ESO4GiGjLlBZDyLu1tCc7eTrLnOnLBOObCEq0vC1SEiagpkjHX8/TLa+1yEhpLkbU1qgWWch6LYDoTbQyxfVg0ad/gJDSbJ6Ks4ukM4D0WwH4wQn8giTeUJ9ifxdMQJjyRJzBSJj2fxdcWx7gkQ6G33V8fVGVyHY3iOxEnrK4QGZLzdApYdfiLDMv5eEWkyR3QkTVylEBmUyZprOPaHse7y4+8SEFRZvJ1xpOkcKX0ZaTJLbCRFfDyDdbcf+94g/j6J8KBMdCSFOJEjNVvEuNuJ42CAyEAST2cc654gwX6RjKGCqM6S0ZcpOVrI2rZ9pOKaJ2uqUna3uLh+jbPNC5xfusKFpcvcPPc4m9UzFPw1FF+BR889ye9eeIPfv/Eef/jnP3zVtPGfYfg/Q/Ljjz/O22+//V8C9FaQ8Lujb5ubtrSlbdu2bQH0X4symQyhUOgbAfrdd9/l+vXr/yVAVzxzGH7jZvTHOsb+UY/+fidlV5PfPvcan3/+OR++/yHHiqcIDSTazRk/bTdsBHpFjhVO8eEHH/H5559z6eh1cuYq9n1BJn9hYvQfDRge8JCaKfDQsYf57LPPePLq07SiK/j7E+jutDPyQx0zdzvx9Uo0Qss8ff1Znn/yZQqeBq6uCLbdQaZ+YUbzazuOg2Fy5hobxVPcuvQka5lN8o4GgX4Z3f0u9Pd7MO70ERlJkbc0uLR2jfnYGgviOnF1FufBCDP3uLAfDGHbGyJjqlHzL9EML7GSOo48UyI8LKP/jRf/gIxtfxRhIkfW2qDsnqMVXqFgbyJrS7g6BHyD6TZA9yWRtEUyhhpBdXvJLmWsEVErBMdyRNRFQuMK4VGF4FCaun+Z1GwZ/2CKxGyJuKZMeKpIytJANtUJjiqk9BUUcwNXh4SkLVPwLJIwNpCMDUrBVWLTJWKTeYrOOVzdEsGRNJXICuHpEnFjlWJkldBkHkefRGQ6i+VwGP1eLzF9Do86g6lfQnCWCeiy6I8EMXWG0O5yM/WgA2tvCJdawtQfI2TOI7oqONVpQloFW08M06Ew9s44/okM3okcxfgq8/mTiNYWcWMdUVchMlnE3ZMgOKbgHkxTCq9xcukqDXkT0dwgrikTmywSHlXwDKTwDmVIGBqsFM9yrH6JhGWOmLZMbLpIcETBcUTA0S2Rdy1QF44yL5/AOhwnOJYlY2sQncpj2h1mZrufiCrHnHSMeuQokq6KuzdBZDxHylgnOJpm6k4HoeEMiqXJvHQMUVPA1ZMgqsoSHc+RMdbQ3uPC15+g4JgjY6ghTBaw7ouQtbcQpwqERhWMOwLY90dJG6rk7U1CgwkMO/wIk3kUUx1hIo9xhx/bvhCiOo+sKTKz045ph5/wSKoNsdoC7s4YgYEEsdE08kwBb6eAdV8I58EIRXuD6Ggaf1+7l1zWFEhM5oirMhi2e3EfiiJO5EnOlnAfjuLvSyBO5EhoioQGU3i7BAJ9CQK9IrKmgDCpkNTmCfUnqHjmiasUHAfDxEZTiOosni6B+HgGxVxFUCmIE1n8o1HcHVG8XXEiwyl8XTHchyPExzOkZkvE1RlEdRbFUCGjKyFNZSl751gS11kU1liSNzg9d5Hzyw9xonSGR889TjZYohit8uTVZ3nt+dd59dnXee251/mXf/mCRx99lNOnT3/lX/5LkPzqq6/+WVPHfwboV155ZStI+B3Rt81NW9rStm3btgD6u6jNzU3+7u/+jr/927/F7/f/f3qn0Whgt9u/EaDfe+89Hnrooa89f+2F31Gw1dHf70L9cyMD39cw+XMjaV2Zl59te6B//1a7os7bFW8/8z0N4z/W4+uIsSCs8s4b7/DJx59wfvEyieks+vtdjP5Ix/APZ7Hs8KMYqpxfusI7b7zL1eM3qHrn8PUKTN1pY+RHs2jutOHrFqh5F3j8ylM8fPomJX8TX38M+/4gYz8yMPlLE6adftIzZdayJ7iwdJnTjXOUbU2C/TLaux3M3OdCf5+b2LhCydniROUsi9I6q1/2RbsOxzHtCmLeHcRxMII0mWcpcYxmZIVWdI2stdGGnl1BvH0yhh1+IkNpkjMl5qKrlFxzpA1l0voKjiMioTEFb3+yPcetypG11XGPRBGncmStrXbvsKpt04iqC8SnSyRmqhRd8wSGk6SMFVKWGv7xLN7RFOHpHI4+CddwAkGfw9ETw7jfR2g6hX1IRNcRwTmRwDYooD8SwK2KY+zwM3G/A89oDO+kjHlAxDOdIWYs4RxLEjXkic5mMR8K4uqXkG11AlMFkvYWrexJooY6wZkScUMe/1AGT4+MrK8SGM+RsLRYr16kIpxAMDYp+FcIq/O4e2Wi6hwhVYGgushq5QILmTPIziWyniViUyUc3QmcnRLBsRwxTZFabIPl4nmSriUkQwNxtkJIncO4J4zpQAxnb5JG/Cgt6TiKb5nwZInwRAFJV8HZLWHYGcLVkyBpatCIr1EKrKA9ECA+UyKiKhAezzLzgA9nh0jOOU/GModibeEeSJN1zJE2NwiOKMzu8KG5z03G1KDkXUCYKmI9EkXQlCn7l0iZ6uh3BJh9wEtgKI2kKTrST0wAACAASURBVJCzNzHtDiJOF8hZG+Rdc7i6RQwP+knqisTHFWKqLObdQcKjChXvAoqphrdLwrDLjziVJ2OsIk3mGf7FLM4Ogay1Qc2/iLMjhv1QhNCgjKwpktQUCPRLeDqiZHRVSs4W8XGF4KBMoLdddSdpCvi6RZxHYmRMFTKzZcKDCQS1gjSZJz6Wafviu0R83XF8PRKp2SLO/WGCAzKxsQxpfYnIcIqkpogwlsXXJRLsTRAeTuLrkfB3C+3/95kiup12UoYyqZkijgORtk1qKov7SIzoUJKqe65tKZlQKFrr5Mx15OkCc+EVFoR1FoR1llPHePj0Y1xavc6V1eukPQVygTKPnL7F4xef4vUX3+SVp17l048+5caNG1y6dIlPP/30awH6ww8/5MaNG1/9/o/jKf/x2a0g4XdH3zY3bWlL27Zt2wLo75r+/d//nb/5m7/ht7/9Lf/2b//GP/zDP/Dss89+43vr6+vMzMx8I0B/+OGHXLp06WvPX3zyZXLGMpq7LPR/b4rB72uY/pWNpK7I45ef5NNPP+Xt373NgriKuyvG5B1mev9hguEfaHEeCLIgrvH8rZd4//fvc6Z5gdRMAcseP8P/W0P//5zCcL8beTrHmdZFXnrqZa5u3GBJOvrVrHb/9zVof2UnNChT9y5yaf0aV4/fYD65SnBEwnUoyuSvLKh+asS0w09iIsfx8hmO5U5xef0qBVsDUZ1j5h4X+ge8TNxhITKcJGuusZ47yUbpNK3YGvJMEfvBCPaDUfTbvTg7YsTHFRqhFer+JTbyJynYW8Qncrh7BJxdIvaDUUIjKVKGKlX/PDlLDcVeR9TmsHXGcfQI6Hf7sXVEcPTFSDnK2PqC2Hsj+FUShsNBZvb70B30oT8cQL/fh39SxD+ZwLDPTWhaJjCdxNYbxzEg4h1L4R5KEtbkyLkbWA6FEbRZiqEFgpNFotoyhdAaoekykqnJnHScwHAG30CSjKlBTFsipClTTxxD8SwjGFq0pONEVFlc3TJJY9vuEZoq0pA3qYjHSNjmSbpa2PsFrIdFAoNp4lMlvEMZiqEVlssXiJnnULyryMY69iMixgNRfENpLB0iCVOT5cJZFP8qCesckqFOUJXDtC+CqzuB9bBIbKpMNbZOXTqBZJsjrqshztZwdMvodwZxdIgk9TXy7kUy9gUES4uEuUneu0xQlUdzvxfNfT4i41mKnnkS+hrhyTKmrjB57zIl3xKmvTGm7/Xg6paQZstk7U18g2mS5gaKY468Z5GoOs/kXS4S2hIxVY6IKounT0aYKTGf2ECxzRGZKDBxpwN/f4qcrUlcncfZIeDpkWjE1qiHV5E0JTT3uPH2SsTHs2StTYIjadxdAmXPPI3IGiXXAqadwfaIyXQBQZUlPKIweZ+ZvK1B1b+INF3A3REjOq6Q1JZIa4sEeiS83QKBfpG8vT3G4+8RcR8WSOmKxNUKsqZAaEQmOppCnMiTmGq3aPi6JRJTeTLGGoE+CXEyS0r3ZSBwWCYynMTfKxAakCk5WsRG0kSG0ySnC0iTeVwHwjgPtQE52J8g2C+RnClgOuRBUGcI9bfDurb9Qex7Au1BlkGZ0KBM1lSh6GgiTmTJWWuUnU2KjgY13wLr2VMcL55mI3+Kh9avc2X9YcrxOnl/mcfOP8kTl57mySvP8MpTr/HpR59y7do1bt26xRtvvPEnQPwfIfk/A/Mf/vAHLl269CfP/8cg4SeffLIVJPxvrG+bm7a0pW3btm0B9HdN165d4+677/7qs8/nw+fzfeN7Z8+eZWxs7BsB+pNPPuHChQtfe/7MzefJmWro73XS//eT9P69GvUvDEhTWa4ev8FHH37M6y+/yVHlBKGBBNO/MNPzP6YY+aEO58EQzfAyj118gvfeeY8r69fImWvY9vpR/dhA399PMnuPE0md5XjpNM89+gJPX3+O+egqkZEU03daGfyeFtVPjfi6BXLmOmdal3jy2jOs5I/iHYhi3x9m9h47E7+wYNnhIzqSYUFY5+z8RW6cfpS6dxFxIodtX4TZB9zM3ufC1RklqSswJ65wonGavLNGfDrN7IMeDLu9DP/UgGGvB1tnkJSjSMqeIzoj4xkKM7vHzfR2O6p7LEzeb0W3z01AJSKZMsRmMgh6hehUCltHFMvhCObDYdz9CcJqhYK7gbXTR9bZoBldJTpRIKTOERhVCKvyCNoytcAyaX2V2HiWamAJUVslpCqQMNVJGOtENWUqwRXSxhrePpm8rYmoKRDTlJGtLRTvEoKhSSGwRtJYw3ZIQJgskDHXcfbIJK0t6vJJIroaac8yRf8qxj0hHB0i0fEcjl4Z30iWhewZMt4VRPMcGfccM7u9GPeECY8ouLuTeAZS1OJHKcWPIXuWyYfWiWpKGPdFcHSKuHqTuHqTZB2LVIUTxK0L5IJrpGxzeIez6HaH0O8KYTsikDQ1yXsXEW3zJByLZP3LZFyL2DsTzO4MYdgTRtCWkfV1ZPMcineJYnCVjH0B/3ge/b4I1sMCYVWO2FSRkKpAyrFAcDZNObhKaKKI5oEApn1hZGMVYbqIpy9JfLZKJbTGYuYkinOB2QcDWA9ECatyKNY6UVWWsDpHNbJGM75BSziK9VAcZ7dIYqZIeCRDXJ3DeTjGnLROM7JGyb2Ao1PAcShGxlQlqSvj601g3h0ioS1R9sxTdM3j6hSxHYoRH1VI6cokNe3bW9MhL3l7g5ytjr+/PSAjTOaQJvLERtIE+yWiY2mqgQXSM6V2w0xHDGmyQFJbQFAreLtE/H0S6dky4kQWT6eAeZeP6Gia2LhCQpMn3C8jTRfw94rExzO4D0Ww7QvgORJDMVba55NZsuY60ZE01t0BAt0ijv0h7PsCxFUKsdEMkZEUliMepEkF004vut+4cB2K4DgQxr4vQLhPIq0rIqgUkrNFCrY6yZkS0kSWkqNF1TNP0VLn7MJlLq9d4+qxG1w7fpNWeplCuMzJ0jkeOX2Laxs3eP3FN/jiiy+4cuUKr7zyCs8888yfAPF/huQ/hgRv377NZ599xtWrV//sxvqPz5w7d24rSPjfWN82N21pS9u2bdsC6O+aFhcX6e/v/+pztVplfHz8G997+OGH6e7u/kaA/uyzzzh37tzX30A/8QpVdxPDdg+D35um5+/VqP5Rj6BWOFk/z0cffsQ7b7zLqfo5wgMJ1D8z0PN/jDP0gxlse4IU7HVuXniCjz74iEcv3KJgq2PbG0D1MxMjP9CiuctKZDjFcuIor774Oi8/81sWhTUEVQbDb5wM/3CG8Z/pMe7yIuuLrOY2ePLWkxSDNZwDIabusTL2cwM9/3OSqXstmA/5kEwZ6tk5Gtk53EMRdDvtqH5tYPDHGsbu0KHb5cQ/JpBxlji5dArFWSGuVbB3RNDv8jB9rwNnRxRff4Kcvc5y8ihr2RMsJ48SVeUIDqYx7PDh65cJDKYouReoBRYpOudZkDZI6qqEhtveXd9QhtC4gqSvUHEvYj7sJ2+rk3c2iajyhMdzRKdKxDRFhJkyGUsDb2+iPfdsquEfVohMFJBMDcKTJRKmJhlbC3e3hLtbIqEp4eyW8Q0r5LxLJO3zRHV1avENnJ0i1oMxJE0RV7eEo1sm719B8a0g2heoCMcJqQoY90UIjioEhtOYD0QRZmu0MqcI6RsUYseI6StM7fRgPSzi7kmg2xPCN5yhKm0gu5dIeZcpRY8S1VZx9qbw9snM7gzg6UuRsc+RDaySDqxRFY+Tci3g6EviH85g2BvC3ScjzlZI2OZIuZZpZk5RE4/hG8tjOiRg3BvGN5xGnC4TmykhmFs0kydpJU9SCK5i60pi2hfB3Z9GNlSJTBWIzVRZLp7Dr0lTE47iGsxg7RCJTeWJqttWFFdfirnUJqvFs5TDa/hHFAy7w4jaIilje+xFvzuErK8xLx5jWdkkrM5jPRwjOJRG0pRQLE0MuwIkdBVqoVWqwRXS5jquIwIpfYXIaAZxIo91f5jQSIpFeYNacJmISsF2IIo8U0Ix1oiOZLDuj2DeG8LeE6AWWCI0nMS4w09gQCYxXSQ5W8TfKxIYTBLqT6IYqwR6RVwdAo4DYRIzBeJjCqGhJNHxDMJ0Dn+/jK9HwvSgD193nNBAgrSuhPtIjNh4hrgqi79bwLjdi/FBN/a9QRwHwl/2RKeRpnOE+2WC/RKmHT5m73Zg2R3A3yPhOBBCmlAo2FoYdjuw7w3h7xEx7/Cg/bUd95Eo9gMh/D0CGX2ZgrWGNNkOHSrmKkltEWFcoWhvcqJ0muPls5xbvML5xStc3bhBPbZIMV7l4ROPcmPzJi889v82cVy8eJEPPviAa9eu/QkMf/bZZzz00EN/FhK8ffs2H3/8MQ8//PCfAfQfnzl37txWkPC/sb5tbtrSlrZt27YF0N81LSws/BlAq1Sqb3zvmWeeYc+ePd8I0J9//vl/CdBvvPoWjdAyph1ehr6vYeB7U4z/1EigL8HZ+Ut88smnfPjBh5xpXSAynGDyV2Z6/8cEA/9rCu09NpK6AmfWzvPMM89wev0cwTGBibtMdP5fY3T9/ThDP55Gt9uBZEpzbO04x4+eIKqVmN3lQHXHLH3/e5KBH0wz8xsbgVGJZnKJp556iro0j280hvNIGM09NlQ/M2B80I27K0bR2eTWxSd57MITrKWPERlN4zwSZ+IOC9a9QZyHohQcDebFNS6uPsRK6jhFRwv/lzeFpt3B9hS3KkvVM8969iQV7zz14DLR8SzeXgnjnhCBkRTubgHFVEMx1yg4muRtdSKqPMGRDNYOCf9oFv9wmvhUHnm2jH6Pi4ypgrdHJjiebdfcTRWJTJYQtWWEyQKuLgl5pkxwRMHdJxOdLiGZG8Rna2ScC0TGchj3hpFnykjTJYx7Q+0ead8KYW2dpGsRxb2IYW8Y70ASaaqMaV8U+2GBanwD2bmEYFlgLnsa74iCo0tCnCxgOyJg2B2hHFom6Vkh4V5iLneWwFQe7d4A0ckCziMihr0RJH2VbHCVmGWOucJZiqF1PON5XP1pXD0y5kMxwmMFiuE14tZ5qslN5vNnSdrn8KsLOHtkrJ0isekSCX0NwT5HI32K1cYlMv4V/BNFfKNZfAMZAmN5giMKgakCxfAqmyvXaaY28apLWDokvMMZpJkSvr4kpkMxotoKS4UzyP4KSccCtq4EgWGF+FQFQVvCdCCCMFOhGllnPrVJQzqGvStBytQgNlUgOJrFsCuAdyjFUmaTprhB1j6Hs1du305bmsS+9MLrd/jJmBo0hXWyzhaWfTECQ2li4zmy9hbuHumr2+estUHaVMW8N4RvMIE4mSeuyhIcbAdSE9NF7H0hQoMpDA96cRyKkNAUESfbt9yejnbgT54u4DwYwbzTi+5+N75uEWk6T2Q4TXgoRaBHRJzIYd8XwrzTj+5eJ97OOIHBL4OG0wXkmRK+7jiB/gSm7R70D7gxbncTGZXxHIkhTeQQJ7OIqgz2/WHcR2KYd/jR3evAvDtAdFxBmswRG80wu8dGeEDGstOPrzOG50gUw3YPwX6JkrNFUptHmsxTcrRI60rEx7OUHS0qjgYlV4vTzfOcaV3g/PIVLq1d45HTtzg5d464QebK0Ye5efZxXn32d7z5ylt89snnnD9//i92PX/88cd/Um/3yiuv8MILL3D79m3ef/99bt68+WcA/cdnzp07txUk/G+sb5ubtrSlbdu2bQH0d03/fy0cr7/+Ovfee+9fHEf56KOPeP/993n33Xd56623OHXqFK+++iovvfQSzz//PM888wxPPvkkt27d4vq1h4nrUozeMcvhvxvhyP85Qvf3xpnZbkHxFTl79iznz5+nmmhi3Otk6EfT9P2Dmt7/NcHEnSYi6iSXNh/ipZde4uGLj5C3VXEciqL+uZ6RH2pQ/dyErzvGXHSFt19/h3fe+D0b+ZPExzMYH/Qx+hMDkz+z4NgbRjHX2Syf5Y1X32I1e4zwpISvV0R7t5PJf7Jg/HIaueZf5MbpR9ksn2VBOEpsJIPzQJTpO21YdgWw7A6Q1JZYFNdYTR9nPr5KTKXg7ZXQ3OPEdjCGYZefmEohZ2lQ8y22/c2mdjWZoyOG/bCAtz+FuyNOxlAjpa+Q1pWRNWXCI0p7xrtPJjZZxNOfIqJSCAykcfWHkbQ5vD0JAiMZvENpwhNFQhOFNqB2JwgOJik6WriOCPgGkkj6GnF9ndhsjbx/mdB4DnuHQHK2jLc3if2IQNLcQLLPEzc3qMaPI+hqOAfSCFMFAoNpjHsixDUl8uE1gjM1cqE1asJxHP1pItMlguNZrAdj+AZT1MTjCPZF0r5VVuuX8EzmMfcISLoajk4JZ1eCYnCFhGuJTGido3MPkQ2s458sfuldTuDslglPFIjo6yScS6y3rrBUvoBnsoJfVcDZm8Y7lMbTIxOcyOOfKLJUusDxxWtkA2sEp8oExrIE1EV8fUk8QxmCEwXKkTXWa5doZU4TmqoQ15YRZyv4B9MY90VwD6ZoysdpCBv4dQrBqTL+0Ryivn07rX3Aj2FPmIShzpx8nLpwFO+IQnA8S0SdJ2Go4e6T0dzvIW1tolhb1EKrOLsThMYURG2Z8Gi7v1tzr5vkbIWydxF5poTlYATjrhApUw15poKrR2L2Nx483SKytkTW3MC4I4DuAS+BAZm0qYYwkcWyL4yvX0YYzzGzw451Xwjddi+ebpHomEJ4NI27S0JQZZE1JUJ9SQy/cWHeFcC+14+gThPokQj0S7g7BDK6Mv4+EW9nnJm7Hdj3R/B2CggTWUJDScLDqbYFYyyN61AYx4EQ3i+bM/y9AsmZAmlde35cnMjh6xGx7PLj7ojh6Yxj3x8iOpYhPVsirSujud9IZCSFr1PAutuP+UEv7kNh/L1xfD0iGX2JtLGMMJ4lZ65SsjdITOfIW6qsZjZZkI6yLB/jzNwlrp14hBOlM5yeP0/SpXDj1KM8eeVZXn3udX73/Bu88vRrnD555qvVwc8//3/Ye6/nuM4zX5d/x9ycmtme8swee2uP7LE9trdly5YlZhIkQABEzqkBdM45r9Crc87dyASYM8WkQImicg6UJVsSFceSxp5h1VTNcy5aVh1vydtzrqRdxlO1LlDfukEVqvD017/f+376R6XA69evf/7z+++///nPt27d4oknnviCQP+hSPiHvPQmX0++am/aZJMtW7ZsCvT/bfzHf/wHf/3Xf83rr7/+eYnwueee+8J7LpeLyclJent72bNnD3fddRd/9Vd/xTe+8Q2+8Y1vUKvVuHDhAvfffz+XL1/mwQcf5Nq1a1y/fp2TJ0/y1FNP8dxzz/Hiiy/yyiuvcPPmTd544w1ef+111lJHcXaEmfi+npE7NYx9R4vvoMz9y1f45JNP+PTTT3noxCMk1QU0d9sYu1PD+J1aLDt8ZE1VnrzSKhs+98jz1APLeHpk5n5iaRUSf2FDGIqxGj/KCzde5uaLv2I9dRxpMoVlj5/pfzYy9QMjph0+EuoSF5au8vjlp1lJHsY1EMbZLjJ7l42Z/2VGd58beSpDybnA5Y2HWJaP0AwfIjSUwNoWQn2vE/12H479Ail9hfXUCcqOBZbEdeJzJXx9CbRbPXh64+i2ehHG06QNVSqeVcrOJdLGKvJEDuOuEJ7+OI6eKO6eKJGpPHF1iaJjiaSmTExdIjicxDeSRpguERxNI8/kCAwlcQ1IiBNJouoy8lwJcb6EpKkR0VSR5sr4h1OkDTWU6TyurhgxfQXF0EBQ11GMTZKWRQKTeWR1haJjGXu3gjSdpxTcIGZdImJZpBk7RdTUIDCZp+hdxTeYwt2XoB45StS+TMK5ylLhHGnPIURtjbR1Ef9QGkuHTFRfIeVeJWxsslQ4TzN9Fvd0Hs90msB4HltnhMB4lqihTlBTo5E+w+HFB8kIR0i6VpE0NXzDGTyDKYT5Mv7ZCvnAOsdWHqaknCTlXSdmWUCcL+M4GMMzmMYzliPtXGExc47F3HlkyxKSvk5UX8M3msG8T8baHUXSVFlInGI5d564a5XQXBlZV0fRVrF1RTG0tbLSuc/WfZuGZUKqEknrAtJ8GddAgrlfehFUecqhQ2Sdy4RnClgPRlHUVZLGBv6RNKqfe7AdkEkYatTD63iHkhj3tWIuMW2rgKjb5sfXn0CazBOdKxEeT6Hb7ieuryFP55FVRaz7JTy9CkXnIpGZ1rZB/VYv0nSWrKVOeDSNbZ+Abb+AosqTtzWZ22ZF80s33t4oKUOZ5GfTYUJDyc83BAYHY7i7I7i6JOLzJcTJNOJECkVVIDKdJ62rEByI4uwI4+ySiM3mCQ3G8ffFEMbSJLUlYrMFYqo89j0hfD0RnG1h/L0KvoMy0nir+FdyLRAcihMciCKNp/D3KFh2BwiPtyQ80B8jZ6pi7fa1Rt2NpYlMpTDt9OA8IKLM5AgPxwkOxMiZqyS1JZSpDBldmZq3NcGjHlhlLX6MtcRxViJHeOjEozx2/kmOlk+RC5a4dOhBHj1zg8fvf4qbz/2Km8++wcmjp7501vP/Lsl/KAnevn2bt956i6effvoLAv2Hm+zLly9vbiT8GvNVe9Mmm2zZsmVToP9v5OTJk/zt3/4tf/M3f4PP5/vSd65evcq1a9d47rnneOONN3j77be58847PxfcPxfh+FPvvXfrfdaTJ3B1hJj4vp6hO+YZ/yc9ni6ZU5XzvPv2e3z88cdcWruKMpNBe7eDoW/P0f+tGbT3OElrS1w7/Rjv3/qAR8/doORaxN4WYuL7Bgb/YQ71z+wE+6M0g4d44vLTPP3Qc6zKG0ijKQzbPUx8T8/kD4zY9oZIakucad7PhdUrrKWO4B4IE+iPofqxBdVPLMz+2IowlKToaHKseJa12FFW5COI42l0O3zM/9yO5j4X9rYQMVWeZekwRXvr3ZS+TGg0jW6bH2e3jGVPkNBompS+StHRpOJepmBfIKGtYNsvtfLC7TKhsTTCWJqcpUHB2iChq5I21/EMJPCPZvGNZwmMZhCni6SNdYT5JOHxNFlLk7S5jqguI85VUAx1ZHWFiLpCyb2ENJVDURUpedeIWRaQtQ3SnhUi+iaKvkHRs4IwkcG2XyRlbpB2riLM18n418n6DyPqGxRDh1F0VUz7JMTpAklLA8nQIOVbZ7lwgYRjlYznECX/Os7eON6hFFnnEp6JPDHXCocXHiTl20C2LSCZy7iH0tgOKkhzJfxTBQKqMquli9TSZwhbligIG0jzZcwHIjj7YriH03gni1Tko6xV7ycZPELcuULE1MAznsW4X8LVn8Y7kiUXWKciHSUTOkrMsYyiryHOVzB3yuj2hHH1J8h5VigG14k6lvHP1xA1FaKGBs6hJHP3+jHuFYgbmxS9ayiGBrMdQWRtFUldI6qrodkdxtYhI0zlietqxLRVrJ1Rcu4VEsYmgqqIfp+IfleIvGOB6HyJ4FgK/d4QEU2FamidmKaKYbeAdpsfYSJLzraAoiph2BkgNJah4F6hGlrD2xfDvFdEmSsgTWbJmhvY9gsER9NkrQtkzE18A3Hs7SIJbaW1gXIszeTPjLi7ZZLaCmlTDWe7iPugjDiWJq2vkNaWsbWFcHdLBPqVVryjQ0SYaN1Cp/VVYvMFItMZvAcVhNE4wYE4/oMRgn0xpMkMUVWenLGGv0chNJYkOBQn0KfgaA/i74sS6FOQp9Kk9GWkiTTCUGvajbtbxNkRxt0l4uuWic5kEUZTWA54yNsaRGdyOPaFcXdJ+HoiOPaGkMZTRKYyiKNJssYqDf8qKV2ZrKFM2b5AzbtE3b/K4dRxztTPc7pygQePPsqR0klKUp3jlTM8euZxnnnwBR6/+BSvPnWTU8dOc/v2bW7evPlHs56/TJIvXbrE73//e958802ef/75P7n+++rVq5sbCb/GfNXetMkmW7Zs2RTovxT+8z//kzvuuOO/lIG+ePEiH3/88Zeevfv2eyxHNrDuCDDy7XkG/l7F6J0a3J0iG+kTvPHqr/now484Xb2AOJ5EfbedgX9QMfjtOfRbPaS0Zc4vX+adX9/igeOPUHUv4emSmPqhkd6/nWTq+wa83QrN0BqXNx7ixv1Pcrx4lshkFuM2D2Pf0zDxAyPG7a1RWevJ45xbvsKZxfMExiVCw3HUP3ei+l8WNPe48PfGyFvrrHw2iaMZOkRSXcK0y49xd4D5u+y4uyOERlKsKodZjhzmSO40aV0FX18U824By34R694w0kSOsmeFZvBQ67bauUzSUMPRFyc4ksLRKROeyBLXlakHD5GzLlB2LlNyLCPOFBFVBbyDKcLTeYTJPFX/Go7eMO4emZJrBUVXJaQqIs6VkdRVpLkKefcKJc8ynp4YylyBkmcZWVsnYmiS9qwhGxdIWBephA7h6U8gTucpupcITBeRDE1qsVPEbEvE7CutIuFAAsfBKAldhfBsCddohlriJFnxOJJ5kUbiNMJMAdM+idB4Fv94FvdIhrRvneXyBRL+DRTnMh5VGvMBBdvBGKGpHLb+JFFzk9XS/cT962SloyQdK7jHc2h2h3EPJjB3K4jzFUrCEdLho8iuVWK2RQR1FVNnBH2biK5NIKgqk3Eukw9voHjWkA1NYpZFAtMF9HtFtLvDeIczxM1NIro6smWRhGOJnP8wkraGrk1CsztEaDJPRF1GVJXwTOXQD8qUhCPkPGuYO2PM/NKPbyRD0tQgbqji7ksSNS6Q86xRl44hqyvM/tKLMJNDmikQ19fxDCQRVEVq4mGyjhVi+hpzW30o6iIpY4PwRAZPXxxrh0Q1fIiydw1ptohmewBPX5yYrkrWuoC7N46lLYQ8UyBjbRLXlbG1ywjjaSJTOZKaVv595h4z4mSGhLaCfzCBtSOMPJMhrasRVRUIDLb+9gIDcZK6Ep6DCs5OCXu7QFxTIqktI05kCAzE8fbJhIYTrZvlHgV7Wwh5Mk1cXSCmyhGfzZMxVPF0y7h7Ini6BNzdEp4umZShTKAvx39XYQAAIABJREFUSkpdJGuuIU2mMW7z4OoQcHe0JDk0ECcynUHf5kaZzhIajOPYH0J/rxNbW5DgQAxnRxh/n0LJuUBCVyKhLlB2LVGw1omq8pRcizTDa5QcTU6Uz/Hg8es8cuYGx2qnaCZWOVI7wenK/Tx88joPHXuU159/kwvnL/xR/OIPIvzmm29+YTLHjRs3ePfdd7l58+bneej//bl+/TpXrlzZ3Ej4Near9qZNNtmyZcumQP+l8P9HoK9cucJHH330pWdv/eodViJHcLYHGfqf83T/zQSD/6DCsS/EsrzB6y/+ivff/YDzy5dJzRfR/dLB0P+YY+CbM6jvcRCZynKyco53fn2Lxy48QSO4ir83wvzdNgb+u4qpHxpwd8mUXYs8dOIaz11/kZPV88Tnihi3+5j8Jz0T39Vh2u5FHstwJH+a6/c/yZXjD+MeFvD2KWh+4WLupza09zgJjyaoe1c5VbvAo2dvsCRtkNSVsbW3yoHaX7jxDcRQZgssy4c5XjrbKhG6F/H1JwgMJtFu8+Ptj+EbiJO3Nqh4lqgH1yi5lolrKq1IxGAC24Eo0mQrvrEgHCZjrJM11an61xBVRcKTBbyjGaTZErKqTMG5iHtYJqLOU3QstZaFzFWQ5spI6hoRTZ2MdQFlroD7YIyCY5HgWA7/ZAHZ2CRqW0YyNMn714mqy1g7I8iqIsp8FfdQGsXSpBI9QcS2Qsa3Qda9iqlNxDPYioxYuuP4p/KsFM+jONdIBTeoRI5h2C+i39O6HbX1xbEcjFFVTpAWjyM610iF1jAclNDuDmPpjGDtjmLrSZC0LlBNniLmXycbPkbUuoStP4mlM4KhTcB0QEbW1MgGN4j4NsjLR0l71hA0DYwdUXT7JAz7RcIzRRR9A8m5StSzRi50hJx3HftACs2uMOYDCrKuiqKpIlsWSAY2KErHyAYOI+vqaPfJWDsVxLkyUX2N4FQBxb5I2JSnEDpC3LSAZo+IuzdJXFtHni3j7EviH89RDK6znD5D2rmMbq+EuV0iqq2QtjbxDCZxdEeJ6urkfassxU5g6WrNfJZmikRmS8Q1Jcz7BTL2Jmlzg7i2gqcvjrsvTsHWim6ExzLY2mXk6TxFzxJRTRnLXgF7u0RkNk/B0UQYz+Dslpm910pCVyGhLePriWHfLyBOZIjOFkloS4THkq0b5skM4lgGZ0e4tfWyP0pivkB4LIU4kUGaao2N83TJuDtFtPe6CAzFCAzESahLBAfiRKZyCCMJPF0Spp1+zLv8OPeH8fdHEUcSpLQlsqYa/t4Ijg4Rx74Apu1eLLsD+HsVbPtDRGYyuAeCCONJjFvd2NqC2NtC6O91Yd8bxNUhII4kiKny5M118uYaibk8WVONgq1BdDpH2lDhdOMiZxcu8cDxR3jg6CNsFI9TF5epxZZ47MJTPHzqMV56/FU+/fRfuXTp0hciGn9q++Arr7zy+fPqq69+qUA/99xznxcTN4uEX0++am/aZJMtW7ZsCvRfEnfcccd/KcLx4IMP8v7773/p2a3f3OJo9iTeTpmJ72oY+AcVw9+ew7Lbx0L4EL9+/S0+fP8jrp1+lJQ2j+6XDvr/TkX/36uY/6kVZSbLuaVLfPD+B7xw4yUWpXX8PRHmfmph5A41s3dZ8HbL1L3L3Lj0FG+98Q4na+dJGSpY2gLM/NjM9I8s2PYEkCfTrEaPcPPF17l67Bq+URHPQQXTLh9TPzRh2OrFsS9M1lzjcPoUzz76As3gGgl1CWenjHlvuJUv7VEQp7LUA6ucW7zIWvQo9eAa0lSrSGjcFcQ/mMTTo5C3L7IoH2YhfIiF8DoJbY3wVA5Lu4RvOIOrL9HKnRrrJHVVyq4lEpoywc9uc70jGcT5MsJ0nqyliWGfD3Eq3ZoPPJZFmC0S0deQdTVkfZ2opoJvMIk4kSU+X2rddk/mSbpWkM1LREyLFPyHMLdLmNoE5NkCtoMy5s4Iac8aCe8GknmZavwU3pE06u1B/ENJXL1xjPskouYmxegpIu41SsoJFPMC5k4FR08Me1cU7a4w3tEsi7mzyK5D5CPHiToW0XVJ2PqSOPrjzG4LYOuKkQ9uEAscJh4+RjF6AsXaxDaQwTuSQbdXwDmcImZeICsdJR46SiV5mrx8DO90EedIGuN+Ce9Ynoi2jmxaJOHfoJk7SyNzBtGwgHUgjblTITCWJawq4xnJ4lfXqCRO08yepSgcwzaYxdihEJguENXX8A6ncAynSXtW8c2nWcqfxTtVxNIVQ1AViWpr+MfSWLqi1IQjFPyHyLjXCM6VMB9QSFkaxDRVAmMZNNsDRHRVlhMnKXjWcA0kMXcqhCfzZExNopoyup0BPAMJCo5FaqENJFUey34JZb6INJUnYWrg6lZw98XJWhdaWxxHEpjbQsTmCyT0VcJjGVx9Cu5uBWuXn7ylibtLRnefB8cBkaS2TExTxtkVITSWIjScQJpIY9/fKsSadwXwf7YkJaYqEFUXECbS+HujGHZ4Me7wYt0VwNMpExpOtdZ5zxdJ6so49oWxtQWZ/5kV804fpu0+QkMJggNx4nN5QsNx/L0K5h2+z8/tbUEsu3yk1AXSpiq6XXZcn42sM9znwrzTh7dHxrLDT3g4QcW5QN7aIDGXJ29rRZ2UiQxZc526f5mF0Bonaxc417jElY2HeeDoI6xmDnP+0EXi1gwPHLnG9XNP8Nqzv+K1517n3OnzX4ho3L59m1dffZVXXnnlj+T4vffe48aNG7z44ou8/vrrXyrQN2/e/KPV4Jt8/fiqvWmTTbZs2bIp0H9J/FcF+tq1a9y6detLzz5470PONO7H2yMx/l0dg9+eY+xOLZY9AZakdd5+8xaffPIJTz34DBlDBfNOL2Pf1TD2XTXqn9kRxpKcXbjEb3/7MW+/+Q6LwiF8vQqqH1sYvVPLxPd0mHf6yFtrXDtznd/+9recbV5s3RrvCzJ3t5WpH5kxbvcTHkuwKBziuUde4NFzNwiqFISxFM4OkZmf2NBv9+DsFMlbGpwon+PqkWsczp4iqSnjG4gz/3M3hp2t0V/CSIq8pcGZhQtU3Is0Q2v4BxM4e6IYdgUIDCVwdSvkLE3K7iUKtiZ5Sx15rkRwpHWjGBzL4u6JIU3mSOoqJDRFkupWaTA8lcM1kCQ0U8Q3kSc0liE0lkGz042syuDqknAPJgnPFAipK4iaOknrIsJUAeOuEKGRFOHRNOa9ImFVkaTnEJJ5gaRnjbh5AeN+Cc9ggtBIBvV2P97RLKXICWT7CknfBpXICczdUVyDKcITOXR7Quj2CpTlY8QC60j2NRaKFwjOV7D0xJHmKzj64uj2hsl51igoJ1B8GzQKF5CdC+gOyvinCrj64pjaJcKzZfLScSLedZrlC1RSpwkZGrgncjgGk5j2tX6/iKFBwLhIKXOWpepFMqENPDNlHEMZbH1xApM5/GM5vHMVkp41Di1doRQ7QVBTxzmawzeWJzxfxtWfxDmSIelepZE6TT15GtG4hHUw0ypVaqp4BpNo94qE1RUaiZMEDVmijhXMPUmC0wVixgayuoJ6exDfeJasa4WFxCly3jVsgykU3Wc5dE0VS4eEpUOi7D9E1rFE2rGAfp+IrC6TMNURplsfXHS7giT0NWqhdcSZIoY9YRydEeLaKln7Iq6DUSztIuGRNMpckeh8EeOeILYDIqHRNEltlfB4Bk+fgjJdwLjfi32/gO4+H+bdAcSxDNJkDk9flMBoishMnqSmjG1fiNm7rKjvcWDfJxCbK+DviyFP5/AfVJAmW8tPHPsE5u6yYW0L4etTUKazJLRlovMlvD0Knm4Jyy4/jvYwtl0+PJ0i/v4oSW2JjKlKsD9GsD+Kq0PEuM2LcZsHx74Q3oMy8mQaYTyJud2Dr1vG0yniOSBh3RVAf58bX1+UyGSW8HCCpKZA0dEgNp0hZ65RC6y0pnMYahxOnWQtdozD6RNcXL7K4xefphJa4HjlNGWpziPnbvDU1ed5/blf8eqzNzmyeJzffvjbP4po3L59m5deeombN2/+kRz//ve/59KlSzz77LNf2Fz4h+c3v/kNp06d4t///d83i4RfU75qb9pkky1btmwK9F8S3/nOd/jwww//rEA/+uijvPXWW3/y/OrRh/H2RBj/jpa+b04zeMcc+vtcVN3L/Ob1t/n000955dnXKNgbmHb5mPy+ntF/1KD6iQVxKMHR7Cnee+d9br31HkdzZxDG0hjuczP5fQMT39Nj3xskZ65z9dg1fv36bzi/cJmCtY5zv8DUD02MfkfH/C8chIeTVD0rPHHlac4uXSY4GyU8ksC8w8/0Zxlox/4QKW2Z44WzHMmcZFHaQFHl8fXFmLvHjbktjO4+N8pMnqJzkeXoUbLGKglNa46wYVcI834Ryz4R2z6ByHSegnWB6Eye+HwR/2AS31ASS4dMaDqPs1tpFbjG00gTGaTxHIHhNMGxLL6hFMJcmZCqhDRdwN2fwLjfT2AkgbNLJjiZJTBZQNDWCWlqRI1NvINpbJ0KSW0Ze4eMozeBoqshW5cRTU0KwhEEdRlbT5yopkJoIov1QISosUYmsIFkW6GgnCDtW8c5niM0UyQ4kcOwX8Q7mqESP0XYsUpGOs5C6TyuiRJhTZXQVA7d7jDGfSJJ5zKiY5W4cIT15QcIGBvoBxQUUxNbbwxTewRJUyGgrSO61jiy/gjl1Bn8+gaCpoZrII29L45vJEtovkJAW6OZP8/6ykOErEsE1DVcw1l8YznMB2TswxncqhIl5TjL5fvJyMfxzNfwzxaRtDWcfQksndHWzbJ3nVryFPXMGYK6JuH5CoqxgaSpot4ZwnwwRt63Ts53CNdcGv9sheBshbixiTBfxrRfYnarn4SxQSV0hKxrGXN3EvdEnoi6RtLUxDuSYm6rn8BImoS+Rsm3hmGvgGswSURdQZ4vI86W0GwLENdUkFVFQmNpjLvDqLd6SZkaKHNlvMNpTHsF/ENJ8s4lQqMZ5u9xo/qZC3efQt6xSHA4gb1LxtMbQxhPY+zwYt0bQv0LF7b2MNJ0Dmk6T2g4RVSVR5nJ4e6SMO8O4NgnYN0XIjicwNujII+lkSbSJDUlQiNJ7PtCGLd5se0N4+mR8fcoiKNpwqNJYjMFggMxQoMxrDsDuDsEjPe5cXeKCKNJlJkc4miKyHQO1wERd5eMv0fG3hbCsNVNaCiOOJYgOBjFsNuBPJnBuT+Mu0PA1hbAuieAs6N1Ky1PpgkNxkiqixQsdRLqAtGZLFXPMnlLnUbgEOvJYxzJnGRNOcrFtQc5Uj/OycY5VvMbnFu9yLWT13ns/JM89fCznFo/w6033/2jiMbt27d5/vnneeONN74gyBcvXvzCxI7/7/PGG29w5swZfve7320WCb+mfNXetMkmW7Zs2RTovyR+8pOf8Oabb/5Zgb5x48b/8b0HTz2KOJJg5icmhv7HPIPfmkV/r5uya4EXHnuJTz/9lBcef5mqcwnLLh/Dd6jp/eY0kz8w4u2PspE9zavP3uQ3N9/iUOwY4mgK9c/tjNypYfQ7Giy7/aS0Fe5fvcoLj73UinBoyrgOCEz/yMrwnRrUP3cijCZpBte4uPYAh3On8IyKuLsk1L9wMf1jMzM/tGDaFUCZznK8dJacpc6SdAhhLI2zQ2DuF06se0Nof+kiMBwna6qRNlTImqqkDGWCIyl0O3x4emOY9gp4BxKIE1lic0ViswVShgrSdB7TPgFnTwzPQBL7AYXwRBb/QIKkrooykycyVyI0kcUzkkHSVAlO5hCnC/iHU7gHZUITCUJjWaLqMqKuhqCpEzG2CnL+iRxRTQ1lroS1XWzlbC0LiIYmEesSWe86PlWZ4HSJpLmBYbeA5YBEyrGEbF9Ftq1Qz5wj6lzGM1Um617B3hvHuDtMzFAlrKsju1Zolu4nr5wk9FlhzzWYQr9HwD+RQzY2cc4UKafPsty8gttQx6HJEZwuodsrYu2JIsxXcM4UiXnWWF9+kEzkOJJzDcnYJDBZwNQRwT2cxjGWR3EtUU+fola4QCS4gWhuIpsa2AdTGPdHsAykkfR1SvIxirETSJ5DRGyLyPoG/qkiur0Cmr0igdkK+eAG+fAGQfMS3tkKEXOTqKmJrS/O7FY/7qEMKccySecyum4B12SBqLmJrG/gm8gzu9WPbyxNZL5GTF/HNZDEcEAhZmgQ0bby06ptAZw9cVKWJlFNCVO7xPzWAMGpAkljg5ihjnpXCFdPDHGyQMpUx3VQQbMtgDRVQFQViWurWDtl3AMxUpYG4bEM7v4ouu1+xLEMcV2F4Egax8EIrp4oKV2NtLHKzN1mdPd5sbcLKLNFwqNJ7J0y/qEk4kSauLpIeDSFdU8Ie7uAq1PCdUDG2xslMp9DnswSUxVwd8sE+mK4u2Q8B2WMO314uiWcnTKxudaHQWE0hXV3AH9/FOcBEcseP65OCfdBCV+3THyuiDyZwd8fIdgfaxUE7/Pg7pbx9UXxHJQQRmIYdrsI9seIzuYJDcbQb3Vjbwvi743g6hQJD8WITKVbc6VVecquRcrOJildmYKlQd23QsW9wIq0wfnmJS4sXKYZW+F0836OlE6yljvM1aOP8MxDL3Dl6MOcWDnNe299wO3bt3n33Xe5ceMGt2/f5plnnuE3v/nNFwT5scce49q1a5/fVH9ZhOPy5cu88847m0XCrylftTdtssmWLVs2Bfovia1bt/L888//WYF+8skn+dWvfvUnzy+sPUBoKM70j4z0/b2KgW+p0N7jIG+u8djFJ/n444958oFnyZpqWHZ6Gb1TQ883ppj6gZFAf5S1+DGeevBZXn7mNZbFQ3g6ZWZ+aKLvmzMMfnsO41YPCU2Rk+XzPPHAM6ynjhGdy2FrCzL5AyMj/6hm7i4bgV6FinORI/nTHM2dxj0cIjQSR/NzJzM/saH6iRX7vjDieJpFaZ2SrcnR3CkiU1ns+wVUP3Og2+ZDe6+bwECCjLFG1lhlNX6UnLmONJNHvzOIuzeBaVeQ4GiaqKpI3rpA0bZAztYkaaji6FLwj6ZxDSTwjSYRJrMk9DUyxhriRJa0sUFgLId/vFUA9I1mCU8XCE/l8Q0rmPeFCY1lSJibhOarCPo6McsCgrqCrK19lpPNYO+UkWdLRK2LCPoFMoENovYVZOMCGfcKvqEUxjYBcbqAoqvhmysT961TSpwkbFwk5VtH1lZQb/Pj6okRM9ZxTxUQbUssVS4S8x8m6lmnJB7F1hnFdEBBmi/jGM3im6+w3LhENnGSkGuJkKWMb7qAvk3GO5LGPprBOZYjJxymXrxA2LdBWj6KoK9j6Um2RLs/hW20FbsoyCeIyUcRPWvIlkVCmgr6dhltm4S5O0bStULCuUQ8tEHQtkzY0EQwNnAMpVHvFTC0RxDmq8StC4Q0NVzzdSRjA9nYwDOZZ2ZbEGNnBFlbRZ6v4p5IM9kWQNA1iZoXkPU1NG0ihjYRYa5MwryANFdC1y6TcC4Rsy0i66uYDkTRtYkk9HUic60FN7q9IaT5CkX/OhFNDeMBBf2eMFF1hZSpQXA4jXZnsPXNgblJzrGMrVPG3BFBmMgSUZfIWBfQ7wli7ZAIjqSQprI4Dyq4++PENGWUmQLh8Qyz99iwd8oIYynCY2kMO/zYD0SQp3LkbE2UmRymXUE8PQqOAzLiZBrTniDubhlHu0BcXSRjrCKMJHF2SrgOiFj2BHG0CwQHY3gOKgSHkigzeaTxFMJYishkGuM2L+ZdPhz7gvh6o/h6FBKaIoH+GOHxFOGBBJ5uGcN9bqx7gzjaQvh7FJztAq6+ILG5ljzb94VxHxAx7/Bh3e0nNBjF3SHg741QcS9RtDdbN9HWOgVrnfhcnqK1yYKwTsWzyOH0SR4+cZ2FxCpXjjzI2cX7WStucKZ+kauHH+bMwgVOr5/l97/7/R9FNP4wF/rWrVtfEOSXX36ZS5cu8eGHH36pQL/yyis89thjvPTSS5tFwq8pX7U3bbLJli1bNgX6L4n29nYee+yxPyvQzzzzDK+99tqXnn388cecW7gfX2+E8e9o6Px/xuj9xiSau20kNSWuHHm4laM+fZ20roJph4fRO9V0/bdxJv9Jj+uAQM2/wnPXX+CZay+wohwmPBxj9i4rvX83zcgdGvT3uohMZdjIneTJB57hTOMCSXXxs3nRRobuUDPzv6y4uyXqvmWOFc9weeNBvCMC8lQG3VYfqrtszP7Uhqc7gqLKsRI5wtHcGTZSJ0ioSzg6BPQ7/WjvdePokPAPxql4FsibGxzOniZjqCCMpdHvCuLoUtBuCxAYSSFMZEgbqmRNdXKWJlljHU9/kuBEDnu3QngyhzCdI2OsEZnJI01kSOgqSPMlgqoigek8wmyZ8EyRpLGGe0DG1BZEVhURpgsE5ysE5ytIujqCuhXjiBuqmNsEAgNJ0vYmnvFca/qGeATJukTEtkJFOIKzK4rjYIyYpoJ7NIN3pkgleZqY/zAR5xr19GlcA0mMeyVCE3k8oxkMvTES3nVKqXOE3WsU46eRjQ3U2wNYu2N4RtKYexMEtRUapQtEw0cR/YdwzuewfZYxtvbEMHTF8KtKFKQjJCOniIlHibhW8cyX0O6TsXRHmd8l4B7JErUtEhOOIAQ2kJ2rhIwNTP0pNPtldPslnEMZwvNlos4l/O5VwtZFFPcKYU0N9f4Imj0i3ok8CdsSgrqK37SIZF8mEz5MxLqIoSvG3J4wgYkckraKqK5hG0pjGI1RFI6R9h3COphmemuQsKpIVF8nMl9G3xHBM54n7lyiLB4lNF9hdluQwHiOmL5GyrqAtVPB2q0ga2oo2hqKvs7cthARdRllroQwU8A7lES3M0TWvoiiLuPoi6LfHcI7mCZnXSCmLuPui6PbGcA3nCRnXcA/nMSwI4B3oLXhMO9YJDCaRHWfFXu7QGg4ifuggqNbwtUlE50rIE1lESYzCGMpQiNJfD0RTDuDmPeEcHVKhMdSJLUlfH0K8mSGwECU8EgK804/rg4B7b0ugoMxgoMJkpoS8mffrjj3i9j3C9j2fJaF/my5ir9PIWeukbU08HRJGLd7MW31tuR4X0vazbt82DsDxGfzBPsVbHv9mHf4sLX5MW33YNrhxdMlo8zkiKpyJLVFio4mCU2RnKlK2bVIQl0iPpfnVPUCVw9f49qZGzSTS1w8dJWzjUtkfUWeuPQMD594jGvnr/P4jSe+ENH4t3/7N27cuMH777//BUG+desWZ8+e5be//e2XCvQLL7zACy+8wPXr1zeLhF9Tvmpv2mSTLVu2bAr0XxIDAwNcvnz5zwr0888/z8svv/ylZx999C+crl5AGE0w889Gur4xTvffTDDzYxOx2TyPnH2MTz75hEfOPEbVs4hll5+ROzUc/G/jTP6TDleHwKKwzivPvMbz119kI3MccTSF7l4n/d+aZexOLaadXpSZHCer53nxiZe5fOhBMvoKjrYQMz+2MPl9A+qf2/EclCi7FzjbvMiNy0/jHhUQxlJo7nUz+zMbsz+2Yu8QCQ4mqXmXOVU7z3riBFlTFWd3BPt+EfU9bhwHRHx9CnlLk6p3mUZglaK9SXgig3cwiWWfgKM7gvtgjIiqQMHeJO9cRJnJk9CVcQ+l8I1kMHdGEKaLuHvjpI01Iqo8UVWBlL6KMFskOF3EP5EnNFtCmC+jzJdxDcrYu0VShjrByVZGOWJYQDYtIuobpJ0rhKdy2DpkEuoy3qEk1p4Eor5O3L1O2LBI0neYiLbK/LYAnt4EoqqA8YCCd7pIPXsWyb1BzH+YSuwkhv0Sur1hAiNpjJ0K5t4Y9dw5lNBhouGj1DNnMfel0LdJ2DoVNG0C2n0SMfsy2dRpgr514sJhDMMxNO2R1vzmAzKavQLh+QqlxElk4Qhx6RiKZxXXZA7dgRi6jgjGziiCpkbcvYIsHicmHSER2kByLKPvS6LZL6FrjxBUVZB1NUKOJaTAOhnpKGnxCPapInNtIuaDcQR1jeBUHudEDr95gZxyjJx0DNGyyHy7jLU3TkTfRNKWsfYlcUxksU/GSQfWSXjXULfL2PviyOoaiq6GozeBqTtBxrVKyrWCZFhAt1/G0hsjYW4S1dVwD6XQ7Q4jzJXJew6Rsi2i3SPhGkwhz5ZIGJtI80X0e8OExjMIMwXk+RLGfQK2LoWUoYE4VUBUlXB0R/ENJohrK3j745j2hjHuDhOZLZKxNPH3J3AcVFDvdCFP5xCnclj2Cui3B3B0RYhryyS1Zfz9MZSZPMHhOM4OCeueII4OAdv+MN6eKOGRNLG5ItH5Asp0DmtbCN09LrT3uHC2h/F0R/D3xwiPfHYLPZ3BuieIq11k7qc2TNt9mHb6CQ7GUaZyJNVl7PuDOPYHsezyY97jx7TNi21PEMN2L9J0itBUFHeHiP5eF7Y9fozbvZh3BXC3i9jbQgQGoiQ1ZUquRdK6KlldmaKtSXQ6S2K+SM2zzIpymGO509y/+gAPHH6YklDnbPMiT1x5lqQzz5WNh7l+7gkevXyDy6ev8sGtDz+X3evXr/PBBx/wyCOP8NFHH31BkH/3u99x4sQJPv300y8V6GeffZY333yTixcvbhYJv6Z81d60ySZbtmzZFOi/JGZmZj7/x/F/el566SVeeOGFLxfoD/+Fy4cfQprIoPqRgYG/m6b/76ZQ/dhCYj7PE5ef5pNPPuHph5+j6l7AtifI8P+cpe/vpxm7U4t9X5i6f5nXX3mDX738JseLZ5DGk2h+YWfwjnnGvqND+3MHwmiC1ehR3nz11zxw9Bp5SxVnl8jcz+xM/rOe+bsduDoEspYaZ5sXefTC4/gmZMTRFJa9IWZ/5mD+Zw5M2/1EpnJUvStcPfIQVc8yGVMde6eMrUNC9VMH9nYR854QaX2VBWmDRvAQZfcisqpIYCSDYU8Yz0ACe4eENJUja6lTsC+QNdeI6aqIk3kcPTE8Iyn8Y1k8PQlS+iqRmWIrWzqRxTOUJjCRxT1t8q/QAAAgAElEQVScIzRXIThZJDyWRbPLg+OgiKIqYO+KEpwpEbEsETY0kc2LxC0L2LsiWPaLhEeSmNpFbP0pku41Is41RNsKFeUYjv4E2h1hvP0xjHsFNLvCRCyLpMRjhByr5OInCM6Vmd0ZxtEbx3pAZm5HEN90kVr+HGLwMEnlBMnABpahFObuGPb+GOp9ErbBJNX0KcTwERKxk8TDh9ANxbGNpHD0JZjdGcLSoxCzL6OIR5EjR8nGTxD1rmEdy+GcyKHfL2PtTeGbyCE5lgh61yhkT5NPnMSjbWAeSaPvVPCOFwjOlHBN5gkYG6TCG1Ty55Ddq5jHcugPRPFNFQioSlh7EzimSySD6yR8h8hFj2GZKGA4GCekKiOqK9h64xgPxojYlnCo0mQD6zimSxi7YwiaKlFTA/9EjtkdIaLWJjHzIgnHCrbBFMbuGIqhgaytIcyW0ewW8I3lKPoPEdFUsfcn0LaJKNoqSVNrc6GpXcZ2UCGhr5N3L+E8GEO3M4R3KElEXSZjbeLqieEZiCNNFxAmc3gG42i2+vD0xRCmcohTeYIjSTwDcRw9rQ+F+m1e1Pe6MO0IIE/nCY+ncXVHESczSJMZxPEM5r1+Zu+2o7/Xja0tRHSuQGgkSVJTwd8fw3FAwrjdg71dQPNLN+ZdAZydIrGZAmlDldhsEfMOL5adfubvsuLsELHsCXy2/KQ1V1oeS+Fql7DvDaG/z4VhqxvzLi/WvQHEsST+oSi67Q7c3TLuAyKmnT7MuwJY9/jR/sJJoFdBmckRmcoSU+VbC1Rm82T0FWreZcrOBTL6CmvRo6zFjnG8cJbzi1doJpc427zEheWrNOLLXD3+ME9deZaHzl/jofsf5tWnX+eDW61Ixosvvshrr73GQw89xMcff/ylknz8+HH+9V//9UvPnnzySd555x0uX768WST8mvJVe9Mmm2zZsmVToP+SMJlMLC8v/1mBfuWVV3j22Wf/ZITj+v1PEFXlmPuJmb7/Pk3vN6eZ+IEecSzJo2dbEZHXX36Tum8FR0eIiX/SMfitOcbu1GDdG6Bgb/LsI8/zLx/9C8cKZ4hMJNH+wsnYd3QM/+M8ml/YkcaTHEoc58UnXuGRs49TsDVxdoio77Ez/j0jMz82Y9oVJK0tcf/SFR488QghVQRlJo/noMzcz+yof+5Ec68baSpH2bnEmcYFav5Vio5F/P0xjLtDaLd6MewMYG+XSMwXWYsfJ62rUHYtERhO4RmIo97qxzeSQrvdT2gkiaIqkNRVWlM2pguEJ7I4uqN4x3L4xjN4BpOERtL4+mPI4xkcnTKhiTyuoTTBuQrhudbGwfB0jtl7ndg7BKz7BMydEQLTeULaBiFDE8Wy3FonvUfA3hXBP5BEvd1PcLpAJnSYsG2FqGedTGgDU2cER2+c0HgW3e4w5i6FUuQ4ou8QkUBr/Jx1OIN9OENosoC+TWJ2W4CUa4WYdIyg5xDV0nkk6yLGgTShuTK2gwlU9/rxTeaI+dcJ+w9RLp8nJh1GOxzHNV3AMZRFt0/C1pdANDZxG+sUcmcoF88jutdwzJWxD2cxHIhgOxjHN1XEpqkiuVepFM+Sip7Arq1hHy9gG0zhGsliORjDNpFFdC9TTp0gqxwnYFnCPJrFM1VCNixgPqCg74ohGOrklWMkg+uE7UtYRvN4p4oI2gaBmSIz24N4VSVSvjU86gwBXR19XwpBXyVqaCCoK6h3hbF0KmRcq5RChxH1NbTtEQRNDcXQIG5sYu2KYdgvIX520xw11JndFiAwnkPWVhHnKjgGkhjaBBLmeuvbhb4Y6u0+DHvCRPU1Yvoqzt4YjoNRAqMZcpYm7p4oc3c70Gzz4+5rFRX9w0n8Iyl8w0n0e304OyXU97hR/9KDp1shNJomOJQkPJEhoiogT2UxbvOjvtuBbnvr/eBwEldnhKi6SGg0SXgoifOAhHG7j7mf2jDu9OPqFAkNx4nO5hDHUri7ZZxtIdxdEvptbozbfejudeE+0JrEEZ8v4OoUCPRFMe1sxTvMO/1Y9gYw7/QR6Itgaw9g2uPG0yXi61GwtQUxbfdj3OHFdUDA2y3j644gj6cRx5LE5vKU7YtkDGWi0zlK9gYle4OF0CHW08c5UTrHRuI4SXuOxy89zQNHHubU0hlOL53noWOPcmrpLBePXubNl3/Dr195i9u3b/P222/z5JNPcvXq1T8pySdOnPjSeMcfRuG99957PP7449y6dWuzSPg15Kv2pk022bJly6ZA/yXh9Xopl8t/VqBv3rzJU0899advqJ96lagqy8wPTfT87RS935xk4vt6wiMJLh56gA/e+5Bbb7/LkryBu0Ng6vt6Br41y/Adc5h2+Mib6zx24Unefftdzi9dJjFfwLw7wOT3DAx+axb13U6EoQQr8gZPXHmay0euUfOv4OmKMPdTO+Pf1TP9AyO2thBJbYlzixc5kjtDcDaKMJbCvk9g+kdmZn9uZ+YuK8JwioK9yVrsCEXHAhljBd9AHM1WD4adfvRbvTjaJcTJLAXnIuJ4ioSujH84hfWAhHGPgKsngbktTHAkgTSTI9AXQxxL4elP4h9KYd4fJTRVxN4bxT+cxtsfx9OtEBxO4RlIEBzL4RnJEpivElJXCc0U8Q6l0O8N4B+J4+iK4BtJE5gqIJoWCRkWSLpX8c8UsXVGSWpr2D9bdy1pyojOVUKWZdLCUWTTAua+BMHpAr7+BHP3+nH2J8gKRxA8h0hHT5FPnMY5XcQ3VSQwmUe7M4x+b5i4cxmfeYG4cpzVlQfxGBr4dHXC6jLz28PM7wohGxo4NVV8tiUWVx9A8K4wO5xAtCxi7UkwvyOEeySNR1PBbWxQzp+jVr+Iz76ET9fAOZ7HPpjE1KlgG83gVBXJxY9TKV0gHFrHY6rjGM8TmK9gOhBF3x3DPJYl7l6mED+JIh7Goavh09YR9A0843nUe8MYDkaJulbIhjZIBddxa+sEtHUitiUU8wLaNpn5PWFEbZ2Eaxn7ZBL9QBrffBXJ0ETQN7D1JpjdGUSYrSKpK0j6Ouo2CftIiqipSURfxzWWZX63QGg6T8LYRJ4vMbfNh7FdRtRUUPQNBFUJ7V4RSVVGVpUQZoqot/mYvdfH/8veez1ZWp732vN/fK69bXnb3rIss2VlEHlST/dM55xzr+6Vc85vXOldOXTOPT05MMMAM8PAwJDEIIE0EpIAAUIgtDGSbImyq3x9B434pM/I2lX7AKroq2pVdffzHqyjVVc/6/797oR+jpRpEXGyirc7jTheouRdJdyrYTsUR39/iEivRsG3Smy4QGy4RGw4jzJVwtspYa+LYt4fwX4ojjJZRBjJI46VSExVUSYrRHoyhLuTuI8IeBplnPVx/C0qseEcKUNlp7axT8PzofT6WxU8TSLO+jjxoSzBNpWsoYY0nEPoS+M8GCHcncS+L4y/RUEY0hAGNYKtCmJ/BqE/Taw3TbgjgW1fCNuBEJHuBOJwFk9bbOcGujtBtDtJrF/D3yziPhzDWR8l8mGvtDiokdaVycxU0KbLlJwLrEjHKDsXqblXWBG3WQivs5U4ycWly5Riszx6/DpPnnuai+uPsJbb5uqx61w6/ggXNx/m5Zs/5mev7gQGf/Ob33Dt2jWuXr3Kb3/724+V5IsXL/6njujfv5566il++ctf8uMf/3g3SPgp5ZP2pl122bNnz65Af5bIZDLk8/k/K9CvvfYazz///J88/+ELL1NxL2HdF2T47/X0/89pJr9qRxrOcmHpYd56/ef87LW32NZOE+1MMPUVB72fm2L4H4y46+PUvCtcPf44b776JucWLqHpa7jr40z8006vtPEuL9Jglo3kCR49eZ1LG1eZD20Q7c5gvNvP2Jet6L7mxHNEQNNXOJ47y9HMKcSZNLGeDK76OJO3ezDc5cOyN4jQqzEXWKNsX2AptklaXyXal8F0fwhfq4ppb5hIv4YyXqBoXyI9XaHqX0WZLOJuUvB1a/g7M/g700jjZTLGGpqhStY6T9owh787TaAvhzBVI9ifI2GoER8ukNLXUCbKKJNVEjM1QmNlJMsKon4BcXqW6FgZb5dKoFPF0yKj6qokHcso7jVS/i3S3g3i+jlkwyzyVAX7YYlQj4ainycZPIoSOEpNu4DsWiemn0dzrWI7IuNoVklZl4gYFxADW8yXL5GVThEyLpELbuPsSKDfLyBMVpCcKwSNCyzMPsTi0hWEwFFU/yYx3SyWBhFvdxbRtIhnZpZM/Bjbx59AiB7FZ60hWZZxdGvYWlRiulkco2Vk7zrV/DkK5UsowkkU/wZx4wKOzjSO1hTu0QKCc4WSfJJa6SJK4jSSb5NEYJPozBzmtiSm1iQxwxxF5SSZyCZC7BiSfxPVu0HcuoyzO4uhKUFgtEzCvkLKu4HfskDAvETSv0HKu0FgvML0IYnoVI20cxXZNI++TcI1UiTl2yTt3UQ0zmNoUImOV9Bcq2iedVx9GqbWNEn3Cqp9BcmyhLk5QWi4RNaxStK0gLc7g+GgQFRXQXOt7awPb0sR6M+TtS+Rd67gaU1iPCQQ6M0gTFZImOfx9mYRRsukjHOouhrR4TyWQwL+7hTh3iy+jhT+7hSxkRJ5xxLieB7jgRDORglv006/s79dwdOiEO5Jk5gqU/GuEB/M4aiPE2hX8TRK+FoVIt0pxJEc0d406aky8cEswlCWYLuKt0nCcOdOODHanUIaySOO5In07FTciYMakZ4k5nt9eBtFfEdEYj1ppEENZTRPsE1FGdHwtcj4m0QCH3Y8e48I+NokbHUh5NEsykh+Zzb6QJhAq4yvScLfIiH2Zwh3Joj2pKi6l1mMblJ2L1JxLVHzrpIzzVL1LrOunmBDPcUJ7SyzyiJPX/w2z135Dle3H2OtuMkj64+ykTvG+eUHufXsy/zmV//fbfPly5e5fPnyxwryBx98wEMPPcTNmzc/9uz3ox+/+MUvPgoS/u53v/ukP753+QM+aW/aZZc9e/bsCvRnibm5OSRJ+rMC/cYbb/yXbR0vPX2LgnUO614/fX83Tffnppj4kpV4X5qTxQd489W3eOUHr7GhHCPYpjL5VSc9fzPJ4BeMOA9EyJpmeWjzKq++/Donyw+gjOSw3Otn+Ism+v5mmunbXUS706zEt7h68gkeWHqEinuRcJfKzLc8jH3JyvTX3fhbJFK6EieK5zmWPUvCkkUZL+CoizN9pw/9XT5cDXGk0QLLsW0q7mXO1C6QMdaI9qXR3x3C1SxjORAhPpQjNV3dqdEKrDEbXEczzuFolgkP5nG2qEQH88hjJdSJEomJEunpKjnrAtHhApGx8k7zxVgJcaKKPFneWTrRm0YaKSKOlRCm5xFNCwj6eRKWZURdjchgGleLRKg7gzRVJjYzi+RcQwttIztWUOyrqMY5Qn0a1kMC8mQRxTJPxLRMNn6CYuI0qneTQvQ4sZEi5ro4wd4Msn4O/2QVNXiUhdnLqLGTaNJJSrFjGA8KeDozJIwLuEZLBPTzLC88TCZ9Flk6QUU7g2+ogLFeJDpawjtewj1WopI8RXX+YQThONHAIqJ9BVd3Bkd7CmdvFs9YiYRvg2rxAmr6LLnMORTvOv7JGvbONI6ONJauNLJtiVRgAzV5lljsGJJ/Hcmxhq03i6UtjaM3i2xdQrGtkIxuEwluInnXUX0bhPXzGJoT2LoyJByraIFNYtYF3OZFFO8aSd8GUesihqYkju4sScsSCdsKoakKY40Com+dtH8Lxb6CpVPD1p4m41pDc6wi6KroG0REyzyqc4W0Zx33QB5HZ4akbYmMY5WEcRH9IYHwSIGkZZHYVAVvTw5He4a8a5W0ZRFpooKtUcF6RCZjWUQ1zGE9LOHvyyLrqhQ9q2SM8ziaFBxHZEI9GWRdBVezgrdNJfHhHLQyU8Z0KEy4N4OvWcHfnsBeFyfQlSTak6HoWESZKONrVYkPZIn1Z/A1S9gORvA2y4Q6k8hjeYrORUJdKYTBHKEOFU+jiLM+Rqw/g/tQnFjfTpAwY5hDHskhj+Sx3BfAcziGsy5MtCdFoFkm3p8m2pMiZ6yRHC/haxJw1Udx1EVw1YWJdKg46kO4m+I7fdH9GqEuhUh7An+zhOfwzny1qy5GtDtBwTpH0TpPzjjLfGCNon2esmuJpcgGFcciWWONc7OXePz0DRbSyzzz0E2un32aq9uPUwhWeO7qd9gqHuf6xaf49ft/HAi8ceMGjzzyyJ8U6MuXL3Pt2rWPPfv96Mdvf/vb3SDhp5RP2pt22WXPnj27Av1ZYmtrC7/f/2cF+q233uKpp576k+fPP/YdMtMl9He46f7Lcdr/YpTxL5oIdyY4UTzP22/9gh/efJnF8AahdpWJr9ro+qsJhr9gwH4wTN4yx9Vjj/PKrVc5WTpPWl/GeTDC6G1mhj5vwHSPH2FAY1U+xhMXnuWRrWssBNeI9iSZvsPD0D+YmfmGB3+zTHqmwoZ6nEsbV0jbi6i6Ep7DIvp7Aszc6cfduLMMouxcouJe4nT1IgX7IvGBLI7DAs4mGUe9QGQgS2Jy5+vuhfAGGUONlL6Cq0khMpjHdlhGHCsT6c+QNc+R0c+SMc6RNFSJjBQRpmqEhgpER8oIUxXksRLKWIlQZ5rETBVxsoJsXEQ0LKLallFMi6QcKwT7U5gOBIn0Z4mPlwlNVBCtK2jhbRT3JknfJjnnCq5mBX9Hiox5Hl9/lohpgXL6HInwcRLBY8ylzuLpTGKpl5Cna4THy9h6NCrpsxRy55FjJ1isXNq5UT0s4elI4x8sYO3OELcssrh0BUk9Q6lwgZxwDEtnBndXFk93BmNzAv94lWrhAoncecTESbzWGkFdDUtrEnevhqUthXu4QDa0Rb78AHLqDHLsKDHXCva+LI4uDXN7mtB0jYR7jZR0Ail9BjmyhezbwDNTw9KTxdqWJDBeRXGsIbqWCYS3EMJbJOLHEb2rGLs1TG0pYvo5ks5VBP0srqkqYccyxdRpMrHjOIeL6JtUJOMCGc8GkmUBY5uKsS9B0rNONn6cgG4WfZOKbF4kaV0h5VjB0qTgGsyTdK+Scq0Q1s1ibE4i6ufIutfJOVZxdKaxNavIhjnSrhUiIyUMDSJp2yJJ8yJZxwqRsRLWehFZVyM2XsbXncFSLxEZLlD0rKHOzBEbr+BqTe50extquJtVbIcFPG0qqZka1dAm/p4k9qY4/rYE4d4UgfYk7hYJb4tCpCdFZmaOxEwVaaKMPJLH36Zgvj+Ioy5GoEUl1JMk3pshPpAjY95ZuCIMajgbYjjqIpjvDRJsl4n2p5FG8qRndsJ90e4knsY44U4V24EIjgNhnIdixAc1CrYFyo4lvEcEvIfj2PeHCXUouOtj+JpE9Hc7EccyaIYa4fYErvoongYB56EY/maRYJtCpEtBHsmSM9aYD6wxG1ij6FhgObZF3jRL1lBlzr/KyeJZzi88xKMnnqQqL/D46RtcWrvK849+l3l5hYe3rnGsdpJvX3+BV7//U955892PRja+973vcenSpY8V5N/97ndcuXKFy5cvf9Tc8f+vwfv933eDhJ9OPmlv2mWXPXv27Ar0Z4lz585hsVj+rEC/8847PPHEE3/y/JmHnyNnnsV4j5+Bv5uh66/GGf8nK9HuFGeqF3n3nXf53rM/4Gj6FNHuFNNft9P936cY+nsD1vv9ZPU1rp16gtde/ikPrV8la6riPSww9hUrw180YviWl0CrTM2/wpMPPM0TDz7DrG+NeH8W0/1BJr7iwHCnF2eDQHKqxLKwzUNrV0macyQ/bCww3xdg+g4vzoYYwVaFqmeVNfU4G+pxKu5l4kMavo4E1oMxPM0q7iYJZaJI3jrPfGid5EyFlGGW8GCecL+GpyNJbLhAuDdD3r5AZqaKMppHnSgRGSwhTFXxdueQDAuEh4skdFWS0zWU8cKOlIwVkYwLiMZ5RMMSqmMNeaqGtzuB+VCYtH6O8HCO0FgZxbFOMriN4t6gKJ1A1s9iqROJDxcI9eawtiQRzEuUUmdRwkfJiKcox49hPaLgaFGIDRUwH5Hw9OdZqFxCVU+RkM8wW7yAvSuNqVklNJDH2qRibkkwmzuHlr+AmjzL7OwlAjM1zB1JXJ0p7G1pbB1JZMcq1bmHEdOnSWZO4Z4pYB8s4ezNYu/IYG5LI5oWyKknEdJnULJnSUrHCNkXsfblsHdnsXdliEzXkIzzRENbSMpJsunTZNSTOCerGFpTOHvzyNZlIlM1vKY5Qq4V0tI2hex5Qs5VTN0arr48SccKcf0cjv4cPusianiTRGgTMbjFTIeGb6RM0rmObF7E2ZXB1q/hmSmQCmyhuJaZ6dTwDxdJOtfQvBsERoqYmhSSzhWSrjVU+yr6JhX/aAnNtUbasUpcN4vpsEJwpIjmXCE+WcHUKOPt1kjbV8i6VpCn53B3pgn25ZCnqqj6OcwNIs62JPJ0jYRxAc26SGQojzhaIj5cxNOSwN2SwFwXIz6cI2WcJT5aIjSo4WiXSJtmCXalsOwNY94fxdkQJ2OYQx0vI40VSBpmUceKRPsyeJoFLHtDuOoFPI0SykSJjGGWsnsZYTiL54iAbX8Yd6OIqyGG94iMv1Ulq59F09dQx4t46gV8zTLGOz0EO1S8TSLR/iTqeJGMsUKgXSbQIhFsU3AfEbDvD+NpiONpFAj2KYjDGp6GGK76OK6GGP4mgUCjhK9JxLYvRLRTITlR+FCWa1RcS+TMc+TNc8wG1liOblFzr7CdOcPJ/HnO1S6R81V47vJNrp28waXVK2xXTvLIiaucWDrLc9du8tMfvcGPv/sKb7/+Dh988AGvv/46Fy5c+FiB/pd/+ReuXbv20azzxwn073/eDRJ+OvmkvWmXXfbs2bMr0J8lrl69yuTk5J8V6F/+8pc89thjf/L829e+Q8W9iGNfgOEvmOj+60lG/sGEv1FiK32Sd95+l5/cepXjhXPEelRmvumi72+nGfqCEcv9AVK6MhdXHuH1H73O1ZPXyZvm8DTEGbnNwtAXjEx93UGgWWLWt8L1809x4+IzLIY3EIay2OsiTH/TzdQ3XFj3BUlOlliJb3Ht9JPI0xlS+greJgVbXZSZuwJY94fxtysUbQucLJ9n1r9K1bNCuEcj0JVm5r4Q3rYElr0RMoYas741lqKbaDM1NOsSwkgRb3sSf0+GQH8Wf6tKSl9DM87tBK8mSohTVWKjRcJjZUT9HNHhAtJYiXB/FnEoT2wgi68zg6CbJaqbQ3WsIZkXSczMY2+RMB/a2YRob1SITFTJ+DeR3Fskg8fIRY7j68thbpAI92RwNKs42tNo4W006TRSaJv54oNEdTUMhyVCfRqutiTGehHJvEy1cglROkkud4FMZBtLRxpPf45Abw7DYRn/YJ756kPIqdOkCxfIpk7jmZrF2p/HP1xgpl7B3JxAC28hKidQc+fRsqexm4q4dDV8oyUMTQkcnWkiUzVigXXC0aPkS+fJamfw25fxT89ia0/jHsgTGC0RdS7h962RkLYpFM4S9W9gm6xh788TnZ4jOFbG1V/AZ10kKW6jKcdJKydw6uewdGaIm3b+AbG3pbGPFVAD66Ri2ySjR3Hr53EMF5AsyyiONUITFfRHZET7Eu6xLMnQBqaBPOaePAn3Gmn3OpJxHuNhmZiuSsa7QdK5grNHw9iaImFfIeNaJ+VcwtaeJjJSImGcRzHO4+nRMBwSUQ0LZByrKMZ5fP0FAv158t5VZF0V62EZ0yEJT2cGzb6IZl/GP5AnNlpE0dXQLPN4WhRm7g3gapKJDxVIWxcQJ8pER7KEBlKEezN4mkXM+6PY62MIw3niHwq4Oj1LQldGGMlhPxjDuDeEvT5GsDOFMl5AGMpRsC0hDmbxNct4miSc9XFse0M4DkXxNUkkp8vkrAtIYwVcdTHsByM466P4W2Xc9XGs+0OEOxLEBzPEBzT8zRL+FhHzXV4CTfLO8pQ2hUCbjPNIBPO+IIE2hVDbzsyzsy6C+1Ac56Eosb4U0pCGOKShjhVIThbR9DUWI5vM+lYpWOaouJeZD6yxJh3jdPki52cfJGUvcH7+IZ575CbXT9/g8smrnF19gBVtg8fOPsl3n/g+r//4TV556TU++OAD/vmf/5lz5859rED/6le/4vr163z/+9/nlVde+S8FejdI+Onkk/amXXbZs2fPrkB/lnj22Wfp6+v7swL93nvvcfXq1T95/qOXfsJccB3HgTBDn9fT9ZfjDH/BiOdInA31BD+59RrvvvNLzlQeQOxPY7jTw+Df6+n/2xlMd/lQx/I8sPwQP/n+q9y48Ax5yzzOuhi6rzsZ/kczum84CTRJlB2LXD1xnWce/jaLsaMI/Rr2QxF0X3cy+r+smO4JkZgssqYc59LaFVL2IpqlRqxfw3ogjPEeP4a7/HibZTLTNU6WzpEzz7MY3SQ+nMXflcK8L0ywO4XlYBRxKEvBsUBGXyZrqiFNVogO5rA0yESGCrgaE8SGc8SG80ijBaSh7I5Aj1cJDxeIjM8i6hcJ9eeQJ6v4mlWEgRzeVpXYSJHYZBXRtoxs37nllHQ1THVxHC0CgZ405gYJcWYWxbuJ7NtEDRwl49vE3pbC151BGC1iOBgjMJinnDiNFDlGUjxNNXcBZ38O74diZjgoMLM/Ri66hSKfQpZPsrRyhbBpCddoGUW/gLU1weT9EWIzVeTIFpH4NuXFh8kkTuPUzxO3LOEfKqI7IBAYKpAIb+JxLZOvXCCTP41FV8RtnMM3XsHcksDWliain8XnWkaRjlMonyetncZjW8Y7UcM5kMfTn8PVl8ehKxMPrpPNnCKlnSIQ2MCrrxGY2FkZbutIYRspEnWtkFWOkxSO4vetYZ2oEjEtorjX8Q4VmD4iETLMUUieIhXewm+dxzRSImpaQPGsk3CvMHMkgXuwgGJfJGwtE9TX0PdkkJ3LJD3rqO51rF0ZnN050u4VUvZlojM1dA0CUfMiac86CVa1r+8AACAASURBVMc6noEizs4MKdsyGdcq4dECur0xvH0aCdsSqQ/bOtzdWTKOJRLmBUKDWaYPRLE2yqQti6Ssi0RGS4SHiyi6Kjn7Mq4mBdPBGOZDcYK9GlnXMpHBPMpMjUB/Gm+XRLAzheHuIJaDO60x8eE8wnCBhL5G0lAjPqDhaIhhrYtiq4vjb1VxHd65gRZHisgTBYTBHIFWBeveMNYDEdyNAt4jIr5mCXk0j69VIdyTItKdItKdxLw3iPuIgOku/4e1eHnk0SyOAxGCbTL+FolIdxLX4Z1xEEddmGCzhLUuhK8pjqchhvtwnGCzhPtwDH+LRKBdxtMQxd8iIw3nEAc1kroSRdsCOVONnLHGunqC2eA6s94VNpMnWRWOsRLfIuep8NiZp3n0xBPcuPAMj52+znxilVlxkWcuP89zj9zk5Zs/4dVbr3/UxHHu3LmPHdF47733uHHjBm+++SYvvPDCfynQu0HCTyeftDftssuePXt2BfqzxK1bt2hubv6zAv2rX/2Ky5cv/8nzn//sHZbi29j2hRn4/DTdfzW+07BxOMZSbIsXb7zE+++/z6WNK8ijOQx3eRn4vIHuz02iv8ODOlbgdPkBXnr6Fs888jxzgTWCnSr6O7wMfsHAxD/Z8TVJFCzzPLD8CI+ff4rNxAmEwRzOgxHGv+Zk/Mt2THcHkQY1FiIbHM2cJm0voUyWCHYlmb7Tx/Rdfqbv8OJvVUhMFFmNH0WbqVELrSMMFXA1iZgPxvC0KDgaRIShHJp5Hnk4R1pfQRgpEO7NYjuiEBsr42lLEh/No0xVEQdzSKN54kMFoiNFXJ1p4voFAiMlYmMVIsMFQj1pxME8vjZlJ1yom0O0LiO71lHMS8QmqlgaJTztErZ6EWeLQlw3SyJ4FNm3RVE5jWxbxtWfRTXM4mlNYtgXw9ebRfKsEQ8dJa2eISedwj1ZITo9S2Qwi35/DHdbCi20hd+5QiZ7jvnFhwlalgibl4jrahj3x5g5GCfhXMHvWCYW2GDz1BPEokcJOldRHKtYWlPMHIwTHCvhMczhtS9TrFwgXTiD3lRCCqzjGytjbkzi7s4QMM7hNNTIaacp1S4SFI7i96zi188RnKxhbUlg7dHwzMySlo+RS59CTp7C41sloF9AdK3hHy9jaElg7NFQvKvklBMI0U08njVE7yqqfxPBvoypPY25O0PcsoDqWUP1rWGbmSXiXEUJbqN61rF0ZzE2J0m415Bt8ziHUui70/iN86iedRKBTQLjZQxNCWTjPCnXKgnHCvpGCedggbR/i6R7jYhpHktrCsW4SNq+jDQzy0y9jLlFRjQtkHauEdFVcfblEKdrZB2rSFMVjAfi6PfFCPRqxKeriNNV/IMFRF2VjGWBQE8GV7OK/r4I7mYZYaSIu1UlPlFGGCsj6Qo4mwRsh+LYGwRM+yKEetJ4WhIEu9LE+vPIYwXk0QL+DhV7g4C7QcSyN4S7USI2oCEO54n1aYS6U3ibZcI9KXwtEvYDUUx3BYj0JAl2qkjDOYLtCQItCt4jO60a9oNhHPVRAq3Shw0aMv4WkWhfEn+LTLBNxXx3AF+ziLdRJNqbYeYeF866MM5DEWI9KcLtKo66EI66CM66CLYDQTyNUTxNUVxHIjgPh4kOJVGnsyg6jciQSmwsga8rTrBfZFU4yppyHNWU5frpG9y4+BzPXXmBx049yWJ2hVlpkQdXHuGJs8/w4pO3eP+9X310y/zAAw987CKVd99996OQ9GOPPfax89G//303SPjp5JP2pl122bNnz65Af5Z444032Ldv358V6F//+tf/tUC/8TZH06fwNIqM3Gam+3M6Bv6nHseBCLO+VZ67cpP3/vd7PLh8GWUsj+EOL/1/N0PXX08x8003Ql+aTfUkt27+kKsnrjPrXSHQKqP7mouev9Ex/kUrrroo2kyFM9WLXDnxOKvSNsKghnVfiLGv2pj4qgvzvQHi/Rqr4jZr8jZZV4VIbwp/s8r0nT7M+8Po7/IT7U2Ts8xR9S5Tdi5QdC4S7dOw7I9hPyxh3h/D154kPphHM84hDGSoeVdRJir4u1K4WlNERkt42hLIkzUi/Rrx/jTxvgzSeIHocB5PXw7ZtEx4rIQ0XSM2VPywGUHD06oSHyoQGC8jWFeJmxYRTYtEp6q4O1WcLQKOBpHIQJboeJm4cw01dIyceJK4dZnIzByRgTyGAzvvV5iqEDIuEPdvMjf3EHJ4m5B5kUJwG0u9iPFAnPBIAd/0HG7DPIXyRQrFBwl41kiFtwgMFZm6L0qgL0fUOIdtooIa32Zh6xpx6ThCZJuwcWdrobFBIjRRwT5RJuxeZH7pIeLaKSyOGoJ7Fc94FXNrEntnBkNfhpB1gYSwRbpynrh2CjG4Rdy1inu8irVbw9yr4Zkqkwisk1KOE02dIhzdRApuErYsYmxPY+xME5iqoHpXEVzLBKJbhIPryKFNRP867vEKuiMq/okKsnedhHcDh6GGy7mEHNxEDR0lZF5gujlJxLhAyrmGZF1A1yZjHMqhBNZQAhtEzYvMNKcITVTRvJsk7SvYO1NMNYiEDHOI1kVkxyrmjgzB0cpO2NC+gqsrw9TeGN7+HJGJKpHpWew9GcKjFfKedVKmeZztSUz1ErYmhehIifBQHkujSmy88uGK7wVCPVlMh0QcRyTcrSrejhSezhT+ziQZ8wKB3iSOVhF3s4KvPYG7ScSyP4anRSXUlSLaq1FwLhHsSOJulgl0JPE2S1j27wi5ry1BuCtJrC+DPJIn2JUi3JPGWR/DeG8Az2GBSHcSX5NMuCuJsz6OPKoR6UsRaJeZ+qYD28EwM3d68DbFcdSHMe/zYbjHjbstiv4+NzP3utDd7WTyDjujXzEydbeNqW/Z0N1lx7DPx+TtNqbucmC83435gAfTXi/Ge1wY7nHhaIggjWtoxhLKZI6CdZaspUrBNsd8eA1xIkNyssCadIyl1DpPP/w8377yAtfPPs1jp25QCNRYzq9x7eSTfPf693nv3X/+o1vmhx56iNdff/0/CfTPf/5znn/++Y/aOP7wlvpf//VfefTRR//o+atXr+4GCT9lfNLetMsue/bs2RXozxLvv/8+d9xxx/+1QL/56s9YFrfwHI4x+A9G2v+fUXo+N4V1b4iKe5nvPPEiv/j5LzhduYjQr2H4lo/+v9XT+7lJZr7hItaX4Vj2DD/+3itcWr2MZqzhro8x9mUbPf9jmvEv2wm0ShQsc1xYeYQH16+wHN9CGMhgvjvA8JesjH/FjuX+ENGeNEuRTRbDG5TDC4gjGsF2Ff2dPoz3hzDvDRPuSqGOF0iMF1kRtyjYFpBG85j2hvF0JDHvixLp1Yj1Z5En8iQmS2QNs6QMNbxtCbw9WTxdGfxdGuH+LNF+DXE4u7N4YjBLfLRIcKxMfGaO8GgZxbhAaChPfDCHt1kh0JUg2KMRnKwi2deQbcvI1lVE8xKBnhSmhgjWQ3EiAzl8wyUilmXUwBaJwDFE1waqYxl/VwbjwRiRgRzx6VkcI0Wk0FEq5QcRw8fJSqeQDPPo7g1haZCIT1WwD+fx6mssrV9BTZ0loZ6hpp3D3JRAXycSHMhj689jG8yTy5xGm71ILHWKYuEBwsZ5TK0pvL0alp4Mpu4MSmCd0uIlQqlT+CJLRD2rOIbymNtTWHrSWHoyRM0LpJUTCNXzyLnTCOENAq4lLD1ZzO0ZTH0aomcNybdCPHOKYPI4YmQTMbSFU1fF0J3G1qMhO1eQPWvEAqs4gqtEQuvEgpsE7EtMtaaw9+VRHCsozlV8UxVmxvIEHIvIkU3EwDoznRrmTg3VsUbKu4F7LE/fgSBB0xwRyyKCZwXLQB5bX46Ue52UcxXBtMD4wRj+iQox0zyhiTKW/iz2nhwJ5xqaZx1xusb0IQl7m0rcMEd4ooqlWcXakSZtWyJpXUbWz2NvS2GuF4iNlggN5DEfUXF0pJCmahQ9a8hTFdztadytCZyNMuG+LOYDMTytKfw9adSpKsJkFtOhKNGBPO6mD7dmNog73eTtCaL9GvGhPL6OBMGeFP6eBIb7/Ezd7kK/z4/5oB9nawxXcxTzgQDO5hiGAz4mv2Vj4nYb47dbGPmyiam77Oj3urE0BLA2hLDWBZi63cnMPW6M+3wY7vWiv9uN4R4vvuY40miG6EAK274g7voIlvuDhNpkfM1xZu514TwYIaErE+1NEepQ8TdJ+BrjO4tZmkQCTQKxniTqeJ6ccY6Ka4n58AZl1yIrwtGdkQ5DFXUqz6K4wcnSWVa0TW5cfI7HTt3gweXLPHf5Juv5YxQiVZ688Cw/+d5rvPaD13n79Xf413/9Le+++y7Xrl3jpZde+k8C/eabb/Kd73yHDz74gCeffJL33nvvo7Nf//rXPP7443/0/G6Q8NPHJ+1Nu+yyZ8+eXYH+LPFv//ZvfOlLX/q/FuhXf/gaC8F1HAdC9P6Njo6/GKfnb6dx1EWoela49fzLvPX6WxxLn0EYzGC400Pv/9DR/Tkdk191EOlOspU69aFAX6Fom8fbJDDxFRt9f2dg6msu7AejpKbLbGfP8vDmVbYSpxAHNUz3Bxj9JxsTX3FgOxgl2Jmg7FxiKbpJJbSAPJ4j2JnAeG8Y/d1BTPeHcNYLJKcraNNV1qVt0jM11MkS9kMi3s4EpoMxwj0ZfK0K6mSJjL6CMlFAHi3iak8SHS3iaE0ijJUI9GqIw0XiQznEoZ2vyCODOWKTs4TGKwRHKwjT80QGd4JenhaV2ECWUL9GaLKGYF5Eca4iOlZJutcI9CSZvMuLu0kmOpTH2ZUhZl5EE08iB7ZRQ9tUpVNYmxTMB+IIIwUcHWkcA1k09RQJ5TTx6HGqhQuExssYG0RCfVncPRn0LSpqeJPy/MMIiTNU5h5C8W9ibExgbU/h7Mqgb1VxjZWYX3sEoXCeZPkBsslT2IcLWDvSuHo1DO1pPBMlMsoJlNkLBHKncDirhJxLGHoyOAeymLvTOEYLqL5VkoUzBAtnEJRtQoE1LKMlzH0a+o40vvEKEfM8IfsiPmGDSGwTIb6Jz7WEfjCHvi1JaHoOybWGb6qKyVjFaZtHjG0hRLcwDRcw9mSIzMyT8KwT1tcwDmZxW2cRg+sI/nVs0xUmWpMI9mVSnnVE4wIT9XFmelQE7xqidxnneBFdWwbBsEjCtUbWt8lMi4qhKUHMMIdoWcQ9VmT8sIxsWUJzr5NxruEZLO7cyo/vdHY7OpJM1cuEx8tkXGtk7MsEhgrYWhIE+jQiw0Xc7QkMB0Vc7UnEqSrCdIXQSA5Lk4SjWcLeHGfqLj+GA2F09/txtsYJDCYxHQljbAyj2+tDf9DP2O12hr9iZewOBxPfcmBvjWJrjePqFHG0xDDs8zJznw/jXj9T33JjPhjCsi9MuC9FQl9B0Rfxt8nY6iI73c2HBbyN4s58codKzrZAYrJEqFPFfUTE1yhiutuHr0nAfSiO0J8iNVPZWR1eH8fbKOA6HCfYqmDbG8JZF2XqDjvqRB5hUMPdFMd1OIazLkqgRSbcruBrlXbWenckkAYzFG3zFK1zVJxLlJyLaPoaFc8SC6F1Ku4FMvYya8oxKuEFLq1c5sbF53jygWd5cOkyZxYvUFMXePHGLW4980N++vIb/OTFV3nzlbd4++23eeqpp7hx48Z/Euif/vSnH4n1Sy+9xGuvvfaf5qP/8Pkf/ehHu0HCTxmftDftssuePXt2BfqzxH/8x39w2223/V8L9I9e/AmLsS08h+MMfdFI51+O0/O5KYx3+sgaq7z0zC1e//EbnJ+7hDpRwnCXm96/1dH9uQkmv+Yg1KGyFN/iu099j2unn6TqWSbcrqK73UX/3+kZ/Ucz1n0B0tNljufPcHn7MVbFbeSxItYDEXTfcDHxdSeme/z4WmTy1jmO586g2SuIYxqeZgXzgSgzd3qx18WxHYiQnC5TsC0wH94gpSuRmCrjaU/gaFaw1Ys4mkR8LTKaoUbeNo84mEEeKxAeKhAZKeFuSyHoanjak4hDecTRAtE+jWhvGn9/FmF6nsBwGdG4RHx6DnmyRLQ/h69dQRrO4+vMEJmaRbAsEbWuIDrXSFhXCA/nmbjbT6Q/h68rja0jhehYQZNOIfp3mjZU+xKmBhlXWxJPR4KZBgnfVJVK6UEk+RSqepr50gUsbSmszSqR4Rzm1iTmzjSV0gWU7DmiydOUqhdxj5Uxtafw9eewtKWYaVZJRY6SnbtENHeW0vJDBJ0rGHtzWHs0LB1pZhoV/ONlUqnThLKnkQonsdlK2A2zGPtyWLszmDvT+MfKRKyLOCKrBORNpNRxIpENTJMlzP1ZbH05gtOzBMYruHzLOH1LxGObqJlT2MxzTHVmsPYXiFmX8A0XsIwVcDrnEYRN4pE1QuF1JgeyOIZKJHybiJYlDG1JzGMFos5FYoFVgq5FJvqzeKdqJDwbKM41HAN5JlskrJMaUesCUfsCo80q7okqKd8Wac8m/skaUw0SwfESkn0Jv67M+KEoli6NuGkBwbKAf6KIrkHC0iZj70xg6VAYuT/I+L4wnqEU3uEUtm6FmcY403VBzG0xJvf66P2qg+E7vejrI3gGkrj7k9jaFJxdKq42GVuTwPReP1N3+bA3CIQGNGKjRTz9KfwDGWRdGWejjOOIjPlgHFv9znIgYaREQj9LyjiHNFIg1J3Gui+KeV8E12ERT4uCMJRF1VUoulYI96RxNcRxNcRx1MVw1sWwH4jiPhwna54jOb3Tc+48FMVeF8WxL0igXcFzWMB5KEq0J0WoU8VzWMBzRCDYomC5P4C7If6hJCvo93oItEgYv+XBvi+Ioy5MuCOBsy6C85CA40CYcGcCYShLYqqAMpolNVkgraswG1hlzr9GxblM0TbPQnAdYSrJZuo4s9Flzs9e4mztQW5ceJbrZ5/i+gNPMZte4IkzT/PcIzd54bGXeP3HP+PHL77KG6+/wc2bNz92G+Err7zCD37wg4/q7r773e/+0Xz0M88880fP7wYJP3180t60yy579uzZFejPEr8X6F/96lf/RwL9/vvvf+zZay//lK3USfxNImO3Wen8yzG6//sEhm95KJhr3Lj0HD977S0ub19DnSiiv8vLwOf1dP/NJBNfthJokVmKbvLc5Zs8dek5ar5V/G0yum84Gfx7I8NfMGDdFyI5UWBbO8sj29dYkbZJTpVxNsTRfdPDxFcd6L7uwt+mULDNc2H5EZSJLAldFl9LEnezgv4uP7a6GMZ7AqjjBWr+VSqeZdLTZeTx8k7zxQEBT3sS+6E4wY4E6kSJsnOZeF+ajHme2FgJf5+GoyNDdKSMs0VBHttpNRAGNMK9GWKTZaITFQIjVSTLMrGpKrGRIqG+NL4mhVi/hr1ZITpdJaxfQvJuIrnXSdlWcXam0N0XQBzM4WhS8I/kSXrXEULHECLbZKQTBMeqGBoUAj1pHC0q+noJ2bNCLvsA0fgJytWHEZzLzDSpuHs17E0K4/dHcPRoFPIPEE+fIVm8QFY7g2WwiG0gh38wh65OwtyokAhv4ItuIJbPkSydxWdfxDxWwTdaZrpBQX8kgWxbJhhbxx1dJ5E7icVTxWGaxzlZRd+SwtKaxNGbxe+YxxtbJyYeJV08gy+8gd04h6Uni3eyirsvh3OsgNkySzSyhihvEhI3MZvmsAwUiJoWiJqWMLensBoqRALLSNF14uF1jKY5DIM5YvZlZM869q4sk60KMfcicf8yQcc8umEN3UAGv75GyLqAZ6LAyKEYhh4ZfY+IczLLQEOEgcYYrokszpE0lsEUAweCGDolzF0iM60xhvYH6LvXj21Ywz9dwjteQNcsY+9OEZ4u4R/NoTsYZey+EN4BDdGygGiZJzBWIThcImVbRpyqYmtWmD4o4GhLkLAukbAsEZmoIEzXSJrmkaerWOsE9AdiOBokggM5EpZ5omMVwiM5woMZgl1pPK0q+nuD2BtEPK0KwZ4s8kSJlHEWZaqMv13BWhfDWhfHWrez1tvVJBHoTKJMloj276zedh0WsO4L46iPYa+L46iPEu5KIQ/ncB76UKoPRvEcEbEfiOFuEDDf6yfclSDalSbYoWC514/zUATTvX7CnSmcH95GOxuiTN1hxb4/hL9JxnUwinVfEGddFMfBCL5miWhfCn/zTid0vDeJMJAmOVWkaF+kYJ5DM1RZEbdYjG6xEFxHNWqUPAtkLGVOly7wxPlnePTYEzxz6ds8+8gLaIECD69f5ea1F/n25Re49dwP+cmLr/Daa6/x4osvcu3aNX7zm9/8kRC//PLL/OhHP+KDDz7g/fff5/r16x+dvf3223z729/+o+d3g4SfPj5pb9pllz179uwK9GeN/1OBfvTRR3nvvfc+9uydt37BqfIDBNpEhr9oou0vRun96ylMd3pITZe4cuw6P3/zbR47d4O0rox1b4ihfzTQ+ZeTjNxmwdsksRDa4PEzN3jxmVvUvKsEmmX0t7sZ/V8WBj6vx3SvD3k4y7HcWR7ausLRzCmS02XcR0Smvulm7GtOdN904W+V0PQVjmXPkDIXydlniQ/mcB0W0d0ZxHRfCPO9QeI9aar+VVK6MjXvCuJoiXBPBvMBgUCPhvlgjFifhjJWRJ0sIQ3nUKYrhAfyOFqT+AeLBAbyBLs1xJEi4mCWWJ9GbChLbKJKaLiAf7yCaFkmMFxEmqnibE4Q7E7hOiLh7kwR1dUQ7auI7g0U/yaSaQFLs4p+fwhvi8zkXUG8A1lk/1HE6HGkyHHy8kms3RrOLo3IQJap+yIY6kVU1xqR6DaieopC9UE8k1VsgwXi4xWm98WYuCeMYl8m7F/DHznK3NYVYqEtbFNVouZFLK1JRr4VwNWXQQht4PAskSidJVs5g8O+iN+2iG+iyuRBAVtrkrBpFot1FiFxDCG9jdFVxuFYwjVVw9aXx9ScwDNSwmadJRBcRlW3UfKnsAdWsRtqOEbLeCcq6BsT6AczeJzzRMPL+HxzWP0LTE/msYzm8RlqTLcoDB2OoBtQcFkKGKeSDI8k6O2XmRlKYp3Iou9J0L8vwESngHU8iWU0yWSXSH+HjG26gNtUxTdTY/SwiLErSdBUxT6ewdKfZqRJJmxfQvFvIPs2cAyVdmaq7UskPesEpqqMNwj4ZmqkgkdR3Gv4dDWc/QUy3g1SzmUCg3mmGgRsnWlE+zJJ5xqB8SreoZ2awJRjFV93mpkDMcwNMqHRAqJxnshklZhuFmVmFmW6huPIzspv/cH4R1svXe0pVPMCvv4UwZ4kriYZ/X1hnIdFLAcieNoS+DtShPs1YiMFfO0qvjYF64EI5gMRPK0Kpr1BfK0K8ZE84Z403iYJ9xER28EIjvoYrsNx7HUxrPvDxHpTeJpk/M0S3kYZX5OEdV8Id0Mc2/4QvkYBf5OI+4i4U4O3P4SvWcLbJOE6FMO2L4SvRcTTEGPmPie2A2Hs+8OY7vbjbRTwNAj4W6Sd7YWNIq5DMWK9GSI9ScRhjVhPGm2mSsW5xLp8nLJrkVn/CiXHAtF+maylQsk7z4Z6kmsnn+DJi89x89Hv8PiZpyhJNa6dfJJLy5d58oGnef7Kd/jl2/+bV155hVu3bnHz5k1+9rOf/ZEQ37p164/6n/8wSPiH89EfFyR88skn+fd///dP+mP8M88n7U277LJnz55dgf6scdttt/3Jm+U/fD3++OO8++67f/L8gYVL+Fskxr5oouu/jdPzV5PM3OFGHc9zYfEh3v7ZOzx75QXy1jlsB0IM/aOZrv82zvAXzXgaRYr2BS4ffYxbz/+AFWWbeH8ay/1+hv7ByMDnZ5i53UO8P8OqtM2ljaucLJ4nMVnCc0Rk8ptuxr5iZ+YbboKdKmldhe3MKbL2Kil9kVBnCuP9Iabv9mO4L4T7iIQwnGc+skFyvMRcYA1hrIC/M4nxYAxPVxLTvijRgSzqZJlYXxppKIcwXCAylMferBKZqOHt1giP5IkPF/E1SwRaVDwtCUIDeby9ecK6OcIz88Qma8THK3jaVMKdaewNMVytKqHRElHbGoJnA9m1jmCYx9SsYDkSxV4vYjoo4OvOEnGsEQ1uoSXPoAa3cA2XiOmq/L/svdeXW+d5t82c5D94U5a/9LyJY8eJ4yJbssROTu+9V2AGHdgANjqwN8pG7xgMpmB6p0iJlMQiiSpUMUnRom1ZtqVYkmO5SO7xWoq1cnJ9ByPzsx05zpn8OXOttdeamQczRzi45sHv/t225hjqw36E1jhh2wpu+wrJzAVmZy/iMlUJGJYIqSqoDwcw1IaICsuIwgIBeZu5rSfweDdw2leICCsY6iOoj8nEzNV9wRWqzG88ipI/jyuwQ8S3jaU/z9SJIKa2OMJkCaN+Br+0ipzcZEIoIVoXMY/nme6Mo66TmWwJM9oXRbAUMVvzTDpKTBjzqIfjaIeSTDYGGW2QGWkPYVSnEc1FzGIZlX0Wk24Gt3URYSLPRIPCdF8ar2ke2VHFbVvA7FnC711HkXcI+TYxDebR92SIiKtE3VsEnatopgp4PGuEA9vE5B2sqgra3gwJ1wYhaxXndJGp7gR23SxKYId4YAe3dgFNR4aodYWUe5uwcYnpFgVDT5qwsELcvUnIuoploEjEskLKukZIu4imIcZUbRj3WImAuoxnchaPao6woUres4U0UsRQv9/HbWuJ458o4ezPIvZkCGvmiesWkYby2JrjaE8GEerCuHvSOLoSyGMlvL0ZfMMZrE1hHO1JbM1RLDX7Pc9CbQhffwZpIIe3M0lMVcbZHMPZGkdsjiHUBBFqZNztMbyd+3LtbIgQ6E7i7Uzg70liOhlAOC3jbovi707galFwNIexnPAjdaf2hfu9Vd2eNgXhVABfR+xO9tleI+PrjGE+FiDQFcfVtB+BGv24HuvpALbTATwtCu7mMPZaGXdrBG9rhEB3nEBXAkddEMd7678z2jILnjXK9ipznhUqjhVmxWVWQ7tkTDPIw/sSFpcAkQAAIABJREFU/fTZ57h59YvcvvYSz5y/zrMPXSdpzfH0hed49sINXnzqy7z9nR/cyS2/+uqrvPbaa3zta1/7FRn+yle+8ivtHM8999ydurtfzke/3yDh1atXDwYJfwf4oL3pgAMOHTp0INC/D+zt7fGRj3yEP/iDP+CFF174b19711138f3vf/+3CvTzzz/PW2+99b5nP/3pT7m8fpXQQBr1p+z0//U0PX+mRvUpK8pIloeXrvDDH/yI5x65QclSxX5KYuwfTfT8xRSTH7fgagwxKy7zzPnnuX3ti6wEt5F6k+jucTH0YT2jHzUjnAgQHSuwkz7HY3tPsZU4R3Ss+J5AO5j4pID2Hiee1ihF8wJV7yYzzirScBJfZwLdYS+GEwH0R/14OxPIfWnS+grB3hRz7nVCQwVsjXEMNQpiawJ7c4zwaIHIaA5fR5yEqkRotIA8nMPWkSKsWcTaniQ8WcbZmSTQkyTQm8Tfm8bXk8YxUCBsWSGorxLSLCJNVfb7ensSmGtCSAN5xJ4MsrBO0L5B3LVJyLyEZ6SIodaP8aSMoy2Of6SIW7dAOLBLNnGBoHMDt24RRTuP7riM/rSMf7iAQ1NBNCwyv/QYqfSDuG1rpOQdzM0xxu/2ILTGEMYLTA1n8fhWSVUexOxYwilWsY9mGbzXzcQxL9rOEMNdYbSjcZzRKjrvAhp7Gd1IiolGieFjHtTNEsNtQTQjcXzeeRzZDaa8Fez2BYTpGXRdSbRtSdRdcSyqPH5xkWjpHP6FC0jhLcLBbTxCFUNfFv1ABlE3R1TaIiSv48jfj1vZQpa3CXg2MI4U0PZlcevniXo3CHnXEX0rWKVVwpFdgtI2Dv0Ck60JPNpFIo4NFMcahvE8RsMsQf860cguknMFdXcGn2aBlGeHsLjCWIvMaGsUl3EOv7BEwLGGrq+AbFwi5dkkYVvD0p9m7HQQcXIG33QFj7qCob+AVzVP0r5JwraO0JVhsjaEpT2Bb6KMW1XG1JHAPVEhI24QMy7h7Mtjbk9iqAnj6MkgdiWxdmXxDOZJmqqkTFU8/Tnsncn9ZSp1YazNUYTmKM6uBPJQHrEzhqs3hbUpjrc/i60pgu6oH/d7v+PrzSD3Z/F0J/H2ZvB0JXG3RDEc82E+LeNoUXC1xfD3JPG0Kfi7kvvv51oZa00AsWF/wM9WI+NoCiOcCBAazCL3Z3A2hhBOSjibwzibw3jaYthqA5gO+xDrw/v1jC0hHA0hXC0RrCcCeFsVtEdtOBplzMf9+Dri+9nozhjuVgVfZxzrSQl3cwRXSxi5P01iskjRukhRWGRF3qFsW2ZV2WVWXKFkXiI1XSInltnK3M/zD7/Azcdv88z561xevcrnL96koixypvwAzz/8Aq+//E2+9a/f5q1vvc3LX3mZ1157jR/84AfcuHHjV2T4S1/60q/cSr/00kt3hPqX89G/Pkj4yiuvcPXq1YNBwt8BPmhvOuCAQ4cOHQj07wNf/epX+frXv86RI0d+q0AfPXqU119//bcK9I0bN/jOd77zvmc//tGPOT9/Cbk3gfqTAl0fmqT3z1Vo7hGJjWZ5dPspfvSjH/PE3tNkpmexHPcy9k8C3X+hZuyfzDjrg8w6Vrj+6C2ee+QGC951vC0xpu8SGfw7LROfsGA+5kPqSlD1b/BQ9Qo7yXPEJ0uINRHGP2Vl8l+s6I94cLdGSWsrZPVzlMRFgqNpwkM59Ef9mGtCaI94cTRH8LQnSEyVyev3XxsdL2KpiyC2JxEaonh7M7jaE8j9GaTe1P5N9HAeb28GsSeLZ7iIoy9PeHIOT1cKuS+DtzO+v3yiN4NnbIaoeRWfqkLIUMU3OoOnI4mzNYbYrODpTGLrzhC2rhF1b6OIm4SEVXwTRaaOOZm6142zLYq5M46uL4XDuojkXUc0LeI0ljG3Rhj8hIDqsAtDa5CR+gCasSSe0DIGYQ6LpYJ1IsvQ3Q5G7nFibJKZaJKZ7FBI5u/Hl9rDFd0mmdzD2J9mujaM0J1E25FA050gJG2S336cQOUCufmLhNxrGPtz2PqzmIfy6AfzyM5lMnMP45p/ACGyjD+whcswj7E/j3kwh2kkR8C+jCJtE1i+gK98DlnZwu/fwDBWRNeXw9ifR7Ku4Lcs4pDWsEU38IW3kMKbiNYqUwMFzMMlFPcmEecGgm4GlWEGu3UBr38Nn3cV9UAOy0iJqGuTmGcT+2SJ0f4EdnMFl3UBv2eVqZECxqEiCc82Kfc21tE83Uc8OLSz+IRFHIYKxuEcwkSFhGODpGuLkLDMeG0Yc38al7qMc7zEdHcC80CBtGeLjGuDkG4BQ2caY2sc98QMrpEC2qYo5u40Yc0CWdcWimYBa3cWoTWJsyeFqzeHuTmGpT2Jf7hIylglPD2PZ3C/UcXRkUBoiKA7LuPsTiO2xgmNFXH3J7C2KIQnKzjbk1hqQwh1IUynAjhaoziaY4RGi/j60gSHi8iDOSynJOwNYeyNCuYT0n4Wuj5MoCdFVDWDNJDGVhfEVh/C3rC/2dDREMHTquDvjBNXzeDrSuJsiuBqCuNpjyKckHA2KdhqZcKDWWITRUKD2fey0mHEGolgXxrxdAD15yw4GkLEJgp4OuL4OhTczZH9RSr1IfxdMTwtUbytClJPAmUkt7++27XKvGeNBc86OcMcZesS1cAWK5FdwtokK9EtHq5e4fLqE1w7f50bV77AhYXLLCZW2Js/y1dvvsLLN1/h9a99i9e/8k2eeexZ3njjjTv55V+/TX7rrbd+pZXjpZde+i/56F9+3n77bW7evHknC33AB8sH7U0HHHDo0KEDgf594n8i0I2Njbz00ku/VaBv3brFt771rfc9+/5b3+ds8Ty+jihjHzPR9f9M0vVnk6j+WUDqSfLI0hV++MMfcXn9CXK6OWw1EkP/YKD7z1SM/qMJ22mJrL7C1TPXuLr7NGuRHeS+NNp7nQz8vZ7RfzShu9uFvztONbDJbu4BzhYvEJ+cwVYXRP1pEdWn7ejv82A9LZGaLpM3zDPnW0EaThAZLWA8EUB/3I/+qB9bXRipN0lsrMCMrUp0vEBisoTYGsfXl8VQE8bXl8N8SiY6XkAZKxIbL+DvSuHuSeMbLSP270u0d7SIvSmCqy2KrTGIozWMqSGE0JvCNpRD6M8gjhew9sXR13qZuNuG+rCN6RMuJhskjMMpzJN5zJMFbKoi9r4YY3fbmbzHgbk+gOpUANNwjlBgA79/E49znVLiLEJXHM2pIK62+H5uujNBPHqG9OwjSMlzzFQuEbGtoG2K4uzJ4hrMo+2M4xWWKG8+jr/wAOmlS8QiZzD2ZTF2p3EO5tB0xjEN55lbfpTg0iMEFx8iVXoQm2F/5bVtsICmPYl5KIvfvoI0cw7X/DnM3jn88gb6yTKm4QKGgSyiahafbg6vbw1TeB2Xso5H2cJonEM3XkLbm8OlmSdgWsShncEcWMFir+ANrOALbTCtKjHVl8VvWiYkrmEdLaCezCHY5vH513C7l9DrykwP5pEsKySlPYKWZcZboxinivjEKj73MprxPJMD+33TSe8OMecm480RJlqDBKyLeM2LmMdyjHckCdnWSHi2Sbq30PXk0LRFcatnkCyLmPvTTDbHkPRVks5NMr4d3BNzGLtSOAezOAZzGNpiTNVHEPuzpB3rpO1reCZncQ4W8Azm8Y8V0dUE0dWEsbbH8Y0USdr2t1A6+vP4h4p4e7OY6hTMjWGMp4O4uxIoUxXE3iTyRInA0H7Xs/GEhLUxjK0hgqUmSHC4QGS8RMa8RGSijLt1P7IhnApiOR3E0RLB0RghNFYiqVsgZVzA3RbDXhPE1RJFrAvhbFFwNERwt0Yp2ZaJjBbxdSXea80IIpyScLcpOBpk3K0KoaEcvvY4troQnuYI7vYojvrg/jrvWpnpwzb8nVGcjSEMRzxYT0nYTgQID2VxNYb3GzwaI0g9SUJ9afLGOWLjBZKqGTLa2X2Rdq0x71ln1r7CeniHwLjCZvp+LlQuc3H5cR5auMIzD17n6pmn2Srvsb2wy3MXrnPr8S9y+6kv861X3+Sx80/w+jfeuJNffuedd+7I8M2bN/nBD35w5/uf/OQnPPfcc++bj/71QcInnnjiYJDwd4AP2psOOODQoUMHAv37xP9EoHt7e7l+/fpvFejbt2/zxhtvvO/ZW99+mwfKDxMaSKP6Fwv9f6Wm/U/HGfu4Gbk3xdmZi3zz1X/jybPPMGOtYq+RGPmonu4/VzH0D3rMx/ykp8tc2X6Sp849x1poB2Uoh/Gol8EPGxn5iB7NPQ4C3UnmHKucKz7EVuosGV0FsSGC9rAb9af3q+zMJwIk1TMseteZsS/g748R6EthPCkzfcSL6aQfzb1OxMYgcl+ChK6IozmIZyCBoU5GVxtg/F4XxgYZ1T0ipnofliYf2lMOtCec6BslzG0RVDV+zD1x9A0yQpOM0CBjOuVBqPVjagzhGS8hjhRxq+cI6BeRJmYIjOax1IT2N8V1JHCPzxAR1gg6Ngi7d0j59whr5xg/7Mbfl8M/kMXYGkMSlsnlHiIY2iMeP09G3sHUlsTSlsDfl0FTr2AZyDIze5FQ9jyhzINUlx9DGMxj7MjgHcyhbVSYrosQDWyiVB7GV3yA4tpjOM2LaHrTOIcLWLrSTDVE8WlmiSTOIGb2SK1fxiOtY1CX0A3lMPVkmWqOIQxkicibWJV1xOgaRlcR0bOETlXCPFhA35vDNphHVJcw+5awBldwBVbxJ3cwCnPohgtYRmeQbatYB/KYjWUMtlm88gpeeQ2za5mJ8QLCWJmIawuffhFNbwaDpYzHVSUQWEF0LDI+kceqnkPx7hCyb6DrTqLqS+J3VvE5qthNFYZ7U7iNVZL+PeL+XVzaRcaaIugG4rh1FVz6WQYbQlgmZkj4d0l6dvCbV9B1pfHq5/BPVxBHCkzUBdF3Jvc7u707BI3LWAYLOAezyNo57AM5Jk8F0DUpBDXzpMUNwpYVArolfGMz+MdK2DpSaGrCaOsjOLpSxI3LRHQLhAxVosYlItNzODtTWBoiGGsj2Ftj+EeKRHSLuAbSBFUzhCdnEJtiONvjmE5KiM1RfN1ppOECWcsSadMy8nAeZ2sU80kZW0ME63tNGs5mheBQgbRuDk9PEldrFEdTFOH0/t8RTsuIdSFCQzkCvWmE0xLWGmk/o9wUwdEYxtWsIJySkPpSuJrD2Gsk9J9z4aiXMB/14G2PYq8J4utKoL7HgvmoB8O9LqynJawnAjiawthP7a/zdjVGkLqT+LtiBDpjyL0pwsMZkuoiRdsiM7YlCsZ5lvxbbMbuZ1neRdGlmHVX2VDuZy/7IM8/cpMndp7hqXPPcP/Sg8xFqlxZf5LbT32JF5/8Mi/f+DpXHniMb31zP5Zx69atX7lx/vznP/8ry1N+/vOf36m7++U4x/sNEv5CoA82En6wfNDedMABhw4dOhDo/79w4sQJPvrRj/6X58EHH7zzmv+JQE9MTPy3Hc+/eL70pS/x2muvvf8N9Pe+z5XNq0SGMkzdZaX7L1W0/8koYx8zEuiIsZc/z8svvMLNx1+kbK9iqw0y8c8muv9SzcD/1WI56iOrneWh6hWuXXie5fA2gYE0unucDH/ESP/faRj9uAl7g0RcnWdRWScnzCANJdCd8DD2KTP9H9Ex8FENY58wYqn3ElIncHRJ2LoC6E650Zz0MHaXwPQRJ2OfEDCf8uLviRKbyuNqCxGayOPoiGOsj2BuVHB0JrG3KARHcsTVJeTeJPHpWcLqCv6xIkJnhuD0PI6uNMp4ifBYAWkgi78riX+0SEhTxT81R1hYI2ReRRov4x0s4GiNExzIYq6L4FdVkM3LRLy7hL275KQzuEcLjB9z4+tOY64NYWiIEBKWiUTPIofPksk+vL9yuiWOqzeN0BRl8riMa6REMnkOX+os6bmLRMK76HoyCAM5hPYEE4d9GJpjpJQ97PIGwcp58guPYNHNYZos4x6fYfJkCHVNENmyiD28ji28gTJ7Hr+yg05XwTldQd+RRl0fwT0+g8O5iCWwjCe8gsFfxuJZRTAuoO3OIAwWMHWkcJgXMHuquANLBGMbiIlNDNZ5TGMlnIYq4kQZTWeSaX0Rj7SMX15F9CyicSxinCjjF9dQ/FsY+7JMD6ZxWOeR/au47AuMTeWZmppBdq2jeHdwTs8x1ZvGY57Da67gsS4yMZBAPV4gEthC8e8gW9dQdyWxThYwjWVw6cpMtitMdCWIBrZJybtEfdsYh4p49fMELcv4tfOo26KMNUTwGRdI+HYI29YQJ+cIaKukvRtImjmM7TGmmqI4B/NExXUU2zruqQV86jlixmUi+iqWljjaegVrW4Lg9CyKoUpQt0jEsEzcsERgsIjQGMPUGMVYE8bensQ/WMA9mMczkUMen8Hbk8bRGtvPybfGsNVHsLdFkUaLBAbz+/WGDRHElghCbRjz6SCejjiWmhC+3gzhsSKOhijWmiCW94YHHa1RrHWh9+IcQYL9GcynAginA5iO+bDXBXHU70c8rKcD+DtjWGslLCcCmI96MN7nxnzMh6dNQWwIYa8L4utQGP+kEeGUH+spCfNRH5rPiog1QWx1Mv6OKN72GN62GPYaCXkgTagvTXyiRHgoR0YzR8myyHb6HFXvJivBHRY867h7Q6SNZfbSD7KTOMeTe8/y/MMv8Oyl59kun2WjuMMTZ5/l8srjXL90ixtXvsATl5/i7bffvhPLePXVV++I8LPPPsvPfvazX5HjZ555hn//93/ni1/84n9p7fjlm+tfCPTBIOEHywftTQcccOjQoQOB/n3ifyLQRqOR8+fP/1aB/spXvsKrr776X4YHf/zjH/O9736PR/eeRB5IMfFxgbY/GaHtj8cY/gcdllMeskKZi2cuc/HMJaSRGNP3WRn4+yla/mSY1j8dZuSfDQgNPhLmPDuLe8SNOUy1HiY/ZWLoH/V0/aWKwX/UYzrpITKeYT2xw1psh6ypgtgcZvo+F+OftDL1GRvW0xLB/gxrkTPkLBXihgJRVRlPV5zp+3xYaoLoD3sJDuXImuYpGBfI6iskpipIQ3ksDQru3iz2xhierjShkSKJyTKB7hQxdRnfUBFnbwbnUImQagFvfx5FXcHVmcTVEsHZquAZyCGNl3Gq5ggK6wR0S0S0izi6UjjaFKw1MvoTMs6+HEH7OrJ3B8W/i2Jdw9yTZvKYB0ezgupuN+bWGAHtAnJoj5ByjkrlMrbREsJwEV9/HvVhL6ojfoKGRVziCq7QNvmlK7jEVUyqWYL6BXR1EUbv9uIaLeJzrWB2LZFeukgocxajaQG3dQlxsMjIPR4MrXEk5xJGawVvdJPM0gVswQ1s7hXcuipTrQk0dRHEsSJ66yyuwApueRmtXMEkrSKa5hEmyliHi5h60uincthci8jBNbzKOgZlDaN1EUEzj9e8hKE3i2Y4g2Cexeeu4hTnMEvL6KxzOK1LhIN72CcrqHqSWLQlfK4lXOYKOl0RlbWC371GOLRLwL2BuieNoC6i+DeR3CsY1HmGhlMEglvI/i0igR30IyVsqgoB2yJO/Qzi9AwjXQoecYl4ZI9EcAfj5Czm0RIx5wZxzyaOiRKjTREsYwUirjXCrnXchkVcqnkS4gZx2yrusRKqJgVtcwznRImAehbn5Dx+7SJRyzIpcQ2xO4m+MYapRcHekcQ7UcbZl8c7VkbRLRKaKGNtTaCvjaCvD2NtiODsSSP2ZAhNVzA2ynh6U9gaFUw1YYTmKJb6CKbTQWyNUQKDWQL9OSynggR605hOyAj1EcS2OMaTAcSmCJ7OBM7mKGJ9CMsJCUdDBOG0jLM5ivmUhL0+gqczjtigYD0tIdbKGI96ERsj2OuC+4OGDUHcrQqm+9xYa/ZvnR2NYUzHPbiao/u3071JxPog6nts6O9xYTrqwXifE+FUAOGkH1dTGFdrBHdrBF9HjNBgGndjCE9LFE9LhISqxKy4yoJ3gznnGhXHKhVxhdXgDvJonPBkmjnnGo/vXuPmlRd56fmXeXj1CmfmHmA5tsHlncd4/uGb3Hj0C7z5jW9z/fp1fvjDH97pdr5169YdEX7qqad+JdLxi8HCN998k1u3bt0R719/vvrVr3L16tWDjYS/A3zQ3nTAAYcOHToQ6N8nfl2g//M//5Pvfe97/Ou//iu3b9/m2rVr9PT0YDabiUQiFItFvvzlL3P79m1u3brF9evXee6557h27RqXL1/m0qVLXL169Veep556imeffZYzS2dxtckMf0xHx4fGaPuTEfr+agrjcTdFcYGbT9/iy7e+wpx7GWdLmImPC/T99RSDf6/FcNhNdCTP/aULvHL7Vc6VHyYxWUSskxn/Zyt9f6th+jN2/J0J5hyrXJi/xNnyI5SEJbwdcXRHfEx+2s7UZ5xYa4KEB7KshnfIGGaJ6/LIAzmEujDa+3yYa0NYTgWR+tMkpsrI3SkyujmU8SKB/iy6mhCu/jym2jDSUJHgUB5vRxxXcwR3RwJpsICtJ4tPNY9neAbf4H5uVaj/RY40gq1FQezO4NUuIVvWCBuWCOkWsTRFcTbHMJ+WMNeEETuSePRVZM8WEf8OEcc6lv4c+kYJ0ymZqfv8WJoVfIZFnI5V4pkHiUfPYp2exzM9h6MjycQ9Hgy1IXyaeSyGOfzhXSqbVxHFNVzWFcKmJSbu9TN5nw9ZO4fZMIvFPE9h+wrexBkEzzoR1zrGrhSjh32IvVlM6iJG0yzx1B6R+QcRYpt4gptYJ+fQtibQdyQxjubQjGfx+5YJZXYZk2YRlS1c5ipWXQVjTxrDYI7pkSxeVxWvt4qY28ac2MRmXcLv2cA+PYu2J41+Io/fuYQSXMcdXGFaWUKUVpFD27jENab6smjHCsieVSLyBm5vlSlnBWdonVBij3B4B/1EmamBPBH3GiHvGn7HMsNDCSz2efzSBmFlF8G0iHYwT9ixTlBcwmWYYbg1wvRwCrcwT8CxiihUmR4sEHVtkvBtIxkWUXckULVEcGkqeI3z2FVlTONlQuZVEuImAdUc6gaF8ZoQQncSj3oG23ABcaCIpK+Stq/hGy5iaEmga1TQnA4idqcxt8RxDBfwDpdQtAt4BrJYWxMYm2NYWqKYGhTMzTGcPTlcfTkMdQFsrXFcPWms9VGEBgVzTQjD8QDScB5HexxHS3Q/19wcw9uTRmgMYzktYz4lYz4p4WyNYauTERvDWGsk3G1xPN0JTCf82BtCuFuiiLUhhFMSppMB9Ic9uFvj2OtD2OqD2OpCuFsVnE0RxFoZ81EvxiNehJMBHA0hrDX7NXfOpghCTQD1ZwUsx71YTngxH3VjPS1hrw3i747haVMI9acQG4I4GyO4myL4O+JEhnPMCEsUTQssS9tUHCusRnaYd61Ttq/g6YuQMBd5dOMJbly+xZeuvcSzF26wW3qQM3MPcGXnKivJLZ57+Cb/+uXX+c4b3+Oxi4/zox/+iHfffZd33nmHJ5988o4I/2IQ8Jfl+I033uDll1/mxo0bd8T715833niDK1euHGwk/B3gg/amAw44dOjQgUD/PnDu3Dk+9KEP8Yd/+If80R/9EadPnwbg5s2b1NXV0dXVxfj4OEajkWPHjtHd3Y3X62VhYYFvfOMbvPHGG7z55pt897vf5e233+aHP/whX//61//bYcMvPPlFMroy+vtc9P+Nls4/HWPsI0a8bQqrkR3eeOXf+PqLr7AU2MDdHEH9LwI9fzXN0N/pMHzORXQ0z7nyw7z8ha+zlbgfZTiP8bifsY+ZGfw7PdrPOhAbQ+QNC2wnH2Av+yCJqRmcrVE0n3Mz+Skr6rtsOBojyL1JSsIi0dEc/qH92i7jSQndCQn98QBCfQixMUJ8cgZva4y0rkKgL4OzLYmuJoy7P4fQEEUeKeBsUXC2RPB3x/D3ZnB3JbF2ZQhMze0vM5ms4O7PYW+I4G6NYa0P42pLYG6NIwuryJY1AoZlZF0VoTWB2BpFf1zC2R7H3Kzgmp4j6NoiFtxDtq3h0cyhqfEzddi7f0vdm8Y6mt/veM4/RDh8P07LEgnXBpoTEuOf9WBtTWBTldCO5kjPPERy/iL2wAbR0B7icJGJw34MdRHsw3k0g2ls1nkqDzyJI3sGb2KPgGOJqcYY041R7INZVANxLFMFkrMPIq0/gqN4Pz7/OlZVmam2JNbBPNODacy6GcLBTYKrF5hMVnEpG7jcK5gnSxj6c0wNpbHoZwl4VpCzuzg3HsCZ3ESKbeHzrqIbyKIdymPXlJF9q7jERXTRFYzKMoH4Dp7QBgbtLOr+LC7jAhFpC8m1wtRUFrWpiNtfxRvewmqvMtqVwW9ZJuLbJORdR92fYmw8hU2o4HFU8XpXmRzO4TYuEg9s4xUWGW6S6a+TsGmKuIQFrJoZpgfz+C1rpLzbRJ0bmIdzDNdK6HqTCONFrONFVJ0JHOo50p5dYsIqQl+OqY442sYwtv4clr40xq4k9oECiqGKYljG3pvD1JVG1xTG1BDB0BLD0pXC3pNDGp9BnijjHijgGMhj70qhr48wfTyAsTaE2JVC7EhgqPHj7k0idqSQRosIjQr64wHEliim00FcXfsr68XWKJ7uFK7OJLaGMIYTfhzNCvamCJaTARzNUUzH/Hh7UsjDOYS6CLYaGaF2v43D0RjBfGJ/4ZCrRSE8nMPWsP9zZ5OCty2K2BDC2RxBf58HV2MEd5uyv8K7Poi3PY7tvRXd0/fYcDaEMR3z4GyOINYF8XfGcDeH8TRHsJ8O4OuK4WkJ42lVkPtSKGMFCuYFlnwbVH2bLMlb5PRzVOwrVD0bJPU5ItokF+Yuc3HlMS4tX+XJM89wZe8qK7Etnjz7LCu5DV69/Rov3/g6r738TR7cusA3XnqNd975jzvS/B//8f99/ety/KMf/YjPf/7zPP/88/zkJz95X4H+7ne/y8WLFw82Ev4O8EF70wEHHDp06ECg/7dRKBTAOyzvAAAgAElEQVTI5XK/NcLx2muv8aUvfek390RfuklSNYPhXic9f6mi40/HGfqwDuGklwXvBv/26rf4wrUvUxaXsNfITP6LQM9fqBn4m2m0n3UQGkizGb+f5y+/wLqyi9yXRnO3g5GPGhn+qJGJT1ixnZYomOZZCW2xIm+R0c7ibY+jusvBxCftTN3twnI8gK89TmKyQN48h7MjSGgoh/GUjPF0EO1RP/bGCNa6EKGhPHJPktT0LP7OBGJzFEtTHLE7jdiexNWRwtEYwdsRJziSxdMRxdkRx9qdJaCuIPbmCWsWcPdmsDeFcTSEcTQqiC0K1q40IWENr34Z2bSMZKji7k1hrQujPeJFbFYwNCg4dYtE/NsogT3Cnm0k3QJTJz2o7/EgNEawtsfRdqXwejbJzl5EDp9Fid6PIlRRHZPQHA/j7sky3RnDopqhuHoFKX+eQOYs2fQDaFviTNeGcffnMfal0Q6kyc89RHTjCr7KeXLVy1i1c2jak1h7Mxj606h7EngcVbJnHsW5/CCxlUeQlS1Mqhn0g1lMgzmmB9I4tGUCyiZC9QzTyQXckQ0c3hU0o3n0w3kMo0W84iJuUwUhtoIhuYI7vo47uoFWO4t6OId+OE/AuY7LPI9JKKPyzmIWK7giKzgDK4yPFTCMl5FdmwTsq+hHMgxMpzCLs1iEMjbPIhNTJUyqWRT/DonQHtapGQaaJQy6PFbzLDZzmZGhDLrJWeL+PWK+XYSpGTqPezCOZ7EZyphVRVQDKfSjJeLebeLebSTjEmNtcTTtMWzjeYTxPOq2KLr+LIptjaRzm6BhCeNQHkNnEvtgGn17jKmmMLq2BM7BAinHFrJ6HttwCVt/bv+GvyXO9EkJU2sce2cKaaxMcKqCc6i0L9CdSUy1QfR1YcxNCub6MK7uFMYmGVdfjoh2AXdPBlNNEPPpIJZ6BUtDGKE2iKc7hacnS0RVwd+fxXRawt2ZwHRaxlobxNuVQKgL4uvPEBouEuhJYa2VEU7KuNtiiPX772Nns4KjNUJyqoyzNYqzPYatVsbZEEKsDeJsjmA5LeHtiOLtiuNqDGOvlfC0Kvuf1rQqCKcDaD5nx9Om4GgKYTkewHzUi71GQjjpQ+pN4mwM4m2P4mxUCA2kkLoSFMyLpNRlMppZMroKFccyZdsSS75NKvZVoroM4ek0Dy9e5sLcFR5ZfpyHFi5ztnKec4sPcevqbbaruzz/yE1uXvkCLz75Zc5tnefVL36Dn/5of0HKjRs37jRvvJ9A/2KQ8Nq1a/9l9fcvnm9/+9tcunSJd95552CQ8APmg/amAw44dOjQgUD/b2N5eZlwOPxbBfqb3/wmL7744m88f+L+a8TG8mjustP1Z5O0/fEwA3+rwXLCR8W1xkuff5nnLt5gzr2Kp1Vh/J8FOj80Sf/fTDN9l4jUnWBdOcOllcfYzT2AMprDcszHyEeNDH7YwMQ/mbHWSKQ1ZaqBzf2IhnYWd1ucqc+4UX/WwdRnnWg/60LqTpBQFSmLSwiNAWKTJUynQxhrgmgO+7C3RjEe9xMayKKM5VGGs/i64rh6Urh7c5jqo7h7s9iaY/uZ5s44Ul8KZ2MER3sc98gMflUF98gMYc0ijo4U7o44Qm0QsTGCUBfENVoioF/Cp6sSsm2g2NbwDxUw1YUxHAvgaIxibI/jNy0R9u0g+3YJ+nZJezeZOOZGdyKEqzOJsTWKMJInET9LrPAQUuwsMzOXcE+Uma5VcPVmEbpSqJqjeF1r5FcfxZt7kNTiZZLR+9G2xxG609h6sow3hjENZMjMP4Rz8UGk5UdQCg9gnCyi7ckiDuWY7koz3REnHFjDkdvBWX2AcOl+rK4qmtECpuEs2p4M+v40VlUJT3oTXWwZlTOPJ76B3jCLdqKAdiCPoJ7BNl7Aap5DrVQxeipYAwtY/FVUmiJT/QVc5iqycxXjUAaVrciUrYQYmEfwLjBhmmFiJI/XskLQs411qsxwXxSdpYTNXsHunmdCnWdsokjAtUVU3kMSVxlqDqMaTuB0LGCzlJkYSTDQmyTs3iYRPIPi32G8O85gs4RlsoBdP4NmKMFgSwSvsITi3Sbh2cY0WUbTnUJUFbCO5phuVRhpjmAfLJBwbZIK7GFXVTAO5rH1Z3GMlVDVhxk/LWNsjxHSLhIXN3Fp5nGpZnGNFHENZNGeDqJtiKKrC+PoShMzLuFXzeNTzeGfKL0X1whjaoxiaYxia40ijc9g7U0QnKrgHynhaN2XYltLFNNJGVvTfre4NFoia1slop7F0RTD3R7HdErG3hTFWhvCVh/G151CGsoRHSthb47iaI7gaIxiOSnh6YhjrQvhaI4SHs0jNkYwn/RjORnAXhfC0RTBVrff6CE2hPF1JbGelLDVSBgOu3E0BLGelnC1KpiPedAfc2A55UX3OSeGe93Ya2SMR9x42/dr89yt+yu/g31ppM44cl8KuSdJdCxPYqJI3jjHjHWZknWJec8GO+kHiajTZMVZFr3rbEXvZyf1AM+ev85e6RwPrV/i5etfYzm1xqXVx7j1+G2++PRLbJS3+MaXX78j0F/72td47bXXfqNAv/vuuzz99NN3Ms7vd/7Nb36TJ554gu9973sHg4QfMB+0Nx1wwKFDhw4E+n8be3t7uN3u3yrQb775Ji+88MJv3ER4dfcaGe0s+nud9P+thrb/M8LA305jOeGjZK3y/KUbXL/0AqvBbbxtUSY/YaX7r6bo+6tppj5tQ+pNsBbe5fzCJc4UzxOfLGA55Wf0YyaGPqxn/GMWLMcDxMcKrCl7VP0b5I0LuNriGI75UX/GweRdIlOfthPoSpKaLlOyLmJt8BKdLGGpi2CpD6M/KWOpDWI5ESDQmyKhKuNpiRAZyeHqyeDuzaOvVfCPlBAaFYKDOfw9KZzNEZyNIXz9OeSpeRwDBbyqOXzjs/gHsshDeRxNUbwdMcSWGD71HAHdIrKwTkjcQtYvIY3PYKoN4+9O4OyIY+5K4zcvE/TtIgd2iUXPEhfXGTvuwdoSQ2yLMXUqiHW0RCZ3AW/iLHL6HPncw1j6MhjaE3j7c6hPSkzWBIkGd5BKD+CeOc/M5lUE9SzT3RmcAwV0jVFGTwTwmObxJXexZnZIbz+Ky7+CeiSHaTCHsSfN2EkJoS+DFN7EkFjDmdvGGV/HaJtHPV7APJRnuiONoTOJyziPzreIMVJlwhhHjK2hNs8yNV5AN1hAnJ7F0JNB56ww7ZpBDCwiBqtoPYtMThYxqWeR3VsIwwUmBxNMWYvY/As4vIto7bMM64qYVbMEfTsEnOuoehOMjyawWss4vIsYDTl6R1NYLFXC0g4R/y768RLjA0nshhms2hJmfYnutiAWY4VE5AyKtIdDWGKoNYxuJIldU0Q/nKT7dADdWBbFt01c3sMnrqMbKuBQz+DVzyMMZxiqk5lsiSELy8R9u/jNy1inF3CMlZBM85h7kqgbQky3RnGPl4m71gnZVgmYVvFNzuEdKWHtTqGtj6CtD2PrSBKcniOgXSBm3yAmrBCamsXaGsfUHMPUFMPUENn/B20gj7FdIW5aQpooIbbEsLXEMNUEcbTHsTcriG0xolOz+IcLuNoTCPUhhPoQlvog5lNBxNYYlroQ0mCO4HAe8wkJe/1+3tlaF8LTFsN8UsJeG8JWH0JsCmM47MF03IfllB+xdl+gXc1R7DUhfL0JtHc7Md7nRnOXiPE+D6bDXlwtEew1Qex1EvojTrR3O9B/zonucy5Mh10Y79vvgxbrg3haI3hbFbydMRwNQQK9CYJ9KRITRZShLJmpCgXDPBuJ+1lX7mcttIc0GiOqypE1VdhNP8hO8gEe3XyS++cf4MmHrnHj8i12y+e4vHOVi0uP88JjL7KYXOXfXnnzjgx/5zvf4fbt2/z85z//jQJ9+/ZtHn300fc9e/fdd3nttde4fv06r7zyysEg4QfMB+1NBxxw6NChA4H+38bFixcxmUy/VaC/853v/Ma+6J/+9Kdcf+xFsoY5TEfc9P3NFG1/NELfX2swH/GTN83x6PZTvHTjK6xFdvG0Kqg+KdD/N9N0f0jF5CcEpK44i94NHl6+wrnKwyQ1ZSwnAox/3MLIR02MfNSI/nMulKEM68oeK6FtZmxLeDvjmE4FUd/lRPNZF9p7XXjbYyRUZUriEvYWifBoAWdnHGNNEP3pILojPhzNMSKjecqOZfydCbLGBfwDeVxdaYyNCTzDBSx1YQIDWSLjeaTeFMHBLCFVhcBEGaE7h2RYwj0ygzw+Q6A/j9i0v+ZYaIoivSfQftsmsrhGULOANF5GaIzibouiPRzA1JLAo6kQCp5BkvdIxc7h1SwwctiFvS2G6ZSM6pgfx2gJv38bT+IMsfIjRAO7TLUnsfWk0Z8MMfI5D6a2OLHILmbfKvLsBeLl82hG8xjHioh9OYbv9TJxQkJ2LGEOrGBV1kksnccsVtHqKoiqCqoGhfEjAZyTJczeefS+BVzxNXy5XTTiAoJpHu1AHnVzDFN7ArNpFp1/EatvnnFrGlN0Ha1rEe1QDutUBWN/Du1gCrWpgM23gOibxyQtMOmvopkq4RBWcJkW0fSlGVelsFhLiM459JYSY85Z1LoyPv8GSngP43CR0cEUVssMVmEWk75E32iMCWMJyb9NMLiH07rMWH8KhzCHyzqHw1JmqFtheDxDSNlDlrfxezaZHMph0pYwqrM4jWXGuuOM9MYIeDdQImcIy9sYpis4dPOExTXc2gqqDoXhlgiiqkzYvUHAuY7DuIRkWiLu3sSnWcDYnWKiKYKxM45XM4tnqoJDs4BkXCJmXUOansfYFEPbGsPSkcDWk8YzXsQ9WkLWVYmalnD3ZDG1RtHVRjA1RhGaFBydKdxDBczdUZxdGcS2GLamGKaGKPbWOEK9gvGkhKM9ibc/h6MlivY+D672OObTMrZGBUdrFFNNEFdbDHdHEsMRH+aTEtP3uLHWhxFqgtgawtjqQohNCo4mBcNhH8b7POgOu9Hf68bVquxX3jUqOJsjmI/6mP6MHfMRL9q7HRiOeDAd8eBuiyLWyng6IkzeZUE45UNzlw3DfW6mPmHFfNSH+Zgfd3MET1sUf1ccV4uCMprD3azg79jPSEfHchQtVVaCuyx41qj6tpgVV5DH4hQs80RUGcrWJR7deIIXHrvNxfsf4+G1K1y/9AW2MvdzrnqB5y7c4POXbrK7dOZO/vndd9/lZz/7GU8//TTvvPMOTz311PsK8uuvv86lS5d+o0C/8sorvPTSS7zwwgsHg4QfMB+0Nx1wwKFDhw4E+n8b165dY3Jy8rcK9FtvvcXzzz//G8+/+oWvMyMsYjnqZeBvp+n44zF6/3wK7d0imekyj+0+zXff/B4b0T18HTGmPmNn8P/q6PlLFZOfsOJsDLPgWePZhz/PheoVUqoZLCckpj8tMvhhPWP/ZMZeIxEfL7KTPse5mYdZkrfwdSUwnZSY/JTI1N1ONPe68LXHmLEuUrIuIk3EiWsq+HrTaI/4sdQp6I/48b63fjulLuHvSpDWV/AP5LG1pRC709g7U4jNCYLDBaSB9P7HzW0xnF1p3P0FbH1FgsYlnAMFQpNl7C0xrDXy/m1eYxRHTxqHuoIkbiBZN4joq4j9eYw1MsYTfibvdmFpT+CcmMXn20YKniEm72IfLTJ8yo29OcLYXS6mjgVwT5YRrVXc4V1KK1ew6ecxjhbxjxSZuNfL6F1uXGMFrJY5DOIiiZWLBJRtdIZ5POZlTK0p+j9px9yewGOrorXO4IltEiifQe9dxuZawaGeZfSkzMRJGcdUiWl9Ebu/SjCziTW9gz64gs24iG4wx3RLHH1vGtVUBoNtBqurjNqXYzq+ikmsYtSWsU7Nou9MoxrLoDcUEZ2zCK45NNk11N55BMsibvcGxuEi44NxzMIsXl8Vu22WaVeZUU8Fu3eVoLKH3VJlvD+J2TiDL7CC07nAtD7PoFDAHVonlNxDDm0xPpLDqJ0hJG/gdy+jncrSOxjDKS/jC24hhXfQTs8iaGdxWSq4bRXs+hJ9bSGMqgJu1xKSbwuDfg6zpkI8sEXUs4FltMBQWwR1h4LHuIBDP4+gnkU0LhER1lBsawj9GSZaFNRNEcz9GdyqWUwjeRyTFUKWZcKGBSydSXTtSfStCXT1YSzdGSydGZyTZdwDeTxDecwNCvpaBUt7AlNTFMP/y957fUlWmHe78zd863jZlpbtz8e2skGBiUzq6Z7OOYfq6q6unPbelXOu2pVj5zwdpicyDDAScQATJUAjBHwgDUqgDyQkG4OQMBdefs5FW5zjY2SdtbzWmQv6uerV7+67unh61/v+fk0JbD05AmNVjC0RpOYYjnYZqTWF0CwjtckIjTGEpjjB8SquThmxPoqzNYlwOoanJ4+jQ0ZojOJpTyOe3j0WtJ4MIzWEsdaFEevDeLszOJqSeLszeHvSmI76EU8EEU4EsBwLYGuMIp0K4WlL4m7dbSqU6kLYToUwHHQjHPNjutOLq2U3rSPSn0NqCKE9uPvNkeWwB/MRH9qvO5DqQrhbY0SHCwR60sTGCgS6Uvi7UgS70oT6ssSGC8w61ph1rLIW3WE5sMXZzCVWAluEx5JMSysk9QW+tX6d5x66wctPv8q52ctcXfomT979DP9w71MsxtZ48u5n+eH3XufalWv80zvv8rvf/t9xddevX+f999/nqaee+kRB/sd//EeuXbv2BwX61Vdf5cc//vHHKR57h4S3jlvtTXvssW/fvj2B/rRx48YNRkZG/qhA//rXv+bJJ5/8g/M3Xn+TxcAm4skAo5830v/ZKUb+2oBwPEDJNMcTV5/hV7/8FZdr9xBXlDAc9jD6d2YG/1KL5qt2/F0p1mI7fOf6Db61+QhVcQl/RwrdHS5G/9bI1NfsOJpixEbybCTOca50NyvRs4QH84gNYXQHfej2e7GeDBHqy1C1LpJUlAmOpkhMVPH0ZNAdi+DoymCuC+PrzRLoyxIdzBEcyBAczBMeLWFtSeEdqWHvyhEcqeAfyONsieFsjOLpSOJsk3H1FfFrFgjql/ApqiS0i1gbYjiad6PCpMbkbhmLboGYZ5u4Y5O4cAZ7fwmpOYbYGMV4PITUmsShmsHn3SaWvEQieA771BymnhjmujCqA17MDTF8ulkshlmi2cvkpu/DJq7gFVYJqWcYv8OH+kgQ72QVs2Ea0bHI/F2P4U7s4AxuEHWso21MMX4ogHesglFVRq8uk5y5RGjhCtbUNpHwWYSJaSZPxZAGCxgVBTSaAn7fMtG1K1hqO3gL53EKy1jGK+h7clhVZTTqEv7QKiF5E2VmDmtpC5t3BbdrFYuyiklRQast4w2sEoyuY6tuoq+eQQqt4U9t4XKuoh0uYdBU8XlXiEQ3cQQWmEwtICXPEMmfxxPfRKOaRj9ZJRreIJU8i8ezwKguh8kzjy+1QTR/HoO4iGaiSip8llj0LAHvKkODSXTGEnbbPP7QOqJ7Bb1mlrj/LGHXGg7TNCPdcSZ6EzilBdz2RUzaGnr1LAnfNrngeQKWFaYGsoy3RbGMF7FrpxE1VYyKCmFhjbz/PJ6JWfRdGbTdMsa2FPbxMtbBIrbJGh7lLCnzKr7xGuauHIYuGVNrCmt7CktXBtdoGc9wmYCihruvgL1/V6qlrgzW5gSmhgiO3hyewQKqw25srTLuvjz29izunhxicwKhKYa7J4PUksTRkkA4FcbRlsI/XMTWmsJaH0Nq3K38dnbKGI/4sJ+OYjzsxdOdwdeXx96cwNMt42iLY2+JI9ZHMBzyYj7i2424a03gat2t+vZ1p/F1JBFPhXE0RjEf8yHVhxBO7uaXu9riBLvTiHVBpAY/1mN+PK1RzHd6sTcEcbXEiQ3l8HfKxIZzOE9HCA9k8bbF8XfJhPtzFAyzlIUl1mNnWQ5ts52+yLS4wqJ3g9BYinOFK8jGAvetPMhDW49y/8Z11nNb/MO9T/HAxnWeuOdZFtNr3Hzpx7z6/E0unrmLH730U3766hsfS/Szzz7LW2+9xbPPPvuJgvwv//Iv3HvvvX9QoF966SV+/vOff1wNvndIeOu41d60xx779u3bE+hPGzdv3qSzs/OPCvS7777L448//gfnP/3hGywHtrA1hBn/Owu9fz7JyF/pMR1yk1VP8+S1b/O/f/oW54t3ER3IYzzoYfRvTQz9lQ71Vx342hLM2Fd4/O6nd3OgtdO4W+Jovu5k9HNG1F93IBzzEx0psuTbYCmwSVVcItCbwXQihHq/B/V+N5ZTARxNEXKGWaKDWZw9YQK9WRxtKYx1YcSWBKa6MK62JMHBLJ7WGPHRIv6eDL6+HObmFMGJaaTOLLGJGaSm3bzc3RrkNM62FGJnloB+GY9qnqB6joh2HvHfd0ctx4M4OlKYGqIErGtEnVtEpDOEret4x6s4W5PojwQQG6OILUkswyWC/rPkc1eJBnbwCKuYOmLojgZQHfJhb09iGcxhmaqSnr6XZPluPL5tssnzCB0ZlEd8mE7FsI0WmRrIEE2dpXT+Iey584TkCwSEVSYbYhhaEtjGymjG8gimGnN3P4J37Squ6kUC4S30Q0X0nVmc4yXUE0UEY414+TzxK/cjrd6FP7mF07GMfrSEMFZGN1bAaqoR8Kzgn99hbGYRR3EbT2oLu3MZ/XgF7XgZwTJDMLCG0z2PsbyGMbuKv7yNL30WvX4a9WQZp7BIOLyBU5pH7ami9k/jjKzgks8gBVZRjpfwus6QjO4QdK+jVMiMi2VswQVsnkWkwAqKqSp+xzqJ6DmSiR2UwymGe2NYjBXsngVs4gyKiTI+5yZy5DwB+zLKwRQDTWEskwUk4zQWXRXVaB63sEQ2fIm4ewvLeJXxbhltdxxBVcKiLDPVm0VU1sh4zhIXd+u8zYoKxp4Mpm4ZQ2ca83Ae62AR38Q0EdMSjuEq9rEq0kABS6eMrimBpV3GNpDHM1jGPVAkoJzFNVzFPVLC2prCWB9D6EwjtKSwt8tMHXHh7s3hHdkt6hHbZSwNcRwdMs4OGXtbEsvxMLamFN6BAoGxClJbCrExhr8/j9ScwN6cwNWZwnw8RGC4SHCoiK05jqsjtZsT3ZnG2ZLE1hxFOBnG0RLfzVFviuPvzeBpT+JuTezmQLclMB31YW+IIJwM4WqO4WxJEOrL4m1P4miJYq3z42qL42yMIpwIIp4IYjsVxHE6grM5Sqgvjbc9QaBHxt+eID6SJzpcpCIuUhEWqFgXdyPsvBvMu86w6t8mNJpiJ3eFnLXGlflr3Lf8INdWH2I+ssJ9aw/wzLde4DsPvMDF9cs89/B3efra82zN7PCz197gRy/9lF//YjfX+ZVXXuG1117jueee+0RB/vDDD7nvvvv47W9/+wd3pH/xi198XA2+d0h467jV3rTHHvv27dsT6E8bb7/9NvX19X9UoN9///3/svL7tRs/ZN65jq0+zNjfmej9sykG/kKDfr8LebLKg9uPcvP7r7OROL+7A73fxdD/qaX/L9WovmLF2RRhWlziga1H2JLPk1FNYz8dZeI2G6OfN6H8soDlqJfYSJFp2wqztjUqwjKx0SL6I340d7gwHPFhPupHqo+QnqySmajiaA8TGy3gbE9hOR3DfCqKvXVXFvzdaTytCXKaaZwtCTzdaUxNKfxjVWydOUKKGrbTcVytCXydMq7WOM7mBEJPjqhpFffELAnLKv6JaeytCaT6KNZTQZzNMcwtSULiGmHbGWKubWKuTSLqWVydabQHvEj1UUynIwjKKvHQOZKZuwmHzxPzb2Noi6A+FkQ4HcXenUbblcElrVJZv59Q7grR4hXk0Fl0jQkMDQn8Y0VM/VkMigKlzfuJrN6Hf+5uKsvfwqqooG2XcQ2VMQ3mUffKJOPbyBfux3XmKvLGNXyBMxhHSwijJSxjJVSDaQRNmXjpLOLKBULnr+LPnUUQ59FPlLEoKmiVRWy6aRziPJbaGopwEUd2HXduE61uGp2qinGihte+gqSuYY4uoEsvYA3O4cyuYQksM6muYlbNEQqexeNYQqfKo5RyGJ1VrN5pbOEVFPoaRsM8sdBum6Bxokj/eByDVMEilLG4ZlFoSpiM8yQTF5Fj57FZ5hhoDWPQ5RDs01hMFYbHZPTaGdKRC2RjF5EM8/R3RdGNZrBMFrCoi4wPyqhGC0R9Z0mHzuO3rqJSlDEOZxGVRfR9KZTtcbQDWTyaWdL+HcKWVSwTM5hHStjHipj6M6iaomjbUoh9eZKWZYLaRZzqeVyqWZyjZYztKUxtSSxdWYTWJO6hEuGJWTwTs/gm5/AMl7A2J7A0JRA7M7h6cji7ZPRNQQKTsyQMS3hHSlhPRxHbUjg6sohNKVzdaVydMt7BIrJxEe9wGbExTrA3j9QYx9OZxtWWxNYSw9ObwdeT263wbk7iak3i60njOB3D35fB0ZLA3SkTGckj1IV215MaIjib43g6UthPR/F1ybhbY3g7UliPB3GcDiOcDOJpjeFqi+Nqj2I+7iXUm8Z8xIv5kAfzES+u5ijCMR+BnjTulijh/gye1gSJsQLhgRwpZYX4aImcZprMZJWKZZGauMKSf4s51zoZscJO7m5mAyvMedY4n7/KuexdrOc2eWD7Os9+83lee+EHXJi/xLX1+3n6m89xbuky33v8JX788k/51du78XVvvvkmzz33HDdu3PhEQf7Nb37DAw88wNtvv/2J8+eff55f/epX3Lx5c++Q8BZzq71pjz327du3J9CfNj744AMOHTr0RwX6N7/5zX8p0C8987+Yta3urnD8jZGuP1HS/xk1+jscxBUF7l15gGcffI7t9EXiw0XMh90M/ZWOgb/UMP4FK/bTUWriMhcrV9nJXaakn8PRnET9DQfKL1oZ/5IV050eIgNZyqYlFjzrlEwLxEbLGI+FUR/yoD3gQXfAjXgyTHysRMEwi+mUh5SygqNVRmxJ7eZA92QwHwvi65IJ9aaJDhRwtiQIDKOuSLEAACAASURBVJXwDJVx9Jdw9Rfxj1bxdKVxt8sft6w5W5N4xqeJGhbxqOZ2DwnHagSGikhNsd2q4pYotoESYWGVoO0MEfdZUt5zRLXz2FplzCfCuLtkzK1JvOYlYqFzRFOXicYvUi1cRdccxtAQw9kpY2lLomuXiUV2yC59i0DxCrmFbxFzr6PrSOEeKWLvzzHREMY6XiY3fw+uhSvEN75FrnYV/XAeY18B12iJqbYkum6ZeGYHS2ELz9oVkktXEaUltMoyoqKKpjvLVEcSv7SAs7aNtbqBp7SJLbmG3jyLeaqGYbyMWVnBqihh9y2iTc2hsMnYY4uYvPNoTNPoFVXs5kUcullMk0Umw1X0rjJCaA5jYIZJ+wxTqipu5xliobOYxoooNVl0zjKCdxrBN4tCLDOuqRL2bRONXsDvXmOoL45Gm8VmryJ5ZhifTDOsLhOOnCcVv0QsfI7xoSyqiQxWUwXBWGF8XKavL07Qt01Gvowcv4RSUUDRHUMy1xA0JZTdMQY7IjhM8yRD58lELyKYlzAqykjqCjZNBVVHnPH2GOaBPAn3JtnwBWy6JUTNHE5VDZe6xlRzDE2XjKk7TUA9h+zbJmhZxWdawqOaxj5cwNwpY+pIY2qXcQ4WiOkXCemXd49OtQs4+/NYW5PYejNInRnEdhn3UBFzZ4KIZpGIehZHVwZ7Rxp7u4zUnMTdm8XZIeMeKJI2LuEfKmNv2V3bsDensLclkU7HcLWncHXIhEfL+PoLWE4EcbXFsTfGsTfFCQ9kkRqi+HoyuNtTiKciCHVBLEcD2BsiuFqSuFoTBHrSuNoShPuy6Pc7EU8Edyu7TwURTgbxtqUwH/MinvJhPe5Hd8CF4bAb4bgf4ZgP6VQIR0MYT1uSYE+aQE+aSH8ef1eKyECWxGiRzGQVebxCwThLzbrMdvoSZ7N3IRuKbCYvktdPkzPV2Mlf4VL5XqYDCzx+5Wlee+Em373+fe5euY97N+/n7vlr7Mxd4Nn7X+Dmiz/mg/d3c53fe+89HnvsMb7//e9/oiD/8z//M9evX+cHP/jBJ86//e1v8+677/LOO+/sHRLeYm61N+2xx759+/YE+tPGv/7rv3L77bf/twX6xadeZiW4haMxjPILJrr+ZJzeP1eh/YaD6FCOy9V7ePpbz3HX7H0kx0oYD7sZ+RsjA5/RMP53Jmz1YQqGWbazF7kyf42yeQFnaxzNHS4UXzAz/nkrujucBPvSVKyLzLvWqViXiI+UsTRE0N/p342xO+jB0RQn3JelYlnAcspF0bKIq13G3pnGWBfF1ZXDfCxEbLRIQlki2Jcl1J8jNFYhoKhhac8QUM7i7M0TGMgRGioS6Mngao7i788T1S3iUc7gmVokbFohNDFNYmoWW+O/t7g1xXGNVgiZVog4zxLx7hBzbRM3LCJ1pvH25HC2JdDURXFOzhBPnCOcuotk/m5ysQtMNISwtMo42lNMHgti7EgRDW7hzl7EX75Cbf1BRNU0pv487sEiqmMBJk4EiDpW8WXPYcudo3DxYSTXCuqxEnZlBWtPlvEjAaSREr7YBsbMOsG5S3gzm2hNM+hVFaxDVSabk5g6U3gcS2hiCwiZVaTkEpbEGpPmGibVNNqhEsaBPIKiiCk4iz4yw7ghjpBaRB1aQqutYZyYxu9cxziYR6vLobGXsIVmED01dMEZFNYqZv0C0ch53JYVpsazTOrSWB1VbIFp1GKeIUsRUVwhFLtAPHYejSLPhCqLKFSwWMoY9Dm6x5JYHSskkpeIJS5hFRdQjmWx22eRLFVMuiLdHUFM1jnk3F0k4hdxec6gGEhj1ZexW2cxT+YZ7ApjVBaJhLZJpi7i829h0c9j00wTkJawjhcZ70ow1Z/GLyyRDJ/F59zELq3i1s3jN85j6c+h7U6j7kohDOUJi8sEDMuEXJuErSsEdPNIAwVMnbuCbe/P4xwq4RmfIWpeISGuE5qcw9GTR+rJYm5NI3VlsXfKOPoKmLtTRLULuHry2DsyONrSiO1pnF27edFSS5LASIWgoorYFMd0IoCrQ8bWlMDZlsLdlcbRmsTfn9/dhT7qR2qMYLrTh6s9hbM1ga0pgas9ias9hfVEEP0BD8ZDXqT6EOajPrxdMvaWOP5uGXd7Av1+J/o7nOj3uzEc9CCeDGE+upvzbD7hRTwdwHTQg3A8gOarEtZjPvQHXNjrwwjHAwS60vjbkkSHC/g6UsgTZfydKWJDBQJdMumJKhXLApvpS2wmL7ISOUtYkWY1vEPNtkpSlWNGWuG+xQdZK27xynde49n7X+CZ+57jrtl72Zm+yPVLj7NR2uHG4y/z/j+//x92nB944AFeeeWVP3hE+NRTT/3BFY+nnnqK999/nw8//JDHHnts75DwFnKrvWmPPfbt27cn0J82/u3f/o3bbrvtvy3QP3r5x5xJnMfdGmP8ywJdf6Kk909VqL4iEu5Ns52+yCvfeZV7lr5FSlHGcKeP0c8Z6f+MmvHPWxCPB0hPlrlYu4f7zzxMTVzC1RZHe8CL6jYbii9Z0R/0EOzPsujd4Ez8PLOeNWKKEo5WGf1hP7pDPgwHfbhaEySVZRZ8G0hNfvKmOby9ORwdaUx1caSWFLbGOLHhIhntDP4uGVldIzJRJTBaxdqRI6xZRGxNE1FUiSqreDuSuFrieAfyhFVzOBTThMxrBI3LRJWzBMequxm6rbsxebb+HN6pGYLeHULuHZKuTSK6BSxtMrbGOIZjQQz1UZzDFfz+TQKpi6QLVwnZ1lCcDuDoy2E8EUR5wIfQkyHoXcfm3yC+dI189W60I0WEkRLWdpmxOzzoGmLEvBsYPYvYUpukt76J0TKPSTeDRzXL+PEwikM+vNpZrMFljMFFAtWz2DKb6J0L2C0LGPqKqOqjmHoyWOwz6P2zSOF53Pl1TMk1LO5ldOMVTGNlrAN5TKoiWmcZs7vKuCGOJb+KJraEbmoGu7iCpJnZzW7WFxDsZSRnBZO7zLg8j9Y6i8+/iS+4g05RZlKXRXTM4HDVMFmKjLqLqF2z+JJniacvI1kWUU0WsLnnsHlmcHhnGVYnUdpKhDPniGQu4gtuMTlexOtexuOYw26bYXgszqgqTUg+S0Q+jy9+Do1+FtFUxWaq4RTnUA6nGOlNIJnnCIU2CYa2MYsreKRVUqFNfNYFNINZxvtlzEM5vNZFnKZ5HNIqYdcWsncbv3Ee82AOdU8ac4+MfaKKWzOLTTNLwLRM0raOd7yGpSeHsTuH0J/F3JZEGCzimZwlqF/EM1LB1V9A7MhiapWx9+V3j16bEnhGKpg64zh7cljqwjja00hdGaT2NLaONNam3fhE/3AJc10E4/EglpNhhIY4np4cjrY0UmsCX28WS10Y84kgxsM+dAfdWE6EEBsiuDqSOFpTuLtS2Jpi6Pe7sdzpR7/fheGQB2dTDOlUBG+njKs1gVi3K9WmO/1ov277WKLdLQk8rUkcbTEMh5xYj/uw3OnBeNCD+jYb2m/YsRzz4WqOEenPEh7IEhnME+7PEOxNE+qRd+PserNUxSXm3Otsxs6xEdthNbpDVJllybvFvHOd6ESaexcf5LmHb7CzdJ4n73mWRy89yaOXnuK5h77LdHCe+7ce4ermffzjL/6R9/7pvf8QZ/fII4/w8ssvf6Ig//KXv+SFF174L4tWfve73YPEvUPCW8ut9qY99ti3b9+eQH/a+L1Av//++/8tgX7n7XfYTF7A0xZj4osW+j4zxcBnNai/KhEezHC+cIU3f/xzrq0+hDxRxXI8gPKLAoN/pWPyywLSqRBF/Sz3rTzAk/c+w5xjDXdHAtOdfpS32Zj4ooDxiA9ve5I5zxpb6UtsJS+RmqjhbJNRH/ChPeJDf8CNvytNXFEkr5/F1hakYFkgOFzEfDqOtTmJ9XRsdy2jWyapKOFqjhMdK+Lry+MZLCD1FPGPzyK2Z4hP1HB3phBPhbG3RHG2yzh6ctiGa8RsZ/BOLRBWzeEeLGE6HsB6PID+WAB7dwZxuEjAs0XYf5aUcwPP5AzmphiWEyEmv+HGWB/FOVbGLiwTSF4kU7obh26BibYY3r48E193Mb7fg324iGCZQ3AtU9x8EIdnA6N2joBpEUN9lOHb7AidMjbTLDpzlUDpHPH5Kxhdy7hcq0hjVUYP+dE2RHEZZ5gylBA88wTnzmPJbyHENnGLK6g7s0w1RBFHC0xpcpikKp7QIva5bXTFDayuRUzaGcwjZUyDBbTGIiahguisoHZnUc+sYwgtYxIXcNjWMI6VUWsKCK4Z3KEFJO802uoy6vg8on+FQOYcgmmeCUUewTFNKLaG0zmDyl5gJFzFkT5DpHQRR2gD5WQJizBLMHGGYHiNSW2GXnUCW2QJf+4sIfkck4YaFmGeeHKHYOQMRlOZ/oEogn0ap3MJb3QTvWMRUVjE61rGY19EMEwz1JdAo8jgcC/hsi2g0U0jiavI4fMkfVtIk1UUIxkm2+KIqjI2fQ2jdhpRO03MfoaYYwNhuMBUXwZtv4y+M4moKGEaKuIxLuGbmsGnnEbqL2DozmLqy2DqkDG2y4iDRdwTNVxDJWztacS2NJbODLbBPGJ3BuPpBNa2FO6RCuqTfkwnwlhOx7G0yLtNhV05rI2J3V3ozjTmugjCyQiWY2HMdREc3WmkFhmpOYG7a/fQ0FwXRneHG6EuiHa/G2t9GFd3GntLAl9/FldbEuuxEEJdEM03HBiOeDAc9CA0RPB0yHjak3g7U4j1QYQ7d1c0jAddGA96sBz34+1M4u+WsZ7wYjrixt0ax/gNB+KpMOqv2rGdDuNqThIfK+DrTJEcK+BujhMfLuBuihHskfG2JymbFqkJy2ymLrIe3WE7fRclwxypqQKzzjXO5e4ibS5x78oDPHrpSaaDCzxy7h944fqLu0kcV55hMbXG0w8/x0NXH+Hmiz/mRy/9hJ+++ga//eC3H79F/u53v/uJgvzWW2/x4osvfizH/+/57+PrPvroo71DwlvMrfamPfbYt2/fnkB/Grn99tv/Pwv0H3ru3X96l0vT1/B2Jpn8e4GBz6rp+6yKqS8LBDqTXCjdzS/+9y956NxjFI1zSPUhJr8oMPAXWia+JGI9EUBW1ThfuYeHzj3OgncDX3cawyEPY1+2ovySgOmQB1dzjGnbMrOOVZZ8W0SHS9hbEmgPetAf9qM/6MPeGCMylCM+UsTeFiAykMXXm0V/Ioy9I4O5LoqzO42zLYG/O439VGT3q+nWJEJHGlt/Be9oDc9QEf9IGcuJENKpCFJDCKFhNz3DNTVHyLqOZ2KWmGEJsSOL+VgA84kg5hMhLA1RLIMFwr6zRP07xB2b2MZrOHuyGO8MMHmHC/OpKOJQAcE4R1C+SDp/FzbjIrpBGaEtieJrDtR3BnAMF9GOFXCHNshv34/k38TmWCVuW2XicADFHV6kngx6ZQHtVJHahYdwVy5iiW8Q9G9g7M2iOBLE3l9AM5ZDNZnFm1wnvHUVQ2Ubb/Y8Ju0MqtYkpt40BlWRKV0el2+BwPxZTGs7WKd3kNxLCNYFdAMFTBNlplQFPMFFApEFRrMVNPNrWEPLuGKbCNY5NONFdMYy7sAS3tAi5uA0yuw0lsQy7sJZHKFVJicr6PQ1ApF1grF1BHuFYXcWo7+GN7WOK7eFxjKDSl0lGNsinjyL0z3P4HgUraeMFFrAGVpE711iUjtDPLZDJHGWYGiTvp4IEwoZi1DBHlxEq68xZZghEj6Hz7mMZKwxqsgw3B7GZCwhGaqotUVUyjIB9wbZ2AVcunlUQzkUnSm0fQms2io6RQHdeAWXZo6E4wwO5Qy64SKawRy6ziSGzhSargS2qRrSSAn3SAXnWBVLXxHjYBFTdwZjRwJtUxxrTwb7YBGpI43UlsI5WME2UEToyWJuTmJukZF68liaEyj3O7HURbG1yjj6iru70s1xhNYUzq40jo4MpuMh9Ef8mOtCeAeK2DsyiE0J7B0pPN0ZpMY45uNBpIYI+oM+PJ1pbM0JpOY4/r40tsYYnm5597N8pw/LsQCWowGcLXFc/95W6OuWcbbGsZ8OY2sIYzzixXrCj+GQB19HCldLnGB/BsspL7b6IMLxII7GMKbDHszHPAgndg9tnY1RfF1JfJ0pfB0JfP+e8BEdzJMcLVI2L1C1LlK1LjFjX2XRu0FZXCCuyrPo2eRC6W4qrnkuzl7l2srDlFwzfGvtYR7afoxvP3SDZ649x9Xte3n4ynUuzl3he4+/xM9ee4OfvPIzfvnmO3z00Uc899xzfzDG7s033+SVV175WI4/SaB///PeIeGt5VZ70x577Nu3b0+gP43cfvvtvPfee39UoB9//HHefffdT34D/YtfcbF8lWCXzNRtNvo/M0Xvn6mY+KKApyPFevwsr7/8I66tPUhGVcVyNMDEF6wMfFaD4nMmrEe9pJQVzhWusJO/ixlpGV9Hiqn9Lsa+YEX5FRHtHS6crXFKxnlKxnkKunmCvRmsp6Ko93vRHPRiPBbActRPdCiPryOFvSOEszWGuyuFoS6MozuH4WQET28WsSGKozGGtz2Br0vG3hzF1JTENzmL1F8koKjh6toVY/upCFJjFNvpCIb6KF7dEj7dMn7NAhHzEkJzArE+gu6QF2tdGP2xIMJ4jYB7i5B7m7BjE7d2AU9fHs1hH9oDHqz1YbRtSZyONdLlq0TkCzhsa1gVWUz1ESb2+7A2RDD1Z5gayhKtXEZe/SZSfJtY6gKOsTLKO4MY6+PYFSVUQ1mcrkXyVx/BPn8RZ/E8Yd8mqrYUurYUwkCeKUUO/VSR/No9eC7ci7hyEVdiE7NuGm1fDruyhnoyh0FTxOGYw7d+Acv2eTzVHWzRNQyaGgZFCc14Hou1hluaxR5dYFDOY84s4S1t4Eiso56sMDVZwWqexedbRjJV0Ofn0CWrCKE5XPkz6B3zKFVVHK5VQoltHNIsCm0KpT2DLTKL6J/GEphnZKqM07tOMnWOYGSLseEYA+ooJkcRyTONwVljWFfC7T5DLHmBaHSHCWWWvlYval0Ws6OK3lBkSJnF4TxDMnoBp22Z8fEcAz1RVL0xDBM5dOoCY8NpzFMzpELnCNnPYJ6YRjmWRdMvoxmSUfUmUQ2mMY6W8GrmCVpWEVVzGJUVDINZDL0ymq4U6q4U+p4M9oEiHkUN+1gNSTWLTVHF0C6jbYoh9GcxdWUQ23b/YXIMlXGMTeObmsPaIWNoSSJ2prB0yDh6MijvsCF2pvEpZghNzmJpTmFtSuLszmDrkhGb4lhOhbGejuHszxNUTCO2phGaEvh68tjakrjaZMS6MNaTYVxdaVydaaTGGN7uNI6WOO6uNPbGOO6OFJbjfqTTERzNMcx3+nC1xnE1x3C1JQh0Z5DqI9gaIlhOBLDc6cNyIoB4KoytLoi7NYbphBdPZxJbfQRnYwT9fheWO/2Yj/pxNUURj/vxd8m4WxNE+jK4WxMkFGWigzlkZYXUeJmiaYGMqkrZukxNXGXGuUJ8Ms+Vmfu4VL6HpfAmFccil0r3kDIUeGj7UR6//DRP3fsdXn3hh3zz3AOcnT7PXSv38uIT/4sbj36fn7z6Bm/9ZDdZ48aNGzz22GN/sInwtdde4+bNm9y8efO/FOi9Q8Jby632pj322Ldv355Afxo5dOgQv/jFL/6oQD/55JP8+te//sTZ22+8zXbmEp72JJNfFOj9cxVdfzKB8gtm3C1xloNbfOehF7g8fQ+JsSLmI14UnzfR9+caRv7aiPGgh5SizJZ8iSX/JhXrEr7ONJpvOBn9nImJr4iov+rA1hglo6pRNM6R1U6TGC1iPRVBfcCN7qAX41E/ujtcu/XAHSlc3WHszXH8A7vibG1NYamPY29OYjkRwtEQJTKQRaqP4GpLYW2T8U/OIXTmCUzO7KYdNMUQTwYR6oJYT4QxtaYJGZfxaZYIW9YJ6haxdaVxtCTRH/Yh1IXR10dxmZYIOTYJe84S8e8QEVZx9+RQH/ZhPRVBaIlj6M/g928g1+7Bn7hAOHkRy0iGqRNhdMfD2LtkVG1JTKoqpc0HCcxdxT99hUz+LnQdadQNcTwjJXTdMpNtcQKpLcJb92Ffu5vi9oPYLAto+rII/XmMgzkm2mM4DDVCc+cxLmwTPH8vvvQGBn0No6KMeazMRF8Kw2iWQHQN0+IZhJkz2PPrCKEVprQVDMoyenUVyTCNZbKAMTXLUDiDNVTDmV9Ba5tBpaminazhD51BnKpgsGaZDGUxeHKI4SqW2BxjpjJG/Ty+4BZ+3zpTwylGzHFMrhx6Wxaju8SwsYjBMk8idYFI/Bxmc5neTh9qXQqzVMAg5OlXJtCYZ4kmL5JMXMbmWKavN4pmMoVWk0GvzdA/GmNiskA0dI5U6hJmwzQDwynUozImfRH1qMxIZ5jxoTQ+cYVkcAePuIZWP4tRUcSszKMdTDHeGWaiN4llsEDUs4XPuopZv4BVPYNNWULXm2GqPYauP4u5O4NvcgafYQm3cRm3bh5ptISuOY6lJ42hS8bSlcY1XMA1WsarXiBoXMI5WsHYFEdsTyF0Z5A6s9jaUqiOe/GMVAmpF/AOV7E2p7B3ZpFaU4htMp7ePGJzAlunTGisitSWRGxM4u5M42hP42yXsTXFcbXLODtlXJ1prKcjWE+GcbTEsDclsDcl8PdmkE5H8fWmsZ2OYrzTi60xguXYbkSkuy2FozFGqC+DozGCszmB5utOhOMhrMeCSKcCSKeCWE56EU76cbfGMB7xYD7iR3/AiXQyiPmoF1t9GHt9mEB3Gm9ngnD/bgNhdDhHuD9HcrxMUlEhpShT0M0x51hnxr3KTGCN8/m72cneRck8j6wtsZ26RE6scmX6Gk/e8yw/+N7rvPTUK1zbeIDN2g6b2fM8//ANnnv4e7z63A/5p3fe5aOPPuLFF1/kwQcf/ESBfv3117l58ybvvPMOL7zwwn8p0B9++OFeI+Et5FZ70x577Nu3b0+gP43U19fz+uuv/1GBfvrpp/nlL3/5ibM3X3+TM/Ed/F0yk1+R6P3TSbr+h5Lxz5lxNEZZCmzw0PajXJ69RlpVRTgeQPF5M/2f1TL0F1r0d7iIjeRZDW+z6NtgxrZCsDeD7rCXsc9ZUHzJiurvRaT60O6bKeM8WU2VtKqGUB9j6pAHzf7dKm/jER++TplwXwbxtJ9Ar4y3N4e1KYGlMYn939sIXa1JvK1JQv1ZpFNBAv053AMlvIpppJ4iYc0i9nYZb2cWZ2sSe2NsNwpstELIvIJLNU9IOENAt0hguIS9JYn5uB/H6Rjm1iQ+0yIB+wbhwA7BwA6y/QyOnhyGk2HsTTH0dSHM/TmCgS1ChbvwZy5RnrmGsTeBpiGGoyO9+9V9XQCXfoZ4+RL22l1El+8jnb2IujuNdaCA1J1h7ESQqW6ZVPEiltwm3jNXSS7ejV5bQz1cwDleYaI1gbI+hMs+j1A4g6myRmD+HGJ4EbWmiklZQTdURNWZQhgvIiUW0GfnsCTnEFIL6NwzaA3TqBVFLJoZ9ANZrKYSGrnCqCmINVhCF5pG6ayhmazitK/jcayiHUwzaY2jc6aRAkXMrhwKZxGlrorDuUEscQFJP4NCEUFnjGOxZxG9eUY1McbMBfzRswRTF/GHNhkaiKM2pBAsOYzmNEOKCH3jKQLxsyTly4QTl1BMFplQpjCLZcy6HCODYXo6Qzidq8QyF4knLjKuKzM6LCNZaliMZcb6owz0xjFrqoSDOyTly5ilFUyGWayTRSRdFWVXlLGeBPrhHAHbEqnwOQRhBcm6hFM7g6AsoW5PoBnIou2SsQ0XCYpLuPRLeKR1PJo5xKEi5u40ht40lt4cUl8Wx0ABp3IGn3Yer3oOqTuH1JFG6M4idmSw9eYQOtPomsIEVLO4B0sILQlsHWmkVhl7VwZHVxqxNYWzM01YOY2zO4e1IYLlZAhnx+4OtL0thaM1hbMjjbsng7UhguGID7ExgvGYH2dHCmd7CntzAm93BqkpivGQD+NRH4aDHmz1ESzHfHg6d59ztSWwnY6g/rod42EPhoNujAfdSHVhTIe9WE66sRz1YznuR/cNJ/rDTnRfk7Ae9WE44MJ+OoTlqJ9gTxpva5z0RJVgd5qUooSvM0VspIC/RyajqlHQzXI2c5mF4Do19yJL3k3OxM4zY1shPJFmRlohK1Z4/Moz3Hzxx3zv8Zd46p5vc9/qgyyklrlv6wGuX3iCp7/5PL98852Pd5dv3LjB9evX+eCDD/6TIL/22mv85Cc/4Xe/+91/ekv9++SN/+fv9g4Jbx232pv22GPfvn17Av1ppKurixdffPGPCvS3v/1t3n777U+cvfH6z7lYukqoR0b19yK9fzZF5/8YZ+RvjNgaQlTFFe7feoSHd66TM0wjHg8w/nkrfX+hYfCvdOjucOHvlFnyb7KTu8Ssa41AXxr9ES/KL4sovySg+nsJZ1OMxFiJadsqZeM8qckKYkMM0/Eg6oM+TEcDmI76CfZlKRrnEU/7SIwXcfVkcfbmMJ6K4ezJYTweJDiQJzSYJ9iVxt0UI6woExifRurO4x6t4VVM4+zKEVPWcLUlEE8EEU9H8I/P4FXN4dIuErFvEdItElXNIraksJ2OIdSFMDYncSmnCfm2CYYuEPbvEBPWkHoLSE1xxIYIqiN+hIEcPnEZj3yBUP4uiuV7ULZG0LfLuDtlFAe9TBwPERCXESMb2ArnqV14GMm0gHo4h324hOp4gNGDbuzKKu7IGrrYCuH1K9gT60yqypgnK1gHCowe8qJrT+INrqCNzyOlV5HSK2g9c0waypgVNTR9OXStCYTJImpfCX2iitVVRMguMuWdRaOtoVFUEKemMQ1k0FuyqJ0ZJowhrP4imtQcKqGCST+LJ7CFaayCeiqNxphCcmQQbWnUzgwj7iJ6YZ6ofAGfb5MJhcyUKYlFymCzZ9Ea4vSZk1h8y/hS54nKl1DraoxPydg9FSy2AgZrf8sihwAAIABJREFUlo6xAFb/MrHCRcKZC5jdayiUWSTXDJK1glaTpaM/gMpUJlK8RDR9AUf8LKOTeQyaAjb7HAZljsH+MBMjMnb7EuHEWdzBbayudSTTLG5pAZMii2IgycRIGlFRwCssIRjmcQe2cFtW8OjnMA3l0fammepNY+rL4lDXkKZmcVuW8ZtWCOjnsPblMPdmMQ5ksfZmMHcmEYfLRMzL+HXz2LoLOHoLWDqymDsz2PtzSF0ypqYkutYYvvEqQmsK04kItvY0ts4Mto40YmcaW7u8+znvzqI/FsR4PIz55G5lvKc3i601ibM9ja8vi+6ID/0hH4YjPgyHfVjrwkiNcZwdSdxdaWzNMfSH/UzdZkO3343+oBvDQTdSQwRbQwxv125GtP6gB/0hF+qv7qZrGA640e534m6Lozlkx94YwXjYi/lOL7qvOzAedKP+qg3dHS6Mh9w4m2IEujPEhwuE+rJEBrKEe2VCfRm8HSkC3TJZ9QxL/i2205eZ861StS2w6Ntk3r3Bkn+b4EicC5WrrBY3+eGLr/PMN5/niStP88j5J3jh0e9TdFW5Z/1+Xrj+PX719q/54De/5cMPP/x4B/o73/kOb7311n8S6FdeeYU33njjYzn+/d989NFHfPDBBzzxxBP/4fm9Q8Jbx632pj322Ldv355AfxoZHR3l6aef/qMC/fzzz/Pzn//8k3eg33qHe5buJzKQRf0NO32fnaLr/1Ay9jdG7HVBarYVnrr3GZ6492lKhnmEk2HGv2Bl8K91DP+1Ef0dTsIDWTaS53lg8xEWPBsEetIYj/qY+poTxRcsqL9mx9USQ56osRzcYkZcJqeZxdmRwnAiiOagF90BL8LJCKGBNCXTPNY6LylVFf9AAXdvHv2JKI7uPJa6CKG+HKG+HP72JN7OJN6BAr6xCubOHAH1Io6+EoHhMv7+AsKp3UNCe3MCR18O+1AZj3GVkO0MPtUcYdUslsYo1pMhtId9GJqiSP05XPZ1AoFzJMMXCZuXMXVksTZE0R72MLHfg6Uzg0tYwhnZIla9m1j0HCNNYYTBHLo7/Yzd7kDXFMNnW8Jgm8NbvEBu7RpTkxX0EyXs/QVGv+5m/IAHv3EOrXMWjXOayMplzMEVtMIsLsMck00JRg54EQeyGO01NO4q1sAMUnUdVXgRi2Me7UiJqXYZbWca41QelZjF6ihiC1XRl1fRRObQqqpYNPNYxkroxzOoxTRme5YJlRdrZhp1cQGNdRrJtYZDWEE3mkdtzuLwl3H6SpicaRSZMmpXDV9iG7+8g043jUKdweYs4w1OI9rzDFnjjIerONPbxEuXkfxrjE7mcfgWsHlncLqrDCiCjBhTePNbeHI7uBLbjOuqeAKreLyLSI4ZhibiDAxHsbnm8fjXcCY2UTsWMZtqOFzz2C0zKEeTDA3F0Spz2N2LSOICRtsiHs8ZEuEtHNZ51KNZRofSqLsSiNoqVtMMVssCDvMCcccWbt0c5qEik0M5jANZTD0yppEi4mQVj2kJ9/g09qES1oEcuu4s1v48pi4ZfUcK+3gV13gNqTeHtSWJuVXG0p1DGiwgdKYxNMWRujJomiKYGmJoj/gxnYphbZWRunLYurMILSls3Rksp+PoDvl32zkPejDWRXB2ZRBPJ3ZFui+DuS6I7qCXqa850B/yoD3gxnQyhLtLxtmWwtMpY60LYTjkxXIsiOorEtr9TgwH3Aj1Yfx9GZxtSYRTIUxHvBgPe3bF+DY7ujtcWI4HcLXHMJ70YD0RQDjmR6oLofu6A/1+F1O3i4gnAthORYgPFwn1pImNFPC1x4mPlXA1xQj0pvG0JCibF6mIS+xkLrMtX2bavYQ8VWY1uMOstMpW8jJ5ocZdS/dyprTJ9QtP8tDZx/nuo9/noa1HefzSU8wllnnk7sd48/Wf86OXf8qPXv4pP/vBm/z2g9/y7LPP8uqrr/Laa6/9J4F+8cUXPxbr559/nnfeeefj2XvvvcczzzzzH57//a703iHh///cam/aY499+/btCfSnEa1Wy0MPPfRHBfrGjRv87Gc/+8TZe++9x0M7jxEdyqP5mo3Bv9DS86eTjP6tAbEuSM22zI0nvs93H/8+ZdM8tlMhJm6TGP6fBob+px7tHU58XSkWvWf4h6tPsxrdITSUQzgVRPU1ibHPW9B9w4lUHyahKDPrWGHWvkrOMIe7S0Z/NIDusB/NAQ9SYxRHU5zM1DRCvZfIaA5/fw5bewbD/8Xemz3JdZb5uvoT9uZ07H3Oadj03pzd0LZlW5ZKqpJUUk1SSap5zKrKyjlzTTmtnOd5nmqepdI8eZJnwMbGyNjGAoMNGNwGTGM3biAMbRpj7I7uiOdcFOY0YMJ3OE5TT0Te1LcirypWPPHl731/nVk8A2UcXRlCg2Wig0XU9gShvjy+4wX8wxUcA3WiljU8A3VSxiW8JwrIB0K4DkZwtCVxHy9gH66T8F4gomyStG4Q1i8iHIggNocw7vLj6E6j9BbxqpskUlfIJ64SsC4j9xVxtieZvkXFuC+MOlhGNs2gRs9TWn2YoGcT7VCe0PQcxqYgmltU7Cfy2K3z2GyzZDauEahexuZYI6xu4ByoMH6rH+uhJE5jA72lgiu6RubsPdgymzgTp/DaVtC1xjG2JfEaGuiNRST3LP7qJo7ViwjVU3j8G5gnGph7i9g1NWxKDcUzQyCygHdtE8v6Jkp8HcWxiltexTZWxWwpo3gaBGPzmF1pxM0NhPIqUmidQOo8knUBo6mGMzBPJLGM11/HkqxiyNVRc6cIzV7CFTrJtGFrjV2mfJpAdBmTlEHjzuCKLBGfu0SwcgGdOI/iXiKaO0M8t4lFLDI8FcUdn8cZWSaQPcW0fxl74CSZ/CVihfNIrjkGhqNYhTJqcBlPfA2jPI9d3cAf2iDkX8dhm2Ncl2d6MIlin8Mlz2OS55GkJZLh82Si55F1M0xrSxiGcojjRWTzDFZdA7u0SEhYJSSsYp+YwTxZRZpqYBvMY+5NI2qqqNYF1Mk5HANVnMN1rENVlMkG9pEytt4scn8Jt6aOY7CC2JFC6kijDFZwj9ZxDlSQjudwDZZxDVaY2utFPpREao0hdqZQB2r4hmvYTxRw9xbx9BZROtIIzWGEljDWfVFcx7aiHt7eIv6BMv7eInLr1g5opTWK5Y7g1t7y7iy+3gKx8RreYzncXSnk/RGkvSGUgxHMd/jwH8sR6isRGigS6ingao3hbotjPxjBttuPbV8AqTlMsDeP/0QO+VAAR2sYR2sUocmH0ORF/xkF6x4v1r0e1M4I0kE/alcER3sQ5XAAeb8PYb8H+ZAf9/EowcEEsckcCU2OteBZysI8NWmRFe9pNiLnuFy+l5Pps1ycucJifIP7Vx7h8+ee4NFzT/C1J17k+rVnubBymScf+RJfeeRrvPjll/jRy6/xD999jR+/+gZPP/00b7zxxgeWpXz961//3faNV155he9///u/V7Jy48aN33t+e5Dwo+Oj9qZtttmxY8e2QP8l4vF4uHbt2ocK9De/+U1effXVP3l+/f5nKermEJv8aD4pMPTfjGg+KeI4EKImLfPsZ7/Kjce/wYr/NMFjWcy3eRn7uBXNpwQsu7yEenKsR85w3+rDnEpcJDlWxX4ojmHnVpGK5XYPrkOxraEi2zIz0hIpTQ1/TwFrcwTb/hjCvijujhSeI0lSYxXsh0MEetME+orInRkcxwvYj+Tw9ZfwHsvhOZLeKnU4nsHRmsDVncM51CBsWsE3UiehX0JpTSA3h3C0xlAOxRAORHFMzJL0niMorJNWTuEZbSC3RpFbIpibggitUYRjOYL+sySSV0gGL+KxrBCankM5nGD6Fg/m5hD2/gK2yRrh/GWqKw+jejax6moEJmeYviPI9B1B1N4CxvECkn2J2t2PoeYv4oifIRU8h7E9xVRTBM9oGetUBaO2ROHUNQKn70GqnCOYu4DTMM/U4QT2oTI2bRW9uYoaWSF7533YNi7gXbyErK5i1tSwDZVRTLMYTSU8vnmC+TWk06eRT53BHTuJK3QSq7aBVd/AItQIxtcI+ufQBtMYa7Mo2WUClbOo0ZPoDQ2s0iyB8Drh2CoOtYIxW8KeqOMpruEtbaKX5jBLc8QL50kUzuBy1RiXYtjjNUKFNTyJJUz+JfTiItH0WfLVqwTiJxkZCWO2p1F8dXzJJQzuOjr7EqnsZeK5K/hDJxmbzKAZjiE7ayi+WfRClWnLDMnkJYK+DZzyAhpLBc1IGpMmjyTU0ZnKGPQ13MIK+cQl3MYljNo6k+N5LOM5rJoCutEcNtMMTt0c3ul5PPolbJMzWKaqWIaKiGMFLP0ZhLEyymgNR28B12ANZXwWu34eRVND6Mli68ni1NRReouIHWnkjgyOoRqqZhbnaAO5J49roIRzoIyzt4i+JYjtQBSlK0twch7fUB25O4+rt4RvpIKn57dyfCiO1BrHN1jC01/C01fB21siMFhG7c7i7EgiH4ghHIjgPZLF3pbAfTxNeLiCeiSNqzuJsC+I/VAES5MX4y4Va7Mfy14f9rYo4uEg4gEv1v0+pnc6MO5yMX2zwtSnZYy7nZjvcGHdq2Le58a2T0U+EMS824Pxdjf6nQ6EfV7kliDO9ijOQxECx9N4ulLERgr4jqRITTVIj9cpGuaoWhaYd27gORFj3n2KtLbKnLrOovsU9849yH2rn+VM4TIVZZ453wpXKtd4ePMxvnT30zx17St888svcc+5a1xduZunH3yOF596iW988UVee+V1fvjSj7h+/Tpvv/32B5alfPWrX+XNN9/kvffe4yc/+cnv7Yv+2c9+9kf7o9/PSm8PEv75+ai9aZttduzYsS3Qf4kkEgkuXrz4oQL90ksv8b3vfe9Pnj92+Qly2hlsu/2Mf0Kg///QMfFJAcf+EFXLIk/c/WUeu/wk864NPF0pDLd6Gfu4Dc0nBcw73YROZFnyneRM5jKL6gaR/iJicxjtzW6mP+PEcIsbx4EoWe0sOd0MJd0s4YEC3u6tNXbC/hjCvq1Mp9qVwt+dwdMdw9kRxXs8h3A4hae/gtyRITRaRzkUx3k4iqczSaA7g6stjtKVxT85j3dyHr9mjqh+EXtbAuXgb2/jWiPYDkTwGpaI2DcJixukXWdQR+uonWls+7Z+EhdawggDJWKhCySSl0lGLuJ3nCSsncV2IIZxdwB7WwJbTx7FtkB25l6SM9dQY+dxORZRThTQNYWQDyVwjJTRD+XwZc9RufoorsYVguUrBJ3r6A4nsHVlUEeraIdziPo6hYsP4j53DdfKVaK5C5jHKlj7ijjG6pi0VcyaArHkBp5TFxHPnMddP4vdv4ZxqobDMIt5qoLVVMUlzRBc2ERc3UCtrqFWNpG9KxgNM1iNMzhcS3js8zgcNaYKaeTKDL7UEoHqJhZ5AZ1lFqdrhUT6NE5rDSlSQIrl8aTquJMzCPFltLYZ/OEzhNPnCUc20GuimD0pfNEKrkAZ0V9jXKwTjJ+jUL2beO4iOmMazYgP2ZlHDdUQXWVG9UW8kTMk81dJpC9hEmuMDkcwTKewiEXMYomx6RyKtEgmcydu9yp6Y50JbRGDJoPNWESnyaAZy2KdrhFVTxNRN1HENQzWGWwTRcyaItNDafSjWcwjBRyjdfziGi7zEoq4ijw9i3W4gLE3g22sjDhWwTFQxD1Ywa1bRJXW8RgXEfpLmI+nsWsqiAMlnEMVlOMF3CN1vKYVQpZVpJ7iVlPhQAlXfxlXTwHdHi/27jyBiVn8k/NIRzLYj2dx9hSQulLIXUlsrRHM+4II7QnkIymM+8NYD4URWiPYDoewHAiiv8ODbo8H0z4/+j0edLs9mJu8CAdDSAfDKIci2A/HMO/xIewPYN7nw7zHh+tIErEliNqZINCTQ+1MEuotoBzYGhS07vbjOBjG3ZFEbY9jvMNNdLiEuz2J2rZVyuI6FEfa7UM9HMfZGsXblcTTniA6sLUDOjlcIjVRoaifJTVRp2CaJ6ut4+tLktfNkLfMMOda497FR7h77iEu166xqJ4iYypTcyxw/8rnuFK9xtMPPsfLz3+PV77xAzZrFzg3e4lHNh/nq194ged/u4njxz/8p99tzvigspRnn32Wt956i/fee49f//rXvzc0+H7Jyh9K9/Yg4UfDR+1N22yzY8eObYH+S6RSqbC2tvahAv1+VvCDzt566y0eOv0omYkall1ehv/aTN/Hphn9hBV7c4iKeYEHT36ee5YeoiavoHbFMdzkZPSvrYx8woLhFheBY1nmnRvMu9ZZ9J0kOVZFbomiu8n1248TqSlAarxCWlMhb5glPVHD25PHvDe8dQPdEkVqCaN2pVA7koT60kj7gyTHasgdadSBCnJXhuBoHelQFO/RNN6uNO62GK6OBPaeEhHDCq7hBjHTKkHNLGpXGndHEmdbHEd7HKkjRci2RljcIOY8TcJ1huDkDL7eApamEMrBKHJbDNf0LFH/OZKpq8STd5IMXiA4MYe1NY50KI69M4XpaBq3tEJ+6QHC1XuIVe/FJy9g6khjPpTEP1zC0JXC0JMmU7xMeP0a/rVrFDceRJ5qYDieQx2sYO1No+2I4XUsE168grR0nuzVh3FHN7Boa9jHayhTdbTHk8hTRYLFTYTVTdSVc4TnziH5lrAYZhAm6pimKljHCriVORz1JezzKyipOdTyGkb7LBbzHFbTHKp7FVGTxx6vMBWOooZKeFMNhOgc0/IsVtsiscxFfOoa5skEFm8MVzCD6s/jipSZcjUQnGuEkhdIFa5iM5WYmvLiciaxu9PYvXkmbBms6jK56r1E8ldxeZYZHw4jyWmcchbBlmJ0MoreViNRuItC+V7coU2m9HmsxjyCo4RZn2ZoOIx2skAofJZM6W5EYYFxaxWrsYwsVNFP5xgbijM5kcdrXSCVuIzXdwaLcwXRPItirmPSFNANp9GPFpA0VSLuTfyOk9hdJ3HKy7h0s5gHMpiH81jGSoj9RVRNHdUwj1daxSOuokzWMB5LYuvLYu7JYO3LIh3PYO5MYhssIY9XMfdkmD4QxNgeYbotgvFwBHNbhKlmH+aOOLYTOYyHIhgOhrB1JhDaE0hdCaTOBMLhGFJnCndvFuFwAltrGHtbAv9AEfV4Hl9PiUDf1sfVmUY4GEc5HMfdkUJpjePvyeM9nsd3Ik+wv4DSFkdsCuE4FENqDuE+ksZ+IEqgL0egJ4/akcDVltjaxLE/jNIcRm4O4etOo7/FTuBEDseBKPK+rSpvqSmAsMeP/WAEaW8Q/9EUSkv4t5s4chTN8yTHKmSnG0T6imQm6sQGS8Q1RVKaCg33IpvpC9w9/wCn05c4k7rCovsksakCeWONq7VrPHbxi3z/m6/y0nMv88xDN1jNnmY1f4rnPv91Hrv4JF9+8Dm+/80f8s6v3/ndzfMHlaV8+ctf5le/+tXvra17f5Dwtdde46WXXvojgX7/e1566SV+8YtffNSv9r8YPmpv2mabHTt2bAv0XyLLy8s0Go0PFehXXnmF73znOx949vM3f8EDq58lN11HbAow+gkbJ/7LFMP/lwlhj5+8bo4rtXu5f/URFjwn8R9PY9qpMvJxK2OfsKL/jANvZ5KyZYFF9wYb0XOkx6soB6NM3+xC93dbEi3tCxHpLVDQz1IyzlI2zOM7kUM8GMPaFMXelkTYGyJ4Ikekv0B4MIvjcJTkZB3X8SKu3iL27uJWQ9uRDIGerdph9+E4vuN5/KMzRA3LuIbrJIR11MEK4aEKnmOZrRKI/VFcPQVi8kmCtjUirrPE3GdI6Bfx9RUR90dxHo5hPRjHqZkh5DpNPHWFeOoq2eRlgto5rG0pXF0phNYYpo4UHtsCkfxlAo07Kaw+hMs8g+FoGnWkir0rzdT+EOJoiXT1KnLxLMFT91Fdux/zWBVhtIJntIruYBhdW5xo9BRycRN55gzxU3cjqcsYdDVc2gbGviLTrRFU8xyu0jqW4hLeyjpKYRmTawGraRarZqtRT+rP4/LMIBXrSPEK9kgZIT6PSZ3Fop/HoaxiN80jTeaRQxn0Vh/uaB7FV8QYmcFgncPrP0sscQFhqoxVjKM4YgTVLKo7ic6RYspRxxs9T7pyJ17fBrqJKA5XEtWexOPMoDNEGJfyRIpXCOevEi1cQavPIYoZgv4Kij3DtC7C0FSMUPYcuZn7iJbvYlqZw2Ao4PA1cDqrTGpijEwmcXqXiZaukindxaRjAZ25hkOaxa7MMDkcZ3wig01bwefZIJy8gOhZx+ZcRjbWsGpLaE5EGBmOMzWYwTKax25uYNDXsQizmCcKaHtiaI5EmDgWQXMkhO5YHNNQCuNoCbOmik1TxNSTxnwsjbk3jbk3i607ja07gzJRw2tawDFWQ+zKoA6VsfcWcA5W8IzWsPcUMXbECU7Pow7VUY5kkDtSuHqLuPvKqL1FXL15fKNVvANVHEeziK0xlLYEjsNJ1J48gYGtCIevr7IVe9obRmyJIDVHkFsjODoSuLuyBPq2au7tHQlsTUEst/kQ9wWR94eQmkN4OpN4jmTwdWeRWyKYdnuR9wUw3+ZB2htEbg4j7g1g3qsiNodwtUax7vYh7wsgNPmR9gWw3OpBaQkh7vHjP5Yh3JenqF8gMVomPVElNVomPlwkfCJHfLBIbKhAWZpjxrvC+eJVzuXuZCNygRXfaU4nrhAdz9LwLPHFu57iey++yteeeIGn7nuWL1y+zsXFK8xHV7l+3zM888ANXv/+P/7utvl9gf6gspQ/3Lxx48aN30U63i9Z+UOBfv97vva1r/Hmm29+1K/2vxg+am/aZpsdO3ZsC/RfIufOnSObzX6oQP/gBz/gW9/61geevfmzn/OFy09SMS8iNQUY+4SNvv+qY/SvLdju8JHR1Lhz5j6evO9pVnybBHsyGG9zM/5JkbH/YcN0q4vA8TQN+xpnMpc5Fb9IZqqBvS2KcaeK/mYPxpvdKPujJIaLLLhPUjHPU7Mt4TuWw9mVwdQcQT6cwLY7SHSwRHKsivdYAk9XlPh4Hf9ABfvRAu6BKq7uPMG+ItHBMqGePPaWEMETeUJT8/g0c6gTC0RtG3gGq6T0c7iPZLDvj+BojeI8XsI/MYfPtk48cJG48zQJ4zKewRLK4a3qY2NLBPdoDb+wSjh1hVj2Toqxy7jGZxC7MyiH40zv8WPpSOG1rqBGNvFXrlI99VnMYyXMAwV8Q1Wmd/mZbgrhM83jCG0gJDYoXXkET2QT/VQN59QswrE84zs9CD05/OE1TPElHJVN3LXTGB2LmCyzOCZmmG5PYTicwCPOYgk1kNKLKJEGUmENnTqPZJrDNFZDHKwgjZUR3DnEUBGXWsCTrmPJLWBU5rAZFvC4TyKPlZGlAqKUwGL14nGnkDJljKEagrxMMHUZp7iK1ZBHcacIB/OE/BkkdwJttIAUWCPZuJto7hJGYwWrksHnKxAOFnG6UozLMZzpDQK1KyRqd2L1LqGzFgjE53CpJRzOHEPjfqy+GcLVS3gLF7BG15k0lVFcVRyuGtOGJMdGfAxrolgcdWT3HPrgIsPWClptBqOlyPhQlBP9AQb6w0yMJTBZq+iNVXTueazWWRRzDf1olvGRFJOjacz9aWRTHcE2h92+htO2gl9cQRmvYJuoYBoro2iqiMNFHFMNvMoqIfsGjrH61vaN0SrCSBnneBV5sIQ0UCBkWsWrncd+ooDcnUHpKeMYqeEZreHsLSCeyCJ0J3GPVBHakggH40htKRy9JdT+Eu6+Mv7BKmpfGfFgHFtzDLElitASQulK4e8r4T6W3ypQGSxjbQ5j2uXDfJsXcf/W0KFyKL61xq6/hNqZQmgKYtnlx7bbj/EWN0JTALEphLM9RWigiONQDOVAFHFfEPOtHuSWMMadboQ9Puz7oxhuc+DtTmJvjWDfH0bc48d6mxdlfxjr7R4cLWHcbTFSY1VSEzUymhqRviJ5/Sz+o2lSoxUCRzPUbIvMOdepe5aY8SxxOnmRRdcGp9NXWXKfYjN5maK1wanSWb5x/Vs889ANnrj6FM8//gJfuPgka7lNrizdxRP3PcWPXn6d1155nR98+x/4xx+8wRce+8LvMs5/WJbyh7nol19+mVdfffV3ovwfhwrf//z0pz/l+eef5ytf+cr2DfSfkY/am7bZZseOHdsC/ZfIPffcQzgc/lCB/od/+AdeeOGFD45w/PNbfOWRr1KxziO3BBn7G4G+j+kY/7gNYY+P3FSD+9c/y4vPfIu10FmCJ3KYb/Uw9Sk7Yx8XMO104zuaYkZZ5erMNU4mL5DXz+A6HMN8hw/9zW4MO9WtIofePAuuk+SmZ6iKywT6Sri7c1j2RZBb40gtEXzHsqQ0NdSOOMG+DOHBMpHROmJ7luDYDPaOrTrvQH8e/9EMavvWGi+1t4S9v0LQsIpPt0RwfIa4dh75QBTXoSjygQjOozkcfSU80klivvNEpHXi1lWUYwXEvUGsuwOY90dwnCjiNC3gi10gXbyLlPcMtv4yrhMFzHcEmNrpQ+hI4xUWkd0rRObvpjB7L9qBDMJYFeVIGs1NKro9QXzmeczyPHJojfz5h7E4lrAI8/gMC0ztC6O51Ys6XsVqb6BXagSqZ3BUNjEFV1Cda5j7y0zujyH1F7CZSxgcJWR3FXdjDWt1AzG+ilU/h3m8jq2/gGyuYFXzuD1FVH8J+9oy1uoCJmkeh2sDh2UZYaqMYM/ii5QRhQC+VBFxaQ6zfxZX4gy+2Fks+jo2pUggWCUcKeJ2JDEk0hgjVXzFTTyFcxjFOTSGLA5PAa8vj+JMMqJTGZfCmAJ15OQSBv8MA9NpLEoBky2FVUnRP+qiX+PFpJYwOiuYgguMKTOI6jxOzxw2ucrIVIyhoQA2oYw7vITgW2DatYTVMU8gvIHqXEJvKKDR59CPJJGVGURpHpt3Dad9lXj0DB5lBbO2ik5fwjKaxzZZxGZqbLUx2tcJimtUNGwlAAAgAElEQVSo0/OImhqGyQrCVBVxtIh1IIfTsoBqW8I5XEM8lsc+VMM6UkGZrCEOlbD2FXCOVXFPNBC7c1gPJbC1p1CGqrhGa9j7ith7i7iGK+jbopj3RbEeiGHeG0HsTKMOV3EPVHD3F1EHysidGSz7wxhv92Ha7cXSHMHZnUU9XsA/WME/uFUiJDZHsDUFMO3yYdrtQ94fRT2Wwde71VAoH4xib40iNoUw3eZB2BvAdLsHtTNN8LcDuO6OBPL+MI7WCLa9Pow7VaR9AcTmEIH+Arb9HnzH0rjbY9j3R5B+u0/auNOFqzWG0hIiPlwi3JcnO1kjOVYmMVohdDxDZLBAsDdHyTBPTVjmZPQ8iekCaVOFJc8p1kMXWHCd4lTsIueyd7KWOs1G8QyPnH6M+5Yf5tHzX+LzZx/n61/8JsuZDR65+Hm+/MSzvHD923zz6Zd47e9f59WXfsR9V+7n3Xff/aOM8wcJ9BtvvMELL7zweyUrfyjQ7w8SPv3007z11lvbg4R/Jj5qb9pmmx07dmwL9F8ijz76KA6H40MF+vXXX+f555//k+ffvvEydXEF+/4wk/9TYui/mxj9vy2Yb1OJj5S4Ur/G97/1A04lLhLqzWPe5WHyf9sZ+4SA/jN2XK0RqpZ5rlTv4Vz2KkXDPOqRDKY7/GhvcmHYuXUDHezJUbMtUbEuUjQtEhksobQnsO6PYm0J4WiN4zwcJ62pYT8YwteXwXM0h6+/jKUtTWBsFuVwishoDXdHCtehCOqhOO7ONK4jaeS+GiHrOp7JeaLaefyDNSy7fYh7Q1iagijtaYSuNGHXGcLqWaLSOhHzCtbDcay7/ehuUhFaIohHU8iGOULJK2QLd+OX1pDGa3j78kzvVJm8SUXsSiJoyljlRTLrDxBOXWRyooLHMIe1LcHY33kw748gT5QxTJTwli8RW78Ha3ANT+gUzokG43cEMB6I4TI20BryCM5ZUmfvxFo/jZjfxOdeR38sg74tiXuiisFcRHTW8KUW8Zw+h2VpAyWyhsmygGW0jG2kjMVaQnaU8PoruIp1TBvzWNINzPY5JOci0yMlpqYyCM4sLk8eg86PLhlnIpJC6ylhDswwqS8xOJrAYElj92axWkNMmtyMeXwYHXnE5ByW4ALDhhI2e41QchFPsIZO62fc6sURrRBILeBOLTOlzqH4V4nmzpKpnkV0Vhgd8uDwFHEEGqipFSbsdYTgGuniFUKps8jOGUYnYxgmUzi8DURnHa3SwCotogZXCQRPYrXNojHlmRxNYNHnkOQaRqGOIM7jE1cIeU4hamfQ6ivotUXMmjz6kRzGyRKKvICqn0MZqiFpZjBoaojTNWyjRcxDOSwjJaSJKvaRCrbONMLxHNbRKnbdLOJYGfOJDPJICedEHXNHGvOBGOYDUYQTeVzjDeTRKnJfAfdoDelEFn1LEOFgFOMdIcwH43hG67j6Kjh7i/iGqnj6SsgdKaz7g9gOxDA1BXF0ZXD3lAgOVvEPlvEczyG3JRBbIgj7Qlj3hRBbIjg6U3hP5EloGri7Mrg70sgtERytMYQ9QYy3+3C2JXAfSRPuLxA4kcfdntgqU2kKIO0NYt3tR9wdxHMkhac9hXm3G7U9hqstjqcziXWXF7HJj22PH8eBCJ6OOL4jWwO80aECwWNpUmMV/Ee2bp+zk3VK5gUa8iproXN4+xJENDnqwgqn4pdYcm9yZ/1+Hjr9OMvxTfJijXvnHuRq7RoPnnyUJ64+xZP3PM3pxnm+842XuWfzPp554Dle+NK3+MYXX+SH3/0R95y/xju//v/iHP8xsvGHAv32229z/fp13nvvPb797W/z+uuvf2AF+JNPPsmTTz7J22+/vT1I+Gfio/ambbbZsWPHtkD/Z8Lv9/PpT3+anTt3Mjg4yFtvvfWBzz3zzDOYTKYPFeg33niDGzdu/Okhw+dfYdFzCvfhGNpPyQz9NxMj/6cZ804XscESF8v38Nxjz3M6cYnoUAnb7gDjnxIZ/YSN6b+14zwYpmha4Hz+Tpbcp8hMNXB1JjHe5mPqM06Mt3qw7QkQPJ6hpJsnOzVDdKhMoK+AdX8MYX8U894Q9rYEQkuQ6GAZaV8A15E49oMxXN0FpK4c7v4Kzu6txjWpZSuv6Toc38qDHowiDVSJCSdRR2ZImFdw9hSw7PEjNAUQmgKYdwewHs0Q8Zwh5DhNwrGJX7+EvSuF2BJh+hY31qYgxkMxHNZlIonLpNJX8Sgn8ZqXcXSlmbrFi2m3H/loCtNgEXd0k+rZz+KKn8NonSMkLKHbF2Fylx/niRzWiRJmQ53S5UfwLF7FljtDLHEOa0+RyeYwzp4i5rEC2vE0/uQ66rmr6GZPoRROYjM20LRH0Xen0I1mGB1PoJ9OosTrDFfraCszTIhFNFM5xo8lmBhIMDIWxWhOYrUk0BWyaDJ5jP4Klsg8enONSU2eaWMel28Gl1xiWvBirqWRQnl82SV8pZNoLXVMYoNw+iSx7DpOIYctGESNZPHnGqjxOQy+WXTKLNHceWLZ03j9s0xqXNh9KYKRMt5EDb2jgtaxSDhznnzjLvzxNSYm/FimAzjULN5oHbNSZMJWJZq9RCRzEW9gnUlLBu1YBNGYxCbm0Qs5tJYyqmsN1bOGYJ1jwlxhSpPGqM1gNeaZ0qTQmyvYtA2CygYu8yJ68yxaYxWTJo9ek2NqKIV5sogwVkHsLWKfaGCbnkWwzmGdqGAczGAYyGCbrmAbLmHrTGHrziNPzWA3LCBP1rH05xGGitg1FYSePNLRLNa2BEp/GVW3iKJpIPaVcA5XcQ2WkI7n0DcHsLaEETozeMdncPVXsPcW8Q2X8Q5VcB3LoXQkUA4nsLXEfltdn8N1ooB3oISvJ4+vt7C1lvFgDOlgHPvhOLb9URztKbzdObwncvhO5HAdTuDuSiI2hxCaw8j7I8gHori7t4ZpvcezqF0p7K0x1M4Ell0+lJYQSnMIe2sET0cS0x3u327aSCHtCSI3BzHf6sXTnkTZG0JtS+DtiOE/msHdFic6WMDbmSI5WiUzXqViXaKgn6FqmaegnSc8kMV1NMJG7DzLnk3unn+Qh049xp2N+ynbZskYS5zLXuW+1c9xuXgv1+99lm89+13uvXQfX/ncVzlZOc3nzj7Ojce+wTe++E2+9ZXvcP/lB38nzf8x4/xBAv3ee+/xxBNP8O677/LCCy/wT//0Tx8o0M8//zxf+MIXeOedd7YbCf9MfNTetM02O3bs2Bbo/0w8+uij/Nu//RsAwWCQYDD4gc+9+OKLjI+Pf6hA/+QnP+HZZ5/900UrT32Thn0NR2uMyf8l0/8xPUP/3YBpp5tof5Hzhas8cPJzrIfOEjqWxXy7h7G/ERj7hI3JT0nYm8PkphqsRs5QMM2TGKtgPxRFd4ubqc840d+iYrxFJXQ8Q2K4THK0jL87Q7C3gGVfBOFgFMu+II72BGJzCLUjgXIgiHQgiLstjtSRxtVTRj6awz9Yw9WdxXEwhtwSxH0ohrg3iNiWwDleJ2hexaOZ34pmdKaxH44h7gsg7Ati2eNHGa8Tdp0m7DhF3H0Gn2EJz/EctpYw5tv9iM0hTF0Z/OopYpk7iaau4veeIyKuInWk0N4ewLoviLkrhW4gSyB1huDsXUixTST3AvJwifFdPqb3BDB3xxg+7GdSk8ZdPcV0cQ19bAmrWGesNcT4/gCG9jCDnWGGuwJIsVn0xSV0s2soyTW02hJTPSnEkSLTYzkm+hM4hRqupXUsi8vYyyu4M2uYrTPYdA1MU1VEWx1JV8AbmUVaauDMz+DKzOLMrWKw1DGaZrDLiwT9y8i6LOZwAHssTTBWxpupYw3OorXVUf2rxHLn8dhnsBl9uIJBQokM/mAO2VdgQmrgi50nkr1IJHMO00QQi9FF2B3HG0ojO5OM6bP4kufI1O8hnDmH0ZJhekxFtoRRnWkkKca4No7DvUYke4V46iJGxyyTkzGEqRhWaxKDNoJmLIbZUCMcPo+oLKG3zTElVjFO5zDrs0yOJdFoUujG8nhNC/gcpxEdaxjsC5j1FQzaPNqxNIapPKbJMuJIGad+HqewiuJeRxYXsIwUMPRlsGlLWMfKKIMl5L488vQcLnENj7iGOFBCGChgHy0jDZVQBiqIXSmUvhJu/RJ+0zJCfwl7fxH3SBlHfxG5O4PhQBDpaBb3QA17XxlbRwa1t4C7t4K7r4hvoILSHkfpSGE/lkc5kkVuz+DoTKEeyRAYrqCeyOM6uvU3R1cG6/4o4sEYjs40ro4kro4E/p4C7iNpnO1JHG0phOYo1t1brYLyvhCeo1viHOjN4zuaQdwbQjmwFQkRm0MoB8PIe4OY97pxtEbxdKaw7Q0g3OHDeTCGtMeP1BzAfSiG0hzEfzSN3BwiOlAg3JMjp50lr5+jYJgj2r+1iSM+WCY9UcHVFeJU4hJX6/fx4MbnuVy5hzOpy2SmqyS1BdaC57lYuoeHNh7j5ee/x/e//SNOls7wxNUvs146w7Of/RqfP/sETz90gxuPf50vPXH9AzPOv/nNb/4o0vHee+/x3HPP8fOf/5znn3/+95oJ/3CQ8POf//x2I+GfkY/am7bZZseOHdsC/Z+Va9euMTU19YFnr776Kj09PR8q0G+++SZPP/30nzx/5pEb1GyLKC0BJv6nRM9/nab/r/QYPu0k3JvjZPwCl6p3sx46Q/B4FtPtHkb/WmD442Ym/0ZCagqSHCtTty3RkFYoaOewt8fR3+pBd5Mb4y1ejLe68B5JEzySJj1RJdpfJDpUxdocRmiNIeyPIB2KIR+I4ulI4D+WwrJHJdSXQ+7IoPZXEI9kCI7NoHSk8HSlcR+OobbHcbRGsB/LEdAu4NbMEtAtEzYt4z6ex9WVxtoUQGwOYtobQJmcQTUv4rat4JXXcOtmkTsSTN+uot/lYmqnk4mWIJbJMqJrGcG1jORYRhrOM3GHl/GdDnS7XIzsdjN5PI7Tt4KYPY2UPYcvtIq2M8HUgSjOExm0rWHGD4bw+9dRq+cRZi+Qu/QILvsyhr4c9v4yQn+BiQNhxMky/tJpTLMn8a5dRK2cwSzMYplqoIzW0PZmMB9Po/oWEBvzSI1l3Il57OklTMIMom4Gi76BpK8hjeVQc2UclTLuUA41UcMSbGAQ65gNs/hDm4jTFSRLFJPLid8XwxtOIfmzaJ0lrOIS4fQFItHT2CbiSIKbgBog5Azjd8fQSiksniXC+UvEC3chKVWMGicBJYhXCqCKIaam/FjUBqn6vYRzV3GEV9FNhnGJEULuFIopjGbcx7QhRzB7iVzjXhzRk0xJBQRTFruaQzAnmNSEmJrOoKrrRIt3YnHMMeGcxSbWEMUKWm2KiZEYWm0exdggEjmP6t/E5l1DUhaRrQ0MYxl0Yxl02gLm0RJu4xxuYQW75yQu9yayfgZ9bxqrpoh5ooQ8WsI5VkMerWA3LOC2LaNoZ7D15FCGS9iGSyjDVVzDZcTjOezjM3imlxB7igjdWdyjVez9JVyDVRx9eYyHIlutg8MVpOMFpK4M9o40an8Jz0AZ9UQOV08Z70AFpSuLrTWG1JpAbk+gHEri7S3g7yujnsjiO1HC2ZXGujeEuD+C2BzGcSiGoy2BuytDcKCE70QO6UAM654Qtl1+xL0BlNbI1iaOrjTujhSOg1GkAxEse4JIzUHMt6soe4PILSF0t9hR2+KYblWR9oeQf7viTmryI+8NYN3lxdkaRtjlI3AsQ/B4joptgZSmRm6qQXKsTHyoRPBYhtRYlWBPluB4krsa9/PA+qOcz25t4ljybFKxzxPR5FiLnOb+tc/x8lf/nu/ceIXr155hJX2S5594kbX0aR6/60s8dd+zfOfG3/OPP/rx7zUQ/seM89tvv81TTz31R3L83e9+lx/+8Ic899xz/OIXv/hAgf7pT3/KI488wrvvvst77733533R/4XyUXvTNtvs2LFjW6D/s9Lb28uFCxc+8OxnP/sZ7e3tHyrQv/jFL7h+/fqfPL9+37PMOzZwtUeZ/JRE38em6f+Ynum/deDtTLMWPMOV2fs5l79MbLCI7Q4/458UtwT6UzJyc5C0pkJdWmY9fI68bhbH4TiG2zzodnrQ3+zGcruP4PEsydEyJeM82YkGkaEy4uH4VozjQBShOYyzLYHnaIrAiTTmO5z4B3IInWmUY1mMhxI4egpYmoPYO6OILQFMtzsw7LRjPhhF6M1g6E4jjpSxHksjdESwtASYvsmO7mY72js8CH1ZpKk6TmEVj7JGQD+Hs7eAcW8A2x4/xt1+LN0pnNOzhGIX8GfuJFu6h6iwhqUjhbMjjWVfCO3eENJYhWD0LErmHPGV+/H715g+lkYeKmE/kmJslxd9R5xI7CTW5DpK9Rylcw9iMc1gmijj0dTRticZb/LjFeaRcuuYssuo9U3E5CrTljriVB3rcBldewJhIIcrPIs1W8MZqSKFq5jC85jlBsbJOhbtLMJAHlmfxRFLYfclUNUUSjiLKVRHr2/gdKzhdq1jG81idwaxTEsE3SFUexhLLIPB0UANnSaev4JsaSAYAwTUIDE5TNgRxGL1Ma3m8ecvEKvciT95Bv1UBK8rSjQQI+aOYjG40QoJwtUrBCtXiVSuMi2UUGwp4tEiHiWORedhfDKAJ75Oav4egpWraL2LmIUKbl8Fr6eCVhNGMx3FYqngTZwhWrzMuHcWvXMOWW4gKXUmx2JoDFlMuhKKdRa3dx2LYxk5fBKnYwnRUEc7lkGrLWAczyONlVDFJQR5CUVeRrYsIE1VEUdLWCZLWMaLKONVbEMFZMMcbnkVu3YG87EcymgVcaSEMlbBNV5DGiggj5TxGuaRB6sIRzIox7KIvXmcIxVcQxXEY1lsJzKoo3XEY3lsrXHEQwnk9hTuviKu3hKu/iKBsVmcJ4pY9oUQDkSx7gtja45g70zjOVFAPb61icPRncG8N4Txdh/mXV6UQ1GEfSGUgzEC/QXUI5mtMqC9ISx7Atia/Jh2ehB/u6ZOaY3hOJRAao5gbfIj7gtgvd2L3BLCdIsH224V7U12TLd5sB8IIzWFkPaFkPcGsOzyYD8YwnKbB6HJh+NghHB/gbxhjrSmSmKoSEk/i68rRXKsgq87TcmwwIJrg4xQ4r7lhzmXu4t5xwZns1dZVE9RtDQoCQ3OlK7wra98h2986Ztcv/cZnv3s11hJrfPE1es8cOYhHth8mO9+9RV++o8/47svvMxTj3+Zd97ZinD86le/+p00//KXv+SZZ575Izn+8Y9/zIsvvsgzzzzDL3/5yw8U6HfeeYcHH3yQd999l3/913/9877o/0L5qL1pm2127NixLdD/f6Ozs5Obb775jz7333//757J5/MMDg7+yYnw3/zmNzQ1NX2oQP/yl7/ki1/84gee/cu//AvPf/EbLHtP4WmPo/1/FHr/apqB/2bA8Gknwe4sJ+PnefzO65zL30lspIx1jxfN/5IY+biVqU9JyM1hIoMFZp1rLIU2SE6UEQ9E0N3mZvx/y0z8rcL0TXaEA348J2I4OsOox6MIh4IY93qZuNWFdreXiZvsWFp8iC0+lEN+9LfK2LuiyN1JbF0prO1p5BN5xMMxfH15XB1xhN0+nIejOI7l8I42sI/PEpdPoY7WiGvnUI/lEJoCSM1BbAfjWxXLugUigYtEfOeJC2t4xutYD0SQ9oWYvt2H2JXBPdXA5dskkLuLSvVe3JOzWI/lcHYkmLjJjbYpgHuygeJcRYqepHD6YSymBlMDOVwjFXRNQUZuciEN5HC6F9B5ZvHPXUQtnkNrqCPqGtgHq4zc5kO3P4pXmUPvrWMNz+HILWOJLKOTZ7Fq6uiPF9C3xVAmiliVLKKngOjI4ajMY0zOY7XWMYw3sE/PIg7kUdxZFCWOxxHHF0ij1OsYvVWs1gU8gTNIUzNIpjQuZxSn6CLii6LG45hSBWzqKsHiFdTAKczTedxqjKgnQSYSR3UFMIVCSIllIvXLRKqXMYl1bGKKWCxHMpjB5wwxrnMiRusEqmeJzd2JNb6GUSgSis3hC+RxO1OMT7ow2bL40xu44icRimcweBZRg/OEYotYLSnG9CGmJuI4nHP4oxtY/YuMuxoI8hye4AoWQ4EpfRatIY9xLIfsmEdwLyFFNrDLiziVZSxTFaancuh0RazjeWyTJaymGWRlEbd9DddUA2msim2qhmGiiDixtbHDOlpGVVZRTQuIJwpI3Tmk4TLCWAn7ZB1puIA4WMQxXsM5UcfWnkY4nMLalsY+VMU1WkUeKCINFBCOZzAdTmJuCm/FlfZHETtTW/+LvSX8Y3VcfUXM+yOY9wYw7PRgaQphbdkSaPeJIt6BEs6jGawtka0NHLd7MN/hxXSHH+veAO4jGXzH8rg6k9iaQ9j2BjDt9GC+3YutKYDldi+Og3G8R9M42xPYD0cRdgew7d6aETDdqiLsC2Da5UG/y4W7PY6rbevXHdtuL0KTH6UliPEWN44DYaTmILHBPMmRCvnpGdKaytZtc3eaxEgRX3eagn6OWXmV8/m7ietynE5dYtV/ho3QOWaUdU6nr5A11bhYv4vLS3fx2MUvce/iwzx+9SkePvUoFxev8sSV63z2wmN8/tpj/PA7r/HtZ1/m+adf5AsPPMHr3/vH3+Wg3884//znP+fGjRt/JMfvS/b169f59a9//YEC/Zvf/IaHHnqIt99+ezvC8Wfio/ambbbZsWPHtkD/Z+Ps2bM0Nzfzzjvv/Mln/v3f/51bb731QwX6V7/6FY8//jj//M//zJtvvslPf/pT3njjDV577TV++MMf8swTX6EqzyO1+Bn9pEDPx7T0/Jcpxj9pxtqkEtPkOb9yhYJUR+kIMHmTzOBfm+j7Kx3D/8OI7mY7zvYQBUuDsjRLXFNEOhjEsMvD5N85mfqMHdNtKvaDEQr6GZLjJXK6GqH+Ep4Tecz7Itg7s9iaQni6M3i7UviPpxBbfAT7ivj6ikhdOTzDMzi7C/j6y/h7Cls56H0h1K4UcmcS+/ECnuklAtZ1/OMzJHULiAejCHf4sNzuQzwUR+hIIk/NEwldJOw+Q1xcQ+ktIewLYdypot3pRWxLIk/WUVwbxCt3k4xewjpURhkqYt0dZPxvnej2BnFP1jHpa7gy58mfepjpyQomTQ11pMr4zR40t3hwDZcwmMrobVWSZ+/GEl3H5FrCKy6ha08xttOLY7CMyVhg2lzAEZ7DPX8aQ2YNe3AN83iVqY4U5u4skrGIxZnD4SnizdaQVlYRikuYjbPYzP8ve2/2ZcdZ5mvqH+g+dbrWOXQVFDSHYrBlWVMqB2VKKSmVqSElpXLOPe+I2BGxI/Y8z/O8cx6UqUzNky3LE8YTxjYYyza4jMEYymAml8EFBS7M0BTlm1pPXySwDgf70BfdeK3jfNaKm/3dx37WG+/3+80jDzdRTTVULU8kXCEcyBGaa6CdmkL0TqFHzuD1rK6vKbgKxBJlXEqAsC+B0sjhiDXxV88SKl9GUGYQnSXikTr5XIW4L4moeRFDWQKFJRLzV3Gm1zAqNeLZWTLJaRLxMrYJN6IrSjA3TzR/Gr28yoRnhlhulUh6nnhyBpsYYWIsgD88iS81jzO5iCEwiy91jkzpIm7vHFZHgTFLDMmYwReaweGexhxaxCo0iaTP4vcur8fYSUVsYzkc1jIObRLJM4/uOkVQWcItLWE3NzALNSRLFWG0hGmoiOyYQdeX8BhmcByv4jA0MY/XUSxTSGNVxMEy6ngTxdDE0V9G2JdD6ivgGGuimSZRRupIJ8q4JqbRhxuY25PY29Yf9WgJ72gTfbCJa6SJc6CCZU8Ce0cC+84wlm0hhN0pvCfq6EerBIYm8Z9soB7IIu1OIOwMY98Rxr4jgrI3i/dYlejQJP7jFbTuDM7OBI6WdTmWdkaRWmN4enJETlSJHKug7Umj7U4i74rgaIkibA0gbA/i7v7dBcLePKHeAq7OOJ59acRtfuSWMI6WMOK2IO7uFOIOP76DaTzdSVydcbTdMaStQeRtIZQd6yIdOJglerRA9EiB7GiT8KHCH5I4UgMVCuNNpvUVlkLnWU1cxtMXY8a1wrS6zJnkFU4Fz3OlejfLhbPcfeoB6toMN2Y/w12T9/PA6c/y6OUnOFu7xHMPPs/3//EH3HP5Pp6+/zm+8vhXeeLep3jqsZt87+Uf8Otf/voP9d1vvfUWP/3pT/8kF/q/v0j4e9F+p/Nf//rXPProo/zkJz/ZEOi/EO+1N22wwaZNmzYE+n8lHn30UW655RZ+9rOf/dHvL730Ep/+9Ke5evUqKysrNBoNPvWpT2EymTh58iTXrl3j5s2bPPXUU3/4s/j985nPfIannnqKmzdv8txzz/H888/z4osv8tJLL/H8s//AtHsJrTOC4RMqJz5g4/hfm5n4qIxnT4JZ1yo3H/4Sd81+mpxxGr0zhvkWLyMfkjH8Nw15Z4jEiSqLwTVWIueZ1k4ROVrGsSuGZUsA22Yfjh1h3LvjlCyzJE9WKJmmCR4t4+nJIrQm0bpzqB0pXN0pgr05XLtjaJ0hPF1pvH15pAN5wmMzKD05kmMzuPdmUXaGUXdF0duTKLuTyL1FIuJpwtYlwhMLxExziC1hpNsD2G7zobTFsbXH8SrLxEKXSPnOE5dPox4qo7bHMH3Ki/FWP1JnHPFEmUDsPMWZ+wgHz6OYZoiMTmPbFmTsEx6EthjSUAWroU5q6R7izeuYxRncyiLaoTJjt/qwtERxTTQxTZTRIqfIXL0PIXsOV/YsPukU4x1JzG1J3KNNzNYyklIntXgJ+fRFhOk1fOHTWEfqmA7m0YfrCEoFxVnFH2gQXFxCWlvGWVxBcM2j2meRhuqI9gpuX41IuIbPX0CbryHn6iixRXz5c0j2Oaz2Kt5gnWxqFnHCjysRw5lL4441iE6ewRk7jcFewxucpdhcJpWcRDH7cQR9RDNVYqU5fPlFDO5ptD4KGBQAACAASURBVPACxeo5spVTaM4YVoOTULRALFojVJxlQm+gRldI1i6Ra1xE91UwG7zoYhxfuIwv3MDoriK658nVrxNJnUPRpjArKexjcXQpi6JVsLrr2OVpZGmaYGhtfdqvVjAbcwjWAoIpj8VaRNJn0Ywz6KZZZMs0BrGBTWxiHytiHMliM1WQzE200Qb2A3nEwRqWiSaKYxZxvIHtZAHHaA15oo54qIRtdwr73gzCcBPNMos61kQ6WUKbmEQbayLszyF0pbC2xhH6irgnZtGHGjhP1nEPNXAczmHbE0PuWs+AFrpSaMequAcahIanCA030Q+XcHZnUDqTyO1xhNYY8p4Mnv4ywZMNQgN13L0FfH0FlPb11Q65LY7YFse5J4W3J0/w+Pq+v29/Gr0rib4nibg9jLA9hNaVQt+TInS4hKsriXdfGk93Cmfb+v6z/bYA8q4Ivu4UemcMx64gWnsMvTOGe28S+xYvzo71KbW3O4WrM45vf4ZwX47okSK+7hSpwRr+A9n1TOihOtP6CnVhnhltmbJpBt/hBKnBCmeTV1lwr3Gtdg+PXXuKxdRpVsLnKDoanMte477lh7lavYdHLj3OnSt388YPfsw3vvQKq/VzPHrhCV544ms8fs+TfO7eJ/ney6/9QaC/+c1v8k//9E9/tA/9Pz7PPfccTzzxxDuevf3227z11ls8+eSTvPrqqxsC/RfivfamDTbYtGnThkD/r8THPvYxPvShD7F161a2bt2KqqoAXL58mUKhwPT0NGtra9xxxx1s2bKF69ev88gjj/D973+fN998k7feeotf/epXfzSBfvLJJ991Ov3Ga29wsXSdyJEi1lvdDH5A4PhfW5j4qIpvb5JpbZlHLz3O1drdFMYn0TsSmD/pZviDEuMfVpG2B0ieqDDrWaMpLVAyTxM8lEfYEca82Yf5Vi/ClgDKrgjZ4TrxI0ViR0r4D2RQ9mYR29ej7PS9aZS2GL79GeTtQeRWH9LOIJ6eHPL+IqHRGbSDReJjM6i740hb/ai71qdnwvYQ8uEKcWWVgGGBhP0UgZEZpJb1CDv7lgDizhC2jjgB1xox/wVSvksExGX8Q020rjSmW7xIO8OIHQkcYw0i6SvkGncT8J/HoywTGKxj2hLCtCWA3pPFdqKEw7lA7fKj+CpXsfoWCbmWsO1OMLE1hH64iHCyiHEgT3TqMpEL9yI0LxAtX0Y2zjDRmUQ9XEYarWAczuNSJoksXcI2t4Zn+TJO7yksw1WE4xWc5ibW8SKqtUQ0OY80P4fYnEHLLKJHT2Ex1hCNTexinUBwBrdYwleuok6XUSMVfOUFXLEljJYmdqlJNHGKeHQG27gHdyGKL5Ijmm3gz01idE9iVWdIV86RLZ4h6Cyiik4S8RjxdIFIsorNU8XsnSORv0SqfpFYegFh1IlP9hP3JYmnC4jOLBNKnXj5Grn6dUKxFazWIKrJh0eOEHRlcDjTmG0FQpGzxIpXcQdWsOg5bKYoupBEFlNYTCks9hKKZQqnPIdkn8WkTWIUCojWHII1j2EijcVexD5cQx+dxCUsYHPMY1ImsRkrmCcKmMaKSEIDebyO/WAWeaCBLCygaqeQrFOYB/LYhovIxjqOoRqOnhxiTwF5fAZdWEQxzeAYqKCN1nGO1pGPVXAcyCPuzSAfLuM1z6MNT6KerOMZauIZaeDozSHsjiHvSePYl8N1tIp8qIy7v0FwsI6rv4LnSBn9YB7n3jTy3hTqvgzyngx6bwF3b57g0TKh4xW0vRk8PVmcXWnE1hhKRwKlK4XnYA7PgQy+nhyufRlce1KonUnkXVHk9jhySwT3njTuvan1iLu2KL6DGfTOJMK2IM72KGpHHK0thtoWxbrNS+BgDrU1inNXFKUlhLgtgKsrid4Rxd0Zx38gjXt3gnBvFr09RvRwkfixMnnjFE1liUl5idxwnZJxltTxKoH+FNETeVYiF7hSuYcnrn+Re5ceJC/UmdVXKYlTnI5d5GrlBvcuPswXH3qOxx96gucf/QpP3fsMF6au8oX7n+GR80/wwKVHeOjKo7zxgx//YZr8wx/+kJdffpkf/vCHfOMb33hHQf7mN7/JY4899q4C/eabb/Lss8/ywgsv/CEFaYP/f3mvvWmDDTZt2rQh0O9Xtm7d+iey/E7P/0ygf/Dq66ymLhM8mMX8cRcn/4ud439lYfwjCu72OFPqMnfO3Mfp+EVSg3UcLRHGPuZk8G9FRv/Ogf02H7FjRerSAvnxJrmRJv7eHNbbAxg+5cJyq3+97WxXhHBfnuihPKHeHLH+Io72JPLuFI72BO6eAvKuCN59aZytERytPpztUTy9edRDZXwnmriO1AgONnB2JtF2x9cvOrXHkNviaCcbxKTTeMZnSStn8AzUce1No7TGELeHkFqCSH0F4r7zxALnSQYvEdbXCA81UTsS2G4PobTFsHUk0E1TxHPXSFZuEEhcIRU8j+tIGdO2MI62KI59aSa6k3hdp0gv34e7eSd6ag2POIexI4GwJ43rWAnDviTmgTyZ2TtRpy6hL14jVrmMbbCCtbeA+2QV0/E8poNJ/KFFnEtnsU+fxts8hxhYwD5WRzVOYh8uYxnKoU2UCdUWUWZn0csz+HILyIE5bLZJbKZJnOosLmsdr6OEf6aAL53HnyoRLMxgczexilPo+iKpzBmcxgIOSSYQCpFOpAlFM8ihGiZnA1/0DLHcRaKRZVSDG5+ikgkFyYTieLQYE1KBQPoSyfodxMqXkS1hNINK3OEn7gvhd0QYn4jhi62RnbxBOH8JyVNCmgjgl4JE1Ci6LYTREEaWJonn7iCWvYzkm8YmZXHa42hyEoc1gsWcwGYsEfSuIqnz2PQF7P5pJKGEYMtiGEtiFfJYJ0q4TNP4tBUc7lPY/Us45BlsEyUmBtMI1gqCoYbjZAXHcA1VXEQLrKHpp7AOF7ENFZGMdcSJOs7BKtLhEsJgHd22iFteQhiooA7X0EYbOE5W0QfqKH155EMl9LFpXEPT2A8WcQ3U1qu/B6rIh3JY9yRQeoro/VWUvvVLsWpPHueBAsHBJsGBOtr+LM7fxdiJu5M49qTR9udx9eTQ92UIHK2s50V3Z3DuzaLsSSG2xHB2JXDuTuA+mMW9J4PvQB7/oRLOriRqewq5JY6yK4qzM4HelUBvjxPozeHZm0LaGV6vA29bT9pw7AyhtASRWoI4W2OouyLYb/Uh7Qji2p1A353AvTuO1hpBaQnj3ZvEsT1AuK9AuC9HQ1qk8rsYu8xwjdTAeltofryJ2hkiOV7kzuY9fPbKF7hWvZszyaskRgtcLNxJ3lRnIbjGpdJdfOXJr/GVZ77K9dP38vm7n+aFJ77GhdpVHrr6WW4+8CUeuPQwL9z8yh+Vp/zyl7/kmWee4bXXXuNb3/rWOwryD3/4Qx555JF3Fejf14J//vOf38iB/gvxXnvTBhts2rRpQ6Dfr2zbto233nrr/5VAv5tov/rSd1kOXyDQk8H0CY1j/4eFY39lZvSDDtSWKBXLDBcK1ziXvUJ2vInaFmPso05G/05m9EMy9s1+In15qtZZqvYFyrY5wodKiNvDmD7lxbplXaBdXXHCfTkKhkkih/JkhhsonWmc3VmkthSengKOXVECB3P4ezKILV68+1J4D5fwHqujHaoQGJ7Bc7SCtyePZ18arTOGvDOI2pUgOD5H0LJIwLRIUlnDd6xO4FARaVcUx44gwrYgyuEiAWGZmO8C8dBlUt7zRAYnkTpTOHZFkXaEMLfH0caniIbOESlfJ1a6QSF5Faknh213Ar07hbktjKk7SSR2Bk/mAr6Z68Smr2IfqmDel8XVX8XenWR0ZxCXpUmodAF7aY3kxXsJpM5gHa0hD1VRB2uMdcaw9WYIpJexV+bRG6fxVFdweBcQrJM4RiaxDFSxH8njNFbQ8nW0RgPNW0LLTWL3TGO3TyEap9GVeeSBAj5PGm8qjj8YIxxI44yUsXjq2IV54tnLuJR5dEMc2S4Sd/mI+4KEXFGsvhwO7yLh9BWSpas4TTlcNicZt4e4w0dU8WEx+1GCMyTrd5GoXMcdnEUe95Dx+MkHA8QcXuzjOoKzTHL6BvHaXbgSa9ilFCE1TsqfJKgGcRi82G0ZAskLZGbuQY+dwRyaRJML+Nx5XFICy0QIiy2D6pgmnLmC1TOLITqP7J5GVWuYDRnM5hQmoYBsquNxLiIri9iDp1FCKzjlSUyDBSzGEmZTFWG8gjxaQ7bMoKiLqI45HKYp7INFHBN1JFMNZbyOOlzF3l9GNc3gVk4hDdSwHyniGm/iGKqijTVwD0+iHq+inKiiDTcRD5VQ+ko4D5dwnajiOVlH6isg9GRwn2yg9pWQ9uWRfp/EcbCAb6CGr7+K/0QN/8k6zgN57G0xnHvSyK1x1M4UrgM5/P0VAv1VfEcrOLuz2FtiiDtDOHaE0PekkNtjuPZmCBwpoe/JoHQkkVtjyDsjiDsCSNuDaB1x9I44csvv2gdbY6htMZxtUZSWCK6OGJZb3Zg3u7Df5sf8CRdq6/oFXL0jiqs9gmO7H3dXDGGLH8eOAHpbnFhfgYp9gap1lpJhiop5lsCBDPmxBvEjJdKDVaKDeWqeGR469zjXGvcw517lcukGieECpyPnmfUsMx9b5eVn/pHvvPQ9Hr76GDdW7+Pxq0/x5PWn+dyNJ7g2fxfPf/ZFnn/mH3j99df/SH7//d//nSeffJLvfve7fOc733lHQf7lL3/Jgw8++K4C/aMf/YiXX36Zz3/+8xspHH8h3mtv2mCDTZs2bQj0+5XOzk7eeOONPyvQX/jCF/jFL37xjmfffOEVzmWvETmcx3qLm4H/auP4f7Iw/mEFvSNGXVrkSu0GN+YfoDgxib47gfFjOiMfVhj7sIJ0u5/o4RxNZYk572mayiKhwyXElijmzX7Mt/mwbfbhPZAmdrRAYaxJ9EiB3MQUzr1Z9H05pI4EencaZ0eCUF+e8OEs5ls0ggdzeA6XCA1NoR4sE52Yw3WwSPREDe+BLOqOIGpLCLU7TXB4GvfILFFplZi4SnR8ivCJKtKOMHJLCNvOCM7+Ku7RKaKB8ySj18j4LxA3ziN2ppBbIgjbQ5g7YriGGvi9q/jzV8lN308+fB6ht4DraBGpJcLIbT6Evhyh4BqO0Cn8M9eJ1y5hOJ5HPFHGe6TC+O0BxnaECGmLCPFFxMQi6dN3YffMYzU2cE9MYT6QY3RbaD0SLTaLkJ5BjU8hp2exuGaQhGnE4SZifwnxUA5dKCHH8zg9WZzuNEq6juCfwjYxiSIuoBsmUcZyeP0xfEqQsB7F60vgyFSwOibxBVYJhM8jj5XwywG8DomCL0DaE0T1BxADNTzJCySqN3D7lnEYgqR8fsqeIHm/H5egIwSSRGpXiNbvJFa9gtWaJuKKUU7FybtCuG0qFluAUO0skalrxGfuwhxooClZUpEy8VAS3erBbA2iapOEiufwly9hyi0jeCYJ+Ov4/VXsEyGMUgy7KYfun8cbW2VQrmENL+DyzKIqNUyGFGYxj81aRTJUcLoWsLkXkLyLaM55RHMd81gRk62C3VTFMV5FNtSQxFkUdRHFOot4ooQy2sBurGMbr67vOQ9VUQ2TeORF1JEG1p4cjkNFHEMVtIkm+ngTdbCGPtpEH26gDtQR96aRD2QRDmRxDdXxDNaRDudxDldxDdSwdSQRO5Koe9I4upI4e/K4j1fxHq8SGplC6y0idCQQW6JYtwSRWtcj7fR9OQLHqniPlpH3phFb4zh2Rn+XwhFC3BHG0RrDvS+H3pVG3Z1E3BlFbosgbA0g74ri2Lme3OHYGUbeFUFui6G2r0c3qrsiyC0hxNuD2Ld5mPiYinC7D1dXAlfbunSru0KoLWH09hi2Wzzo7TGU1jDx4yWKxmlq4jxFwxSZ4Qbhvhz58UmC+7MUjbPUhAXmYqvMxpY4l7/GSugCZ5JXmVaXKYh1lnznuLHwAHdfvo9X/uHbPHXvszx46REuNu7ghce/xueufp7H73yK62v38POfvcWLL7z4jnXcN2/e5Jvf/OYfSlX+x+c3v/kNDz744LteInzttdd45ZVX+Na3vsVvfvOb9/rV/r7gvfamDTbYtGnThkC/X+nr6+PVV1/9swL99NNP86//+q/vePa9f3yNq9UbxI8Wsd3qZvAD6yscYx9VcLZFqNnmuGfxQR448yhl8wza7gSGv3cx+hGF8Y8oCFv8+HsyNMVFFn1rTMqLhA8XUTuSWLf4sW7xYd/ix9OdXBfn0SbRIyVix8t4ekvInSmUrjTK7hSeA1n8B7PEjpcwfkIheDiLqyeH/3gDpbdC1DiHtr9AYri5vuu5K4LaEsW1L4f3aAXX0DQx5zlCpkXi4zOETtYRtwXXo7p2htD6CqjHq4SDF4lFr5D2rBEcn8GxN424PYTxFh/W1hj6QA1VnMefvUpl/n689jmk/jLewyUMn3QzeosHtb+Ips5hV2ZIr92P5ltk9EQBfaSJtDfD0Mc9WNrj6PIsRqWOFj2FZ/ICFm0OmzSDc6DBeGscY1sMl6mOWSxg91ZRQw3k8hLm0AyScRrb8RrWg3nkE0V0bwHNnUHXkoTKNZTGDIKnidU4g0dZRjlRQVfSeF0xEv4E8UAc72QeKVFB1OcIpC6iSwvI5gxhf4yQ5KQYjBAKBJGzcRzRBZKTdxDIX8Zuq+DTY5TCGarxGHHdiyjr6PFJQo1LJGbuxBaeR5Lz5LMlcoEcSV8Yy4SI5i0QzC4RLKwhldawuieJJqdJpmsE9BQWiwvbRIRAfBZvehlbbAFzbB53aIFIcgFZKGCWY1jNSSRTAW9gDtE3y5CniUOZwhtYRLRXMNkLWKQSwlgWh62KoM+gBk6ha4vIpklEUwOrvYHFVkWy1rCPF7GMV9G9y6jiHOpABfFICdHYxGqoIpvrCKMVxPEGmnEadbyJvaeArTuLcLiIYprCaWjiOFlFGanhNkwiHS1ibU1g353E0hZHOVzGNdzEOdhAHaogH8lj7Upha4th3xHGujOKsDuJ80gVvb9GaGwa19EytvYE9pbIevHQjvB69XxHEt/xGv7+KureLGJrbL1ufmsA+7YgYksEYWcE1/407p487p4czt3J9XsB2wLr4nx7ANu2AM6OBM6uFO7uNL6eNGprFHlnCGlrEGVXFMeOMOZb3EjbA7j3JvEfyOLZk0beEUHfHUPaHkDa5kdpDeNsiZA8WaVonKIqzFM0ThPuK5AdrRM8mCN6tEB2ZJKlwDku1+9iMXmGsjTNqdh5ZpwrrCYusxy5QM5e44HTn+WrX/w6y6UzPH7nF3n43OM8cO5hbpy6nyfvfJqnH/gy3/7Kqzxw92f43jde47H7H+frX/4G//ev/ziO7utf/zrPP//8n0yn//sJ9COPPMIvfvGLdzz/3ve+x3e+8x1++9vf8h//8R/v9av9fcF77U0bbLBp06YNgX6/MjQ0xFe/+tU/K9DPPvssP/3pT9+5qfBf3uT69H3Ej5ewb/Yy8n9KHP9rK2MfUlB2BikYprh74TM8sPYwVcssemcCyy0eRj7sYOKjTmy3ePB1Z2jKSyyHzlGxzRE6UkDvTGK9PYxlsw/bbQGUtgjxYyUyI3Uyg9X1WK0jRcSOBM4D6wURvt4CemeC6NEC1i06oUNFtO4Mel8F/ViDwNA07iMVwgN1pF3hP+TYKl0pHJ0p9NFZ4tpZQsY5kuYl3H1FbJu92G71YdsaRuxMIB4pEgldIh66SlJbw3myjrInjWWzl9GP6VhbIij9RQTjNOHqnRSqN3AYZlCG6ih7Uwx/zMXErX60/hKW0Sqia5Hy5YewSNMYDDVC5jkmbg8z8kkv+okSNksZo7mMf/o8avMclugpvJ4V7P1VxraHUfqKSOYSJrmA7mvin1/BOnUKJX0KyTSNub+C1JfHaa0iyVl83gL+YB7fyhzK9DR25yyytoBimkEcLuOUM6TiJWLeBMFoHG06h+Rv4EqfwZc4h81QR9XyJCIFAnqAsBxAS3px+FME86cIT15E8M5hcRRJZyYpZgtkAykcJgdOX4hgeopQYRGlsMK4s046v0g6PkUmVUQxyUgmnUikSig+hZqYZtQ3RTS/SrKwTDjURBJD2CY8eNU0/nAV1dfAFJ5EDyyRLl3EHZzDrmQR1BjCWBRNzuHQa5h9kxhtNbzaErq+iNVWxaoVsZqzCKY85vEcgtJA1RdQJqYQh6rYLQ1MYg1RqmEzFDCO5pGsVUTLJPJAHcu+HPaBClZzE9UyhThRwzZcRDHUkUaqmLoSmNsTWLpSCCM1VOMk0nAD51gDzdDEcayEuT2OpSXOxPYw4v4c7rFJtKEmrrFJpKM5zF1xpK4k9pYo5u0RrK0xnH1FXCcaBMdn8J1sInankX83ObbvCGPfGUPsTOLrrxA62cR7pIS2L4Nrfxr79hDCjgjijijSrgj6vizBY1UCh8u492VwtsfQOuJILSHstwcRt4dwdiTx9xYJHMoTPFTAvSeGsz2OY2cQpTWCfYsfuSWCc3cUtT1G+GgR374Unu4Ezl0h7Lf519s8t/hxdcWIHMqTGqySGa2THW0SOVIkM9zAuy9DdrRB6kSFBf9ZzmWuMh9YJT1Wpq7Mkzc1uFS6zox2mou5O1nMrPCF+57lvoUHmQkvcbV+N4/f+UUuN+/ggQsP8cynv8wPXnmN1771Ouebl/jyYy/yyL2f5Zsv/CM//O4bfzJB/uIXv8gbb7zxjoL885//nMcff/xdBfvb3/423//+9zcE+i/Ie+1NG2ywadOmDYF+v2KxWHj66af/rEB/+ctf5sc//vG7lql8Zu0RUidr2Lf6GP2Qg+P/2cLI34rI24NkR+vcmHuAG7P301SX8HansW7xM/YhhbGPKFg+4cGzN0ndPs+8Z5WqbZZofxl1dxLT7X7Mt/rW/8i3BkmcqBDqy5IerOPqSuHvK2JvjeM8kEfcFcV/qIjcEkHfHcd6m47WFUduj+LYlyMwMo1+uEJgoIHvSBVhawD7bV7EbQHs2wPYdoXxW5aISGsEDXPEbUuInUmEbQEMH9cwb/Zh3RZAGawTjVwmFb1ERF1DPdHA05PDfJuPsb/XEVrC2PvyKMoC6am7iaSu4rDPE7TMI7YlGP6EC+uOEOrJCsbBAoHyJTJn7sfomkfS5wmMTjGyJYhpewTXcJnxkRyCvUbm6r0I9bPI+bP4PCuYerJMtMVxnaxgthSxmQv4ItOop1axzq3gSq0g2Kax9pdQB6rYTQUUuYhbLeLN1LHPNBCzk0iBORTvKWwjdaymIh5/nXikhtsew1PLIGfSOHwVgtXTSK45JqxV3J46hcI8itmHS3TjifkIxAqEslPoqTlGpTqu0Cyl+inyuVm0cTdOyUE8miKWLBJI1RnXaziji+RKFyg0TxPyJ5FHJUJqkEQ4QyBSwOTK4fDPk6pdJl24gNtfRRZcuM0efHIUv57C7spjl5qEE+cJpM4hKQ0kVxLHRASXlESyx7GKGezOOpbBIppjHpt9CrNWwS7mkcw5bIYkVmMWu1BDGKpi7ysgGCYx2BvY5EmsxhLG8Sx2SxWbuYLQX8KwO4m5t4BpooGizCFaJzEN5ZEMVURDHeuhHLY9aSxdSawnaut16YYmjpEqmqGJOlrDuj+L1JnB1pHE1pNDH5/BOdJAG5nEM1rHfjCNvSuB1JVBak9ibU3g6C3iGmgSNswSGplC7c2jHcgjd6aQOxJIbXHsu5Poh4oEBhtER6Zw9+bx9P2+wjuNsC2M2BLB1ZPD118herKBtzeP72AO9771LGjHzijC9iByawzXgQyR/jK+3hz+A1lcXQnce5KI24Lrk+odYdSuGGpHDL07jr47TrA3i9r6uzWQnUGELT5cnQl8+9JEDhWJHy0RPJAmfqxE8GCW6NEiyYEK6aEGs65V5r1nmXGeoiJMEzmaZVJeImussRw+z8XcHXzhnmeZT61wLnuNM4krLCbWuFi6g3sXH+LGyv08escTvPat13nlK69y84EvcW3hbp76zDPcuXIP3/7aq3zvG6/9iSA/9thj/OQnP3lHQf7pT3/KzZs3/6cpHa+//vqGQP8Fea+9aYMNNm3atCHQ71ecTiePPPLInxXoF1544V13pX/+87e479RDpIfrOLb6Gf5bif6/MjH0ARHxdh/pwSpXG3ezmrxMQ5jD05XA+EkXQx+UGP2IjOHvnbg645QsM5QNM2SGqwQP5RFbIphv82Pe7Me61Y9wm59wXw5XR5xQXw5tdwx9Xxp7awJtfw5ldxLX3gxKWwRpawDLbRri9gByaxRpf4Hw6BzO3hKx8Rmc+7II24I4dgRxbAti3+LHuidJ2LFM0LpM1LJE2DiPozOBvCuK6ZMexG0hLDtCuMVFQoHzpMKXCTnXcE/M4tqXxXSrD/vWALadYayHsnj9axTm7iOQuILuPk1CXMK0PcLErX7UrhSWQxlM/Xmy89fxzd3AGl/F5zuF2FdgfEcYZX8WsT/PaG8Sl2ee0MJVLI2zeKevIMszjO9LIfaWUEYrjJ9IIY3nidROY24s4Wgu44guYhemsA6UcIzXsUyUkM1lvI4KarWGWK8i+yq4c0vYxUnMhhoWa4VgYBaXOY/fn0GrxPEEMwRTFTzZeQxSHaswSSy1QiZzCvuAjt+rEIuFScSyhKJ5zK4yFucM8dJ5koWzxEN19BGBhEsnHQyRiCSxSzHMzgbx4hUyk1cJpxZwGlWCVpmE4iHhD6HIYUyWNKHMZZKlO/CEFlDVMG6jTkTxERL9qNYAFnMKpzRNOHUJVVvApueRrVG8jhi6FEMyhhCsGeyjFcyjZQRhBpOridVVw2bNYjMnsRhS2NUStvEyYn8JxTKDRZ3F5p7DItYxjmawGkvYbVWk8Rq23hzS0RKyuIDiWsJhncI4VMBhqOIwVhFHKjgOFbHvyyINNXFKizgss8jDNeSxGs6xGmJ/Caknh9SdQjpSxm1ezkHU9gAAIABJREFUQB2eQh2axDXSwDtWR9ifxL4nidSVRtybRTtSRT/RwDc2RXC4iXa4hPdYBa0nh3NvBqU7g9iZQt2fw3u0SvBEjcCxCr6+332J2Z9D6UwgtkZR9qZw7k3jOZDHeyBD5FgZ78EM7u4MWmcKYXsIpS2OsyOJryeLtyeL70AG1740gUOF9UKW7aH1Pei2OPruGEpbCH1PnGBvbn09alcU+xYf4tYAnj1pPHvieLqTBHryeLpShHpzOHdFyAxVCfcWqJjnmHYtM6OfJjvWpGieIXIoT85UJz82Rd5W40rlHr5437PcmHuAnK3Gou8MV2v3MOVa5kLtGjdmPs2nLz7Ei8+9xMvP/iNP3fscX/7c17hj5h7uP/cgV0/dxdef/QZvfP+f/+Qi4UMPPcSbb775joL84x//mBdeeOEdq77ffvttXnrpJf75n/+Z3/72t+/a/rrB/7e81960wQabNm3aEOj3K+FwmHvuuefPCvSLL77I66+//o5nP/2XN7lz6j4SJyoIW/wM/o3Iof/NwMn/YsO62UP8aJHV2EWWw2cpGqdw7Y5h+qSLob9xMPphGePHdLS2GKmTFVIDFXKjTcJHiog7Ikzc4sayOYCwLYhwe4Bgbwbf3gThQzkCB9cjuoTWJHJXBnVfDqUjjr4nsX6paYcXeWcIb08O6UCB4Mg0Wm+FuHEe55402u44ztYwjm0BpB1BHL1lYo5V/IZ54vJpghPzuPbnkNti2G/zIe8IYd4ZwWdbJOw7Qyx8iYjvPFHLHM7uDMbbgkjbg1h2hrAcyODRlkjW78Kfu0Y0cZnA2DSGHRHsrTEce5OMtkUQRqrE61dRi5dwli/gci9g2JfBujeD81CB8a4YE91xYukzKM2zWCurRKYuI1gmMR4poo80sBzLM9YVQjVX0arL2BsLqPkF1NQCNrGJMF7HNljBPlHB0Z/F563hmqqgp8u4wzX05AxmRx2LqYkqTONzzyEPJgkkwviCQcKRBH5/BilQxWCvo3lXSOUv4pJqSEMiIU0m4w+QDARwqzGMagVf7Bzh7CUSmbNo424igpWsQyWnuQkIboyGEKHMBZKN60Ryl1DFCH6jTF51UvToRCwa1mEPmnuWRO06ofxFZH8Z3RYgKrmJO/z4JRcOqw+HpUAgcZFg8gJSYAZHoIDbkcDnjKIa/Ei2CDZTHk1a3ze3ehcRYvNISgmbNYtpPI4k57BYisijdWRhDtG9jJQ4jeRdwDiewzCaxW4rY7fWkAYrOAYqOJQFtOgZVO8KhpEy9vESkqmOMFFFGawgHCkgDjdwu1bRnStIo3XU4d9lQA+U0U5WcRwuIvWXcRlmcY5OIQ/U8Y42cQ/W8QzVkXrTCHtSKL0FtBM11CMVtMMVtMMl3IeLhIab+Afq6L0FtIMF1J48QmcGtaeI91ARbW8aX1+eQH8Vf38Zd08OZU8apTuD1JrA2ZlE35vCfzC33jbYX8G1P4O4M4rSkcTZkUBpjf4h8tF3MIdnXwZnRwJhaxB5ZwRn+7o8O9ujyK1BlF0h1F0RbJt92G71oOwIoXVEce9J4u6Mo+2K4NubwrlrPaHDtz9NqC9PzTbPpLZCXVwkPzGJf1+G/NgkkSN5IsfyTGsr1FwzPHnXTa5P3sesa5WSPMWCZ41TgfMsh8/TdM/xzEPP84VHv8jn73+amw98mSfueIrP3/U0X/j006wWL3CueZFvv/gd/u03//YnEvzwww/zs5/97F1j7F5++WWefPLJdzx/8cUX+Zd/+ZcNgf4L8l570wYbbNq0aUOg368UCgUuXbr0ZwX6pZde4gc/+ME7nv349R9zpXKD9GAN4XYfgx+QOPy/TzD4X23YN3tJHC9xKnyWM5nLNMQF3N2pdYH+oIPhD0mYPq7j3pMgM1ilbJ6iJswRH6ggtcbXi1Q2+7FvCSDtCK1XAB8qEj6UIX6ijLYvh9qVQWhL4upd/0Tt78nh6Upi2+pC3h7E35tHP1TGc6yO98QkweFpXPuyePalUXZFEG8PIGwNoB0qETTN4zMukXCeIWicx3+kiKMtjnBbANttXqztCfThSYLaKrHoVeLRy8Rt84h70li3BZG2hZi4LYD1YJaAuoQnch5/6Q5qzXtQ+ktY2pO4DmYx3h5gdGcYt20WV2IVKXmG6NJ1RHsT86Ec2tEyjgM5hm73IRzKEUivYU4t4G6exVc+i9XaxD7WRD1RY6I7iWF3BLcyhZhuohTnkIN1lNgcJqGBY7SO5WQNaaCM0J9DC2ZxZjI49Th6IIMQqmGTGthHJ/F5llGGyriFKG7VRUh1EZYDuD0JbL4ign2WWPoyAf8q2ngMl9VEzqmRcahE7BqSGsbhnyOUvUyqfBVdKeExKpR1lYpbJ6sqSEYFOVQjNXU3kcqduKPzqEY/Bd1H3e8iJ2roRhHBkSRUv0aieR1n5jQOT46QEiHji5DQ3GgmFVmMo4WWiE3eiTO1ii09g6aV8XuzOC0hZEsAu5RClpoEM+cweGcwp0+hRBfQ9DrWiRR2IYvJmkU0V9CVOdTgKo7cOZyZsyjiJIahHHZjGYtURTBUkQ11RGEK1b+CFjmD3TaDfbiCw1BDmKjiGKuhjlaxD1RR5UV0ZQnhZBX1ZA3n6HrJij5eRx9r4DhZQR1qoo5O4TheQ+ktoh8v4z7ZQD9ZR+jNoB4t4TfM4DhYwN6dRe3Jo3ZncR0q4B+q4ztRw3u0jqe/gmNfFmF3Amd3BkdbDK07h74/T+BYnfBAA2VPBml3EmFXDKklgro7gdqZQN+bxr0vg3t/Frk1hqMjjtKeQN4VRtzqR2uP4+5K4WyPI20PImwNIbfEcO5OoLWvF6ioO8OYbnVh2+LF/HEX5k+6kVvCOH8n31p7FGdbFK01iu1T60kc8s4wod4cJess09oKVdssycEqwZ4cRcM0gf0ZosfypIbK3Jh7kLXqedbSl1iJXmQ1fpHYYJHL5RsseNa4Ur7Bhfkr/NO3Xufawg0+d+fn19sHP/dVPnv5SZ6+/znONC7wwI3P8G//9qfy/Pbbb/PZz372XXecf58RffPmTX71q1/9yfnzzz/Pm2++uSHQf0Hea2/aYINNmzZtCPT7lcnJSZaXl/+sQH/jG9/gu9/97juevfHaP3Pvqc+QH2kibfcz8kGJ/v9kYvADNsQtPuL9JU4nLnP3woNMyUt49qUx3+pm6O8cjHxIwvhJHXdngtRgnZp9lpowT3KwirwrhuW2ANYtAaxbvDjb4ni70yROVPDuSRAfKKN3Z9H3ZxHaEnj6Ssi7YoSPlHHvTWLZrOHcFUbdmyFwoobaW8I/OoPnWJ3A0TK+3izi7T7E2/2ILWG0QyVcJ+oE7SvEtHNEJmaIj04jtkSw3+bFusWH2JHC2V/CIy0Rjl4lHb1K3L6E2J1F7khg2exjfLMPqa+AT1lA8SwTa96glL8D25ES6pEizq4Uw3/vwtASwS/PY3XPIkWXSZy6C8NQCcvJCp4TDQzbowx9yoNrrI7dN43RN4krv4I9OofR1kQxNLD2FRnbFUHozSALZczeInZnHtlfxhKawiQ3sZ6sYx+oIx7O45zIo/kSaFIYTY6ixfOI8ToWUx2nvIhHWkQ5mcOn+Im6vKTcAaK6H1cqgV2r4gmeJZy+jNPcQLd4CQp2ql6dstuN26XjCOfw5C6QqN+JN7GGOBEi6/IxGQ3T9OkEBQFZDxCZvkyofgeRyWtYnQVCWpRyPErVFyJkE5EEF5HqMsnFa4Sn78CQnETXC6TCebKROB6Dhih4UF0VYjPnCc1cxlReQYzP4fVX8TjziCY/khpDEnLo/mm8xVWGQlPYS6fR/XNIQgWTKYPZnsUmlHBYK6jeBYTwEo74Krr/FHZjDbupikWsY7VWcZiqCIYasmcRV3wN0TqNOFjFMVFHnFg/UybqiMNVVMs0bnURx1gT4VAJ9VgJx2AVp6GJNlZFHq7iNs2gjjUR+ysIe9PIB4s4enLoww1cQ3Wko3n00Try4SKGjgTK3jRSewqlO42zN497oIbneA3v8TqO/Rns7XHsu2LYt4WROxPIXWn0/VmCJ2qo3RnsbTHsrVHkttj6V51tIZT2xPq0uSuF3J5C7Uwh7oog7gwh7AigtkZwbA8h7QgjbAmtr220xdD3JFHboiitEeTtIRw7wxg+7mTiY05st/twdkRx7Ynj6Yqj/W6KLW0JYN/iQ2kJIW3zE+8vUhPmmVSWKVlmCPfmyAzX1wuTjhbIDNXITTQ4V77KI5c/R1NfZC5wmhl1hcXAGfLWBqcjF7izcR/fevFV7jh7Fzfv/xJrpYs8cddTPHX3szx25Qs8c/+X+OoXvs5D9z/8rhPkt99+m8cee4xXXnnlHc9+nxH99a9/nR/96Ed/cv7ss8/yi1/8gt/+9rfv9Wv9fcN77U0bbLBp06YNgX6/srKyQrPZ/LMC/corr/Dtb3/7Hc9+9pM3eeTKE+THmzi2+xn5GzvH/rOZ4b8VsX7KTaQvx6nQWT6z9ihT8hLe/Smsm72M/zed4Q86MH/SjdYaITvepCrMUzJPkRioou2OY98awro1gHmzD2VXdH1SPVLH25Ug1l/EcyCDfiCH0JFEP5BHbksQ6Mnj25/G+CkV95446p4U3sNFHL0VwsZFtIMlYkNN3PuzCFu8SFuDiK0xnHvTOPrKRNRVIo41YhNzhEamsO8MYd/ix/QpL0J7HMeBPJptkVj8KrnYFYLGOYQDORxtUUb/L42xWzwovXnEsQayfori4gP49VXM/WVc/VXMm4MMftSJtS2OamoyYSjjr17ClVllZCiPY6KJeijP0Cc9GLaH0I01xs0FbGoDrbSMNbyAyTmFPNTEtCeLoTWCfrKCXS5gUwuo7jL69DzW7DySMIV1sIZ0vIZ0OIcqZXE6k/g9ccLxFNp8HTHcwGKbxec9gzRcQzGlCPoipHwxsoEQ4XIMZyGL6J0jULyMy3camyFD0B0l5HBSjURI+N3oGQ+u3ByJ6Sv4K5ewKjVcSoJqKkslFCLrcuFURMK1OrH5syQXr2LLLyGqRXKpMvlwnqQ7gGa34wskSNSXiM6cQZxcwxabIxyZJpVu4BFiOBUdhy1MONUgVJhHKiwi1lbRwguEo/NIUgZRiSLLCSRrBm+0iRifZSzSQA0v4fEuYrPWMEtFrM4SoiWPYClid02iZVbRfcsolkkcpkmsQgOLrYZgqWIxFbFba7hCy/8Pe+/1nfdZ5+36L9jzbmbWu9deA0MmQEjiKrnIVrNkyZZtucjqT//139N7773oUa/uPc0QEkpoSZwGmEBCaGESIAmsoc7QYYJn1sxc+0CBPUxgOHjXIgfxdSZ9H53eunTre38+qNIsyrEq0mAFydBAMNfRrE3EiSqyqYFumkaenMK6L4fYn0c4UEAzNNEnGkhjNZymJupYDUtfFltHCrk7i9CRRj1Uwj06hWOkju1oAfFAHlNHEnF7DNv2KHJHCrkjgz5QxD3UwD88hd6Xx9aewLY9gmVzEFtLGHFXDHl3Cu/hCs4DZfTeLFpnGqUtjm1LEKEljG1rCGl7GL0jgas3h2tfFkdXCmV7GHl7GHlHCHHbujSL2wLobXHc+zKEBkrYd8dQWt6Iu9sZRtziZ/K9GlKLH3t7DP8bO9P2tjDOtijiZh9KawhxUwB9Z4j40QpVyzw1cZ68YZrwQJ7s2BS+vUmyIw0SR8ss+M5wrnSZK837ORW7zLz3JNnJOhcL91MT56nIM3z45CO8/MK3+MKnv8T55lU+cvYTXJ6/l4fWPsaNjz/H9WvP8LXPfYMf/eOPuf7JJ3no/of51S9+9Ucl+dFHH+ULX/jCn0zZePXVV3nttdd48cUX3zR/+umn+fWvf81vf/vbt/pYf9vwVnvTLW6xYcOGWwL9duXq1avkcrk/K9Avv/wyL7744p9M4Xj64RvkJpuorUFG36lw9G9sHP/fNsx3OAn25VgNnuOhU4/Q1Jfx9aaxbQ5guN3JyDsVDH/vQN0eIjdSZ0pdpGycJnakgqc3jbA1iGVLENtm/xuVwHGSQ1VC+3NEDhbw7suiduZROjNonUmcvVn09hiezhTG9+u4u1OorRHsPWn0gSrByQXs/WViY9NobXFsd7mxbvIgt4QRW8Kog3XiznMELEvELIu4DlexbPZher+Lsb93YGsNY+1M4tLWiESvkg6cQx9uoB3II2wLMvJuO4a7fMg9KcxHi7gT5yguPohsnkMam8IzWGb8PS5G3+vCcSCPdayM0Vghd+5hBN8io0KNsLqMaWec4fd50PZlESdKTFqLuJJLOOcuYM2uYQ+tIgzXGWuLIezNoBorWMQCdmcNf2UeefUkYmUJ0TqDMNFEPFhGGysh2VIEAkVCgSzB5Qb6WhOrdwrNs4RdW8I6XEbXskQDBTKhFLF4HP9aCnumgqe0hr9wHqswhaDmSEcqBJwBMv4I3ogdbzpGenaZ2MIFpOgyJrlMNjdLLpqnEMvgstoIhFyky1VSUwu4p1cZ800Ryy6TzSyQiZfxKypuQSOTzpIs1/DmmxiyswQLp0lWTuP3NnHoYeyig4AcIZYo4oqVEVJNnIk1UsWLuH3zSGoO3RVHM4Zx2zPo/jJadBqDXsfjWESTFxCkKjZnEVnKIhhS2CxZlNAMincBdaKJMFTDam1gtFWQ1DoWcxGTsYgk1pBsTcQjRax9OSxHKthsTRRxBsFQxTpRRrFOYztRwNSVROjOYupMI56ooZmmESemUA0NtIkatkNZzHsSWHbGMW+PY+vJYB9uYB9p4JpoYhvIYOlOInWmEHbFMbdEsOyMIXdncR9vEJmcwXOshtyRxt6dRtwewdYaQdgRRdydwNGXJzjUxHO4gqM3i6Mrg7IjgrQ9inVTEKk1inNvFt/BEp79Bdz7sri6UjjaE0gtYeQdUWxbA8jbI7h7s4QOlwgfKuDuTLxR3x1GbgkhbFlvK7Ru8ePuShI/ViLQn8XTlUFpCSJu8SG1BBE2+nDsihI9UqRinaVsniU1VCFzvE74QI7w/hypE1USx8osek/zgYWPMu1dZsa5zIy2xlr0AsnxMsv+sywFz3KhcZVnH3uej575FPdPfYirM/dz79wHOVW5yBMPPsNnHr7BN774Tb7/6g/4ytNf54mPPc39F67x7a+9xq9/+es3SfDjjz/O9evX/8eUjZ/97GfcuHHjTfPr16/z+uuv3xLovyBvtTfd4hYbNmy4JdBvVx5++GEikcifFehvf/vbfPWrX/2T82c//Tx1aR59d4zx23QG32Hi+F/bML3XSaA3y5LvDPfUP8i86xSRQwXEliDjt+mM/53G+LtV5C1+UkNVKtY50iMNIocKuLrTmDYGsGz2Y9nkQ9ziw7EnTrAvTaA/g2NXBHfv+v6z3ptH3BnDeyCPujOGviPE+O0KSmsA22YfYnsS19Ep3ENNPIN1IiemEbYGsd3twfx+F5a7PFi2BLAPzxDWThGyLhMTVlB7s8itYUx3uDC8z4V5cwChL4/fc5p47DJh11nUkWkCR6pYtwQY+XsHpk0+xIEswkSNSPVe4tX7kORF/Ooq+r4s4+9zY97kx3G0jOFoDs27TPGej2EKr2B2zeK3LjHREmFySwDn4SKG0TwWU5nEqauoK5ew1M7iDp/EcrTEZHsC+9EK5vEiNmuBQGQW79kzCGdPo2SXsagziBMNbINlbONFdK1COFTHHy7iOD+F2mygRWdwxFewTTYwGcu49CrZ5Ax+NU2gFMVVieLL1InNLqFHFhmzlHG7p8hVF/FqMbyig1BaI1PKkShXCTRnGXc1cAYWyBVXyRcWCKg+AoJAMR2jWMqTKBYxhcro8SUylfNkq6fw+ZK4JyWyTg/5ZIx4PIUSzaKF50nU7iGcOovDVcTr8OAzOEi4gsRCMXRvCtXfJBQ/iydyFkFoYPcmcQph3FIYuxBDc6bQg1OYR4tIxmlstiZWZwXFXkK1pLAaYwhiDsleQ5psYD1QQhhvYBCnEF3TWGxlJicyiLYqVmMZy+Ecpt4s5n05zJYpFGUW0TKFaayEal1f5zD1ZxC6k5g6UlgOF9Ets4jGKTTjFPp4A2WkgrUng9iVwbo7jrUri3K8jn2kicswjWe8iaknjtibRupIIexJYGmLI/Zk8AxNE5yYIzwxg9KTw3kgj7IngdqRRmyLI7QlcO0vEByaJjI2g2d/AV9/Hq0jgdqRxLotjLAjgqMni/9wlcixGv6Bwhsxdim03XHklvV8Z3l7BO+BPOnRKcKDJfx9WTw9GRx7EohbQkjbgsgtAex74qjtYSKHCoQH8gT351C3r8fYiVv8iFsCuLuSBPflSB5fl+TwgRyJY2V8vSkywzWC/Xmyow3mvWtcyN/HrGON5FiR1HCVU7HLNLUVstYqZ9NX+ejFT3B5+j4uFO7lSuUDfPjUJzmTusiVuQdYzpzm6Yc+y2vf+C6vfeM7fPZjz3LjE1/k+oee4tLqFV598bv8+HtvTtu4fv06TzzxxB/dkf5dysbvar//2M/+9re/vSXQf0Heam+6xS02bNhwS6Dfrjz22GM4nc4/K9CvvvoqL7zwwp+cP/mhZyhb59F3hRh/t8aRd1g4+tcWjLfp+HvSzDrWWA6cZVpfxteTxrzJx8jfqYy8az0LWtzkJXqwQPJYhejBAv79OZRdMYx3+TBv9CFuCWG924urO4G2PYhvbwKlNYS3N4O1NYqzr4S4K453oLh+K7bVj/FOB/K2AOq2IGJnisDwNPaDVQInmngHq4gtYZTW9Vsxcasfc0sQv2WJkLBM0LxMVFxG789h3x3H+H4X4rYA5k1+lKEqId85kvErRLzncVkX8R4uYdrow3SnF2VHFGtfBlWaI7fwIUKle9F9p0l4T2PZGWNyYwBlTxzhYA7DwQyJ6XuInn0Ya+YM9sgq8lCNiR0RpO4k0pEiE4fTKEKd1PlrWFYu4Fi6jMO1iOFwHsuBHOpQCcOxLKqhSCi9jLC8jLSyipxeQPXPYx6pIp6oYp4o47Q38EhlfFNV1PkKjlgZf2MR2T+L0VDFZKgQDi4SdNbxaSlClSCxXJJEqUi0OoVRr2MSp4hkT5POriGPefA5JIppL4V0jHwuixIsYHI1iWbOkyicJ5GcwXlCIOdSmEr5qWSieL1hBG+VeOkKyfpVPKEF3DY7UaNEyeGgGPQS8/qQ7RkCybPEClfRPQvo7ih+s52E4iKmuHFLHuyeFE5lFl/0LLK2gOwv4dAieMUwXjmI3eDH4UgiGipMHMkgKfOYfbOIvjqKnMNmiSLZkkhyHttoEetADnmsjsW5gM23hFmuYxhLYTHnEaxlxIkKlgNZrPvzCNYZNPcyojCLYayMYqohG6rYjpYQ9+cx96axHa+iqysIxhnUyQb6eA3d2EAaLKEcKCD1ZpD6C2hjTfSJWZzGWTxjTVwjdSw9CaSeNFJ3GnlvBqW/iHtoGt/YLKGxadyHy3gHq9j7cui9OZSONNZdMbS+PP7jU0RG1+vo/Ycr2Pdlce3LoncmEVuj6N1JHH15vAdKhA6XSY408O0v4O5Zv6UWtgaRd0Zw9+bw9+fx9+cIHMgRO1bF25tBbAkhbA2sNxHujuHpTaPsCRI6mF9/oNsaRtoWQNwcQGkN4OqI4+9L4d+fJbQ/T/BADm9XAs/eJMkjFQJ9GUqmGVZC51gKrSf2pI5ViA7lyU9M0ZSWOR2/TEWf5fEHn+FS7X6qyjwXC/dxLn2VK5UPcP/sw8zHVjjXvMT3Xv0+Lz33Ms889HmeuPYM1x94muef/DIn62f45lde5cff/+MC/dxzz/GjH/3oT6Zs/G5d41e/+tUfFeibN2++1cf624a32ptucYsNGzbcEui3Kzdu3MBms/1Zgf7ud7/L888//yfnH7/0GPnJKZSWIMN/K3H4r4wc/V8WJm9TcXUkmJKWmNGWmdaW8e3LYL3bx/Dfyus30Let13mHB3LEjpTJjtaIHSuj7Y5jvNu7nq+8JYiwyY93bxJ7W4TI4eL6L+SBPLYdcZy9BZTdKVz78mhtUfS2KGKrF2WbH1dnAqUnT2B0BvuBCjHDIq79RRx7EusVxC0BlG0hxM4kIWGZgGWZsHCKsLiCe6CAfU8Ky90+tB1hrC0hnBOzRLxniMWvEg5eIGo/iXOgiPGNpBB5TxRjewK3skx+/iG8pXsI5u8hpq4w2RrC2hbH0Ztloj2M+WCWTPNeHHP3oM5cwR5exjSQw9STwX2ohLEnzXh7lJB/Gcf8BYSFc4SXriK65jAOlVCGKlgPFzEcSKOOlvBVlpEWF9Erc7gqC4iuWazGGpYTVRRDA3W0hEct45vN483l8afL+CtNLPYqBkMNTZojFF5BG84RDniIxz0U0kGSiST2WBGDXMbjO0kseQG/fx5xUCBpl6iH3DRSXiKeAFZnGl/8PNHCVaLZ8ziMfqJGkZom0Qi6yLjsyFYf/uRJ4rX78Scv4HRlCJg0SppCSVXISjJ2swPNXidavodA8gJaqI5Hj5JQPWQ0FyGbjEdwoZizuDxruKLnECML6NEqLi2DTwmij7vw2MNYLWlkQwOjrYY1sIyYWkL3NrBZ0lgNCRQlh8WSRxqroEzUsXmXUbJnUCJrmMZymA0FbOYSoq2COFrGdqSAIMziip1F85/COLGe/6wYqkhjZZQTZWwH80jDdTy+02jaKqpxGm2sjj5ZRxuu4jhRQzpQQDpUxmmaQzfMYp+cxTPaxD1Uwztax9qbROnPYT9UQj9SQx+sYT9SxzfUwH24jP94jcBQDfehCnpfAbkrg7Q3h7O/iG+ghKs3S+BIBf/hCsEjVdwDRcSdcZT29Qxo594Mnr4svv48/oNFgodKqHsSCFuDqLvj2DsT6HuiuDrXs6D9B3I4OhJIraH1taqWMHpHHHd3Cu/eJGKLF31XFNsmL+Y73di2+FFbQzjbY/h60vi6krg64ri7k2itQbx7k7i7EoQPFCha51mJXWJKXSY9VCHUl6MmLODqilKPu6dtAAAgAElEQVSXF2goK9zffIj7Vj7A+fJVmvZFZjwrTKurXKl+gDOJy1yb+zBnpy/y4Wsf5vnrX+bpD32OT116nC9++kt84uJjPPHgMywX1vjWV17hN7/+wyrv3/72t1y/fp2XX36Zb37zm380ZeMnP/nJ72+j/3tj4e8E+l//9V/f6mP9bcNb7U23uMWGDRtuCfTbla997WuMjIz8WYH+3ve+xxe+8IU/OvvZz37GR89+ioptFn1XlLF3yQy+w8TRd1gwvseOtztJU1thOXCG5cAZoocKCJuCjPytyvC7ZMZv01BagsSOFClNTlMyzZAerqG1xbFu8WPa6EdsCSNs8hPYlyHUnyN2pEjwQBb/QBGlPYnSsV4iobUn8ezN4OlKobYFkbYG8PZlcPSXCJxoYj9UJWJYxNWXx9ufw74ngbI9iLg5sJ7SYZjHa1ogaj9DVD5F6GgVrSO1XgaxxYepJYjzxBQR12ki8atEopfJ+c+h9uQxt0TQ22KYNocwtycJqEv40pfwVu6jtvxhHGNNjF0pXP05rNujjGzxoY/V8GfPI+ZOEz51Ddk5i2mwhDRYQu/LMbotgLU7QSh+EmtuEUfzNK7aKaz6DKbJKsqRCqb9WSydcZyGKnpuCrXSRI2WceTmMDoaiBN1hGPrNdLiQBa3J40rGcMfjOOPJNATZcx6BevEFMHAWezmaRxjYYIOnVzARcbvIewLovpTSOockfhFwsnz6GMJ3JNGCppOza2S1TV02YkemCFYuEqifB8ORw3PhJOG28m0x0lZkXBOimiuPLHmvQTL9+BMLmGXw+QdPmouFyVVwW8UUKQIgdwZkrPXUDJrKJEyQUecnDdKTLLjM6roagS7fZpI8wp69hSW4iJ2XwO/M4s2GcSlhhGVOLK5jDe6yrhvGqF6BiW9imavYp6IoQgZrFIGyVRBlaZQomuolUtouXOIYhPjWA6btYxJfCPrebyMKE3jSJ/Hnb+AVZhDGquhGeuI41VkQwV1so40WsfhXEG3ryIaptFHp3CMNpGHq9hH69iH62gnangsC6jj0yjH6mgDZVzHa7hHmjhP1LDtT+MaquEemULan0fqL+E+WEHrzuI+VMZ7vI73eB3PkQqO/SXErgzSnhTOngxaRxLnvhyuvgKhoTrug0XEXQnk3Qmk9gT6njj2jgSOjgTuvvVMdbkthtASRt2dQGtPILWuV3U7u9f3orWdUYSNAYQtAcSWII6uJI72JPZdEbTtYYx3OrDd7cZ6pwfrJi/S1gDOPTFce5N4OuI42xOIW/xIW/w42mLoOyJEDuapCvOshS9StS4Q3p8jPVQjeqC4/s6hP0HBMMO1+Q/z1EOfZSl6minnMnnjFA19kbXQeRa9ZziXvYdnP/UcH732MU7Xz/PoPU/wzIc/z/Vrz/DpK0/w2Y89y2MfeJorJ+/lRz/88ZsE+Te/+Q1PPfUUP/zhD3n++effNP/c5z7Hz3/+c27evMmrr776B2kdv5Pv119//ZZA/wV5q73pFrfYsGHDLYF+u/Kd73yHQ4cO/VmB/uEPf8iNGzf+uED/9Gc88cGnmVKWsbdFmLhtfYXj+P9txfg+B/7eDIv+09w7/SDLgXNEDhWxbfEzdpvOyLtUJm+3o+0MkRgs01RXqEnzZCem0HbHsW1ZX5uwbV2v8g4eyJEaqhDsTRM/Xl7/l3N/AWFXAueBMnJbDP9AEX9fDqnFg7TFi6snje9IHefBGu6hJv7haTwDRSLHKijb13Nu5ZYQjn0FXMfq+MVVoo6zRKxLJCbmkTsSyC0BxC0BLNsjOA9X8UhL+GOXiSfuIe04hdybQ9ubRmoJMvY+L2JXmoCyjOo9SahxP+W5DyIcLiMMFHHtyzF6h4uxzT6C4gJSYD06LXnqAcYmSkwOVXAdr2LaGWP4fU6cx0po/llM0XkcmRWk9DyTSgObqY54uIyhI4nQmcBhKyFHSqj+PJovhy3VwOCsYhuqIo9MoQ6W0YYy2NUgLnuYgDeKL5JCThUxW+o49FX8jpMoRwu4ZR8xp5usw0/a6cYRCSB58nii5wjlL+NUF1AnAgTNMvWgm7rPhU9WUENRApVzxOv34smew2ZOkHCFqYei1N0uIqINTXMRmT5FcOYi4ZnLmEI1fFqSQihGLRQlbBGwiw78iQa5tav4Zy5hLCxiD1SJB4pEvXE8Bjtuuwe7liM2tUZ04SLm+knk/DKeQBOHkkW1RVHUMKqYweGdwt88zVh2Fql5FjW4iM1SwmbMY1Kz2OQiilDBHphDzZ/CWbuEPXQS60QNwVLFKlaxmcuI5io2ax139CSuxFkEaQ51bAp1sokwUUM01VBMdcTxGg51HqdrGWVyCulgGf1oDXW4ijrWQB+to4zWcQvzyCeq2AZLqH0FtL4C6qEyzpE6zpEG1v0p9OEGYl8ec2cKbW8WuT2JfX8ex0AZ17EGnmN11P4its4k1rYYyu448q4oWse6SDv7C3gOVpDbk0h7Usi7YyhtEcRtIZRdMbT2JPauNMquBGpbHG1PAmV3HKEliNwaQt0eRd0RRt0R/f9vnffEcHUmcXTEULcHUbeHkFuCjN6mYL7TjbDJj74zgqM9jr8nvf7ocFcUcaMXeZsf4S438rYAoYE8dWWRBf8p8hNThPfnyI408HenyI83iR0qEhzM8oGlj/D4tWc4Fb/EYuAM8ZEys75VCsYmZ1NXuVK9xldvfIOXXvgW9y1+kPnkCjc+8UUeOfcoNz6xnsRx45Ev8NKXv8ljjz7Ga6+99iZB/sUvfsFnP/tZfvOb3/DEE0/8yZSNmzdv8pOf/ITPf/7zv5/9+te/5umnn+b111/n3/7t397qY/1tw1vtTbe4xYYNG24J9NuVn/zkJ3R3d/9Zgf6nf/onPvOZz/zR2S9+8Quee+IFpvVVnB1xxt6tcvQdFo79jRXz+1x4u5PMOk/yyKXHWA6dJzxYQNgSwPheF8PvVJi4XUffGSVyqMCMfZmKbZbcZBNXZxpbaxjTpiDmTT6U7WFc3Uny41N4u5PEj1fw9uXwDhQRdqVwHSwh7ogTOlTA15PFssWFtiOMuyeNuy+L3FcgODmP52gd32CFwJEy4jY/2o4QUmsArSuL0pPFL60SUc8QMi4QGp1B2hVD2uzHeIcLW2sIvTePZpolEL5IKn0PfusSlp4seleCyffYGX2vC3lvCrt5BlGdJzn3AUKRcxiOlNGPVRBaw5x4t329FlyYxSDU0MMreGrnGZ4oYTFNoR4qMLrRz8TdfpwnKhgsRcxaHTk6g1BYw+CbQ56YwtSfx7Q7gX6wgE3IYpNSaGoGV6mJUJtH0OtYTtSxT84i9udRTRkcjjgBV4yQL45jpoQtWcUmTuMPnkWdbGIbTeF3hkm6YxQCQcJRH1oxhhKcxl+5iDd2BtNEDrcWJex0UQxFSHtduCIavtoUifkLhKYvY/JMo6sZitECpUCcrNeDW7GRbJTIrJ4ktXwBW3kZwV0jEatQSpaIyH58spWQP0p5ZYHU6hrK3BpCcZFgZJ5IpIbTFsXrcOHRg0TiJVJT8zimV9BWzuNKnMQbnEOUckhqHKc9hkPJ4E82UFKzGPLTOHPncToXEUx1LHIRUc0hi3kkoYgcmcFeOYUztIpknkUyTGG1TmEWSohibT2FQ57CGV5BkGYRBytIRyrrDzWFJqKpijBRRbQ1UK3TWEcrWPvyKPtLCIfKaBNNtMkG0lgdlzCNdTCPYW8SW3caoSOD1JNDPVrFNdrEOTqF9VAO4UAe454Etl1RxLY4SmcapSeLfqCE90QTx2AN/UAB254EYlsM86YA0s4YSmcSrTONs7+Avb+Avi+LvTONsjOC2BJEbA1j3RJC3h5BbU9i70jj3JvF1ZNB3x1D3hZG3B5Gal3/74+w0Y/UGsbVkyIwUMDdvp7CobRG1m+VW0OM/b2C9W4P2o4wvr4sru4EalsI2yYPlrs9GO9wYLzDjuVuF67uKNETReIjRVxdUfTOEOquIPJOH1pnENfeODPOUyznz/DwyUc4nbzCjL7Gyfgl4mMFCpYm895VHl57hJe//G2+/NRXefyBZ/jIpU8wF1/m8QfeaCK87yme/eRz/NMP/pl//O73eOrJp/jKV77yJkH+6U9/+nsp/t1t8n+dP/HEE7//3n9/SPg7+b4l0H9Z3mpvusUtNmzYcEug367cvHmT7du3/1mB/ulPf8pTTz31J+evfOM7zLlP4WyPYrjdwdD/I3Hsry0YbrPj7ozTUJb5+KVPcTJxkdhgEWVnkPH3rOdAT97uQN4SIHKwyJSyTF1YIDc+ja83g7UljHlzAMsmP8qOMPrOCOnhOr6uJLHjFVydaew9acS2JM6+AmpbAu++HPqeKNa7nWg7gqg7I2i74yj7i4RMi9gHKkRGp3HszWC9y41toxfrJh/yjihiT56g/TRh5RQRyyLu43WE7WHMd7oZfbe+nq/bmUCdnMYXvkAmcQ/2sWmkQyWUPTFOvEtj9HY7SncS89ECsr5I6fSHUeQlBMM0wYkZxu/wMHS7E7UrjfVYgYmhAtHmVdTsGYbFBl59BaE/z9AdHqTOJNJwiYmJPJq7iXPmNJbKSeTECvLEFJPdaaxdGZThIgZDGoergidaQV1bQZpeQJCnEa0zKENVbIfziNYMQX+RkDePv1pAO1VDDNWwh5dx+FYxnagg2TJEvEWy0SyJcAz/Ugh3OU+guUK4dhaz1sRkLpBO1vFoEbKBBAG/SLwRprA8R3rlJEp+gTG5TDKzRCZWIxvNEVJtJKMOyrMlKiuzhBdmmYxNE8qtkS2tEPEXCdjthFSdcjZNvlokVK0hNWfxF84QL5zF427i1MMEHU4iqpdcPkswV8RebOIqnCaeu4Rsn0EQsrh9CTxSCI8jhu7L4y7NMOmuoevLSJYZbFIDq72AqhURTUmschZHYhYtMIsw3liPsTM3MUl1ZK2B0VLEaswjqvX1bOiBApb9BazHKljFaURbE9tkHZutjmSuYRrMYe7JIu7LY96bRRquolpmESYbOMQZ5OEypoNZLJ0prO1JrJ1JhL486tEazrFpXMZZjH0JrD1JpK404q441h0xbLuTSD0ZnMfr+EaauI/VkLtS6F0pxJ3R9bzo1gjC9ij6vhyB41N4DlZw7svg6Eii7U4gtoSxbgliawmh7I6+seqRw7Uvjb0jhrQjhHmTB9NGD4a7XBjvcmLbEUTdE8HeHUPY5sW0ycXE+3XGb9cYv0Nj4j0a43fo2Lb7cO2LYu+KIGzzYrzDgelOF6Y7HJjvciG1BPH2ZyhbZylbZ4gdLhI/WsLXkyF5vEKgL0f0UJH0ZJVH73+KojbFyehFZvQ1ziWvMiWvkhNqlMRpri09zAvPfI1P3fMkD5/8BE8+dIMHVz/GauXUG+2DN/j651/ix9//Z7715Vd47pkX+PgHP8WjH3/0TQL94x//mOeee+4PWgX/+47zf/36ySef5De/+c3vb6SfffbZWwL9F+at9qZb3GLDhg23BPrtyn/+53+yZcuWPyvQP//5z7l+/fqfnH/r699mJXIeX28S8/udHP8bkaN/Y2H83SrO3THqtgUemH+YBd8ZYkfKKNsjTNxuZ+SdCmPv0rFt9BIeyFOYnCI3Xic8UMC9N4lpkx/zZj+WjQHUHRHklhChAzlc7Uk83QnUXRHk3QnErgxqRwZnTxa9I47cGsT4Hg1lWwDLRi/ijgj6wSqBiTkcByvExueQd4SxbvRgfb8X810ejHd5EfeXiKinCdhWCNtW0A7WUNuiWDf6mbhdx3ynF2t7HIewQDRxhVjgPJphHv/YDNL2CMO32THd6UHuTWM4lCOQPE9m8UPI+iouxyqeoxXG3utl/P0u7PtzTA5mEUx1Svd8BCF3lnHfDH7HKsb2JOObQtgPZDEey2IeKxCunMZx+gqm6bNosVWE8RqGvSmkg0VMQzlspjzBwDSBxRWsl9cQy/PYPDMoyizmIyVMw0U0sUw02iQUKuO6VMO+XMWVm8FbWkOQphgfL6HLNTLpeWKhCoF4gMBMkMRcjczyAp7sPCPWEi7nLKnsKm5XhoDmIp6WKFcSFGdKZJeaTHjLOIJLJLOnyFXWCDnDhAQr04UQzUaSQjWNlq9gTy+TKl8mmjmJy5kiJEpkNZ1GNkghE8WfTuLKLhEpXsYXOomiFgm4PITMGlmvj3gogD8aw5uZJhA+g+ZcxmKt4fCl8GtRvGIApxQkEMngitSYHCsgTDSRlDksjjKqu4IkpDEboqhaDt1ZxWaoIxytYhuvM6lMITinMclVTBNZRLGC2VDEcjSP7VAB64E8ZnMTUZ7DampgsTSQLTWE8TLm/jS27jSmvRksh/IoljmEiWnslmnU8QbyiTJiXx6hK4VtTwJjRxrhYBFttInbsoDH2GSyM4ral0fuTCJ3pTHtimPZk0Q/XME11MA73EDqTqN0p7DtjGHbGcawJcDkJh/mthhKXxZ9IIutLYx1RwBTSwDDJi+jd9oZfZ8Tw1YvUlcM+74UemcUtT2C3BbC0hLAcKcb411uLFv86N0pokNVIkfL+PrS+PpySG+8HRA3BxC3BrC3J1C7g5SMs6TH6ni7U0hb1x//Cpu8yNtC2HdFCR/MUzDNkB2pEz1SInowT2B/lvhgEf++DJnRKdZiF6k5p5lzncLbH2fefZol3xkW3Kc5nbxMRZ3mTP0Sj1x+lHsbD/Lg0se4t/4gDy1/jI9ffoyZ2CKfefjzvPqN7/K97/yAG498kWc/+TxPf+yzPPWpz/DAhQ/y61/9YQ70D37wA1544QVu3rzJP/zDP/DKK6/8jwL9pS99iR/84AfcvHmTH/3oRzz//PO8/vrr/Pu///tbfay/bXirvekWt9iwYcMtgX678p//+Z9s3br1zwr0L3/5Sx5//PE/Of/a519k3rWGqyPBxO12jr7DwpG/MjP6TgX7zjAVyyxrsQtM68uEBgoIW/2MvrEDPfYuFfMdLkIDOZJDNaKHSgT6Mzg7k5g3BTFvWa/zFrcGkVqD2HdF8XYm0baHcHfFsbZG0XqyCLuSeA4UkdsiKNvCWO9yImzxIm3yY9sewTlYx3W8gfdYg8DwNNKO9Rg7211uxM1+jHd6cI9NExCW8dtWCAuruIfq6G1xjHd6sd7tw7rZj21vGp9+kkTyMuHA+fVab+Mspk1BJu7wrBdK7E1gO1ImN32NSP0BtNBZYrHzCHuzjG70I7fFkA/kmDyQIRg9RfqejyJUziNEFrGbZxhri2LtTKIcKjBxMIlsqZE9ew3xwlWU1UtooWUshirmgwXkw2UMRzI4bA0CwQUc504hXVhDLc2jp+cxm6qYhsqYhou49Rl8+hThYhXHap5AuUxkcQFXappJUxnTeI1QYIVQcBG/kiZadJGrRSjUMmTnq1g9FcxCg3DsLMnkGWRrEJ/FxlTaSbMSolGL404mEDxThNMXieUvEA7M4hmXKDtkltJOmpkgsagPR6RCtHiZaO4ymmsOr+YhMi5R82g04y4yXgf+UAZf/BSh9GVkdQ67O45fcpMSHaQ0O3HdTjgSx6PPYnevIWlLyKEqHl8OpxjCZXXjtPnxeZPIQoWxgxlkZQGTbwY5NIOsFjAbIshSCkVIYZkoYhnMYzlexuJaQAotY1QaGMcz2GwlbLYiwngJy/4sxn1ZzIYZVNcqFmEGi6GGbKwhmarYjuYRBnKYetNYDhWRLLNYJ6aRDU2kEyWE4SLm/WksexMY2+MY9iYw9GUwHC5hG6ogHMph7o1j6Iww0RbCsDvE5PYIY60hzL1pxAN5tMNFlL40cncSW0ccoSOBZWcUc0sIqTuL60iNwIkagSNV/INFnP15XH1ZlN1JLFuDyO0JfIcrBI/ViB2rET9RJ3S4jGtvGnFbCNuWEPLOOI69KYKHK0QOl4gdrxE9WkFviyO2hLBtWo+AdLYnCO7Po3YGiQwWcbQlELb6ETb61h/gbg1g3x3Fvz9L7EiJ8IEc3n1pnO1xQgdyBPpzRAYK5MenuVS+j5XgWdz7YySHaoSHchTGm5xKXGbBd5bLxft58NxHWc6dYsF3mivlBzgdv8LDqx/n3toH+fjlx1ipnOa1l77Dt77yCk8/dINPXrnOl5/6Kp+69jiPf/gJHr73I/zTj/7whvkf//Ef+drXvsbNmzf53ve+93uZ/lMC/e1vf5uXXnqJmzdv8v3vf5+vfOUrtwT6L8xb7U23uMWGDRtuCfTbld8J9C9/+cs/K9H/k0B/4dHnmdFXcLTHmbh9/RHh4F+ZGP5/JdStAfLjU8zoK8y5V4keziNtDTD6dzoj71IY/zsV811OfL1pwgdypI9ViA2W8PakMNzlw7IpiHVzAOsmL/Y9MfS2CLHDRezbw/j35xB2xLD3ZBF2xvAdLqPsiODYE0Pa7kfc7EbbHkXpTOE/MY39QIXg2Cy+ow3sHSm0tijiZj9aawjr9jB+wyI+0yJh+SQR9TT+4Skc3WmMd3pRtoUQtkeQD+YJ6ydJpO4lGL5E1H8e79EakxsD2LaF0DvimPbEcFhmKC48jLd6P/7SVZLRC0zujmHcFcXZm8XYGcfUlSDbuB/PyWuoi/eiJJewjlYx7MvgOFjA2pPB0JXAK87gmT+P9eRFfKfuQY0vYxwvIxwtYx0oYBnMo4+U8aXm0U4uotVn8DQXUGOzmAxlTMcryOMNXNZpNGOe4FQOfylJpJAnPt1A8FWYGCthlxaJhM9inyzh092kUnaqaR/FfJhgLoVRLeD1niIcO08ouop1QCKj2ZiJ2VnMOchFPKjeKL7UWaKFq4TjZ3FaQoTGJBpOhbmQnUZIwqN7CKRWiZbvxx07h+7JExTcFBSNiq5S0ASCDgcOZxV/7jyu2DnkyAwef5KoEiClOghOiIRVHdWWQdfm0MOnsEUX0TJNnM4sDlsIh9GNxx7EZkkijpcZn8hjDC4j5tZQQnMYxuOI5iSSLYnVVkAcLWEaKmFyzSOmTmLyzjNyIsXkRIaJiTSGkTSGwSRj/THGR4uYnXOMSw2GTuQZO5pgfDDG8MEYkwNxTuyNMD6QwmRpYJisYxopYzmcX5frw1mEg1lMPUksB3LII3XEiSYO4yzusSmcg1U8wzXMvTH0wRJafwGxv4B2pIZrdIbg5AzewxX8x6p4j1ZxHalg7ysitKeQ9+ZwDJTwD1bwHyoTOVHHf7SK/0gNtSu1voa0O4GrP4d7Xw7vvhz+gTyRYzXcPVnE1gjWrUHE7SEc3SmcHUn8/VkCAzmc3WmUHVFsW4NYN/sRtwZwtCdx96Tx7Utja/Egt4Qw3+HGcpcb22Yf0rYAjt0xggfyhPozeLvXUzv0thjuziTe7hTRQ0UqtlkuVu9jSl1aF+z+JImhKo6eGDPaKtPqCtdmHua56y9wqXo/KUOZhrTE6eRlLpUe4GLhfh5c/AhPf+QGD973EE9/9LNc/8BneeYjn+f6A8/w6atP8qlrj/PJBz7NYx+5znde+84fCPFrr732+2SNX/3qVzz99NNvStn4r5//53/+59/Xfn/3u9/l61//+i2B/gvzVnvTLW6xYcOGWwL9dmbLli3/xwL9mU98gaXAGby9KQzvdazfQP9fZkb/VkZtCZEbm2LOdYozmSvEj5ZRWkKM3aYz9nc6Y+9Ssd3lxb8vS3akRn5iisyJOu7uNMK2AMaNPmzbQlju9uHpTuHdmyJ5vIpzT4zIYBl5Twp9bwZpTxLX/jxqWwxvTxp7exRxiwdnRxzn/hK+oQbqQIWIeRnPYBVPf349xq41iNIaRO1KEzLM4TUsENLPENHOEJuYRu1OY90SwL4rimVbAP1giaj9FJHYVULRy5Sy9+M4VMbQGsXVlcTaEsLQEsJjmiFUvIq7eh+55Q/jU5cwdmew9+eQ2uOMbfahHMwRzV1EKJzGf+YaVt80xtEytiNltP0FxlvDmNvjBH0rWEtLyFOnsDfWsAVmGZ+sIAyWMO/LY+3Log+VcWTrSMUacryIszyF0V/FZKpgOVzFa1tEPlhYf1QXjxKOxwin4ngKBczOArbJJuHAOTzqEvLRCAFNoxR1UUl4SQVd6OEwkn2GYOwikdRlNHMe9biZqsvBXMJO3avglBSckTqh6lWi+SvYfdPYJ7yUPG5qupOaXcZrtqDpKSK1ywSqV7CnVlFdKWJaiIrfQ15UCBqsaNYA7vAC8ekriJk1xHwTjytL2hfFP6kRFGU0OYhkLeHJrGLLLGIoLiAG6uhyCtuwB9XixWLyYxyPYRUKnPDWGE8vMBGdZmQiwfCRIGPDIYYnI5w4HmX8RJwxtYIhtYQhusjYZJ6xYynGRzNMjmUwjmUwj+QxWGvo6bMo8bMYbdPI41WU8SrCRAVxsoI0VkGeqOH0nsTuOYlqW8A+1sQxXEcbqaOP1lBP1NDGGrgts8hjTZQTU7hO1HEcreMaquEYaWDpTeA8XkM5VEYaKCL3l3AOlHDsy+M/VsN3rIH3eAP7wfJ6W2FXGqkzhWtfFvu+DO7+PL7DVXyHK8gdKawtUYS2BGpHCq09gasrhbsni7s3i70rjdQaxbYthK01jLM7jborgn1PHHd3Gnt7Atu2dXEWNgcRtwZxdifx7E1h3x3FvivG5Pt1LO93Y73bh7TRh7R5vaEwNJDD15tB2x5C2uxD2x5CaQ3i2BMjPFCgoSxyoXCVgmGaYH+OzEgNR3uE+FARrTNEQ17i4ZOf4MbHv8D53L2sRM/jO5TkVOoyTXmF87l7OZu9h89/8jm++tyLXJi5wgOLH+TZTz7PI+cf5cbHn+Oxe5/i2tpDPPqhJ3j5H77Jiy+++KYb5ZdffvkPar1/V4zyL//yLzz55JN/8PnXX3/991L9yiuv8NJLL/H666/zH//xH2/1kf624a32plvcYsOGDbcE+u1Ma2srP/3pT/+PBPorn/s6a9ELBHqzmO5wcvyvbRz9XxbG36mg74pStsxyLncPF0v3kjpeR24NM3Gbk7F325l4twrZE1sAACAASURBVI64yUd4IE9TW6ZinaNknMbVlULaFcW0KYCwLYz1Lh+BviyxI2WSxyuE9mcJHi7h7s0i7cmg9xXROlK4utMEBwo422NYN3vw9qTwHS7jHqxhP9IgZFjCtb9EbLiB3plEawkitQRQOlN4j9VwGxcI62eJKqeIG2ZRujMouyNIrQFMm3zY+/P4hEUC4UuE41fJhi8g7sshdWdRd0UZe58bU2uEiLyE7lvDXbxKee0j2E5UMB7I4xgoMH6Xj5H3uwkYm+jeRWzRZcJr9zMiVJgYK6MMlbF1pBm904val8XhmcMUn0VOzCOVl5j0TGMwV7EeKGDuzWNrT6IbSkihAlqogD1UQi1OYfTXMJ+oIo/P4JxoIgyk0JUoPn+UeDxOKJxEzOYwCCXszhUC/rNIwyUUg5+w6iXn9VP0e3C6HYj+NO74GUKFqzi8y1hHInhMCtWgn7LDjddiQ3X6iEydI1y9jL98GaOUIeiIUvTFKXt9hK0WFFElVJwmMHUaZ+00o5E6spwk5g4RVdy4R83oghVRDuEtNZHyMxzPNJlw5lHFCMqkC2lURrLJWAxe9GAOrTDNRHmG8ewsVrWE1ZDAMhlEEPyI1ii6nkOvLzJRmkFeuIASWMRiKCKYS9jUAoKQQ7IU0cNzOOYu4lq8ByW0inWygWCoYTJVsFnLCJYKZmsNT/YMnsJFbPb1DGd1ooEwWUMw1hHHK0hjNeyOBXR9EetYDXmwhmOojnqijj7eQB2roYzWsZubmAfz638wDRRRe/M4j9ZwjE3hOFHH1J9EPFjG3JvB3JVE35tF606j78tjP1TGc7yBfbCK2J1G6klj2RVD3Z1A3hVD70zj6M3j6i+h7c0i7Ukjd6SR2uJIO0MoO6LoHUn09jh6RxKlLYa0M4qyJ4a9K4m6K4qyI4yyPYrWFkNsCSJsDiC3hLHvjuHem8LdlULfE0XbGcW2ycPo36tYN3mwbvSg7ozi7UkRHMjh6U6hbA0gbvYh3u1F2ORFaQkR7E8z41xlNXaR1PEakcNFogfzhPfnCR/KobeH8B6M88jFR3n03ic4m7zKvPMkJ2MXCQ2lmHOucipxlSvlD/DFx77ES1/6Fh+/8igXZ65yrnqJ69ee4amHbvDpe57kMx95liceeZJXvv3Km2Lobt68yUsvvfQHe8+f+9zn+NnPfsbNmzf55f/H3nt+512f+br+A86ZM3P2mT0zmfQMYJDcLTdZbpJsy7Z6e+qvPb333ntTt5old6oJBCZACAngGDBkKAklISGwJ4SyGcqEkBUSz6xZc50XCuxkQg77FayT6Frru/T81v1IL3/rWrfu7+d+7z0eeeSRP7h4ePHiRX71q1/xwgsv8NJLL60K9CfMp+1Nq6yyZs2aVYH+c6atrY1XXnnlf0ug/1in+tWfvsZS/By+jhTaaxz0/o3Msb/SMfp5E7btYSryNHfMf4PzxZtJD9cxbQmgucrB8OfNDH/BjGGDD9+BFBPOBSryJGVxaiVOqzWO9lof0sYAYrMP194E8Z4S/vY0kZ48wa487s4MwtYIjoNF5G0x3B1Z3J0ZzNv8yJtcuPencB7IYNyfxTU4gXugjutICX9vBWVTANNmP0KTG+OuKNb9aVzCcQLWkwSkeXzDY4i74sgbvGivcaFr8mDck8CmmcTlWSKeugG/cQ7dvgzmfSm0V7kY/rINeXsUpziJZJggWLmJcPYGVD1lDL0lDG1x+j9nQd3sxaMZQyvXUTyT+BrnGBBLaMVxzN0l1JtDDK91YzuaR2+ooLdXMfjrKNVFVKEZJH0dXXsO/d404r4UwmgSyZDGYsthj5UQGhMI7hrq/ioOeQbxUB6hP4nFGMdji+F3RLDm0gjZHIK5jid6CpM0hbo/hd0QI+ZMkPIG8TqdGFIujOEqzvwJbLF5BlQZZF0It8lJ2OjCb1AwmHXYMwnsmRqG1Bjd9iJD6jAOUwiv2YVLI2MVRnD6nQQaBdylBsO5BipXGbsji8+ZwjbqwGMS8DicZCdLxBcmME1Mo4wv4g7P4fbUsUgJnGYXXouHcCRF5vg47uMzuE6dw5ldxuGYRNTnkQ0x7NYQTnMCd6KIozSJUBvHVT6LQZpA0tTQGwpIhhSKksNozGBJTuEoLWEKzSJpxjCqGui1FUSlgqRUUGvymOxjWEKzaMQa0tEipoE60mgVUaijaKsomiqyUkPSVlD3ZBE6sigHskg9ZSzqBoaRGobRGnb9BNrDKXQHU0h7kihtaYydeYzdRSwDNRxDDVTtSZSuPNrWGPKuGPL2GMa2JKb2HLauEs6+BuaDBSyH8sitMZRt4ZX85u1xTLsTmHansB7I/fZksbQlMW4LI28NIm0MYtgaxtgSwbgthmVnHNu+NJ6OHNZdUYxbg0gb/Ugb/IjNPsRmD4bNQRx7kwSPZHC0xX8bdxdAXOdBWu9l6AtGxGtd2HZEiPUVCXZksO2MrcxBN3uRmlzITR5Mm3349qc47jnJpGORyNEC8e4C3vY00SOFlWVJXQWCvRnmS6e4/fhdLEbOMmFZ4GT8BsbNc8S1eSadC1yYuJPnH3+BZx99ngcuPMzd19/HyeJ5TjXOcu/Z+3nojkf5p/ue4o2f/QvPPPMMr7766h/E0F25coUf/vCHvPzy/xrr+MEPfvDh889//nMee+yxj1zv/cYbb/D888/z8ssvrwr0J8yn7U2rrLJmzZpVgf5TJJlMsm7dOjZs2EBnZyevv/76R36vq6uL559//mMF+sEHH+Tdd9/9yNo7b7/D9eVb8Hem0a910v+3It1/pWfkc0bMm3zkVXUuTN7JjY3byKnHsO2IornazeBnTYx8zoyy3od7T4yqMkVJN0lVmcbXkUZpiaC+1oPQ7Efe6Me6PUqku4BjV5RoTwnH7jiOvQmElgjOQwWUljC+QwXMO6LI69wIzU5M28KYtkVQ9mbwjU5hP1bB31fD1ZlHf40LudmD9monhpYQcmsMl7iI37RASJjF0VNDak0gNnsY+oIJfZMbQ1scua+Kx7NMLncTVtUkSk8ZR2eOwS9aGPi8FcueJNJAGWG0Rnr+a1hdJxDFCTz6KTQbA/R93oxhWxipJ8dIfxZnZAFX7Ty95hoWx3EMR4sMNnkQW8Io3VlGelMYlDK2why6+jL65DyKpo66I4PQlkQ+nEE9lMRkKWK15ZHGx1FNjDNqrKCRaugHS4wciDHcH8GkxDGbIhjcQdSTCUbdCTTOEnp7lZ6uOD3HQpjEGA6jH5vBiRIzoaR92HNlbOkGw5YivSMJPL4iFjlM2BnBZRWJ1ZwU5iuk5sexVscZspYJRmdJJqeI+Ip4jAaSQQvjSznGlutE5mros+P4k4skMsu4LWU8VhdRm4lyKkBlKkN8ooBzfgJP4SSB5DJmSwOzHCVktxOx+MinkwTTSQJT47irJ/EFl5HEMQQph9sVw2sJ4bKFcIfSBGpjaBw5FMM0imYMQaoimHKYHHlkfQLZksGRHMfoG0fXV0YeqKJXNdAbqwimOmqhiCQVUWx1dFIZfVce8UgBoa+EII0hig0kXRXZUEcaLaA5lkbsymM4kEV3IIMyWMWoaqCoxnDJkyh9efSHkgh7Eii7U8h7M4jtOQzdZWxDDRyacdTtCaR9CQz7EkjbYui3x5Fakyh7Uji6K7h6q9h7q5j2p7G0xjFtjyJsDCJsDiNtDWPem8F9tIrrUAFHZxpbWxLTrhjS5hDS5hD6dV6ULSEc+7O4DuXxd+VxHUhh2xlF2RJAbPYirfMhbfBh3h7B25Eh0lfG25nDujO6colwvQ+x2YdwnRvNNVY87WlSw1Ui3UXMLSGUDT6kJi/SdS6U9T5MmwOEjuQ57lumLM0Q7MoROroizaGuHN4DaRI9JRYiZ1koLFMyjTHjPcWc/wzT7mWmHCdYjt9AeCjDjRO386OnfsLlr3+XBy98h2+efYA7l+/ippmvMpta5NLtl3nu8g9489U3ee1/vM4Dd1/kJz94kd/85je/F0N35cqVD+X6g+dXXnmFZ599litXrvDWW2/xxBNP/IFAv/jii7zwwgs8++yzvPrqq/z617/mP//zPz/hN/2fL5+2N62yypo1a1YF+k+R995778PP09PTWCyWj/ze0NAQTzzxxMcK9KVLl/7oqMe/vPYvnCtdINiVR1jrpu9vJI7+pZbBzygoGzxkhmtcX7mVhdAZ0gM1LNvCqK5yMvB3Rka+ZEZY68K1O0p2pEZmuErkaB5nWwxhgx9tkxfddW6ULUGU9X4ChzJYtgYJHcpi2hTAtDOKvD2O7UAWZVsUV3seZaMf/bUuhHUu5HU+xI1elL1ZfCNTWDqLBEcmMLalVmLsmtwI17rRN3kRdsbxSrP45HmC0hy2nirWfUnEdV5GvmBBu9aJsD2C0lfB7z9FPHojJu0UTs00ptY4g1+0MvplG6a2OOp9cazmGfKLX8fsWcbsmCOgm2b4WjfDV7ux7EuiOphEdSxJfPpmlNJp+l0NzJYpRvbF6W92IbSGGToQYeBwGNlYQl+f4Vhpgn5Hhf7+NL17QgzsCNC/18/A4RCSmEQfyNO7OMZAqsyorYTWWGboSIqhwwl0Aync7gYuZwHz8QzKbBZnqYG7MoVkbzA4mMUo1ojHZomFxvBH/ETn/WSXSuQWJvCUx+iX8lis04Qj89jtOXxWD4mgwsREmPHlPIXFCkK0iMU7SzR1inByAbcxQkQWmEi7mKqFqIzFcdcyuFJzRNLX4wssYDQlCZktZAxmpgoeKjkv0VwEf20af+ocVsccoj6Pz+0lINpIu9wkgm6S2SjBTBVvYBFZmUYv1zA7k3gdCRySF4fJQziRwRMpMzyUQVY1EOUJNOYSBlcZWU6i1Yaw2HNYPRWk0QLKQAVRVUdrmUSwjTMqVhD1eSRDCZ0mi9CbRT5aQNdVRKcZQ1KmkIQGotTAoCkhDuTQdSaQDmTQd2QQjhYRhxsoqnGc8hRmdRXpWA6lI4W4K46wO4GuLYnUmccyNI5DM4lTNYZqRxDLoSzS7gTS7gTaljD6HVHMXSXcg2MEVVM4Duawt2ew7Eli2BlH2BxGvzWMvCuOt7dGeKiBt6uEuz2LrS2JcXsUcVMQcb0feXMI1+ECkaE64Z4yvkM5XPvTGFpC6Ju9iOv9CBv82FrjxIdrZFUTRHvKOPYlkdb5EJu9CM0epA1eTC1BnPtiVM0zJAdrWFpCSM0epGY30joX8joPpi0Bot15ZnzLpIZqBA/nCHRkCB7K4mvPEOrMkByocrZ4C7fP3UOoP4vvUJwT0fNMWOZZjt3AlGuJ5dh5ZvMnuOP0Xdw6cSe3zd7NDZVbefDWh7lh7FZuX/pHzozdwLP/9AP+58v/k6cefIanH3qOe7/2LZ5+9Fn+5dW3Puwe/24s3e8+v/vuu1y+fJkrV67wxhtv8L3vfe8js6OfeOKJD393VaA/WT5tb1pllTVr1qwK9J865XIZq9X6kTVJkvjOd77zsQL9yCOP8NZbb31k7WcvvspS/HoCnSk0V9vp/m86jvyfGvr+u4SyzkOiv8Jy8npq8nHivUUMLX5GvmSh/28NjH7BivorVtx7EsR7iiT6yvg7Unj2JdFc50Vo9qO91o2yOYB4nQdnWwxHawTPvgSWbUGULRGMrQmMO+NY92Ww7kmibPQjNq90oOUmD8J6L8aDJdx9DexdZYKjkxh3JTBvDaO7xom01o3mGjuGA1l8+hWBDigLOEfHcexPo13rRnOVA7HZg3prENNInbD/JB73SYzSNB79BOp1bvq/YEN7rQvVtgCDOwJY7FNYkidQWSdQzJOo9kY5dpWV4WsdjG730bvNh24gjWfiDKOZRYZDk+j0FYZaQwxvDyDtiTG8N4Y8kidcOoVy7gb0c6dQQscRLRNojuUQOzOoD2ew6Wv4vNO4zyyj3LyAuTaFs3gcvbHGaG8O3ZE8dsM4XvsUgUgZ51KW0EyJyOw47lKdUSGPZrCEzzVPwDePy5QhELWQrwUojSUoLZVQAnn0hjoB/0nC0WUUIY5LJTOWNDNdczMxFiCSD2MOVgglzhBKnMFpH8OuMZBWFOayNqbzLnJRO4F0kVDuHL7YWRTjOG67j6DaSMVrZjxqJu8zEUnHcEfn8YbPIBsnsXqzeG0BAno7MYuZpNNKLB7F5hzHYptFsR9H8NewBYuYlTAWlQO3KYDfG8dorjB6LI1imEbrncYQnkI0F9GMhjGKcYxKElHIIw4W0PaVkBwzyIFZRgwN9KoCor6AXpND15tGfySD9mAK7WgNxTaLII2jlxrIo2UUVRGpN4twOI16fwrhSB5xtIGsm8Qhz2AdqWEZKmPqLiB3pJHa0+j2p9F35rAMT2BTT+FVjePoKaHdE8TUmUU5kEFpS6HfGVtJ4ugfI6Aex9ddwdtTxtqexdKeRdweR78lhLw7gbunSmi4TrC/QmiggvdwEdueJOLmEMKmIOLWCN6jZUKDNeIDNcK9ZYLHShi3R9Gv96Nf50fa5MfeliDcWyI9OkZyuIFjTwJ5vR+x2Yu+yY203otpV5jQ0RzOzjj+QxmMmwPI672I17kR13kQ13mwbA+R6KmQ147hO5DG2RrDvTdOsDOH70CKUFeOnKbBhYk7mPWfIjvaINidwXskQUWYZCl2nnHLPGfzF3jy4tNMJxcoGMZYjp/nxupt3H78Lm5p3MFtC3dy1/l7efjbD/PYxcd59O7HuXTHo3zv4rNcWLqNHz/9Av/8g5c/7B5/IMNPPPEEb7311u8lb9x///0fRtx90I3+3fP+++9z8eJFHn/8cd5+++1Vgf6E+bS9aZVV1qxZsyrQf6rE43E++9nP0tTUxFtvvfWR33E4HNx9990fK9CPPfYYb7zxxkfWfvLcSyxGzxLozKBf66L7vwkc/gs1fX8tIja5iHcXmXKeoGGZIz1Uw7YjwsiXbQz8vYnBzxlRf8mKY1cUX0eWZH+ZUGcKX2caXZMXbbMHXZMXw+Yg4gYPth1hfO0pLFsDuPfFMbREsO7LILXEcR0qoGwPY9kZQdnoQ3utFaXZjbTZj/1wCWNnDtuxMs6eMvL2MNKmlQUp2rU2Rq6yIe9LIx8pYOivYhypYTyWR7vVS9+XzAx/xYxqrZ3hDV4MgxWcznnMtjns1jkcgxWGmlyomr2YtodRbQmi60yvRNSVbsRZuIFU/kY0bQlU2yLY9qfQtkbR7oqSSZ3Dv3Qb1tlbUFKzGJQxRjtSGDoyiHtSaPbGcWnq+MfOIZ45h2PpeozZObRyFfXRHLr2NNLhHLbhKk7HGMa5CQzjDVyTk5hyE4wKRdRHChgGa3iN01hHi7hTSTzFCOFiivhsGUM0j0qdx67MEPIs45TGsKkdxCJmqjk35UqQWCmEYEvicp8gFD6NL7CM7qiBiGJgOmXleNZCJWbCGQjiTy4TSp7HEzyJxZjAO2qh6rEyFTZR94sEvA78iRmChRuxR5Yx+kp4LH6SBgcFu5WsIpAM2HG4i7jjJ7EFl5AiE1gjBTzGEAHJhlelEPM6MNsymEwTmLyzqMMzGDLTWH0lDOogVq0PhxxAFuLI6iJDfQm0oXmU3DKGyHFGh2NIQhJJTCAIWcTBPJpjaQTbJIb0KbTuWTTqIqKmgF6XQz+aRx4poj6SRTdawRI6gWSfRS+MowxXMajKKEMl5N48+qM5xN4SJnkaWZnGLM5gG25gGahg7S9j6i1i7CkiHSuidJcxjYxhU0/hGWlgO1rE0V9B3x7D3l3GeCiPri2FpbeKc3ic4OgEnmNlPL0VXL0VnD0VlD2plZGf3SmcxyoE+msEu6sE+6v4ustY96URtoQQtoQQW8I42vN4DhdW4uWOFPF3FTG2RNBt8K0kbWwMYN+bxNuZxn8oi68zi3lrBHm9H6HJs9J5XufD2RrH35nB25FE2uRB3+xCe7UT4Vo3wnUupPVerDvCpIZrhLpyWLaHsLSEcLRGV+LtOtKED+epSNNcmL6DmjJN4FCOvG4CT3sC/5EEJe0Us57T3DZ1F89cfo4LE3eS0pYI9aa5oXwby5Hz3LlwLxfG7uTuG77BU499n8vffIwbpm/l0Xse5xunvs3j3/o+N85d4Lnv/pCf/uiV39s8eOXKFR577LEPLw1+cB5++GHee+89Xn755Q8j7v7refDBBz+8cLgq0J8sn7Y3rbLKmjVrVgX6/6+0t7fT1NT0B+fOO+/8ve+Vy2XS6fRH/o1IJMKFCxc+VqAff/xxXnvttY8W6Gdf4nz5ViJHsuiuddL3NyJH/kJD7/8jIlzjJHQwy7h1lqXkOXKjDczbQ6iusjH8eTNDnzGi+YoN+64ooSM50sNVQkeyOPfF0a73ompyobrGiWatA2GdG+NWH64DEaRmJ5bWANoNHvRbfYw0eRFbQ4yudSBt9iKsd6G+2oJ2rRVpexDj/iT61gSW7jKmQ3lsexLI20IITS4Mm7xIm4I4e6u4h8fxKgsEzEvExVls7Rl0673YdkaQNgeQ2xKE5FlC0evx+M+Ry13AM1xHszWM9bfrlNVNXhwDdZLVW7EXbiQ+9TVC/pOoD6SRD2QwtcYYXedDak0Qj51BKS3jWvoqGn8DtaqM6lgOw/40qpYw+tYoXmkCpbSAUF3AWJtHjE8xrC+j786j35fFeDiP+Ugea7iKkqtgShaw1+togxVGtXl0h/O4pONYeyqYVUlsoSChRIRYIYa3mEHvTiGqa/hcy3jsJxCPRrApVopxH7W8j0zChTnoxehs4IudJRg/j0koI3TJ5D0uJhMu6iETTrMBR7RMsHgOf/p6TP5pDPowMbOXgt1F2WUkZNBhc8TwFZYJ1M4jR+aQA3l8lihpl5+AykhIFLGZ/FgdZULV04ipBfSFKayeMgFbFOuIDa/iwCR6UNQZHNFJpPQcQmMJQ+o4ZkMeURXGIoaRjVFkfRqTUmTAXcY4dhZT8RQqcWW7oKDLoJPTiNockjqPbJ/AUj2DnD+FVmogqSoI6iI6VR5FW0AaKSKJdVzZ01iip9DI4xiHa5hHa8ijVaTBEvJQCbOmgcO1gME2i0mZwjJQw9ZfxTpQxTRYwjRYxjBUxTRYQRmuY1FP4Bps4DxWxtFfw9ZbRbsvhuVoEe2eBHJXHuVQEdfREs4jRTx9NVzHqrh6qyh7kuhbQihtKYz70jgOZHHuT+E+VMLfW8O2L4OwJYywJYi4LYqlLYVtbxLn/gyuA2nsbSlMO2IoWyLo1q1c2rXtTWLfHcXetpK2YWwJITR5UTaGkDb6kTcEcOxZkWfn7jjGrQFUX7GujEQ1exCvW1my4tobJz1cxbMvibzOi2GzH8vWEJatQZytEcKHC0w5TnCucgvp3451RLryRI4UiPYWsLQFGDPNcd/5B3jsG09wKn0TM+4lUpoSkeEs084TXF+6lRvKX+XRu5/g4Qcu8+3bHuT+C5dYyJ/mgQsPcemOR/nmmQc4VT/LM4/8gF/8/L0Pu8cfiPAjjzzCe++993ty/MFc9H+NuPvd88QTT3Dx4kXee+89fvOb33wSr/1Vfsun7U2rrLJmzZpVgf5T5+WXX6apqekja/l8ntOnT3+sQD/11FP87Gc/+/D5F7/4Bf/6r//Km2++yY9/8ALnqzfjO5xGdbWVnr8WOPh/qOj+v3WovmLFuS9CQa7T8EzjORRD02Sn73MKPX8nceyvdfR/VkLa6MbbFSd4NIX3SALjDj/6DU5Gr3GgutbJyD/YMbT48R5IkBwqYdsRJng0j31vElNbAmVnGnt7HsP2KIGuAu72JNJ6B869MTyHizgPFzAfqhDQzOA6UiZwrIK1LYFtexhzSwB5awj3kRJu9TR+4xJ+0wnCmhmMe1Mo26JYWgKornaj7IwTlGbwBM7gD19PNnMTSmcOYU8Sy84Yo9e4GL3OQ0g/gd27gD19jtz8nUiaOuqDWcwdWbTNAYaucuI6WsTmnUUMzeKfvpFBc5mR0Qr6/jLC7iSj63wYdyexmyfRBMaQ45MYy7NowjMMyxU0HRnkjhzinhRKTwbJl8cQzmNPlbDWG6jCVUYH8hhGx3Hrp9DvTyAJEdzuGLFUmlA8iZxJMmrIYbPP4wucwqSuoun24TN6yUUiFGI+LHYboi+CM7WEL30Ge3AR1WAcs8pOyhEg4/LilgSMJjuhxgl8pTO4i2cYclSwmxIknDFSbh/uYQmzYMYbLRObXsJTPclobgqDq0rYk8avBHGojTitZqzGCNH6NN7JeTTjCxiyM7hcVcxCFIveh93oxiaH8QQL+Mdmsc6fRJ5cxuiaRNZkkTUpFHMEk5LAYsxgK0wiVKZwLF6P4j+OfrSIqC6hkzJIYhZJzGFw1PEsXI9z7kYkz3HkkRrSaBWtuogolZC0RXRCCW/xFI78KXTmKUzD41gGGyijZaTRMtJIGVlVwWSdRi/UEEcqmHqrWHvrWIdqmNQ1jEM1jEMVlL4imq4s0tE85s4cpo4cjoE6tqEatoEamj0xtAfSSJ0ZhLY41gMZzPsyWDvzOI6VcfRWMB3IIbUmUPZkEFoimFvjWHbHsO/PYmvPYdufxdiWwtyaxLQrgbEtgaklhHVXHMuuBJbdcQzboxi3RzBsi2LaGcPelsTaGsXUEsK8LYKxJYS83o+00Y+yKYBlZxz3viTe9gzWXWGUdT5019hR/YMNqcmF1OzB2hLC054k3lfEvj2K2OREXu9GanJj2OjHsi2Ivz3NYuw8c5EzhI/kCR3O4t2fJtJVIHAwi6c9hasjxP23XOK+8w+yGD7LuHWRE7HzBHsylEyTNEyznEzeyGP3PsFPnn6Jm2Zv5e6z3+TuU99mqXKab5y+n0e+/l2+c9tlLpz+Kr/4+S9+r3v861//mitXrnDp0qXfu1T4wXKVH/7wh38Qcfe754UXXuC+++7j/fffXxXoT5hP25tWWWXNmjWrAv2nyE9+8pMPP8/MzDA4OMh//Md/8PLLL/Pcc8/x6KOP8q1vfQtJklAUhUQiQaVS4fvf/z5PCnxtKAAAIABJREFUPvkk3/3ud7l8+TIPPfQQFy9e5Bvf+Ab33Xcf999/P/fffz8PPvggly5d4pFHHuGRhy+zkD2NqyOK9mobPf9dousv1PT+jYh4nZPwkSzLmXN8deZOCpox7DvCCNe6GfqCmaHPm9CudeDem2TMfJwx8xxjtjl8nRlsrTHU13mRNofQrHXj3Bsn1JUj1lMi0Jkh1lfGfSCN3BLFui+LqTWFY08S36E89tYo+rUOrLsiOPYmsbansHfX8Y5M4jhcJNhXR9oWxLzJh9DkRt4cxLI7hUs7jc90gpBpCd/IBOLOBEpLCN1aJyNftmFujeFSj2OzLxFOXE/QvoS2PYf5YA5hnZvBz1kQ1gfw6SaQ5HHcqbNEKjeiGaojDlawdubo/aKN4Wuc+Ebq6Ix1FPsk3vpZBsxVNOZJDAM11NtijFzrxdSeRRDLCPYapsA45voio7EZtHIdbWcOpauAflccXX8awZzD7q9gD5XR1cdQeWuMDpdx2xcQjxYYPZpA1iZw2VN43ElMkQTqbBrRVscZX8bqmmP4WBpFGyfozRC1RXGZnOiCdhz5CQLVJTy5ZQalCrKQxSr5ibpT+ExOTCaRYClLfHqO4MQC6tQUWnOVkK9GIpTHqfPgNouEAn7y83XSMzPI9SmE7Cye0BR+dxWLLozHasFndZOv5Mgtj+OamcYyt4w7tojDPo4iZLDIXvxWD0F/lPR0Dd/CFP5zZ3FkTmFWJtCN5pFNCWzmKA5jHHsyT/D4LPL4OPbiErKmjjhSQ68vIBjSKIYciiGDpTiFs7KI5J1CGq0jjdTRqyrojWUEsYRan8fsnkDxTzKiLiIfq2AerKOMVhE1dUR1DUlTRZEbaAbz6AbzKAfzKO1ZjAN1LJpxjCM1DKN1TKN1dF1p9F0ZlANplD0ZDB15zL1VbINj2PobjO5NYDhWQr87jmlPEnlHDOPeDOaOHLajZWxdZUzteUyHshj3JDG0RJC3hjG1JjHtimPem8K8P4v1QB7bgQyOjhzmnRHkLUGULWGU7RHklgjGbWHMbQlse7O4D2Zw7F7JgVY2BtA3ezFsCSGu9yFv9GPfkyDaU8K1P4Fpewip2buSwHGVndEvm9GtdWLfGSU5XCF4OIthoxep2Y3+WhfSdU6kdW7kdW68+9MsJc9TM83i70yvjIG0pwh0rPyMdZcoiZMczy5yY/1rHPedZt5/hhnPMuO2eTJinYIwxkLsFM8/8WOefeSHfOdrj3KqfD13nb6PB7/6MPOZZS7e9jCP3fMEL7/wCvd/+/7fk99/+qd/4u233/5Qpj9YnPLBeeedd3jsscf+IOLud88bb7zBPffcw29+85tVgf6E+bS9aZVV1qxZsyrQf4oMDAzQ1NTEunXrOHbsGK+99hpvv/02/f396PV67HY7kUiE3t5ehoeHKZVKnDt3jp/+9Ke88sorvP7667z55pu88847vPvuuzzzzDO89NJLf7RDfe/5+8mM1DGs9zH4GYVjf6mj/zMy8joP0aMlzuZv4o7Fe6hb5nDsjqK71snQ58wMf86MeJ0L+44oJf0k6aEKDfMc3vY0pu0RRtd6Edb70TV5sLfG8bVnce2OETiYwtmWwLE3jm5TCOehInJLFO+hAtbdCYwb/GivtmDY6MO0PYSyO4arfwxX3xju7jKuI2WEdV4MG31ovmJD3uxH2RbBqZ7CY5gnqCxi628g70lj3BJk+ItmVP/gwLQzhrGngs00R6ZwCzb9DHJ3GV9fA9VVDvr+3oRlZwRDXwmhv0SidhOu6GlEcRqnOI20M0Hv5y0I632Y+/KohwpY7NP4xq6n11bH4J5D7iuubCHcEkHuSDNyNInZWMERnEY3dhJVdh69roa+v4SwL4luX4KR3gRmqYjVVMKQH2N4egq1vYbBOYXZMMVoRwpVbxKnuYzbUcbmzqCrZxFSJezZWVzpRUbUFYZ60ni94wTdZbyOFAaPDXcjQez4JOGJBaTIGAOqIoHADGY5ScCbwWEwEsm7qSyVyZ9o4K6PMequ4/TNE08v4jIXcRktJDxmphcSTJwsEp0pYKqN44ovEo4tYzJUsCt+InYr5YSXiRMJMjNZIstjeEpLOHyLSEINRYgTcLqI2L1kUhHCpQSZM1N4x09gsc6hH62jlwpYzHHclhh2exhPIkuwXkfvziOLE4iqBnpdFZ0xj2QtoNfHkRwF7KlxZGcVfX8Jw8gYOlUdwVRHJ1VQ6YtIxjKypYpKV0AZKCMfLSAMVBGECQT9GLLQwGAeRzeQRTeYQz6WR+7MoT+cxzDSQBkZw6BqYBemkPsL6DuTGPYlkfZmkPZlEDpyWHoa2EfGsQzVUXckkPenMLQlEbfHkXcmkNrSyPtzOI6VcfXUcfRUsLansexOYNwVQ78lhLg1jLI9jrE1getIGfehPO7DK/+tMWwNI24KoF/vR9fsQ9wUwLY3jaszh7+riLs9hXFbCHGdF12Te2XeucmDstmPpyNDfLCKvzODcWsYfZMb4VoP+rUudNc60FzrwNOeomSYJngojbLOi9DsQn+d68POtLLRS7S7xLnCzRQ0EwQOZgh2ZAgdzhFozxA+lCd2tMjJ+PXcunAHWblMTZlhKX49E9Z5FsKnmbAskNHVuDD1Nb55x/18994n+c5tj3DvmQc4P3kTt8/fxeW7Hufc2E08eMdDvPHKv/Dzt9/lm/fcx/vv//pD+f3Rj370YWf5v67q/uAi4QMPPMAzzzzDa6+99pEC/atf/Yq77rrrQ/le5ZPj0/amVVZZs2bNqkD/OXPzzTeTSqU+doTjhz/8IS+88MJH1n7xi19wx9w9JAcqSOs9DPytgWN/qaf/b2T0a12ED+dZCJ/lZPo8Bf0E9h0x1FfZGficgaHPmdFeZcfcEiIzUiPaXSQ7XMO1O4m8MYB6rQddsxf9Og/KliDe/WnMW4OEj2SxtASxbI+g3xzC2plF3hLB11VG2RxCWe9Dd50D4xY/hvVehF0xvMOTWA+X8fXWsR7MI673Im/0orvaibzOi74ljFs9iU+YJSwvYusbw3owj2FjgOHPmxGuc2NsjSJ0ZPFYF8lmb8EiHseum8F1uMjgl6yMfMmOaXcM7b44Ul+Z4vw/Yg2cxmSfx6ccR73Rz+BVLsy7V6Lu1O1xIqlTOKduotc/id2zgNhdYGRzCKk1gfZAEs2RNHZjA+/UOUaPn0GXmkM0NJBGq2j2J1G3p9D1ZPBYJ3EFJtCdnEVVn0CJTmCNzKIaKjF4MI00XMTnmcHvG8dcyiLPF/COT+Adm8EQHKe/L4tBXyfkmyUUPo7TESIw5SF/ukBuvkZgvMaAMY/JMknAv4DJVMJmDBLxGZiZDzF9Okn5RA5jKofFN0M4fha3ex6zECVoVGgkbcxN+WkcDxGbTOLNzRCKnsVqmUEUkvgsNlImK+NFJ6WMi1w9RHxqGl/0DEZlCr2mhMMZImD2ErO7SIRcFGoxQtkSTs88BmkaQR5DsuSwuzKYRT92U4BQMoM3WWa4L4NRnEQ2TKGy1RAcVQQph04Xw+opYnIVEEaLKMM1RPUYetskWtM4I2IVSSwj6HPo1DmkgSLS0SJifwm9fgJRHEcSxpGVceTRIkJfFuFQCrEzg3ykgNhdQhqsY9BOYhOnsKjqCIcyyB1pxD0J5AMZdHvTSB15TEPj2IYncKsaqHaFMLdnkdqSSLuSaLZGEFpimDrzOPrq+IfHsR/MYd2bxLw3jbAtjG5TEO2GIMLWMM4jZUIDY/iPFnF1ZLC0pRA3B9Fv8CGs8yNsCGA/kCMyWCM+WCdwpIBzTxJxgw/ddW50TSsRdZadEeL9DarKcWIDFYwtQcR1XoRmL8J1K0tUjJuDOA/EmHYtE+jMIjZ7kJo9iE0uxOs8SE0eTJv9FMRxTiTPEu8tE+hckefgoSyB9gyBwzmSA1VuGbuT247fTdkwSXSoQMUww5RjkRORc0xYViT63NRNXL73ccYDc1wYv5O7l+/j2zdfYrFwhvtuucil2y9z6RsP88SjT/L8Ez/hx0+9yFfP3c5Pf/QK7//qfa5cucLrr7/O008//UcF+oPRjieffPL3Iu7+6/n617/O+++/z7/927992q/zPys+bW9aZZU1a9asCvSfM3fddRd+v/9jBfrHP/7xH1248s5b73Bj/atEj5WQmlwM/J3Ckb9Q0/vXIrqr7YQOZZnxLDFlXyCrHsPRGkF9lYO+zygMft6E+ss2TC0BYt0l4r1FEr1lvPtTSBv9qNe60Vy7svBBvM6De28c+/YI0cM5LFtX1gqLW6NY9qYx7Ezi6swjbfBj2BRAd50N48aVRQ6GtgzuvjrWwyUCwxNY2jOYtoTQr3WjX+tYyYRuCeJWTeAT5wgoC7jUM/iOltE2eRj5og2p2YNusx+pPUvcd4ZI5Ebs5hNEnEtIu6IMXuVEavYib4+i2h7Ga5kjPX0Htvg5vLHz2EYaDG/0odkcxNgWR7U7htJboLh4O8apmxmJzmBxzqA7mkPVlkDZk0S1J4ZxsETQP4/9xguIi2eRk7Mo/inUvXk0HWnU+9JYR2t4LTN4pk4g3LCIaWwGa3UG0VlnsDeH+mAOhzyFzz6L21fDNpclOF8hujCGb6zGiJJDM1zCb1vA51zEaS7jcFooNgJU5xJUThVQImlEUwWve4mQbxm9Ko5FbaIUMTM97mZ6wk+i4sUerRCOniUQOI1BrmGXncQkI5MZK9MFK8W4kUglSyB9Grf/JKLSwOqI4tE5ydqtlEJm8iEzyUIcb3IBp+8kinkGyVvC7U3j0nvwm6xkQi7i8Rg29xgm+wwm5zw67zimcAPFkEAeduOyR/AGUhjNZYa7U0jyFNrAHFJ4Fo2hhEadQBHSGAxZZKGANFJGO1RGcs4geucYUhqIYg1BlUOrziIM5NAfy6DvzaNX1RBNMwjCBJIyiTxYwThSROzNoW+Po+vMIHbl0HWXENUTWPXTmIcrmHsKmI7kkTpSiB0ZNG1x1LuTmAbq2EbGcI+MYztaRL83jKE9i9KeRrczjnZLBFNnHlt3Hf/IOP6eKp5jFRyHC5j2Z9BuCaPfFETaHsfTUyMyNEZkoEFkoI73SBFlWxzdBj/6jUHETUFcBwskhsdIjjSIDtZx7U8jbvSjb/YhNHkRN/hw7E2RGqxTNRwn3lfFvC2CtN6/Um/yIW7wYtkRIauu4zuWwLU/iem3me1Skxth7YpI27aFmbAuUtBP4NoTw90Wx9eZxteeJtSZJ3Q4R1E3yR2L9zLnWyanGiM+WCJwJEtaU2XKscRx3yluKH+VR+59jJOlc5xK3EBarPC1uW9wY/mrfPumSywUTnPpzsv87MVX+dEzP+am2Qtcvutxnrz/+9x69jb+x3M/5e033uHKlSv88pe/5KGHHvr/FOjvfe97PPzwwx+OenxUl/qee+7hzTffXBXoT5hP25tWWWXNmjWrAv3nzIMPPojFYvlYgX7xxRd57rnnPrL2xqtvcPP47WSGqxg2+Bj8jIEjf6Gm+6/0aP/BRuBQhkn7PGPWOQq6MVx7EqjX2hj4jJGhzxpRfdGKabOPyOE8OVWDQEeS4OEM4qYA2mYfmms9KxFbVztxtMZx7o7j3hPB0hLEtD2KsTWBuD2ObV8ec1sSy44I5m0h1FeZVnKgN3iwH8zjPFLGfrSOf2QKZ2ceW2sM/TUulPUehHVuDHtSuIfG8MuL+A2LhIyLuLuKqK5zITZ7MW0Nod0YwNZbJhO7Aa//HIHA9SRdJ9FuDqBZ78OyK4pucwjdzgjF/I34Sjfjyt9IpvFVpK48qm0xDLvjCNtWYuxC5uNE5m/HNH0TQnIGo/s4qq4cQkcG7c4o2r1JnKMNIuVz6M+cxzh7Cjl/HL11jJHuHNo9KaSOHE7VBE6hhmF8EmGsgX16CnNpkmFDieGuDObBBn7zHHZVFZM7hj0bJVxLE5krY0nlGVXncMiz+B0n8BmPI/d5CQftlMs+ipUgiXIAyZnA41kkGDiD13WCkaMOvHoz41kn4zk7pYQJV9SHP72IP3YGh/sEijWPTesm53FTj9kouvTEYnY8yUn8+fPY/YsInjpWTwq/6CVltxM3SKSjDpzeAu7IIubAItrANIbkGHZbErvKjktnJ+xzY3FmMFkbGD0zqENzSPl5lGAd3WAIgy6IRQ4jm9IoYoW+3ji66BxSdhnBP8OIKo2ozaLTp9GOJtGP5BjtyaA3NjDElhlxTKETaogjBbSjOfSjOfQDWVRH4qgGCkj24wjGKSRlAmWwgmGwhDxYRurJIxzLIXYXEIZrCOIEVv0MtqE65v4ylr4K5qEK5t4iUlce7f4UhsE6ltEJAupJnD1VXP1VtPuiOHoqSPvTqLfFMB8u4uhvEBn+bQZ0Xw1ffw1LRx5xWxR9SwRxRwJXT5XQcIPIQI1wfx3v0SqmXSmEzSGEjQHETSFcnQXCfRXifTUiAzUc7WmMO6MYWyII632IGwK49qaJ9laI9lXwH8pi2x3DvDWIYXNwJWt9vRdnW5z0UI1EbxX9OgfKRj/KhgCmLSsXD+UmL+79CcYsc/jbU5i3hrDuiODYHcG1O0GgM0OoK8ukc5F/nLubsjhJ+FCW9FAV3+EUyeEy3sMJ5kPn+PrSN/n+wz/gVPZ6cmKDheBZSsYxlmLnuHPhXr42dzfXH7+J119+gx8/+SIXb3uEucwSF297hKcfepZz0zfy0g9+ypuv/q+85wceeIBf//rXf1SgX3rpJe6///4/iLj73Szob37zm7z44ov8+7//+6f9Ov+z4tP2plVWWbNmzapA/znz+OOPo9PpPlag//mf/5mnn376I2tvvv4m95z9NjnVGIaNPgb+XuHYX+np/r90qL9kwd2WYMw8x7TnBBVpGs+BNLq1ToY+a2bw80ZGPm/GsMmHryNDXjVGoDNDvKeMtDmAuGlljEPeHEBocuPelyJ4KId9RwTP/gSW1jiO/Rn0W6K4D5dRtkdxHUjj2B1HfbUV82Yvtt0JvEeLWDrzuPvHcQ9M4j1UxH4gjdDsxbYjhLjBj/1QAfdADZ9hAb9hiaT1BM6uPNoNfuytMZQtAfQbgnhHxglHz+P0niGZvgWvbgLV9iiG1jjGlijqdT6sB3Pky7diy5wjVL8Vf+Q06vYM2v0pTLuiqJr9CNuiJH1LmKtncczehCowgVZuMNydQ9qfQtsSQ2qN4x6qYsjMoS/PI1fnEPPHGZQqjHan0bYlsR0rY+kqYLZW0KdqGLMV7JNTaFN1BnU59EdLeKRZ7CPj6HuSGNxRQtk08bEc3mqGUW8SvbqCz3mSgGMJfV8KedRNNh2lVIiQyXpRgi4svjqe6CkC4bNIxnFGDlpIuP2U437yQRt2h4w9XiRQOIM3eRolcBydksIjBci4gsStJgI2GYs7ijs9T6B8CiEyiy4+htWUImAJYh+w4LcYsbmCWG0lvMUFxNQs2vI8SqCBVUqgDLux6jwosh9Zn8biriClZ5EaJxHT86g1WTTDEURtDEGJIqjjiJo0/dY8hvpJpOwyKqGCdiiLRp1Do0qi02XQDqcRzWPYqucQkovoDA2kgRLCcAG9Ko+gKqEfzCHqK9hjSxgC80jGaUzDdazDNZSRMvJQCXm4jElTQxEnEAxTmJQZHAMNrN1VbEMVLCN1jAMVDD1lhINZxKEaVs0kPtUk7u4qjsE61t4aQkcc5WAGXWsS05ES5u4K3t4anmNl3L1VvP11HF0lDHvTyLsTGPZmsXYWcLdn8R7K4++u4Ouu4mjPYdydxLgzgWFnHHt7Fk9HGm9nFk97Dtf+LNbdSaytSZRtYczbYtj3p/F3ZPB2ZrC3JbDtimPYEsS2I4ZxcwjLzhie/Sni/RWcbXGsLSF0TQ7EdV6MG/0Yt/gxt4QJHs1RkSexbY8gNbsxt4Qwbwlg2xbGsTtBvLvE6dTNnK/eSrK/QuhwHn97muRAFe/BFLG+lbzni7c/zEP/+CinMzdRFsepmCcZt85Td8xwPLDEhbE7ePKBp7nz1q/z5Le/z6WvXebes/ezXDvDXSe/xcN3fZfz0zfy46de4r13f/mhAF++fJl33nmHS5cufaQgv/XWW9x777388pe//Mj6e++9x8WLF/ne9763KtCfMJ+2N62yypo1a1YF+s+Z559/nv7+/o8V6J/97Gc89dRTH1n7+b/+nIfufIycuoFpk5/Bvzdw9P9l7z2f7LyrfF/9BXOHO3POvTMDg2cMtlG0UkutrFYrS53DzvHZz/PsnHPOeffu3TlIrWQ5Y8AEB8k2sjECgwOeAQYYwxB88QC2gEOoqRo+90XDVHGwD+9GL9yfqlXdVev9U59evX7f9Vda+j+gR3WnFdfBGG3nPJcrD1GzTK+e6V7vYuwOmcEPrQq0tStErL9EU54hMVwk2ldA6oqg2+pHvd6DbqMX01Yf3t40mbEGjn0RImfyOA+nEffF0O2MYj9ewLg9hO9YDs+RFJqNVpz7Yzh70jiPZbH05vCMtXEN1PGcLiAfSCB1hbDtDaPb7MFxNIt7pIHXPI/fPE9cmMdyMIV+exDr7iiKj9rRbPER1rZx+1ZweVcolh7GcDyLam8ceX8c1T0ORu+y4x2s4vQsIMfOk5h8BJOhjeJEFvPRDNp7/Yx8xIZ8OI3bMY3WM42zfoFxV4NxbQ3lcAFNdwzF1gDm7jg2ZRW1q4Eh2kauLqBLTTMiVlH0ZjAcyyMcz2HoTaG1FjEFyjjSTay1FiPRGkPDGSyaCbzmWXQ9CZSjUezeDOFUnkAqjSaZYERKYXPP4vYvIxraDJ0KYRMixKJpUokIJpsNpTeMIzuPN7GEHFxkdDyLethNQAoT9wWxCmaMkh1vsY2ntIAtv8igt4ZgyBJwpPGafIhjApIgYXOkiTansBZmUBSn0XrrOOwFRGUIQWVDNlmRtD68qTLOxgTGyUX0hTlEuY5uPI5BEcZsciEZAshyAnthAtvCEvLMRQzWNpqRLJrxLHpzBKMugkWXQIjWMNba2GYvYnB10I+W0Y4WUavT6I051Jo0RqmMZ+oicusiamsb43AZ43AFjaqIXldEq8yi0ZWxJeYQk4sYrB3EkTrScBWTYjUHWj9ewqKqYDY2MZibSJY2tvE68tkq8mgdUdHAMlLBMlLBOFDCOFpFGK1iP1PCcaqCfaSB3FfFMVxH35tEeySFOFhGPF3EebyAdDCN7VQR12Ad+6kS1uNFLD0ZxOP51Xi7gykcPRkcvRlshzJ4zpSRDqeRD2WQD6fxnC7h2J/Auj+B9UACeV8CaU8M66EUtgNJrPuT+PuKeI+kkbtWJ9KWHSGk7ijyrgjSrgjOQ0liw1Wi/WWsu0LoN3gw3+tHt8mFdqMT01Yf7sNJ8vo2qfEG5i1ejJvcaNc7MG/yYtnuR+oKET6V52rzEaY8S4RP5vEdzRA4ll59WHg0jftogrKpzVJlhcfmP8Ni+CLTrmVK5gkymjrz4UsUtA1anhm+/PTLfOuV77BYXuHa1Rs889DzXH/wBsulizxx9Rk+d/k69889zNs/eeePBPj111/nO9/5Di+88MK7CvKvf/1rHn/88f+Ku/vf62c/+xkvvvgizz333JpA/zdzu71pjTXWrVu3JtDvZ37wgx9w7NixPyvQP/zhD3nppZfes//qC69T1LSwbPMz+iGRvr/S0vdXWlQfseI9kmLGf47HV56k7VrEfSiOcbObkTskhv92dYXDvjdKVlFnwj5PVegQ7y9g3xtF/TEP2s0+1Pc4kLtj+I5mSI5U8RyMEx8q4zyYwLwrjGFPHLknjWV3DN/xPLb9cVT3SFh2BLDui2I7nMByvIhvvI39VAnPmSLGrgjCNj/6DS5097iQ9sZwjU3gMUwTtCziV7TR7o5i3hPFsNnDyN9bMO0I4BmrY5UXCIYuEAtfRHs0h3A8j3lniOEPiSjvchJUNjDpWzhD50g0HkCva6AbqyOdyjN6t4vRf3TgOVvEpK9hFCfwli8x6qijsEwgjNVQdsdQbvGurnsoC+jEKpZgG6k8z3hqGoVQR3k8izhQRbs3jvJEAp2xgN3fwBaqoqq0GPRVUCnLOGwzCCNVhg9G0Y+ncLmLeIMFzJ4YA7EEencde2we2TPH4OkUmvE0DjGHT05iEXyMyFZsxQbu8hSOzAIDlgoqTQGTNoLbmkbUONFrBZzRGOHJCfyNKZTJFmpbHZerictexDjqQTYLOCQn6U6B6GQLc7WBuTiPwzONXayhV0aRjXbcgpNoLEFyroK708K+eB5ndBHBWEc3lsVsCuC0eHFbwwRKBYKLHUJXVpATi5hUNdRjJQzmNKI5hiTEEEMZQosLCO02psgURlUT81gdjaqAVsihM+TQG3NYK7M42+cxhaeRdR1ExQTa8TJafRWNpohKV0D2thGC0+iFJnZNB4dqEpOijkFVQ6esIGhqiOYWJm0Vi76OPFjBeraKrGhhUTSxjNQRxuvYlHWE4TKW/gKOvjL20yWkk0XEvir20Sb24Tr6E1lM/TmE3izWoxmsvVnEnixibw7ryRLOvgqOsxWcAzUcJ3JYDyax9WQQ9sax7E0i92Sw9eZwnSziPFEkMFjGfSyDpSuMuSuM0BVZveS5P4H7aB73iSyRkRrBMwWk7iiGjV70v//DVdwdQdodIXiyQMUyTWSghOleP/oN7tUouw3u1bi6jQ7Cp3LMhc4TPJHFuOn3/Xuc6De6MW5wY9zsIXK2wNXawxS17dWp8++TOP6QyBE6mSWpKvHJpc/S9MxQESZZiFykJc9RETtkVFXmgxc4X7jKoxce46vPvsZzj7xIJzbLC5+6yefOP80Lj3+J+yYe4rGlx/nazX/ixS988U8E+Hvf+x4vv/wyN2/e/LOPBN9rQv2Vr3yF69evrwn0fzO325vWWGPdunVrAv1+5p133mHv3r1/VqDffPNNbt68+Z79rzzzKg1pFrkryPg/SJz9gJa+v9ahucuG/1iaueAFPnXuCSZdy7gPx9FvdjO7ZghXAAAgAElEQVT09yLDHzSjvNOGbXeY9EiV5GiFqrmDvzeNtDuE8m43xm0B1Hc5se+N4zoYx3Mojn1vFNehOHJ3BM3mAPKhDMKeBNaDSeyHU5i3+1F8VMR8rxdxRwjT7gjWUxWcg3XsJ8u4TpcwbAti2R5E81E7+g1OTDtC2EbqeLVThMVFXMNNTIfSWA/EUf6jjdE7ZMw7g1jOlpDULRLpB3Bb5tD3VfGONtCs9zD4QQvm7QHkgTLa/gLh+EUC2avojZNYjZOYDqcY/LCMZqMX+UwB9UAOq9gmUL3MoLOJzjmNabCMYm8c5b1+jPtijJ9JIUktbK4JdNUlRtIzqPU19IoK2pNpVHsjjB+NYdGXsMo19L4yZyotRpwVTO5JRNsUo0cTDB2NYzVWcUo1LOY0Q+Eo6mwROd/Blp5mTFdi6FQCl62Fx1bDLmVRmaxYCjFCkw38zTaGRJ1+ZR63o4NFKGETsph0Mh6/k8J8juxiFUe1jCZYx+GdJRSex6ItIepd+G0S5XqI+rkC4cks9nYTR2wel3Meg6aMoAvgk2wkgz4aywlSU1lSl9p484vY5VmMqjp6XQaHLYDPFiSaihGfylG4bwpfYx5ZmsGibWMUqpgsSSQ5gdkaxpspEppoISVrmI1tbKYZDMYWWmsZrbmEVpfB5K/iyEwgBSYQ1S3spiks5g4GoYVGX0OlK2MWq5jtdYxiFZtmAnmohmScwqRvo1PVMalrSMIEZmUZQV1FHqgg9VeQh+sI402E0Sbm0RY2TQtZU8d4MoOtr7C6gnO6gqE3h3Wojm24gXWogUNRx9ATQz6cQj6eQz6WRziQxnQwje1MBddAnaBqAk9/GeexDLaeDMauKMauKObuBObuBO5TVcJjbRLKFuH+CvKhJIatfrSbvBi2BTFvD2E/lCI20qJsmiY+UkXaHUW/0Yt2gwfNPR4MW71YdgaJDlWY9C4TPFvEsMmDfqMH/Xo3uvUudBs9mDZ7kA8GmAuv4D4Yx7DBjW6DC/16B/r1HvTrnZi3+slomiynLhEfLBM4lsV7JEWgN4OvN03gRI7ImTzn0/exkDvPbPAcBX2TgrFF2zbHXOACWVWVun2apy4/w+s3v8Fi5QLXHvg81+7/PNOZBZ66/Aw3PnmTp69+nqcfepbnn32BN3/0Jl/+8kt/IsBvv/02N27c4KWX/rT3h/rDI8F367355pu88sorfPGLX+TWrVu3+3P+vuJ2e9Maa6xbt25NoN/P/Md//Adbt279swL91ltv8YUvfOE9+88++jxF3cTvJ9ACp/9CTd//0KG+U8a1L0rLPs+lwoPUxCns+6Jo7nYy+EELIx+0oLhTRtjmJTlSxnc0RU7dwHM4gbDdz+hH7Og3+1Dd7UTeFcG6J4y8K4TvWAr7vgi2PVFUm73IR7Lod4ZxHysg7Ipi2RpA9TEr0jYvlm1+dNuDOPoq2M9UcJ6t4ThZxrQ9gLA9iPojdsybvei3B7D1VfFpOoSFeazDTexnKog7w4x+WEZ3lwupO4L+UBK7aoJ89mHs5nlsmmm8I3XGPmJj+A4b4t4I2sNxdEfT5KoP44hexGybxyPMouqOMPQRO4adQVT7IygOR/FYp/C17qfP28bsmkE7VGZ8Txj17jCK7hDK3giypoorNsd4ewlFfAqdtYHeUGfscJzxvSHUxxI4TS0ccgPlRIehSgtjegIhMc24qshgTwJDXw6PNInX3sLkz6CZyOGebOFsthFjdfoHUwjKOj7rDD73NIIxjJzykl0ukJiv4W1VGZPySMIEfvc8gr6KXhXCZZOpzwWZuJQiP5NGzmSwB2YIB87jEKcwa5J4ZBvFhJvOfJjKTID0dAp/oYM/cB6bPItZX8LtCBCzuSkVPKRTTirTMVLTHYLR89jFOYxCA9mXxeOO47EGCEa8ZGppIuUK3ugyNts8ZuskRncdq7+G0RDGYgnjS+bx5auYjFXMhiZmeQZDYBq9u4Vam0VtyCC5y8juCpKlgUXdxCJOY/EsoBPbKAxVzOYaOnUek6mMrGsgjlYQVU0s0gx6/QRmbQuLZRJhvIJlpIQ4WEIcqCCN1jEP1zCPNRFUbazqJnZlA3mwhO1sAfFEAamvhKE3h+lYAWmwjnWkRkA3iXOgiHF/GPvJPNLRLIa9MbS74liO5HENNAiOTxAabuAfrODpK2HeE0O9xb8aVbctiP1EmaiiTULRIjbawHkki+HeANqNfrRbfGg2eZAPJEgpWpTMHeKDFcTdkd+nbHjRfMyNbqMbcVeEtKLBhGeJ8Jk8lh1BzFv8q1Pn9R50GzwI2wMUDBNEFXlcBxOIO4II2/wYNrpXj6hscCPvCjHpWWTCuUjoVAHPkSS+I2l8PSmCxzIEjmbIjNX4+Nynub/2ceLjJSYc85RNkySVJSbsS0x7z9FwTPHp+57gpeuv8JlzT9HwdnjmoRt8buUa86VzPHnlGT7/6Bf45y99kx//6C0+ft8n+erzr/LUJ67xzs9u/ZEA/+Y3v+Gpp57i5Zdffk+B/sMjwXfrff/73+f111/n1q1baxPo/2Zutzetsca6devWBPr9zO9+9zu2bNnyZwX6pz/9KTdu3HjP/uPnniSvaWHZ4Wf4Q2ZO/YWas3+tZfwfJBx7o9SEKaY8i7TlOTw9CTQfczHwNwaGPmhB8Q9W9JvcRM7kiZzMUtS08PUkMe8MoLrbiWa9B/0mH4bNXqzdUey7w4RPZZG7glj3hNBtDSIeTKLfGcZxIo9pWwDrjiDqe2Qs23wI93rRd0Vw99WQjufxDDZwnqli6Qqj2+BBfbcd071etJv9OPqq+HVT+PVzeFTT+Efq6LZ4Gf6QtDpR2xpAvSOMX5giErkPu7RI0L6McCTN0J02NBtcGHeGGd/qQ+wrkGk8gjV+EWfkAjZNi9GdfpTb/Bh3hRnfEcB4JEkqcxF58gHGY9MIzkn0ijKK/TH0e2KM7whjOZ3Ha25jn7mMduYCxuQclugsytEi44eTqPfEsY9UCZg7OGJTKBZnMDU6SLUZ9KEGAwMpVL1p3NpJ/JYZHHIFfTGFd6lBYKGFu91gWMyhGioQEOcIWOexm6pYZDfFpSSVi0VyywUsiTgGuUzQsYzftYRJXUTQOcknA7RnIzRnAkRLXtypEqHQCn7vOWRLG1mOErL6aNRCVApOMgmZRLtAILlMIHwRSZ7G4ingscdJegPEAw6yaRvJUhxveo5A4iKiYwZdcAJ7tI5DjGMzO4iFQkSSCay+Fq7AArJ3DkN4Fjk5h9FeRDMawGZN4ghlsdhqWIQmSkMFc3wZU2wRtaWJWp9Fr8lgNGWxCBUshtWDKGJgHjGwjNLSxmRqoBvLra6PqEqIygpmbQOTfgJBnkYwdrCYOphHS1iGCwgDBYT+AuJYHctwDUN/FZO6jVUziVPRQOovYu0rYx8uI50pYuhJo96fxHy2gjzSxK+cwNNfwdlXQncwivVkAdWuKMqtIUwH0zj7qwRGmoSGqgSG63jOVjDti6PZHka3zY9maxjnySKRsTqJsSaRoRquo1lMXVFMO0Lot6weUbEdThFXNigaOkSHa6sHiHaGEbrCaH+fvW7bG6Og71CX5wicymPdE8WyI4Bpmx/TFh/a9S6suyO0HItUhGmMOz3YusOIO0MI23yYN/vQr3fjPhRnyneexEgNT08S18EEvt4UviMpAsfT+I6laYozfGLhs0x5zpEZb+A7laCgnWDStUioP8NsYIUHmp/k8auf4/7JR7lUeJAr5Ydp++dYKd7Pcw89z1Rynhc//SV+8MaP+P9+8BY3P/dVlmsXuPGZF3nuief519e/+1850H+oa9eu8corr7ynQD/11FN89atffdfeG2+8wTe+8Q1+/etf85//+Z+3+3P+vuJ2e9Maa6xbt25NoN/P/EGgf/7zn/8fBfqdd97h2Weffc9DKk9deYamMI2tO8jYh0VO/6WGMx/QMPZhAceeGCVdm2nvOeryNIGjKXQb3Ax9UGDog2bG75AxbHDjO54lO14j1lfA35tE2BFEu8GF4h7H6hrH3Q6se6I4D8TwH0tj2epD3hvBuCuCeU8M864ktiNZhB0h5F0hxu4UMW9yY9jkQtgfx3asgHSiiHuohauvirw3ivJuB7r1jtVJ2WYP9tNFfPoZPPoZvMY5ImNNFOvdKO9xIO70o/qYC+O+BJngBdzu83g9F8gnrqDZHUZ5rx9hVwjNFh+qe/2k3MsECw9gS10iUXkE03gVxZ4Yhj1xNFsDqLYH8I01iDcfwtK8gjE9j9E1iXIwj+JIAs3OMLo9MdzDNULBJYzzlzBMLCOWFzAEJhkeyKDYF8d8JItf3calaaKvtTHNTOFdXsTemWVEKjF8KoV1qE7QMINT08IgJnFWCySWW8TvayMU8oyo0jj0HfzWBXzSHJqxGP5olGInT3kuR3Qiis4Tx+2dI+g9j9+9hEoVR9K4qZYTNCcjJGNWXLkg3tQ8/uhFfMEV9I4Gopgg7o9QzYdJuERCGTeudAtv9gK++Aoa/yRSrI5LjBN0BPFb7URjAWyBIs7oHI7MefSJOSyFBWRfA0EVwGoI4PGGMXtyyK4WztgCxtw5xOoFzLFZ1ONJ9Ko4JlMcnSWDKFYxinXGfU1stSvowwto9CV0ihxqRQatIo1eW8CoLSO553AWrqB1z2M0T6AfLqIfLWJSrGY8G0YKmHUNRNsUJmkao2kKy1AZy1AZYbiEcTCPaaiMabCI7mwBvbqFpJ3EMdbEeraCbbCMPFxC6itjOJZFcziFaaCKPNrAP97C3Vde/W9JfwXtoSjmw0l0u6OIJ4o4hhr4h+oE+mt4h6s4+6pIh7OY9iQxdccw7UvgPFMhMlojMtYgMFDBfaqM7XAGYXcE064Y5t0x7L054mMNMpoJQn1lPEdzq48Ju2OYt4ewdEWwH0yS1bVIKZq4ezN4jmSxdkeR90QRtgawbA/hPJygYZshdDKPtTuC4V43ws4Atl1hxK4Q4s4Q4TMFWo4FXAfiiDuCWHeFsO2J4OpJ4j+aJnQyx2xohUu1h0iOVPAeXZVq17EIWVWTujhDXJXncxee5svXXmEmskRFmGQl8wBL8cvMJc4xFz/PZ1aucd/Mg7z15k/4l1e+zfOP3eSJi9d5YOFhPnPlCa598hn+9fXv/lEKx29/+1teeOGF91zh+EPE3XPPPfeu/W9/+9t861vfWhPo28Dt9qY11li3bt2aQL/f2bx5858V6J///Odcv379PeT6Fjef/iotaQbrriBjH7Zw5gMaTv+FmtG/E7DvDlHQtJkNnqMmTuM/lka7wcXoh0WGPmhm9EMWdHc7cR+OU9RO4OtJEO3LI2zzY9wWQHG3A9OOAMo7bTj2RfH0pLDvjSB3+ZH3RrHtX824lXuymLtjyHsiOA8mUNwlIm73ImzzY+vJIB5OYT9TwzXSwn2qhKM3jW6TD9ueCMbNXoRdEdxnivj0s/iM88Rs5/D0VVBu9iHuCiPuCKL6mAvH6QKp4EWcznPEovcRti+h7Aph6I4jdoVQ3OPG1B2jknsIW+IC/sL9hNMX0fUVUB9JY9wTRbnJi2FXlIR1AUf5MvbGFYTkDAZ7G+VICcPRFOqtYSyH0jjPlhFD0+jLSzjmL2HrnEftajMymEOzP4ljsI7jTAmzpow22cTdmiFw+TzmxjSDQhHNmTw+wwxezSTa02kM7gzhRoN4p0lwvsF4IIveWMFrXyBgX0Q3VkKriJAolcnV86SqKXQxP0KojidyDl/gHGbXNOMjUWxigHwxQzIWxOazISeK+HLn8CRXEKMLaD11HEKGWDCD3+bB7bFhCSRwJTv4S0uYUguYK8vIniZ2IYmsCeC0+5C8UWRHAVdmBnNxHmn6CmLuHJK5iEEZw6QKYpBCmIUMor2MpbSIY+F+rK3L6AwV9GMZNMoUKmUMvSaJVpVGCE2izU9hKa+gFproBotoR3KolCm06hyq4TRGYw1neQVdfHH1eMtAGcNgEaMij3ZktXTKMqKzg9k3iyjPYBuqIg5UMI+U0Y+sZkGbRkqYxmsI4hQOeRaXoo3tbAXbUBXLcBlxsIzQX8B4KodFM4FbmCGkmMB1poxjoIJ9oIpjsIr6QBTDgQTyYJWAZorwaIvgQBXfcB3X2Sr2E0Wk3izi4QxibxbfUJXoaJ1gX5VAfw3XiQLuk0Xk/Smk/UmsB1P4zpaJDpYJnC7h6Enh6s1iP5jGcTiFvC+GuC9GuK9IcqiC52gGaXcUaU8U16EUzkNppF1hrHtixEbKpMYqCNu86DY6Md67mqeu2+zAtN2DsNNHaCiL51QcxUdlFHdKKD4qor5bRrPBhm6TE8fBIFXnBFldFdvBINJuP7b9YTy9MbzHkhS1beaCK1yavI/PXnqaC5kHyWgrNMRpOu5lrpQfYcqzyEximZdvvMaTn36aLz/9Mtfuv8Fzj7zA9QducLF+P4+ufJInHnya77z+Xf7XL//XH0nwSy+9xIsvvviugvyLX/yC559/nmeeeeZdkzi+8Y1v8MYbb6wJ9G3gdnvTGmusW7duTaDf72zevJlbt269pzzfunWLW7duce3aNW7dusU777zzX/X222/z9ttv881X/4WGNLP6iPAOkf6/NnDqL1QM/60Jcbuf9FiN5fQVWrZZQifS6De5UPyDlZEPCYz8nQXjxtV/8zas04ROZ8mM15F2hzBs8zN2lwvD9gDau124DiWIDZRxH4wROpHFfTiNfX8MzbYQjuNFzF0hnEfSuA6l0G12YN8dRtoVxt2TxdKTwT3Uwj3QxHOmhHwghWl7CNfBKNr1LuRDCdxny3iNc7iNsyTsywiHs+i6wrh7Mmg+5kR9j4uIooXfdQ6nY4lC8RHE4QaanjTOE3n0m7yM/KOE+2SegHcZOXSOVOtR3IFl9ENVzH0lDF0xxu92Y9kXxyt0MDg7RKYewlZaRm1poFE1MPak0HZFMO9LYusvorE3sOWWCMxfQW5eYNTRRnU6h/FkDnt/Gf2hJEpDEUdqCl9zDs/sEsPZCYbUZWTdJF5xFsPJPCNnknhiTSLlNqFqC0U6x5iviN0/j8uziCxOM3QijttVJZqsEy+U0Hr8KMNJHPkFXMlFxPA8w4YqFlMB0RIhEskh2tzoXX5cmQbeygJyao6x2Ayys03Q38RlTiLqPQh2F6ItSajeRipOY6guIuWWcPomsWgymBRBjCYPFl0IV6iEozyBdXoFW+cKsn0K3XgO9XACnTGEWRPEaIojJRt4ly/gWriKyd5BP1JGPVpAq06g18XRqxIYXGV885dR5lqY3TNYVHWMo2VU41m0+hyK8RR6QxlX7TzW2gqifx6btoM02sCoqqAdK6IZzaNVlbD6ZrBllrAF5vHqp3COtRBGqxgUZUzjZUyjZSRjE9k1g9czT9g4h1cxgXW4gThSQxqqIAxUEEcqWDUtvOYOYc0kIcUE9oEa9oEqtoEa1rNl9L1JpKEKXsXqrrOvv4b7bA1XXx3biTL2U0Ucp4o4TlfwD60eRfGfLWHtSSMfzqxOn3uyOHtzuI7nCPWV8J/KIe6LInQFMWz3Y9jqR9wXxbIvimVfGF9fBufxKOqNNsY/amX8HivK9Va0m10Ytnmw7PGT0BZx9UZQftSK8k4J7Xo7uvUuDJtcGLY4CZ7NM+GZw9UbR7/ejfZuB9p7Vh8RStsDiF0hMqomj0w9RtUyjf94Dm9PmuDxLP4jaWJniyRHqsyFLvCFx2+ykFyhKnWY9Z8nPlpgwj5H07rAYuQSF3IPcN/cg7z64te42LzK51au8eJnvsxnzz/N85/8Eg92Ps5y9SJPPHSNn/37nx5Eee21195zwvzOO+/wxS9+kZs3b77rNcLXX3+d73//+/z617/md7/73e3+lL+vuN3etMYa69atWxPo9zt33HEH//Zv/8bPfvaz/2Ndu3btv37/gzj/QaS/9+1/Y8q/jGNvBPWdMn3/j4HT/5eKsb8XsHaFqJg7XK0/ykL8EpGzRcTtAcbvtDH4d2ZGPigg7QgQOJGlZZ0lPVYjp25i746g2+RBvdGDdrMHw71e3D0pkmNVPAcSJEbKOPcnsewMo98ZxX40h3F7GO/xPPL+GObtbuTdIRz7Yzj2x7D05HAPN3H2V3GfKmDZG8d5OIl1TwTt3S7kfVE8I03cmmn8plkihmlMPVlsx/PYDsQYv9OKYaOX4HgdpzCD371MsfAownAdqX/1XLLiLgeKj9gJjlRX0xwcC9QWPovNsYBB3cI5UkW1LcDY3U5cx3KYlFXMwgTZmUewF1cYFScQtS2MvVkM3VEMu6MYBvIYTXVC+RX8zRV05RXG7RMYhirYlC30B5MoDiXQ68pEcot4s7PoylP0hxvo5Qns9lkkdYuh/RF0wxmi6XnC6WmEUJHT0RxicgpbfAF7cJ6h/iy6kRx+9wSRWBvZk2bY5kcqVHBXZ3Bk5xi2NdBoKvg9U5gNSUyaGDqTC9ETJzDZwtfqoEq10Pk7eN0zuKwt9KMxjAYHktFNqJAh0G4h1icQm0vYffOIxia68SwGrQ/Z5MHpjBBoFfB0JvAsr+AILyDqmhjHyxiFOJIpiGwOYUtkCSxNE7xwHkd6EVk/iaBuYjQWMZpTGIwJ9LY0gYV5fOcuoA82sBo6WHUdDIY6OksFpSaLRpNBys3gX7iCLbOER5zDoe8gCpPoNXU0ihIaTRmLaxJHZglbYBa/PI9XP4tsnMGkbmAcq2JWVBCNDWy2Dk6pg1/dxquZxGucxTLaQBqtIQzXkMfrOEwtHOoG/vEGnpEG9uEm9oEa1v4a0tky0pkS0kgJ87EEzhNZ7KcLiEfSGPbHMB5KYu5JYTyURDqdRT6RwHIghOlAGNUWL8otXtTbfah3+jHtjyL1JvH2Z3GeTKHd6kGzxYV2swvtVh/GXUGsh5L4+0pUrNNEh8oYfr/fbNzixXSvH2lXBOv+BInROkup+wicKKDf4EG73rUqzhu9CNsCWHaEcJ6IsJS8vJq2s8mNfr0TwwYnhvUuDOs9yDuCFLQTrGQeJDVSxX80jb8nvZrC0ZvGfzRD+HSeGf95PrPyFJcLD1E2TZLVVmnb5kmpy5TNU8wFVnio9RgvPfsK55uXePzc51ip3ce1B27w1JVn+fzHX+SJS9d5+oHnuLr0AN/65rfeVZL/6Z/+iSeffPJdez/5yU/48pe/zNe//nXeeOONP+m/8sor/OhHP1oT6NvA7famNdZYt27dmkC/39mxYwf/8i//8kdrHL/85S//qH71q19x/fp1fvWrX71rffeb/8a09xzuQzEU/2jl7P+t5cxfaFDcIeHcE6Vlm+PBiU+wGLtE6HQO83Yvox+SGPxbE2MflpB2hQifzVPUTtCwTJNXNnHtj6G824VqgwfVPU7E3WGcB5IETmbx9aZIjlbxH0sj7Axj6o4j7ksidEdx9+aw7Usg7vIhbPfiOBBD3hdDPlHA2VfFeaaM60wZ+WAGT08aw0YPps1e5O4Ijv4qLtUkIcscfnUH+XSFQF8FwyYvio/YkbrD2M8UEccapCKXiAcvIyomCOinEfbEGPlHG8YtPlz9ZXRniwTdS5RnH0eyL2GX55DOlhjf4EWzyYd8PIPmZAaHpU1+8hHEwkXG7C3MijpCXxlNVxT9niiqEynswgSR+DKu5n0oi0vorG2s4hTCSA1Fd5ixA1Fs+jqB0Bz2UIehagdNooMUmUX2zDB2KsPA/ihWfQ23dRKXs8mAI4G20sBamcaen2XcUmPwRBK3MInPNoldrKPQuDEnEwQ6LVzNCYzJOkP6Ik7LNAHXLMr+KDqVG6vdS2wyS3Shilwsok+2sNln8TvmsWjrmPUhnJKbeCZCZiGPv5XHM9vGGZ3H71xA0k9gMqRwO4MEvRFizRixToHU5Ul8pQW8rmVk3RRmqYbVnsJuT2EPxgjPV8hemSE0uYTXvYzNNINZaiM4a5jkPBohjqvQwjs9RXhyGcnSxm6ewixOY/ZOoTGWUWsLGH11bNlpnPFpvM55PPZF7M55LNYZtLo6Gl0Vk1xDsDdxuKfwiB2c2g4e+yI2eQ69soFxvIpJV8cwXkDUVrCNVZCGK1hGqhiG6mjO5NGcyaE8nUE/mEV3NIrxeBzT8TSGk2lU+6IoDiVR9STRHEljGcgiHI1jPBjGejqP8VACze4w+j1xLEdzSCfyeEYaREbrBIfLOHozmHbFMO6MIHTHEbrjuE6VialaFPQdEuMNLHuiaDZ50W70YtwaxLwziPVgkpSqxaTvHJGzJYRtQYxb/Og2etDc5cCwOYBlV4jMeIPlzH34jmUQtvkxb/WvRth9zIn2Yw4sW/yUjB2i6jyuQwksOwII2wIYN7rR/T6Jw7ItSFOaoelcIHgyh68nje9ICk9PmsCxVYFOjdW4WHiQRyY/yax/hUnnIjVhmvhYgUnnEjFlkWnfOT535Tqv3PgaL3zyJtPJRT618jmWixf5/Mdf5MmL13nukS9w84mv8qPvvslnPv0ZfvCDH7yrJH/ta1/jqaeeetcVjR//+Me8/PLL/PCHP+TVV1/9k/5XvvIV3nrrrTWBvg3cbm9aY41169atCfT7neHhYV599dX3lOM/1LPPPvtfMv2/19e//E0Wwhfw9CZR32Xn7F/pOPOXWsY+LCLvClLWd7hae5TL1YeI95WRd4UY/rDE0N8JjH5YxHSvj8CJLImhMtO+c6RHa/iPplDf48a41Y/iow7k7ghSd4TAiRzhM3mCJzIETmQx7QhjPbSagWs7nMF+JI1jfxxptw/DFifuA3Es3WHsJ0vYz5RWzyH313Aey2Pfn0BztwPrrjDWfXHE43lcIy3i0jIe1SR+dQfv8RyKjzrQrXfjPpTEuD+F1F+hlH2YoOs8bssCCXEe5UY/io+6cByMYzwYR38oRTp2iWj5YZyhC0SCKwiniyg3+zDuCKHrjqI9nMRvnCRefwhL6TIa+wSSqYPhZIHxnSFUXWHUB2K41A289hlMswXNiHEAACAASURBVFfQFZYQg7NY7G3Ge5OM7gqiP5LCrW3iME6gijYZrkwiluawpOZQCxUGDsUQzhRwG9p4LG20xhTj5SK+hTlsEx3MyQZ9Q2lERQOfeQqvPIVelcQUiJC9PEHsXBtno8y4q4BobhOwzuOTZlCOhJBtfoozeVoPVgm1ksjFHI7gNEH3Mj7bHBZDCZs9TDKdoHGxRHoqTHIuh788hd97Hp9zCYu5ic2XIxjIkK4kCRVDFM8XiU21CUZX8LnPIUhTWAINHKEyNnsaRzROtFIk0mwRSF/A7z+P6JzDHJ5GDrXRmXOYbWnsqQqudB23dw67YwaDNIkYmcfomESpKaHQZ9BYcujkIoJYx6JpYJGnMNqmUOlrjIwXGB/PMnQ6gmI0gXowuSrAyhIGY4Px0RLjg3kUw3kUZxKoT8Yw9WeQxipIihqmwQqGgTL6oRqmodXps/VsAfvZIq7RBq7xBsbeLLpjOcSzNexDdQLKSQJDq2e7DQeiiEeymPenMHQnEA5lcPTViChbxMZahEcbOI/nMXaF0e8IYdweQbc1hP1Yjrhqgqx+ktBgBevBJOauCMZtAQxbfOg2e5C6Y6TVE7ScC0T6y0i7I5i2B7HsDKHb4EW3wY1lR4iqMMOU7xy+Yzms3RHEnSFM9wYwbvGi3+hC6grTdi/SsM9h6vIi7wohdgUx3+vFvNWPfr0L96E4075zZJUN/EczeHtSeI/8Po3jWBrfkTQVc4eHJz/Fhfz9tGwLtJ0LTFhnmXQtEuxPMRtaoWBpcOOTX+RLT36VJ688yxMXn+Fy634u1K5ytfMQn125xo2Pf5Gvf+kb/PStn/Lm937Mgxcf4utf+wa/+c1v3nWK/MILL7xr1vMPf/hDXnvtNX7xi19w48aNP+nfvHmTn/70p2sCfRu43d60xhrr1q1bE+j3OyaTiRs3bvxZgX7++ed5++2337X3ja9+iyvFhwgcy6C9x0H//9Bz9gMaRv7OjGW7n4KqwaXiQ9xf+zjJ4TJiV4DxOyVGPiQxdoeE/mMuwiezZMbqdHxLxPpKeI+m0G3yYrw3gOpuB0JXEEtXkMjpPImBCr4jKfy9q9cHbYfSGLZHcJzII+6J4DmSRNoZwLjFhWN/FHFfHPfJIo4TZRxna3iH6vhOFZG6wmjuduI5EMfcFUI8kMI/PkHIOI9PM03Gtox8MIniIzbkrhBidwT1lgCukQbZ+H04pWWS4fsIa6ZQbHCj2+LHtN2PcrMP84EElfLHccYv4U/fR8C1hL4niXJ7CMP2IIrNXkwHk0TkWRz1q0jly6jEOpLUQXkkiWpXCMVWP9LxHF5lHWtiGe3kRYTCIvbCEnpjjaHDcZRdYewDVfyaCSSpgbI5g21hGef8BYTSDAODWRQ9cTyKNl5dB5uhhjacJ/TgAtH7lwicm2NIzqMeyeEzThMwz+I2T2CQYmQvTFB5bJbc/S2MiQR6RxWffZGgvIhb6qDWhogk0rTvr1G7XCRQCePM1wh4lvG7zuOyzyHYS/i8GQoTRTK1CPGij+hMFU9iGX/4Ak7vImZ/G1e0QTCYxRcME8lECJayuNML+OMXsQXPYQzNIMc7WKx5zMYANm8MWySJ3lZC9HQweyfRBDroApMozAWGB/0o1AHGTWHGNSlUmhwqsY460Ebt7TBqqDA4mmD4bIjx8QRqTRa9uoggNLFGlhD9C6hNbQy6JprhLPqRHIKyhKiuYTN3cNnnMVtmMBsmMevaSCNVxIEiYl8OabSMXdlAGGlgHCgjqCaQlBO4VE2c/SVs/SWsfWXE0wWMR7MYerJY+mrII3V8Iy38A1VcfWUcZyso9wQx7k9g6I4g9GRwDNQJjzWIjdYJDNZwniojHUxh7I5h6l49pGI9miWubJDWTBLoK+M+VsC2P4l5ZxTDjiBCVxTroSQ5U4eKZZrAmQKeI1nErgjWvTGEbSGE7SGs++O0vUuUzNO4D6fx9mawdscRuyIIOwIIW/24e5LMRi+TUzbx9aYxdfmQuoLIO4NIO0NI2wPE+8u0nQuEThRwH0rgOZLC05Na/XkkRfhsgWn/OR7tPE7HvUhB16aobdOS52k7lpiwLpBQFni4/QnOty/x2ZXrXMo/yMOTj3O1+ihX24+wmFvhaucRvvCpm3z/2z/ixz94i69cf5WXn/saD5x/mBeefJG3fvine8wvvfQSr732Gt/5znf+pPe9732Pf/7nf+a3v/0t169f/xMB/8IXvsCtW7f4zW9+c7s/4+87brc3rbHGunXr1gT6/Y7X6+Xxxx//swJ98+ZN/v3f//1dez/87ps80PwE4ZM5dHc7GPifRs58QMPI3wgIW7xkxxs8PPUpLuYfID1aw7I9gOYeJyMfsjD+DxKqj9gIHs9Q1k8yYZsjcjqH50gK884Q6g1etL+PmZO2rwp0ZryGa18UV28C24Ek4t44xq4IzqN5hJ1hPEdSiF0hzFudWHeHELuj2HtzSCdKeAZbeAcbeE8UMGzxYr7Xh707iuoeF/LhNCH1BH7tLF7dHDn7EvptIbQbPEi7QijvcaHe7CUtLxB0X8BjPUcp8zDm3hyqbSGE3WG0G9wo1rsIq5rEsw9gjV0kUXoIhziDrjeN4WAC7SYvys0+XKcKROMXsJQu4WtcReeqYxbaqE5kUO8IYdgZxdNXxWuYRGisYJ25infuKrbiecY1Zcb2xzEfzuAfa+IcraGNT2K9cJHQ/Q/gObeCMjjBwOk0cn8Vn7qDR91GZyrg6nRIP7xC+uMrWFp1Bg0ZnIYp/JZ5fMIMOlUeV6hE/lyH0uUOgZk8mkgWh2cWr2sBt3UBvVzDYIqTKBcpzlYIpkI4qxlcqRm8wXM4PYvoXB0EVxW3N0Mkm8LhcWON+dCHy5gDHczOSUY9E2hjLXTGBAa9H73JjtHhZFyKobaVUbrqjAVa6LIzaDx1VMNBVKogOimMypJEIxYxeVsYs+ewNS9jji+gUubQjCZR69LohAJmsYZRamIvXECfmMcYWEBnaqIbyKEezKIZz6FXFTGZaljdsziTFzB6FrBI0xgHSxgHi+iGc2j7spjHy4j6CQRzB9k1j1WcxT7aQDhbxNxfwDJWwtiXx9yXx3i2iKifxC3M4ldO4jhTRu4rIfaVsPSVEE7mMfSmkQZreHQdIqrVDGhXfw372TLy6SLK7jD6/XGsJwoEVJMkVG2CwzW8/XVcpyvYjuaRD6UQDiQQDyTxDTXI6KdJqdv4zlRwHMvhPpFH3JdA2BNF3pckMFChapklp57Ae7KAszeNbX8K15EUUncEaU+UcH+ZjnuZxFAV58EUniMZXIdTOA+lsO2JYNsfJ6tqMeGcx3ckhX1fHPv+GNa9IcRdfpz74ngOJ6kJU+Q0DWy7w8g7g8i7wzj2RvD2ZPD1pMiM1blUfpiV9H1klQ1ifWVSQxVyqhYFdZNJ5xJzoYtcbN7Hkw9cp+xoM+1e5kLmflZSD/DY1GdYyV5lLr/MEw9d49/f/Anfeu07PP+JL/LsQy/w8nNf42LnCs89cYM3/ul77zpFfuONN971mMq//uu/8s1vfpPf/va3vPjii7z99h8/Qvz85z/PL3/5yzWBvg3cbm9aY41169atCfT7nWw2y5UrV/6sQH/lK1/hRz/60bv2fvGLX/LY/KeJni2g3+Bk6P81cuYv1Qz9jRHzFg+pkQoPND7OhfwDFDVN5F1hdPc4GPmQhZG/t6C404rncIKqcYqipk1mvIbvaBZxd5jxuxwYtgVR3+VA7grhO5ImdrqA80CMwPEMtv0JjDvCCPuT2A7nEHeFcfekMd3rxbTVibjVj7Qninwgif1kGc9gHX9/DUdvGs16N859McRtftTrndiPZAgaZ/FopwlblgiMNdFsDSLvT2DbE0P5UTuWvTFy/gs4rcsEvRfIRC6hP5TCeCiF/UAC9UYv+i0+Sv4VnKELuBOXSTcfxW7qoDtZQOpJo9nkx9QVIaJuY0+u4ChfITH/GHr/BDptE/3pHJodYeQjOZynSsjWCaTaBWL3PUZ45WGMsQVGx4voD2dwDtZx9VcwDBQwx6eInL9K/OEHsc2t0CeW0Q2XcGsn8ao76M7k0MllUgvnSC0tE7q0yHCshFFq4pRmcZhnUI+WUYykCJfbRP5/9t7zSbLrPtPsf2BDWu2uNCNSI40o0cO0b7Sp7q6udlXVXd5mZaXPmzdveu+9964qs7xp3+gGQAAESMI7wpAEDQQQECF6kUMStAIByD77oQmEKELDidiIwUagnojz4caJ/JZx8omT731/xSLWRJzxoJ9pZw6VVEWjLjKuyjM0GkajC2PyhtGbHUxZzIxYg8yYC8xKRUZ1ecasJVTKJCZrDL3eh8JkZ8riQ+3OYQg2kQWaqDIrCL45BE0KtTyEWu9DZY2gM2cQQnV06QWMzQsYcutoFBnkY1Gmp0LM6kJoDEk0YgZduoO1dRFj8RxKVRXVeJrp0ShT40Hkihgzsjg6Zx1b/QLjzhqCZR7teB7VWBrZeAzZSITp0QjK2TxSeAVDdBWzfRHzdBVhrIByPIVsMI58JIVqIotOV0P0LSNZF3DNNjGPFVEPZtGM51ANplENpzBMFBGEOZymBfyqNo6JCsJgFt3ZLMJgFu2ZDLq+NNJMFY/QIaabxz1ZRRrMI53JIPZmMPRmkB3yY+jPEtTPk9K3CUzVcAwWMPemEY+nMJ1KIp1KI51MEpytUbasEJmpYT2dwnQsgfV0CulwBMuxOJaTSeLyBmXTAp7+FObuCNaeJGJXGNuJBJZjMWzHExQMbQr6BqauEMIeL+IBP6bDIazHbrw34O5PMu9ZIzpRQL/diX6nB90uN8bbvEgHPOj2uQgOZamYF3D1xlDdbEdziw31TQ4Me270tNuOhSkJbS4Ur1GzLOLvT+I8HsF/Nk1gIEtsrEBqpsZG8gqfv/9ZzpWuUJFaBMbjVMU2y6ELrIYvcqlwJ3e07uXi6mW++PSX+OKDX+GBC4/y+Xue4f7VB3nmvi+y0bjA3Zfu5Vsv/q5AP/XUU7z22ms89thjv7P3yiuvvHMz/cILL/Dtb//259+ut9sS6P/9vNfetMUW27Zt2xLo9zu1Wo25ubnfK9Bf/epX+c53vvOf7t+zeD/RkSzqm22MfUBL3x9OM/THSpSfsODrS7IUOsdq7AJFfQvjPi+yj5oY+VMNo3+mZfpDRqT9PjKqGv4zKQraBpYjYfS7PUx8yIR6l4epv5Yw7vfjOBnDdTyCtzeO80QM6XAQ+a1OhCNRtLcFMBwIIHUFEQ960e+zY9znwdwdQXsogKm/gG2wguNMDuloBO0+P94zGbTbHQh7vdj6Uthlc1imGsTMK0h9WdQHI7j60+h2u5F/zIrrTAaPaQmzfp5E/Co+aQn1ySTmMxn0+/xMf9yCdDiC37qCwbJIpHiNVPVONLIq+rE8uq4o8ludaG/z45gqozE2CdWvkTn/aeSmKnJFBdWJOLqjMfSHIwgn4si1ReyJVdJX78OzfI1xW4PpwST6oRzGwRwz+wOMDkYxBho4KstYWssMhIoMzCZRTuXQTGSZ7AnSf9CJ3JBADBUwRHOc8UTpsyeQabPMqnNMT2Xo6/ahkiewB8o44kXGbX6GvDE0oRqCp4nS1mBEVUAzm8NqKyFICZRSgEmbHzFUxJxro/E3mYosoLe0sJpr6GcTqDRh5GYfGmMUa6qKNtZAW1zFkFzFKFbRTmVQTESY1XlQqfxozAmEZBlTax2pcR6TNIdWVkA5kUKhDqKY8aOYCaB2F7EsrGFZuIjB0UGU1dBOF1HMJpHJo0yOB5kVMphrq5gbm8gMeUwzTQzTVVTKIjNTScZHIsxMpzFE5rHVL2INruBUzmOariOoqsjH0sjHkygm0hgMdezpTRzeJQKGRRyzLczyGrqJAqrBDOqRHMJMCbt7Cb93jYi0jE8zj0VWQz+YRz+SQzeQRT+Qwym2CVgXSRgXiOoXcUzWEM7kEPtyGPoziH0ZjKM5nIoKSW2HiKqFbaiAqTeLdCKFdDKF6XQax2iJpK5DQergHc4jHokidSewnEhhPBLDejKFZyhP1bZCWtNC7Aqj2xvAsD+AcCCI5WQS67E4voEc7cA5QqMFNNtdaLa70O/xotvjxtQVxNYTIzRaZD11Gc/pBKqb7Ch/s7Q7nQi7vVgOBbH3h+l41nAej6Hd7mD2o2ZUn7Sg2e5Av92J7WiYum2BzfQVUrIKzuMxnN1h7MdujPUODuVITlXYiF/i0Tuf4mrlbvK6FnF5Hs9QlKZ1marYYT12mTta9/DC01/n/OJFri/ezcNXHn+niePRa0/xmY0HWS6uc6FzmZ/95Oe/I8mPPfYYr7/++rtGNF566SW+9a1v8dZbb/Gd73yHF1544XcE+u3PbPG/l/fam7bYYtu2bVsC/X5nfX2dTCbzewX6xRdf5NVXX33XvV/84pdcKd9JaCSL5hYbw/9FTd8fTDP4/yhR32IlcDbNcvg8q9ELlPXzSAe8yD5iZOSDWkY/qGP2YxbMh0KU9HPERvLMuVdwn4qj2+1m4iNmVNtdTH/YhHQoiPdMmsBAhuRUGU9fEvPREPLtbqQTCVQ7fZiPRjEfjeI/k0a3z471cBDnyTiGI1EsZ4tYBvJY+9JIPXHsvUm8/ekbkxCPxfGMljFP1LHPNAkbl5DO5DH35/AOZJB/zIL6VgeBqRImeQObrkMufyd2TQdxpIR7tMjszU7kn7DhPpNBP1HAKMxR7NxLMHkZnaqBZaqG6oAf2U02NLd5me2PMzOZxptex9u4xIRUZXIixcyxCLJDfsZusjB6yMXoQAidtYwYbTIRm+OsJo98NI1qJM3Efi8DO+xMDUYxuRpYo/MoM3Oc9ZdQmWroxTo6RYWBAz5m+qN4fG2CyRX0gTKnvSm0sXkMoTaCo8XgSIqZMwlshho+XwedlGVICqCLljFlWojxOUZMJWbkRSyGBkZNmYlhLzKDF40lgqlQRspUkYUqqH3zWPVNzNoqyukUCpUHQe/HFEhgLJTQ52sYa8uYbW1Mqga66TwKTQRBH0CrDSLEE5hbTSwLK9hCK9i0LQRZBbUug16Io1QFUVnj2Dpt7MurODJr2HRtTKoWGk0JjanItCyKTBvDVOtgXVjHUz6PbqqAWdFE0DXQCVWmJpPMyJJog00sjXO4Chv4bas4NW0sxjZqVRX5ZIaZqQx6sY4ltow/c46IZwOvsIjLuIiobKAayqMZK6CTlTCZW/g9K0Sti0Rt63jFZcTxCvrhAvrBHMJgHqumgV+YJyZ0iOg6eOTzN2rs+nMY+rMYz2Zwyxs4x3K4xnKEFC2kEymEniTiyQzGk2lMvRnc41USmhYxeQPb6SS6/UG0+wOIR2MYuxNYT6XxT5SpOlcJjRXR7fGh/c1Yb90uL2JXEFNPnMhkmeXYRXxnM2h3utFsd6Hb7UF5kx3dbjeWoxFymhYbmas4j8fQbHei2eFE8QkLqlucaG51Yjrgo2ZdJDybwd4TQbvDdWMg0k1WZj9mupGZPhKiauxQNy8SHMhg6w5j7w5jOxrC+Zvx3rHJMuvJS1xv3sNa7AJ1yyJlYQ7fSBzfcJy6ZZGWY5Vr9Xv4wkPP8/T9X6QRmufq/B3cv/YAD9/+JPevP8RjdzzNw1ee4PLyVT7z6c+8a9PG2xL89NNP89Of/vR3Gjrebu/4+c9/zlNPPbUl0P8/4b32pi222LZt25ZAv9/51Kc+hcfj+b0C/bd/+7e8/PLL77r34//xGtcadxOfLKLb5WTkA1r6/w8Zw3+qRrfDQWyyyEb8Mp+av4+qoYOtO4zso1ZG/kzHyAd0qG6xYzsWoizOUZM6dLzreHsTaHe7kd9kY/aTdhSftCF1hYiMFQiNFMgoagQHMliPhVHt8WM4GkG9y43leBzXqRTBwQzyWyTsPWE8fWmMx9OY+vJYenNYejNY+9IERwsIt3nR3GLFeTKGYzCPaaSET9XGNdPANFzGL6uh2eNi4kMiwm0edD0RZntiWNQNXNYOmvEikqyMqsvH8H8XmPqExOx+J6MHPShGkrhCKyh1NTTqGtr+JNO7nIx91MLsHjfjXX70k1l8oWXM+fNM2+dQTRcRJ0rI9/uY2uFiqsuPRVEl4F/DlT3HbGYNta2FZJpHN11kfK+Xib1eLPIKPsciVkebgUANVaKDFFlC75xn/EyC4QN+zNMl7Lo6VlOTAU0URaGBub6MkGgzYcgz1BvDIi9jVzcwqgpMzPhReZK4Vxaw1OeZ9hUZ0+aRlHUcujlERYnhERtaQwB/vYJ3uYYykUGdrCMZW3iMHSyqJkpFDFEK4Qwm8XQKGItJHJ0mZk8Hr3kJq7qJTptDtCSw2BKYkwkcjQKetRa21BIe+xo2bRuNoYrBWsBgSaOUYtg6Nbyr87iqi/i867ilJQziHIKzhdpQYFIRR8zUMLcWcNXWCAQ2MKpr6KU5TO4llLoKsukMSlsZY6yNGG7j860T9Gzi8W1isS+jnq0gn8qh0ZbQSVXMlhYeYZ6AY4Vg4CIO8wrq8QqaiSK6qSKCooxNVcenaxIwLuAxLCJNNdCPlNANFdEP57HOVrGPFvDO1PDONrCO1dCfTCGcyWPoy2EaKOKaruObKGEfzCGcjCEcjaE7lkB3OIZw4sZ32TNRJqGoE5woYeqJI3SF0e0PIXRF0R0IYTuVJTRdo2pdxjeUQzgQRLfXj26vD91eH5o9XsSuEGllk47/HJ6BLPo9XrS7PGj3eFDc7EB1qwPpQICmfYWOfxPHiQSGvT6EPR6UN9vQ/KYz2nCbh4ZtibppAd0+O4bdN6IamlvsN+JUN9uwdofJqZskpkt4jsdw/Eae7UcjOI7HcB+PklM32EheZSN5mYZlkZqpQ0WYp2FawnU2QmAsQce3wQPnH+XZh57n0WtP8cD5R1lIr7KaOcfDV5/g/rUHefjaUzzzmS/y/W/+gIcefIhnn32W11577V0F+u0+6P8Y0fjyl7/MD3/4Q9566y3efPNNHnzwwXcV6H/8x398r4/x9x3vtTdtscW2bdu2BPr9zqOPPorBYPi9Av3Nb36TF1544V33XvvxT3ng0mMkZRV0u1yMf1BP/x/OMPynKnTbncQny2xmrvLE3c9S0s/hOBlj5iMWhv/ixg20docDU1eArKrGSvg8DcsiwaEMml0uFNtdTP6VhG63B8M+P9HRApHRHJHRIuHhDJZjcYSuEJp9fjR7fAhdQazHInh640x/3ICpy4fxiBftoQCaQwHUR8NojoQQeqIYj/iY+GuBmZtENHttTO90MtsVQBjNoutPIZzN4hzJMv5hI7KPWxAPepjZ7UXRFSRoX8YmLGCcbRG1raDeF2D6YzaE2/yo9gWQHwwSNi0RSt2OybWO17uBabyCfK+XqVscKHa7mT0YxCWvEYqex5A8h8bZQa+tIMorTOz1MHGzHfkBP/aZKg51HU1yBUVyBVtyA5N/CdmZFCM7nCi7QtgmithmyszoC0wW5rG0NrFWN1E6Gpw5HEDXm8I6XcauqCKfTjAVzuPY3MC+vI42O8/ZsRjCaBHnbAOnso5anmZWjBA4t0Dg6gpSvcaYPYNeV8OlncelnsegKTA+48BfLpO+YwFbI4cul0Z0t3AZ2niNSxg0FfSWJO5wjtTFOdzNJL6FArZsE4d1CY9lBaM4j95Zxuot4c4VsJVTBFZLOMs1nJ4VfPYNTI4ljP42lkALnTmLGMtgz5dxlps4gmv4PBvYvetY45uYgwvItTmUUhZdoIzgq2D3dHD5VjHYOphCq+gdC8iVJWbVBVRCEZ2xjMUyh83Uxh+9hDN0Hp0wx8x0CbWqhGI8jUFZxKSqYjU0cFgWcTlW0cob6Kar6KYriJNFhME0NlkZh7KBXd1CGC9hktURJuoIw0Xs0zUsA1lMA2nskxUsE2UMfRnEMzmMY2XMI2W8M1W8o3kcQ3mk3hSyfW6E4wn03XHEUylsA0X8UzViMzXcIznMJ5Po9ofR7Q8idEXQHQxjOpEkoW6RF9o4elOYu+MIBwOodrvR7PKg2+NFvz9AUZynal3E2ZvE2h1F2OVBPBhEvdONarsDw20+mq4VMso6piMhLN1hpAMBdDtd6Ha60e5wYTkapG5fJjFVxt4TR73DgWGfC3GnF8NeD4bdHry9KdKKGv6zaRxHI9i7I1gPB2/U2XWHCQ6mqVoWOJe5naXgOWqmBcr6NlVjm5q0QE3qEJrOkBLLPHnvMzx1z7N8ZuNhHrn6JJ/ZeIhOcpVOfJVHrjzOw1ce58Xnvs5P/sdP+dlPfs79936Gv3nhb951GMrbAv3d736Xr33ta7/T0PHjH//4necnnniCX/7yl7z11lu88cYbPPLII7zxxhv80z/903t9jL/veK+9aYsttm3btiXQ73e+8pWvMDU19XsF+nvf+x5f/vKX3/0lwl/+ii88+DxpeRVhp5uRP9dx5o/kDP2JCsUnLASHMpxLXeG5B79EyTCH80SE2U9YmPhLgZE/0zHzERPCXjehkQyd8DqBoRTu/hjyW6zMfNLC8H/TIvukicmPiBiOeLH2+DF0uTB0OZjdYWV2l4Pxj0kodjqY3WlHt8+J8bCf2ZslbMeDaPe50HYFEI5EEU8mkU5ncQ0VMHWFUN5sx3kihmGfD+VuL7aBPF51B+tEnYiwiL0/zeRHzAi3+RAPBJm52Y7YkyDtv4hJs4DPtkFQ7KDY5Uaxw41uj4/Jj9tR7/eT8KxjD5zD6tkk4NtAmioh3+9HtdvL5MdsaA8Eb0yii25iTF3AElxFsDRRDeWYPuBl8mYHQncU61Aeo1BHVTqHo3kJd+0SgqfN2Ikosj0+zGcy2MdK6MdzzKTmcZ67inv9CtbmJsNTKaaPhbGNlbFP1DDKSshMWdxXL+K/4xLOcxuM2LJMTaZxyps4ZhqYFTUUuhSBxQ6Z+y4SurKIKp5GZS3jEBZxauYxa1qopAJqW4TiXatELtSxVtMYUiXstgWcpiUsuBrLWQAAIABJREFUQgedo4kjUCPcaOKtZvE0s9jrJay+RVyuZUymDvrAIvbEIq5oA8mfxhpPIKWzmGMdnL51zJ4VTLENHIVzGOw11EIcwZFGH8iid1SxBpYxB9awpi5gS55HaWoim0ygVKeZNWYRrHUEYx1TYAVzdBW1o41S10SpKiMfjaNUZNHrygjqCibLPPbwJibnClpxHkFTRzWcQX02iTCZRVCUkDR1rMY2otDGaOhg0sxjmigh9CfRnUkgTOaRpisI40WMkxVMyjmsihYueR3L2TTSYBaxP4VxIIs0kEXXm0IaKeKWzxOQ1XEM57EN5RB704jH40ztdqI9HEY4lsQ5USU82yQ8U8U5kMPUk0TqSWA4FEZ3wI92fwD7mSwZYY6koon1ZBKpO4bleAJhfxD9bQF0+3w4TiZpuFZIKhtYeuJYuqMYDwSw9kTR7/ej3e3F3ZdkzrNGcDSP+UgY65EbQ0/Mh8NIBwOYugLEpopUzAt4zySxH41hORhC3O9Bv9eF5WgY27EI0bHib/qfo7+JasSwdoWxHQ7j7IkSnyyyGNxkOXKeqnWRnKZBTtmkIrapGDrUTYvM2VdZTG2wUljj/o2HuJC9xrXmPVxv3MMDlx+jE12lHV/m85/+At979e/50fd/wt88/RIvPvMyt29c50tPfYXnv/Tl/1Sgf/GLX/xOROOZZ575reaNr371q+9EOn71q1/xxBNPbAn0e8R77U1bbLFt27YtgX6/8+1vf5ve3t7/qTy//vrrfO973+Ppp5/mRz/6ET/4wQ/47ne/y7e+9S2+8Y1v8PLLL/PQPY/gG4oj/4SRwQ+o6P0DGb3/p4zRv9Ag7LeTFop00sv4J2Jo9lqZ+LDAwH9RMvCnSkY+qEG7y46zL0bTvYhvMI5/KIVulwv5J803XiTc7kDxcSveviSxiTze/iSe3iTGgwHEg0GU2z2Yj6fR3RbA1BVCOhREvcOCvSeMdqcL6XDkRqvFmTyWswXc/VnUO5xod7rxnI4x+3EL6t0e/JN17PJ5LFNNktY1tAdCKLa7sHaHUN5kZ+qvTfinynhMa5j0C6TCV3DIaszu8yMeDqO61c7khyXMJ+NEfOcQbWtEMteIRC+gPZNF3R1DtcuF7CYnxu4oHm0LQ3gdf+12fOXLqAxlFGfTyPd6Ue7yYu3LYB4poAq28axcJ7x5F665y8g1VSaOBhGOJXEMl7AMZZkVKrjP3U70rrvxX76d2XCbkcEE5tESjsk6dlmV6akUrvYa2c/dTeLT19HV5xgxZDGp6jiU89jlTWZkBazBJvnrV8jefQ5ru8JMtIjR2sJmWMCq7zCrrSDaa9iSRWILbSzpDPpSAUOohcW5hNm6gMoyjxRcxhVu4cvVkQIxNJEE2mgdc2QFk3MJlWcJU3oTi2ceQcwh2JKo3AmUzjymwDzG0CJibB1L8RLG0DKKqSQaVQq5McmslEVrriB45zBmN7EWLmEIrqFWlVCOp5iZSTKryaLSFtAYa1hTm0iJTaZNNQzSPLqJHIrhBLOTKeTTGbTaKqJlDkd0A6NnBZO5gzRVRhjJoDgbRzGcRDtdQFBWEPVNLI5l7NICbnkDy0gBbX8K9WAK9ZkU2sEshokikrKFx7RISNvGOVHCOJBH6EujP5PB0J9CeyKBcSRPwLBAQpjDN1HGMpBH6ktjOJFAOJlEts+L/niCoKpJybpCZKaJrTeL6WQC8VgC47E4xp4kxu44oeka8/5zRGV1LMcTmLpjmHriiIcjmLpjWHpipNQtVpKX8Q3msR6LYe6OYTwQwHY8huVYBOuxGAVxjqZzGVdvEkt3BPPhIJYjYSxHI1iPRHD3pamYOsSnKpiOhDEfCiPtD2LrjmA65Ee3x4l/IE1GWcd/Jo20z3ujS32PG+uhIPbuMK6TCQr6OVZjF2nZV4iNFwkN54mOFolNlMhpWtTMC6xEL/DIHU9ybeEuUkKRjnudldAFrhTv4lLhOnd3PsNyfoNz7Yv8+Ac/4e9e+BZPfOoZnrz7Wb7wuS9zefl2vv6lV/jcvQ/8liC/+eab7wj0m2++yUMPPfRb+08++eQ7N85vvfUW3/zmN9/phf75z3/O5z//+S2Bfo94r71piy22bdu2JdDvNz772c/SbrcpFAqEw2GMRiMf/ehH6enpYd++fVy/fp2HHnrot9bDDz/MI488wn333cczzzzDF77wBb785S/zta99jZdeeolXXnmFR+99nKSyim6Xk7E/03Hmj2Y5+38pkH9Uwn0qxkbqMheK12jalrH3RNFsdzDyAS2j/03L2J/pMB0KEh0rUDUtEB0tEB3NYdzvY+bDZmSfvDEVTXWzHWt3CN/ZDN5TMXwDacxHI6h3ulDt8WHsjqHb68N8JIRulxvDATeG/T7EQz6MR8IYT6Ywn8ljHyhiO5FEvcuN/XgU29Egsx8zYzocwStvYZ5s4FbMExUX0e4PIh6JYD8WRfFxK5odLpLSAmZtB7u4RDl3F8aBErrjCazHEyhucqC4xUFodg6LbQmTc43ywn0EvOvohguIp5Iod3jR3xbA2Z/BYltACq9TOPc5InN3MDWVRTGYQXPoxt/wltNp9DMlhOQ6hU89QPaOz2HNnWdyqoC+P4ttuIx9qICyL4XK1SJ17dMUHnwA38XrDJvK6GYrWOUNbNN1FGfTyGayxJcuk7l6ndDVy4zEK2itDayGeSzaeZSTJabHMwTzK6SXz+MqzTGWyjMbbCA525jNHZRCE5m6gs0xhzVaQnBlmPHHmQ4WkCIdjP4OSlsLbWAFo7mOzVHDaMmjdCWYcqUQAnWkaAdloIMxfx4pvIqgLKJXZVFKGWYdadSWLGpvFV18Eal8HmPmPKKmgnYyi1KRZtaYZtaQRq5No411sNQuYildQJI6GKbKaCazzM6kmJlNIVOk0VhqmIvnMGU3kWkKWGRVDJN51PIcU2djzIwlUM7mEV0LOLKbOF0rOJVNbNMVhOkC8uEUiqEUypE0utkyrvAGbucKQW0Ht6yBOFlEM5RGfTaN6kwS3Wgem6VNyLlGXFwiqJnDMlFG6E2jP5NF6E+j601jVzVJujbI21aJaeaxDZeQ+nIYTiTQnUghnkoh9CaIGxdYTFwlqV/E1ptFOpbAeDyJ8Vgc8XgMW3+esnONtcJ1ghMVzMeTSN1xLMeSGA/HMPfEcfalmfNvMOffwNKTxHgk/Bt5DmHpiWE6HMF9JsNC6AIJeQ3jAT/CPj9SVxBTVwjLkQi24zEi42WWI+cJDGYw7PEh7HKj2+FEOuDH1h3BeiSMrTdE3bKIfyCDsNuF5lYnwk4Xhj1ujHt9BIdzNKyLrIbPU9A28PencHTfqLELDeZITFXJqZrc3ryLx+78PPeuPkDFPI9nJErdssRa7BJLvnNcq9/Np9ce5J5r93HfXffz9H3P8tDlx3no8hM8cOFRnn/0q2zUz/ONF77FPdfv/S1B/vWvf82jjz76rhGNtxs6fv3rX7/z/Nprr/H000/z1ltv8ZOf/ITnnnuON954g3/+539+r4/19x3vtTdtscW2bdu2BPr9xu23387CwgIXL17knnvu4eGHH2bHjh0888wzfP3rX+dnP/sZr7/++rs0bfzinR+Ud1ufv/c5KmIH8YCX8T/Xc/oPZJz9w1mmP2TAfixM273Gon+D5fA53KcSaHc6GP6AjvE/1zP2QS3iXg+hwSyJiRJN8yLh8TyW7hCTHzah2u5k+q8ldLvcmLtCBAazhIYyBIdSuHoTaPd40XVFEA6GEfb6bgx+6I5iOxlCv9uB81QC6/EYxlNZTH05XMMlLCcSGLoiBEfzGPd60e9x4xnIYp+sYhquEhKX8UzWEI8n8Q7nMR8Ko7zFhu9slpCujXGmSdR7kUz0CsahItahItKRCJodbqQjEcLCPKJ+jlD0EvWVz+I0LyHN1BBPJBAOhzF2hbCczaDTNQgWrlK/8hCR+p1MTOYRBvKY+3IYT6bQdoWZHc/hjmxQvvYA+WsPoPAvoZkpYZ2uYR4toTwSYepkDHd4idT87aSv3MtUdolpcxVJ18SsbKAdzjF6OITdOU+4dJ7o3AWmYnXGIi0MrjaSZQ6Nts5IXwJRUSIUXcGXXmLGnWU8UkJMLWDwtZk115nS19HNlHHY59ALeWRigmlPCiFWx5CeR+FuIA+20dvbWLR1JHUZrZhn1pVE68oiRqvMhmroC2sYUqtYxRairIx6Ko3SlEJrSaOU0igiFUyNDcTqORzOJUyyKrqZAgplCpU+xdR0lFlbHqmxjrG+iTO0hl3RRJqtolbmUanSjA+HmJ5NISQWsVbP4ctcQDucwapoYDLUUcvyTI3EkE2k0dsa2IqbBDMXCEpLuFUtrEIL7UwJxVCK2aEUGkUJR3SVWOoCacc6QXEJp7aNMF5CPZBBdTaDbjyPw9omnbhMOXiJnPscXm0bXV8W3dk8uv4s+v40Lm2LfPg88/Gr5F3nsI5WMfZlMRxPIpzKIJ7O4JbVSEhz5BwLJHQdTKeyiD0ppBNJxO4kUk8Sx0CBqmeNhnsd++kMxqNxjEfjmI4lbsQ3ehL4R0osxS6TVTcxHQpj7ApjOBjCeCiEuedGc01kosyF0l0EhrMY9vkw7g9gPBREu8uF+VAI56kkRWGec6mreHtTaHc6Eff40Gx3ot/tRtjjxXUiTsuzTkiZwd+fRr/ThXaHA90uJ5pb7Ii3+fAPZJj3rtOyLhMdL+E6mcB+NITtcAhfX5LgYJairsXVyp187vKjnM/fQdO6QlZVxzUUpiotMudYZSNxic+ee5hXnv8G19bu4HztMncuf5r71h7gkdtvvEz42J1PsV67wCvPv8rDDz7yW4L8y1/+kieffPKd56985St8//vff9eWjf94S/3DH/6Q559/njfeeIN/+Zd/ea+P9fcd77U3bbHFtm3btgT6/c6//du/ceutt76rNP/HGMdDDz30n+4/effTdNxrmA8HmPqQkd4/kHH2j2aQ/ZWIrStAy77ExdKdXCrdgac/iWaHk7G/EBj9oJaJP9cj7veRmC6RV9VYT18hMprH3hNF9gkL6h0upv7KhLgvgLMnRlbVICWvEBnP4x9Io9nnQzwSRbPHh2F/EPORKAlZBVd/FP1eJ5GxAo7eNNKpLKbTWWz9Wcwnk/gGi8RlZTQ7nHh6kyQUDcxDJUwjFeLmVRwjZRyjFRLKBrpdboR9HuIzNayTdSzyJoXMNXzCIpbpBlHNHIb9ITS7fNhPJjEM5pFmG1Qa95LO34lFWsalm0fqTaM7FEa3L4C+N4l2PE+mdAeVtc9hDp9jYjKDaayMNJhFudeH/GAQ3ViOSOwcmeZ1rI3bmbbMYRJamFUN9H0Zxna60Q5lCQbWiaXPI6VWGI22MYWWsTgW0WtqDB8IojyVwO9YJBBeRfS2GPSVMVfWMadXMLjmGR7LIutP4FDV8bkWEc01Rmwp9Nk57M11tJE5RqUiSlUZq6qGXdNAI88wJgTRunLYGh30mQYz4Tqq4DwWVQOnvoVhKsOsJobenMTozaJJltAUWxhKy1jNbTzC/I0mE10arZBEo0uh8GYQ6/MYW8vYfUv4jMvYlQ10QhnBXESujDOti2FsLGJsLuFKrxM0r+EWFjAIdQzWOjMzKSZlcbSxFub6Gu7MJkHbBvrpPA7HEiZpDvl0lpnJNFpLDXNujUB6g5h3k5hjnaB3E5OhjWI0y+xgBq2qjCW0TDh9jrTvHEn/BUKuDSR5A9VAHvVQDv14AbNxjnhgg3zgPDn/JQKGVYTBIoazefRnswhnMtgUdSKGDmnLGnFpGcdUA9NQCcPpLMKpNKb+LO7pOil9m5imhdSXQDqVxtyfx9KfRzyWRDqewjdRpmxdJqFoYD2VwtSTwHgkhqkngelYAsvxBFF5lcXIRQJjBcSuEOKhMMZDYcRDQaTDIcxH4+TFNhu52wkM5tDv9mDY40M6FEC/24t+jxfHqTgd7wYLvk3cvSkMe33od7vQ3OLAuM+LfqcL18kES8HzNGzLiAdc6Hc7MezxoN3pRH2LHXGPl8BghrxujqyqduPWuSeM7UgY2+EQ9p4IntMJSoY5zmWvcLF0nY5vk4qxQ8XQJq9tYDsTpGFbpGVb5d7lz/Hc557n8/c+RzPc5lr7U6znL/Dwlce5f/1BHr3+FJ/ZfIjLS7fz89d+/lsZ5rfeeouf/exn79wovx3ReOmll34nH/3v16OPPso//MM/8P3vf5+vfvWrWwL9HvFee9MWW2zbtm1LoLfgf0mgf/3rX/9PBfpvnnmJpfA57EeDTP+1kbN/NMvg/61k9iNmnMcjdPzrPP6pz3OpeheBgQzqHU4m/8rIyJ9qkX1YQtrvp6ibY8G7xtX6XYTH81i7I6i3O1Hd6kL2ETPi/gDegSxN2yIlYZ7EdInwaB7DoTCGrhDKnR5MR2NYexKUxAWcJ6NIh7zkVE2sfTeGT5j60phPZTCfTJPWNPGdTaPf6SQyVsQzVMTYm8UtaxBQdzAPlYlqO3gHcqhusWM9GsXRn0Z/Mo1HPU8hdhWzfB63toN3oo5qtw/VTg+W43EUR6I4Z1vUa/fg8mzcEGhlC+lMBvkOD5p9PhRdQWzTFbKxi/gLt6N3r6KQZXGLHfSnU0xtdyK7zYdtukLUvUogtoEivooxuIrLv47V1GH8Nj8j2x3Yp8v4pDZuxyITnjpiZQN7YRNrfI2p0Qwjt/mxjhRxqxq4zW3GxTyafBv7wiWs1U0mTSWG+uKYx8rYZirYlXWmFAkUzjzu1XXsixtMB8pMGspI0xVc8iYOZQ2ZLM6kIoC1UMe9sYo8WUadamDUt3CpWzjVLTSqAnopg8mbx9JqoC9XMLfamNxtPMISbl0H0VDHaC0h2goIoQLGRh3zQhtLfBG3ZRWPuIjFvojZ00a015DrM4iVeUxzi9hyy3jd6/gtKzhcK9gj6+jFOpPyNLpIA1NzFUd+Fb9nnYBtDVFqYXWu3Oh4nsqhNFYQI23s0SVCgU1C7nVCwYvYzMtopsrMjubRzBQxGBo4rHP4jB1ivguEfRex6TvoJyvox8toR/JIs1U86jp+/TwBwwJ+0zKWmRbW6RbSaBnDQBG7rIZ7skRQ3SCgnsM6XsU6VsY6VsMyWMIyUMI73SAsr+CbKOMYzqPs8mE6ncXcl8V2toSlN0dwpkZeWsR9NoflZBLT8TjSkRjmYwnMxxPYTqVJq+doeNZxnE5hOhpFPBjCeDiMeCiM6XAYy/E4Tc86TccazpNxrEcj6HZ5kQ4EMOzzo9/nxd4TYyl0kYJuHuvRGLajEUwHg+hudaPf5Ubc48V9MkHVskhipvqbDncH4j434j4vwm43xr1evH0pYhMFQiNZ7MciOLojWI8EsB4J4zgWJTSUpqRr0fGuseTfpGbqUNa3qYhzVKUF0soqnpEYi+FNHjj/CE/d+wwPXHqMh648TiPQ5p7Vz9JJrPHwlSd44OKjPHXPc7zy1b/l6c8//a6C/HYM499HNJ599tn/qUA///zz/OAHP+Db3/42L7744pZAv0e81960xRbbtm3bEugtYMeOHfzqV7/6/yTQP/r7H7MY2MR1Iobsw0aG/0TF4J8oUHzcjOdUnNXwBb718ne4Ur5OZKyAZqeL2U9YGfmvWlQftyLu9ZJVNthIXeWO+U+TVzewdccQ9/qRfcTM7CftCLd58J9Jk1c3KOpaFDRNohMlxINBdAcCqHZ7MXXHcJxIkpRVMR30Ye0JEh7NI3XHMR6LYzmTQzqVwj6QJzJVQdjjQTzoJziURbc/iHgiSUTXwTZexT5eJS0uotntRr3Ljft0At0+P+oDIVK2NfzSGmb5PAn7JuYzGZS7PEhHw2j3+VHd5iOkmyMVu4JkWsHnPY9XXEA4nWR2lwflbi+KvV48shpB+wqG8Ca28HkMpjp2Yxv5kQgTtzhQ7vXjldVxK2tonG2MxQv4KlfwZs6jUZQZ3O5AfSCEbbiAfbKMUl5Ak1/Bv3odz/wVjKEFBo+H0J9MYh8p4RgvoZhMM+Mo4b10Fe+F2xFKiwzMpNCN5nFM1nFOVtFM5VDqM3iW1gnedTu6ZpspXxmtpopb0cQlb2GQl1GLWTSeFLE7z2Fs1dFVygiuFk5tG4+2jahuYHTVcUVbhNdXsbVbWObrSLE5rMYF3OICojiP2dfGHulgjtcx1ZuYF5qY8nPYnIt4zMuYLUtYwqvYIstoxDLqUBkx18SUm8cZWMXlXMXmXMMePYdkX2BGVUIlllC7qhicDRz+FdzeNVzBcxhti2iEJmplDY26hEZbxCDWsIhNHLYFAuGLOL2bSPo2gqKFpGuhm8ghzRSwqus4jR0c0iJe5zqSto1Z2cI028QiqyANZrBOl7HNNnBp57DI6jh1HSzyFg55E9dMHcdwDutwHvtkGdtoGft4BWmwhGOygXumSVDeJDRRwT6YxXgyie1MltmDfsy9GaxnC/gn66R0c2T0c9h600jHYkg9caTuGGJPDPPxGO6hEhXrKlmhjfV4AlN3FNOxGIYDAQwHQkiHI3jPZFgMXySlrGPtjmE9EsG4P4D1WAxxvx9htw9vf4qme4XIRBHz4RCmw0Gs3WGkQwHMBwNYuoIEhzKk5VX8vWns3RHMh4KIt3nQ73NgPRLCfiyCr/9GN7vnVAJLVwjnsQiWgwFsR0K4jsdIzlSpmRfpeNdou1epSIvk1S0qYpuqsUNFXCCvr1N1t7i+dBeP3P4k96/duGW+f+1BWpFFPr3yAJ30Cg9dfpwXnn6Jn/7k53z/u9/n2Weee1dBfjuG8fbzG2+88VvS/G4C/eqrr/Lyyy/z6quv8sorr/Dmm2/yr//6r+/1Ef6+4732pi222LZt25ZAbwFdXV38/d///e8V6Icffvg/van+1a9+9c6IX8XHLQz/VxUDf6xg5iMSzhNRmtYlXv36t7hSvouMoo6wz4vsoxIjH9Ai/7gZ/Q4nsYkSa4nLLPjXqZoXMHeF0O31MP7fRbS7XKhudeDtzxCdKJKYLpNV1HH1pTDsD6La6Ua3P4jhcBRLdxRffwZhjwdXbwj36STCoRBCVxhzbxbz6RzekQq2nhjanR4Cg1m8fSlUu9yYTiQIaRawDNfwKeYIKxrM3uLE2BXC3ZtAcbMD7b4Aadc6FmUbl36ZnP8i4vEEyj0+zEciKLY70Oz1E9HMY3esY3Gskcldx2daQnUkhmp/gJmbbOgPBnEMZbGZFxDDGySbn8LiX0SQV5k5FEax3YV4OIK1P4NhNIc2vkZi8x6ii3fhSG8y2Rtn5jYf5tNp7P15tGfTzFpqJD91P5FLd+NbucqkuoDsdAL7UBH7SBnjaIapmSyxa3eT/ux9+C5fY8xbQa4o4piq45ysIY1XkM/m8Lc2qD7xWUJ3XkWRrzBrr2JVN3HMziPJqyh1ZVzxRewb8wQubWBsVVEl6ljMbZxiB0ndRG+ZxxFaIjy3ia02j1Sroy/VMboWcDiWMBjaGNzLWENrmIMd9P4yYryMNllFCi9i9SxhdCxjDmxgj51DMM2jMZYQ3DXUziI6Rx2zv4PVt4ojeQF7+DyCZQGDtoZeKKMTiwhSHaOxji20gTt+CdG5iErXRBLnMEznEJVF9KoiBl0ds7mNLbCJ07eJSVrEZlzELKtgHMkiTuWR1FWMqsYNibas4DQv4xQW8ajmsIzkEQZSiKMFzLIq5ukaDlULh34Br7BIVLeAZ6KIaSCL/kQCsS+LfayMeTCPdbxCSN8mbVokKKtiOZPBcCKJeDSGeCKB8pAP6VSKkGKOlu88KVULU08KY3cUqSeBeDiM1BPD1B0lIquxkrxMbKaK6WgU6Wgc09EIxsMRzEejmI5ESc62WA5dxHs2h+loCMuRKOJtfsxHwpiPRrB2h0kpahQNc7h7k5gPB5EOBjAfDmE+FMJyNIL7dIKkrEJsooDjWPRGA8eBINajYcyH/Gh22/GdTREZzREcyWHrDmM9FMR2LPKbJo4Qnr4kBV2TlmOFpn2FijhPUT9HQdOipJ+jZmhTlTqshC9yqX6NjepFFhPrXG/cwx2te7lv9QEeuPAIzVCbBy8/zkppg+9843v8+Ac/4eUvfYMvPv48n7vrQX7645/9jiC/HcP494L8yCOP8Prrr7/T8/wfBfpHP/oRzz33HC+//DJ/93d/xxtvvLEl0O8B77U3bbHFtm3btgR6Czh79iwvvvji7xXoxx9/nF/84hf/6TTC1dglPL1xFJ8wM/DHKs780SzTHxJw9ESpmRZ46r7nWAmfJyOvIexxM/EhkeEPqJn6SxHdDjvBgSzLofPkNU2atiVsRyNodjqZ+Esjmt2eGzV2p5MEB3OkpqtkZmu4TiUwHYn8Rjaj6A8GMB7wYz0SxXkyhr03iLjfg6Uniqk7gbkvg7kvS2C0iGF/EMN+P/HJIobbPGj3eHEP5nBOtzANV0hYVnCczaLa48V5Momwx8PMJyy4+jOEjMtI8jkSgQtkvBfRHY0i9sTQ73a/MzUxJC4gGBYIRS9Tm7sPm6qJ9mQS9R4Pmp0epKNR7INZ9I5FQqVr1C4+iC24wuxAGuXBAMKhCOaTN5oYlNoavvnrVO9+lNzFz6A1zyE7mcDan8PWl8Pcl0M+msHduUL1gUcoPfAIxuIGE1NZzOMl7KNlzCMlJgeT2AvrVB95mNKjDyDMrTBhriApa1gVDSxTVeQTBczONvk77qHwmXsxthaYiNYRpDksQhuzqolcXsVoaxOqbKKPFxCzdWbLDbSBecz2BUShhdo4jzm0it27gD0yjzFURRmvoo7PYwosobPMoXctY4lvYvIsYjRWMLiq6IJVNM4KYrCNEFjAFN3AmryANbyJXlPBoK+gs1bQ2iuoxBKCZx5z+hzO1GXs0XOYjXMYJnIImjIGUxWVJo/aWMcWXcOevoTRt4pWXUKaLCNNFzCoiihn8giaKqKxhTu8gSt0Ab9jDY+qhW26gn4kg2Y0g3Yyj0FewSK08Xg38TvXiAgalYAOAAAgAElEQVTz+GZrSKM51KcS6M6k0Q1kME2WcYoLxJwb5GyrxLRtLKMF9KcSaHsSGE4nEU4lcUxVyTrWmYtcJqX/f9l7z+dIz/NOd/6Ec9Y+Xnsd1mHt1ZrmkmKc4QRggJkBZgZxAAxy7Nz9dvfbOeecAzoBDTQyJnPIGXISJ3DIZbBImrREBUqkRMmy8kqUSJljfdB1PkDmWkvy8FRtWXTZuKqeQlc9D/rb+9ZVd9/P764hdMRQHQqgaPGjaA2gbA0gaXYS0syxkbuAf7KI+kAIVXPgV/LsRdPqR3coSFpcZCVxBnt3HGF/AHWTB02zD1WTF22LF8OBECXbGmX7Esa2EJp9HrQtXtS7t2LqtM0eLEfDzFoaxCVFTO0BdE1edE1utPtc6Pe5MbZ6cfcnKOjq+EazmNuC6Fs8CLvsiPvd6JvcGA/6MXS4ScrL+I4nMLZ6Ue2yIex2oG1yIbZ68A/ESSpLlA0Ncpo5gsMZ3D0JfMdThEdyZBRlivoFTmXPc23zFicL55i1zBGYjrMcOMGJ1KNsxM9x4+QzlAN1vvTSGzxz61n+9sXXeeb8C7x4+WVuPf4sty7d5s3Pf4P33n2PW7dufZCs8U9tGP9ckF9++WW+973v8e677/LMM898SKD/ScK/+MUv8vbbb28L9KfEp+1N22yzY8eObYHeBsbHx3n++ec/UaCff/55fvjDH370oJU3/46Gdx370TAz9xjo+e1JOv7vMYb+WIG430NBO8/5ypOsRk6SkMwi7HMy9Kcq+n5fwvE/lCO7z4TtaJB55xop6Syz4gLGA15kD1oY+nOBmftMjH5GQN/sxXUsTny6gP94GsvhrQlq0/fbUe8PIHvYiWq3A2GvG29fHOVuA4oHbdg6owhtEVSHo+g7Y5iORtHs82A86MfRFWHqbhF9kw/PRAFNbwbxeJ6YYQXhUBhNawBLR5iZe4xI7jcTkpbRjZUQp8vkYo/jUsyhOhLHdDSC5H4L8oes2Lqj6KVVtKo5MqUnSaUfRz9WROiKo9ztQtjvRXsgiDCRR22cJ9W4TH7zJlpDjbHurZQFXXsE4VAQaWcElXWB1MZV8o/dxFM7z9hkBlV/Cm13AkNXkqm2IBJlnuSpq+Qu38K/cYE+IY9sOotubKvHdqojxsTxGIHZk8Q2L+JcOc1AqIzcWEWrKKGdKjA9lGHieAqHb4lA+SSmeJ3xVIWZaB2tZR6VusTEZI5pZQmdpowzusSEEGHSk2M6WkUfWUJhqTKpLqFwNNCoypj1FbTGEjPWDOOeHEJkDqmjzIyjhia4juBYQi8rolPkkOsLSO1ZVPYCk6Y8cm8dXWINbWgNs76GZiSFYiaDTJtBLuYYlyaQ+ebRxdfRxzawWZcQR3NohtMo5Bmk0hSjEzEkmhya0DJidB2new1FbwTjWB71TJap/giTwzFmJpKodBVM4Q0CoU18qgWc0gr6yTwzfTEmjgaZ6g4jG01itDWIBE8QN60QFOoYp0tIjoaZ6Qgz3R5A1hHBIC0R9W9SCZwiZl5FHMwjawshPRRCfjiE5FAIcThLwr5OI/EoIXUd4UgM1YEQygMhFAcCKFqDGHtTBDRVSt513KMFhIMhVM1+NAdCqJt9qFuDiEej1P2naMTOYu9JIh4KIbQGUO/zbmVA7/dh6YyxHD1N3rCItSOKsT2CrtWPeo8TbZMXbbMH31Ca1dhZwmN5xAN+DG1+xNatISu6JjemtgAJaZmG/wSe4yn0vxqwonzIjm6fE7HFh7MzSkFXxzEYwNsXRbPbgWqXDd1eF7L7zIjNHmJTBXLaOgX9HInJAvbuKKZWH/YjIQLDKcKjGWbFOk8sXOPaiac5V3mCmKJAZDqDcyTMgnuDZf8pzmQf5/ajz3HhzEW+963v8+TGVc5WznN56TovXnqJ6+ducfXsDd78/Nf56U9+xssvv8z3v/997ty5w1tvvcVXvvKVXxPkr371q3z1q1/lnXfe4fnnn/+QQP9TlfrVV1/l29/+Nv/wD//AL3/5y0/7Ff7vjk/bm7bZZseOHdsCvQ0IgsDly5c/UaBfeuklvvvd737k3rfe/Danixdw9cSQ3mOg9/ckdPxfYxz/QynCHidFYY7VyCku1K8Qnsijb/Uw/F/UDP6pgmO/N430swYMrT5KxkXyujpZYQ7b0QjSB8xM/Xcjo5/RMfVXejQ77YSGs0QmcvgGkrh6E+j2e5DuciLf60b6sAX1PhfGgwES0wUm79lqIfEMpBAOh1G3RTD2JNEdCqFt9ROeKGBo8SG730xoPId1MI+mI4ljpoZnqoz2SBTfaAHzkRDyB63YOyJ4JRU0AzlcwiLZyDkMx/NYR4uYj0ZQ73GjbXLjHM2jGsnjtq1SqF7GZV5FOzGL2BlD2xZGs9+HcCiAYjSHL3SK4up1orOXmJ4qMtnuRzyWQns4gmSPh4kjIdzeVfIbT5HauMKMbRHJVB7jTAn9YA7pgTBDTW4spjqR7Gnia08wHV5k2lTDKM4jyirIeuIc3+3BrKzgD2/gy2wiCc0zGV3EHFhGtC4gmSow3BNFOZzC41rEFVhB6iwyHqxgzK4hhpeZVOYZU5aQjWcxK8s4rIuMKcKMWFIIsTkMxVXGDbNInHMo9HPoJ/OYVRXUmhwztjxyZx51dJ5J1yyq2BJqXwOjsopFMotmIoPMkEVlyzOpSzHpLqBOL6NMrGE2LmKTVNBO5JFLUsh1OSYkMSbUKVSJBurUMlbvCm5lHYusjEZRRDadYvR4iLGRMHJHBV1yBXtgBbd6AdXxOHaxjnIyy/ixIGM9QSQzaQzBRTyBNcKGZYKmNexCHdlIhunOMJOdQSSDcbTGOYL+dZLmNWK2TazKOaSdCaaPRJluDyPviqJXlon7Npj1niRuXkccyqM4GkN2KLqVBd0ewjBRIOdZZyF2nrCmgaE3ja4zgbotjKw1gOpQCNNAmrJng7xrFdNACnNvBrEjjv5wFFWzH3VrAFtvmsXwKQrWFazHkph7Y5g64+gOBVG3+NE2B3CPZFlLnCEiKWFsD6E/6EM8FMTYHka334eu1U9CVWM1cQbPYApt069aOfZ70e7zoG1yY+8IUTItMe9YxdMXR73bjr7JjfIhG9omF8IjTgLDGSrGJYr6eYT9NuQPmlE+aEXY40DxkAXjAR/B4RSz+nmS8hLuYzGs7QF0+5zom104u2P4+pLUzMucK13kycVrrMZOkxNq+IbixKbz2AdCzDvXaPhP8vSjz/H1r3yTM0vnuHXmWS42rrAYXeXGqWe4snqTyyef4tLJa7z1hW/w8/d+zhtvvMHXvvY17ty5wxtvvMGbb775a3L83e9+l1deeeVD/dL/+4jvF154ge9973vbAv0p8Wl70zbb7NixY1ugtwG3283Jkyc/UaBfe+01vvWtb330JcLv/IDLK0/h6Ysx9Vd6Bn5fQtd/GOf470tRPGglJSlxIvUoz174a8LjefQtbkb+XMPIn6rp+70Z5PeZMbf5KRkXOZE8R1ZZxXEshuR+K9IHrYz8mQbp/SbUjzi3RvyqaoTG8oTHchjagij2epDvdKJ42I56rxv/UJaSuMj0fXpik0X8Y1k0B4NoDoYwdiVRt/qxdMXIaBfQ7nVi74yQVFQROmIIHXFCmgaG3gz63hRReQ3tfi+aPU78w2nEYxmEYxmS3lO4hWV0Azk8U2X0B0Ko9m5d0NJ0RlAPZskkz5NInkenmMMwXcbUl0Y8HEW2y810kwd5R5R4+DT5ucvo3etIJSXUx+OYx2eRt/oZe8CGvCtGwLlKIvMoltxpZqyLmK1L2HSLiGN5+u+1Ij8SxiMuEPSvYwouMRFqYImuYfWvYDQu0N/sZarFj0szh9u6iNm5wIhjFlPpBLbsJjp3g/7hBFNdYcSxHA6hhsVUZ8SUQUguYK1voo41GBJySKQ5tEMZTBNFLEKVQWUYiSWNsbSCNFZj0ltmxjWHdqKAZbKIfiKHVJ1Fbc2jchaYDheRJuaRJebRClVsMxVM07MolXnUuiwSZZJxQwp5eh5FdgHRuoBDXsUqraHVVtCbq0hm4oxORpCFKihSdcyBJZzqOg7lPGbjAnpDjcnRGCPHQ8wY8mjii1j9S7h1DZzaBRSSHIKsxHh/lLFjIWYkafSBRdyBFXymZfzGVRyGZYSpEpLeJJPdUSSDSXSmGgHvCmHHOlHnOk5tA91wAWVfFllPAnl3FKO8TNSxTNq9Sdy2iVM+j3Ywh7Y/i9CbQH44imksT8zQIGlbI6hdwDFRwTxUwHAsi/ZoHKE9im0oS9qwRFy7iG0wi+KgH3NfFtOxDGJnAu2hCN7xAnO+DbxDOaw9CcQjEQxHIpiOxjB3JdAdDBJTVVnwn8DaGcV0JIjY4kN/0I+u1Y/hcAjzkQgV2yoV+wqWw2F0zV6EfW7EVj/6/R6EJjeewRQLvhNkhRrmw0G0TW50+xyodjnR7nNhOODD15ekZKwTmyxgPRJBdr8B1S4r2l12tHtdmA/58R1PEB3PERrLYT7ox9ji+ZU8ezAd9BE4nqRsXGQlfJq16BlK4gIZZY2MpoZ7MEZ0KodvOEbF2uDq2k1euvkqN888w1y4weWl61zbeJqSd44bJ5/hqfWnOVV5lKfO3eIn//Md7ty5w3e+850PLg5+6Utf4hvf+MavyfF7773H008/zfe//31eeeWVjxToN954g1u3bvHDH/5wW6A/JT5tb9pmmx07dmwL9L9l3G43d999N/fccw8HDx7k7//+7z/yXDqdplarfaJAv/7663z961//yL13332X/3Hxr/H2x5m+W2Tgj2T0/NYUg38kQ7nTSkZZ4anNp/ni575MdCqP8aCPybuNDPyRjP4/lKF62IqnL0nVuszTjz5LUVcnOJpB8bAdyf1mBv5EgeJhG/pWLyXDAmVzg4y6Sk5bQ9fqQ7nXzfT9VpR7XKibvMRlFWJTeaQP68lq5jB3xtA0+xEOhtG3R9G0hAhM5vEPZ1A8YCU0ksE1kEZ1MISpL41XNofQFcMxMotnpIBilwOx1Yu9J46syY9xOE/Gdwb9eAXzRAXvVBndoRDKPR5M7SGmd3kwDmaZTZ7HblpFp6jj1i5gny6hbPEh3+tm8kE74vEUMcc6/vBplOZl7PYVNDNZdGN5Rh90MPGQHeNgGr+2jtu6hDK4gjV+AlfoJA7nGmMHAgzea8Y8lMMpLWPXzjFlqWItncFVOoM9eZKJyQz9u53ouxNYxnI4FBUm1TmEWAPP+uPYyieYNJUY7o+i7Y1j6s9gHM0ikWVQO2ZxNE5iXTnNhG+WSUMB9VAG81Ae41AWyUSCKWUMhSePsbHOdLzKTKSGSlbEPFbCMlZCOplCMBbR2WcRklUk2SqSVBW1sYxFUsE0WUKjKKM1l9Ebi8wY0khSVWTZGhpPDbOqjlVew6Cbw2RfQKHIMzYeRRIoo0zOowssYBPrmBVzmIxLmGwNZNM5xkcTSA0F1LEGRv8iTusSTkMDh30N2VSWmbEsspEUckURrbOO093AZW3gNq/itm1g1i2hnZxFOZJHM1lEr6rg0M/hNTUIuDbxmNaxyOcRxkpohwvohgsYpwo4pSU8qjncijn84gqWqRrmiTL6wTzG4zlsE2W80wXckgr28QK2kQLOiVmsYyWM/TlMgzncE0Vishq2wTSG3iS2wSwzTU7MfRksA1msAyniyhp5wxJiWwD9wSDGzjji4ShiewRrTxLXUIaKe5W0MIdwwItmnxvxoB9Tewix1Y+hPYh/LE/dv050qojY6kO3z4NqlwNDWwDxoB/9AR+h0Txl2xKB0Sy6Ft9Wv3STB+3erdHd1sNBvAMJYtNFPMcSmFr9aHc7Ue20IH/YgG6PE0OLB+vhAJ6eKI6uCPpmF4ZWD/q9TnR73VgPBwiP5UjLyxR0dcrmFXKaGknpLHnNHGlVGdfxMElFmXnvKsvpk9w4+QxXV29wdf0GNf8i1zae5vLSU9TCi1xqPMVzF/+aZ556jrfeeusD+X333Xe5ffs2d+7c4Qtf+ALf+ta3PiTIN2/e5Nvf/javvfbaRwr0d7/7Xa5evcqPf/xj3n///d/wW30b2Bbobf6V8Gk/CNv8y/HTn/70g8+FQgGFQvGR5xYWFkgkEp8o0F/5yld44403Pnb/hcsvEZnMI7vPxPCfyOn+rQlG/kSJ8IiDgnaez11/lVeefo2cpoah1cv0PQb6fk/C4J8pUD5oJTyepWpb4dqJWxR1dbwDSaQPWhn/bzqG/4sK+cNWjG0BEjMlIuM5Cro6KUUZ9V4n0p0Opu6zotrnRtviIzSRx9jqR3/QQUpZxnAwgGq3B/2RyFZ/8eEo4anS1tTCVh8JRQntAR/K/V68UyXMQ0W0nSliwgLikTDK3S7c/Qm0LV5mdjkJKefwCMtohmcJiSv4ZHMoHnGhbQ2ga/Yz87AT51ieqHMTrbKO17FBzHkC83CemV0OZDsdyB5xYx/O41FUUZuXcIROEkmeRyXLIz8SZfQ+C9I9HmxDGWyjBeTSIsbMKWKLl/Hnz6HXz9H3sBVFsxdTdxzbUJbpwQRCaIn4uacIrlxEDC3RfySIsj2EoTuB2J1kqifMlCpD5PwlohevoMktM6jMoDgWx9iXwtCXQnosyvRkAk/1BNFrVxHKK4x6ikgkeQxDeUxDeaTHU0jkOQTbLNq5BqpSnYnELBJxFsNkCfNEEdVEHpW6jGirYEg2UBVqyDNVZO4KoqKKOF1CLSmjM9YRTXPIDAW0mQVUuXkUgSqifgGzeg6dUEe0NdCZ60jlebSBOvpcA224jtG6gEE3j8G0hMWxhl5fRyopIBgq6H119PYaZvsiFnMDq2MNu30dmbSIfLKIqKpg0FYwasuIiiIWcwOHcx2HYx2TsIAgqWKUVzHJSlinC5imi1gUFcyaeTzWVcyqOkbZHKbpEm5FDdNgCuN4FnGkgGW6jGm6jFu7iHmyhmOmSlAzj30oja47jngsidibwj4xi2W0iH2yinumQsa8REhaQWgPoz4QxNgTQ+xKIDvgxjGUIySrMR86RVha2opnbPKiaQ0gtoUxdsUwd8dIauZZSz2KdziL0OxF0+RBvWfr1xFjexhrZ5SUosqCaw1HT3wrfWOfB9VuJ0KTC22zB9OhAMGxLImZWRydUbRNbpS7nAj/FGG3343pgB9Xbwz3sTjWAwH0+90Iu53o97nR7nUiecCAsyOMoyuMozuCocW3VbHe70W7x4W4342jK0J8ukBGWSarrDKrXSCrqpKQlMgoK+SUVbKqKiFJhpO5R7m4dJn5yApX127y1MbTnJ+7RD26wtXV69zYvE09tszLT7/KT3/yUz7/+c//2vCUO3fucOPGDd5//31effVVvvOd73xIkF988UXeeOMNXn/99Y8U6Pfee48nnniCn/3sZ9sC/SnxaXvTNtvs2LFjW6D/vRCNRlEqlR+5d/bsWdxu9ycK9FtvvfX/mdZxde0mkfEc0s+aOf4HUjp/e0uglTvtpKQlXnvu81zduElRv4C438PUvSK9/3GGic9okdwj4jkWpyDMsRE7w1LoJO6+BOo9Tob+TMP4X+qQfNaEodWLdyBBdDJPzbZMYmYW/YEAsgcszDxoR7XXi67Fi7M7itjqxz0UwT0Q/1U1zY/+SAz1wRDGngTW7hjqvW48A0mCo1nkjzgwtIXwS6roerbyeVOGBsq9HnStflx9KRQP21DtdZPQLWKYqGCarFIIn8cxNotkpxPDr9I61Hs9uAYzmFTzCKp5MpkLJMPnUHfGmXnEifQBC9qDfswdUfTjeVSGBVLzl8gvXEM6mWS82YvkITva/X4Mh6MoD4eY0paIr14hf/Ym4epjjPZGmW71oWuLom8PIT8UYGwwRuzkFbIXbxI/e4UJZYGp7ij6zgRiVwLl0TCjPWE8lVNkr98iePYiY84iYxMZDMdzGAeyqI4lmBxKYPY3SF++hm39DJPxKuNiEWGigDhaQNGXQjKVxWCZw7t0hpl0CVVxHkmwjFpZwSCroBwvoFBWEIzz2OOrmGZX0FWXUOcaCOY59JoqSlkZnbmBwb6CwbaIPriIKb2ENruEzreIzlhDI9bR2Zcx2FcQDXVEYw2Dax6tvYzWMYfOOofetozJs4bFtY7O0EDUVBGFMgZjGZ1YRqWcRXQuY3auYXWvoVJWUMuKGKYLWFVlNNIcakURUVPGbFvFbl/HYlrFoV/GLithHsujH88hjOXQTucxykrYzCu4zGu4hUXC2gVcU0V0fQnUvQn0g2k0wzms0ioecYmQaZmCfZWAvIymI4rqUAhVexRDfwb9sQxuSY2kZY2V9GOE5RU0BwLImryoW/wIh4LoO2MoDvjIGJc4VXoSz1AW5T4vyn0e1Pt9KPd40B4IIh4OkzU0WIqcwnQ0gtDk3Zo+uNuJep8HodmL/oCPlHqOnLaOsS2Iao8LYZ8b9SNONHtdCHtd2I+GScrKxCZmsXWE0TV5EPY4EHa70e9zY2jx4joWIz5ZJDiSwXY0jOmAH/VOB2KrB12zG0t7AG27g9BIBl9fCltHCMN+L/pmF7o9DgwHPASGMyRnimSUVXKaKhllhbS0RFpRISMvb0XZaeY4mTlP2b/A4/OXeKx6iaytxIX6Za6u3uRM6XFWs5tcWb3BX195hf9x6wW+8sU3eOv1b3Dt/HVef+VL/Pzn//CBAL/wwgv8+Mc//rULhf98felLX+KVV17hy1/+8kcK9J07d7hw4QLvvffetkB/Snza3rTNNjt27NgW6H/rOJ1O/uAP/oC77rqLH/zgBx955vr16wiC8IkC/c1vfpPXXnvtY1s4LsxdJqOsodpl5fgfyun8rTEG/1CB8kEL4dEcT59/ngv1yzT8m5gOBpB81six/yRl+M/VTHxGi70jQlFXZzl4ko3kozh6YmhbPIz8uQbJ/WbG/puAYb8PZ0+MojBPxbKIpz+BuT2EfKcd6SNOFLtdqPe6MBzy4+yJE5hIoG1yYj0SxtoRQWgLozwQwjmUQ9fsQ9fqIyEtYjrgR/GwBe9gBtNgDvXROD5ZHZ+kgnKPB2tHFH2zB9n9ZkztYXyyGqrBAh5hiWL8cYzHUluRc7udyB+ybl26Gs6gmizhtq5Tql0h6FhH1RlD/U+Vvn1uhAMBZNNF3KGTFJaeIlu/zGhviOlmH9oDAXStfhT7fUz2RHClT1M4fZPsqesI1kXGjkTQdcQR2kIIbWHGDvqxRdbJP3aT7MVb6GJrjI6l0B5PI/Zk0HbGGWsPYLAtkHv8BqknnkLIrDJqqaCTzaIfK6A9nmW8K4FeXSW2coH4Y1cxltaZiC2gtSwgKiuox/LMjOTQCjVckQ0C9TNMeDLIZ5fRR5Yx2RZRSorI5VX05gYG0wLuyBqGQB1FbB5tagXRu4hMU0ZlWkBrW0Y0L2Ox1DHa5tF4ami884iBBnJzDb1zGaN7DYN7FYt2HqOqjMFYQXBWUelnUVlr6HyrGLyrmDwbOC0rmMayGFWzGM0VlPIcMmUB0bGE0buK2bOOzdJAGExgnipi0JRQzmRRTmRQyYuYrMvY3etEAicJ6RbxyKvoRtIojyeRD6ZQj6bQS8u4bCvEPJvkXSeIiUvoBzPMHPAj74qi6I4hDKSwKuZIuU+wlDxPVFhE6IiiOBhgZp8XVVsIVVsI40CWjHOdE8Un8EzMom4JIG/2o2rxo9jnRdXiQ38kileSZS60gaM/haZ1a+qgqsmLYq8HdZMH8VCAsnOdeugktp4EYlsIXZMf5SNO1M1e1HvdGI+EmPOdIG9YxN4Tx3gogL7Fh3qPE81uN/pmD77BLIveDZKyEtaOENaOMOIBH+pdToS9bqxtISJTBWbNS0Qm8ji6oti7ouiaPej2uTC0+PAeS5DV1LD0ePANJbEdCWM65MVyyI92jxPb0TCx6QJJ6SxZdYWUrExwJIP7WBzfQIqEdGuIypx9jceqT/Jk4ylmnXMsBjdYDm4SkiXZiJ3l3OxFHq1dYKNwmjdee5P/+cOf8MKNz3G6+iifu/Y3PHn6Cn/74hf4+2989wP5ff3113n77bd58cUX+dGPfvQhOf67v/s7nn322Q8uG37UeuKJJ/jhD3/InTt3fsNv9G1gW6C3+VfCp/0gbPN/RmtrK3fdddeH1mOPPfZr56LRKF6v9yO/4+WXX2Z8fPwTBfo73/kOL7300kcPUvnpz7h59jny2hrq3XaG/rOC7v9nkr7fn0H1sI3AcIYnV57i6votViInsLQHmL5HZOiPVfT/ZxkTf6nFdMhP2bzMcuAkq7HTOHtjiAc8jP+VHsn9Fkb/QkDX5MLZE2fBs0ZKXsLZE8XeHUG5x4V8jxv5LgfKnXY0e10kZRW8g1Fk94l4+xM4ehOoWoNo2yLY+tKomzxYOyJEpwvI7zNjbPERkVbQdCTRdadIiKsYumLo2sIERrKodtpR7LTiHcohDhbRDuRIB84RMawidMRxDKTRPOJEu8+DvsWLYayAbmqWTPoCufwFjNMVhJ4k6v2+rZ/U93nQdEYQFFUypYsUG9dxe08w1O5HcziM/nAU4WAASZMXlbJMfukq+c0bBKqPMT5VQBwpYBzIoe9KMNXsRzaUJrNymdkzNwivPMmEqYZeW8OqqKEfzjLVFkbSlySSOk1q5TKRjSeYCTfQOhtYzA2M8grjvQlmBrPYzYuE82fw5U+jyKygTqxhC6xhMNaZHM2hVFTRy0v4fKt4I+uMaOMI2WVsmU0ExzxTilkExzJazRx27Rwu5xJaWxVVoI4ls4Y6sIjUWkNwryDYGpikJezaGgZjDZ13Hr13Hpmzisa3hNa/it6zhkOsY5spYVaVMdjm0dkqzCgzKJzz6EIriP5VXPY13LIaFsksJlMNQTPLzEwGuSKL1rmIKbBKwLOGR1ZDO5rAoiqjGEkwPRBjeiyJUl7A5F4l4Fsnblwhal7GOF1E1h1l6nCI6c4Q8oEERnGOqG+TonuThGUdcTiL5FAISZuf6YNBpAMlSmAAACAASURBVO0hxIkCCdcatcgZwppFdF0JVO0RJM1+5AdDSFt8iMfSFNwbrOUv4pupYuhKoD0cRTgURrbPh2q/H7EjRs1/goJ3GVNvHHN3HLE9uhVn17R1xtKZYCPzOAvhk7gGM5i74hgPR9C1BtA0+VDv9eAdzLKZe5SSZQXP8Qy27jjmI2EMbSE0ez3oW/0kFFUWfJukZCXsnbFfrSiGAz70zW4cx+LkdPOULYuEJ3JY2oNYD4fQN7uxtPsxt/sJjWbJqLYqyPp2J9p9DoTddoS9NpQ7rZiP+vAMRPEMRnEPRjAdcSM0WZE/ZEC5x4zuoAOx3UVQkSRnK5O1V0mZCnjH42SUVeqONcKSNCvhTU6mH+Pqqeu8+Oxf8523v8eLV1/hytoNasEGr93+PCeqZ/niS1/mzS98g/fff587d+7wzW9+ky984Qs899xzvPPOOx+S45/+9Kdcu3aNr3/96x8r0JcvX/6gt3qb3zyftjdts82OHTu2BfrfC2+//TZ33XXXR+597Wtfo6ur6xMF+gc/+AEvvPDCx1agv/S5r5BTz6NrcjH4J0p6fmuS3t+dRvmgjcBAklPZx/jcjVdo+Dexd4SYutvA2GcEen93monPCGj3uahallkJnGQ1fBL/8TRiiwfJ/RYm7hYZ/a8aVA/ZcXXFqbvWiE3k8Y9kCI5lUO5zI9vtRLrThmKXHU2Ti5ymhvmIH/VeGylFGcPRKIpm/6+kOIh6n5vwRBFPfxzVw1YiE3nsx7Mo2yLYRmfxK+cQDoWxDWSwd8dQ7bRjaPHhHimgOprAPl0hFzyHcaSIvi+NpSOK/kAAbbMXc3cEVV8Kj3aJYuFJ/PZN1CNFDH1pLN1JjB0xVC0+ZF0xfJY1SvOXSeYvopTPIemNYhnKYhnMIt/vZ7LZh8+xSrF+mezCVQTXGlp1DaewgF1aQdERY2inA5euTjx2mmz9EmLqBEpHA6drBaehgXIky/F9PkwzJYKuVaLxM1jTm6iSG3jSp3D41lFKZxk9lkQzmMFnWiDoWcPoaSCPLOGunsGeOYFUX2FaVUYxlsU6VcBrWsTmXGJQH8eaX8UyewKJtYrStYhKP4c4nMMhLWMV6+j8dcTQAsbEChLfHMrgImpPA5OsjHV8a/S1wTGPMdBAadoayqIMNxCCS1jFBRxTZczTZUxiFZOzzrQkyZg8hcK7gDa0hMO+hFc6j0NRw6yfRz2VZXwgwlh/GLluFm1gCbd7Bb+qjldoIB2NoxxOMdUZYrwzwMxIAoN9gYB7jYhuiYhxFbt8DvWxFJLOKFNHgsx0h9GrykS9m2Sdm8StG1inKwi9adS9ceRHIkgPBTFOFsh4N6gEzxIzLmMfLyH2pxGOxhG64igOhTAOZqmETlGPP0pYvYh9uICxN42hN4G2PYLmQADb8QwrmUeZD53BO1VEOBrEeiyDoTOO4WgUbUsA33Ce9dR5UsICwakS7uNZbH1JTEdjmI5G0B/wkRbmWI6dJjiRw9WfwtoRw9YVx9Ebw3gkjPlIhFnDIkXzIvbuGMa2ANr9HvQtbnQtbsQDbqw9IUIzaTyDUYQWB9IHDCj2mJl5QI/kIRHFHhP6TjfmHh/mbg/a/VYm7xWYuV+Pao8F9R4LumYHts4AnqEE3oEYhjYPYosLYbcN4wEP9u6tynTds8a5ykXO1y7R8G1SEObIqKqkZRVm9QtkdRXqvhVevPIyf/Pi33Dl7FNb471XbnL9xG2Krgq3zj7HZuUMrz33Bd7+yv/qg/7xj3/M888/zzPPPMO77777kYJ86dIlvvnNb36sQF+7do1XX32Vf/zHf/wNv8m3gW2B3uZfCZ/2g7DNvxxf/epXP/hcLBbp6+v7yHM/+tGPaG5u/kSB/slPfsKzzz77sfvf/fb3KGjn0Dc7GflTJT2/M0nv70wiuUfE2x+n4d3kG2+8zZLvBMHhNNL7TIz/pUDP704z9VdaNI84yGvnWY+dZS1+mrS8jH6/F8l9Zob/Qs3k3XrkD1gJjeWoGBeJTRfJCXO4+pLIdzqRPmxH/pAd5S4HliNhiuKvIuqOBYhKiqj2eVHu82LrS6Nq9qJr9ZNWzmE44MNyJEhOW0N7KIz6YJigqo6xL4NwOEp4prRVqTsUIDpdxNSbRH04SsK8TkhcRejN4pws4RrIYO6MYjoaxtQVR9uVIO07RSbyKAbJPFbZPD5JFftwDm17GEWTH/XhKCnfKWYLF7HY19FrG5gkRazTsxj6U0w87EDRHiRkXCIVOo0vcRatcw2//wRe+zoOZY2hXW4U7WECQp2IfQWHexVd6iS+/KP446ewO9cYag8y3eLDJSnh0y1gNy+g8i3ibzyOr3IOc3CFUUmema4Yxv4MblkNu3YepaOGo3iCwPpFxNgy06YKEukswrEE5uEsFmkFlaWC3J7FWd1Em11BHphnxlJDO57HPJjDMJRD0JWwRpYwBuaRBWtIwwtIg3PolWUso0VM40W08gIGcw2lKs+EMoUsWEMWmsdoqWOfLGObLmNQV9FrK0wNxxgbiiGxllBFF7A6Gzjl89gVc9jFRXTKCpLBBJN9IWZkGdSeOg7XIi5NHa9uGZdhicm+CLLBFNKBBPLxDDrbAn7PMkFjg6BlFZduCaOkimYoh7IvjWokg0FbI+paI+nYJGJZx61tYJ4sIw4V0PZnEPrTWGVlsu4TFIOnCRuW8WsaWMdKmI7n0felEXvT2CdnKXk3yTg3CKrqBOR1HGNl7MN5jL0pDL1JvBNF5gObBKUVnIMZvJNFNB0BbAMZbP1pTN1JEuoaBVsDc3cUQ0cEY2cE49Ewxs4Q4pEA+qMBwoo8nvEE0l0W5LutKPbZkO+zI91rRNFsQzzqwT0RxdjjQf6IiZn7RWQ7LaibHeha3YgHPXhHUkRm8jj7o+ib3Sh3WtHtdWA85MfaHsTVGyc0kiWrqhEYSmNtCyDsdqLcaUH+oAFLmx/bkSCu7ijh8SzBkRSGAx7MLV7EvU7EJg/2oyGS8jIl8yKL3k1WI2co6OvEp4rk1DUyijJJWYm8bp6V6Ek2Zs/wuade5WztMU6XH+VS4zrXT9zm6vJNaqEFLi5eZSG5whde+CI/e+dnH8jv+++/z40bN7h58+YHVen/fV25cuVDEXf//P+vX7/O7du3+cUvfvGbep1v88/4tL1pm2127NixLdD/ljl27Bh33XUXd999Nx0dHXz729/+yHO/+MUvuO+++z5RoN99911u3rz58S0e3/o+VfMShlYvE/9VS89vT3LsP04xc49IcCjFWugU3/jq3zHvXCU0kkFyr4mRP1fT+zvTSO/duiA4Ky5wtnyReec6WXUV9W4n0/caGPoTNZLPmlDtcpBRVcmpa+SEGnXPGtajERS7nUjvtyJ9yIpqjwv/aI60ooLhoJekUCA8NYuq2Yu6xYehI4Zqnxd7b5K4vIKxNUBUUiCjrSMejqI/EiOgmENzOI6pN0VSXcdyNIKpLUhoIo+uLYK1P0PWtYlxtIJ+qEDKsIZjKIf+UAhrZxR1iw/zsRTFwGm8pjX0kzWS7pOE9MuY+pOomn0om7xY+5PE9A3C3pMI4hLJ+KO4zYuYpbNM7XYzvcuJ7XgGv6KGW7eA2rpEtPIkicIFwpHTSI7FGXnQjrUvhXtyFpeihkRTJtR4gtT6VcKlx1GoSozs96I/EsUxlMUxXUIizWNOrJG+eIPI+pMo7PNMjqRRHwlj7E5gGcqinMmhd8wRXX0M34nHkQcXmDLOoh5IYjyWRt+bQDaYRGeooDDl0OaWkQRrTHtrqKYKmIfzGI9nUI1m0WlLCPpZFPYy8sQC0vAcGl0Vy9QsxrECelkJUVdFIy8wI0sjJBooU4vobDXMshomSQ1RWcUsLqKWFJGOpxB8dQypFUyeRezCPFblAnb9ElZDA420jGI8i85Qw5JYx+lZwiEu4jQsYTetYtctMd0XQzOaR1RVcAQ3CPhW8ZlX8FvXcIqrOA0rGGeq6MZKGKdn8ViWCNkahB3r+C2ruLVLeIUlLFNVTJMlzJMlAvpFImKdgLCAU17Dr2ngVi7iks5jHSliHykSUdeJaipYhzPo+5Loe5PYp4qYR/Loe2PoeqMEFAXs43GkTQ6kTU7kB90oDnpQtLsROoPou0IE1DlM/WEm7zcxs8uGosmJ5pAX8XAAa3+CoKRIwVrH2RtFsduBYrcdXasHw6EA9u44nuNpiuYGc85VnAOJrYuCe90od9kxtPixHA7j6U8QmZ4lo6zgPhZHv9+DepcdYZ/zVyO7fbh6YgSHs4TGszi6Ioj73Qi77eia3GgesSN90ICzK4rveIrAYApHRwTtXufWuT1bfz29MSITOVKyMhl5lVmxTk5VJT5d3EriUFfJKquUTUucn32SC/XLlD3zXFm9wUbuFCfz57i6doOn1m5xbfM2S8k1rp64yfkTj/Puzz5cZb59+zY3btz42ArzjRs3PjSl8J+ncNy+fZvr169vV6A/JT5tb9pmmx07dmwL9Dbwy1/+knvvvfcTBfrnP/85N27c+Ni9N1//OkV9HW2Ti7G/UNP5H8bp+90ZpPeZSEqKnCte4I3Pv8mCa53QSB7VQ3YG/lDGsf8kQXqfCXtXhKK+zqWVa2zET1OxNNA2OZHcb2LgjxXIHrCi3ecmISuTkM6yFj3DWvwM1qNhNE0eZh6wIn/EgXqPi9BEFvdAksBwmrgmi3MgibEtiOloFHVLEE1rgODkLJ7+NMZDAYriAo7uOOLhEO6RPNbBAprDUQLSGhFZGd0hH97hLNbOMNoWL2FplaDQQNObx69uUPCextgRR3cogHjAj7Dfi3skT8ywjDBZxW1YpZS5SMy0hrzZj3qfG/FgEOfxNO6pWXTKOnbXBqW5a0Rip5F1Rxm734KhPYy9L4V9KINsNIvZv05+7QbF1adw+9YY3uNG2eTFeDSKvT+NrDeGxjxP7uwNsmdu4s6eZrQ/juJQALE9guFoBElnGOlkiujyBdIXbqJPrTGmziPtiSF2JtB3JpB0RJCOJXCEl4mcuYQ+u8qMbw7ZdB7DQBaxP4O8J4lqJo9RrCEm6siTcyhTCyhNVXRjRQxDOdRDWTTyMjpNBZO7jqm0iX52FW2wgVFRRT9ZQjdTwahbxCjW0eqr2DLrGEubWJJrmIwLGGVlRHUdk34Rk7iIIJ/FGlzGUzyNJ30Cq62BQTeP1biEybiC1bCCqJzDZlzEHVsnnNzEbl/CYl7Gatrat5uWkY1mMKmruM1LRJwr2HRz2MzL2E3LuIwrOMVlrKoF7MoaHu0cXqGGSVJAO5FFP13CKKthmCljnC4ijudwSnKYhmLIOwNMH/YhOepH2hNGM5xEMxBHHE7i1RQwDUSZanIhPeBDfjCA0B1B35/EPl0iqJyjHj+FZzSNfK8b5X4f+o4w4tEY1v4Mmq4QBfs6m/nHcQ2kUO51b6VotPgR20KYO2O4jqeZ855kMXAKe1dsK2FjrwvVTgdCkxdjWwj7sThFU4OSdQlrRwT1bhfCbhfqR5yodzvQ7dsa651VbV3wc/XG0Dd7UO9yoN7tQLvHidjixdMXJzyaJTiWxdkVw9DiQ/OIE32zE12TC/vRENo2B97+GJ7eOM6uCGKLF33TVsyduc1PcDhNdCJHUjpLWl4hJSuRlpXJyMuk5GVS0hI5dY2NxFnOV57kYv0qTyxeoeSpcXn5OivJTU4VznHzzLNcXrrO7bPPcePxW3zxb7/IzZs3P1KCX331Va5du/axAv3000/z6quvfuTeO++8w3PPPfdBD/U2v3k+bW/aZpsdO3ZsC/Q2/0ug33vvvf8jgf7b579I3bOBsc3PxF8K9Pz2JAO/L0XyWSOR0RyXlq/x5Zff4Fz5Ar7BFOq9WwI99KdKpu7SYT0aJDYzy9X1G1xaeoq8ro6h1Yv0ATPDfyEgvc+E8IgT30CStKLKyfSj1N2rWI+E0bf4kD1kR/6IA81+D+7eBO5jCUrmBo7BILbuCPaeOJbuGIr9AQyHo/iGc1iPRnANpMipq+iaPTh6E0QkFdQdcbSdSdLmFay9cYztEULjBfQtXkxtAWKqOYzDBbTHtwaqJM1rCAcDWLpi6JvdWI+GcfQmME+W0EyUyUTOU8o+iXOmhrTZi7DHjak9iKUrgrY7jlpRJVl8ktn6U4SCJxjaZ0e+143Q7MXQFkZxMIh0JE1i7hKFjeukFi4x0Z9E0upDaA2gPRhE1epn7LCfWPVxCmdvkFi/jERdQtaXwNCTRHc4grw1wPiRAE7fKrnzNwmvXUThqyOVFTGM5hF70sjaIkz3xBGFCqkTVwisXEAsrKO0z2FWzGEcKyLvSqIYzyOqqwTzZ7GWNlDG62ijy1gtWxcSFcezCLIyevUc7uAGwdo5HHNnMBc3sfnXMOkXUEvKiLoFDPpFbNYVvPGTePMncc6ewpU8gcFQR6utYzSvYDYsYzWv4HIu4/au4gqt4k5sYLQ3EM2LmC2rmIxLWEzLOEyL2IQaDmsdo7mKSllErZtDo6mg0ZQR5BW0sgLq41HEmRTy8RgTx0NMDASZmc4gm8ygmMhgkBWxT2cwjsZRDSWZ6goxcyyCYiCOXlHGrJrDb1ik6NskpK6h7oig6owi9CTQD6SxTpfxCg0yjhNslp4kKKsgb/GhOhhEeSiE2JPE0JfGPVOh7D3JmdplXENZVPv9yPZ6ULf6EVqCiB1xLP0ZgppZGvEzWHuT6Fr8qJo8KPa4UO11oT8QwNodYz50msXgSZzHkoiHAghNHlS77Kj2OFHvdWLtiFJzrpAXGzh7t5I4xBYvqj0ONHuc6Fo8eI+nKRrqRCUFHF1RrB1h9Pu9qHc60e51f5CikVFUiIxlcR+LYzsaxrDfh26vC2OrF89AkpikiPGoE99AYisr+kgQW3sI3T43rp4osakC4fEsSeksCUmJuHSWxEyJpLREWl4hLStTs61yrnSBi/UrPF6/wqPlS1xeu0nJXeNC/QoL0TXOz1/k6votXnrqVb7/9z/gra++xc1LT/PYycd558c//ZAEv/nmm1y+fPljBfr27ds899xzH7n3ox/9iBdffJEvf/nLH5tstM2/LJ+2N22zzY4dO7YFepst7r33Xt59993/XwL9caL95Vfe4GT6MSztQSb+Ukvf700x9P+y917Pldhlum7/BafqnDPn1OxJbBhm9gwbBjA44LY7R7XUyjmunHPOOeecJC1ltaTOud3BjQMGmzEGAzYYbMAkA/YYb8ZwMcNzLgTUZmwfLvsCPVXrYtVbutHFqqd+9X3v93cypj+mxjWQ4ELjGi89/21urD2Orz/xh2XD8X9UMfFRFdajAaKTBW6sPM6N5cdJiUvYOkMIP2Vg5l+MTH9ch+phO7YTYZquJTaz54kLy7h6E1g7wkg+50DyOSfqfR5MR/x4BpOsxDdR7rdgOxEmOFlAcySEfJ8P20AKw5Eg+sNByqZ5AsMpDAe9v1skzCA9FMY5VSainEV9wItzMIm7J759cvhYAN9MCUVvEqe4QTF8Bsd4AfWxELqDXrR7Xej2utEfD6MczOLStikXrpAIbCHviCPb40azx4Nmnwf5bieik3Gc9mWKjesUatfQzJQYfsiK4XgY9SE/ikc9jO914fYsUVi8RXHlFmbnKsKeJJahLKaeJIpDfkYfdmAzzlJcu0Nx8zaO1AZCcQmrsIJ1rIiqK8bEPg86WZXC4mMUT9/GXTmLzDWHVTuLQ9FENZBm5kQcrahMLH+W4pnHCbXOo4ovYfcs47Itop4qIh3Oopc38DhXyLav4CltIAnXcaRO4QmuopSUUUqqGDVtzPpZorFNAslT2FJruMpbOOJrqLR1VOomat08Bs0sDuMsXuciZmcTo38WnX8ekaaARF1Boigjk5dRz2TRT6dRKzLIdFmmxDEmxEkmZGlmxFlEojxqYRb1cAyzIodBV0QiyjA5GUemLKHU1NDoGriMs9hn8piFWay6BorJDPLxDCpxCaNxDodlgah7hYx1iahuFv1IBtnJOLL+BIrBJDpBCadxnqTzFK3IGeKaeTQn40gOBZEfDyM/GUPbn8IqrpLzrLOUv4BPWEHdEUNxNIT4ES+KQyFUxyKYhrJUg5tsVK/hGS9i6IqhPuhHfTiAZLcbxV4vhhNxWuEtCp55TCejmLti6I+GUO33IX/EjfxRD6bjERYim8wGTuEaSGPtjKE/EkJ30IfiUTfqPW68I1nmAxuUzYt4BlNYOyPblwkPB1A97EB/yE90pkjF1CajrOPuTeLsiWHvCqPf70W3z4NnMEFCUiGnqpGSVfANJfAMJDEdDWI55sd2IkxoJENcWCQlKePoDeHqjeHsieLuiWPvDBMcyxCezBGdyJEQlIhOFwhP5/D0JwiOpklLKxR1LVYTW5yrX+NC/RoXW9dZjmyyEFhnNXaavKnGRvEs7cQKV5Zv8v1vvc5bb77Nt1/4Lp8/8zTL5XW2ls/wyldf5Zf/9s4fSfAbb7zBlStX/n9foG/duvW+2RtvvMGXv/xl3n33Xf7jP/7jXv90/1lyr71phx127dq1I9A7bPPwww/zxhtv/EmBvnv3Lr/85S/fN/vpD9/gfP0q9q4QUx/TMPjXEgb+Ssj0x7TYO0Ocq17mhSdf5MkLz+AfTqHb72L8n1WM/L2CkQ9LMRz0EhUUubZ0m+srd4jPFHH0RZHdb0H8GQujH1Egf8CG6WiAxfAGq/HThCezJMQVzB0hxA84kT3oQvo5K4qHnYSn8iyFNxF+Vkt4uoB/Iotsjx/5Pj/u0RyKR5zoDwXIKOvoD3ow7HcREZRQHYmhPBolppvH0ptCud+HZzCF+lEn6oedWE+E0PcmUJ5MknSukjCvoOmMYToZR3/Qj+6AD/U+N6oTETRDOVLBMxQyF7CImqhPJDB1hjGdCKM/FED0iAv1aJ5s6gKl6nVCwS1kQ1kkRz3Yh9LYepIIHnGjGMxQrFymNPsYqdoV5NI6DmkDp6CCdTSP4FEP8u4EhfJlyguPkV24gcKxgNXUxqudxympIzkWQ3IySTS4QaF5jdLqLQzJdWzBFfyeNRy6OUT9aaTDOZyaFrHwBqnSeZzVM1jzG/hSG9jsbUQTORSiMprpEk59k4B3Eb1vDqGvjDW9jMpaZ0qYRSgpIBhLoRqOo5fkUGpyiCx55L4S0/oMo5IkE8Ik08Issr4IupEEelUBvbOKzlNHaMgjNpaRGCrIdFWs8irm0SwuXQNvcBmTo4VMlkdlbaCxz2F0tPFY2rgFJZzyKi7bPGpxHuF4Aqkgg9bcxORcxG9bIqJq4ZbXkA3EkI2kkQylEA2lUMzkMVsWCDuWSZuXiOjbmCZKKLpiSLtjSE6EkfbEMCnqpNyrNMKnieramEezqLtiKE9EkB4JIT0WxjCWp+hdZz59jrBqFutIDkNfGuWRCKrjYcR7fWi74rRiGywkzhMUN7ANZtF3xDF0J1EdDKDY68V0MsZy9jxN/wauiSya4wGsvUl0R0LojwRR7vHhHUqzlDpDwdgmOF3cFuieBKaOCIZjIfRHAiRkFVreVdKKJlFBBe9gCkdPHGtnBMPRAM7uKFllnYJxlpiwTGSqgH8kg2cwgaM7gqM7TngsQ1paJauoEpnM4u6PExjN4O1P4B9O4RtJEZvKkZKUSUpKhMay6A+6MB7x4OmN4RtMEBjNEB7PEJnOExdst+DYO8JYjvpxn4wSGElT0rU4Xb7MmcplztWucip7jpq1TU7doG5dZM67StO3QNO/xPmlS3z/u9/nB9/5IV+4/Cw3lu7w+bNfYKGwzFJ5lVe/8T1++oM/PpjyzjvvcOnSpQ8U6Dt37nD37l1+9atfvSf70Y9+xAsvvLAj0PeQe+1NO+ywa9euHYHeYZvjx4/z7W9/+08K9NNPP80vfvGL981+9atfcWXhNs7uMDP/U8vw30np/YsZBP9Ti/VogPXMGZ658ixfuvll4qIihgNeBB/XM/g3EkY/JEe920FSWmUlscWl2WtklHWCE1nEnzUz/Qk9ox9WIP+sFcNBPy3nEmlphZggT0peRbXHjeQBG5KHHEgftCJ70E5MWCY8nkHwaS15bRPjiQiS3S7Uh4OYu2JIH3bi6k3gG0yj3e3arsSbLCDfF8DUmySumUd1KICxK4p7MIHpSAhrR4igoIDycAjrWJ5iYAv7RAldVwLXUBZ7bwJrVwx7bwp1ZxyXtEEpfoGIbR31UAHXdBXveBHnYAbdsTDKE1EChjbl7GUyqYvolC0cigbq/hjemQq6k3Eke32EzYuUC5coVS5jca1hNy0Ttq3g085jGM4x9agXj6JBKrhBoXQJT/YM1uAG4egmftcyuskSU4eDGIZSeDUt/PY2Zv8i+vQajvgaFvc8wukMkz0Rpo8F0A0nMIgyyKQZRK4y+uQcKk+FCVGSsYk4YyeDyLoC6MfTqCUZFI4qikAZa34ZoaGEUFNGLC2g6U9hn8hjl1exBxfwFdaxJlaQu+ZQ2mdRmBuYhSWsgzmsM0WsjjlcwUXk6gJiUxmlu4XKOYdNWccxVsI6VcCma2EytpAJs4hEWeTWJmr3HC7jHO6ZKm5pDYuyjmoii3QsjWQ8hVxeQuecxWtrE1Q0CajnsMnqTJ8IIOtNIOmNIx9LY9A3CdkWSFiWiBgWcUpbGEbyaAbTyLqiyE5GMQiKJJwL5D2nCGnaeCRNjAM59H0Z1N0JVJ1xLON5av4NGtEtAoo5fOI6ttHtERnDySSqEzHsw1nm02couNcISRsEhDVsQ1kcwzlMXXG0x2P4pgqsFS6RMSwSENXwThbQdAYw9ySw9sSxdMTJqJssRDeJi2uEpstExRX8o3mcQ0mcfUncAykKxjmKhjl8I1ncgxl8IxmCEwX8o3n8Y1miwhIFfYu0rIpnIIm9M4z1RATvQIrIZIHgZJ7ITJGUrExcVMTRHUO7x42tM4KnJ467L05oNLstxcICoYkcru4our1udHudqPbYcPbG8PTFCY5liE7nwLmdLAAAIABJREFUiU7msB4PYjzgRfeoA3tHEP9wkpKxRdO1yGbhPKfLl2h5VkhJq+TVDVLiCjXzAm3vKlvli5xpn+f29Tt84dqz3Nl8kqvtW9w5/RTXF26zUt6gnVvmW89/hzd++PP3Feh33333AwX6+eef5yc/+cl7su9///t8/etf3xHoe8i99qYddti1a9eOQO+wzejo6AceSfnfP88++yw//elPPzA/V71KaDSD6FMGBv5GxMn/cwrBxzQYD3lp2Bb50s3nuTx3g5SkhGq3g+mP6+n7f2cY/YgCyX1GEsISNVubtcQWJf0szr4EovuMjP8PFWMfVSG5z4ylI0jJMEtwJE3DuURO20LxqBvRZ62I77ci/awN9R4PaXkV58kI5pM+6q5FjMdCyHa7sfYkUO3zonjUQ0xUwTeUxHkyStO1hGswg+KAH7+wjGM0j+JggNBMheBkAVd/gpiwSGCmhL4zRkw7T8ywiLojgXu6TExaxz9ewNGXxD6QxtSXJGNfJR/YwjhTxyZukTQuE5LXsQ+kUBzwYepJknasUIqdw2VaxqRukwluoZ/MYJssMvOAA82JCB5RmZCljd3eRqFvEQit4bLOYRQXGHnIxvQeB/r+KLqxBIrpODPGCpZIG7N3FpWqyNBxP+OP2FCfCGIYiqGZSiHQFPHWtwg3z2H2LyAQZpnuiqDriuKYKGAXltEY6wRKp8mdvY0ltoLM3EAiLKA5Gcc6kMEyWUCtreKKriD3lNCGFlB4WkiNNbSjWSyDaYwDaQzqOjZvG4OjgdI9izIwh9RRwygpYxnOYRjOYhCWsBibqGRlZMoi2tA8muAsZl0L23gRy3QZk6yOUV5GOZlDOplGY2tgDi9itbRwiqq4ZE1syhYWaRX1WA7JYBKVtIQ9vITbNo9b0cSrnsWlmMOhaDHTGUQ5nEQzncfjWSHqWSZqWyKoW8Ipn8UpbWAcL6IbyqIbzeExtcm4l0m71whq2nhls3hk2w0bpuE8puEsIe0szfhpcu51vLI5fLImfnEDx2QJ61Ae60iWpKHNQvYCScMCAWkTv6iOT1gnIK5iH87hGs5RcqzQ8K7jHsvhHMkRmCkTFFXRnPDjny4SEdeZC58io2psy3R3Akd/CvdIloiwQmSmTErZpO5YIiIoYDwUxHQ0hLUzir0njn8sR0JSI69pkVHXCYzl0B/2odvrwnDIj70rirsvRWgqR1beJCWr4B/JYD4aQP6gHf1+L7bjIZwnIwRG0yTEZVKyKt6hOMbDvu156j1OdHtdKPfbCI3niEzlyMirBMfS6Pa50e/zoHl4eyExOJIip6pTMrRoOpZYiW6S1zRJCEpkFFWyihoZaYWKuc315Ts8c/3LzGcWaUbaXFu8yfWlO9xYvs1jy49zY+UOS5l1GrF5vvPia/zqf/3xS/Jbb73F9evX/3BN8P0E+pVXXuFb3/rWe7JXX32Vl156iV//+tf853/+573+6f6z5F570w477Nq1a0egd9hGLpdz8+bNPynQzz//PK+//voH9ES/zUp0k9BIBtEnDfT+5Qxd/9cEU/9Diemgj4p+lq8/9zKbmXPUrW10e9yIPqmn+y+mmfwnDbIHrKSkZWY9y5wpXWI9dRZndxTVbidjH1Uy9c86xJ82EBhJk9O2KBpnudi4TlxUQXvAg/yB7R5o6YN2bF1RirpZgiM5sqYqRUMD0/Ew+sN+zN0JpLvd6I4EKehn8Y9mSSmqtDyr2E5GsXUniMjqqDti6I5HyernCQurOPuSpBV1bH0xvJN5stZlrBMVVN1pMqYlkrp5rL0JzB0RNAd92AaTxHUtrOIakt40Lm2LkGkW43CSqYeszDxkRH3EjX4ggnYqwdRwGqOmjsvSxCDPMb7bxsRnDWg6/Bh7YxjH0ghERZzBFRL5MyTSZ5CNZJl4wI6xK4pjOIVzqohCUCJSuUBp7Q65+WtotU2mDgdQHw5h609jH80in8ziDK+S37hNbO4KSksD4WQW2ZEAps4Y1sE08okMNtscofIZAq2zqH3zSK0NFH1JDD0J9J1x5MMpzPoGNuccYkcJTWwBTaSNXlrF0JdB35dEPpzGIK2gV1fQmutYc6cwppaxWtuYJ4oYRvIYZ8oYpVX04hIqcR5rfBlrdhWPfxGTsIppqoRZUscsa2CQVFFO5bHY5/BmNwjFN3CqGziUTWyqWWyKFmZZDfVkHrOuRSi1SSp9Go9hDpe+jUvTxqGcxS5vIewOY5HWiUU2qeTPE7Iv49a3ccrncCvncSpa2AQ1HJI6Ke8arfxlUp51PJp5PMo53LJZPNImbkkTt7BG2b9FK76FW9bAKa7hlc/ikjTwSpr4ZS2i6nmW85co2VawD+UwD2SwjeTxS+oExQ0CogZpfZuNyhUiojLaYyEMHVGs/SkcQ1n8wgq67iAF8yKL0dN4h9Ko9nrQHQ5gOB7B1pPANZAiIq5Qc67QcK7gGkqhfsSNZo8b/SEfpmNBbN0xghM5Wt41arY2nsEk6kfdaB5xonx4u9/Z1hklKa1SMbUpm+YJjmYwHvKhfMiG6mEn2j0unN1RkqISGUV9uwN6NI3xoBf1Q3b0e53o97lx9UQwdnmITOYIj2cIjmTQH/CgedSJdo8DW0eYwHCK8FiWlKRCTlknK6+SkVW2GzmkFZKiMllFnYXQGpu581yoX+NS8zold52Cq8a1xVtcX7rNrbW7XG/f5s7GE1xoX2Vr6TT//qt/f48E//znP+fOnTsfeG3wzp07vPHGGzz33HPvyb797W/zyiuv8O677+4I9D3iXnvTDjvs2rVrR6B32MZms3H69Ok/KdBf+9rXeO211943+9lPfs7pwkXiwjzSBywM/JWInv9nmql/1uLoidB0LPLdl17jxtJtZr0r6Pe6EXzKQM9fziD4hA7VIw5y6ganixd58sIznC1dwt4VRX/Aw9g/KJn5hB7pZ80khCWyyjoXmjd4bO0O3qE0puNB1HvdSB6wIn3AQWAsR0xQJimu0gwvEpzMYD8Zx9mfQnMoiOwRD57RDJGZAs6+GEVDA/dQDGtXCM94Bu3JCDMPu9B3x3FPZdAc86Lv9KE57EC824Kxx4+mL8zUPg+K7igueQlDfxTpfieKvQ40Bx0YOwPYJ9JIepPop8sk3GskXatoT8SQ7XFjPhHB3pfANZpBP1PGblykVLhKtXQN3XSO0U+ZMRwNYumK4ehPIe+OYbEtUpy7QXnuJgHfOpMHAij2eTAeD2HriSPuiKCRVygs3iS/cgt3YgPxZB5lRwTd0dB2o8fxMMrxLLHCWXKnbmNPn0Jha6Aez2DpS6M9FkJ8OIh8NIPFOEty8Sre8mkM0SV06jr2yRL67iTSE7/rURYX8SY3UIdn0SbbWF1t7PIauqEsysEsWkEZg7iMyz6Pr3QWd2ULZ2wNj7mNfrKIZrqMUdrAKK1h1c3iT53CXzlNMH8Gv2cVs7SBWdbCrGxhljcwK1r4/Gsk6hdIlc8SDG5g1s5iVs1hVrWwKFvYVLOEHCukUueoNa4QT27hMs1j18xjU83hUM3jVM5jlJRJ+taoZi8QcK9h189iU81h18zjUszhUc4Ts65QT5yjkT6PW9XENF7EJm3ilLdwyefwKOdIWFZYL10la1zAOJRBP5DGNJLDIajjlbXwyZtkLMtsNa/hnyqiPBxGeyKGtjOBdSiLe6qKT9Sk4l5nq3Ed13AGxT4/6oMBjF0xDMcjWPtS+GeqhNUlFpJncA1lUO/3bdfY7fOiPxrC0hXFP1Fko3yFduQ0vtEMhoN+tHu9yD/nQL3Pg/F4kNB0kZXkGequFTyDKYyHAuj3eVA8ZEf5sBPz0SAJSZW6c5msqo5nYHtRV7/fi/whG5pHnNhPRokKCmTkNaLTeTwDCSwdIfR7t0XcdMiPbzBJaCKL7ogdT38M70ACy/EAlqMBDPs9eAcThMaz+IdTRIVFItNFEoICCWGJtLRCRl4lISxSMc+zWbrA6eJFNrPnOF+5wq2NJ6n558nZy1xfvM3t9Se4tnCbJ849zbeff4XvvvLqBzZt/PSnP+Xpp5/mhRdeeN9DKb/vu3/88cffk3/zm9/ktdde2xHoe8i99qYddti1a9eOQO+wTSwWY25u7k8K9EsvvcQrr7zyvtkvfvYmd04/RWgyi/whG0N/I2LoryXMfFyLdzDBvH+dn7/xJl++/QJNxzKmIz5mPqFl9MMKBB/TodvnJjye48r8LV567mU2CxdwdEXQ73Mz9TEtok8bkT1gxdkdITie4dLidVYym9i6QphP+BA/ZGPy4zqmP61HdciJ5oCTkCRDRJlGtteE5ogT5UE7458yMPlZE5oTHmR7bJg6/SQ1JbSHXFi7Q7jHk0j2+5Hs8xKQVbEPJNEfC5KUVbCeCOHsiRKeKWEeyqE8kSBtXSXjWsPYGcXUFcV0NIDtRARbVwzTcB71UI6Uf4tK+jIB9RziRzxoD/ixdkSwdkZQHQ4gHy2Qip+jVLpOOn6Oyb1uxI86MHWEMB0Po9jvR3giQq50mWLrJtnaFRTTRZRdMazdCQzHI0ge9TJ10EckskFp8Sa59g30tjbq0RzO8QK2/hSSPR4EB/3YNXVyCzfILd/CkTyFWtnEJa7hmCohORhCdjKBcaZEvHCWwvotPKUzGDyLeA1tXLI60q44ypFt8fd7Vyis3sSSXMQUXsTvXcOln0M1mkcrqGEQ1XAa5inOXyfeukygeo5AbAOXbQG1uIZB1sQoa2LTzJHOnqPSvk5m9jKJ8gU8vmX0yiZG9RxGxSwW1TxR7ylKhQsU65dJ1y/h9C5h1M9h0c9h0cxj084TtiyTC27RrFwhFt/AYpzDpJ3FpG5h0czj0MwTdaziVVRIuZbwGOfRTOUxSCpYtbPYVE2c6nlitjVqwS1S5iVME3nUA2l0wzkMk2Ucylm8qjlS9lVWilcISGtou6JoulOoTsbR9WewTVdxyVsU3BucblzHO1VGczSIvjOK6nAIfWcMY18an7DGYuYC5+Zu4BkvoO+IoDoQQHcsjOpAAP2JCK6RLJuNq5Rcc1h7ohiP/26J8BE3ykc96A778YzkWM9dYCG8hWcoheVEGMPhINoDXhQPbY9dhKbytDwr1GxL+IYz2DojmA7/rsrucw7Mx0OEJ3JkZFVyqgbuvjiO3ij2EyH0B7wYDvnwD6WITheJC/KkxEX8gyk8/XEsR4NYjwZxnIwSGssSHs8Sncph7fHjHYri6dueg3Z2RwmOZPAPpQhNZAhPbM9PpyRlYjO/E2jZ9tzzcnSDM+VLbOYucr52hQuNa1xp3+Tawm3aiVVy9jI3lu5w69Tnef7uC/zip2/y5s/e4ttff4Uzp86+75zzD3/4Q55//nmefPLJDzyU8vuX6P/69y+++CKvv/467777Lr/97W/v9U/3nyX32pt22GHXrl07Ar3DNvV6nWw2+ycF+pVXXuGb3/zm+2bvvPO/+OoXvk54IoficxYG/1bM8IeljH5EjumIj4K+yTe/9hJf/fLXiItzGA+7GPmonKEPiej7WyHC+7SoD9ioeOtsLp4mKE2hOmBFeL+eoY9KGPqIhLF/ViDbbcE5HGG1vElGU8I9EMPRF2LmM0amP21EvtuGaq8TS0eIleRpIsIM5g4vGWUN47EwkofdmDpjWDojaPZ7SCoaJARFLEcChEYzuAbTyPZtn0xO6NuoDvoxn4jgHUxh7QhtdzwPpJAdjWCfLFMJnsYtqKA64Md4JIi9I4y9K4rhiB9ZRxS7uEE5eZFM4DSa7iTqQwGsnVGsnRE0+zxMP+LCo5+nVLhMsXgFu3IW8WE/+hMBrCdj6I8EGf+MFZd2nkL1KuX6DQLBDRTjeVzTJZwjWUxdMSYesGMTVyhWrlCevUGicgW1uoVH2cQjqmPqTzP1qBf9SI5M5gKl+Ztk529g9Kzit6/gNy5gmSwhPh7DMFEg7F2j3L5BYfkmrtxp/JFNQp41DKIqytECOmEVl2aOYvkKlYWbeIubOKLLxNNnMaiaqEVVDJIGVlmTdHiTYv4imYWrZFduEK2cx2CaQ6tooFc1MStaBA0LpAMbZAsXyLavEi6dRW9sodU2MWhamLVz+LTzhDQtMvHTJHJnsDnm0Rpb6A0tjNo5LPo2QcMCAUmDjHedgHMJvayEYrqAUdvAZJjFop8nal8mpWvjkpQwCHNoJ/KoJ3KoJvKYVU3s2jnitmUqvnWimjmMIzl0Qxm0Qxm0/WkMk0Xc2vntirrMeSLKJobeFLquOPqeJNreBNqeOA5RhdnEWdYLlwhJaph7k+g7Y6gPBTF0xlAfDWMdzrJavMRy6jwhQQVrXxrd0SjGjhiqAwEUe3w4B7OslS4zF9jAMZREe9SPvSeB5qAf3ZEAykfdeAZTzPvXKZnaBCcKOAeSWLuiWDrC6A/4MB31ExeXKRnmyajqxEQVvP0J7N2x39XZBXD3J4jOFMgoqsQlZSLTRQIjWdz9CRwnozi7I/hHU8SmisSnyySEZULjORKiEv6RDIGhFIGRFKGxDKHRzO96nnO4BiO4+8NEBXmCYxn8AwkCI0lCo2lCkzkCI1nCE3mCoxmiUwUysgotxzJny5fYzF1gK3eRc7VrrMZP0/afYim8yenSJc42L5E25/ni1ef40Ws/4e233uZbX3mFL177Ms/cfJaV5hrfe/n77znZ/ftFwNu3b78n+/2hlN/85jc8++yz75mT/spXvsKPf/zjHYG+h9xrb9phh127du0I9A7brK+v4/V6+eEPf8jLL7/Mz372M3784x/z+uuv89prr/Gd73yHl19+mWeffZa7d+/y/PPP8+yzz/LMM8/w5JNPcvfuXW7fvs3Z9XOYutxMfFxO91/P0P3fJun7q2kkDxqISHOcX77MM098iZi0gLXTz+TH1Iz+vZyBvxKi3G3D3hXmbPUyd88+Rcu1TFJWQb3XieATesb/UYXk00b0e72UjHOcq14mMpkjp6zj7osj+owF8f02lI+4kD1kw9kTZzG8gfGYF2u3n5S0imy3E+nnnPjGcyj3uFDudpFR1nGdjODojJBWVNEdiyDd6yOiaOGZKCF/xIWrP4W9M4LtRAhnbwxLXxzlkTBxwyIZxxq6zhjm3iSO7ji2zgjmY0H0HSE03QnSrlMUI2dxSZro+7J4RjK4hzLYu+PIH3Gh6UmQj5yhlLpIzLuJfqqMfTKPsT+KczCL9BEvyuNRColzlAuXyeYuYdG1CRkWCKvm8AmrKA6FUByLkQufplK+SrF8FUfgFCHvKWKuNfzqWRSdCdQ9GSL2FcrFS1Tq1wnkzhEvXCSVPIvftox6tIBqKI9DUiMd3CCXPU+sconkwg3yszfwBzdQiypoRTVMU0XCujZJzxrByCaRuQt4iqdwR06hUtZRS2voRTXcgioRXZuIb51o4SzZhetYfEuo9HXU6jpa5SxOYQmvsELIvkgosYE3vILW0kJjnkOrb6HVtfCoWrhG84RNbUK+VayGFmp5BYN5Fr1h++M1zOETlvFJ63hNbcySKhpxEb28jMHQwmSaJ2RZIK5tEVbNYhjPIeuPopsooJnMYxCXsOtmidtWKLpXCavncAqqaHuT6AfT6AcyaEcymIRVSv51mpEzBKQN3FMVzH1pNB0xtF1xtCfjWEbytFNnaYXPEBI38E5VsPan0Z+Ioe+MoDoUwtKTYDV/iap7naCgin+mirk7ib0/heFEFN3REL6JHKvpc2R0c4RFZVwjGQwdQSwnYli64lhOREjKajQ8KyRkdQJTRSLCMu7hDO7BFI6TCTyDKVKyOllli7iwSHSmTHA8T2iqQGA0h380S3g6T1xYJCkpERMVCU/mCY7niE6XiM6UCI7lCI5lCU3liAryBMZSuHrihCYyRKcLRCYKhEbShMYyhCfyhCYzeIaSOE5GsJ4IoD/kJDSWITKVIzyWJTiaIjSZxdMXw9YRxHY8iKc3TmymwGLgFJv5C5xKn+Vs5RJrqTNUDHOUdE3q1gWWwhusp85yuf0YS80V3vrFv/Hdb3yPJy98katzj/HF689za+txNuZP869PvfCeHuhXX32Vl19+maeeeoq33377j7I333yTL37xi/zmN7/hpZde4rvf/e4f5c899xxvvPHGjkDfQ+61N+2ww65du3YE+s+Rd999l/3793P//fdz3333cd999/HRj36UD33oQ3zyk5/k0KFDPPPMMzz33HM8//zzfO1rX+Mb3/gG3/rWt/ja177GU089xeuvv85PfvITfvazn/HWW2/xzjvv8Ktf/YpvPvcyGUkV1W474x9V0P0XU4x+WIZ2j4tZ7zI3Vh/n68+9REHbwj2YQPAvekY/LKPvvwlQPmjF0xtnM3Oejew5qtY2BXUTxUNWBJ/QM/xhKcJP6lE/6qRqXaCobRGfLtIOruHojiJ5wIb4QSviz1oQ32fGO5Qmq6xhOuQlKs0SE5VR7XGj2u/FMZhC8pAd07EwMUER24kQgdEsecMs2iMhDMfCxNVzaI8E0RwOEBWW8QykcJyMkJCUMHcnsA/nydnXcArKKI9EiclqBMfzeIe2+3WNvQl84goF3xYJ6yra/hwR9RwxeYPgdHn7amFHmIRxkXL4NPnQGUySJn7dInFjG8t4CttgBsXBEEnzMpXoOSqpCzjMS/ica5QSF0i51rFNFhEfDOKTNsi51iknzhMMn8YfOUOlfp1i6gI2ZRP5ySTmoRxR7TwJ2xp+/ykChfPUlm6Tr13DqGqimCyg6UnimiwS1czhM7XxZc5Q2XqcRP0yWl0LhbSCYiyPdTCNX1TDrW7gCq4SqZxD42+hNrdQ6Rqo5FWMgylco3mcsjoe3wqB+Dq2wApG3yI61wIqfQPLTAlLfxqHqIzHtoDHs4Te0MDknscaWEJrncOhaGAfyeGYKuJUN3Hp5zHIt0+EW7wLWD2LeHQtfKIqbnENm7iGVVjFMFNGN1PAqKrh9C3jN8wSUc/hU8xim6limigwc8SPdiiFbjKP17pAwr5I1r5GUDmLW1zDMVXBMJhFczK5/b+R1amENij5NvCLG3gFNdwzNSwDGUwDaQw9SbziKu3MGbLWFfyCKl5BhYCggn04h7U/g6UnSVTVYK14maS2TUBYwz9dxjtRIjBTwT6YwjWUpWhepBnYICat4Z8s458sEJjJoznuIzhZJCIoU7IuUDDOEZ4p4Z3IE5op4RvLExGUCU8ViYu3l/zi4jKewTSe4Qz+kSyh6QLhqSJRQYm4qExEWCA0mcPVG8PeFcHWGcE/nCImKJMQl4gLy8SFJUITWZwnIxj2ebB1RXD2xAmNpsko62QVNVKyKqGJLLbjAXR7PViP+bAdD2I45iQpqZBXNcjKa0RnCpiP+NHt86Dd7cTZEyMlLdOwL1C3LHAqc46zpUvU7QskRCXS8ioFVZ2GY5F57xq3N5/gtW9+j7X5dZ65/mVun3rid00cd7h96glubj3OevM0T954+j0C/ftFwK9+9au8/vrr73so5fedz//1pPczzzzDm2++ya9//et7/VP+Z8u99qYddti1a9eOQP858tvf/pa33377jzpMn3nmGYRC4Z8c4XjjjTf40pe+9IH5k5e+SFZRR7Xbwdjfy+n6PyYZ+e8y1LvtVH73avylm//KvG8d71AK+QNmhv9WwsBfixB+Qo+3L0HZOMupzDk2cxcoG2dRP+pC9CkTo38vR/RJ4/ayobJBXFBgNX6a5dgWpqNBlI84UTzsQPwZC7L7LcQFJeKiEqGpLDlbGc9QEsPhANaeOOp9HiQPO/CP5sgqGniHU8z71ojMlDB1xQnOlHGN55Dt9eEZyZLXzxMVlIgJy0QlNRyDKVKaeZKGBVTHE1iGMhTtyyTVLQKTeTzDGYKCCgXbCgXHGubxKtbJKmX/FiXXGiFJHc3hIN6pPHnLMmXvJh7tPBbpLJX4eYrh01gFaVSHQtj6k8RkDbLWZYK2FSzGBcqlq1QKV0gHtpAcj6E+FsI/XSQqb+BTN7F7Vig1r1Np3SToP4VyNIfkcAh7fxr/TAmPpIrRMEuufYPi4k08vnWUiiqS/iTa41FcIznskwXM2hbBzBa5tVvYQyvobAuo5BVUnREs3Qmso1nM6gaBwCr+9AYScwlLaBm9fQ7jZG57Aa4vhU1Zw2VbwOloY/EvYU+uYQos4VQ1MA+kMfanMc0UcepnsepaGDU17JEVbNFV/I5F7KMFbFMVzNMVTDMlTOIa2pkCNtsc3vgpEsE1PMIaTkkDm6CGeaaKeaqIZiSHSVIhHDlFIbZBUDePRzWHQ1THIWpgna4gOObFPFUk6l2jnjpL0r6CR9LCKarjFtVxixtYx0qYJ/JkPWus1q6Ssq3iEtfwiOq4Zmq4p8t4Zsq4p0pUg1ucql0jqmnjEdbxCqp4pyu4psv4BFVC4jqL2fO0wlsEJXV8giqeyTL+6QohQRX/RJW4rMFibIu0roV7OItrJIN3uvi7vICuK0BGO0vdsUJgqoi5K4r1ZAzXQBLvSJ7QTJmYuErB1KZqWyAwWcBw0I/5aAhLRwRHb4LgeI6sskHNukjVskBoIofpoBfdPvd2C0dXGN9Qkqp1iYZzhYq1TWymiPVYEMWDNvT7vViPBQlN5MipG1QsbYraJtGZAtaOIKqHrWgecWI7HiA2U8A+FCIlKpPXtUgIy1iO+lE/6kS3z4WrM0pCWCIjrVE1zTHnX2POt0JWWSUlKpMSV0mLy+QUDZYim9w6dZcv3fhXvnD5WbL2Ihdnb3Br/QluLN/m+tIdrrVvbbdwNM9x6/J755hfeuklXn31VV577TW+8Y1v/FH24x//+A/S/M477/DEE0/8Uf7UU0/xy1/+ckeg7yH32pt22GHXrl07Ar3DNi+99BJ9fX1/UqDffPNNnnrqqQ/Mnzj/NPPeNbT7XIz/k4KT//ckox+RIf+siZSsys21uzx/96ucq1zF2RNB9rntto7Rj8gQfEJPaCxDUd/i8+e/wK1TT5CSVTAc9CFzgqqlAAAgAElEQVS8z8j4P6oRfMKA7USYvGaWhn2Bx08/xVxgHUtHCMMRP/KHHYg+Y0a7z0tO3SSrqLNVuEBKV8DVk8DWm8QznEb8oB3lXjcpZYOCfpaCbpbN0kUCoznC0yXiiibqIyEU+3wklS0KhjZxcZWKZZHQZI6UqkVGN49zvIDmRIykfoGye52UahbvaBbvUJqoqEzevERI0ULTlyVuWaUcOkvRfQp9ZwzDsRCBiQJhUYWIZhb9dJWEZ4Na+grF+HmmHnUi3ePB2ZfEN54nIKigE1aJx85SKd+glL+KSVBBuMeLvTeBayCJazSLaiRDPHOO0uxNMtUrmA1zyHriGDoiOHpT2AfSqIfSeD3LFBZukWpcxeZbQaepoe9OYDkZx9ydQDmUxm6cJxzfJNW+iiuxgdG7gFlQwD6URXcsim44jV3VxGWZI5I/jcRawhFfx2mYxTlZRtOZQD2YwSwsY5FXcVrnCeTO4Mlu4fet4ZE2MA3lMU4UMU2XME2XsErr+ELrhEtnSSVP49POYRVUsAirWAU1zIIaFnEVj3WRWP4s5cJFQtYlHLI6VlEDi6COTVjFKqrhM7Up5i+yMHuDuG8Dt3IWu6iBXdTELqrjEjdRjyZoVa6wtX6XlHcdp6yJQ9LAJarjFDbwiOpEtQucmn2Ms2t3CZuWcErquEQ1nDMV3MIaXmGVqGae07M3mI2ewTlVwjldxiOo4RbU8Amq+EQ10voFTjeuk1S2sPQmsfSnsA3n8Akq+GeqBARVSo5VNotXCM2UMXVE0R2LYelJ4hrM4p0qERFW8UtzLMXPEpwsoD8cQH8kgKkjjLUzhnswTVYzy6nCRdqhLcLTBQyH/Gj3edEd8GI5FsLZGyeraXK6coWWZ43QZA7TsSC6PW7Ue1wYDvtx98WpWtosx7f+INi2E2EMBzwoHrRhOOglNlMgp25StcxTMs4Smd6WZ+M+N5rdDizH/ITHM6QkJRyDAeLCEuHJHLaOINajfoyHfQRGUviGE/iHUqTlte1XbHGJ+Mz2ImFaUiUmKFDWzXIqfX57oTB7gbOVq1xfvEXGUuRM5SI3Fm9zc+3zXGnf5PapJ7jQvsIzd7/E43fe26Tx4osv8oMf/IBf/OIXfxjX+P3nBz/4AS+++OIfvv/XOenfXyjcEeh7x732ph122LVr145A77DNT37yEw4dOvQnBfqdd97h8ccf/8D8q09/nXZ4A/1BD+P/KKf3L2eY+Acl6t0Ocqo6X3niq3zvW9/n2sItHN1RNHtcDH1IwtQ/q5F9xkRSVKTpWuK1l7/Hl258mfB4FsvxIPLPWJn+mBbhJ40ER9OkFTWuLt7i21/9DgVdC89AEkdvHPH9NsSfNuPpT5GSVMlqm/zr51/AOxMhPJElISphOBxA/KAde0+StLxBcDzPUmyThn2RpKRCWtXCM5pHstuLpTdJ1tQmOFkkNL39ou0byZCUVYnJ6yiPxbCNFCm5T5HQzmHrSWI7GcU9kMQ3kiEqrqHpz2CbrlAKnKEcPotlOI9ijwf3YBLPQBLnQAJ1bwqHfI5y6iKVzGUCxgUG/0WPoy+5PRLSl0B2JIhL36ZSeYxy5Tqx8BayngT6jjCe4QyO/iTyw0H00yXy5SuUWzdJFC6hU9Yx9Cew96aw9SaRHwmhHckS9q9Rmr9Jon4Js2sBi7CKYzSLsSeOZH8A7UgWq7RKqniRTPs6vtQWTnMbn7SOdTiP/FgETX8G/Xgen2uFwsJ1lK4agdA6ftMCdkEV7UAO43gR/UQRh7pJoXmFVPMSydx5op517OI6hokyxpkKpqkidkmdTOYcpfnHqLWukU6ew62dxyCoYRZUsQjr2ER14v4N2suPs7L5BMXiZVz6eSySBlZJA4uohk1YJ+FYY2XpLpevPUc+tz3GYpM2sYqb2ER17JIWMcMyMdcspxZvE3asYJc3sUnqOKXbgu2RNIkZFlmrXaMRO4N9uoJlqoRD0sAhqG2/QosbpC2rnGs/RkI7i2Uwi2Uoi6kvg3OmjFdYwyuqU3KtcXHhNkFBBWtvCkt/CkN3EltfBs90mZC0znL2PJfat/BP5DEcD2E8HsXcFcfUFcN6Mk5M3uDc7GMUXA3cQ2n0R4IYD4cwHgmiPxLAdjJGRtXgyvLjLCfOEhzPYekIYzjkR3/Qh3afB3tPnIJ+ltXMORYjmwRGs9g6w5iOBDDs86B91IWnP05G1aBmW6TpWCYwnsFxMrp9xn6/G/ORAL7BJPGZIilphaKuRWgsi6c/ibUjiLUjiKc3hncouT0GMp3H1hPAO5TE07d9udDTGycwnMDTu32+OziaJjCcJi4qbjdxiEpkZRUyihpLoVOcLl5iPXmWldgmW6XLXF++w4XmNbK2CqvZTa4t3ObW+hM8ce4ZXv36a3z1he3KzfdbFHzhhRf40Y9+9IfKuv89e+2113jppZf+8P0LX/gCb7311h91RP/+RXuHe8O99qYddti1a9eOQO+wzbvvvsv999//JwX63//937l9+/YHj3j86GcsR7cwHPEx9mEZw38nZuIflBgPeyloG7z28vd555fvcGfrSXx9cTR7HUz8g4Kpf9Igvd9CeDLLQvgUb//b27z4xW8SF5QIDmeQ3G9F+C9GJJ8x4RlMEBzOcHvj83z9uZfJqRskRSXMHUEEn7YgecCKsy+O42SUgrbJY+t3MXZ5yCkbBCazyB52IX3YQXC6iL0rhnsgyUJ4C99QithMgaS0iuZwGNkeH3FZk7C4hulomKiwhG8gSWA0S2S6iKknjuJIhLh+gbzzFNbuBPqjITz9SUJjBXyjWUw9CdQnU6Qca5Qj54kbl5DvD2LviRMcyxEYy6E5FETRlSAb3KKSvkQ+cQFNfwrBo1bcfUm8w1m0h4OIDwTIRM5RLF6lVLqKTT2Hrj+FZySDsz+N5nAQ4R4vQfMCpeo1Ks3HCEa2MAsrBCVV3KM5FAf9iPYGME8UyOYuUJp9jFT5Mg5zm5BmDr+0jqojhrwrhn4oQ8S9RqV9k8L8Y/ijW8TcawR18+j6s2gGsmiHs7i1TarNG9RWbmMPtolHN4k4VjFMltFPlDBMlrBJGhRzF6m3b9LauEtl9jEigQ2MojoGQQ3jdBm7qEE2vMV8+xbr55+mvvr/sfeeT5KdZZ52/xU7s7sTs8syeCOGwYgRIECmvS1flVneu/Tee3vyZJ5z0mdVZZb3XV1tqo1arZYE8ggEEkggIY0QCCEkEOoOzUwM135ISYNgtHojNt7tiKGuiOfT/UTWt4yrnrzv330Fn3sR7WABbW8eQ28Oy0CRkGWesnSGhaV7yc9cxGasohsuYhgsYhoqYhkoE9TPkg1uMFM4T9izjHm8gnGsvmDFNFDENlQmaqhRCKzh1xewDGQxdmexDhUwDxex9hexjxRJmOaoxU8S19WwdilY1TJmtYxJrWAfKOIcKKC4l1nNnyfYn8fcJGBqETE1C5iaU1g7JNwDRWrCKbbKFwn0ZtEfimA6nsBwNIa5IYHhSIzgUIn18gWW06cJ9OQwH42i3evHdCyC4XAE3f4wkcE8Z2uXqUXWsTVG0NzpwXwkzOQ3Pejv9KPfH0AYKzKfOEnJOU+4W8ZxPI7pQBDj/gCaW11YD4dJDOdRDNPIuimifTLOxvo/feZ9ASwHgzgbEvjbU8T6JJIDecJdGXwtSdyNURzHIjiOhnE1xvC1JvC3vTMUKBLrUwi2pQi0CniaEngaYniaYgTaBdyNcZxNIewNIcLdGQLtAo5jwXocXkcKX0sMb2uCWJ9CtCdDvL++RKVgqbGZO8tifJP58CqbyhnOTV/kzNRFzpQvsFU8Sz4wRclf5Z61b/PkQz/mN6/8ht/+5rc8/J1HePaZZ/9MgN966y0effRRfvWrX73nRfmd2k9+8hOeeeaZ97xWv/DCC+8R6HeEfJcbw432pl122bNnz65A71LnD3/4A5/73Of+rwX62rVrLERXcR6NoP7EOKqPjdD+oWF033AS7c3w0x8+x7Vr1zg/d5lol8TkrXbUHx+n/cPDDH3RiOWwn9nwCs987ydcXr2X5EAWd1OM3s/pUX98gr7P6THv9eFrTXDX8r2sCFsII3kSQ3lGv2aj+3N6Rr/mQHu7F8NeP1Ouecq2WbT7bGRNU1iPRuj5ggXNbX6crSnGvurA155CmiwR6EghDOWJDmYZ/Kob3YEIgraK/kAIzW0+oj0KIVWaYLtIsDvN6O1BzE0pROciwZEKY9/0YX27tzSgSmE/FmXkjgCOrhySbw3RvYruhIDpcAx3cwJ3UwrL4QgDN9txj5TJRraQ46fw6WromwS0R7zYG+KYDkXo/LwZe4+CFNtCEc8SD25g7i8QGCkS7MthbUjS/Y8OdE0JMrHNelqHdBq3bYmoeZaIdgZbR4ah24NoTySJuRfJZc8hZXcIxbZIR06ScC9j78sxdiSBpkHAO1YhL50llz9HQjmHlN9BTp3BPl5hojWDtk3C1l9CTpykkDuPNHOBgLhMXNzEPF5C25VFq85i7FJI2ObJCqcoTF+kuHoP8fQWhrEyk/15NH059P15AuNTJO0LKOIp5MoFgtF1jLppdGMltEMFTMNl/BMV4toZ5MgGiegGDnMNq7mGSTeNbriAeaRESFMlOloi7VkmZJvDNlHGPFrGYa5hHqtgGS0TM1ZJm2cJT5QxdmbQdQhY+3OYB4s4J6vYR8qkHPNUwusEB0s4upX6Km61jEUtY+/J4RrKUw6vUUueItCbxd6WxtSQxNSYwNIqYm4R8fbnWSteYia6UR8SbBcxHY5iOBLFfCKB4WgcX0+Wk9OXKDoXCfTk8KjSGA6FMR2NodsbQL8/SLgvy1xyE0k/Q6BLqudAH/ah3xfAdDiI+XCYWH8WWVchOVjE354m3CPjakzgaUliOxLB0yoQVEtEeySiPTLhbqmestGZwdsq4O9I4W1J4m1NEuwUCfdkCKpE/B0Cwc40oa4M3uYEnqY4/laBoDpVT+poFYj0ZAj3ZPC3CbgaoniaEvhbE/haBfztSSJdafwdAsZDXgLtKQId9ezn+gt1HE9zgqAqTUglEu3OIGvKLMbXWRG3qAZWWBFOsq6cYSG6wVx4lbnQCifzO2yXz1EKzDArL/DKL37Na6++zg8feprv3v19dtYv8ujV7/LIg4++R4DfeustHnroIV599dV3Zfrll19+t/bjH//4PRsKX3jhhfe0dLwj0P/8z/98o7+2/2K50d60yy579uzZFehd6rwj0G+++eb/lUC/9pvXqdhncZ2Iov7YOM3/Y4DG/9rHxNfsRHskHrzwCK/88hVmAysk+7KMfNmC+hMTNP33AYa+YMBwp5elxAZXN+9nIbZGwVLDdTxG701aOj4ySs9nNUx+3UmoK8N26TyZsSK1wAoZbZnRW+z03GRg4utOBr9oRr/XTzWwQnIwh7XRS8Exh+FAgMGv2LA3JZn4ppuBL5mJD2ZJDuUJqlKkNWWcTQIj33Dj65Xxd2cZ+Iod67EIke4M/vYUnpYk3o40mgMRomMVBPMcuiNxDAfDhPuyeJoFnMdjGPYFMDQkSBpmkbxruAZKaI/GiY2WCXYpeNpSjHzdif54nLRjGTm4QdyxhL5dJmGex6ZK4mgTGb3VjeZwBMm7ihLeRIpsYpuYQfAsI7tXiU1MozsQZXx/GME6TzayiZI8hdu6SDK8RV7YJuVcQtsoMH44jm+oRDa2STZxilBkA0E6Q6l4kYh3BX2HzGRDCrNaQrDNo0Q2Saa2yZQvkJu5iM+5xIRaZkKloGtLExgpkTTNEgmuItUuEUyvo9eV0YyWmOwroOmScXQphEbLRB1zxISTpMvnsLsXsJhr6CfKaAfzOLskPJ0SCdsC0dAyft8Sds88ducCZtMMpoky7v48zpY0Yd0MQdscblMVi7aMyzGPwzGHzTiDf7xMqD+PZ6hAQFvFMzmNdSiPfbyC01LDY64R002TNs7i7S9gVyuYujJMNMYx9yg4RksErPNkXIvkXCt4e+sDftZWEWtHBptawtyZIThZpSqcJutcxtOt4FZncXcqGI7EsDQmMTcJ+AdyrGTPkjbW8KgVPCoZl1rC0pTEdCSK+Xic6HCJheQmidES3i4ZjyqDo1XEo85gb0jibBKIjxbJW2tEB3P4VBk87Wk87QKavR587SL+DpFYv4IwnMffI+PtSBPslnA1CYR7JHwdaYIdIqFukVhfFn97mlCnhLc9RbhbxtdWl2O/WiSgEvC3iwQ703U5VqUItKcI98iEe2RCnRmC6jSe1gS+NgFPYxRfR+rtpSoZUiN5hJE8sT6JYIeIsyGK/VgQd0MET1MCa6OXnKmKMJQj2isT7c3gaophPhjEut+Hvz1F3jTDUmKDqn+Z+eg6J/PnWIivkx4rkjVOM+WcoxZYYSG6zoXlu7hy8V52Tu/w40ef5p6Nb3Nx/gqP3PU465WTPPHQkzx89dH3CPA7bRmvv/76u4kcf/zi/MMf/vA9wv3aa6/xne985z1bCq9fv86//Mu/3Oiv7b9YbrQ37bLLnj17dgV6l3/n/6tAX7lyhTfeeOM/rL343EuUbDVcjVF6Pj1Bw1/3ceKvehj7spnEUI6zM5d4+vGfsBhZJ2+ZZuwrFno/PcmJ/9LLwOeN6O/wMB9dYy19ivX0NkvCSSyHQ4zcbKXjo2N0fWKCwS+ZSI0UmA2skpkosVU8R7hHYuJWJ0NfsTD2jzZ6b9JhORCgYKkSVqcJD6aQ9WX0+3xo7vThbksy8EUzY193kRzOE+6uL3goO+exHo1gPZYkNlZCsy/I0FcdRHoLxAZz+NoEwj0Z7E0C3k6ZlHEWd1eO0W/5CA/kyGiniPQpOBvi2JsSJCamyNgWEUxzTB5JEh6uoDgWEXVV3K0pDIfCiKZZZMcCadcypp4C3tEpsv51QpNFLC1JNPtCJDUVZPdyXcQ1M/jMi+Tj2yjRk7j784zsjeDpVsiY58j6VvFbF/D718krOyjCaaz9eUaPxTAcixMaKpDQzhC0zhFOnCJbvkQqtY1ppMykWmLiRBxXe4bIUBHPWIVQfJPC/N0kMttYTDWMkxUmOxWMx2N4OyU8I0X83gVE5Rze2DJaQwmzpYZJU8bULGA5kcQ5kMdvmyUcWiYYXcMdXMHmWcBqr+Hqz2E5HsfZm8WrnSFgm8dtqeH2LOEJruB0z+HTTWFvEXGoMzgHi7gnp3Frp7Bpp/B4FgkFVojb5vH15HB057CoJBz9BVwjZWwDeZzaKaLBFaTgCgldDVdvXZ5tKglTe4aRo0GsPQpJ1wJTwklSpjmc3TkcKhlbu4SzS8bcWu9tTtnmWSmdJ6Gt4uyUcXbKuDplnO0yTpWEoy1N1rHAknSOyEgZjzqLU63gak/j6pDwqiX8XTJF1yIF5xy+nixetYy7I4OrLY2/U8arkogMZJFN0wiT5Xo0XUcGd3uaQI+Mq0VAc8BNdDCPOF4iPljA15nG05Em0CnhbhEIdUuE+hSEsTwZTZlov4KzIYGvLYW7OUGkR8LXLiKMFZB0FSRdhUivhOtYFPOhAI4jYbytSeKDWYr2ORTdNOJkmdiQgrsxjv5bLswH/TiPRxHHClQDy+SNM4hjRRJDOVwNMTRfc2Da68XdEEOaLONWh1AmSkiaCsJYHufRMJO3OtB/y02oM41imCIzWaLimGM1vc1qaoucaYp4v0KsT0HW1GtLyU3u336AJ7/3FJe272YmOcep8g6Xl+9lZ+Yy9516kOXCOt974Af88OGn3l2M8s659957+f3vf89bb73FL3/5Sx577LE/64/+49Xely9f5q233uLatWvcc889uwJ9g7nR3rTLLnv27NkV6F3+nS996Uv85je/+UCBvv/++3nttdf+w9oLz7zISnoLV0OEgc/rOfHXPTT+t36G/sFAcijHXHiVp7/3Uy7MXiZnnmH0Fgtdn53g+F930/2pCfS3u8mbqsxH1ri6+QCr4klM+31M3uqg8xPj9HxSw8Dn9cT7ZVIjBTYyp7m0eA/u5gTGvX50t/sY+Hs9PX9vwN2cJDNeJjmcZyo2j7cjieVgCE+bgPZ2L72fN2I7FkMcLyGMFJj2LqHop/C1p4kNF/Cq0wzc4sR0JEp6soKsn0GcrCBqKsSG8giTU8TGp5jYH8ZwPI6oryJb5hB10/g7RJITZdL6Kil9FVOriL5RJGNfIutcJqWbwXgoTHhARtTNoNgW8QyVMKpzKP5NsqEN/JMl+r/uxHwiTqg3S1JbJaSZxjxSIZvcJps8Tcy2zOTxJNrDUfzqDIFeGe9AHrthlqxyjpxygbB7BUNvlomjMdztIn61hEstY9NUkIsXyJUvEg5tYDNV0fbImBviuFpFzE1JrKMFQoEVcjOXCSdO4vQsYjVMYW1LYWtMYmxIYh8pEXDMEY9vEEisM2kq4PTO4xktYW1IYDyRwDmUx6WdxmepEYquEkqu4wutELHWsLdlMDYkMalk7MNFXNpp3JYagcgaEWGTdHQd32ARm1rBrJIwtmew9RdwjZXxO2ZJCpsUxS2iuhr2rhzmDhlTewZTewZbt4JnfIpsaovF8gWipjnsPXksHRJmtYStQ8baLjF6PMhU5ixbS/cSN87i7M5i61SwqeqC7OiU8fYXmM+eY336Et7BIja1jKszi61Dwtkh4VLJBAcLrMg7VEJr9Xi6Trle65RwqSTcnQqx0TKLqZPIlll8fQoetYyrI4OzI42vU8LfJSEaaszG1hE1M/jUEs4mAXd7Gl+XhKddJNSfxd0Vp+pfJT5awNmcxHI0grM5iastRbBTQpyoUIusUfEsEB/O4zgSwnIwhHG/H8eJGJEeiZJjnqXkFkVbjdiggu1wBOOdXox7vVgOhwn31Ads56Pr5C1VEkM5HEci6L7pRvsNF7YjUTKTZXKmGar+ZQq2OVKjBRxHg+i+6UR7qxN/u0BqJE9moohbHSZvmyY1nMd2OIj5Dg/mfb76gG+PRLgzTcEyQzWwQs40Q7xPITmcI9mnEOmWyGhKbBV2uP/0g3z7zEOcmjrHXGqF6cg8q9ktztfu4nztMhfmrjArL/Hw3d/lF8+//K4Av3OuXLny7iDgm2++yT333PNu7bHHHntPS8c7wv3GG2/wxhtvcN999+0K9A3mRnvTLrvs2bNnV6B3+XfuuOMOnnvuuQ8U6AcffJBf/epX7ztEeHHpCo6jYYa/YOboX3XR/D8G6fn0JEG1yLRviVd+8QrfvfoE6Ykihjs9dH9aQ8v/HKTzY2OYD/hJDuW5uHiFnz31PPPRDYz7/Oi+4aTzk5N0fXKS8a9aEYZyyNoKP3rsGc7P3427MY6nRUB7p5fum3QMf9lCYjCHOFZiXT7DqdlzuNvjRHuzeNVpBr9kZehmG5FeBVFTIWuY4fLG/YjjJZIjRSIDObR3+Bn6qpPIQA5RO01ytEzOOktqvEBaUyE1UcHRmmb4Nj/RkTKSZYGUtoqjKYmnOU5yoIA4USHQl2f0UJSwtkrWs4bkWEJ/OIrpcIRIX5ZIr0xwMM9EU4qYbQk5fBIlsMnkiRj9X7cT7c8R6lXwdqTRq2SE4CZK6iyycBr35Axje4P42tMEeyQcTQkmTiSIBtbIZs8jSefwu5bQqCTMDTEC3TK2piTa4wn8xlkkZQeldJFIdAO7sYq1XcTTLmJuiKNtFHBPThH2LKGU7yIhncYTXMY1WsLdIaM7GEbbJGDpz+HWTJFMniSR3UZjLhB2LBIYLmJuFNA2JDGrJKx9eTy6KnLxPEL2NJnYSWKGWaxqBUNrBl1LCkO7hKU3SzK6QaF6kanCDknnMva+AsYOGWNbBkNrGlOHRMQyx0z1MlubDyCF1nH25zGpFCwqBZNawtIhEdLMsDR3hXNnHiFuX8TSncesVrCoZKwqBVunTHC8TNxb4tTqt/FPTmPrzmLtzGFX57CpszjUCsGRMmeX7mWpcBHfaAVnbw57l4xNJePoyuLqVhAmZ9ievZuif5XgcBnfYAFHu4xDJeNUS7i7FBTrPNszlxC0U7g7FdydMs62DK52CY86Q6A3Ry22yanpS8THSrhaBKwNCWwn4jib661DwmSF9fwOSXOWcJ+M+XAI67EY1uMxjAeCeFoFSs5FTpYvspjcqmcu7wvU0zH2BzHt8+PvSDPtXWZN2mYhvkm0T8Z+NIL+dg+mvX6sh0JEeiVylllqsXXmIuvEe2UcR8OY9gfQfsuB81iUeH8WYbRATj9NNbhKvE/BdSKKeb8f+8EAnsYYvrYUsZ4Min6KYJ9AqDuFrymOpzGGpymKuzmG7VAIf3ua1EiOeL9MvF+uDxP2ZRAGswgDWSquedalbU6+PVS4ltlmSVqjGltiObPBTHSBnZlL3LV0D+dnL1NLL/LCT1/k+vXrXL169T2Dgn+avPHHSR1/3B/9x+u7X3rpJV577TUeeOABrl+/zr/+67/e6K/sv1hutDftssuePXt2Bfo/O0ajkY997GN85jOf4dixY7z++uvve7exsZHvfve7HyjQjz32GC+99NL7xNz9nkcuPY6rIcrgF3Q0/rdeOv5ujN7PaAh3SWxkz3Dt2jV+/tzPiQ/ksR8J0fXJSTo/PkbXJzUE2pKkRos8+ciP+e1vf8uMb4lAh4j5YICuT07S9UkN1sMhhJEss6EVXvvNa6zL20R7JQKdKQa+ZKb7sxr0d/qJD2SJDSh85/wjVIPzeFrjJAZzGPYH6f28Cf2+AMJoiWCXhGKaoeKaJTVRIjNZwdWaZOBmJ9oDIQTNVL23uT1JfCBLYiiHop8hMlhg6JsedMeiiOY5kvoZrA1xnA1xEkM5UqN5kmMlJg9HsbRmkN2rZL3reHqzTNzuJdIrEx/MEulTGD8QxtabRw5ukAvVNwwOfsuN9qCHWL9CqFdh5A4ftoEC2cRpFOE0srCNsV3CfCJGpC9LsEdm/I4AJpVEJnYKRTpHPruDxzCLpSONtyONuyPNxN4ghlYRr3YaSTlXF+j4Bu7xKdOIXaMAACAASURBVIL9OZxtacb2BtE1C5i7ZOL+NfKVS2QK54h6lokbanj7skwciaI9kUDbJOCZnCJXOE9+5iJ2a4mUewX3UAFdYwptQxJdUwJbd5ZUZIPy7N3MLV6lkD6Ld3waXZuIri2NrimNqUNG8KwyPXOZzVMPUlJ2cI1PoVfJ6NskzGoZc4dMzDzHUvUKp7YfJhM9ibm/gKkzi16lYFJlsXZmiWhrbMzdw9nTjxD3ruIcKWPpLWLuzGJWK9i6skQmp9mqXUEIzBAxz+HXVnEMlbB25bB1ZnF050lqa2zPXqYc2cQ3XCIwViEwPo2tK4u9S8HZnUNxLnN28SqioYarW8HVlcXdncPTl8PeKeHvzzGX2OLM3GViwwWcrQKu9nrLhr05hVuVJjZe4WTpIuu584T7C5iPRLEdj2NvTmJvSmI7kSDrWGB7+iILqVPYGiPo9nqwHolgOx7DcjiKp0Wk5FriZOE8U/4VogM5HEcjmA74Me8PYD0YJNCZRjHNMOtfpeJaIN6fxdUYq6+qPxDAeSxCqFsiOZwjZ5iuxzv2Knhb6zFz7oYo9qMhXI1xol1pkkM5hJECYXWGWK9MSCW+fS+C40gIb3OcSHcab0sCZ3MY+4kg4a40/rYklv0BnMfCBFQpXMejOI5HCXeJRLsyJPoVEn0KOdMMG9IZVhKbzHiXmA+vcTJ3ltOVC8zGl5gXVjlV3iHvmeLy0j3cv/0QLzz9IndduuvdV+bHHnuMX/7yl+8r0O9sF/zT/uh3zrPPPsuPfvQjXnnlFR555BGuX7/+nkVUu/y/5UZ70y677NmzZ1eg/7Nz4cKFd19KzGYzZrP5fe/29/dzzz33fKBAf//73+f5559/3/oT33mSkFpk7GYL7f9rGNVHRhj+ByOxPoX7th/k2rVrPPfjFxCGc7ibo3R+chzVR0fp/pSWQGuKjKbIz3/2C37+s5eQdWXifTLjt9jo+uQk3Z/R4mqI4m6Ks5o+xU+eeJaCpUpmsoy7OUHPTTp6bjLiaIjiOBYl3ClxYeFukqMy0ZEMqbECw1+x0/sPJjwdKRxNCcyHQlTcC2TGiuRMVSqeRYwHowx8xYa/N0t8pIT2Dh+hbglxpIg4XkTWThHokhi81UtopEzaMo+tNYV+f5D4QP1VLjlcwN2eZvxgiIRulox7BcE0z8TeID5VmsRwnuRQHseJBGP7QqRdy8iBDZTQJtZOBdOJGLpDHqL9WWzHYgx/00vCvoAcOYUc3yZkXsDZmSXUm8WnymA4FGbkWz7cA0Wk2BbZ9DmE6CY+zTQJzTTBwSK6/WFGb/djbBBIuJfJSWeRpDMkQ+tk/KskjDX0J5KM7QsxcSiGd6xMNnOWbO48snSWUvoMomsFY4vIxNEEuqMJbF1ZlPgWpdJFStOX8bqniLuXMahkNE0pNE0pzCqZTGCNcm6HuaX7KE/dRcC6gK5TQdcmoW9JY1IrCNYlZosXWFv/NsXyJbymWUwDeYzdCvoOGbNaIaqrMZfdYW35fvK58/hti7i0M9gGS5i6FMxdeUITFarxLWrZcyT8qwRtC/iMNZzj01h6clh6csT1VeaEk+QC6xh7RByDOQL6Gj7NDPa+PI6+PJJjkRXlLEltlcBICV9/EXdfHt9IGc9gCU9fgZnEFsvyGQI9WbydCm61gkst4+pS8PbkCI9NsT51kXlxi0B3FnuTUN8u2JbG1SbibBPJ2OY5XbvCtG+ZUG8OT1sa86EwjsYEjiYBZ5NAzjLHRmEHxThLsDOD8VAQw0Ef5oNBHA0JgqoMkmGGac8Ssr5KUCUR7Ezjbkzgbk7gPBEloE4TH8yRHi8hjhYId2YItKUIqOsr6ANtKVwnYnia4oS70kR6JPzqNIF2gYAqTbg7g+NoGOexMN63o+f8b4t1pDtDpOdtUT4RwdsUw9scx9kQxdkQI6wWCapEDIdc+NuS+FvjBDsFXE0JXMdCeJpiRLol4r0SsR6J9HiRxfgaG9I20+55ZvxLbCinOTt9ibPTl9jKn2MmssiKcpKdmbsohCr89AfP8dvXfstvX/sdF85deFeg/3RQ8E8F+sknn+T555//s/7od86vf/1rHn74YX75y1/y+OOP7wr0DeZGe9Muu+zZs2dXoP+S2NzcpL29/X3rBoOBU6dOfaBAP/nkk/z0pz993/o96/cT6UozcJOWjg+P0Py3gwx/yYirMc6DFx/lzTff5KELj5IcyuFpiNH5iUna/26Y7k9psBzwkxot8NQjT/PYle+RM02T0ZQZ/LKFrk9M0PWZSQx3eLAeDXG6fIFz1buo+pepBlewH4nQ93kjIzdb0d/pQ/NNF+J4iQ15m9RolpQ+S2woy8gtdsZvdeNXZRi9xY7tWJTZwDIZbYmsaZq8ZRbNbV40dwaIj1cwH44w9lUHWeM06fEyqdEiyeE85uMxrE0CommW6HiF0VvdeNpEUmMlUmMl/O0i2v1B3N05Mo4lROsShkYB6/EkscEc0YEcvo40I191EBgoILlXkXwb+CamsXVIZPQz6I548bQIDN5iw6HKIPvWUEKbJN2ruAZLZOyLZMyzuFQZhr7uxnAoimBZJBfdIhXcJGhZQA6uk/Ov4u3JM3ZniIl9IYLjZXKxU+SS28SCm2STZ8gnTuEaLDJ+KM7EoSjungJyaJ1s8hSSeJZs9hzZ1GmsvXkmGwQmj6ewtGdQvGsUk9sUCxcoTd2FzVTGNFTA0JVF2yJi6MiQNNYoxU5RrVymMnuFVOIULkMN63gFQ18eg6reJiHZFymmT5EvXiIRP4nfvoRdV8U6WsHYlyMwVEQ0VFFCG6RDm0RcK4S8K3jNc7g009gHS0Qnp0kbaqQdCyQdSwQNs/h0M4Tsi3j1NVyjZVLmGnnnPL7+AsGJKUxdKay9WXxjU4SMs3gnpikFN5gOb+BSy/h7s++u3fb2FwhOTJMwz7FWOE/Zv4xHreBoFfF1Z3GpZTxvy7NkW+DUzCUkYw13u4irLY2zRcDZVm+V8XVJZB0LrGTPkJqo4Fdl8LaLuJoFXC1J3M0pwr0KkmGGonOOxGh98Y+rMYGrOY72gBdvi4CvvT7cGh/ME+qpvxYHuyRcjQmC6kxdoJuiuBujBFQCvjaBoFrE11wXX29LkkBHCl9LXYZdTXEC7QJBVRq/SsTXliLSkyHYIRLuThPoSOF5+7P8bQKhLpFwV4ZIZxphOEdquEhILeJrEep/o0si1pshrBKxNvrJm6oIIwWCKrH+Yt2aJKxOE2gTEMcLVIPLrIrbzPiWKNlnWVe22VBOMxdcYSG2zmpqi9Pl80xH59konuaph5/h/NnzvPziy/zwgR/xxLefYrW6zgtPv8i1N6/92aDgnwr0P/3TP/HEE0/8WX/0O+f69evcfffdvPjiizzxxBO7An2DudHetMsue/bs2RXovyQOHTrE3Nzc+9YDgQCzs7MfKNDPPPMMP/rRj963flI5TXq0yOAXjKg+OkrjX/cw+A8GnMejXF69l1+++DKXl65SC67gOBpm4PN62j40RNenxtHe6iBnmOLqZn2V94Z8moymzMg/2ui9SU/3pyYZ+0cb1iMhtvLnWIpvsCadZjG2jn6vl5F/tDH5DScDXzAx8XU7Jfsc89F1JG0J0ZzD1ZRk8jYPrqYExn0Bev/egL8jzYx3GWlyioKlSrQ/j3F/kGCXQqgvz9BXbOjv8JE1zJCZLBPrU/C2Cdga6kkdgm4G4+EYk7cFEMcrpMZLhHsUjPsCeNQyomGWjGWJ4ECJiYNhEhNTSIYawnAR7e1e7M1JMpZ5JMcigmkBfUuapKFG1rGEqTWMdm+QyTv9iMYasnuZjGsV20CRpG2JYnAT0TKH5mAEzd4gkZEyWc8KWd8qPsM8YmCDfGybmGkWzdEk4wfCuDtlJNcKim+FiHuFjHCaQmaHsGUBfYeMriWNuSVN2lQj71slFd4klz9PqXCJiGsJ62AZc38es0rG35snqZkiHVglW7hANn8Rk7aIVTOFbbyCfbCEuzNDaCBP0jFPMrJBoXyJaHgTv2sZl76GQzONeyBLoEsiYZ0n4V5GCG8SDW4Q8Kzgtc7jtcwRnCjj7sgQnZwipKsSs80TNM0T9q4QdC8RdCwSM1aJjxZxdSsERiuEtTUC2ip+bZWIZ4Wkf42Cf4W0aQ6XSsamyhAYKuPokzGpBILaGZTIBgvyWURDDUdbBntLGkdbmsBgAf9QEd9gkXx4g42piyQ0UzjbRBwtqXo7RmuKQG+W0GCJcnCdFeUM0aECnvYMzrY0zhYRV1v9BHsUFHONvL1KoFvB3Z7C2ZLC2STgbRPxtIkE1BmigzniAwqBbglPSwpXi4BfncbZGEdzwEWkRyLWIxPtkfF1CLhbBYLqNO6mJIEOkXC3TGwgR3wwR6RXwtOSINyZwdOUINxVl1dhtEh6rEBqpEC0VyGoShFoFwmp0njbBBKDOUq2GopxisRgjsRAlkivhLc5gbc1SaxPRtGWqAVXUPTTRHskkiM5wp0ZbIeCeJpixHqzzIVWCAwkEEbypEYKpCbyhNRpzAcDOI6GEEfzVAPL1PzLTDnmmY+ts5k7QzWwRHo0T940w5Rnvr6NMLPF1uxpnn7qaX7zq9+wWT3FdmWHu1fv55FLj7NQXObZHzzPr37+6/cMCl6/fp0rV9673vv1119/N6njT+X6jwcPn332WZ566imuX7/Ov/3bv/0//Pbe5Y+50d60yy579uzZFej/DNx222186lOf+rOztbX17p1gMMixY8f4wx/+8L6fI0kSkiR9oED/7Gc/4wc/+MF/3AP9uzc4P3sXBVuNkZvNdHx0lIa/6mXw7w3Yj4bZLp/nhw/9iId2HmMjdxbTQT/DN5tp+ts+ej49ydgtVsqOOU4qZ7l3+0Eur95HpE9Cc6uTwS+b6PzkBAOf0+FrTbIY32A2uMrl1XvrbRf7/Jj21l+euz6lZeKrDvLmGmXHXD2JQJvGdiSC/UQUT0eagS+aGPyimVhflpx+GnG0wExgCb+qnnsbHy1iPBym/4tW/Ko0qbEC6fEiiZEC4QGZ5ESF5OQU/u4sw1914+1USGumyGhnCKpFnC0JUtop0roZkpMVJg5EcHcrKNY5spY5/GoJ/f4QSU2ZjLFGxjyHuU3CN1gm61lFdiwyftDL+O0+YsMlMqZZRPMsrqESXk2NXGgTJbCBuztXT+HoypI2TCNb5whoZoi5VyiIZ1Gi27iHK1hUWWwdGRKjRRJjZcL6WRKRk+Tk88jCGbyGWWxDZWxqhfBQsZ4pPFgkEdygULyEIu8QdC3jNs7iGC3h667/vO8byBN1LJEWtsmXLmKzTGM1zuCx1AgNF3A0CgQG84QMNSLOBTLiKZKJLcKBFUK+JRLGGWwnknj6snhGywT1VaLOBZLRTRLRk0RDayiBVfy9WRztGdy9OTwjJQL6KjH7EmJ4g0zyJNOZbSITFWxtGcwtIs6eHP7hMhFtlbh9nqJ0lrXKBQRdFXt7BktLGnOjiFOdxdmtYO5KsVy5yPb8VaLjZVwdErbWNLamFPYWEadaIjBYYDFzluXcGfy9OeytIvYWEXubiK2p/sLs68wyFVil4J7H0ynjak/jaBFxtKZwt4t4OtKE+/MU7PNk9FN4OyVcbSlcLSKuVgFvexq/WkKYKFOwzZLWTRHsy+JsE3G3pPCqRdzNSYKdGWztYfLWWWTdFLGBHN63U1Y8TUkC6gziRIWqf4WifRZxoky0TyHYJdXbNVQi0V6FonueWnCFrHGG1HCBcFcGd1Mcd0MMb7OAYphhPrJK1bdIVj9NZqJEoEPEdSKCeX89QaPqW2IhukHZMU/BNE3eMoO/LVH/tehwgMRwDsVQRjFO4e+Lk9EXSY5mMR3wMX6rGeN+N572KG5VFOtxP7ExEdGaJzSUwNbkwXjEhf6gE0dbAG9XBMlZYDG/wuWLd/Polce5sno/tdgyy/Im52fv5pFLjzMjzvHTJ57jpedffs+g4DtJGn8sx38cVfd+Av3II4/wxBNP8Mwzz+wK9A3mRnvTLrvs2bNnV6D/EqhWq9x8881cu3bt/3hvdnaWYDD4gQL94osvvu+w4e9//3sevfJ9CrYqE7fYaf/QEE3/vZe+z+pwHItSCyzzvft+wHM/eoHTU3dhPehn8ut2Wv92iM6PjTPyJQs5wzRTznmee/JnPHT+UXwtAqZ9Xsa+bEb1sTG6PzVBsF1EmiizLGzy0x8+izhaxHkijqclQf8XTHR+fALzgSDJ4RyZ8QIPXnoUf3+MSI9CbEDBuC9I92f16G/zkRjOkRorMeNdZjayTmIoR2KkgE+VZvArdnR3+hHGSmTezsHN6MukxsukxorEhotM7gui2RdE0EzXY+smKzgbkki6KSTdDMJEGVuzgPZwgpRpjox1gZRuBsPBCGlNmbx9Hklfxd2lYGpNo7jXUNxriJYFBm5z4lGnkQ1VZGON0HARW18RKbxJNnKSjGcVS6eCrVUkNVkhOV7G3aXg1lRRkqfJCWdIh0/imZzB2J4m0p8jOV7G1prENVohmz5LTtpBSp0h7FzCMVLE21mP8bM3J/EMlYg6lshld8hmLxANrBN0LhAayhFQS9haUjj78/i1NRK+FfLFC/h8CzhtVRLmWQJdCrbmJK6ePL6RCkFdlUx8i3z+PGLqFPnYScKjJUxNCcytIo7eHJ7hMiHzHPnsDuXKBRaKFxGMc1hbMhhPJDA1C9i7s3iHS6S8KywtXuXc5gMIpjmsbRnMLWlMLQLmZhGHWiY8WWVt/h52Nh8gND6DpU3E2ipibhSxNItYm9O4umRirjLrlbvwDBSwtqaxtqSxtojYWtPYW9L4+3Jsli9SS2zjHyjgUMnY2zLYW0UcbWnc7SLR0RInK5co+deIjFbw9WTr+dWtAs6ODK62DBn9DBuFHYqeZRKaKUIDRdytAs5mAU+bSLBXYTqwynruDDnbHML4FJH+Aj51Bq86g1+VRpgosyCeIqrLkNKUCHXK+NXpettGS5JIb7YeUSduMR9dIzVRwdsq4GlNYj8axtOSQNZNMRdZZzGxyWJinfRkGXdLHNuRCM7jMZwNMSRdmSnvIiXnLBXvHPFBGeMBD9rbXWi+Zcd6PIinM4pbHSUyJpLQSTg6AozfZqH/yzpGv2nGdMyD7pAT0wk3wcEEkbEEblUIw0E3xv1uLIc82I8FsB7x4WuLIRvKlBzTJIeyhDpTxPtlkv1Z4r0KFec8l5bu4dG7H+fKxv1cWrjChbm72Zm5i/XsNpVQlZ3qZa5ufodpYZanHnmG1379+nsGBV9//fV3F6P8R1F17yfQTz/9NA8++CDPPffcrkDfYG60N+2yy549e3YF+j87Ozs7fOITn+CVV175wLunT5/GaDR+oEC//PLLPPzww+9b/9VLr5A1zqC73U3L3w7Q9j8HUH10DPvRMMpkmZ/+4FneeOP3nKlexHEkhOZWO+0fHqXjo6OM3GwhPpClGljm9dd/y2NXv0dInSagSjH4BQPqj47R9zkd4a4M8aEsD51/jKe/9xMSgzmiPRLGgwG6P62h7yYDQXWa1GiBinOBJ77zQyyNvrc3DqYZ+rKVnr834O8QEUYLiONlTlfOkzVOI+unEUYKaO/00fdFS/01cLyMMFEmoylTtM8y7V0ia5rB2ZRi8GsuAr05MoYaon4ad7tIYijHlHeJKd8q0cECY3eGCI1WyFgXkewLONpTeDtSZE0z9c1s2jKTRxJEdTUynjUk7xqB4TKjt7uID2eRdFPEh4voGlMInhVykS1y0S0k3xq6EwnC/VnSk2XiAzl0xxKkPCsoiW2yyTNkoqdwD5XwqNKkJiv4umT0xxL4xqeRY6fIZeoSHXEt4+/PE+7L4VVlMDYLeIeKhExzKOJZivkLyJmzJC0LRMfK2NpEzC0p7J0KnqESCc8yxcJF0tJpou4aonkOZ0cGzaEolmYRR1cW72iFXPoM1eoVVubupRDcwNEpY2gQ0B+NY2wSsKklUu5llubv5fTWg8i+dcztUv1OYxLDsSSmxhThiSmWqpc5t/UgMcsC1g4JU1Mac2MaU5OItUUkOFzm5PxVzqw9QFhXw9FbwNKRwdSSxtwqYm0TCQ4XObtyH0l3hbh+luBYBUdnFmtrGkuriK1VIj42zeWtB1gpXiJpnCU6MU1gsIS9Va7Lc0eGrG2eS2v3U0tskTLNkdBWCQ2X8KglnG0ZAt1ZZuNbnF++St42R2QoT2SoSGSoiL9Lwd2RITFWYUU6zcniDmndNMEeCa9KwqdOE+iWCPTIFByLrBfOsSyewqmKYT8ewduawqdO4zwRIzacZ9q3SC2yTNE9S2wgjWG/B8N+H9p9bvQHvDjbIkTGJKKTEpHRFPbWIGPfsjB0s56x26xo9zmwNPqxNweIT6aJTUh42iKYDnowHfFiOuTF3hjG3Rwh1JNC0pUpOWqEO9P1Hum2FP42Ac+JKM5jEeIDMnnjNOnxIoGOBNYTQSK9GfwtcYx3enEeCSEM54j3K0R6MsQHJCLdGWJ9MrFeGUU3xVJyizXpNMuJjbeTOM5xunyes1OXOF+7zHZpB9lZ5K6lq5yducisvMgrv/j1ezYMPv/887z66qs89NBDfybIjz/+OD//+c/fV6B/8YtfcOXKFV544QWuX7/+f/w1b5f/f7nR3rTLLnv27NkV6P/sfPjDH+Zv/uZvuOmmm7jpppsYGhp637tXr15lcHDwAwX61Vdf5dvf/vb71l9//XdkjVM4jkTo+MgIbR8aQvV3I3ga4uTNVV55+VXefPNNlhIbhFQpxm6x0P6hYVQfGcV0wE98QOHCwt1cu3aNreIO0W4Jz4kYXR+fRP3xCbTfdJIYzKLop/j5cy9xrnoXqdECqbEiY7fUV4OPftVOtE8h3CtzunKRuxav4u6OUrTVcDbF6PqsjvGvOUkMFwj3yiSH86ymt5mPrjMbWUPUlBj4io3JO/wkxytEB3J42kSypmnKjjlmI+uUfctM3hFAdzBIUjtDSjuNs1kg0CVTtNYo2mYp2GexHI9jbhIRrYvIjiXCo2WMR2JkJitkjVVk3RSWhgTungIZ1yqSe62+lbAhiaMlRnxIIaOpoD8cxdWTRfatIwc3yAZP4hur4FWnETUVkqNFDIejWFpTiO4V5Ng2+eRpBP8q4fEKsaEC8ZEi5uMJLC0p/MNl5OhJcqmzKMIZRPcKacscgd4c+sNxDCcSWNvSxMzzZFNnyMk7lNNnKEXqr8aagxG0h+Poj8dx9+UoCNtUCheZLlzAbyrhGSigPZZAeziK5nAcU1OKlHORWuUuVhbvJxffxt5XwNCYQteQRHs0jrlRIK6vMV+6xPbmg+QSp3CPVDCrZIzNIoYmEVNTmujkFJu1uzl98iHk8CZ+TRX3YAmbOoupWcTULBIdn+LM8n2c2XwA0bdOxDhHYGIad38RS7uErS1DVDPD+bX72azdg31UImmeJzxZJTBcxq5WcKgkcq5FdpavMp04RcowR8o8S0xfIzRSqUfVdSlUk1ucmr6EbJ0jNlYmPFgkMlomMjGNr0shOlZms3KRVfkcydEikb4c4e569GCgRyHQpyBZaixIWxRds3jVKWwnwpiPBTEdD2E+HsbUECKmy5I05/H3xTEcdTP8DTPjd9iY2Otg/E475gY/gSGBmCZDaDCF5Zgf8yEvhoNerMdDeNvj+DtTxIey5G1VJE2JUJeIrzlBoDWFtzVJqCODXyW+La4VFMMUkc4M/rb6UGFQLWI/EsJ1LEKsN0PybfENtNeXoUS60rgb49gPh3EdjxJoE/C3JvEcjxLuFgmqBAyHnO9G4oV7JHwtCayHgjiOhol0isT7ZGI9EqmhIvPReh/0jH+Joq3GXGSN0+XznHk7iePM1HnOz13h3PQlFFeBhy8+xs+eeYH77rv/PQL8wgsv8IMf/ICXX375PQOFfxxV99RTT71nqcofnzfffJOdnR1eeumlXYG+wdxob9pllz179uwK9C7/zhNPPEFzc/MHCvTvfvc7rl69+v4tHs++hDiSw7w/QPv/GqbtQ8N0fnyCQIfAfGydN998k1/94hXyxhmSw7n6sOFHRun4yAiuoxGi3Wm+/50f8uorrzIXXKHsmMXZEEH9qUnUHxvHcjiApzlOwVLj+Wde4GRuh7nYGlldheGvWOj5tBbr0TCuxjiexjjnF66wIZ0mbc4y5Z/HuD9A3+cN2E/E8bQKGPf6yTvm6j3VoVVWMqfwdKQZ+qoTV7tIYryI/oAfT2uKWmCZKdcC074lhPEymjsDhAezpPRVPKoM2r0+ys4FyvZ5Ko55wr0KpmNxYhPTiJZ5kvoa2gNh/jd77/Uk13ne6+IfOdt725ZNWcHailu2t0SbokgxIA0mYXLOPal7Oufcq9fqnHPu6ckJgzRIBAEGiQRFUiRFiqJAKlgUg8Agl8v2cy4Gkja3SOtUnQu4SvNUrasXVZibWfPUt97v9xPGkiRUJcLyHKY2ifnDTiRlhYC2Rsi4hL47jLE3iGskhH0whPmkj9nv2PHOFwgalwhbVnDKS1iG4oTVZfyzGfRtIrMP2tG2+/Dr64Ttq0jmBp75InFzg6C6hOKIC9m9NmYfcuKczhFzbxB2rOG3rpFwruJXV5g76mbi21am7rej7QwSsa8SETaJ+7ZJijsIygqzTV6mHnIw/YCThRMSfkOdhG+HfHKPZPg08/0+lF1B5lslph92ozgh4leXyPl3qFeukI6ew62qox9Jo+mPo2jzI2/24Z3JUU+eZa3xKMnoaQTjIubZPIaRFKqeMAttQVwTKZaSZ1kuXyaf2MNnWcaxUMYsy2AYTaHqDuOZSdOInibv3ybu2SBgWcKjruKYK2CZzKLpiRJQlVgMnyKsqRLQVlH2+HAtFPAoytinshgHEuRc65SkDVyjSYSZHO6ZLLaxFK7ZPA5ZFutogpJ/nYi2gLLJhbZdRN8loTrpQdnmRtMtYRoLETRn0Xd7mLxfz/i9FE69eQAAIABJREFUWmYPW5g9Ymb2iBllixP3bAyfOoW5V0B+xMbcAybkD9vQnfRi7vXhGIkQUubI2aqIEzFMrSK6JoGFY3YWDltw9YfxjEYJTCeJqQr4JhKYbydrGFsELG0ipnYRc7uEqyeIbzyBq2//sqC51Yv9pA9zm4jxxP7us61zX3qtHSKWk9J+Qsfty4mWVgFbt4SlVUR72IGhWcDUKmDv8ePq8WPv9CMORZHGYjh6/OiOuNEdc+DqCeDs8e0ncTQZid6u/ba0ezEcd2FudePuD+Hs9O9XgxsrNIJb5M01IvIceXON1d+eOufOsZk8zancebZSZzhXvsRju9/l1Npp3vznN/n5Gz/n6iMfre9+++23uXbtGj/96U+5cePGHwjyL3/5Sx577DGuXr36sQL9L//yL+zs7PDzn//8QKDvMHfamw444NChQwcCfcDvef3117n//vv/qEC///777O3tfeL8B0+8QGQ2g/qwne67puj4yzF6/0aG9qid9fgut269x6sv/ISiY5GwPMvIlxX0fnaa7r+eRH6fCUu7l+/u3eDmy2+wmTxNTVhD8aCVoS/J6f/8NDP/pEd+r4mio8G13Sc4Xb7IdvosrqEQY1/XMPZ1JYoHrci+qcN8UmS3uEfDt0HMlCaykGXmXjMz9xqxdgeY/Iaa2W8bKbtXqHnXKFjr1KR1VIedqI66cI3G0TQJDH9VRWguTdWzQsZUJ7qQQ9/sxdgZQJzJ4JlKM3G3EV2Th5x1kYyxRlCWRnnYiWc8hW++gE9RQtPmY/5hJ8H5LAl9leBMmtlvW3AOx/ArywTUVSyjCRZafYTkRYSpBJo2F1N3m1Aec+NbKBDS1RBVFQyDcYLKEhFNBVNXgIm7jUzdY8Y1niFsXETS1LHNFQmaGkQNi+g7Q0zeZ2XyWxaMXWHC+kWCpgY+8zIxzxYR+yr6/hjzx73MPOxG3eojpK0QtTSIi9vE/DtEXBuYRpJoeiMstAdQtfoJqMokHatkorskIqeJSTvIurzox1Ko+6Nou8K4J5JknKuUk3tkk3vEg6dwa+pY5groxlIYhpI4RuMkjItkAtukwrskQruI5iXsqjLmmTyWqSzu8RQJQ5WQoYFfXyfq3SJgXUXQ1bErSthm8gQWioRVRYTZLJ6ZAj5dDa+mitdQxyUvYZ/NEdZX8M6mWGh2o+nxox8MoOz2ourzoxuLoh8P41HG0fa4Gb1Hi+xhM7PHbMy1OpGf9KDplXAvpIiYs+h7RGYeMDPzHTPqFg+GLj+2oQiemRTlwCYl7yqOwSi6VhF9q4i2yYulN4gwmiAwnyVrXiRnreEY3E93MTTvZyMbT3ix9YbxjCb2d/BlaZz9IUxtIvrjbiztErpmF9P36XB0BxCGI/tpHR0+dE1urB2+/YbOFi/2rgCu3iCOngD2Hj/6Ex6snT6MzeJtiZYQhmP4J5IIw1GsnT7MbbeTOLr8mNq8uAZCxJUFIvNpXH1BbF0S7r4Q1vb9WDx3f5DQdJqCbZHQdGr/RHowhHD7Z3L0hRCGIpSdS9jHBMSRKK7+EOJYFHEshq1TwtUbImOs0JDWKdkXicpzZPRl1mM7rIQ3KTka1IRVVqM7nCrssZ06w5W1R3ntxZ/w7ju/5uqFR7m8/ShPXvgep5ZO889v/H6F47cXBW/evMlzzz33B3L84Ycfsre3x/Xr1z9RoE+fPs3Nmzf58MMP7/Tr+k+aO+1NBxxw6NChA4E+4Pe89957fP3rX/+jAv3BBx/8pwL93BMvUBdWkT9gYegLs7T/+Qi9n5li/l4jS4FNfvzCT3j9lTfYzZ3HP51i9KsqBj4/Q/ddU0z9gxpHp49LK1d59voPuLr1OHVpldl7jIz/g4bhLysY+ZqC2XsM1MU1dot7XFp5lPP1SxiaPczeY0TxgI2RrygY/fIC/qkkK5EdGv4Nit4qlm4vCw/aMZ30oTnqovezM2iOOfdPnqU1yq4GofksxjYJ13Acx0CEsb/TMvENLaHZDHnLIhljFe9wFOdQBO9ECu9EEsURJ+Pf0OEdSRCazRNVFlAfdmDu9CFMpRBnctiH48i+bcU9kSIwm0OaSDPzLRPKhx2IM1l88gLCTB75CS8eWZaQuoJrLMbA/1Iyfa8FYSxFUFHCJy/uN+QtVIiaFhFn8iiOuJl/yIljOEZYWSKoKmOfyRMwLxO3ryHKS2g6gyw0i9gGY8Q0FcLqMoKyQtC5RlzYwmdoYBhOoO0JY+yPEtWUiahLBE1LJAI7JAK7+B1rWKYLGMdSmEYSBOZzeKfSRKzLpKOnSYRPExW3mBn0Y5wpYJvOIc2kcY/GCWir+C3LJEOnSYR28ZiWcKqr2BUlpJk87uEY3tk8wkIJSd8g6tvCa13Cpq5gUxbwytPoO72ouyRUPX40QyEMkwmsqhy62Ti6mTi2+RCKZgvj3zYwddjKXLMTebeAajiIYT6FS5cl5iyh75KYut/C9MM2VO0i+v4Q+oEg9rkktcxZltO72AdjqJu8aE540LZI2AaiuCcyBFVlNvKXaAS3sfWGULeIaJu96G4XpNgHo4iyNEXPKnFdBXNXAF2LiK7Zi7bJi75FxNgi4R6KEVEWCMtzmDv96Jq96E6I6E4I6E4ImE9KCMNR/JMpgjMZ7H1BdM0C2iYBc7uEsVXE2u1H22YnMJtFmkri7I9gahH35bnZg/mkhF+WIqOr4J9NI41FcQ9HcfaGMDR7sHZIuPqCpLQVcqYq0mgM70gcaTKJsy94O8vZS0SRo+xaJmOo4BuPE5Qlbu/cRzC1CAQm45QcDcqeVWKKHH5ZkoSuiG88jqXVg73LR1Jboi6ukdKUMHY7Cc2nSepKuG+vcLj6AiRVBbKmCtH5DElNhUZwk4a0TsZYJTAZJybPUbAuUnWvsFe/wqvPv8abv/wVN3/0Ot/de5p6YJXl1AYXVx9hd/Usr3z/VW69e+t3Anz58mVefvllXnjhhY8V5HPnzvHEE098okCfPXuWH/7wh/zmN7+506/rP2nutDcdcMChQ4cOBPqA3/Pv//7vfOELX/j/LdA3X/kpu/nzyO8zMvwVOa1/Nkz/52eY+aaOhrjOtd0neevNt/jepWf2I+r+0cDA307T8+kJRr6iQByJsRbZ5olzT/HjF29StNVRfNuM/D4jA5+fpfez0yjus1ByLFETVnnusR9wvnYZ3QknhhNeVA/b6fr0FCNfUhCeS5M316i6l1nJbGFs8/wuymv0a0p6Pz+DvUMiPJshIs9S864iTiTwDsdwDsZQHnEx8EUFhhYv3tE4flka10AYV38Y73gKYTSOrSfI8N/r0LeJSFMZJFkaU4eI9pibsCKPNJXGPZZk+l4r2pN+AooCwfkcps4AC4edxNT7sXaSLIOy1YdpKE5QUyOoLmPuCzH8TTVBRZ68fZmwooChJ4RjKk/YtETE2MAxnkbd4cc9lqTgXiJuqGAZSuJRVYk4Vok4VxEWKpgGE1gGYsT0FcLKEs6pDEHbKjFxi5i4hc+8hHkqi2UiTXghj38mg300hs+yTEzaJibtEHJu4FJVsM8XEKdTeMfiWIfiuOaLBG1LRLxbBIR1lJMRTPIMLlkcQ7sHTaeEuieAdiSMaS6Fw1TGoMqgmY1jmggyf8zE5HcMyA5bmW5xMdctYpAnsOjyOIwFQvYi2i6RyfutzB1zomyXMAxGsM2kiQrrVPLn2axewj6eRHFMQNkkoOsIYR6I4ZrOETI0OLV2ne36JawDUZQnRBaOe1Ee86Dr2K/ato/FSYh1FiOnMPVEUDWLKE8IKI97UJ3w7KdsjMRZSZ4h41jB3BtB0yqhOSHuV203e9G1iDiHopSFNVKmRVyjCUydfrTHvWiahP1ylFYJaSpFxbtGUldBGE/hGIhiaBXRtngxtIg4+sKkDTWKnlViqhK+6TSuwSjGVhFDmxdzuw9pMkne2sA0JBBR5vFPp/AMJ3D0hdCfcOPqD5PUlym7VsgZ60QVBQKyNP6JBLYuH44uPxF5nqKjQc5co2itE1ko4J9M4ugO4O4LIY5EKVjr+/vHqiIF2yJJXQlXbwh7dwBDs5fwXIaCYz8qL6kuUveukTfXcPUGMJxw4+oPEZXnCEynCc+lKVhqxPVZwsokzp4A1nZh/xR6NIKj24d3OELdv85SaIOktow4EsE7GEEajRJX5CnaFrm69RivPPdjXn/1p1w79QRnyhfZze+xGt0m6y5xYfUym6UdXvn+j3n3rXd/J8BPPfUUN27c+Egr4f/5XL16lccee+wTBfr8+fM8/fTTBwJ9h7nT3nTAAYcOHToQ6AN+z3/8x3/whS98gffff/+PCvSFCxd47733PjEL+sraNZQPWBj5opy2/z5E72dlyL6hJWetc7q0x/vvv89rL93E2R1A9R0rA5+dpuNTYwz87TT+8QQJVYGnLt7g7bffIaEqYO0QUT1ko+Ovxun81AS6ow5C02mS6iKvv/pT6sIq9u79prSR2/nTsrt1eAYjeIejbKbPkDQX0Lc5cfaF99dLPiNj8u81uAbDSCNxQjNpcpY6wZkMAVkGa5ef4a8omLpbj3sktt9AOJFAHEuQNddI6cv4JpLI7rUy8U9mxMkUvqkM4ngSa4efgm2JomOZpK6M8rjA7ANOpOkcvrk8gfk8hnYfCW2FRf8mZfcapq4AimYRn6pCQF0loKli6g0ze9RK0bZEyb2CZyKJtj9KyLxEyLxExLyMbXI/Li2lq5AxV3GOxLFOZvfl2b7/iLpFrEMJ/HM5ouoC1r4wxuEEIdsyAfsaQdsKPmsD81Qac58fx0gAdbMbeZuAdjiERZnFqs5hVGVRz8ZQdDmRt9iYecjExMMWZM125P1eTKosFm0ekyqNW5nA1Otj9oiNuWMulO0S2oEQHl2JqH+LXPIMK4U9RHkBxTGBhWNeNCeDmAYSOKZzpMQtGpUrnFq+jme2wPxRgfnDbhTHBfSdAcyDUbwLZTbqj3J65RrW0RQLJ7zIjwrIjwgojwvoTwZwTWQ4VbvKRuEi9rEUmg4/C00CC8cF5McElMcErH0xVrKnEfUZPFM5zEMJ1G0+VE1e1E0C6iYBz3Cc3dpFyv5NvLM5HCNxLL1h1Ce8qE940bf4CMznOFO7TEFYJzBfwDOZxjYQQd/mQ98qYekKkDItsl3YI2tbIqQo4pvJ4ByJYWiXMLSL+CbSVIR1lqOnSJkWiatLiLI0npEEtq4g9r4ASV2ZqrhOzb+OdciLdzyCMBpDnErh7A0RnMmQtzco2BcpuZZJGSoIg1FcA2GsJ314R2JkTTUylhoZY5Wqe4msoYqzL4C53Yd7KIx/Mk5SV9oXZ+siNe8aCVURa5cPZ28Q71CUkCyNZyBEeC5NxblEVVghOJXGOxTGdlLEMxz5XcOgNB5lUVwhb6riGvShPmLB2RPE2OxBe9SBsc1DeD5NXJEjqS3uf+XpCeLuDyIMhPFPJ1gJbnJ54xqP7jzB+fplThcvsJU+w27+HKeLF9hMnCaoiXK6fp7Nwg6vfP9V3n/v/d8J8Msvv8y1a9d49dVXP1aQv/vd7/6uUOWTBPrq1asHAn2HudPedMABhw4dOhDoAz7K/1eBvnLlCu+8884nzi+uXcPU4mX4q/O0/tkwHX8+yvQ3NQgjES6tXOWDDz7g2evP4+wNoD/upOtT45z881H6PzONsydIYDzJT354k1eefxVhKIqjK8DU32k4+ZejdN81ibl1fydzObDJj198jfBcFr8sibndS/ffTNNx1xSGJjfuoQi+qSSPn3uaqCqNZyJEaCbD2Nc1dH9mGm2zB89QBGE4Sk1cYyW0RUVYJWuqoWtx0/c/5ehbRYSxONJEksB0hqXAJqvRU9TEdbzjSUb+TouxO4Q4lcE/k8M5GCOuLrIc2mE5vEVcXWLqWzbso0n88iKBhTLO4TjuoRgV1zIl5zJZ2yILTSKe6Sx+VY2AuoYoL2LoDGDocZIx14jIs2jafQiKAqKmjKQu4VEW0XUHsQ8EEWUxLL0SsodtaEdCWGaSGKbjGKYTLAz6mW+yYehxs9BiY/TbeqaP2VGPBjHMJDHPZ7AuZLBORnCNhdH3SMw+bEfRLKAfiuA11gm6Von7N8mKm4S1VQwdfpTHvKjb/Bj7onjlZZK+HfKJs8S9DdyzaVStEtP321lo8qI56cPYHyVmX6OS3mO9/ihBXQ1Vq5/ZB93MPuhCfkxA3SLhlRdZLlxmZ/k6fm0VTUeIhVaJuYfdzD7oZOGogH0owUb5CrvL15HUVSwjKfQ9QZTNEnOH3SwcE7APxdmtX2Zn8VGC6houWQ7TQBxdZ4iFJi+q417cE2n2Nq6zXr6MdtCHMJvHOpLE3B9F3SqhbhIJy4vsrV9nKXWeiL6GT1HCI8tgG4yhbQ9g6gqRc6xwqnKBanCHhKFOUFlCmM7gGotj6gwiTCSpR3ZYiZ0hZ1sioiwTnM8SmM/hHk/iHI4R11ZohLepetaILuQJzGTxjETxjMTxz2YIzOXJ2ZYoedYoWhuE5rKommxYekTEsQTCaJyMsUbW2qBgXaJoX8I3GcPeKeG9vZ4RUWQJylIktfsnyjljFWk8hqVdxNIh4p9I4h2N4+oLIY3GKDkapHVVvEMRzK0C9i4/rp4A1pMSpmYPvsk4OXOV+EIW20kJV68fR7cPY5MLzREnlg4J/3iM0Fwa72AYd18Q60mB+Yd0GE640Rxx4Lkt7I4eP7aTEp6+EN6hMI7eAOJwlIJ9kZXwNg3fBnlLjbJzic30GbayZ9lM7LKdPcup3DlO588T1MZZDK9yduU87779648I8C9+8QsuXLjAT37yk48V5GefffYTUzh+W8by28KVA+4cd9qbDjjg0KFDBwJ9wEf54he/yLvvvvtHBfr69eu8+eabnzhvSOuYWjz0f3aatj8bpu2/DSO/V4+7P8DzT/yADz74gN3iBbzDEbTHHHT8xQTt/2OEqb9T4+wNkDNWePfdX/PI5vV9kZhNMvJlBR1/Ps7wV+TYu324B6I8/cj3uXHlWcruZQqWRfTHXPT8jYyRLyuwdfmw9wTIWxs8/+QL1H2rBJT7axjDX1Uy8jUVzr4gjv4gjt4gFxqPsFs4z2b6DAVrnel7TLdPn+O4h6PoW71kzYusRbbZSJ1hKbSDqklg/iEHnsk04lQG40kfjsEwdWmdmneNRWkdc1cA9QkB91QKtyyNeTDE7EM2gvIUoYU03ukoc4dtKNoE9IN+tP0BVH0So/cbUJ20YxxwYRrwMHGvhumjFrSDfgzDEYwTCRY6JXSdXoILGXxzCRTHnMwfcWIdiyOqK/gNi3g0VXxzBSLqCkFFEdXx/dNZY2eIoL5GzLFG2LVO3LJK3FjHPhBj7kE7iqMCyiYvjok0MdsqCWGTQvAUSesqpr4oM/fbkd1nY+YhO7qTPkLGOoXALovpc0j6KvMn3ChbJGYPu5DdZ0Vx1IV3Lk81cY7V6iMknOtYJ9LoeyMo233MPexGftSDczLJcmaPjfpV0uIWnvkSpuEkur4IyhYJ+VEB51iKrfJltuqPkvFv41VWsE9mMQ/H0HWHUZwQ8coy7K09xlrpEhlpm4C+jnumgH08jXkwjqrVR0Rd4fzyVWqxM5QCp1EP+ZCUJdzTeewjKUw9YUrSBpv5c6Qsy6TsK8RMi4S0VaT5Au7xNB5ZiqX4aWrSBgF5jqC8QHChSFBRJKgsIs5kSRjqrCROkzLW9mu1RxL7xTzTOULyEklDnaJrlZq0TlJTxt4XwtrlRxiN4Z/OEFbkSRtqFFwrlN2rJDQF7D0B9E1utCecWPsl/FNpfFMpEpoCeUuDqLyArcOHpVXE3Cbh7AsjjkVx9ASQbldm+8b35drc7sXa7sV60oelQ8LZHSA4mSIkS+Ed2b8EaG0XsZ4UsbZLGJvdeIZCBOdSuAdCOPuCmFsEHN1+7D1+bB0Szr4A0mgMcTSKucWN/rgTV28QZ48Pe5ePheNGQjMZgrI0tm4fmoes6I85cfYGcPX4kUajZHRlViPblF1LxFV5ovIsZfcS2+kzbGfPsRHf/V0Sx5nSHmfLl1jJb/Dolcc+dk3j/4yi+zhBfvHFFzl79uwnCvSFCxd45JFHuHXr1p1+Vf9Jc6e96YADDh06dCDQB3yUu+++m5s3b/5RgX7yySf52c9+9rGzt996h4KljjQRY/Bvp+n61Djtfz6C5ogN/2SSn938BbduvcdmcpeCfRH1g1Z6PzNNx6fGUdxnxtzuZff2mscjW4+xHNoiNJti9KsK+j8zjfxeM6ZWAe9whFd/8GOevf48pwrnqQkrzHzLyPCX5ll4yIq+yY36IQfr8VM8dekGZ6sXiRrSmNq8TP69Bu1xN8Z2kfn7zXhH4uwtXWEnfYbztYv4ZElk9xjRtQhY+vzIvm1g5j4TaWuZtL1M3JDDNuhj4ls6FpodLLS6mH7QSO+XZzD1uxEVYTwyP6pmC7IHjSjb3Wi6BDRdXka/oUHd4iSuz5E0lbD0+Vk46sA1HscjSyHNFTF0h9C3SyS0FYTpMNaeAPIHHdgHIwSUZULaOp6ZHLahBCFlgfBCEX2Ll9n7baiOeRDn84T0dfzqKt7ZPHHTIv75HIoHnczcZ2X2fhvW/ghh/SIhQ4OwdYWEfQ1xPs/CcYG5B13M3GdDdcJLSFMh7lgjI26RcG8gqSoYusOoWiQURz0sHHUhzeXJetYpxc6QDuzgUZaZaRUw9EVRtvlQtXjxTqQpBXZYLl4mFzpD2LaKTZbDNJpC2xNB17EfUbeaOsNy4RLZwGmSwhYeRRnHVAHTcBJTfwRhKs1m4QKLibMUw7ukpW38uhoeeQnHVBbz7Wi/9fRZMq41Uq41cv5totYVRGUF91wez0yesneNin+LwHyRoKpMzNTAMh0loKviU5YJ6WqsZc6SMtSx94XwTKQIzBeJaKqk7MskrUsUvJusJHYJLxQxtknY+yIIEylCCwXi2jIFzzqNyC41/zqBmRSmVhFjq4RrMIp3IkVkoUhMW6Pq2yBvXUScSGBsE9E2eTC3SbgHovimUoTmsyQ0JdL6CsJoDFOzgK7Jg6lFwNjmRdVkRxpNEJ3LkdAWcfYFMTa5sbZ7MbQI6E94cHQH8E+kiC7kCE0nMZ8UsXb6MLUKmFpFLLeTNAKT++tMzt4A1k4RW4eE5aSEuc2LszdIRJ4lLM/i6AlgbPZg65KwtXuxtInYu30EZGly5jrh+cx+DF77vljbOv04egJ4h6IUrXWcExK+yTjWThFrlx9xLIqz1497IERKW6Lh36DmXSUoSxGRpam4V1iLbbMR32UrfYat1BlO5c+zmTrD2cpFnr78LG/+7Fd8/8b3eeTyVX70yo/+0yi6TxLo06dP85vf/OYTBfrGjRu88cYbd/pV/SfNnfamAw44dOjQgUAf8FGOHj3Ks88++0cF+saNG58o2r/651+xlTxNeDbNyJfm6f+cjO67xlE9aCE0m+Gdt9/h1q9vcXXzcZZDW8x+y8DIl+bp+6yMuX/So37Iwbn6ZX71z2/xwpMvcW7xMs7eABNfVzH2v5TM/JOO6bsN+CcSPHHuKV586oc8euoxEvoiU9/UMPkNDYoHzIx8Vc7MvXoK7hqN2CormTVccxLj31AxdreC6Qd09H5BRvfnJzH3uQlo44QMMYKGJDPfMTD3oAHlCQfT3zHQ9ZkpdK0uEoYCBc8iaXMZe58fa18Ax2AE+1CM8X80oHjQRs5UZ1HaIGdvoD3uQhhL4J1IIcqyaNsk5h6w45clyRprROR55r9lwdThQ5rOIs3lsA3HUDUJBOeyBOdyKI/ZGf+GBuXDDrwTGfzyIsJUDmN/nICySGihgLkzyOx9Vua/bcE5FCOkLBNQlnHP5QjoaoS1NWwDUZTH3MgfcmDpDRNSFAmqq/i1NaL2FaLWFVyTafQdAZQtIubeMBFVibCmRsqzTtKzRcK9iUdewjwcR9cdwtIfJaqukLYuUQjvkhJ3SIrb+LQ1ZjskrKMprKMJwqoSRc8q5dhZsr5TpHzbxFzreJRlnDN5HLIcYXWJgmuFjHedtLhJJnCKlLSN37CIsFBGlJdJmJfIOpbwL5QIamok3Bvkg7vEXRv49Q2CpkXqoR2iqiKukQTuqSzSQomYY4V8YIeka51iYIet0gUkWQp9qw/HSAzPZJqAsoxrPkXKvcp64QIb2bMI4wnUx91YuoI4h2IIE2mCqjIF7wab+UtUxQ1cg1F0TQKqY24s3UFcQ3G8sjRJwyKr0V2Shiq27iDaJg+a427UxzxYe4IIo3EiigIl+zJZYx17dwD9CQFdkxvtCTf6Y26cfSGiiiI5Q52soYxrIIyhyYO+yYOxyY2hRcDY6sXQ6SSuLBCey+IaiKBr9mBpEzG2eDC1eJEmk8SVBXyTcVwDIZy9QZy9fownBCxtXtx9IeKqAhlTDe/I/uqEdzSGqy+E9aSEtc1LaDZNxbNM2lDG2R/CMxTCP5XCOxzD0ioijccp2hapi2tE5jK4+nyEZlOE5RmEwTDiSJi0oULdu0bGUEHf4UQcDZNQFwhNp/BNJIgpciyKa5ScS0TnM4Rn0pQcDVYjWyz61qi6l6l7V9lI7HKqcJ7d4h5PX3qGn772M95+6x1ee+kmV3YepZFf5onL3/tIAsf/HUX3cYL8/PPPc+HCBd55550/mP3mN7/h4sWL3Lx580Cg7zB32psOOODQoUMHAn3AR+np6eHq1at/VKCfe+45fvSjH33s7N13fs0Tp7+HbyLK+FcV9H1eRt/fyJj+BzXR+SwvPf0y7777Li8+/UMW/atMfUPN8Ffl9HxmioEvzTL9T2pK3jq7S2d5/NoTNFIrTN6jYuirs/R+eYr2vx6m87PjmHpdBPUJiuEqm0tbaFssjP+jktnv7Itxx6fHUR23kTIVqYgNLp+6inXIg7FFwNzhu32RcIa5e03kTDUavnVWIzuUbA2cAxGcA0EcfSEmv6ll5CsqpPEEeVOdor2BqzeIezCCZyhrjUTJAAAgAElEQVSGeyiO6riHka+rcQ+GCcrSxJQFlIedWLv8BGezCMMJLD0hpu4x4RqO4ZMlEccSKB6woTnqIqYuEJzL4h5LMHfEjXs8SWA+jyRLM3OfkZn7TISVeZKGOt7pNNrOAN65AmFNlaCiiKEjgOq4Zz8+zb2CfzaLYzxFQLtIzLxMSFvDNpJA1x7AM5agKq4R11aRFkqEbavEbGvEbGu4pnPYRpO4JzLU/BtkbYvELA1i7nXirv3Hr2/gnM4izOTJOxokjVUSlmUSnk0SwhZJ7zYx5zryXglJXSFtXiSpqxBSVQho6ySELdLiNklpm5BtlZB5iZK4SmShgGcihWc6g6QskxA2yQV2SftOUQqfYSO3hzCRwNQVwjocwyPL4VNWyUrbFMOnWSld4lTjCo7BKJpmD+beEPaRBB5ZlqCmSj6wy07jGluFC1h7gyiOelA3CZi69/+dNJ3Fu5Chkd6h5tvCeNKP8rAH5REX2mYBS3cIz3iSmLbC6dolyu5VbH0R1McFlEddKI+40bWK2PpChBeKrMZOU3Qt4RmLoz8poTkuoDriRHvMg7FZJLpQoCKskjbW8I4ksfYG0R4X0Dd50B33YO8OEVcXSev2d6XFiQSu/jDGFgHDCQ+WkxLiaJK8eRFthwP/dBJpKoV7IIK9O4DxhICrN0jaUKHgXCKqyBOYyRCczuCXJbGdlLCe9BOR5yg6GqQ0RWILecLyPElNCd9EAmE4gjgao2Cvk7PVCc/mSKjzpPVlogs5IvIs3tE4GVOFkmuZuKpAaCZD2d6g6lkmtlBEGouTVOWoi6tkjVUCkwniCzli2jQpU57wbIagLEl8oUBCuZ8C4p9IULQtshLZpOpeJiLPEpClSKiL5Ex1lv2bfPfCDX7xxj/z1ptv8cLTL3N59Sqni3s8snmdtFTgqWs3+PELfyjK586d+8QUjmeeeYbHH3/8YwX7vffe48qVK3z44Yf867/+651+Vf9Jc6e96YADDh06dCDQB3wUmUzGzs7Ox5an3Lp1i7fffptf/vKX3Lhxg6eeeorXXnuNV155hZdeeonnn3+eZ555hqeeeoq9MxdZOKKn739OcuLPBmj5iwE67xpF32knZktzZvcsly5ewqeIMPYP8wx/bYaTfzFM96cnmL/fQNZWYiW5xas/+jF764+gO+HC2Cww+rUFuv96gql/UJE1VKh5V7m28wQ/+O6LuPuD2Lv9aI446f70FL2fleEdi5Ez1Slal3hk8zEUR404e4NYOyUm/k5Nz13T6Jv3a7WjihwpXZHgTJLATAZhOIL6sIOez+1nRXuGIkjjMew9AYSxOFlTjYiigL03xOjX1KiOuPCMxhDHk9h6AlhOSpQ9K+RsiwTns0x9y4quzYdvJoNPlsY9HEN/QiDvWKYmrZMyVFg45sbcHyGgLOGby+OVZZEfteOairAS3aYsrGLuCuCcyhDS1QmqqwQWSlgGovjncqwmdlkK7+AcSyEqy4T1i4QNDSKmZbyzecTZLHX/FjVxDd9cnpCxQcSySsS+RtS+il9fQ1IUKdiWyFoXEWcyBHUNYq51Ys514s4NYs51otZl0rZFMqY6nsk0HlkWv65Owr1F3LNNxn8KizzOYmSH8EIex0AMy2AMtyxHyNggJW6RCZxiMXeRneolxIkkmjYRQ3cI61AC90yWuGOVbPAUq6VLnF29hmMgiuIhF5pWCUNnGNtwEu98kYy4xenl65yqXMbYFUJ+2In8YTe6Nglrbxj3RIqwvsaV099jPXsOa38MTYsX+WEXiodd6NokLP0hAvICq/kzxM1FPGNJLD1hlMe9KA67UB51oWvzIckynKtfoeLbQpSlsfdHMLZLKI+6UR13oT0hEJjNsZ44Q97ewC/L4hqOY+kJ7cfYNXmwdAZIqEs0QlskjXVC8jziZArXQARDqxfDCQ/SRJKCbYmKd5W0vkJMXcInS+McimJqE3H1hUmoS+RtDQrWBtYRkbi6iH9mX44dXQHC8ixFe4OkvkLWVKXiWiatLpFUF/FNpAjJMuQsddKGCjFFnqJjiert/88vS5FQlfbj7WyLhOcyJNR5qp5Vqu5lArIUsYUcUXmOrL5KTJknOJ0mo6/QCGyQ1JUIypL4RmNE5rNIYxE8AxHCc2kWxTWq7hWCM3G0TTbcfcHbVeBerO0SCVWBhm+DqrBCZC6Dpz+IuzdEUJYkrSmxHtvlxuXv88aPf8aLT/2QS8tX2cmdZSe3x27+PFfWrhF3pfnelaf50bM/5sMPP/yDi4Af10T425i75557jueff/4PZu+88w7Xrl07EOj/AtxpbzrggEOHDh0I9J8yr7zyCna7HZVKxcTEBN3d3dx111187nOf46677uKhhx763a3zvb09Ll26xNWrV7l+/TqXL1/m4sWLfP/73+f555/npZde4pVXXuG1117j9ddf54fPv4yzN4DiPiOdnxqj59OTDH9x7vYfx03e/MWv+PWvf01KU8TS6mXyf6to+x8jdH16AkunRFJTZDt9llu3blEVlrF3+DA2eej66wna/3yU2XsMBGUpgtNpnrn+LBuJXcTRKNJInOm7NbT9xQijX13A0e3HMxQiZ6lyKn8OQ7eT+EIeW6ePns9MM/IVBfYeH+7hMMJwjLq4xqJ3jaJjiaiqwOjX1Yx+TYm9N4RnKIZnJEpEnmU1tkXDv0nBvsjCww4mvmFAGIkjjMfxju+nIayEt9nKnGXRt4mlN8T0t22I0xmkqSz+2f3T5qy1wdnaJbaz5/DNpFE1e5Hmi/tpHYoS0lweYSpOwpZjp7BHVFvCMhgloKoS0FT2BVpVwScvUJc2WPRvEl0oIcxkCRsa+4+xQdC4REhTo+BY2t8rnS/gGk8TMtSJWJaJWleJO9dIujbI2peoCGt4p9KYeyO4JjNETA0SjjUS7i3yoVPUgjsk9RVsfRH0HQEsAxE80zli9jXini0qsbP4DVlEWQrVcQFdi4S+I4hlIIZfUyMjbbOYucB29TLuyRTyh53IDzvRNEuYukM4xpKknOvsLD7KqcWruMaSaFpEFIfdKA670bZKmHsj+BVFzq8/xunGowhTWSw9EbRtIvKHXSgOu9C2+nCNJdlbf5yd6hV88wUcwwlM3UE0J7zIH3aiPOrCPRrn3PJV6rEdDAM+3BNprP1hTCeDKI+6UTd5CcnznCpfYil+moi6jCjL4hrZ/7KgbtovLUmb62zmzrEY2SFuqBOUF/GO/T7n2TOWoOBcZim0Td23Sc66RERVxD+bwTMSxzkYJq6tUHSuUHStUHKvUvGsktRVCc5lCcxmiMznyVsaZEyLFO1LlBxLOEb9BOfSpPQVkpoSGWONpKFCWlei6l4mrS8Tns2QUBeIKfKUnctkDRXCcznS+jJlxxIJVQHvcGT/xFhTIKLIEZxJEZpOU3Y2KDuXCM2kMbeJ+EbiBKaS+82HJyViyiI1cZWitYYwEMbdG8DR5cMzGMbUIuDo9RNV5Fj0bRCdy+IdjmLuEJh/WI+51YOt00dwKklSXSKmzBOSpXH3hXD3h3D1BvEMBMmaalxcfoTL69c4v3iZ3eIeO7lzbGXOsJU5w3b2LNups5yvXCLuynB19zo3f/j6xyZpfFJU3RNPPMHNmzc/to3wV7/6FY8//jgffvgh//Zv/3anX99/0txpbzrggEOHDh0I9J8yb7zxBktLS5w5c4Zr167x7LPPotPpEEWRt99++z9d4bh58yY3btz4xPnz330JR5eE/F4Drf/PEO3/fZihv51FGA5TsDe4desWr734E/yTSTyDYQa/MEfrnw3R+akxjK1enH1Brp95kp/f/AVZQ5WEuoCxRaDzr/YFWvOQA1dvgIgix09efp218DZl5/6n3tGvL9D1qXFUD9pw9gZw9we5tH6dvcYj+BRh8pYqmqMOej87i+awE2dfAHd/mJylzqOnnmS3uMdqZBvPcIzhrynRHnfhHIjgGYnhn0pxcekql9evcaqwR1JfZuoeM8aTPjyjccSJFM7RGDXfBheXr3Jx+SoVcQ3lUTfOoSiiLIs4ncM9Eickz7NTOM925ix13ybW3v0oPGm+gE9eRJzeF7SquEZYm6LkXMIxmiCwUNqv/VZVCGgquKfSZG2LbKbPkLMuYe4K453OEdRUCelqRExLhHR1ouoyS6EdosoihjYRY3cQv7JE2LhIxLpMzL5K2rZM0lBFGImjPiaga/dhG4oR0teIWVfJ+reoBHcIL5TQnPCiObGfk6zvDOCZSpN0rFOJnmYpex7DgB/lCQHFYTeqYwKaZglDV4iIfpGV7B7blcuEdXXMfWF07X6UxzwojrhQNwkIUxl26o9wqvEoMfMy9tEEpu4Q6lZxX7YfdOAajnJm+VG2qleIW1dwy3LYh+IYuwKom73Ij7hwj8S4sHad1ewF0vZV/IoirvEUtv4ops4gymMegvI855euspw6T9azhqbPiziT25fj7gD6dh95xxLbpYsshnep+LdIGBcJLhQQplLYB+N4xlPU/dssh7YpeVYpi5vknatE1GVC8gLSdIaYrkLNt0nRuUzWVCdlrJNzLpOzNUjoyiS0FXK2BgVHg5ylQWQ+R3guR2yhQNpQoSKsU7AvkdJXyVpq5C2L+CaSuPpCmDoEpOkEaWOVrLFOXJkna66TNVVx94ewnJSQxhMEppJE5Tm8wzFiijwlZ4OksoCnP4S5XcLW5SMwlcTVF0QYjJDUlSnbFonIM7j6AphaPNg6fLj7Anj6Q/gnEuRMVbLGKv6JBOZWL44uH7YOCXuXD89QmLSuRN5cxy/L4Oz24+wJYO/eT+KYe1BLYDJOXFkkoS7i6g9haRdx9uz/3noHIySUBRr+DRr+TUqOJdK6EmXnMqey59hKn2Yjsct25ixb6TOcq1xiK32GiDXJtfOPfyQD+uOi6P7v5/r167z11lsfO//FL37B9773vQOB/i/AnfamAw44dOjQgUAf8FEymQxOp/OP7kD/7Gc/48knn/zE+SPr1whNp1HcZ6LzL8do/W/DDH95DstJL6cK5/Yl+4kXyFtqBGZSDH9xjs6/mqD/89NYO0WksRg3X3mDm6+8wWp4h6pnlYUHLfR+bpr+z09jbhOwd/jYKezx1i/f4sLyI2wkT+MdizH8JQXDX1Fgbpew9wQIzaR5/dU3eOrSM2Q9ZVKmEjP/qEf2TR2WDj/OvhC2Lh8Xlh/hxadf4frud9nOnUd71IniARuO/vD+5/UWL0lNkSf2nuLazuPsLV3F3htA3yriGUviHo1jOClh6fBztnKBC41HOFu9SGA2i3MojjiVwTuVxTOWQHvMS1lY40z1Eqfy55AmkghTScTpLNJsHmm+gL4zQGA2x2p8F1EexdoVwtYTwj9XQJIX8S+UcE1l8IwlKXlWyFoW0Z/wojkm4BpOEFwoEdJW8S2U8cuLRJQlfJMZNMf3d391zRLSfJ6IfpGoZYW4ZZmwpoK1L4LmuBtdi4jquIBjKELc2CDtXqMUPEXCsoRzJI6meb9dT3Vc2F9dUBSpBE7RSJ0n7VxD2xtA1Sqhbd1fcVAcduIeT7CUPMda/hIZzzqSooRtJIGhK4iuzYfymAfnSJzt6iWWcxfISduEjQ08t9M1TD1htCe8eCdT7DausJw+T0HcJmlfRZSXcE1ksA3G0bcHiKqKnF+9Ri1ymqJvi5ywSVBdQZot4BxL4hhOUPaus1W8SEncpChuUPBuYRz1E1RV8MmLBBUFVhOnKQvrxLQVksY6RWGDknedtKVBXF8jZWuwFN4mY6gRkGUJzBeIqssUhXUq4hYF9yolYY2yZ42YuoRrYL9O2z+dIaoqUnSvUJE2yNuXyFkbhOezWDp8WDp8CCMRQnNZYqoCaWONlKFC2lglNJfG1iahO+7C3R/C3u/H2uvFL0tSci1RtDcQJ+IYmj2YWkRMbdJ+rvNEkog8R9m1QtWzgqM3hKVNwtQmYG4VcHb5CYwnSBvLVN0rJNXF/TSOkyLmNi+Wdh/WkxLRuRxZS52Urow4GsMzFMbWLmFrl7B3i/gn4mT0FVKaEtJoDEevH2ePH0eXH0eXhDAYJW0o457yEZ7LYG0XMbcIOAf8WLt8eAZCJFUFGr51lgMbxBdy+CcSJFRF6uIa67FdtlJn9tM4kmfYypxlJ3uWC41HePF7P2Rnc4dnn332E5M0Ll++zHvvvfcHs99G1F26dIn33/+ofL/xxhs888wzBwL9X4A77U0HHHDo0KEDgT7go6yurqJSqf6oQL/55ptcv379E+fXTj1BxbXM7N06+j47TddfTzB3jx5Hp49nrj/HBx98wMvPvsp2+iy+iRiDX5yn/3PTzPyjFnOLQMZQ5datW/zy529ydfM6i/51pr+pY+Srcua+ZcDU4sHS5uWpK9/n3Xfe5fknXmSvcRlDi8Dk/9ahfsiK4YQb5YM28tZFXnr6ZV7/0RusFTdwDfqR32fG9P+y994/ch/muS/zS/6E/BLg4uCcIMV2Yjtx4ntix4qPayJZjaRYd5fbe++zU3Z67/U7vfeZnZntu1wuq0SuWERJlChRogoli7IoSqRIWQkSf+4PQxNWJB0buLhHxvU+wAI7eL8YLIHl4IN3n/d5njAi32dl9EdylAcsHCme4NyxZ7l84SWS+mI9+uuQE22zi5lH9Iz8WEbWUmWzeIqnlp9mzreItsWNvsODvkNA2+qm/wERvqk4tcAaq+lN/JIUujYPxi4fxh4BU4+f8Z9pUDbYyFqqlFyLWHsExLsMGLsDmPoDWAZDyJscyPZZ8U3HiKkLDP+rGNFjetTNTmxDEaxjUQw9AdRtXuzDMZyjUeQHrczsMiLdZ8XUG8A5kcAyFscyFsM1lcQ+GkPyhBnxLiPTO01oWt3Yx2K4RCm8ijw+WR7XVJLZBke9fe8xA7P7rdhGwviVBaLmGn7NHG5JDk2Xvw69T5iR7rdiHY6QtFRJeVYJ6CsI6jKyTjfT+83IGp3IG53YhkMUvItkvOsEjTWChhoOcRZ9fxhFuw9VixfXZJyl5CZZ7zIRY5WwsYagKmMZT6Dvj9S37eoCS8mjJO0LhE0VQsYqIcM87tkC1skkjukkRfcSOec8XkkGv7JI1DhPzDJPxFhBUBQIa8tUQmsEZBnMfUEcozG84gwxYxX1kIewbo6ce5mysIptOISqyYmh04d1OIxPlCZprpF1LpJ3r5A2lDD1epHuMqNqdGLsEnCORPCL02Rt86QtNQKzWQydHmZ2GpA+YULX6sLU48c1GiMkz5J3LBLXFjG0uZHuNCB6VItirwVDiwtrn0BImqbkXCBrrWDq8CLZqUf8uA7JTgOaJjvGLjeGfid5W5WEroixw4P48XoCh3yPCdkuA66RMBlzhYQmj3s8iqnTi6rBgmyvkdldBvTNDtyjYRKaIu6xCIZ2F+ZOD7pmB8q9ZpT7rNh6BDKGEhFFBl2zHVWDFXNPHaDl+01Yujz1JA5TGWEyWm8jbHVgH/Bjandh6nARlCRIm+aIq3LIDmpQ7Ddi7/fhGQ3jGgjim4yRMZRIm8oIUzEsPV48YxEy5jJVYYmasFyPsvMvsxxZZz6wxrHiSV449xLvvXuDj27fYXV5lTNnznwhQJ8/f56f//znn5ltbm7y8ccfc+7cuc9E3b3++utcunSJjz/+mP/8z//8sj+q/6D1ZXPTtra1Y8eObYDe1qd15MgRenp6fitAf/DBBxw/fvwL5688/xplzzyD3xPT9a0ROv5uhMl/UaBusPDa5Tfuxd29z9baOVQHLfR8R0TfP04z/AMJYz+WkTXNcf2td7lz5w6vXX6TmKrA8PcljP5YxuhPZhn4ngjFXjMn50/z2uU3+eD9DzhWOsHMo1oku/SId+rp/ycxQ/9LRsFW42T1NC9ffJXVucPI9htQN1hRNdgY+4mC7r+fwD0WZjG0xmb+BE+tnMXW40fb5EDd5EC+z0Lb340yu99C1lyhKqyQs1UwdngwdnrRtbpRNzsZ/IGM4R/NEhAnSRnKhOVpZDsNOAbDmLsDGLp9TO00MvITJaYeAb84hXs0gmSnDn27C9d4DMtAEEWLE9FOE8a+ALahEPpOge4HxpE+YcInTuIei6Pt8iFvcWEfS2AfjaFv9zGzy8j0o3psg36CshyWoTDGoQguURrnVBLrUATpPiuinSb07W4SuhKuiThuSaZu4xBncU6nUHV4kBywoe/0kjRWCMizhPVzeBUlvMoibnkB40AEVasPbXeApL5M2lwhYVvAr63i11UQVGUMozFETVZMgxHSliq10BoJ+zwhQ4WAtkZAX8WvncMuyuKSZCn5Vih6FvHP5vGrioT0VYL6GiHTPEFdhYh5gYX4USKqPMa+IPbxOIKiSNhQIWqpETHXyAlrLGWOY+4Poj7kwtDtxzoSQZjNEzXNE7cuspA8Ttm/gvqQE8luE+pWF7oOH/bRGCFVEfNkkHJ4lbSpiqrRztTDWmYP2NA2uzB2CzjH46St86ykj5E2VtC2eph+WMP0IzqUB231jOe+ABF1kfX8cXK2eUw9fsSPG5j6mYbpR/QoG+yYun2kTGWWYkfI2moYu7woDlqZeUyLeGf9d9jSI1B0LVB0zRORZ7H0CWibnch2Gpl5XI/8CQuWTh9p8xyKNgOe8QiOgSC6lnr8nHS3EfVBO35xioQ6i2soiKXXh33Aj7UvgGKfGeUBM+7RelxcSJbG1uPD3O1DmIxj7vZhbHVh7vYRUWRI6gs4R4LYBwL4xqMI01Hck1HMXR5C0iQZQxm/OIapx41nIkxSVyCqzOKfjBGVJclbKsTVOaw9Pmy9ArZhH/7ZOCl9fSNesNdIGUo4hgKYOt34pmJkLHMUnTXSxiJpwxwFa5Wqf4WF8DrH557iyrOvcvPGTd67foNLWy/x7KlL5CJF5rI17t79+HMB+sqVK7z00kufO/vkk094+eWXP5PU8eqrr3L58uVtgP490JfNTdva1o4dO7YBeluf1vnz5zlw4MBvBeiPPvqII0eOfOH8ww9usZw4zND3JfR9Z5LOvxuh77uTyJ8w8MzJ5/jwg1vcvXuXV59/jdk9JqYeVNL/PRGdfz/OwHdnKDrn2Tp8ng/e/4D3b9zEPRJBtsuA+FEd7X83Sue3xnD0CSxHD/PUytO8f+MmSW0B5QEzyn1mhv+XhENfHUD0qIacZY6F0DpnVs8SkMcQ79KgabAh3WWg+WuDdP/jNP6ZBGljmaK9SkyRwdIrYO71oTnkoP8BMa1fH8bU7iIoSZHQFDC0OfFOxPCLklj6/Yh26en4h0k0DQ4svT68kzGU++rZuDF1Hv9MCnWTk/5/lqFtcWHu8WPpFZjdb2Z2j4mEtkBcU8Q2EGLsER2GLgHrYATrQAhVk4Pe70/hFyUpOBcQZClkB52YBsLYx+PYR+OYegNI9llxjkapBVaJa/Poev3YxhO4xGkcohT2sTiqNjeO0TALkcNkHfO4plO4ZFk88jxuWQ6XNItlOIZ9IsFCeJ2Kf4WwtoygLOGTF/HKi3iVRXyKAj5pnoVovbkxoMjjmS0gqEp4VWX8mjIueRHNuMBy5igZa7Wecz0aw68qE9DMEdBVCBrnyfjWWM+dwDURQ93iRt8TxDwSw68uE9JXCRlr1BLHWMkeR93sRLLXjKLJib7Lj3U0RlBfIWFfYrnwJLXIYeQHrUw8rEG2z4Ky1YWh149jIkHSvshmbYuqfwXNIQeTj+oQPaavw3GbB3N/kKiuTCmyQMSYx9gjINtvY+pnWmZ2mZAftKPv9BLTFDl37FlKnmWMPQGUjTYku4xMPqxFvNuErs1FXFvkWPUUWWsN60AAbasLZYON6Yd1TD+iRdPkIK0vUQ3W0zocQyGM3T5UzXbEu/TMPKrF2iMQVWSJ64oIUwnck1Gs/X60rU5ku43om50ExElCsjTCZBxJoxbfVBz7QBBrj4C60YF7NEJcm8czHsUzESGqzBGW1g8NLT0+bH0B4sosodkU9v4A/ukYGWulvkG+l9gRU+aIqXM4h4PYBgRi8hxF+zxpXYmctd64mdKVCIjimLq8uIeD5C0V0oYiaUOJmDpHWl8kJE1h6fZh7fIQkWfImeeIKJJo2iz4JiO4hkJYujyY2l14xiOkTHOUXPNElRmsPV6cQyECkiQxZYbl+AZXX3id9298wPVr17lw7CJr6aMsxzfYWjtPypelEC3yzpvvfgqCP/74YzY3N3n33Xc5e/bsFwL09evXPzP/9aH0NkB/+fqyuWlb29qxY8c2QG/r03r11Vd56KGHfitA3717l42Njf/tvOpbYuYxDb3fmaTlb4Zo/+Yw+mYHq8lNrl19m7t373J67SzyvSbEj+po+uoAh77Wz8gPxGTMZRYia/zi5+/x4rmX0DY7UO23MPDPYg78j27avzmCezRM1lRiJX6Ely9cwdEfwNrtQ3HAUm82/LMe1A02QpIU0dksh9NHcY0HMHQ5cA4FGf3xLAf+rIeph1RYe3x4xiP4J+Ok9HmS+hJhaQZti52Grw4y8a8KdE0OTJ1ezB0evOMRSu4FUoYynokY3f8oQvSIFkO7F2On995m2kXZt8ScZ5GYtsDogypEu0yYevx1gO4PoD7kJG+rsRw/QtmzhOygDXmjA8tgBOtQBMtgGGO3H32vg5XMBvOhdXQ9AoaeII7JJNbxGLaxGI6xKMHZHJulk6ynNvGKUjgmEjimUzimUjimU3gkeULKIodzx1nPnSSiLOARZ3GIMvU0DmkdgmPmCivZY6wkN3FNxLFNxPBIc7hmc3gVBbzKIgn7IouJI6RNc2jbPWg7/Dgmk/gUeXyqOQL6OVKeVWxSP7ahIPIGO8omJ7ouAftkCr+2TNBQoRw7ylruBOomJ9O7jEj2WlA2udD3+PHN5gmb5lkunGQlewJVi5uZnWYke63I9tlQNrsxDYQI66scXz7LavYY+k4fswdtiHeZED9hQtHgQNPuQZDlOHfyEoupY5j6AigbnUj2mZl+RIvEAisAACAASURBVMvMbhPKJid+SYazxy4St5dRtNnRdXpRNtgR7zQx9ZAG2V4TQWmWjdIpKsIKjok4lt4gmlYXs/stTD2iQbbfTECSouReIO9YxDOVxD4crsNxgx3JbiOWPoGYMktcWyBuLBOUpHGNRrD1BdC0uNAcciLMJAnNZghKUyR1JVL6OfzTcRxDISzdAp7xKCFZBs9YhKAkTdZUwTjiJChN4Z9J4p+OEZan8c8kcY6EiCozZIz1RI+8s0ZSWyRjmiOqyOIY8OMZCZPQ5EnqCsRVWSKzaQq2KlnTHM7hEOYOD0Fxkrx5jqgyg2MwSGA6SUCcwDcRxdDmwjEYIKkrkjeV8Y5HsHR7cA74cY+G0DTZsHR5icnTFBxVIrMpXMMB1E02Jh6TYu5wY2hz4RoKkdKX63F6MwlsvQKGVie6Jhue0RApbZEnl7d4fusF3rjyJlvr51hPHaXqX2U5tsFieI3Ty2eJ2hLM5xZ5+bkrn5vlfPfuXTY3N78QoO/cucPRo0c/U7Ly+uuv8/HHH/OrX/3qy/6o/oPWl81N29rWjh07tgF6W5/WzZs3+d73vvf/GqBv3bqFbyKObLeeQ3/Vz8E/66b5KwMY2pwkNAWuPPcqd+7coWCromt2IHpEw77/3sWB/97F1IMKAjNxEpoCN969weHMUdyjYZzDQbq/PcHe/6uDrm+NYev1Ye/zs545ytkjF0hq84RnM6gazPcPElUHLBg73LgGQ2ytnyNjKWIb9+GdjNL59xO0fmMYxV4zmkN2dM0OKr5FDufqB4lJfYmJB1V0fnsK5UErumY3hjY33ok4x8pPsp45RlVYRdNsp//7UjQtLgwdPoydXix9fg7njvHU4hYb+RM4h0NMPqLH2CNg7Alg7A1gHQhQC6xy/tiznJw/Q1CWRtHkxDwYxjQYxjIUwTYSJ2GoUI5W2CgfJWObx9QfwDoSxTIcxTYWxzERwyfNcLRyilOLZ0gaSthHInV7x0QSx3QKuyiJR5qhKqywkjqCZzKOttWDbTyOU5TGNV23cYT1FVKWCmlzBV27B8VBe93eMJXALc3jU5ZI2pcoeFZwjkVQHrQh2WtGftCOtlvAK88jKIvk/evUYhuM7VYi3WtF2WhDus+CvNGBbSyOX1OimjjKSvYE1uEIkr0WZg/YUByw1Sux2zwEVSUOl06zmj2BbSSGssWFZI8F6T4L4j0W5A12XNNJnlo/z3LuBM6pJLouAUWTA8leM6KdBsRPmHAMhzm5vMV8fBNhNo91OIy2zYu8wY7ocQOTj2hxj0VYz5+g7F/DI04ha7Zg6vGjanEh22Nmdr+FgDTLnLBKxjpPwlTFJ0pjGw5j6hJQN7swdgnENAVShvrBYMZaI6oq4BqLYR8IYen345qst/3FlAUypgpZc5WkoUx4NocwlcQvTuGXpghIUkQVORLaIlnjXP05XYm0cY64uoBnMoZvOkZUlSeqzBEUJzH0u4jqMmQtFQRRElu/gCBKkNIX8U5EcQ4G8c/ECUlTJNUF7H1+rP0CcWWWhCqHa6DeKmjp8REUJXAM1iu0Q9IMKW2B8GwKS48b+R4jth4fzoEA9n4/rrEQBWeVrGWOwHQMbYMdbZMV7SF7PQu6VyCmylJyzVOw1bD0COhbnGiabGiarIw9IiUwnajDt22esDSFscONtsFSz4huceIaDjPnWeRE9UmOFE9S8S0xH1hlJX6Y+cAaNWGFhXtxdpvFk0RsCdbKh3n+mec/BcEffvjh/Qi7I0eOfKay+9cA/Xnzixcvcu3atW2A/j3Ql81N29rWjh07tgF6W5/Wf/zHf/DNb37zdwboO3fufH5KxxvX8Y1HMHd4af5qPwf/rIuGP+9F02TDMejnratv8/6ND8hZqoTlGSYfVNDwFz3s+29dTD2kRN1opWCvcuvWbTbyx8la53CNhej4xggH/6yHkR9KUTdYMLS6ePnZV7h46nmWImtkzHOM/kRB898MMfajWZQHrKgO2ii7l3nzlWus5jbxSIPo29x0/MM4E/+qRLnfirrRjnskytXLr3PxxHMcm3uKoCzN4PdlSHca0TQ50bZ50Xd6OL16ljeuvMm5Ixcp2OeZfkyHssGOttWDocOLoc1D1lzltZfe5OULr7KWOYq62YW+04u+04uxJ4C+3YdjNMKZtfM8e+oSJ+dPYxsMYuoJYuoPYh4MY+wNoO/wUg2sUQhUiajTGHsELPfmluEo9rE4pr4gIXmOpdg6IVka+QEbxp4A1pEI9tE4jokELlEK30yKjHkO53AY+X4zigM2TP0hnNMp3JIMflWRqK6ET5TA1OlF2WhH0WBHdchZf4+ZNHFrjaxjEfdUAmWjHXWzC1WTE0WjHW27F0GWI+9ZoxRcxyfOMPyIAtkeC4pGO4omJ9I9FtyiJMupY8yFNwgoCxj6gsgP2pE8YWF2n4WZnQasgyE2yk9RiRwhoqtgG42hbfehaHQiecLE1GNajH0BNmtPUQ6sE9bP4RalMPYHUd8Df9FOI67RCOv5U+ScS8QMVUKqAraRGMa+EJoOL4pGBxFNnlrkMEljjbipSlhTYLbDim00Wo8VHAiRNM6RtdVImOZImaskDBViujKCNItXlCIgTZM0zBHXFknqS6QMcyQMcySNVVKGMnFNiYgiT0ieJTqbJyjJEJCkiWtLZC3zZC1VotoC3qk4fkmKoDSNfTCAcziIeyJGTFUga6kRkNSzmwPiBH5JCkOrG90hRz0OstuBdciHX5wkIsuQ0hYRRDFU+y0o9puw9flxDgXwjkUISVJU/csUHfPY+vyoDliQ7zWib3bgGAjiHg0TVeVZjB6m7FzA3O1D1WBD/oQR1QErpg43EVm9vbPkWiBlKGLvF1DsMaI6aEG134S120tKX6Tkmq+3FI5HMbV7UTVaUTVYMLW58E5EMQ05SGoLeMfDGFudWHt9aJrsGFoceMZDZM1lcra6d1qYihESJynYaiwEV+8ncVR99VSOpcg6i6E1wuYYF59+lmeeufi5Wc6ffPIJp0+f5saNG5+xd/z69X+dnz9/nnfeeWcboH8P9GVz07a2tWPHjm2A3tan9atf/Yqvf/3rvxNAHzt2jFu3bn3u7NrVt8la5jB3e2j52hBNf9FL89f6ke3WIkxFuXXrFjdv3ORI4Tg5S5mB703T9teDtPz1AJLHtSgOmDh37Bnu3LnDxVOXWEttYmhz0vmtuv9Z9KgG+T4jkdkMt27d4u3X3+GppS1SuhIDD8ww8MAMkt0GVAfM6NtcXH7mCrdv3eaFsy/ilgcQPaxm4iElin2Weu3xHhNz/mXeu36DG+++z4Vjz6JrdTO714y6wYGm2YFkdx1Czm1e5PWX3uSNl9/ANxVH0+isp3W0uJHvtyJ9wsx8aJ2nlp/m7OZF/JIU+jY3+nYvug4fujYPU49oianyrKU3WU5sYOryYujwYOzxY+y5l8Rx0Ia1P0jFt4xfFmd6lwb1Ief9pA7baARjrx9zf4CoukBYlkHd5ETb7MDYLWAbjmAbrUO2eyqBazyBYzSKusVVtwq0OLEPh3GMxhBm8wSVRTwzaUw9AsoGB6pDTlSNTvSdPtzTCWL6OVK2RQRpFsdoBEWjHfkBK7MHbCgPOXGMhCl4lsm6VxCUebySLGO71Ej3Wetb6n0WTL0B5hOb5LzLBDUlAqoSlqEw2s56W590rwXbYJDDhRNkHEtEtBWCmjLumQym/gCaDh/KQy7C8ixrueMkLQuEdGXC2jlCmhLOqUS9rGYwTMZeYz6yQUxfIWYsE9XPEdXNEdaU8YpTCNI0Be8yGVuNmLZMTD9HRFcmqi+jGrATN1ZImKrkHDUC0gw+UZKANENUVyZpqJK01EiYqiQMZeKqAu7xENZeP86hEJ7JBHF9ibSlRsJQJizPEJAmcQyH0DTa0bW4sA8GcE/EiWtLJHR1e0VSX8IxFES224jygBVThwfXcBDfdJyMpUrFv0LZs4BjIIB0lwHpTt29pI4AtiEB27iXo4WTVLxLOIeDyHYZkO4yojxowdDqJDCToOJbYjWxQd5ew9ojIN9nRr7PhOxxPfo2F3F1nqXIOiX3AiFpGmu3gLbJhmKvEdUBM6Z2NwVrhcXwGkFRHFu/H8dgPc9dedCCvsVJXJUlayyT1OSxdHkwd3pwDvoxttc9zsJ0jKS+SMZYRNliZnafDt2hurXKcS+rOqMvUXDUCEkTWLt9mDrcBCRxCrZ55gMrVDxLzIfWWIoepuZfZTW2wcn507zy3KtsrG3wwQcffKYw5Te9z5cuXeK11167P7t9+zYnTpz4lGXjN+dbW1v84he/2Abo3wN92dy0rW3t2LFjG6D/UJTP5/nKV77CH/3RH/H0009/4XO/Bugv2iz/5tepU6e4cePG585uvHuDE5WnUDdZ6PzmMK1fG2Lgn2aQPq5jIbR6/xDxpQuvULBX6funKXq+NcbID6TIdukxdbh559r1+2kdp9fOMfOYjsEHxIgeUiN5vH5odTh7nNu3P+LOnTtcu/o2jqEAUw+qkO3WI92pZ/xfFFj7/Ty/9SI3b3zAhx/ewjhoR7HHjGKvBdkeI+M/VSB6WMdK7DDnNi/yzrXrLMfW0TTZUR20oTpoQ/y4lsF/FhNX5zmcPc6ppS2K7oX6BrDFieaQC3WTg4HvzWAf8FMVVlhOHMEvimPuEbD2B+/l/3oZe0iFbK+JtKFMwbGAaziIpsWFV5TAPhTE1ONH3mBj9oANz1iMmDqPvt3F1ONKrINBgpIMlv4gum4f2g4ftqEQztEo5l4/2mYXulYngjiFZzqBdSCEbTyGfSyGczyOttWNqsmBosGGfSBASJ7FI0oQUOZxi1L3GvZCyPdbke+3omt1EZJlCavyRIwVfLM5PJIMzqkEug4vyqb6hjooy1D2LZOwVvEpiwizBXzSLLMtdqSNVrTtHuLaIkuJTeLmGn5lCUFZJKAs4pNlsQxHsIzGKHoWWU0fJ6ovE1AVCarnCGhKBNRz+KQZAvICC8mjlHzLhFVFIto5QuoiYW2RiH6OiH6OrGuRhcQmEXUe72QSnyRDWFMioisTM9bBt+BZoeBcxDEcwtTtxzoQwidKEtWViBsqqPodFLwrJHVljO1elAet6NvcWAdCeGeS9ywa81SEtXq0XI+PmZ16VA12DO0eHCMhBHGGOf8Kq6lNKr4l7IMhJI8ZkO42oG12YOjy4RmLUguucaJ2hoqwjH0wgGKfhamH1SgPWNC1OnGNhlkMH+bJhS0KzgVsAwE0hxxId+qQPKZD2+wkKEqxGFvHLfWTMpSxDwbqBStPmJHu1qHabyOhKbCWOkLWWvdT2/sCWHu9KPdbmN1jwDkcIq7JkzWXCUzXq7h9UzFsvT50TQ4s3W4CkgQZUwnfeBRrrxd7r4AwFcM9Fsba7UUQRclaKoTlKaw9ApZuD77pWP1wcTpBSJwkZ62QNpZwDgYwtDrRtJpxTgjkTHNkDWUK9hppfRnfWBRTmxtrr5ewJEXeWmXOu8hCcL0Oz8E1FoIrLMcPc3rlHNeuvs0HNz/g+s+vc+zoMX75y19+phDl7bff5sKFC3zyySe8+eabPPvss5+q6v7NBsJr1659av7UU09x8+ZNfvnLX/4f/OTe1ufpy+ambW1rx44d2wD9h6IXXniBy5cv88ADD/xvARrgG9/4Bh999NFvBeitrS2uX7/+ubM7d+5w9YXXUOw10vedaQYfmGLip3JED6k4u3nh/nO3b90mYywy9pNZxn8qZ/xHswz9swTXkJ83X7l2H+RPrz6NfLee2d0Gxv9VTv93Zph4UMl6epOXnnmF27c/4sXzL6NrtKHYY0L8mIb+fxLR84/TRJQZjpZPcWnrMleeu8r4I1JUBy0o9psZ/5dZWr85hLHDRc2/wuHMMY7NncQ7HsHaK6BtcaLca6XtW6OIHtGQ0hcpexYpOKp4xsL3KpLD6FtdDP1QxuD3xfim4yS0RZLaIoYODxFllvBsDvtwBPHjOkZ+LMfQ4cM7GSc4m8bQ5sI+GCSpKxOazaJtdiJ+3IihW8DS58cxHEJ9yM7YwzKi6jxpcxXrYBBVswvbSAT7UBjrQAh1gx3FPjPeiThz3mV803EsgyHck0kcYzHsI1GM3QKKBge2gSAl3yJJXQmfNIf3HhS7plM4JmJo271Y+gPMB1ap+JYJa0u4JRnc4gxeaQavJINtJIZzIs5K5ihr2ZOEtCW8khy+2XqmtCDPYxgOYBdFObG0xVrmGEFVHr88jzCbx68o4lcVCarLZN3LnFg+S9pawzWdxC/N4VcWCShLBNVlwvo5quEjrBdO4hqNYugUsA6F8ErShFQlYvoKEV2FWuIIc6E1dK0uFA32e5FyQQRxmpi2TMJSZS1/krJ7AX2rB8keE6pGO4Z2L9bBMAFZhpx7magjQ8mziKVfQLrLiHyvCXWjA2OnF/dYjEpwnWeevEQtsIptIIhyvw3J43oU+633tsshKsIyL124QsW/WofeJjuzey2IHtGhPGDFMRRiMbrO2c0L5G01HENBDO1elAdtzDyqR/aEkcBMiuXYBmupTSLyHO6RMNY+AW2zHcnjejSNdkKyNEV7jYQmj6xZhzAVxTEYxNjhQdlgxdbnJ6nNI4gSuAaDBGeSBGYSCNNJTN0ezN0CMVWOuDJb90X3+IjIM6T0JfxTCXyTMeLK7D2bRRRjuwvncIC0rkjWVCZvq5I1lUnqioSlScwdHkwdbsKyNFlDPbu57F4ga5kjpshi6xfQtzlwDgdJ6cukDDkc0z4K9ippQxnPSBhjuxtLj4+wPE3RVaNorxFT5UkbS5Td8/daBze5cOwi71x7hw8//JC3rr7NhePPsrVxjlp2kXfffu8zhSlvvvnm/YKV/7qhfu+999ja2vqUX/rkyZOfKlm5devWNkD/HujL5qZtbWvHjh3bAP2Hpt8FoL/73e/yzjvv/FaAPn/+PNeuXfvC+euX30B1wMzUgwr6vyOi59vjjP5QyrG5U7x3vb65vvHe+9gHBaQ7tYz+SEr7347S9fdjBCUJTs2f5vpb73L79m1iqhzyPUbEj+no+Nsxmv96EMU+M/PBVY6VTvGLd96j4ltE3+pC3+Jk8l+U9fKWH86S1BaY8y5xrHSKlcQRZvarcY+GMLQ7af3GMO1/O4pnLEJCU6DomCdrrpA2lInIc3gnY4z+SMGhrw6ibrQhTMWJq/P4JmMkdEVylhoRRQ7tIQdd/zDB7D4Lpk4vnrEozsEAzuEQc75lspYq7okYA9+XoGy0Y+jyYezwYe31oW12knfUoSCmyjP9mP5+LbipL4ClP4CyyYq628Ja+ih5Ww1tuxfzYAjrYAjbcBj7cARDl4+wPMNG6QSL4XVcU0ls43FsYzHsY3EcYwlsI1Gi6iKnV89xrPoUYWUB+3gc11QK52QC51S9vTBtrvLc1mW2Ns4TVhVwTqfwiDJ4ZtK4JVkEeY6ce5lzp55lJX0E30x90+sRZ/BJc/jlBXzyAmFTkXygQlRdwNglYB2I4JVkCMjz+BUFAqoylcgGh3MnsPT6UTU50LW4MfYFEWRZQuoyQXWZ5dxJVlOb6JqdKBptKBvt96rRQ/jledLWBU4unWU1dRRDlxdFoxV1sxNlYz16zjkWo+BZ4cKTl1jOHMfU60fZYK/bUPZb0ba6sfQEKHqWuHzhFcKmNLpOD+oWB/L9lrrN4YAZY5ePsnuJ589ephY5jGMsgrHTg+qgDdluI+KdBqx9fuY8S5xa3GLOu4xrPIKtP4C+rW4JEj+mwzkSpuCoUXDOk7NWESRJXGMRzN0+tM12NE12fNMxQrNp/DMJ4toicU0RYTqGbcCPscONZyxKVJHFPRbGORQkrs5hGLQTlKYQRHGCMykiiiyCKIa504NnJELaWCJnrlBw1IE7pSsRVeWw9noxdXgIzCTImSrMuRfJmSsUnfNkjGXcw2F0LfVClLS+SN5WI60vUnJWKThrBMQJjM0OTJ1uwrIURVu1njSiyZHSFklp83jHIli6PHhGw2SNc2QMJeKaHO6xIPJDOrzjEVzDwfq/V1Ugay6TMZUJiJNYu7w4B4KEpSlyxjm2Dj/DL965wc0bN3n1+dc4tXCmnuNeOMFG6RjzuUWuXLzKmae2PlWYcvXqVV588UU++eSTz2yor1+/zvnz5++//q/zzc1N7t69uw3Qvwf6srlpW9vasWPHNkD/oel3AegHH3yQy5cv/1aAfu6553jttde+cP7U0hayXQZGfiSl+Sv9tPz1IJM/maUWWOH50y9w9+5dLl+4UrdANNno/vYkTX/ZR+c/jBKdTVH1LXLluatce+UtfJNR3CNhlA1mGv+ij0Nf6cfc5SGpKTLnWeK1F1+naKsRU2RxjYXo++40+/5bF9JdevxTccLyNIuhddbSR7GMOInIU2ib7Bz8ix5GfyjF1OnFPRrGNxFjIbbBcnSdgq2GbzpBx7cnGP7RLOpGO4ZWF+ZuL5HZDEcKJ1iKHiZnrTL841kmf6ZB1+pC11aP5HIOBtnIHWOzdJJacAXFAQvivWYMHT4MHV5MXQKWXj/L8cM8vXGB9cxRbP0hdC0eTL0BjD0C5l4/pt4A1dBhcqE8W0eeITSbw9gbwNwfxjIUwjoUxjYUoeRZ5vWXrvHys6+SNJSxDoewj0WxDsewj0VxTiVImmtcOvcyF5+8RFRVxDkRxT5+79BwKoVXnCFhqnJyaYuF2GFs/UGsA4F6LfhUCs9MFrc4Q8a1xGr6GGF5FlWzC01LfYPrEaXxibP4ZvMUAmuUg8tI9uvQtbrQd3hRt7hxjETxyTKEVCVWsidZzR9H3+1F3+7C0OFF3eJB2+7BI0oRM1Q5Pr/FRukk5v4AqkMOdO1utK1eVE1OjN1+MvZ5zh5/lsPFU7jGYmjb3Cgb7eja3KgaHKibXaTNNZ5/+jKr2RO4JpMYOuuwrjxQB2j1IQcZ8xxPb16kGtzAOOBD2WJH315/D/FOA7pWJzlrleXEUfKOeeKaIu6xKNbeQH3jvd9a/91QZuvRc6Y5MqYKIUkW50gYS5eAuduHbzqBdzqOMJMkpSuSNVWJa4sExSmE6RjCTIKAOIFjJIh3ov7XjKy5QtYyR0JXIqEuElXmcY9EsfX4CMzU7Q15UwXToJOkvkDOWiEgSmDscGHv95NQ58gayqQNJYr2efKWKnFNAVtvAEObi4AoTkZXIipPE1PkiCiyFB01wrIM9j4/ztEwUUX2HtAmcPQHCUiThKVJApI4flGMlK5A3lIlrS9h6REwd7lxDwbxi+K4hoNkTGVWE0eoCMv4p2LYunxoG6zY+wREe+REpSmKznmOlp+k4JrHORzC0OZC1+xA3+okIk+zGFnj+dOXeOHsSzx/5gU2cidYjh1mPrjKQmiVtdQmG+VjlEIVXrl4leeeef5ThShXrlz51Ovjx49z+/btT1V1f161939N5djWl6svm5u2ta0dO3ZsA/T/n/SDH/yAr371q5/5qlQq95/5XQD6wIEDnDlz5rcC9IsvvsjLL7/8hfOasISlx8vET2Q0/VUvTX/Zx8yjGuKKHE8ubNVtIKvnCIoT2PoFWr4+RMOfd9P/3an6tf1Mklcvvcarl67WN2baAjOPqWj48x5a/2YIQ5sLW7+fjKHEz994h/XsUUruBdzjETq/NUrr14eQ7NLV/abtbs4dfYZzm88QVMeIa3KM/UhK17fHke7W15M4GiykjCVevXSVkwtbrCSPoNhvZuB7YpT7zagabKgb7Tj7A7x08VVe2LrMiepTuEZDTD+iRdvsQHPIga7ZianDy5MrZ7n+1rs8d+ZFUoY5FA02dO1e9B0eDF1eDJ0+aoE1btx4n3d//gvmg2v1Q8JuAWO3vw7QfQES2hJXnrtKtVijGlzB0hfEMhDE3BfEMhjEOhTFL8lwYv4MZ9bOE1XmsQ6GsQyEsA6E64eE43ECszmqwVUWIxvYB4MY2j3YhsLYR6M4xhPYJ+LEjBWy1ipxXQlLXwBTjw9jt4BjJIpjIo5HkiHnWqTgXsI7EcfSH8DUJ2Ds9qHv9OKeSuCT5ZiPb1INHcY+Emb8UTmm7nq8n7bNjWUgSEhdYr10koX4Bn5JBm2LC327G2OnF0OnF02Li7i2xJPr51mMHyE4m8PY40d9yImm1YWu3Y3igIWIKs/TR5+j7D9MSFnEORrD2CmgaHSgbHAg32closxxfGGLnH2RqKaEX5rCMhBE1+ZB2ehA1WgnqsxRDa6RMFaIG+bwziRQddix9PsxdPuwDgQJK7LENaX7MXUJXZmwIo9PlMAzEcM3ncAvTROS54hr63F2CX2ZpLFCXFMkpirgm07iGg0TkKbv5TKX6k2Ohjky5ipheRbbYBDHUIiwPEtSWyRlKJMxz5ExztUj6mYSmLq9uMYixFU5QrI0AUmSqDyLRxzCL4vinYjiGQ8TU2WJqfM4B/04+/z4RQliqhwpTYHgTJLsvRSNoDiFoa1e3e3o9yNMxQlJk+RtNVaTGywE1xAmYxjbXCj2mrH2CbhHwsTVeWr+FY5Vn6LiW0aYitb/r+w3o2uxE5hJULDXWIlvsJ49Ttm1gHMogLrRhrrBjKHVSVCSxKcIUREWKbsXiCmyOIcDaJps6JrrUXhpXYml2Dpr6SOUhUVSpiJZa5mMo0zSXCBhyhJSxonoUiRdOUqhKq88e5Vrb1zj3Llz94H48uXLvPrqq/dfX7hwgbfffvtTVd2/CdDPPPMMb7311qcA+t/+7d/+v/4o39Zv0ZfNTdva1o4dO7YB+g9NvwtA9/T0sLq6+lsB+pVXXuGFF1743NlHH33EanyDmCpH/3enaPzLXpr+qg/ZLh2mdhdnN5/h7t27PPvkJaq+ZSy9As1fG6Dhz3sZ/YEU5UEz7uEQN35xg5+/8Q5HS6fIO6oMPCCi+a8HGPpnEbNPGJDvM3FyYYtbH97iuadeYCN3HOVBC13/MMHYT+TIdhuQ7zURECe4+f4HvPPmdSqxeVwjQ60NpAAAIABJREFUAoPflyB5VMvsHhOKAxaM7W5eeuZlbt/+iDeuvEk1sIJkp4HZvcZ7aR1W1I0ODmePc+fOHW59eIvTa2fRt7pQN9nRHHKgbXKiOeQgrsrz+pVrfHjzQ84dfQZzjx9tixNtmxtdhxtNmwvrUIAnl57m+a3LHK+exj4YxNjpRd/hrpen9AgYOwUqwjLH5p7EMGTH0itgHw5j6hYw9QUxD4QwDQaJKPPUAmuE5VlMXV6coxEco1Esg2HsI2G8kiR+aYqUsUxgJoml14+13493OoFtNIpzIk5EUyamK+KdSuKZjGMb8GPu9WMdCuOdiuOciJF1LpK11/BNJ7EOBDD1+O9t0gWsA3Wv8Xx8k4J3CUGSwz4SZvhnsxg6PJh6BQztHnyiBEcrT5JzLxFSFvCIM+g7fWiaXehaXSgbHQiiJMfmt8jaFwkq8gQVBRzDMXRdXtRNDlQNdsLyDOuFk6TNNULKIkFVAUGWxToUwtgjYOoWiKlzlHzLxPVlYtoSUU2RsKqAX5rBPZnAPRkjoS2RNleIa8tEdSWi6hIBRRbdoIuoskBYXiCszBFV5olpC8Q1JWKaIol7W+a4pkhAksE/nSQkzRJV5kloiyT09WfTxjmi6rp/uH5Il0aYShAQJYlrCmSMFTLGCjFVnpA4TVJbICRLYe0VsPf78YxHSWgLZMxzJDRFspYKFWGZgDiO9pANbYsD+0AQYTqOTxzGPxtlJXWUpehhApIksieMKPdbsfUKuEZCRBU51jNHObX0NEvRdTwjERT7zMifMKBvduAcDpG3VjlaOsnp1acp3tsGaw/ZUOwxomm04BmLsBBa5cmlLWqBFZK6Eu7RELo2J+qDVnSH7ETlGZai6ywnDhNWJPFNhzF3u1A1mZHt0WHqdmIf9RFQxrGMOZk9pEGyR4XskBbRbiUz+xQoO4wYRx2o2o3M7FMi2qNA1WHBOSUgyMMIsjARbYqIJkXCmCVpylPy1Tizfpb3f3HzM4Uozz//PG+88cb916+88gqXL1/+VFX3f63v/rXl48iRI3z88cfbAP17oC+bm7a1rR07dmwD9B+afheAnp6eJp/P/1aAfv3117l48eIXHhFeOPEsWdscPf/3OC1fH6b9m8OIHlajabLx+st17/TP33yHU/NnkB8w0v53I3T//RjTD6oRP66j4luuHxre/ogrz14lrS3S/08iRr4vZuZnamS79Fi6vffTOj54/wNOzp9h+mdqph/SIHlMh2x3HX5Pr52//7MdXTmO/ICxntTxhAHZHiPS3QZSugLvvv0ud+7c4Z1r13GPRVDstyDfb0FxwIxktwF9m5sz62d55fnXeevqWwjTcbRNTtSNNjSH7Mj3W5DsNFAVVjg1f4bTK2cJSVPYBwLo2z1oW9yoDzkQPaolLE2zFD3CSuwInrEoAXES91gUY6cPQ4cH5QEblj4/BfsCZc8S0oMGrIN+IvIcztFY3SPdI2DtFwjJMqQNc7hGwtgHgvhECSKKekW0ezKKdyqBayxGQJzCORLB2h/ANhAgosrhnUoQVuQIq4u4xxM4RyNYeoX6drnHh3siRlCWIWOdJ26q4JlJ4Z5IYB0Iom/3oGv3YOkWCM5mqIXXiZvm8E4n8c6kcU8mGXlUjqbZib7NS0SeZT17grihgiDJEpzNI8gy2CcSmHsDGHsFUqY5VlKbRDQlQooCfnn98DAgy+ERJfFOJSh4lpkT1oioS4SVeQLKAiFVgbC6SFhRJK4tURJWSBkrhBV5IspiPUlEWSSqLRPTFonpyqSM9cPNsDxLRFkkoi4SVRWJ6Yqouu3E9WVCszm8UzF8kzGEmRRhRY64tkRSf68wxVwvEfFNxzF2+bD2B3CPxUhoiqTNZbK2GlXfMtXQCoGZOOoGC9pDTmx9AXyTcVK6MvPhwxzJHWc1sYFvOoF8r7leAtTuwTkUJCBNc6J2mjPrF1iOruMejaA55EC2U4++xYml20tKW2SjfJxyZI6qsIx7JIi2yc7sbgPqBhv2Pj9F+wJnDp/jRO00BVsN51AAc5cXxb0kDt9ElPnIGmvZTUruefyiGNY+H9pmK5JdamT79Ri6HARVcQRFGPOgi9lDeuTNemb2KJl4RIp4rwrDkBV1lxnJQTXifWpUrQZ0XVY0nRa07Xa84jCuqSDmHhey/QbEezRoOixElGkS2hw5S4m0vkBYmsbS48XY7sI+6CeqzFJ2LbAYWqPkmGchtMZCcI2lyDrrmWNcOPE877xZPyr8td1iY2Pj/vcXL168v1H+dazd008//amq7t8E6F8fFv7yl7+8D9D//u///n/o03pbX6Qvm5u2ta0dO3ZsA/QfisrlMn/6p3/KH//xH/Mnf/In/PjHP/7CZ/V6PX6//7cC9Ntvv825c+e+cH7zvZuUnPP0/s8pev7nJGM/lCJ6VI1nNHw/P/rOnTu8dOFlZh7TMvoDKVM/VSJ+TMfsXhOXnn7x/nu9//5N3MMhZh7WIHpYjfgRNaIHFWSNc3z4wa37W++suYr4MT3ix3RIHtEx+VM56kM2zh+7yHvvvMedO3eIG9JM/kyBbI8R2S4j4z+VM/oTGVXfMk8fPs8bV95kPb2JucuDoc2NYq8F8WM6+r8jIihNsZrc5GTtNAuhdfyiBN6JCMYuL4oGC4Pfk6Brc1FyL7IU3SCtKxORZ4mpi3inYpi6fEw9rEWy20RcXaBgr5HUFHCNhEkZy0RVeTyTMWT7zSgOWHEMRYgp88SUOeQNRuzDfrKWChFlDmOHF2N3PSLPMRwiKEljHwhiHwiQNJTImiu4RyN4plNYh8PYh0I4hkPYegXM3QLeqQQl5wJRVR6/LIdjJIpzPH4/Ek/X7sba76fiX6HqXyGoKuISJeuZ0lMJXBMxrP1+rAMBFsLrLKc3CSsL+CRZPDNpPDOpeqtfi/n/Ye+9nuS6z2tt/B2+t6s+Hwc5yz5HsiWLoiVKokhRzCBympxjT+gcpnPOOefuyTljAmYQBzkTgQCIDIJSlW0938UeQqJJWqfqXEBVnlW1b/DbmC5Uofc8/fZ618LeFmY8OctgWLjH1Z3E1bW5cNgjXFFtkZniEkX3MN7eJO6epJDGIc7gkaTxSNPETf0MR6cIyjO4e5N4elJ4xRm8kjQ+WRafPEfOOUrePoyzPYKp0Y+zLYpfmsEvTROQZYn2lSj7xsnbB7G3htBVuDFUuLG1RgjIMwSVORLGMjapl37vKI62IJp9NpS7LOgrPTjbo4QVWYquEZbG1xmOTmJvDiHfIeSFa/baMNYLcYPT2QVOr55jODqFrdGP9AMDyh0mwVa0x4a/K8rK2FGunLnKgHcMc50P9S4r8g+NSN7XodlvI6LIsDx6hLPHLpA19+NoDqI/5EK5y0z3m2r0Bx1krSUmc3MMRkZRVukx1jhQ7zXR/baSzjfkiHf04ZGE8MhDGBod6OqsSHZpEL0vp/nn3TT9tAvpbjXyQzp6dqno+kCBskKPrt6K8oAB2S4dxkYH1hY3+jo74g80yHfocbYHCSuTxFQZ4tosYUWasDSNscIhNBFWuQlJU+QdgxRsg4JtRZ3F2uBDs8tC314LrrYgIXkMi8hDxlQmrS/iahPsIuqdFiwNXiLqFEXrwCY0j1L2DFNyjTDgG2MytcDZtQvcv/uAx48e8/D+Qx4/+i1AfxE/97tlKF8A8vPnv630PnPmzJdyn78oV5mamuKzzz5jdnZ2C6D/QPSyuWlLW9q2bdsWQG/pq3K73Wi12t8L0Hfv3mV5efm/vSeuTNP+bxJafySh6d96aXq1m5xl4Es50/P9y4jeUNL+UxlNr3RT+912xO9oOHdUsFM8f/6cM2vnhKnxW2rafiKj8n+3U/vPneTt/WysnOXxoydcOXMVY4VDSGp4V0ftdzvY99eN2Jr8TCbmWJ85wdUz17E0upHt1qM75KTzDRW7/6wG6fs6cvYBRiNTLPQvk7cOEJKlcXSE0R5ycPDvm2l+pYeIMk3W2E+/Z5RkX4GcZYCwIoNHFKP5R2KqvivC1hQgKE6S0heEVANjmYy5n6g6h3yXiaZXxWj22rDW+wlKUrjbo7jbw5S9o+StQ5jrvYje1qI56EJzwI65zo+jNYJkuxaPJMJgYAK/JIl6vx1dpRtdlbBsaKx2ozvoIiBJMpmYJWcbFCC30Y+x3rvprfVjqvPi6YqzOHiE8cQMrq4E5uYwpuYQpsYA1pYw1tYwYXmW4wsbzBaX8PQmsbRGMLeEsbVHsbXHsLaESejLnFo5w2RmAW9vEltr9MW5vT2GqzuJocPH7NBh8q4RbG0R3F1xHJ1xnKKEMFkWZ8h7xpguLuGXpLA0BXB0RHF3JXB1J/D0pPDLcwxFZxhPzeNoCWKq9aGr9OJoj+IVpwjKcgSUeWaKS0ym5rA2BTFWe+jbL8S0OTtiBORpkqYyR2ZOMpGcw1zvQ7PPhvaQA81eG4YaL96eBP3+Sc4du4hD7sdQ7Ub2kRntQSfq3Vb69tuxNwWZLSxx7cINRuOz2JoCqPfaUO4wo9ptRbXbgrstylx5mUtnrzEcmsLWFEB70IlqtxXpdiPynUaCkiTj6RlmSgskDHmM9R7U+0z0fqCl7XUpol8qsLV78SgiWDvd6JtsyA/oEG2X0/JGD3U/FtH+thRlhQ75AT3inWrU1SZkBzWoK0wodhtQHzRjbHBhqLEj3aFDsduIWxQiokwT1+YIy4UPZxF5Gku1G8VOE4YKIdYuZ+0nrSsKTYC6PI6WIMrdQrW2uz1MylgkrS+RNfeTtw3g644KFdw7TZiqvUQUQuxcwT5IyTFIvE/4GZpdFiGtoztKXJUjZ+snYy6ibTCR0hdxNPmxNfhxtgWJqTKbNeF5gr1JEn158tZBhoMTHB5c5eq56zx6+Jj7dx9w/sRFjkwdZWPlLOePXeTRg8f8+te/5tSpUy9sG6urq3z66adfqe/+/PPPOXnyJDdu3PjS2RfpGw8fPmRhYWELoP9A9LK5aUtb2rZt2xZAb+mrSqVSdHd3/16A/uKXyjed3793H+1+C50/V1D/PREH/raRym83k7WU+PjKrU17xlNCkiTSD3R0/0LF/r9pZM+f16HZa2Mmu8DVc9f57LPPGAyMY6x0oK9w0PD9bnb+aRUtr0rI2/oZj89w/eINlkfXCYoTuNvDaPZa2fmntVT8QwuB3gRZi7AMdeLwBhFVGl29DXdHmNrvidj5v2qx1HoISVKkDSVGIpMMRybJOwaJ9xVQ7jCz+y8akH+gx9boI9CbEJanPCOMx6cpOIdwtIWo+j9tiN/tQ7XLgqXWh6stTEiSZCq3wGhshlhfjvbXlUi3GzYnkBYMFS6sDX7GorMslJcouUdR7LGh3GtDs9eBZp+NvoMOjDVeIn1pRjJjzBUPY2sOCP7jCjfaCieGai/GWg8Z+xDXLlzn2PxJ3KKE0FhY48NQ58PY4MdU6yNtHuDWtU84triBtzuBqSGAsT6AqSGIuTmEuSVI2jzA5bPXmS+t4OqIYWkMYW0JY2kOYWmJ4OyMkbGNcHLxNEX7ILaWMLbWMPaWKLbWKPbOOI7uBEX/OFlfCWurH2tjEHN9AGtLFHtHFFdXAo8sx2hsjtnSMo6WkODdbvBhqPLibI/i7U0SUuZZGDjCQv8K5lov+ioX5jofhs2IP093kqRpgPXF08yVVzA3+NHsc2KsdmOs8qA+aMfSEGAkMsO54xeZLixhaQqi2mejr8KBtlLwXxtrPcwUD3Ph5GVGo7NI9xhQ7bOi2mtFc9COfKcZW5Ofkdg0h0dXSBiL2NqDqA9YEH+opeOXCjreUqCptuJVRvEoQuib7CirTHR/pKT9HSlNP++h4WfdyPZrUFUbUVYa6auzom90oqu3o9hvQrHPiKbChrHWiWa/hb4DNjzdUYLyJHF1jrA8Q1CSIihL4WgOot5txVjtIaIU6r41lUaiqixJQ1FYDtxnRbPHiqsjTFyTI6ktkDYWyRjLRBQZzDUe5B/pMVS5CElSJDR5CpYBUtoCGVOZQG8C/SEnfftsuFqCxDUZcqYyUWWWjKVMztKPrzuKtcGDqz1MTJUlZ+rH1xMjKEuQ0OTImEoExQlC0iQFxyBl7whRhZBN7WgO4O2OId2jIaHJMRAYZya3yHBokoA4ibXWg6HCib0xQFyVYTQ6xdXzH/Pw4WM++fgOx2ZPMpGapd8zwuLgEVbG1jl//CKXTl3hV7/6FdeuXWNjY+Mr0+j/Wtl97NixL0XefXEdOXKE69evs7y8zOeff86///u/v+xH9P94vWxu2tKWtm3btgXQW/qqRkdHqamp+b0A/fTp0xfZqF93XT51GcMhB6o9Zir+sZW936qn8u9bSeqLLA2t8fTJU+7eukdElsbVHqbrDSV7vlXPnr+oxdroI2vq58jEUZ48fsJIaJKYOou9Jcihv2tix59WI3lfR0icJKktcPHUFdZnTlDyjJDoy9PzSzUf/Uklba9JsTf68Ymi5Ez9XDx5iZHYBPYuN462IPu/VU/D97tQ7rJgrnFjbQywOLDC0dmTTGXmSRkK1P9rL80/liB5T4dyh5G+A3YisjQXjl9kdWyd4fAE0g/0dL6hQvaBAdlHBpQ7zRgr3ZxYPMXljWusjB/FUu8TvsLfZUWx24xmrxXtQQdT2QUe3n/IlbPXCEpTqPbY0BxwoNpvRXXAjvaAk5J3hCuXrjA9PkdQkUFb4UF7yIn2oAtdpQtdhZu0qcztj+9y+ew1AtIUuhoP+mo3umof+movpoYgCUOJs+sXWRpbw9eTwNYcxFDjF6Lw6gPY2iIkDWWWRo8wEJjA2RbCI4pja41gbghu2jeiFNxjTKTniGny2JqD2FqCONqimyAdwdOTZCgyzXh6AV2VA8U+E7amIJYGP9amEPa2GD5JmrnSCpPZBWxNgRfpE+Z6P8YqL7bNCffq7ElG4jM4OiJoD7kw1Xgx13gwVHvRHXIzEJjk5MpZ+oPj+MUpDFUeNPsdwkT+kAvNPitl/xiHJ9eI6vM4OsP0HbIj3q6j+z013e9pEO/Q4lIECRoSaBtsyA/p6d6tpuUtCc1v9tL4s266tqvpazCjb7aja3Cga3CgbXCiqbah2mdGtd+ErtKOudGDtcmHuztCUJ4iKEsTkWcEK48shaszgv6QE2tTgIgyS7wv/yJtI9lXIChOYahwod5jxd0RJqrOEtPkSGjzJPoKJPryuDrDaHZZ0B20ExQnSejyJPvyxFRZjM0OAtIY1jof2v0OnG0BouoMEUWGmDJLxlgmbSwRU2VwNAfw9cRJ6QtEZRl8ogiB3gRRRZq0vkRMnSWqylJyDjEYnCAgTuJsDmCqcePpFDLRC45BBnxjTGcXGI1OE9Vk6NtrQ3/Qib3BT1CcpOwa4vDwKosDq4zFp/F2R9HsNqPaYcLW6CMsS+PrCzORmWVt6jhFxxDOtiDKj4SFRHOdh5JjmPnyMscXT7GxdIaF8jL9nlGGghP0e8cY9I8zmZxjZewoJ5dOc+HYJZ5/9pwHDx68aBj83Vi6L64vrBtHjhzh3r17XwHoc+fOcerUKdbW1vj888/5j//4j5f9iP4fr5fNTVva0rZt27YAektf1crKCjt27Pi9AP38+XMmJye/8ez88YuEFWlUe83s/VYDB/66kfrvdRGQJCg5h3n65Cn3bn/KUGCcmCZP/b90svvPhamxudqNvSXI8sgRnj59xtrEMQb9Y5iq3ez+y3r2/00D8u0GDJUOXG0hbl37hBuXbjJfWiFtLlH73Q4O/X0zHa8rkG/Xo9hhZCw2zZPHTzi5dBqn3E/POxpq/6UT0RsKet/RIH1fj7M1zCe37vLpnfucXDqNozlA+8+UiN/tQ/yeFsmHetR7rZxY2uCzzz7j3iefkjGVkLyrRfqBUPst+8iEcpeFidQ8z54948mTJ/R7R1HsMm1mXm96ZffZyNkGuP/pQx4+fETRNYJmnw31Xrsw9dxrQ7PPTlCe4fyJy5w9cQ5LpxtzrQ9thQv1fjvaQy50VW58vQnmy6usjK4TU2Xxi5NCUkaVB12lB1O9n6AsTb9vjNHoDIGeOJ6uGEFpGmtLCFO9D3N9gIShSNpUJm0o4euOC4tzHRH80hSWliC29ggFzzhZ6xAeUQxvVxx7SwhbSxBnWwSnKIq7K85UboGiawR3ZwxtpRPJTi3WpgCWRj/W5gBxbZGFoSPknUN4u5NYGgOYar1Y6wOYa3zoK10kTQWmBw4TVGcwtfjR1Trp3aFDvEOLeIeO3o/6sHR7idjSaOqtSPfpEe/rQ/SBkqY3e2l5U0LHOzK0zVYcEj999XbU1Tb66uzoah0oD1hR7DPSV2HHJQrh643h7o7i643hFSewtPrQN7gIiFO4O6LYWwO42qOEZRlCiixBeZagLENYkSUiz+JoDWGocuPsiBBRZYgqs4SVWSKqPDF1nqAkhaHKhbHSJTT9afJE5BmiigwxtQDPHlEMU40XjyhGWJomJEkTUWaI9xU2ATqPvyeBvytGxjpAWJ7B2R7GI4oSUaRJ6ks4uwM4OgMUXMMMh6dI6groDzkwVntwdUQIy9IUHUMMBSeYKy0xmZknrEih3GVBu9+Ouc6DpyPCgG+U9enjHJs9yVh8Fp8ohmaPFdl2I6ZKF/6eGKPRKc4dvcj67HFK7hHcHRHUuy1IPtBhqnAR1+aZLy1xfP4Uc8UlsqYytgYfuoN2lDuM2Br85O0DzJUOk/HkCSkTRBRpHO0hTFVuzHU+Ar1x+j0jjMWmyVsHiPVlKTqGKLtH6PeMUnIOM+AfI28fZDQyxfLwGkdnT3D59DV+9atffakQZWZmhufPn38JkG/cuMGJEydYXl7+ynT6i/rvpaUljh07tgXQfyB62dy0pS1t27ZtC6C39FWdP3+eN9544/8ZoG9evc1oaArpB1p2/1kt+/+qnvafStHstpC39fP8+XOePH7CsbmTpE1FKv+xhT3fqqfhX7uQvqtDsdPIpQ2hqOWTG3dYGl6j5xdqKv6hlcZXuul6XUnPm0qyljKfffYZz5494+NLN3CL4tT/axftP5Ej+rmC3rfU6Cuc3Lp2+8Vr2sRuun6houstNV1vaBD/UofkAz2r479N61idPIp8hxHxu3p63+lD/J4OyfsG8o5hnj59yvPnz1mfOo5mrx35dqOQ1vGhAel2Ix5RlCtnr/Hw/iOOTB7FXOehb78T2UcmZDssyHda0Fe6mB9Y4dTh08yVlghIEjjbo+iq3IKndq8V7SEHefsgs7lFSp4RpPu1RNV5XKIY+go32kMuDLVe/JIUJfcoWcsAnq44AUmKiDqHvTWCvtKDqzuOtzNORJYhbSzhbA/j6ggTUWYIybOY6/3E9UVCiizWpgBRdQFXRxRHaxh3Z4SYJodbFKPoGyOmLWJpCuDqjOJsC2NrCmBtCeIUCRnD5eAIHmkCXa0bbbUD6V4jbe/IkO0zINujw9zhImCIo6q20LtHS9eOPkQfKml/W0b7O1JE78kxtDpwK8Ooax0oDlnQVNnRVttRV9pR7DOhq3EQVCWJGwq4uqI4OyI4RXE8PQl8vWl8PQm83QliSiF/2S9JEZClCUjT+CVJgvIMQVkaX4/Q9OfuihOQJIUzqXDm6Y2hqbHi6oziaAnh600Q3iwxCUjShORpouocAYkQPxeSpQhIUgTECUKSNGFFmogiJ2RGK7NEVRlyjiFifXnsrUFcbWEiiiwJdZ6YJk/OMsBgYJKJ5CyxvhzmGg/GGjfO1ggheYasqcxEao6loVWmcgsEZSn0B12o9pgx17pxtoUoOoaZHVigGBtgKjOPvzeJapcF5Q7B2+xqD1F2DXP17HVOr55lJDyBoy2Ibp8d+YcGNHutBLpjzOQXOHF4g9OrZ8gYS9ibg+grHcg/MqI/5CCpzTOTP8zq2DqTqXniqhyejgiWOi+6gw4sdV4KjmEmk7OUXEMktUUyhhJBSRKfKIqzOUBKX3xhKQn2xDDWOjG3uEgbisQ1wqQ8qsoQV2exNvgxVDmw1HuJyFMUnMMM+MbImvoZ8I8z4B1lyDdG2T3CTG6R88cu8vDBoxeLhNPT03z22WdfKkP5r5XdCwsLPHny5CsA/ezZMyYmJjh16hSff/45//mf//myH9H/4/WyuWlLW9q2bdsWQG/pq7p79y7f//73/58B+unTZ2ysnKHzdQUH/q6Bqn9qpe01KV2vy1ke+216x6MHjwgrUtT9cwf1/9pNy48ktP9UjqPFz+PHT17ctz59nM7X5bS9JqP9J1I6Xpcje1/H+WPnX9xz7fx11DvNiN5U0fm6EtHPFXS/pWI4OPFbsL/2Ca1vioUIuzfVdP9CRcfrMpytQW5cvcmzZ8+4c/Mu7k5hmib9wEDv21q63lSh+EjH/MAy549d5NbV2yT78thbQhgq3QJsv6NF9IaarHWA+eJhVieOUnQMEVFl8HTFMFS5ke8wIXpTjbszwqBvjInkLHFNnrSxTFSTx9sTQ3vQieRDA7oKFwltjpJ7mJg6j3hPHxlDmZgmv5mW4cRY48HRFialLxFV5fB1xwnJM+Ssg/h7Ejg7IjjawhhrvXi6YoQVWdydUcET25cnokoTUiawtPrRHHIg32ehr9pOX6UNxQEjfTVW7OIAFpEL6UEDHdvVtL6roOM9OV3b1bS/J6dnlwqLxItbFUBZbUWyz4R8nwnFQTPK/RZa35FiqHeTtpfJu4ewtYcxNwWwd0Sxt0VwdMQF8BenGAxNkjEP4BbF8XQncHZG8XQm8HQl8PYmCCuyZKwDBKRpPJ1RIYO5R7jXJ07glwgV1TF1Dt/mn3l7knh7EvjFaQLSDAFpmpi2SNogFPT4exL4eoQGPr84TVCSIajIoW+1U3KNkDQW8IqEDwwBcYqIIktIniFjEUB1IjlDVJ3D0RLCWO3B2RIkLE8T1xYYiUxzbP4kM8VFAuIExio3hoNODFUu7M1BMtYBVsaOcu3cdaZzh/F0RNHstWOodNG3z4q13kdmoAlMAAAgAElEQVTGWObSqSvcuHKT4fAErrYIfQds6PY7UO8yY6v3Mxyc4NzRi5w5ehZzuxNnWxhDlQvlLguaPVYCPXEmk7McmTjK0vARivZBPG1hbE1+DIdcaPZaSetLTKXmGAqOkzYWKdgHiakyeLuiWOt8BHsTxDU5cpZ+ItI0vq4oSV3+RbV3QpcnIk8RV+ewNfsxVjqx1nuJyDOUnENCEocmR0Kbw9kaom+/DcV2I6ZqN57uENYONxlTmZxlEE9nBN0hO4qP9Gj32XC0Bkn0CX7qAf8YRecQ/Z5Ryu4RRsJTLJSXuXTqCg8+ffgilecLWF5bW+POnTtMTU19BZC/mFDPzs5+ZTr9xTUyMsKZM2e2APoPRC+bm7a0pW3btm0B9Ja+ql//+tf87d/+7f8VQE9PT7+Yxn6tjePkRTrfVNL4Si9NP+ym4zUp0g/03Lxy87cRdfcfYqhw0PZjCc3/Jqb1R2LafixjMj37Jb91SJah/edCxnP7a2KaftiLpd7Dp3fv8/y5EIlXdo8ge1+P7H0dojeUNL/Si+gNJQsDy9y8dptnz54xk1+k/RcSDBVOFNtNtP5YQsM/i0gbihweXOXyxlXWp04QlqXwiKKY672I39VT9U+tOFqCDAYmmC8vsziwTME5REyTw9sVw1jjpuafO5F/qCelLzHgG2M0Nk3W3E/JNUq8r4CnO4bo50q63lLj64qR0BYpOoYJyYSlxJJrhLgmh3K3GelHRrSHnPi7EyS1BcLyNLL9WgquQVLGAvo6O8q9JqQfGZDtMaKrdWBq8qCuNOHs8eNTRdDWm+n8SE3LL6U0vymm9S0p3TtU9OxUoao2EjRGsEm8KA4a6fpIh3iHDsluPYq9Rvoq7dg7QkwWFygHR7G1hTDWCVYPS6MfS2MAW2uYkCLD6tQxhiNTONpiOFoi2JrDWFsj2Noj2DsiyCqNzA+skDSWcLRFsLdFsbdFcXREcXUmcHXGiBtKjMVniCizODvCQpZ0RwR3Zxx3VwJPb4qsbZCR6BQJXYGQIotLFMctiuHpiuPtTeETpwTvdXyWlKFMUJbC1RHF0yU0BAYkSRLaEotDa8zkDxNVZ3B1RHC2hrC3hPBLUoTkGQrOYTZWz+JSB/D2xLHU+bA2BjBVe3G0holp8kznF/n40g3my8u4OqLoK5yY6/zoKhyY633EtXlOLp3m1rVPmMkt4WoLo9lnxVTrxVDpwlDpJGMsceH4Ja6cvcZYdBpnawhzjQfdIQe6gw6sjT6GAhOsz5wUvMHOYfxdMeyNgRc+6YA4wXhimonELEXHMBlzP+pqA/7uONYGP45mP1FVjpJjiKg6Q6A7SlJfILWZsBFVZQiI40QUaTztYUw1Lqz1PmKqLAXbIBljiaQ2R8pQxCuK0LffjvxDPcYqF3FVjqyxTNpUomgbINCbwFDhRPmRAfVuK46WIBFZiqylTMk1TEKdw90RRrPLimqnCUu1C293jIy1TNE5hKbWSNpYwtESwFTtxlDhxLWZ+FFyDZE1lRnwjlFyjzDoG2UsOs369HFuXrnFk8dPeHj/EQ/vP+Lp02c8e/aMzz///EXG88WLF78WoL+o9J6YmPjKdPqLa2Jigo2NjS2A/gPRy+amLW1p27ZtWwC9pa/qN7/5Dd/61rf+rwB6YWGBBw8efOP5RHKG9tckAhz/sIf6H3RhrnV/abJ8auk0kve0iN/to+01KdXfaaflVTHLw2s8fviY58+fc+PiDcy1XnSH7Mg+1FP3PRGH/qGZkDzJ+vRxPr1zn3uffEpCk8PVEcZa56X7DSV7/6Ie3UEbw+FJlgZXuXXtE8YTM6irjLg7whirXez7qwZEb6hI64sM+sdZ7F9haWSNsneEpLaArydBww+6qf2eCF93jKS2QL93jInEDJPpOcqeUZL6IoqPDNT8c4dQbNIVJ9lXIGvpZ8A/xkh0ioy1hK7KTuOrYrp+qUK+S4++xo6pyYWl1UPUlCKgjdFXY6bhtR6aftZN40+6aP2FmJ6PlEj3atB32Ei40rhkPro+1CB6V4XofTXd72uQ7TSgrbSRMOU5unSSkdQUxnov2goX2grXZjmKW2ia05e5duEGC4Mr2NsiGGt9mGr9GGu8Ql50U4CErsT5E5cYj81ibQ5hqvNjqg9gavBjaQ5ibQqSMpXZWDlLyTWKszWCpT4gZEk3h7C3RrB3Rik4Rog4khScgwRkKdyiOLZW4dwliuMSxRkMT7Eydoy8bZCkVqi+drRFcXXEcHZECSqyzJVXWBlfJ6bKERAn8HYJYO3ujuHtSZLQlzm6cIq16eN4e2M42yK42sM4WkI4WsP4ZGkG/ROcP3mJtenjOFoiQtFMSxBbs1AuE1RkODy8zvULN1gcOoLoQyX6CgfW5gC2Jj/6SjchcZLTa+e4dPoK4/E5fN0JTDVeDNVuLLVeTFUu0qYyJxZOcXx+g5x1gJAig7MliLHKjbHSjaM5SL9/lNn8YUYiM6QMJRLaIiFpCnuTH3ONl5BUqMlOGcpEFGkS2iIJbYG4Jk9YniYoThKWJAn0JrDV+3E0BYmr86SNJZSVeiGJQ1fE3xtHf8iO8iMj5lofUU2WpLZAylAiaykTkiaxNviQfWhAudOArclPVJ4mZ+3fhOwiQUkSwyEn8u0G9AdtBHqi5Mwl0roCaVOJnHUA/2ZhkKHKibMtREpfJKXLk7P2U3QOk7MOEBTHcbUJMXppfYlEX46UvkDO3E/eMYi20UxYmiKlK9DvH2cwOE5SmyeqzBCSpYiqhQ8CM7kFzq5f4NO7D3j08BE3Lt/g6PQJjowf4+zaea5sXOXRw0cvJsq3b9/m6NGj3wjQx44dY2xs7GvPvlg+/MID/Zvf/OZlP6L/x+tlc9OWtrRt27YtgN7SV/UFQP9uVvM3XcvLy9y9e/drz549e0ZImhTa0N5RU/OdDvb9dT2OpgAXjl/i2TMh43kqvYC90Y+x2k3zq70c+JtGOl+XMx6fZmPlLM+ePePc+gViyizeriiyjwwc+JtGar/bQUKbZTg4zsbKWe7cvMtgYJykroBbFKH6/7Rz8G9bcLaGSGoLlL2jXN64yuroOi6Jn4gqTe87Gvb8ZT3a/TZ8oijxvjwD/nFOLm0wnpohZ+/HUG1n39810PxTCbIdevoqrZjqnaQcWUqxAUKGGH31Zg5+p4nK7zdT+8N2Wt7sRfS+DGWlnkK8RDZYxKeJ0PK6mNafS2h5XUb7mwokH+rQHDAznp3mwpmLLI4sY6p1o9hlRr7bgnK3UG+tr3QzHJpkbnae1dl1HK0hdAccqPYJi4Z9h5wYKl1kzP3cu3Of4/Mb2JuCaA866DvoQHvQgaHKi6HGQ8rUz82rt1kYOIKzNYKxxou+0o2+2oO5LoCp3k/eNszVc9eYKy4RUWVxd8Yw1/kw1fmx1AewtUQouUfZWDnPWGyGtKFEUl/E2RHdnEyHcHbGGE3NcWT6GJYOD/7eOCF5mogqh6MtjL05TECWYX5wmZWxdSKKDP7eBL6eON6eON6eJK7OOEl9iWOLGywOHcHTtVmD3RnDI4rgbAvh60kwFJ7k3PGLzBQO4+tJYK3342wN4WgLY2v04+6Msjp+lPPHLzEcnMIvTmKu9WJrDgjxeQ0+vN0JTi6d4cTiaTKmfoKyFPL9enSHHNibAziagyQNRRYHVpnOLpLY9DaH5Wlc7REstV58PXEK9iFK7mEh2UKZJarKbd6XwdcTxy9OEFNmcHcIdd4xdZZEX064V5El3pcjLE+hr3Kj3mXGWu8jrsoRVwvwHNfkiKtzeDojqHaZkW0XlvFiqgxJXZG4OoeuzkpInsZS70Ox3YT2gB2/RIjBi6mzpPRFspYSUWUaa50XS4MXnyhCTJkWLBqm8mZaR5mEOo+nM0JYkSJvGySmyZLRFUlsWjnytgHSxhJJQ4EB/zhD4QkKziE8nUKiR1yTpWAbYCg4zlRqjrniErPFw6RNJSx1XhzNQbyiCBljiYQjxcLwCicWNxhPzhFRZdAdcGCocOEVRSh7Rjg+d5JHDx9x7/Y9zqyfZ66wyEh4ikHvKMsjaxydOs7545f4+NKNFwD99OlTZmdnvxGgL126xPDw8DcC9NLSEisrK1sA/Qeil81NW9rStm3btgB6S1+vv/zLv3wBuP/dtb6+zq1bt7727OGDR2SMZTyiCG2vSaj6pzYO/n0Lns4wE4lp7n0iWC+WhtZIGQqYatwc+nYzB/6uBc1eK0ltnsnULE8eP+Ha+euMRCZJ60s0vSpm77ca6PmlGq8oQkSRZnn4CPfu3GNhYJmydwjVXhM7/6yK2u+1I9+lR1NhxlBrZ3p0hsmhabx9AVQ1Bvb8VQ17/q6WmlfaaPl5N21vibF0u5iemGYwO0TIFKP+R11Uf7+dhh/10PIzCV1vK9HXODi1vsH1q9c5ubKBodpB79taJO/okL6rQ77dgHafldWJYzx//pxb1z/B0x1DtsOI7AMTsg+NyHeYUO+1MhKe4unTp9y8cgtfTxzlZlKHcqcFxW4LfftsFOxDPLj/kMnBaewtPnQVLtR7baj22NHsc6A94CRlLHP7+h0unb5CUl/E3SUkOvQdcgiFK5WCv/T02gWOzpyg5BwhYSji601hrPVhqHJjaQyScwyzNLLGdG6BlE7IAo5rC7g6o5gb/DhaQwxHphhPztLvGyOsyBKUJIlpcsTUeaxNQfySNDPFw4wnZoiq8ujq7Fhb/Ph7E0SUWbzdcRL6EmvTJxiJTAte5Z44vu4kPlEMX/cXfugpTh4+Q8kzirszirtTsGN4u2J4O6N4umIcHjrC0flTJPQlvN0JvN1xHK0hYTmwPUpYluLw2Brz/StEVDn84iT+3hQeUQxHawR/b5KMschIZJKia5iAJC1MeCUptDU2zI0+IR+5r0BIliIkSRGRZ4U0DulmTJ0sQ1Cawd4cRHvQib1J8EBHFBki8jRhRYaoIoe/J4HukB3lTjOOZj+RL+5RZIgqc8Q1gj9dt9+OvsKJrytGRJkhpsoK4KwpCAudnRGsDX6C4gQxRZZEX56EOktMnSWpL2Jt92Jt8RJRZil6hinahwjLU8SUwhJpxlgkbSyTMRQZDk0ylZqn5BjC3REm0JMgrs6RNpbo944xlZ3nyORRZvKLpIxFnM0BrPVePO1hEpo8C+Vlzh+/xInFDSbT8yR0eYwVTvQHHThbgmRMZdamj/PpnU85Mb/BeHIGf28cXaUT1S4z/p44w6EJji+cYm5ykcnCDHnLAL7OGMZKF4YK5+bS4iJr08dYGVljsX+FsegU/d5Ryq4RYYkwMM5s/jCrY0c5f/QiV89e47PPPvuSDWNmZuZrAfnu3bsMDg5+I0Cvrq6+aCLcAuiXr5fNTVva0rZt27YAektfr29/+9t8+umnvxegT5w4wbVr17727MnjJyyUl4koU1T+YytV/9hCww+6cbaGiCgz3Lx6i4cPH3L66FkGgqN0va1m5/9XRcU/tdD7ngb5Hj2u3hBra+scXlwiHyrSV2di+59VsPPPK6n+1xYaf9pF2y96SfnTzM/PMzU+TcqVpe6VTg7+YwN13++g+Se9dPxchrc3zLVr17h9+zazk/NoDppo+6mQ1NH5hpLed/rQHrBz7dx1nj9/zuPHj0n0Fej5pYbut/roekuD+B0d0u1GlkbWXtyTt/Qj/UCP+B0d4nd1SN/TIttupN83zrNnz3j06AlF+xCavVbkHxmRvm9Ett2IYoeZpL7I3Tv3efjgEUOhCZwdEUzVHtS7Lch3WFDvteKXpji7fp7rl26StOdx9YTwixOY6nz0bQJ0UJpgtnCYtanjDIcnyTuGSOiL+MVJdNUeDNUuouocZd8Y48lZCvZBEtoCWesAcW1RmKA2BSi6hkmbhObEnG2QiFz42jxj6SeiyOIWxRiNz5A2lfB2xUgbS4RkqRcQmDKVSfTlWRw5QtJYxt4WJijLYG52YWxwEuhJkugrMBScYml0nZgmj6MtirMtQkiWxdebJCBOElPnWBg8wnz/CmF5FldnFNcmQAclSSLyNBlTP1PZBUai0/h743h7E3i6E7hFMbzdcUKyNCl9kYxZ+ADg700I8NyTwN+b3FwaTOHfjOLziOL4N1/f35MkKElhbvZibHBhafSiPejE2R4WEjhkwn0hSUr4ACFOY67zYal34+1KEJalCckywsRdkSGizBIUp3C2hYhuQmxEkSG8mREdU+eJq/PE1ELe80BwgrJ7lKgqQ1iRJq7OE9fkSekKFN0jjMVmmM4tUrQPEpIlX2Qyp3QFsuZBioEBSrEh5krLZK0lXG0hbPVenJv2ifH4LBdOXubMkXPMDywTU2cw13owVrmx1vsIy9Osjq9z7/Y9rp67znh8mpA4ianGje6ADXtjgLx9gLWp43xy4w7nTlyi7Bwm0CPYOPQH7AS644zFpzk6f4KV0TVWx9YouYYJ9CZxtYdwNAdI6QqMJ2eZTs8xHJokrEniFoeE6b0qQ0InTNxL7hHytgHCshT+3iQl5xD93lEG/GPkzGUGAkICx0R8luWRdU4dPsMnN+58aZFwbm6Oubm5rwXkZ8+e0d/f/40AfeTIEcbGxrYA+g9EL5ubtrSlbdu2bQH0lr5er776KpcvX/4SEH/22Wc8efKEBw8ecO/ePW7fvs3a2hpHjx7l4sWLnDt3jo2NDU6cOMH6+jqrq6uM9o+hqtTz3p/s58P/dYhD32mk7kcdiN6TMT4yzvz8PIsLi5Tig9T8Syt7/rqGyu+20vzjHlp+KmYwNsLNmze5c+cOt27extkSoPGVblr+TUz7T2SIXpdhbw7wcNPv+Pz5c0aik7T/VE7nz+S0bqZ1SN/XfymtoxgYpPUnPXS9qaLzZzI631TS+3YfE7+zuLg2eQz1LjPSDwx0v9VH91tqRL/oI6kr8eiR8HqnDp/B0ezHVO1BtcuM5F0d4re1ONtCnD9xiU/v3OfCiUsk+nL4exPYGgPId1iQvK/HUOlmOrvA8bkNThw+w1BgnKS+RKA3ianei3qPBWOVi7xtgKnUAvPFwwT7kvgVMZL6En5xAu0hJ/bmAH5xnIJtiOHwFFlzP1lzmX73GAldAUdrkIgyjVsUJShJkbcPkTWWiahy5OyDFFzDhKQpCq5hAtIUpjo/MXWejKlMVJElps4x6Bun4BpmJDZNUJbGVOvH3hIipikQ0whWhbx1kJn8YaZzi3h7klgbQzhaQjjbI7i6Q1g7vKRN/SyPrTGRWMDdEcXRGRW80q1B3B1RoqocaWM/U5k58vZhPKIYro44zg7B0+zsjAoZyQrBxxuUpvB0RHB1xXB3xnBtwrOvN46/O4GzM4ynI4y/J4m3J46nK4GvexOkexP4exN4eoQIOt/mPb6eBAFJkpA0iVsUpq/ORspQougcJqrOEugVADy4uXCY6CuSs/QzFJpgMDBO2lwmKE0JGc4KwcJRsA8zk19krrQktPCphcXTiCJDXJ0nqSswmV5gY/UsK2NHSeuLeDrDuNrCuFpChOUpyp4RTi2f5ebVWywMrBCSp7A1CkuCxho3XlGEuf5lbl+/w4WzF/FpooRkSUxVbqwNXsxVbuJ9WZaGV7l39z6XTl9lNDaNryuKtd6DsdqFsyVI0T3M+uxxTi6e5sjEOoO+MUKyJF5RBEutm4g8xXh8muncIqPRKQZ8Y4KNw1TaTD/JEFGk6feNUnINEVdlCYoT5B2DFJ3CNDz+RTuhNIGrNYi1wYdXFCGuzWIVeciayhRsQwTFCSx1XlQ7TRgOObC3+EnriuQtA0L2s22Afs8Y/e5hBgPjDPrHWRld5+a12y+iLX83iWN2dva/Begvlg7/67W8vMzU1BTPnj172Y/mLbEF0Fv6A9HLfiNs6eVrcnKS1tZWKioq2L59O6+//jp/9Ed/xJ/8yZ/wx3/8x+zcuZPJyUkmJyeZmZlhYWGB5eVljhw5wvz8PPPz85w5c4YLFy5w+fJlrl+/zq1bt7hz5w7379/H0xmk/l9E1H+vk5Yf9tL2IzEpQ+FLcL44coSWH0tofrWXpld6aP2RGPmHRm5e/a095PzJS/S+o6HjNSnN/yam7cdSOn+m5PDQ6m8j6q7cwlDhQvx2Hx2vK+h4TUb7T2Qk+nIv0kLu3rqLudFN93tKlDvMdL2pou0ncgwVDq6cucqTx0948OkDis5hPF0RbA0BVLvNdP1cifgdLVPZeTZWz3H31j0WikukDCX8vSmsTQFkH+oRva4gpS8ynZnn6PQJVsbX6fePkzaW8PcmMdZ4EP1ChWszt3ciOctkepaRyBQDgQlShhKerhiqvVZ0h5xEFUJxxHBwgrA6RVAbp983RlJbxNkSxFTrxVInJC3kbIPkrIMU7ENMpOYY8I6R0hawNQfRHXJhbwkTVefIWYfImPsZi88wW1xiMDSBsz2CqdqLsdqLsy1MrK9AzjzIUGCCk4unGU/O4WiNYK73Y6r1YKrx4WoPE1FmKbhGOLF4moHgFI6WELbmoJDU0RzE2hzE3OBF22BnMjNHUlfC3hrE3hLC2hzC3hzG2RrG3RElKE2TtfYTkKQ3s6qjODcn1G5RDI8oRlSdJ2vuJ6HNC3aN9giuzhiu9ghuUQKfOEnaLIBVwTNCWi9Myz2i2IsJc1ieYSQyxXR2gaHwFHnHIFFVdhOeEwSlKdKmMrOlRSLWBP2+URK6AjFNHr8kSUCaJiRNMxSa4tLGFVbHj5IylAhIkgQlScEzLE2RMZVZnTjO7Y/vcGTquOCXbg3h6Yxibwrgbg8yFp3mytlrfHLzLoeH1oSlwEYf7s4wljovvq44c8Ul7t6+x+UzV5lMzxMUJ7HV+3A2B3E0BYhrsqyMrnPp1GVWJ45Rcg+iqjTgEUWxNvgJ9cYZDIwyVzrMVHae4dAEWVOZlE7IXA6rhH9P2TfKYGCMhKZITJUhYyySt/aTNZeE+DldgZgqh687hqM5gKczLHxbYRkgpS9StA8Qkaew1nlQ77Gg3WfD2RoQ/NK2fkrOIRKaHL6uONp9NmQf6lHtsWCr95HSFyg6BlFV68layng6whgqBJuHrtKBvydO1iKU/Az4Ril7RjctHMNMpWc5dXiDOzfufCkV6HeTOE6fPv2NHujHjx8zPDzMp59++rXnCwsLrK6ucvv27Zf9uN4SWwC9pT8Qvew3wpZevs6cOcPo6CiHDx/m1KlTXL9+nR07djA6Ovp7LRxXr17l5MmT33h+9/Y9FNv1NP1QTOMPumn6QTetr0k5Nvfbv/P06VPc7VE6Xxdgt/nVHhpfERPXZL80/R7wjaHcZUa100TXL9Q0vtKN/CMDH1+5+WLhcXVsHWdLEEudh769Nlp/LKXpB2LGU3NcOX2Vp0+fcWnjMoHeGOpKM/YmP4rtRqq/005EkWY2v8iZI+e5/fEdRsPTpI1lgr1JbA1eqv+pA3Ode/MX9gLH506xMnaM4dAkGUOJkDRF60/kSD/QE1NlKdqHmEwKS1Pz5WUGAhNkrf2od1vpfbsPR0uIqFKA45HIFAuby1UjoSm8nVGUu61odttwdUReQHTRM0TCneHw8BpF+xCmGg/qTdB2tUeJqfPkrIMsj65z4cRlxhNzWBsC6PYJi4T6Cjeu1jAhaZqJxBwfX7rJRGoOW2MAbaUbQ6UHfZUbQ5Ube0uIjLGfs0fP0+8ew1TnxVTrwVjrxVTnwVTnxdoUJKLKcnhklYyxjKUpgKUpgLnBh7khgLUpjK0lRESTw6MNkjH3E5SksTcHsTUFsbUIAO3qjJJzDrM4eITh8CRZUz/eniS25iCOVgGQfb1JhmMzrE0eYyI1R79nlKShuLlQ+Fu4Xh49yonDpxkKTZAxlcmYyoSVWbybk+e8bZiz6xfYWD1HylgioswKHmRVhkBvkogizVR2kY8v3eT44gbSfRp8PXEC4iQBcQJna5C8dZCN1XPcuHqL1bE1/L1xYaGxO463M4qjRQDjG1ducfnMNcELrswIk9auGJ6OKP7eODOFRa5dvMHa5HGKLgEuA70JnC1B/D0JctYyc6XDLAysMB6fEZb6Nqu/w7I0EUWakmtY+D9o7iepy5PUFsgYS6iqdUSVaeLqDEl9kagijaMxgEcUJWUokNaXhKQYc5moIoOrJYh2nxX1bguO5hCJvhw5c5msqfwiRtFU6Ub6vg7ZhwZsjX6yphIpQ4mUrkjeJqRsGKtcKHeY0R2wExDHiamyZEwlSu4RsptJHLZ6H67WIL5uweOdNhYpuUbIWQfQNVkISZIEZUJFed42KKRyeEcp2IeEKbZrmNHoFEsjRzYLix7y+NFj7t99wIN7D188D77Y4/hiUfCbkjbu37/P5OQkV65c+drz2dlZzp8/z7lz517243pLbAH0lv5A9LLfCFv6w1RzczOFQuH3AvSNGzc4evToN56fWDyN7AMd0veFIpL673ch+oWam1d/mwN96+ptnG1C7qtyl5mWH4mp+U4nw6FJ7t2+x/Pnz3n08DFFxxD+njiWBi+972qp+IcW7I1+FvtX+Piy8POWho+QMgixW/pKJxXfbkH+gZ6yZ5TZ/CIfX7zBtfPX6feNYGpx4BcnqPu+iI6fyoiqMpQcw0xn5vn4sgA1I9EpsrZ+JB/oqft+F652AWYL9kFmC0tc2rjM4aEVxuIzOFsCtPxYhmaPbbNlLkPeMsD69HEuHL/M6thRctYykg8NyD/Qoz1gx90WJqrMUnKPcPX8x1w7/zFT+UX0FS4U203Id5rp22/H2RoiIE6yPLbO+Mg4h0fXMNV6Ue00o95jRbXHhvaAE3O9nwHfOHdv32W28P+z957Pcd/3vS//lSST8zDJg8zkzD0z58Sx49hKbMuSLNuSLNlqVCEp9gKi97q7wPbee++9AFj03gGikAQIAgTATsrJSU5e58EPgsRr69j33slIk4v3zD4gv7/lsO3uez+/9+f1HqT7jI72DxUCieOk8JCc1uIShdlY3iRtLdBzTof4lJquT1QC6u6UFrvWaEwAACAASURBVOk5HW5xlNXZdVKWAoYaJ7ILJsRnNIhPa5GeN9B9wYhfmWBlZo2it4+ALI650YPsglHA2R0uHMaNeVbnb6JtMxDXZ/HJYhjqnMguGlFWWNFV2SmFBlmaWqXgLRPVpAmpErglIbTX7CivWbG1hxgrzbAwvkxQmcAtEnLNPmkcS7MbbaWDqC7L6uw6E4Vp3OIwlmaBkGFt8mE+XOQbSo5x68YmveFhgYpRLcQ3TIfM76AqwY3ZNVbm1kiY89hafdS804apzoWx3omx1kHCmGVrfYuJwgx+WQxLsw9zgwtjjQNLowdnV4iSv5+p/hlyrl6cHUJlt73Fj6lOyIAHVQlyzhIRTQZfTxR7sw9HewBb66GZb/bhlUVxisJorlkwVNsFAkdrAFurH0eHcK2u2o7oEzUd78tQXBIm0ULDX4DWT0RYm92oLhloeKOLhjdEKC+ZsXcIeWpXe0Bo+2v2CU2Z78sQfaxCW2HB0ebD0x3B1xPB1RXC2R5AccGA+ooJS5Mbc4ObgCyKWxzGK4kIJrcjiKnOgaMrQFCVIKbN4BULefqgIkFAFiOsFu6OpC15SsFBkqYczo4gfmmEoCJOVJvB2GEj5cgz0TtNOT5CzJAV/v5rHbglIfKuXuaHltjb3uPRo8fsbe+xMLpMX3iIsdwki+Mr3L6xxbNnz44e//zP/8zm5iaJROJrlwjL5TIzMzO/97xQKLC7u8v8/Pw3/dZ8LI4N9LG+JfqmXwjH+naqqakJo9H4Bw307u4uo6OjX3s+kplAfdVM96caKn7UyJn/VkHDLzuZKM18yXhe38bbHcbc4KLxzQ4+++8VXPlhLWFVkpG0wIJ+9PAxfeFhAoo4yismzvz365z7bhWGWgcRdZKR1LgwXZ7bIO/uxSeNcu0nTZz+b1eRntViaxa4tjODizy8/5CJ0jTqJj3dn2n59P+6Stt7PaivCFnToCLBnVt32dnaZaY8j08e4+pL9VS/2kbnSQXKyyYMdU6K3n4ePXzEztYuA4kxmt7ppub1dup+2UnHe3LkFwyYG1xsLN/m6dOnLI4tIzqlov4NEQ1vdtH4poj292VITmsox0d59uwZc8NLdH+mpflXYprfEWgczb/poeMDOTFdmoODB5ikh7GS9xS0/lpG2yHqruOkEm93jJ3tPSYKUxjqhAlux0mlYKI/VCA5pcUrjXF3a4fp8hx+aQRrqw/ZBQOdH6kQn1bTfUZHWJvlzsZd5ocXyThKeLqjmJu8yC8YEZ/SorhsJm0tcGNmndHcJAlTnoQxh7cnir7WieyiAV2lnb7oMGOFKYq+AbouyPDJY4eItzCKS2YcnUEm+ufojw4RUgk/7+wM4hZHCCrjGGpcAqJuao2Mo/eQbRzE3iaYSGuLF5cozEhuisXxFaL6tICJaz3ExzV7sbX6iOky3JhdZ6I0i1scEXLMNQ7h12r14xFHyTqLLE7cIOfuE5b+GtyY6t20fCTG3i60QeacJbLOXvzyOOYmN5ZGt0DmaBBiIUFFHL8ijrHBhbnOdTglFoy8pUFYtrQ0uFFcNtJ5SKmwNXtxtHgPzb4He6sPbaWN1nckNP9KguqKCVurB9vhn8XZLizYqS6b6PpAjuS0Gl2VDVuLF2d7AGd7AFdnAMklJT3ntSgvGbC3ePGKwrg6/Dhavbg6A/i6I3jFESyNblyiEAljloQph7srhFcUxiuN4BEJbYQRTYqCp5fe0CBJc56ANIpTFMDXHSUgj5NxlBjNTTJRmmYwMUrSmsfW6EFfZcXZHiRlzTOen2ZzdYv54UVGcxN4e6Jor1mRnzdga/KS9fZz68YmU5PTDOZHKPr6D6f2OlSXTPh6opTjo9y6scnBvfvcmF6lHB0hac4T1aXIOkoMpyeYLi+wMrXKwb37L+Sgb968STKZ/L055+3tbcbHxymXy19roL/IUh/rm9c37ZuOdawTJ04cG+hj/X7JZDIkEskfNNAHBwcMDAx87fnSxApBeZz296Wc/dvrnPvOdXo+0xBRp9hYFOgd9/fuU44M4xWHOfedKj7779do/003liYPYVWC3Tv3ePbsGRtLt+kLD9L2Gwmf/NdL1L/RhfKSCVOdk4y9yJMnT3n86DEr0+v4eqJ89j8quf6jJto/kKG4oEdbYWVhdFlA7B08wCSzUPfzDq79YwM1P2uj9TdSxKeUeLvDPLgvLAneXt1E9ImaqldaqXyllerX2ml6W0z3aQ03ZlaF3PWtHeTnDUI1+M/aqXmtjdqfd9DyTg+l4MBRNltz3ULj22Ia3uyi9hedNP5KTPOve4jpsjx69Ig763ewtvrpOaen/QM5jW8JpI6W9wSM3cH+fbZv3kV0WYalyYPyipn29+W0viul/aQCf0+M7dt32bu7T9HbT0ARF0zvJROdHyoRfaImpIqzNLHC6swaA7FRkuYc3p4YpkYv3Z9p6TlvIGbOMRAfZSg5TtKcJ2nJEzfm8EgiaCqtqCtslIKDpCx5YsYccWMOnzRKWJMiZshgPqywHivMENalsbX6iapTdF2SY2/3ElYn8UljpOxCxbVfGkNTYcUtieCXJ3CLQ7g6gyTNOSZKM4wXp7G1+VFfs6KvdeHriR3mbuNk7SVWptYo+gcwN3rR1whRDkujh4A8RlibIufuZSg1RlCVwFDjQl8llLDoKu1YmoWykqg+hbc7jLXVi67GibHOhb7Wib7GSdtpKdpqC8YaBz3nDGiuWzE3ODHXujDVujDWuw8npE66PlbS9p4c5WGVt7XRg7nBjbnJg63Fh6HagfiUBtl5PeZGD5YGD5ZG4WFr9eFo82Gqd6OpEEgUIXUCe5sPS5NbMM8dQRythxzn7ggpW4GULU9QkcDZ5j9E3fnxiENYO1341CH6w8Pk3L1EdOkjBrRbFCSmSzOen2Kqb5aJ3mmS5jzOzgCmBvfR3ZhybIRbNzbZXN1iLDeFtzuKod6J8jB+kTLnWJ1Z5/7+fXbv3KPkH8DR4Udx0Yj6sglrs5eCr5/NtS0O9g5YnVkXas+bPCgvm9BV2ggpk4zmppgfXhQ43c4shmYbHlEYW5MXW4uXjK1IX3iQoZTwfzJlyRPTZ4hoEsR0GYKKBCl7geHkGKOZSZYnb7C/e3AU4/jtb3/L2toaxWKRvb293zHIm5ubzM3Nkc/n/48G+l/+5V++6bfmY3FsoI/1LdE3/UI41rdTNpuNurq6P2igHz9+TKlU+trz+/sPGE6Oc/0nTZz5b9e4/nIz0rNaNBUW5keWjq67u7mDs93PJ//1Etd+1ED7uz30fKbBUGt/4YNwfnSJih83cvF7tVT/tIXWX0to+00PvYHBo19r/94+3aeVXP5hLVd+UE/Vy80CGeOykYPD2u8HDx5S+5sWKn7URMU/NVDxowaqXmmh5W0JcyOLQmzk4SPcoiB1r3dS9WorlS+3UPlKK3Wvd5B3C7SORw8fEdNnEH2ioe09GbU/66D6Z23U/7KLkCrJ48ePefL4CX3BQYy1LhRXTXScVFD/SxGNb4hwdQXZ2b7H06dPGS9OC611TV5UV6y0viun5dc9WFt8zI8ssbm2xdLkKso6HW6xkEmVXTDQcVKOpcVL0d/PaHaCicIMBf8AicNcrKneTfcZLT5plKAyTtKap+QfIGHMknGUiJvyQlyiyk7CnMXRKVAhBKqEYE6yzhIRTQpfd4S+8ADWZj/qa8ICWdyQJaxOEtYkybv76QsNM5QYw9TgRn7JhKHOjV8WR1VnwN7lpxQYZGF0mbyvH0ONgJBTXDRhbfYRUCRJmHL0hYaYHVokqk8fLgoKRA/1VQu2Fj9RbYq0vUjaXsTeHkB93Y72ugPNdZtQ3V3pwN4awNbmx3xI3NBV2tFV2tFU2AWOdJUDfZXjkAJhQFtlO6Rw2NFW2jDWujA3uun6TEH7RzI0FVYchwZTX+PAWOsU2gCb3FgaPZjqnHi7I0T1aSE7X+fC3ODG2uTF2uTG1RUipEqSdZbIunuJGbKCOW70YGvzY2/3E9VnKMdHGEqPU/CViejSeCURAWPX4sUvjTOYHGNt/iaTvTMkzTnckjCujgDmRg9eSZisq5cbM+ssLywTNAvRCFODG0udC02FhbA2zczgAns7+9y7u8dIZgJHqw9NhQVDjQNjrYOkKc+tlU3u799nbW6DoreMrcmDpsKCqc6FqzPAQGyE+dElbi7fZiQ1RtyQxdcdOeJNx3QZ+sODjGQmKbj6SFnyhJUJAvI4QXkMZ0eAhDFHxlHEJ43i6PATkMVwdweRXlfjl8WIqBM423wCJaXaLnDED7/0hBQJovoMflmMsDpJTJuhLzTEUHKclalVHj18/IKBXl5eZnh4mPX19d8xyBsbGywtLdHf38+TJ09+r4H+/PPP+Z//839+02/Nx+LYQB/rW6Jv+oVwrG+n4vE4Fy5c+IMG+tmzZ+Tz+f/jNcuTy1z8QS0XvltJ1SutNL7ZRcs7Pawv3jy65sGDh0hOazj/3Woufr+Ga//UyPWXm/GIQi80IvqkUS7/oI5L36/h4t/XcuUf62h9t+cFWkfRV6bqp21U/KSFyz+s5do/NlL5SjPDufGjayaKM5z/USUt7/RQ/WobFT9q5PqPm4hok0eLRytTqxhrnCguGen6SEHN6+1cf7kNY72LvXv7R5PloCqBucmN8rKJjvfl1LzWhvy8noWxZXa2drm//4CifwC/NIalyYvqmpmmt7uRnNGQdfcyXphmdW6Dqd5ZMrYifmkMc5OHnjM6pGc1eMQRMvYi5egIw6kxzGInIU0cnzQmGMFqB9pqG97uCAlTnt7AAFlHib7QIAlzTpjsSmOorgn0B293lIQ5T8ZepODupy80RM7dT9KaQ3PdRvdpDcY6Dz5pnKQlR8ZRYqI4y/TAAjlXH+rrNsSndcjOGbG2+gnIEqTtRcZy06zN3yRmzKO8aqb7rB7peSOKiyZsrX70LQ586jDjxWlckjCKyyYUV8zIL5iQnTcKjOJWHz5plKg2hanejfLKYRX3ZQvKyxbUV4VyFFOjB0uzB1ODG/U1K6qrFlRXzcKUusqGrsqBodYtMJd7ItjafGiv21BXWNFW2tFXOTDUOHCLwkS0aZLWPAFFHGO9SzirdWKsc2Jr8eFRhHAqvJSCg8RNOdzi0OFSoRtTgwe/Qsi5jxem6Q0OkDDniGiFaa+50Y2zI0DB18/t1S3mhxbI2EsEFHHBNLYHsLcHiOrSzA4tsL97wOLECn5Z5BBx58dQ68LTHWE4Ocb2rR3u3d1jqm8OR5sPY60DS4MHc52LgCzG+vw6e/cOWJ+/SdqWo+NsD/pKB9YmYcKdc/WyMLrM1vo2o+lxopoUblEIW7MXV0eQiDpF0V9mNDtJOTZKylLAL4/hkwpoREebn7gxQ97dS0yXxdMVxCeL4pfFhBy0OEJIEcfVKSwzGqvtQryk2YNPGhHuCqgTuLpCmBtc9JxRIzmtRnpWh6HWQVAumObW02L80hiGKhuST9S0/roHyadKDNV2AnKB+BHRpYW7B5oUYXWKqCFL3t3P4ugyDw6+xFp+8XpeWFhgbm6O6enp3zHIN27cYHV1lenpae7cufPC2eeff06xWDw20N8ifdO+6VjHOnHixLGBPtbvV39/P++///4fNNDPnz//gwY6ac1y4TtVXPhOFef+x3XOf7cGyafKI5by8+fPmR9dpPKnLVx6qZ6zfyfQOip+1Mj86OLRNZtrW4hOKmh8U0T1q21c+UE9l/+hlpgu8+XEe+8+thYPPZ/p6PhARt3rHVz5QR2aKyYePHjA8+fPefL4CTlnicYP25Gf1dH1sYLKl5tp/U0Pi2NLRx++M+V5ArIY5gY3yqtmWt7ppua1NtK2AlOlWXY2d9la3ybn7sUvj2Fp8SK7qKP6p63Y27xknSWGk2NsLN5kvDhN2iEYJ3Ojh5Z3JCgvGgnIY6QseQYTY8wMzjEYHyPjLBFQRFFdsdD5kQpDrQOfJErCXKA/MkzUkSDtylPw9eMWhxB/qqL7lAZzvVswx6Y8o5kJlidWmR1aIGHOIz2ro+MjJbJzBiyNXrw9cXLuPpYnVtm+fZe0vUDPWT1dn6ro+liJ/IIJa6ufkDLBQHyEmyu3CamSdJ81IPlMh/iUFvFpLarLFiwNXqK6DMOZCRxtAWTn9PQcEjt6zuqRnTeguGBCWWnE2unC0R5AedWM/LwB6TkDsvMG5BfMqK5asbX6hIytPI6zM4D6mhX5RaFuW33NiuaqFZ8sSslXJuvqJaROYWv1obpmRXXFgrbChqnBTc7Vx0RxhnJ0hJS1gE8WQ1/nRF8jTJ6dXSHGC9MsT99gMD5KztlLzJDD1RVCV2PH3OgmYcqxtnCT+clFDB1WwpoUYU2KoCqBsdaNVxJmNDvJztYuq7PrBBUJobjlkFrhaA+QtfeysXyb3Tv3mChN4xGHsTW5BV5yqw9XV4DpwXn2dvZYX7hFxtGLqyuItdGDqzOIszNITJ9meWKFnc1dRtKThJVJIQfd7BOmr6oERU8fY4VppnpnSZpyQrV6Z5DW0xKc7X5ihgxFTx8ZexGPOIK/J4ZHFMIr+ZLE4ZWE8fVEMDW60VyzYm/14RGF8Ekj+KVRXJ1BbM1eVFdM9JzW0HNGg6HGQVAWE0gdXUH8MmEC3X1KQ/u7Ujo/VmKosuGRRHCLQoQ1SXw9ESwNbmTndXSfUSP5RIW20o5TFCSiTeGXRhFfkWFqcKGttKC+ZsFUK5TnhDQpArIoEU2KsCpJTJchZSkwmp1kc3XraK/iq48vDPTMzAwbGxv09/f/joFeWlpiY2OD9fV1lpaWXjh78uQJ/f39xwb6W6Rv2jcd61gnTpw4NtDH+v2an5/ntdde+/9soB8/foz8vJ6qV1u4/nILV35Qx7m/rSJuyLxwXcqUo/1DKe3vSqn7RQeXvl+H5FM1jx59+YE4N7yIrsqG7IKOrpNyKl9to+aVFubHlnjyRPiQ3Nm6R1AVx9LoRnnFROu7Ui5+r4awOs7i2AqPHjzi8aPHDCZGkVao0dfYkV8wcPF71Wir7OScvUyUZniw/4D1uQ0K3n5CqgTWZi8VP25G/LECvyxKypZnrDDFve09Jksz5N19hFRx2t7rofHNLiyNHrySCClLnonSDFvr24wXp+kLDmKoc9D4ppjuzzQYa114xRFSNmFR7s7NbRbHVojqM3R8IKP5193Izxkw1rrwdUcpePqYGJlkemKWvKsP0UdKWt6V0vIbGfLzJizNXnw9UWYHFzjYv0/GXkT0sZqODxW0vy+QOhQXTRhqHWQcJW6vbhJUxZGc1tJ1Uk3nh0o6TqoQf6Km56weryTK7NAiQXkCVYUN0Sk1ok81SE5pEZ1S031Gj6MzxERJiBPY2wKor9vo/kxH9xkt0nMG5JdM+BVxyukhrBIXUX0Ge0cAxRUL8otGZBdMqK/byNpLbCzdZDQ3Sdpewi9PYGvxorgslImYm70MJ8fZ3NhmojgjxFBMeXzSGNoqJ+oKMwFFnIWJZTbXtoQJvClH0pInZshiaRQW9Yr+ASEOM74qtDb2xPHL44Q1KTySMAF5jIXRJe5u7jKcHMPbHaH9bLdQfS0J45dGKcdGubOxzdrcBmlLAWuLF68kItRk90QJq5Isji5zd3OH0ewUnp4YthahlCaoTBDVpsk6S0wUp1gcXSFlzuNoD+Jo82Nv8+MShYgbshR8ZYq+fqK6NB5JGEe7H2dHAHurH0ebj4A0RkSTxtHmR1dlw9rsxdnux9UVxNkZouljEbYWD+Z6F7LzeiSfqjDWOvB2h4T673Y/XrHAeJad09P5wSGJo9qGoy0gGOieCM7OIK7OIMpLRiSnVEg/06G5ZhVKeyRR3F1BggoBN6e9ZhVy4o0efJIIHkkQjzhMWBUXliy7o5ibhMXFpDVPypzHI4kQVh0i6lRJlHV6XJIAvaEB+iJD5Fx9wsRZnSKiSRLVpSlHh7gxu8b9vfs8efKE/d0Ddu/cewFj98VdsmfPnjE5OcnOzs7vzTnPzc2xubnJ3t4eo6OjL5w9ePCAoaEhPv/8c/71X//1m35rPhbHBvpY3xJ90y+EY307tb29zfe///0/ykB/0dD1+87ube9hqLIjO6uj/X0pda93cOmleqbLX+VAPyVrL2GqdyK/ZKDxLRHnv1ONtc3LrZXbRx+Gy5M3CCsTWFs8iD5VcvF7NXR9rKLgK7MytcrTp0+5v3ef/vAIEU0KU62DSz+oo/4NMX5ZlKyjyNLYCs+ePWN9bgNrjxtHl5/an3dS9UoLpjoXPkmYtK3A+sItHj18zOLYCgPRUdSXjVx7qQHpeS3GGidecZiMvcj+7gEP9h+wNrtOWJOk9mftNL8tQXZej7HGiUcSYfiQEPLw/kP6I4O0/LqHul920PyOBOk5A6Z6FwFpjFuH6K1ybISOD4VJe9ObIlp/04P0rEC1GE5OsLSwhEvuQ/yxiuZ3JDS93U3LO1KB6HFKQ0SXZmdrh4K7D+UVM10nVbS+J6PtfTnt7yvoPKnEIw5z+8YWfcFBnB0BdJU2xJ+qaf9QSddHCiSnNfhkUTbX7zCemyKiTeHsCqG7bkX8iRrJaS3y80biljx3t3aYH16m4O0nqEpia/OjuGJB8pkedYWV3vAQO1v3mB9dwCiyk7KV8MsSGBvcyA+zz1N9c2ws3mSqb46sp4+8u4+kuYBLFEJbYSNuyLAys850eZ6Cr0xUnyaqz5CyFgmpEjg6Agylxrm5sklvcBC/NEbSlCMoF8xxTJ8hbS+wMrvGjdl1AY1W7xJu/WtThA5N7WRpms31bcZzU3hEQUz1TuztASRX5SRMOXLOXiaLM6zOb5CyFrC2+DDXuzHXufFIIiRMOYq+Afqjw+TcfXjEYSEjfUjYsDR5CCoSJIzC783Y4MTSdEjYaPFhaRaqva3NXtydIbQVFrpPazDVOXG0+rC1eLE2ebG1+3C2+9FUWBF/pEJySouuUpgauzoPDXZ7gM6zUuSX9Ig+UaG4aMDc4MbZ7sfRJhhw36Hp11XZ0FRaBVOuTAiYO5HQsOgVR/BJIkIZiixKwpojZSkQUsXxS6P4JGH80jghVYKMvUjJX6Y/MkxfaIikOYe/J0pAESOsTJJz9zE/sshMeY7pgTmKvjIxY/bQQCfJu/pZGFlifHiC0YFxJkuzpCx53KIQpjoncV2W+ZFF7m3v8fjxY6Hpc3adgegIpUCZieIMy5OrbN/aecFAP336lNHRUfb29ujv7+fx48cvmOSpqSm2t7eP4hpfPdvf32d0dJTPP/+cf/u3f/um35qPxbGBPta3RN/0C+FY//FKJpP8l//yX/izP/szWlpa/qjnPH/+nL/5m7/5owx0X1/fC3GMrz4Odg+IadOY6t00vS3m6kt11L3eQcnfz/btnaMPuOnyHFFtCsUlA5d+UEvVy604u/zkPf3c3dzl+fPn7O3sM5QYIyCPc/WlRip+1ISu0oqvO0LO3cv9PQFbtbV2h6HkGJ0fKrj8g1rhVnO1A3eXsPj09OlTnjx5Sjk/iLnVycUf1tH8KzHSzzQYqm24u4Kszq4fmfvR7AR1v+ii8uUW4bqzOrSVFmL6NA8PaR1zQwu0vSul6tU2ql9tpelXYsSfqtFW2lieFGgdMwNziD5RUfvLdmpfb6fmFx00viWh66SSkq/M48ePmR2YR33ZTMcHMhrfklD7hoj6N8S0/FpKRJXkYP8+w7lRxBcUaCqsR7zoll9LaX9PRkCZYP/ePusLN4kZ0jg6goesYCXt78sRfawiqsuwt7vP7tY9ir4yEU0a+6EZE32kpOczPRlnL3c3d9ndusd4YVqYCCsS2NoC9JzVoamw0hsbYWV6jaXxGwynxukLD5OyFfHLE2grrdjbAkwPzDGSHqfkH6AUGEReo6HoL5MwZbF3BEiacixPrZK2FvH3xMk4e0maBSRezt1L3JhjrDjN4uTKYVGHm6g2TcZRImHKkbaXGMtPsTa3wVhhGleHH+11O472IHFjloy9SNFXZn54mfXFm2ScJSEaUG1DX+PAL42RMOfpDQ4xkhlnNCc0ChqqXZgOlw9NtS5El+QkzDlihgxucQhLk1fIQNe7Mda6MNU6sTZ5CSkSWBrcKC+a0NcI5tjc4MZUJ5A6rC1eTPUuZOf0SM/pMNQ4BbRdo7CIaG0UMHbmeifdp9RorlrwiEJYmw9JHS1eHO0+nO0BLI0u9FV2XKIgYU1SWDZs92NvE/LHrq4w8godpmYnWUfx8EtJDkd7AI8oiFccFl47zl76QoOM5qcox0ZI2Qr45VG8kgj+nihJk9BEuTq7wczQPEV/mbStSEAewyeJEDdkmSxOc/f2Dgf7D5jqmyXjKODtiWJv9eKXRxjLTXL35l0ePxJM70Tv9JcLh80+ovoUN6bXjspQxsuTuBR+vBIBbxmUxxiMjzI3vMDm+h3WFm4ymBgjYysSViWJqFOUgoMMp8dZHFvmxtQaTx6/2Eg4NDTEgwcPmJ6eZnt7+wWTPD4+zr17915YGPzibGdnh8nJyWMD/S3SN+2bjnWsEydOHBvo/+z6t3/7N/70T/+U9fV1/uVf/oW/+Iu/YGFh4Q8+79///d/5y7/8yz/KQA8NDbG3t/d7z548ecr88CKOVi+X/kGo35Z+psEjiTCam/pyifDgIePFGep+3sGVH9bR+aEMXaUVZ2eQlZn1o+v2dvZxigKc/24VLW9L6D6lQXddMNH79+4fXTfVP0vlj5u59k+NNP9KQvenGhQXjQzGvmRWD+QHuf5aE1f/sZGKHzfR+IaIzg8UmOtd3LsrLAneXr2D5Iya6y83U/FPTVT+pIW6n3fQ+YGMmYEFnj9/zvbGNrpKO23vSql7vZPKn7RS89M2Gt7oIufo5cmTJ+xs7uKTRFBdNSP6WE3jGyJqf9ZBw1tiwto0Dx8+4sH+A3LOPuztAbSVNsSfamh8S0zLO92ElAkODh7w+NFj+uIjKKq1OA6v6/hATscHMkKaNHe3uPtCowAAIABJREFU7vHo4WNWplbJe8sEVUkc7QFkF4yIz2hJWQrMjy5zY2qVtfkNhlJjpO1FgsoEpnoX6mtWioEB+sLD9AUHGS/MMJQYZSA+TMpaFDKzojDj+Qki6jQhRZKCp5++8BAlX5lSQOAEFzz9TPTP4OgIYqp3EdGmKXj7UDbqKUdHGMtNMTu8wFB6AnOjF/klI+5OIbZQ9PZRjg6zOrvO+sIGeXcfuiob6msmdFUOfN1RkuY8/ZFhJvtmmR9ZwtsdQ3PNiva6FfVVM8ZaJ355nJS9SMHTR9yQwVTvRnfdhr7Sjva6De11q2B6VUmC8gSmWhe6Sgf6GoHOoau2oa+yY6xz0n5GhvyyAXWFFWubT8DWVQuLiIZD2oap3oXighFjrZOgKomzI4ChxompTsDYWZo8WJsFA+3viRE3ZgmrU1ibPVgbBVybrcWPRxIiqk1T8JUpBQZImfO4uoKHU2P/Eb1iojjLRHGacnyMvKefuC6Ls92HsyNAWJ1kPD/F+PAkmWCewcQoeU8vcWMGjyhMSJ6gPzLM5uomjx4+YnnyBhlnkZAygVcaxdMdoeAfYG3hJg/uP2RvZ5/50SWC8piwINgVwC+NMju8yMHefe7vP2B1foP+yLCQX2/3EVQkKPrKTJfn2NnaZWP5NoOJMRLmDEF5HF93lLStQG94kKnyLEPpMUbS46StBTw9IbqvKAkp4yTNOYrefoHioU0TVMYJq5JCBlor3EEIyGNknb0MZyaYKc+zMrXG40ePXzDQX0ye19fXWV5efsFADw8Pc3BwwD//8z8zMjLyQqX31tYWs7Ozxwb6W6Rv2jcd61gnTpw4NtD/2TU4OMj3v//9ox83NzfT3Nz8B5/3hYH+apbw6x5jY2PcvXv3a8+fPH6CsdbOhe9V0/BGJ6JPlCgvGsnaiy9cNz24wOUf1HL9x800vSWm6yMlsnM61uc3jq65u7VL86/EXPhuNZdfaqD29XYa3xTj64ny5IkwcTrYv4/ikpErL9Vz6R9qufzDBip/2kLXSQWbawKt4+HDx+iqTVx6qZqa1zq4+sMGrv24gerX2hjOjB+Z/7S1gPyclq6PlNT9opOKnzRR82obCVOOp0+f8uzZM8ayk9jbfKgrLIhOqaj9eSfVP+vAK40eZbjX5taJ6tLY2/xoKmx0fayi/pddeERBdrfv8eTJU/Z3Dyj6BgirUzjaAmgrrHS8L8PZGWR2eIH1+Zvs7x4w3TeLuslASJ3E1uZDdl6HpztM3tNHX3iImf55VqZXGUlPknX2EpDHsTR5iRkyeHqEBayib4CxQwbwQGKMrLNE3JihNzCAqUGos45qMxR9ZUZS48z0zwtM5vwsfdEhNJU25BcMeERhYoYsvcFBxgvT3FrdYn3hJll3L4rLJnrOatFV2fFKBEKIvsPC0tQNVuc28MvjKC+bkV0yIrtgxFTnxi+Nk7YVGUqMMZAYE3jXl4woLxtRXDCivGTE2uQ9ZE5n8Ulj6GscKK9aUF21orpsQnVVoI3Ymr3Y24VlPWdn6PALggXtNQuaSiu6KgfGw4puW5uXsCaNtzuCvtqBttKGvtqBqU5A1smuaLCKPGSdJaK6DPZWH/oqhzB9rndia/WTthUpR4fpjwwffSmxNHowNQjxjbAmxezgInNDS4wVpikFBkmY8rg6glibPXgkIfqjI2zfvMv60k1GsuMUvP1kHSV80iiuriBpW5HVuQ0e3H/A7Rtb5FwlYvo0kcMYStyQZX50mb3dA/Z3DxjOj6GpMwjTZFkMvzTGRG6Se9t7AqJu4SalwBAhZRyvJEREnSRjKzFZmuHezh43V24zlBwlqkvj7xYoGmlrgVJwkKnyHGPFacbzk0JUQyrQOHzdEVLWHEV/v/D3ZcgQVqcIKGIEZDFCygRhTRKPJEzksDzH2ujBWCvcEYhoUoTVCdrOiAnIY9iaveiuW1FcNKCvsuEWR4hq03glYSLaJBFNkqA8TkyfpT80yERx5qiJ8KsGulQq8ezZM/b29hgbG3vBQA8MDPDo0aMXFgq/OLt16xYLCwv89re/5X/9r//1H/l2faw/Ut+0bzrWsU6cOHFsoP+zy+v18t577x392GKx8Omnn/5Rz/2rv/qrP8pAT09Pc/v27a8939vZo/6XnZz/ThVXX6qj+jDmUI4Nv5BT1NXaOfudKi5+p4pLf1/L5ZfqkZ3V8eArm/UpW5HqnwpM5vPfq+Xi92qpeqWVpcOYxPPnz5nqm0FySkn7+zLqftHB1ZfqufZSA1nXl4b99o1NNJVmGt/rQPSxkrpfdnL1pQY8otBRnvv+3n1S5hyOdj+aa2Ykn6qoeq0NQ52dne29o2zleH7qCFumq7TR9q4UxWUjM4Pz3F7d4snjJ9y+sUnRXyasSWFvDyC7aEB2UU/aXmIwPsrS+A32d/aZ6Z+j6C0fTiZ96GrsODoDRLVpegODzA0tcnt1C1OPjYKnn7g+i7c7guqaGXubj5guTck/yOzgAjeXbzFTnmc4M0naVhBoGBcNuEUhYoYsfcFBliducG97j42lm2QdJWTnDIg+VqKvceCVhEmY8gxER7i3vcfm+jYhVZyeM9rDnLQOU70Lr0TA7M30z7EwuoStzU/3aQ2SM3q6P9MhPW/E0ihMenWtVtLOPJYmD9JzBhQXjXSf0SE7a0B1xYK50Y1fFiNuyOAShTE3ulFcMiO/oBdoHJdMqK6YsbX5iWrSJMx5fNIo+moHiotGlFfMqK9b0VQIWL+8u5dSoCwQNkQhdNdtaK5b0V63Yap3kXX1Md07y1BqjIyjl7AmhaXJg77GgaHaiVcSYbI0w1h5nIQrTX9kiJS1iK87grHGia3VS87Zx63VLXbu7DJRmKYcG6HoLRPTZ46Ms2Bq99lc3aIcFab5QklNjqAywXB6gp3NXe7d3WN6YJ60rUBYIbCNI5oUvcFBbq9ucrB3n9X5dYq+Mv6eKBFNmpg+Q8ZeZDQ9wd69fW7f2GI4NUpElcDR7kV0SUbWUaIUGGCqb4754UUmSzMkTMLynlscxt0VImXJUwoOUPSVSVnzxA0CY9kjDuPrCROQxvBKwsSNWYLKBLZmL8Y6B75uYfHSL43i6Qrhlwq5akutC81VC5orZjyiIAFFDHdXkLA6KfDOG5xorprRVlhRXTFhafbg7Y4Q0SbxS6OILkmxNLvRVFhQXDKgq7JhqnMKpI4eAYcXUScFjJ0mSdbRy1h+iq2bd4+Wir/6/pLP5/ntb3/L8+fPfyfn3Nvbe1T5fefOnRcqvdfW1lhZWeHzzz8/NtDfEn3TvulYxzpx4sSxgf7PLo/H8zsG+tSpU3/Uc//6r//6a7PNX33Mz8+zvr7+tefjxWmu/WMj137UyIW/r+Xs31Zw/eVmNje+ZDdvrd2h62Mlrb/upvZn7Vx9qYHzf1dNf+jLlsMH9x/i7gohvaCj46SchrdEXPl+PdYW9wtGvxwdwdrsQXnFhOgTFXWvd9B9Ss3uzpcxk43lW3ilITrOSNFetyL6SEHLOxImemfY2drl2bNnPDh4yGBijKg2jaMziOqqmca3RMSNWYbT49xcEiq61+dvUgoOENVncLT5aP9AirXeQ9yQpS80yOrsOg8OHrAwskzRP0DSlEN9zYziggFnR4CoPkNfeIi1+Q32dw9YGF05LFWJ0nVSgfqaGWdHkJg+Q19wkJ2tXZKxFLfWbpM05+n8UEHnh3L0VXbcXUES+gxj+SkePXjE3u4ecX0G0Uklre/2IDmlwVTrwiMKkbWXuDGzwZ2Nu7jFEbpOCguGnR8o6TmtEybC8hj9kRGWJ2/g6gzRfUaL+FMNoo+ViD5SIT9vwFjjJKpLM1aYJCCPY250IztnQPKpGskpNdLPdMjOGXCLwnjUPryqCAFZHFO9E+lZHT1ndYeoOiO+niiT/bP0hodImHN4JFF0lQ4UF82or5jRVtjIOHvZWLzJRGmGgrdM5It/nytWVFfMOFr9jBem2bu7x8LIEoPJcTL2EiF1EkOdC12VjZgxx8bSLfZ291mavMFIZoK+0BApcwFbux9nZ4ix3BS72/fYWLpNKdKPqdNOwVem4CkTlMfIu3q5tbLJztYuk70zZO0l0tYiSXOOtLVA0dvP8vgN9nb2uTG3RtZZwisOkzJnyTqK5Fy9DKfG2blzj62NbYaTYwTlcaEFUJ0k5+qnLzR4tLQ40z9P3JTB1RnA2eHD1eEnac5TCg7SHxEiNClbAV93BGebH7cohEccovWM+LBqPY+jLSCUuohCeMQR3F0hXB2BLykanQF0lQIS0NkZwCMO4+4K4uuJ4u4I4mgLYKhxoK2woa+0Ya534++J4pNGcHYG8EkjeLrDaK5ZUF4xY6ix4+r04+mO4BKFCCliBBUJAtIoxhoH+iobjg4/fkUUV1eIsDJORJkkpIijrNZhaLARViWIGbMkLHnC2hRhdZLIYYQjbSkwGB9lbf7mUXX3FxPnR48ecXBwwL1797hz5w6ZTOZ3ilF+X1X348ePX0DdLS8vs76+fmygv0X6pn3TsY514sSJYwP9n13/byMcAH/3d3/HrVu3/qCBXllZYXl5+WvP07Yioo8UtL8vpfHNLq691IC60vICuWN1dgNTvRvFJT2iT5Q0vdVF09sSdu7sfiUn/YCUOYe9zYe2woLoIwU1P2tnMDV2tMz3/PlzZgcXiOnTODsDKK8YqXm1DY84xERxmt07946y1H2RIWRVauwtXup/3omuykrClGUoPsrd2zs8e/aMWyu3GYyPEjdkaH9fSvcpNa6ugNCydjiZffL4CRsLgqGzNrppfluEtsKKo81PVJdhKDV2hM/b2dolbszQ9CsRnScV6K5bcXYEiOnSzA9/0YD4kJQlT+s7PTS+KUbyqRpdlR1XZ5CcvcTunXvk03nCmiTt70ppfkss1Iuf0aKvceIVR5jsm+Pe3T0imhTiT9V0vC+n5Tc9tL4rpeeMHkOljbStxK2V28QNeQy1LuQXDLS/L6f9PTldHysRf6rC1xPlxuw6Jf8AAXkCc4MH6Vk9oo9VSE6r6D6twSuNsbF4i8nCjNB+KIlgqnPSfUpHz2kd8osmUrYidzd3yUdKBPQxoroMbkkEzXUb0vN69DVORjOT3N+/z9b6NiOZCfLuPiKaFJZWL8orJjw9MVam19jdFgznVGmGcmyUtL2EtyeCqdZJ0Vdma2ObG3PrzJQXGEyMUY6N0h8eIqbPEFKmWBq/wfbNbQZT42RswmS26C3TFxqiPzjEaHaS7dt3WZldE5r+OkPETFn0HVZK/jJjuWm21u+wfWuHoeQYvu4opgYXIVWKoqdMOTrMVGmGzfUt5seWiBuz2Fs9WBpdONp9xI1ZSoFBhtMTDCbGKHj6hYltowdbqxdbkxevJEzKUiDrKOGXx7G3+3G2+3C0B7C1+bC3CJnpkCpOSJHA3OBGW2nD3uITrmvz4+jw42wP0HZKjKXZLeS1a+w42nx4xEGh9rvNh6szhK87jK7KjvqKBWujm4AihqMjiKsjgK87gkccwSMOY232YKpz4OgMEtGk8UujBGQxvOIw3p4IAWmMoCJOQB4nYcqRd/eRshXwisNH5TFxfZa+4AD94UFGc5MMpcbIu/vwy+P4usMEVXEyzgIpf4Z0MENvYoCYNYVPE0bbaEHfbMGp8BDxxMml8hTzRRLRFEFXiLAnQiKapFAo0NfXx8DAACMjI4yPjx/FMP7vmecvDPRXJ9JfRd0tLCxw+/ZtPv/8c/793//9P+id+lj/T/RN+6ZjHevEiRPHBvo/u/71X/+VP/mTP2FjY+NoiXB+fv6Peu4rr7zCzMzMHzTQGxsbzM/Pf+15OTKCtcWL4pKRzpMyan7WTtbX98Jt1jsb2yQMWZwdQaRntFS/1oahxs78yNJRJe+TJ0+ZHVwgbs6hr3NQ9Wob3Z+pSVryTBSnj0oU9ncPGC9MEzdmaXyjk44Pe3B1BonpMowVpo6Wi+5u7mBTOVFeNNLwZgfaCuthDCLDzMD80a3fg3v3CWsSVL/aiuikCs1VM/ZWIS6xub59dF0xMEDDL9qp/lkb4k9UaK5acLT7KPkGePTwMU+fPqXo66f5V93UvNZO/S+7EH+qQnfdirsryPr8TR4/fkLRV0b0kYqmtyXUvd5J01tiRJ+oUF0xMxAZ5uGDR9ikLmSXDEjP6mn5dTcNb4loeruHzpMKoto0ezv7TBSmCchimBo8SM/paf1ND20fyOj4UEFAFuXenXssT9wgYy/iloQx1rmRfKaj40M5klNqEuYcezv73L29Q29o6LCFL4yu2o7kExXKS0bK0WHuHzzg4f1HTPfPUfT2E9WmcXWFkJ7TY2nyMDM4z86dXfZ3DxjIjRAwRMi6+giqkuiq7UQ0KdYWNlgcv8FMeYG5oUUmSrMMxkdI2Yv4uqOMpie5tXyLvvAwGVuRgdgIQ8lxxrJTDMRG6A8Ps7awzvL0DSLaFO7OIBlHL+X4GEPJMWaHFtlYvMXm+jbDqXGcHQH0NXbCasH0DibGmCkvcHdzl+WpG8QNOSyNbgw1ThxtfmK6DMomPaO5Kab7ZukLD+LqCmOsF2gdplqXUHZjzFP0D5I05/BKhDZBc6MLS4Mbc70Tc4OLkCJOwpjF3RnE3OgWEHZNXqyNHszN7kOsnQ+fVCgcsTS58UkjAuau0Y210YOj3Yej3Y+l0Y3uuhVHe4CwNoVHFMbR5sN5WA3u7AwgOidHec2IWxImZsyQMOVwtgt17a4ugcYRUiYIKuLkXb2UAoOkbUU83WG83VHc4hAhZYKCt4+RzDiTvbMMJceEuy7aFM5OP15phJgpw1B2lLmJefpSg6TceUKGCMZWO5p6I6YuO0FLmEwiRyFXwGcLoO8woajT0lOlRtWow2P0kU3mGSgPks8U8Bh92MRubCI3domXfKDI0twym7c3ub1+m/mRRcqxYdK2opD/L8+zMrnK/s7+77wPfVHp/YUpvnnz5tca6K+i7mZmZrhz586xgf4W6Zv2Tcc61okTJ44N9P8fFI/H+fM//3P+9E//lMbGxj/6ee+++y59fX1/0EBvbm4yPT39tee3b2ySthZRXtJT80orbe/1ENNnWJleO7rl+uTJU5YmVgkoY9S+1k7rOxJsLV5iujQ3pr/MNz968Ij50SXa3pXS8IYI5RUTthYvEW2arfU7L1zn7QlR8XIz4o9VKC+bsDZ7SFuLL0yrtS0GKn7STO1rbXSdlKO6YsLa5GG8+OUXh7HCFPU/7+Dqjxup+VkHXR8rUFwy4JNE2DukdUz2zdB1Uknd6x1UvtxE7esdtH8gRXnRwOygQOtYHFtGV2lHfEpN89sSal5tp+71Ttre7Sbr6uXx4yfcXL4lVBjXOpGe09H0q27qft5J068kRLQZ7h884N72HpYuJ8ZmF4ZaF9LPdDT9SkLbezLixiz3Dx7w6MEjxnNTxA8Zu4ZaF10fCwUpBV/5KFe+MrVKb3CIqF7IHCsvm1BcNjGSmWBna5eDe/eFFr3iDHlfmag2jbnBja3Nz+zwosD0HVhgdX6D5alVRjLjgjmWx8k6e1maWCHvKZN1lBhKjDKSGydkizKWnaQ3MMDMwDyzo4v4pFE8ojAZR4nh9ATTfXOsTK+xOrvBzeXbDKXGMDW40R8a7oK7j9HMJIujS+zt7rO2cJOYMYeh1oH6qkWIxhwuQY4XZ1ib32AkO4mrM4i2QshA66sceCVREqYcfRFh+S+qy2Cqd6GvtmOodqCrtGOqcRJUJpBWawkpk7i7hOprQ43j6Dp9jQNLk/fo3NkZIKRKYmv2Yqp1YjhE3Vma3FibheptV2eQuCknxF4aXALGrtmNvcWHrc2LtdmDXx4n4ygRN2WF2u8WrzA5bvcJCD5TlpK/TF9okKxDiKk4OwRih1ccJmMrkPJmyAYKjBWmKUdHSFpz2Nq8OLp8hNRxemNlFmYWGekdIx8qETbFcXR7UVTp0DSZcWl9JCMZ8tk8EX8co8iKtsWAok6LvFaDTeYiGUxR7h+g3DtAJpzHowpg7/bg6vGTcueYHp3h9q3b3N7YZGFskb7IEClrnqyjRH90mPHCNPe273Fw7z6rM+sMxkeJGdJ0X1GScRQZio8yMzTPTP88C2PLDMRGSFryRDVJoto0MV2GcmSY0cwkK9NrbCz+7k7G0//N3ns1N3qf2b78GvMpxp5bX82uc/aebW+Pwx57rLGsMMpZLanVOTNnghEgSOScc86JAJjAnHPOZHfbmmD/zsXLRouWWnbVuZAvuKpQ6qr3X0B3U433hwfrWevx47JtY21tjbGxsRcC9NcrvYeGhtje3r4E6L8hfd/cdKlLVVRUXAL0pV6sTz/9FJfL9RcBemtri2Kx+MLrjx8/ZiI/RdVvW6j6XQsdV6SoqkwENBGOv7YgeHb2GMVDHbd/WUPT2x10fN6P/L6OjOfic6c8A3z5vx/w4KVG6t8U0fl5H4pHOlbm1spnpofmuPuLWr78pwfc+5c6wX7xkRhvX7A8+V6ZXePqz+5y6+fVXP9JJXd/WUPVK810fdHH6rzwXJsr28jua2l8q5OHLzVz62c13P5FNVW/a2EgIPy+DvYOcUr8SG+rEZ3D7O2f1/LgV3X41FHOzs44Oz0j685jbHXQd1dL+6d9VL7UzIOXmnBJ/eW0junBObwKoTii/76O5vd7qHmlDb8qyvGxcGZvax+zxImm2Yih2YH0tlBuEjbE2Vrb5mhfiLubzE+X4VhbLzTVpdwDjKbHGctOsbG0ydbaNsOJMWLmNHaxH0ePl4HgEAFNjLA2TiE4xMLkMsszqwwnxkg5cuT9gxQiI+jOv94P6xMMBIaYHZlnbXGd+bEl5scXSbvy9N/XIr2jxSH2E9YnyfqKOAwujg6OWZ5exScLI76upOuzfnRNNiEhxJRiOD7G1toOpcwEuiYbnV/I6PxchuSGGmOLA688TMaVZzhaImZOI7ujo+e6Asl1Bd1fKui/r8MschPUxAnrUrh6g2jqLEhvqRHfUCK+pkR8U2jLc4h9OMQ+rB1CAoSu3krfbRWSmyp6b6uR3dOjfGSk6bMODC12Apoo9h4/ikoD/Xe1yO7pkT3Qoa4yYWxx4pWFiVtS+ORhTG1OZPe1yB7pUDzQo2u0EdRESbsHyPqKRE2pc4uHBVWVUfgGpE/4BmR6aI7R1ARZT4GgJoau0YKyUo+hzU7UkmB8eILx0QmijjhujQ9DtxXxfTldt6SoRHrcFh+RUAS7yYGsTUlfowJxrYzOe2L6GhS4jB5SiRSZZAa/NYSlz4mx24al14lPF6KQGGJpYYWVpVWmBmdI2AX/ftScJuMqMBgdZXt9l8P9QxYnl8m683hlYSFSTiN8YBrLTTI+MMXc2AJZTxGvLIyj24et0y0svNqypBw5Uo4cPkUIT18Ip9iHvduLs8dHw6etBDUxgro4hhYH6ioT1g4X9vMab4vIjasvgLvXT1iXJB8cZqo4y/L0twP006dP+eqrrzg+PiaTyfDVV1/xhz/84RsA/fVK72exdn/4wx++77fkS53r++amS12qoqLiEqAv9WLdv38ftVr9FwF6f3+fbDb7nWdi5gRf/M97PPhNA7Wvimj7UIK6xsjR16bBy1PL3PxpNVf/133u/Esd1a+20vBGB4Xg0PPX2j2g5f1urv3vh1z735Xc+UUN93/dQO9tFUcHR8L0+fgEfZOVyt818/A39Vz7cSXXf1JJ1UvNTA/Nlm+mcUuGOy9X0/RuJ1UvN3P9Jw+59fMq4pbni4tTxRm0jUJTX9tHEh79tolb/1yNS+ov35B3NnbxK6IYmu303dHQ9pGEh79pxNHtKYPx6ckpg9ESXlkQfbOd/ntamt7uwtLpYWdjp2w/WZtfF/y6/SH0TXYk15U4xF6G4qNM5aeFBraTU5K+DMZuK57+EOY2F15lCI88RFifYDAyysbSJvs7B0zkpsh6iiQdOaKmpGANELkJ6RMUQsPCue19liaXmR2dI2ZK0XVVTv8DHY4eH2F9guJ57NnJ0QlrC+t4ZCFhMfATKdo6K05JgJgpw1hmkqPDY2ZG59E12Gj9uBfRJ72IbyjL1dRJRw6j3EQ+PIL8vo6OK/20X+mj/ZM++u9qMbU58atiZL1FEtYM2norkhsqOq/00/5pv/Ch6qEee5cXvzJGWJfE0SO0JIpvqOj8XEjikNxUIX+gw97twa+KETGkhGSTGjM959d7birpu6PB0uUhYkiSducJqGNYOjz0P9AhvaOm/64WZaWesDaBQ+0hZIkRs2TwyELoG63039OgqDRi6/YwnBhjY3GTyfwMOV+RiDGJtdON9I4KZY0BryZEqVBiZnqGdCiLzxDEInUgrVLS9kU30hoFNq2TkD+Ey+bBqLAia1PT36Skp1JKzyMpJpmVRDRBOpHGZwlilbmwy904+t0ETBGS3ixzU/OsLq8yOThN1JzE1uNG1qhmwF9kODHG1uoOhwdHLM2skPMUhNSLNqcAvb5BStlJJovTrMytkg8M4ekLYm5zYmp14u71E7dkyLjzDPiLQtlNXxBLpxvzuR/a0GwnoI4St2awdXnQ1VkxtjixdLiwdXowtTpxdHuxd3lwSQIYW+yCt7vGgr3Lg1nkPk/acNL8RQf6FjumVgeaBjP6BiumdjdOqeC/tnd5cUkDOHt9uPpCpJwDTOanOfhaJvyzx7NK72fQ/Mzn/OTJExKJxLe2D3711Vdks1mOjo4uAfpvSN83N13qUhUVFZcAfakXq7W1lc7Ozr8I0CcnJ99p9Tg7O6PtQzFX/scdrv2kkuv/p5IbP3mIrtFy4ZynP8id/1vL3V/Wcv3HlXzx/9yl8t+a2Fx5njFdyk0g+riXxnc6ePBSI9d+XMmX/+s+A1+D7O21HXRNVnrOUziqX2nly396gEPsL585PTklbknT9Gk7XV/20faJhAe/rkdba+b09HkBw9zoAl55CH2Tjf57Gprf7Ub+SMfm6la56exo/4h8YAjXre1sAAAgAElEQVSfPISh2U7vbRXy+zoK0RHmRhfKlpHVuTUy3gJeeRhTuwNNrRF3f5CYKUUpOc7+zgFnp2csjC9RCAyTsKSxdDiQP9Rh7XAR1ScZjpXY3zlgZWmFqC/GzOgcHlkQ0SdS5A8N2Lo8hPVJRpJjnBydcHYqlLh45CGa3uuh49M+1DVm7D0+4pYMU8XZc3Bfw9jipOndbhre6qLnmhJtvbAsmbTn2F7fYWZ4HlWlkeYPemh8p4vWD3rov6vB0GzHJ49QSo1TSo9jaLbTc0NBywdimj+Q0PaxlP57eqwdbiKGJPI2FS5pAH2jDcktFa0fihF9LKXzi35k93U4JUFyvkHi1jQuSQBNnZXuL+V0fiaj8/N+eq4psHZ5GEmMkfMPElDHsXYI6R89X8oRX1fRd1+HT5NgfnyJUmaSpF3IXDaJXPTeVCO5qUbf5GAwVmJvZ5+50iKFyAgxUwpnr4++u2p676qxSz0M5wTojQRiWBR2rDIHyiYtLVe76bjTi1lmI+AN4LK4sersaHuNKNs1SGpldN3tRdWuJ+yLkIqn8Rj9WGUuvPoAXkOIsD1G3JVivDghQO/QNEGdkO2ccuQYjAwzlp1ka0Vo+Vtf3CDrLWLv9mBotj2f9GYnmRtbYHNli6HoKC5JAH2zDW2DFYfET09VLzlfkUJIaBv0yEIYW+wYWhwYWx0Ym+0EVRESjiwBVRRTqxNjsx1zi/BfQ5Mdi8iFpd2NXxXFLvZiaLKhb7JjarVjFgk504ZG+3kRjB9Lh6u8hGjv8WLucGFosmPtcOHo9mEROVFXGdHWmrF0efD0C/9+HF0e7N0erB1uuu/0I74tQ9dgwdrpwi0L45IGsZ+fsYt92Ls9BJRRMu4Ci+NLHB18e3LQs9jJZz7oRCJRTut4No1+9vj9739fnkonk0nOzs4uAfpvSN83N13qUhUVFZcAfakXSyaTUV1d/RcB+smTJ0Sj0RdefxZRV/1qG/d/3cCtn1bz+f+4zXDiuW/67PQMS7uL9s/7aHyng+rftfDlP93H3Oa48FyjqTHUtWZ6rstp/UhC5W+bkdxUlie9T58+ZXdzj4Ayhr7RjvSuhrZPeun8VMr60saFmKux3CTSGiXyah1997SIPu4l4yuwNL1ahuOD3UMKoVEC6iimVjtdX/Rj7/GSOIfPZwuJmyvbDMdLxK1Z+u+pkd3XYO10E9YlGM9OcXoiLBFur+8wMzqPpc1J6wfdKM4TDyKGBFOFmfKUbHd7D7c0QO1rItqvSFFWGbF1eYgak6zOr7O/v08kEMXa7qH2dRE1r4oQX1eiqjHjFAfIeQscHRyzubyNoclG3ZudVL8iouHtHnpvaYQ2O0WY2eF51hY2MLW56bqqoOmdbmr/vZ2W98X03VFhanGQcg6wOLlCQBVFUydMhJve66HhrU5En0iR3lbj7g+zMLFM3JYVikbqLHRdldP6QTftn/TS+Vkf9i4PC+NL6HtNeFVhLF0eVDUm2j/rQ/SpMKn2KcNsLG0yPTRH2l3Ap4xgancjvauh+4t+VJVG8sEhDvYO2F7bZTg+RsySwd3nR/bQQOfVfowiO4XUELMzs0yOTxL3JHEo3ahbjXTcktD8eSeaLgM+px+nxY3NYMeis6GR6JE2Kui+L0Vap8RnDxAPJ3DpvFhlLhxaNya5lYQ7TdSZpJgcZmVxhcmhGfzKCK4+P0l7jpHkGDODs2yubrG3s8/m8hZZbxFLuxN9k42QVsj+HstOsjK3ys7GLqOpcVxSP9p6K6pq47mVJc2Af5DhRImRRAm/MoKu0YamXlgS1DVY8CsipBw5ErasUAQjcpUXDLV1FvRNNsxtLtrvCkuhFpEbc5sL03k8naHBiqbBjK7eglsawNkbwNBsw9btxd0vROZp68yYWoXabwGYHeib7Vi73PiUUcxtLqydboznr2XtcKNvsKGpNWPtchPWJ/Croxia7EKEXYcbS6cwRbZ1e4iY0iSdA4R1CRzny4yObi/evhC2PhceTYDhRImBwBAZTx6HxI9T4sMnD5P1FlmYWOJg5+BCqs932cmeAfTw8DBbW1scHh4yMDBwAaC/+uorYrFYGaSfeacv9beh75ubLnWpioqKS4C+1Itlt9v58ssv/+JN6enTp0QikRdeW5tbR1VlpOtqPy0fiKn79zbaPuzh8Gv2jbPTM+KWtODVva1G9FkvrR+IWZhcuvBczxYSjSIHfXfUNL3TRcyaKcfOPXuuiYFpIV2ixU7T293om22kHDmWplbK544OjvFbQlglTjquSOm7p8Xa6SJmSrEwsfT83P4RCxOLKCsNtH7Yg7LSiKXDTdSYZGX2uddyf28fR7ePypeb6Py8H8UjPdYuN3FzhsM9wV5yeHiEU+Ln0a8bqH6ljc7P+wU47vYwFBvl8ePHHO4fYu/xUPNKKw//rZH6f++g55ocdbUJryLM+tIme9v7iG710PGZlLq3Oqn8bTMN73TTe1OJrsHCYGSEg71DYqY06hozkptK6t/spPrVNhrf7UJ8Q4lfE2Nnc4+hyCgOsR9NnRXxNQX1b3TS+E4nrR+IcYj97KzvMj04S9SSwdLlQVltpP2zPhrf60b0aT9eWZjdjV2213bJeAeFLOJ2N7L7OkQfSei9rSXrK3B0cMTJ8SlOrRefNoJbFkRdb0L0aR+KWgOZ8ACzM7PMzs4ykCjg0vjQdZrouddPwycipLUK3BYvTpMbu9GB2+HBpLAgb1XTU9lH930pDq2LaCCBQ+nGKnMRtsfIxQtkIwMk3GlywQKzE3NMDk7jkgZx9fpI2nOMpsdZmlphZ2OX3c09Nlc2yXmLGJqt6BrsBNURYtY0ZrmNrdUd9nb2GR+Ywt3nR/FIj/yB4POO6pMM+AcZz00xPTxLWBtHV2dBWWVCUWlAW2vBKxOaG3P+IcK6OI5ur7BEWG1CXWVEVWXCLHISUEeJmdK4JH7sYh/GVjvaGvN59bcRTY0Zp9SPTxXF0u7E1evHp4iga7CirjGhrTejqTNjaLLRfr0bVY0ZV68fvzqK67z4R1tvxdBsw9wqTI41dWa8shBxmzCJNjTbMbY6MIucGJuF5j93X4CELUvKOUDUnMIlDWBud2Jqc+Do8RGzZBjPTTKSKDEYHyPnFT4IWdrdOCR+ErYM0yOz7G3tszy7xnRxjkJwiKgpJcRDOrLMjs6zu7XHxsYG6USG6cKsEEvoLpDzD7IwuczB3iGPHz/mYO+Q5ZlVZobmWJpa5Wj/6DsB+hkMz8/PMzs7y+7uLoODg98A6EKhwN7e3oWM6Ev9bej75qZLXaqiouISoC/1YsViMd57773/3wB9sHtAzJhE32xFfF1B49udeORBDv/sRrc6u0bEkEBTa6TxzXZkD3QM+Ivsbu5+zQ7ymIXxJYLaOE3vdiK+rsDa5SZpy7K1tn3BorE4vUzPVRmtH0pQPBIa7hKWzAV/5Pj4OD13ZTz6TRPtV6T039Ni6XCT8xbLU+jHjx/jlYW4/bMaql9to+OKFPkDLdYON/OlhbJNJaCJ8vClRm7/opra19vOIdqAXxXl6OCYx48fk7BkEH0gpvrVNu79qoG6f28XEkJqjEwNzgrNhqFhFJV6ur6UUf96Ow9/00D9Gx10ft5P3Jrh9PSM2ZF5mr7sQFVjovuagro3Oqh6uYmGt7rw9AU52Dtke22HqDElVEo/MtD5uYza19poeKsTnyLC/u4BJ0cnDCdKBFQxLO1ulI8MNL8vpvNKHwl7tpzWsTC+TMY9gEceQtdope2TXrqvy4j70szOzDI3N8fYyBh+cwh9twVJpYLGT0S03xbj0DlxGJ04TS4CvgBmrQWZSEVvrZzO+1L0EgtBVwRLvwO73EPEGWekOMpQboS0L0fSnWVyaIqR7BgOsQ93X5CUPcd4dpLN1S32dw7Y3dxlY3mTnLeAusaErtFGQC2UbIznpjjYPeTo8IjJwVkcEi/9dzT03xd83hF9nAH/IFPFGVbn14lbMqiqTUhvqem/q0Fba8HdFyRqTCFvU5EPj+CVhZDd0yG7p0F2T0P/XQ1mkROfPELSkSWsSeCRhTC3uVFWCgkcsvtaFI+MOLp9BLVxnL1+vPIwflUEU6sDxQMdiod6FFVGtHUWoaK6w4O7P0TEkMTdJ1SIKytN6OosaBut6BpsWDvd+NUR4vbcuYfbjbbeir7BirbeIkQZNupwK/xkvYMk7Dn8yijaRhv6BhumNjtBXZLxwjQTA9OM5SYFD7chiUkk1HOHdQkm8lPsbOyxv7PP9NA8w/ExkvYsLmmAsCHBeG6KnY1dHj9+zPHhMUtTK0wMTDMYGiXlyDFZnBU8/KenZeidLM5SyowzVZxjcWKJ/e19zs7O2N85YGFikZRrAGm9nKH4GBP5aXbWdzg9OWVnY4+Z0jxZdwG/IoL3fBo9MTDF7PD8haSdPwfop0+FRcKdnR0GBwfZ2tpiZGTkGwA9PT3N4uJiGaD/4z/+4/t+S77Uub5vbrrUpSoqKi4B+lIv1ujoKC+99NJfDdDfVfu9tbKNuz9Ew1uddFyRYulwMeAfKmc8P7OCzI0t0vqRGNFHYmQPdJhaHQz4By9kRp+dnSF/qKXy5RbaP+1FeluNocVeLiJ59vDJQtz4SSW1r7bR9qEE6W0NlnY3O+vPy1lcKh9X/udtbv28mtpX2xB9LKHvjpqELVO+2Y6kxml+p4tHLzVx91f11LzaRttHYlTVxrI/e35sEdlDnTARfl3Iea56pQXRR70MRkd58uQJ22s7uHr9KKoMdH7RR81r7Tz4dQM1rwpJAycnp5wcnZDxFDB3ulA80tN9tZ9Hv22m+lURPnWEoyMBDKaKs3Te78UicqF4aKDtg14a3uokZk5fSOvI+QbxyINoG210fimj+cMeQuY4c7NzzM3NMTU1RdQdxyi2Iq1R0XSlk8ZPO9D3GQXoNbsIBoL4vQG0UiN9DQq6HkiRNatxGTyYeu3YFR7ingQTY5NMlqbIhvIk3RmGUiUK8SEsXR7c/QFSzjwT+WmmxqcYGRw9rwffIOfJI3+gR99ox6+MkvEUmCzMCOUzp6fMjy3ilPjo/lKB9I4aW5eXsD5Bzj/E7OgC+zsHZL0FlNUmeq4JjYWaWosQd2dMMxQbZWZ4jrA+ifyBnp5rKiQ3lEhvqjE2O/DJwmScA2TdBSK6BGaRG8VDg1D5fUOJ/K4We5eHsDZO5wMJIW0cn0qoEO+/r6XvpgbZXS3qahOObg8+RZiQLk7MmsEtE7LN++/rUD40oHpkRF1jwtUXIGJMknYXBJgW+1FVC9dUVUb0jVbChjgD/iJDsdJ5/XcUY4sDda1ZsODII4xlJlieXmWiMEU+OCQs7nV70TdacfcFGEmMsbmyxdTUFKlQhrHcJGl3Aa8ihKc/yGBklM2VLU5OTjg+PGZnfYfpoVmGE2OknXkGo6NsLW9xeiJA79L0CjNDc8wMzTNXWmCutMDWyrZwffeQpallcr4CCVuW4USJyeIMO+u7nJycsrd9wNz4Ehm3sAfg7g+S9eQZz04yMzTP+uIGM8Nz5UQOW6cXe7eXnkopA/4iI6lxEudV4z55BEeXF/t5I6FfFSHnLQgxdiPz5cKk7wLoJ0+eEI/HWVtbY3x8/BsAvbGxwejoaNnC8Z//+Z/f91vypc71fXPTpS5VUVFxCdCXerGWl5f58Y9//FcBdCKRuOBD/vPH8fExXV/IqHtDhOhjCZKbKozNDjaWNy+cc4q93PjxQ2pfFQk11teUOHv9Za/x06dPGYyNcOP/VHHnFzVU/66Vpne66L4qK5efPH36lMXJZRrf7OLOL2t58OtGql9upeGtTvSNVg7Pl4z2NvfouSXn7m+qqXqlhXu/auD+r4USlJnz7OmT41MC6hjSuxpEn0qpea2N2z+r4uG/NpJy5MofGkZS45hFTmT3tHR8LqXy1Vbu/6oBrzLM2Zkwyd5c3iasTwjnHupo/0TIgw6oo+XFRSGtYwS/Ioy+yUbPDTm1b7ThVvqZm51jfn6emZkZsvEcktp+pDUKWq92UvNeC/IWFXaDA7fdQzgUJhQMYVZZkLWqED/sQ1LZj7HPikFsw6H0kPCnmJ6cZm5mjmJiiKQny0BkkJRvAJPIiUcWIu0cYGZojtOTU06OT9nfOWBtcYOEI0vfbaE63KeMkvUWmR2e4+zs8XmD4xp2iY+OK3303lJh7XAT1MQY8BUp5ccZyOUZSY2jqjbSdkWK6NN+NDUmbN0+woYkw/Fxtla3yXoKKKtMdH7WR9cXMsTXlOibbHhkYdLOAUZTE6TdBUwiJ4oqI91X5XR8LkN6W4NZ5Bam0K4CadcAAU0MS6eH/rtaer5UIL6hFBYvu92EtDEyzjwpZx6PLIyhxY70tgrpLRXS22rkjwz4FRGUbRpSrgHChiTOXj/KKhPKR3r672lQVpsIaWOM56cYSY6TduUJqKPCBPiBDuUjPU6xj1JqXChsGZ5jKD5K3JrF0xdEXWXE2u4i6y+wsbTJ2dkZOxu7TOZnGPAPEtTGsXd5SDlzrMytcXx0zNHBMQe7ByzPrDE5ME3WUyDtyrM4tcLR4bEAvZMrFOJDBBwhlqdXWRhbZHlmjcP9Qw73j1icEr5dSNgE/7YAoHscH51wsHfIwuQyGU8Rd18AlzRIxp2nlJlkdmSe7fUd5scWhNzmPiEZw9bhJmbOkPMVGc9Nkg8OkXHl8fQHsXS4sXS4sXa68SnCpF0DZFx5IvoEfnkIe7fgkbZ1enD0eLF0eJBUyYgYEvhVUZxiYWrv6PEKi4rtLqydHjyKMEl7lkJwhKnB2XI++58/vp7E8axxcGlpiampqW8A9LNK70uA/tvT981Nl7pURUXFJUBf6sU6OTnhRz/60V8F0NlsloODgxdeL6XHufr/3uf+r+t4+G9N1P+7iI4rvRfKT7bWd6h9rZUb/1xN5W+befibRh691Iizx1cG1dOTU7T1ZmpeaeXRy808/NdGbv+siqZ3uthafZ7WkXYOIL4mp/n9bmpebeXWz2u49fNqhhPPC1JWZldR1hmoeruZto97qXm1jVv/XEVA+3wh8vjwmKQtK+T5nsPxw9804OoNXlhamhmeJ6COoGu0ILmtoPbNNowiK3NzcywsLDAzM8Pw4AgOpRtZgwrRtW6q326i84EYu9GB1+UjHA4TiURwml2oOrVIHvXTdb8XeaMKo8SKQ+0hE80xMzPDwsICHquXqCtJyjtAQBfB2ObAqwidL1at8PjxY8EjunvI+tIGIX2C3ptqjC02vIoIWW+B5ennVe2bK9vYxT6a3++h97YKs8iFXx1lwFdkZ32XJ0+eMDMyh6rGTOO7nbR90ouqyiwsS+oTlFITHO4fMZocQ11lpO0jCS0f9ND1hQxtvQV3X4iENctEcRqD1Iy5zYm8ykDHlX5aP5QgvfUs4znCYHSUUmqckC6OpctD/3nkXceVPmT3dZjbBK/6SGqMpHMAnyKCsU2oBu+5Kkyh++9p8SrCTOanKUZGiJlTOHv9aOqtiG+qkNxUIL+vJ6COszi1zER+mqyvSFAXx97jRX5fh/SWCmuHi6HYKLtbe4S9UVIewf/rUYRQ15nR1VtJ2LOszq9zdnbGyfEpsyPzDEaF13R0eQlq4syNL3B4cMjRgQC+u1t7TA/OMhgaIeXIMVWcYX/3kP3dAxYnlpkZmmN1fp3NlW2WplZYnFxmd2ufw/1zqHXliVszjCTGmB9bZH/ngOPDYw72D1maWSHjKeCUeHFKAsStaXQSo3Bu94Cl6VWyviLuviDGFjsWkZOoMU3ON8jEwBSl9CSF0DDu/iCmVgfGNieGZrtQ3GLLMuAbJOMcIKRP4hD7MDXbsbQ7sXZ4MLc6CGqEbxKixhROib88Zbe0uzE0Cakd3r4gMWOqbMGImVIEVDEMTXbsPQJAG1ocyOrUGDvseBVhgpoYIX0StzSIo8eHSeTCJQ3gEPsJqCLkfUWWplZeuFD450kcuVyOyclJ5ubmvgHQX331FeFwmHg8fgnQf2P6vrnpUpeqqKi4BOhLvVh//OMf+cEPfvBXAXShUGB7e/uF120dHu7+3zoevtRE9cvN3PhJJc3vd5ctCU+fPmUiP4XoYzH1b4h49Ntm7vyylhs/fsTMeXbz06dPOdg5wNzqRHxDSfP73VS/JuLajx8S1iUu3CTzwWEMLTZ6b6vouCLl0UvNmFrtF26smytbuOVBGq600XNLQf07HfQ90FyA3rHSGH5LEHmDhrZrPVS/3UjjZyIcRid+b4BIJEIkEsHvDaCTGJBWK+i4I6HrtgR9jxmX1kchW2Rubo7FxUVmJmfJRwdJeHNYe9wYW+14FSFy/iLrS88/TBwdHLO1uo2nL4D4hgJ9kwWvPELWW2RrVbCgjI6OMj02ja3bTf2b7fTeUmFqdeJXRSmEhsvLVKuza+garNS+3kbL+z3IH+gxtbmI6AXf6pMnT5gfW0JTZ6b5AzENbwp+a2W1CafET9ycZmt1h4WJJWxdbmQP9Ig+kdLwdjeS688mwqFzO8EKEUMKS4eb/ntaWj+U0PJ+D723BJtN3JJleXYVaaMCrzwsFMvc0SD6SELHlX6ktzX4VFGWZ9cYz00Tt2Rw9wbQNdrpvqag/bM+pHfUBNRxNpa3WJxcEfKI9QnsYh+Khwa6v1SgqbNQCA2zt73H4d4R45kpsp4CAVUUXYMN+QMdAU2c5ZlVTk9PefLkCavzG4wkxknaszh7/TjEPqHpcHe/DL2lkRK5WJ6RxBgpxwCDkRF2NnbZ295ncWKZ2eE5NpY2Odw7ZG1hg8WJJTaXtzjYP2J+YomUIydAb3KMpckVjg6OOD485ujgiJXZVbLePJYOF06xn5RDmLAvTSxzcnzC+sIGA4EhXFI/unoLxmY7EX2SnLfIeG6K+dIio+lx3LIghiY7+kYrugYhKzxmTtPfoqIQHiHtHMAlDaCrt2JodmBscWBoshNQRch4CqSdOXyKMBFTGqfEh7HRhq7BiqnFgas3QEiXIG7J4FcJWc8hXQJDiwNbuxtjsx1jswOvPETUmMInCxPWx4lbhfO6RhsWkQtrlxBT55YKxSkJa4aMt3g+ZResG88emmYj6mYDOX+BrLdIyiU0RjrFPpw9fsH24y4wMzLP3vZfTuP4OkCPj49TLBZZWlr6VoBOJBKkUil+//vf81//9V/f91vypc71fXPTpS5VUVFxCdCXerH+9Kc/8fd///ff6W1+9hgeHmZ9ff1br52dPcYu9tB+RUr9W+3UvNrK9Z88wq+6GH03MzyPpt5Cz3UZoo8l1LzWhrJSf+H1jw6OiJqSaBss9NyU0/xhFx1Xe5mZnilD7+TkJPFAEnmTBtH1bmrebabq/SasGhvBQLAMvaFgCIvKRtvdLkQ3emj6tAONyIjXFGB0uMTs7CyLi4sszi8ynB4lZk+jrjOib7HiU4YpRkbY33k+dT89OWVzdQtzuwPJLRW6Jis+eZh8aOhCMsDB/iHmdhc1r7XRe0uJsdmOTx5mOF4qLy7ubu1jaLJS+dsmmt/rov+uRqhm1sSYH1sUPrRkivTeU9DwTjfV5w2P8od6bF0ekvYch3tHbK/t4BT7kd5V0/qBhPrX2+m+KkNTa8bZG2BmcI7DvSNipjTmNgd99zS0vC+m8a0uxNflaOvNZFwD7O8cMJwYwyMLo2+yI72rpfm8Glx8XYVfHWN3c4+5kQUStgxOqeC77r4mp+UDMZ1X5QRVUQE2t/aRizSEDUkcPT5U1SZEH0uR39eS8w+xv3vA2dljZobmGPAJ1gVzh4veW2qcEj/z44tlW8z+9j5jmUlSLsF6YelwUYyMsLu5y9HBMceHwvLm5vIWY9kpsq48OU+B1fl1djZ3mR9fYnZkns2VLU5PT9la3WFpcpmV2XX2dw+YH1skYc2QtGUZTowxlBlheHiUk6MTDvaPWFvYIOPOY2p14RL7STlyjCbGWJ5e5exMyOAuhodxSnyoa4wYmmyEdAkyrjxj2UnW5teZHp7Dr4qgq7cif2hAUy20EcYMSfKBIcYyExTDI/hkEbQNNtQ1ZjS1JnQNVnznMXaF4BBRc5qYKYWrV4jD09ZZ0NaZsXd6COni9DUoCagipJw5QroEtm4funorujorunoLnv4QCWsGnyIiNAS68ufQK4C2UKbiwNUbxK8U2hRz3gJhfQJ3bwCTyIGpxSHkPEu8xExpsp4ChfAIWU8Bv1Lwjds7vbh7A8StGSaLs0zmZ5gsTlMICX8Ge6cXvzxMypVnZmSexbkl0skM86VFSplJEvYsYX2CfHiYxYklDnYPhbbPc/vQX3qv+noSx8rKCslkktXV1W8F6GKxSDKZ5Pe//z3//d///X2/JV/qXN83N13qUhUVFZcAfanv1l8L0OPj4ywtLb3whpX15FHXGui+JqPt4x5ar/QwNjR2AXpz6TxqkYG26z1Uv9fCozfqMckthEPhMvRGIhFcZjfyZjXt13qoebcFVYuOiCvG+Nh4GXqXl5cZG5wgZk8iva9B12jFpxKWrr6+uPj48WMcJifqWhPimyp0jTZ8ihCjqfEyzD59+pSDg0N09RZqX2+j94YSXYMQ9/WsiOTp06ccHh5jbHJw91/qaHqni95bKgxNVvyqKJurwnT+8OAYW6ebmldbqXy5BdEnEqS31ZhELrKeIqcnpxwfnRDSxOm+fp7L/Fo77Z/2oqwy4BT7WZ1d4+z0DK8uQNftXqS3VLS+303t6yK6r8pRVhkphkc4O3vMdHEWnzKMrkGYxje+20XdGx10X5UR1ic4Ojhie22XuC2Do9ePts6C+IaSxjfaaf1QTEAdY39nn5PjU0qZSaLGFHaxH02dhdYPxfRcV5J25Tk8b4FcnV9nIDBISBfH2uVBekONvsHO9PBseTJ4enKKSWEl5RogqIljbHUSs6TZXN3m6OC43Mp4sHvI9OAsA/5BkrYc86UFNle3mS8tMldaLNtK9ncOWJ5eYWl6me2NXT8aiicAACAASURBVOZG54mZUySsWUqpCdYXhfzvk+NTjg6O2FjaJOkqoG+24ejxkbQLcPzMTnSwe8BocgxblwfZAy3aRht+VZSMK08uVCQSiLMyu05Yl0RTY0Z2V4PqkQGnxC+AXWCIifwMU8UZguoo2kYr8gd65A/1aOusePqDJGxZBqOj5ANDxK1Z3P1BtPVmFI8MKB7oLnjGE9aM4BM2JnH1+lFVmVBWGlBVm3H3BYia00RNSTKePGlXHr8ygrHFjqbegq7Bhr7RiqPHh7xFR9AQYyAwSMycxqsMo2uwom+yYmixY+lwCz7i0DCl7ARZb4GQLoFJ5MTY6sDW7SZqSDGRnxYSNPLTDMVHSTpz2Lq9OLp9xMxppgoz7G7ucXZ2xurcOhOFaQG0dUnSzhzTw3PnaRwC9J4cn7A8vcpkYYaRxBgLE8vs7xxwenrK4f4R60sbeB0+9ncO2NnYZXtth6ODI05Pz84n/0sMJ0qM56ZZ+I4ila//m3/6VFgkPDw8JBgMsrm5+a0APTExUc6DvgTovx1939x0qUtVVFRcAvSlvl1/+tOfePr0KT/4wQ/IZrMEAgFyuRwrKysXoLdUKjE8PEwsFiMSiZBKpcq//vrD7w6gFGlp/qyDqreakNWrSIXSTE5OlqF3ZWWFmclZguY4PTflaGuNBNRR5koL34D41fl1ZPe09N5SoWu04pWHmB1duHDm6OgI+UM9dW92ILmmRFNtxiMLsTr/fFJ+enpK7Sct3PlFDU3vddHzpRxtnZmgLla+EZ+dneGVh3jwUiNVv2uh5f0ewbrQaGU4WSrflDOuPO2fSql/u4P6Nzpoe1+C9LYKp9jH7vlS03huCk2DmZ5rMprf7aLu9XbaPpLQ/0DH+MAkT548YX1xE58ygrpOqJ1ufLuTmtdaaftQQsKW5vT0jOPDY0LmOD33+9DUmpFcV1D9Shv1b3US0MTKFekzwwJMOsRe1DVmmt/vofVDMSlnrmyfOdg9ZCg6SsSQwt7lRXpbjeyenvHcZBk2njx5wsrcOvngECFtHJPIiV8RYWV2laOD4/KSp9CkuEwxPELSmmU0PcHa4iZzowvMjwsxZU+fPiWTzjJdmmVxcpm1hQ1mhmeJGJIkbVlGU+Nlm8rZmRCJtrG8RdKeQ9cgwGDClmU0OVY+d3R4zGR+SqjOvqVBW2fGr4iQcQ1QykxysHvIzsYuSXsORaUe8XUF8ns6HN1eQtoYA75BpotzrM6tEzWn0TXY6LulpveWCk2dMK2PmdIUQkMY+s2knDk8fULRSN9dLdK7GsxtTvzKCFl3nmJomLx/iJg5jUsaQF1lQnZPi+KRQYjOMyTJeQoUQsNk3PnzBUc3yocGlFUG1DUm7F1eks4BCqFhBmMl4lahQlxbb0FTY0RTZ8LQ4iBpyzKRn2Y8N0nWK1SI2zq9aBvMmFqEn9NEbop8Kk8qkGU0PS4sBUoDWEQuApoYo6lxttd2ODt7zP72PlPFWQrhYaLGJBFDkrHMJDtrO2Xoffz4MVurO8wMzTOcGGOqOCtEzJ2ecbh/xObqFjsbuxwdHrO/vc/2+g572/tChN3uAQsTSwzFS5QykyxOLHN0cCzA9MkJe1v7zI7Mk/UUCWriJGwZ1N16ZkfmOdg9ZGtlm/HsJAl7Dq8ijEPsLX9wmSrOMj+2eCG159t80F+v9PZ4POzs7HwrQM/PzxMKhS4B+m9M3zc3XepSFRUVlwB9qee6cuUKP/zhD/nhD3/IP/zDP/CjH/2Iv/u7v+Mf//Ef+dnPfkZLSwtjY2PfgN6NjQ3Gx8cZHR3l+Pj4hR7E+fElpLe1SG9r0Nab8SsjbKxcTOE4PDxCclNJ07vddF3tR11lIqCKcLB7cOEGqGuwcvcXtTS+3UnHlT5UlUaStuyF1w7rE9z+eTW1r4tofLuTzs/7UNeaWBh/PikvJce4/ssHVL/aQvO73TS9203PFzI8/cHypHpldg1ltZHOz/tpfreLxjc7aXhTRN8dDUvTQpHK0f4RAXUUxSMDHZ/303gee9f8TjcD/sHyTXskMY5D7ENZJdRO177SSvXLLYT1ibItYWN5i7g1jb3bi6raRNunUureaCdqTpXTOs5OzyjGhpHWKrF3e5E90NF9VcZgbKT8PE+fClF2Q7FRwsYE1g439g4XMyNCTu6zCfuTJ0/YWNo89/XmKASGmB9fYm50QYCbc/vJ48eP2V7bYWlqlaWZFcZzk4T1CVKOAcayU2U4fjbt3VrdIm7NoKk1Yev2kLAJE+H97X1KpRKLC4vMjMxh7XTR9WW/UOIhj5B25hjPTXF8KFgwiuERlI8MdFzpo++2GkuHUCed8xWZHV3gYPeAtHMAfb0FyU2V8P9NtRF7t4+oIclgdITVuXWKwWFcUj/6ZjviWyrE15XnMXYRUs48pcwEI8kxYpa0sGxYY6b3uoL+uxpsnR5CmhjFyAiqTq2QiqERpuzyh3r672hRVhqwtLtJOgaYLE4zmhojYc8KXu8WO4pKHYpKA7oGKwlLhqWpFaYKM+SDQ0SNKdzSAPJKA5p6C57+ACPJMXY391iZW6eUnSTjKRBQRzE02XBJAxSjw0KE3OkZpyenLIwvMZQonfuTIxSCw6wvrHN6csrZ2WOWl5cZzA8yP7bIaGqCUnqc9YV1To5PONw/LEOvMKk/LpfKnJxH2C1OLjMYGy1D7/HhMU+ePBFym7f3mRtdIOPJ41dHSFizjCbHy1X2e1v7TA/OkbRm8PaHsHZ6CKhiDPiLTOVnmB2eY3FyhYy7iLPXL1R1d3lwSwOknDnUXQaGkqMMhkdIn9t1HD1eHGIvlk43IW2cfHCYkcQYc6ML5W8xXgTQX/dBezwednd3vxWgV1ZW8Pl8/OEPf+CPf/zj9/0Wfalzfd/cdKlLVVRUXAL0pb5bP/3pT5mamnrhzejZY2VlhVKp9J1nVFUG7v9rPfVvddD2sQTpHS2jqfELZ5L2DDd/Ukn9m53Uv9lB2wcSFFV6djb2noN4aZ6610TUvtpK6/ti6t/qoOW9LmKW1NfAcQ91tZHm93tofKeLpnd7qHmlhd6bKnY298rTzbg5TdVbTTS/J8Bz5W+bqHu9ldHM89/X/Ngitk4vsgd6Oj6TUvuaiHu/aiBuzVxoK0w5cmWgar/SS+XLLYT18QtQP19aJGZOYu32oKg00n5FStIzcOHMydEJY9lJIoYEti4PxmYHo6lS2c/77NzO5i66XiNppxAFNpGfYnZkgZXZtQsAIVgcVlmYXGIoNkpIGyflGGCiMHPh6+7Tk9Ny+YqqxoSj20vClmE8O1U+9+TJExanloXa9U/6UNeZ8cqCJO0DTOSnOTufUI5lJlA+1CP6UJjWm9qceOURMu48y9MrTE1M4dMH0Tfa6PlSQfvHEgFAO1yE9QmGYgI8ltITuPtC6BusSG4q6fq8X7BByIIkHTlmR+aZHpojYcvgkgbQ1Jvpviqj96awUBlQRRmKlVicXCYfGCKgjgmxcg91iK/JzxcqnaQcOVbn1xjLTpJ25vAqIpjanfTeUtF3S4WmxkTUlGZjZROL2kYhNETMksbVF0RZaUD2UIet081wfJS9rT32dw6E+LnAECF9AmOLA4vIRdaTZ21xg9PTs/NvGzYYy0yQtA+c13JnWZoWlgaf/azPTs9Ynd9gIjfNcLzE0tQKhwdHF6D39OSUs9Mz9rb22Vnf5fjwWIiom1ymeJ5oMl6YJBlPlr9VOdg7ZHFimay3gE8VIW5OMRwvMV9a5OTohMP9I+bGFkg6hKVDS5sbvzJK7rywZL60wPriJoXgMO7eIJYOF8Y2By6Jn7glw4B/kMniLGO5KfKBQQKqKNYuL9ZOd9nPP+AtMhQdJR8cLk/jg+e13/Zuj2CL0SWxyJwEzVEynjz54DARYwpPX0hIAGl14FNFyPmKDMdLzI0uXLBfvcjG8Qyg/X7/Cz3Qi4uL+P1+njx5cgnQf0P6vrnpUpeqqKi4BOhLfbdefvllstnsXwTozc1NBgcHX3h9bX6dBy81UPe6CNFHEurfbKf2tTaG4qULAKepNlHzahvN73XR9mEPD/61kd47ak6OnwPhQGCI7i/lNL/XTePbnVT+rpmH/9bE/MTzyfLWyjaWDjfSuxraPpJQ90YHd35WQ9qdK585O3vMgL9Ix00JXdf7ab8i5eG/NeNTXGxV3FzeJm5JY+kUwKv9EykhTewCzD5+/Ji50iJRcxqH2Iu+3kralS9P6cpwfHzK7NAcWW+BhDVNMTLE7MgCa4sbF276J0cnrC2sMzs+T9aTJ6SLkXYNMDs8dyETOxQMsbW+Q0AdQfnIgL3LS9yaYao4e+Hc2sI6xjYHrR9IUFebcEsFAJ0emi9Px2dHF1A9MtLwVgeSG0oMzXY8shAp5wCbK1s8efKEqcFZDM12uj7vp+0jCfL7eoytQu30SHKM48Nj5ksLeGVhNDUWxNcUdFyRoqoy4hQHSFjSLE+vMloYQyMy4ewNoKk10/l5H5LrCuE1+0OMJMbYWd9lMDpKSBfH3O5CWWmk47M+eu+qMTTbSTkH2NncY6o4Q8adx6eMYBI56b2tovOLfuQPtCQsKXY2dtlc2WIoXiJuTeORhVBWGpHcVGBotFKMDAue25NTZobnKIRHiJqSmEVudHVmoqYky3NrnJ7/fBLRJPnokGAxUEYJamLMjS5w9OcfcNZ3mRqcZSheYnpolr2dAw72Dtha3WZva5+zc4h+Zi852D3g8OCIxckVitFRxtITLE4sl78JefLkiXB9apm0u4CnP0jMlGIoVmK+tMDJ8SmnJ6eszq2R9eRx9vowtggJKRl3npH0OGaVVfB4pybwycMYmmwYmmzYuz3EDElyvmLZBjEUKxHUxrF2ejC1OtA3WstLiIXQCKXUBCOxMTKePEFtDGOLE0uHC0u7m5AuQc5boJSaIOcrkA8OkbTn8CuECbqx1YFPLmR5F0LDpOw5RlMT5M7zri0dbhxiH9YuN155BKfCh7XPyWhmgnxgiKQjh1cewi724ujxYu/xEjOlmMhNXVjs/WsAOhgMMjMz860APTc3RzweZ2dn5xKg/4b0fXPTpS5VUVFxCdCX+m59+OGH+Hy+v3hD2tvbY2Bg4IXXpwZnaPlQQsNbnTS920X1K23c/1U964vP/ciH+4fYOzxCcsN73TS81c6dn1aR9RUvPFcpM4mx2UnvHTVtn0io/G0TbmngwpnD84mwpcOJ/IGezs/7cUp837CXrC2so+8yo6rTo2s0E9ImODo8+sbNdnFqlQHfIHFjiqQjzdzoPFtr2xee7+zsMZvL20yPzhI1pgjp4mQ8BRYnlr4B29sbO7j7gygr9di7vcQtGebHLp7bWttG32Sn5YMelJXCAmHSlmV56nl2s83gQF1loPrVNsG/XS8kOKScA2WQWJ1bw9DsoPXjXlo/kCC9IwCoXxGhlJ7g7OwxG0tb+BVhVFUmeq7K6fhUyFu2dXmImZJsrm5zsHtIypHD1RtAWWWg47M+ur7oR99oxdXrYyI3ydHhMWPZqfPCGBeKSj3tn0jp/lKOvsFK2pnj+PCYiaFp1CLdeZSdE+ktNaJPhYXIqDnN/s4BR/tHlFLjxG1ZPOeNfp2f9aGuNVIMD5Ur2Vdn1xiMjBAzp7F1e1A8MuBVRliaWilD7+nJKXOjC+SDwwR1cbyyMGO5SQ73jy78nR8dHLNQWmQkMc5YdpL/j733aG4sT9N7udBXUIQi9BG0GIV22mmrzdV24kozVzNxpbkaVU93dXeZLu/SVxomvfckSMJ7770HCMIQBEADggAIAgRI1uTI9O8uDogkksyq6rl3Ijui+UaciI7GqYOTOCDO7/+e532e48MaJ7Vr0Ns5J5lMspMVBuHqlRMaJw1B3tCF3mJ6r7d4ubi4oNVssbezj0cdRDVtwLrpImyNs7tVpH3W7rmE+HRB5KOa3jX0KAN9NnbZaB7jso3VxxKWH24gGRL8t4WOsBBDvh3MYhY5kIxoelHeunkzdqkQMrI2vU7Sm8KrDXW17CpWu0BrWLHh0QTZ8m4TtsSJ2OK4lH70y1ZEXSs7zYwRm8RDwBglZImR9G3j1YUwrzkEOcVQ1y96zoxL4SNiT7LlTRMyx3Crg+iXrWy8UCIb1SJ5qcK85iDh2mI7kCEdzuHThbFLPUhHtchGNWjnTLgUXqLuBBadlWx0l4Q7hUvhQz1lwrhsx68LkU8UhMHFn+g8X/8bvLwUBglNJhPRaPRWgE6n0wSDQfL5PL///e/f9c/xXXXrXXPTXd3VwMDAHUDf1Y/Xp59+ikgk+skbUrPZxOVyvfX1wvYeq4+ljH08x4v3JnjwnweRjqj79um0OwQMETZeKJj9ao3RD2bZeCG/kXBYq9RxK/0oJoRBKe2siXrtZtepsndM0BTFInJgXLOTie5QP+5PKLu4uCASjGFTO9AvmjGuCfHJB8Wjm8c7PEY2qmbp/ibyEUHTe5Dvt+6rHddZfSjm+XvjzH0rQj6qwSn1UNl/7ZFdLddYfrDJvf/0nLEP5lm+v4FyQodPF6LVHf6rV+pIhlQ8+29jDL43weTHi6w8FqObM/ecP07rp4x9M8XMF8uM/WaW0d/MMf3ZEpLnSqwbLhq1U85abYL6iBAM8s0aY7+dY+T9GZbubaAYVZONCImL2cgOlnUnG88VzH0tdNlHfj3L4r1NfDrBHaReOcGrDaGdNwn+zV+s8vRvxpj8aAG71M3pSZNO55ztYFYYsps1IXoqZfhXM8x8voxPH+6lQJb3j1geFWGXeVBO6Jj7WoRiXEsusdM/uJg7IGKNY1pzoJoyEDJFqFcbfV39TrvDXu6AuDtF1J7gIH9I/bjO8UGVk2qjTwpxUm1QO6pzUhcG2UKmCAlXir3sfh98tdvtrkVdENWUAcu6k4g1RiFVJJfNkU6nqR3VCVliyMbULD3YQDVlwKXwEXVsUUwLNnb7uQPMIgerjyTMfyNC/EKJccWGRxUg4d2msn9MIVXEKnYhHdWy2I3z1swKNnZBY5RsZId8stiDXtmolsV7m71FkFsVIOFKkQpmiLm2hNjvBQui72WsPNhEMSlowf26COI5GWF7jIAxglnkFJ4UPJKy/lSOZtaIXeom6UmR8mVIuFNd72wbmy+UwjaoQL9oIepIUMrskwntEDRFccq9KMb1bA4qUU3qsWy4SYey1I8bFFMltropibp5M+pZA06Fn0wkx/FBjU53KDafELTZLqWfgCFCYbtE/fikN7RotVo5rTfZy+6zE9+lXDyi2WgKmvvmmTCI+I8AaIvFgsPhuBWgr2Y+YrHYHUD/EdW75qa7uquBgYE7gL6rH68nT54wPj7+s25INpvtra+ftdoEjVFkYxrWvpegGNNQPare2K9RaxC1JzCt2NHMGkmHcj2o7Osw10/ZDqRRTxsxrtgIWmLUKvUb+5X3j1l/Lmf53jqyETVupZ/aUa1vn1QixfNfjjL4iwnmvl5DMqzCpfBxWj/t644v3d/g3l8+Z/Q3s8x/tYp8TEvQHO1N/J82WijGdTz6q0GGfjnTtZRbRz1tpNjtGrfP2jikHiY/WWLk/RnGPpxn4qMF1h6LcUq9Pe1ywpNic0jJzOfLjH0wy8hv5pj+fBnpsKp3rHLxiJnHSyx8t8bM58sMvz/Ny19OMffVKhFrrOdgETLH0MwZEX0v+Dc/+b+HePn+NE65pyeNKW6XcCl9qGeNiJ5KGfrlNOO/ncOrC/UcPVqnLba8aRxSL4pJPQtfryF6KiUdyfYNLlbLNeLOLSzrTlSTehxSD9VyrQ96Ly4uUEnUbPkzRKxxdrcKVI8Ei7JG7bS375XEoXZUp1qpk9/aFaDXneJg97DPbaHT6XBYKONVB1CM6zCv2QlbY33JdI36KTHXFpKXSha+EQnnJ/cSsSfZzx1weXnJ8UEVp9zHysNNpj4TpCz6RQtuRYCEO0U+s4vd6MClCCAb1bD03SYL326gGNNhWrXjN4TJRvIclY4JmgRQlY8JCxjRYwnaORNOueA2Usrss+VN41b60S1Z2XihYOFrEdJhNaZVB15tiExkh3Q4S8AYxSZ2o541svJQzMoDMcoJHTaxi6QnTWG7xJY/jVcTwLhiQzKsYvV7CaInwsIr5kjisnrwW4JE7HHcKj+aOSOrj6VIhlQYV2yk/BmaJ02O9ipshzLdCHEH8lEtlg0XCU+KcqnS07rvdwNvvJoQboWPdDTL8WGt77q0z9qUi0fsJAqUMvs06qe3Qm+n3enZGJ6fn1OvNihl98nFd9nfOcSge53+2WqecVSqkI3l8WmDuJR+Ep4U+WThRwcIr3//rpw4rFYrFoulJ+m4vkWjUfb393E6nXcA/UdU75qb7uquBgYG7gD6rn68pqenefTo0c/q6lgslh99/azVJunZRjGhw7hqJe7auhWO93cPWPteyvL9DaTDavz6yI2bYu24zvTnKwz/aorpz5fZHFTi14f7OlCtVovF79a4/5cvGH5/munPVhC/VJL0vR6K7HQ6rL+U8uH/8RWjv55j5NezzH6xgnxcx/FBtXez9WrDDP96muFfzzD58RKjv5lh8bsNvOpA76ae3yoieiJl/KN5xj7sbh/MInmpprxX6S4QTjGLHKw9kTL5u0VGfzvLs/82ztTvltnybfccAhLubQFunkiZ+GSRp/9lhOd/O45L5e/JEo4PqohGJawNSll7ImHkV9MM/mICjzrI2ZWtXOecbHQHh7wrvfh2g4Vv1khes6i7vBSkCyl/BpvEjXragHHFxmHx6IZ94Em1IcRPW+Nsh3Ic7R9zfFjjtN58I/BGiKqulmvkEnmCxigJd4py6aj3vlarlfPzc8p7FdxKH7IxDeY1OyFLnL2dw97xzlpnpAIZNl8omP1yBfm4IHmJ2BKUu08KTk+aBPRh1h5JGP9gnrXHUgFUFT4Sri0atVMatVP8ujCyETWL99aZ+3IVyYgaw7IVvzZMJpLn9KQpLOBEdmTjGua+XmPpgaDVtnWH7Eo7e0gWZHhUgu56Y1DJ7JcriF+qhDQ/dZBsbJdSZo+wNY5N4hF8nh9KWPxuHemoBsu6k4Q7RWW/ypY/00vhU4zrWLq3zvJ366imDURsCU6qDfLJYq+7rFuwsPpQguipDN2ChYRvm+ZJk9N6k3Roh5BZGLKTD2vQLViI2BMcFI4EGcvODiFPmHQwh18vDEIm3Fscdd08rgPm8UGN3a0iu1tFquVaL6b8OvReXFz03FI6nQ4ntVNKuX1yMQF6r//ddtodauUa2cQuXk1AsCJ0bZFPFnqzAifHJ2wHMjikHjRzZkG/rRGGFlUbGo7KFY5KFUKmGIZFG/IxLYoJHU65D78hSjaap9R1xvkpgL7SQVutVjweD2dnZ7cGqdRqNY6Pj9/1T/FdXat3zU13dVcDAwN3AH1XP15isZjPPvvs/xeAruwfM/XJIqO/nmH60yU2nslJuPtdOM7Ozpj5YpmH/3mQoV9NCX7Lz+S9ruvVzU8zZ+Lef3zG2AfzDP9qmonfLaKa0tNsvNYvJ1xJnv23UUZ/O8f0p0sMvT/N1CeLRO3x3j5HpQpzX63y5X96yMTHC0x+vMTg302wOajipKuxPWu1sYndLHy3ztiHc4x/MM+zvx1n5Dcz5GKvvadzsTzqGQNLDzYZ+1AIQXn01y/xG0J9bh1eTQjltIHlh5sM/3qGJ/9lFI8q0Ae0pexBV2+sZ/neBtOfLhJ1Jvs11+0Odo0T2bQSzawJzYyJYvomPJw1z8gnCoRscRLebSGFr1y/EThx1mpTPz7h+KDKdiRL0Bgl6d3uBZZc3/f4sIpN4kE2qsa8aidsiXNUqvRePz8/JxvPIx5UMPXpEtJhFdYNF2FrguMD4QmA0+HEZwix8kjM8C9nWHkoQT1tEMDKvdXzl446EkiG1cx/I2L682U2nivRLZjxaARQ7XTO2fZnhPCWMSH8ZPG7DeSjGiwiBxFbnJNqg0KqhEstpOttvlAy8+UK609f63XzyQLVco2ovWtlN21g9YmE2c9XEA+pMC7bSLhTnFRPEM1s4tcLgTHKCT1z36wz9/UaslEtIWtc6OKWKsTdW0K4yZKVtScSlu5toprQE3elBMlLuyMM7Nnj2KUeZENqFONaAoYIB/nDnpa62WiRi+UJm2PYxW4CpggH+XLfcO3VAq2Y2WMnvsvR3jFnZ+0+6L0a9r36/658m/d3DoRh1vwb0Ns5p145Ib9VxKMJ4pB6iTmS5BO7vcVvs9FiJ1HAIRNkO6pJPW6lX+jWJwq0z9qcHJ8QcyYxrdgQDymRjWiwbrrx68OkwzmK23tUyzUSrhQOmRfNrAnpkAr9kgWvJkDQGMOssBLxxkgHBOs/u8SDatqIYkKLac2O3xAhHcqST94e6PTmdpVIaLVaSSaTHB4e3gBon8/H6ekpf//3f/+uf4rv6lq9a266q7saGBi4A+i7+vEymUy89957Pxugfyy1UD2t59v/8yljH8wz9P4Mw+9Po50390FhOpTjwV8OMv7RAtOfLTP8yylGfjXDTqLQ1wVd+G6dwfemmPp0ienPlnn6X0eQDqn6OmNuVYCZz1cY/s0MEx8v8PxvJxj8xST7u691y4e7R8hGNNz7r98z8ptZBv/7OPf+4jlhe6wPVMPmGIoJLQv3BD/ih//5BQ6Fp3+BcHCMS+FHMaln6f4GEx8v4L0Gz1fnVcru41b60c6aUIzryER2bnxWnc45e7l9wraEYMOWKlKv1G904nfzu4T8YY72KyS92wSMEVL+157M17dquYZ104V0RI1xxU7EGqdarvWdW2G7yPozOVOfLCN+qcYicgpd0O7xzs/P2Q5lWHm4yeAvpli6t4liQodNItjdnbWEobh0KIdkSMXcV2tMf7aC6KkM7awRl8pPYbvE5eUlBpkJ+ZTg4zv/9RqL362z2dUIR2wJmidNKvtVPOpg10tZwdyXq6w8FAtpflIPhe09Wqctkt5t7FK3kKb4l8VxcQAAIABJREFUWMLU58uInsrRLZhJelK0z9oUUiUCBsHlQTGhY/7bdWa/WEEyqCRkjtE6bdGonbLlTfe0v6Lvpcx8voxsWE3ctdXT3MpFCqKOJE6FD8W4FvELJU65l1J2vy9UprC9R9SRxC714lL62N0u0XrjGp612uznD8nFd4VgmtMmZ612t6vbv2BqNlqCb3OjxX7+kJ34LvtvQK8ge2lQSJfwaUPYxR4iVsGpo149weFw0D5rU8rt41b5UU3pkY9pcMq8xJxdH+VWm7PmGelQDuu6A3FXA23pumtsBzIUu17Q6WAWl8KHbt7E5gsl2jkzDrmXoDFKJpzl+KDKTmxXgF6ZF+2cCfELBaY1B359mC1/mlx8l3yywJY/jU8XwrTmQDykQrdgFtIRjVFcei92vZNMdIeAKYpT4UO3YBFSG5eFMJykN917KvFzAPr8/By73U6xWCSdTt8AaJdL8F6/A+g/rnrX3HRXdzUwMHAH0Hf14xUKhfiLv/iLn3VDstvtfVrY61v7rM381yKe/e0Y05+vMPPFCg/+r0FU0/q+/cKWGGO/nWX4/Wkmf7fI8/cmePb/jFE7eq1vPjluCIl5ny8z9P4Ug7+c5Nv/+JSkN9V3rLhrC+mwipmvVhn+9QyP/moIh9zdt8/pSROvOsCzD4dZvr/B+IfzOGSeG+df2T/GpwminjYiH9UScyVv7HNxcUG5VCHm2iJoipIJ54T0tWt2clf7ndaFiOKoM4nfGCETyt0aQVyr1DCs2JANqzEs24jaEz33ictLwT7QorOy9r2MiY/m2XypxLjWBdBrx9tNFVm5v8nge5MsfCtCOqrGuuki5U/3IK2U2UM6pGLqkyVmv1xl+b4Y5aQep9zDwa4Qc10uVjCvOdh4Lmf+m3UW722w8UyObt5C1J4U/IPrTYLGCOoZI+vPZMx/J2Lpu3UU41psYhd7Owecn59jkllQzGpQTOhZeSxm5gshYEc9bSDl2xZcTfYqBC1RjKt25ONaFr5bZ/LjRTaeKwiZY5w1z2iftckEc3i0QQxLVtafy3tPLmKOZK9TWi3XSLi3cSr8KCd1iJ7IMK05KGX7XTPKxSMS7hROmReb2E02utP3ZOPy8hKXy00xt0c+WaCY3uek1rgVes/PBR36WfOM00aTvW6n903ovbwUNPTFdBGvNoht00XYGmMnnu+d//n5OYeFCgFDCMW4DsmQGofETcQWZye+2wtM2d0qYhe72XihYv2pvDe0uOVLU0yVMBlN7CYKXTmI4IKinjZg23AJXdxglnrlhGJKcBZxyn1o582sP5VjWLLiVQvuIDvxAuXSEdvBLD59GNOaA9mIGtWUHovISdAYYzuQpbJ3TDaaJ2iK4lYHMC7bBF35kpDaGHck2c+XKaRKZCKCE4dV7EI5KYC9YUmINM/EstjNDrKRPDHnFl5tEPWMEfW0Ad28iYAhwn7+4EdTCN8E6Farhdvt5uTkhEAgcAOgr+Y6Xr169a5/iu/qWr1rbrqruxoYGLgD6D+l+qu/+iv++T//5/yrf/WvfvZ/k8/n+Q//4T/8rBuS2+3m9PT01tdazTPkI1pGfjPH0K+mGfzlFN/9x2dsB7N9++XieTaeK5j6dJGh96d4+NdD2MT97h7tszYhcwzpiIqFe+uMfTSHZdV+4z0btVOCxiiaGSOyIQ0hU/RWwK9X6iyPreHXh0n60r3J/zf3azZaHOweErJGCZpj7CQKPY/evk7vUVWA3hE1hmULCU/qBiwd7VUQPZYy8eEC689k6JetJNypvuMdFo5YvL/B4HsTzH+1inhQiUXk6LlwXF5eUsgWefm7McY/nGf+GxGL320gG9Vgl7h7Gu6TagPruovVJ1IWvltn6f4GK4/EqKeNxBxbdLpJdhFbQvBlfixh6f4G89+IhK6jyNnTcO9uFbFLPSgmtCw92GT2yzWW7m8gH9OSCeU4Pz8XosFtcYxrDsTDKhbvbTD2wRyrTySELbEerPosfqRzSozLNjYHFV1Hkk2itkSvS9s6FbTZbpUf1YyR1UdS1DNm8qlCn2a3dlQn5cvgVgUwiRwkvCnq1ZuOK/XKSU/Xe9xN3XszoOZqwK112uqD3oPdw971iUajHB4KKX57uX082hC2DSdhS4ydRH8SXq1cI2SKIRvTIB4UHFJCltfQe3FxweFuGZfCj/i5kpVHYnQLZtwKH3H3FsVUqft9KOPThdDNm9l4rkQ+psO85sCvC5EKZKhXTjjaqxB1JHsx16KnMrTzFpwKL1Fbgp14AYPWSMK73YNe1ZQeyaAK85rgA53ypalX6uzEC8RdW7jVAQxLNtafKdDMmnArfIStcfbzZSr7VdIhITDGLvGgnNYjfqlE29UuF9N7nLXO2InvkvQKUeP6RQvyEQ2qaQMeTYhS9qAXIZ4J7xC2xLGJ3egWLXhVfjJRwTKw0+lgsViECPHoDlFbgphzi2JWGEx8WwLq27aLiwvq9To+n68n5XgToK1Wa2+48K7+eOpdc9Nd3dXAwMAdQP8plcPhIBKJ/EEAfXJywr/7d//uZ92QAoEAtVrt1tfOz8+JOxJsvlAw/42I8d8tops33bjpnbXahG1x1DNGpMNq3CrfDRs7AWabpAJC5yvuSFI/rt8qHzlrtdnb2SdgDBOyCI4Mt8GxSqZGM2dGNqrBsGxjO5i9YYlVOaiy/GCTyY8WWX0sQbtoZjuY6w/P6FrUDf5iitnPBY2tYcVK4VrIy0lV6KAP/2qGhW83mP9qDfGQEpvY3esunzXPcEo9LN1bZ+E7Ecv3xSzd20A1riPp3e65CCQ827z4cITFexssPxCz+N0Gq48lmEUO6l1XkqO9CtZNF7IxoYO78J2g15UMqcjFdnvR2zHnFsZVG5IhFUvfrTPy2zkWvl0nak/2PrPDQhmvNiQ4RjxXMvrBHLNfrBC1xvukC7lYHrc6gHbGxMp9MdJhFbnEbh/0lgp7aNZ1eDXBXkz2bU4qzUaLUmaPfGKXo9IRzdPXTg1vLqxapy0aJ6c9ecPB7uGNJwDtdoeD/CEeTRDzup2gKXpjMdSonxJzJJGNaFh/Jse85iBkirITz9Npd8hms0RDMby6kOB3/e161wbO200L3O99H0LGGLoFC+vP5UiH1BiXrb2O8Em1wWm9ScKV6oaDmNl4qkA9Y8QmdhMyx9iJCzribESwjDOLnKim9YgHleiXusfybnNSbQh2fp4UHnUAw7KNjecKVFN6bJtuAsYo+7kD3E4PQVuYoCmKoyupEHXjwd0KH7sp4W+klNlnK5DGpwtjWrUhHhS0y06Zl0KqSKctDBXmkwWiziQOmQfdvBmbxM1WIEutXOtdo9P6KTuJAjFnkpAlQT5Z4OT45MaCVnAAOaZcPOp5dHc6572/7avB007n9VY/FhYOV4mMfwhAHx8fEwqFerD8ww8/3ArQ//AP//BP+Mt8V39ovWtuuqu7GhgYuAPoP7UqlUp/EED/wz/8A//m3/ybn3VDikQilMvlt75+lfTm1YYIW+I3PJmvtk67QzG7h08bImKLcVAo3wrHlYPjrqRCg3HFxu5W4cZ+lcNjlu+vM/HxIsuPxOgWTOSThb59GrUG3/2XJ7x4b5zpz5ZZfSRBv2TloPD639JqtpCPaxn6uykW720y9+Uaa09kOKXe3iP2TuccjybA9OcrLN7bYPWRmPmv1pAOKclc6xrn4rtIh9XMfr0mhGJ04di8ZqN50uye0ylWsZvNl8KCY/mhmMlPl9l4pqDY1RBfXFyw5c8w/MUE6y+UzH+7zthvZ5n6fIWYc6sHL/XKCX5DGP2iGdH3sp51Xtga7wHtxcUFpcweHnUQzZyJpQdi1p/JyERyfZAjDL0V8etDgjRAHaBycNOO8KzV5iB/SC6Wp5Tbp3FyylnzrN+po9nE6XDSOm1xUm9QzO6TTxQ4LJZvLF7Oz88pF45wqQKYRTaCpgj5ZKEPmFrNM7Z828iG1Yi+l2FasRE0CvtdHa/ZaBE0RREPCp+rclqAy5Alzl52v7dPxBZHt2Bh87kc8ZDQUXUr/CS9aRq1Uwq7RbQb+h70il8qUYxqMYsE7+ZcTEh4LKRKAvSuO1FM6LrdWbPgDuJO9Xypk960IKlYtCAZUiMb1nS7y2H2cwe9RUnIGschE95z7bGQIGiXuMlvFel0zjk+qLEdzBAwhjGLnGy+ULL+TIFN4mF3S/gctra2CDjCJDxdaJ8zY1yx9lxBrhZL7bM2pcw+Se82fmOUdChL9bDWc3i5fq2rhzUOCxVOqg06nU4f9F4HVsH+rkOj1qC8d0S1+xTgzd+J4wOhyxyyxEh4toUwmeYZgUCAarVK86RJNrqLQ+ZBv2QVPk/v9o3vxE8B9OHhYS9EJRgMUq/XbwD0Dz/8wP/4H//jn/BX+a7+0HrX3HRXdzUwMHAH0H9q9YcC9O9//3v+7M/+7GfdkJLJJHt7ez+6z17+ANWkHumwkKK2v3sTuMvFMovfrjP5yRJL9zZRz5lu7Hdy0mT2y66N3WfLLN7bRL9ooVZ5DeXtdgfZmFYYdru/yewXKyw/2MSt8PV1oQPGCF/9xUPmv1lj7Xsps1+ssv6G88de7pDNQTnTX6wIFnsPxEx/voxl3dkDgLPmGS65F9H3Mua/FeB48tMlVh6LObwG4/nELtolC6Lv5cx/vcb4RwuMfjhHyp/uQUfrtEXIFEM3b2L1iZTxjxcYeX+GiC3R13k92jtm+ukCmlkTy482Wbq/QSqYuSFJ2MsdEDBEMa3YsIs9HBZuDlp1OueUSxVysTyF9B716glnrfYNELrS9Z7UTylm99lNFijvVW509q804S6FH9OaDb8hJHQ3r0G7yWgiE84hGVF1Fy4WfNqQAHvXQC7uTCIeVDL/jQjZiBbruoOQOcZ+vtwD+6RvG828mfVncsQvVahnjdglXpLuVM9mbye2i0PmRT1nQjqsFgYql2z4NEFyccFRpVw6ImiOYl53IB/XIR1Ro5o2YJd4iHct8cr7ZSSLctzdCHHZqAbxkBJdtyN8dV7FVImIPSE4S8ybWXsiQTqkwrLhYich/BubJ022AxkCxgiWDSeSIQ1rT6SYVux98H+0d0zKm8al8qObM6OZMxK2xCiXjnqflaCTLpPypwkaIyRcW1T2jvvcOkqlErFYnHrlhHKxQq1c63Vzb4XebpDJaf2UcrfT+6Yk6fxccOvYie8SssSIO7fY3Sr22VSetdoUtoq4FIIVn0PqJe5Ikk+89m4+a56RDe/glHtRTukxrQqDhtuhLIVUiWQySWY7Sy6ax68XZCO6eTNedUBYuER3ei4vP2fb29sjkUjw6tUrMpkMhUKhB89XFnd3AP3HV++am+7qrgYGBu4A+k+t/jEA/a//9b/+UXeNqy2dTpPP59/6+km9wfRny4z9do6pT5eZ+WoF46q1z5Xg/Pwc6YiGl7+c7ELvKnNfrRIwhPuOFbEnGP7lFGvfSxF9L2Pmi1WW729S2buW+HdYY+WxhOnPBReI1ccSxj+cxy529f49nc45HrWf7/9uiPHfzbH2RMrUJ0ssfrvO8eHrG/FB/hDNnInlh5vMfrXK9CdLDP1qmmzstYNGp90hak+gmTWy8kjMxMcLDP5igrA91vf5nRyf4NeFUM8YBa3xVyISnq0bkoRyqULIHMe0ase4YqOUPbi1i2ZQG9kOZdhJ7FI7qt0KvVe63nr1hEJ6j92tIpX941t1o0f7VdxKH6Y1GwFD5Ibs5fz8nHyyiGRIyeojMdp5M15NiML268ASwYkji3hQydxXIsQvhaCOgCHcc0k4Pz9nY34T7bwZ0RMpkhGVMGi46RYcL7rd+FLuAFvXskwyIkCvbl5I4LtyZzmpNghb4phFTqSjahQTOmQjaizrLmKOJKd1ISUxHcri0QSFTu+IGvGwCu2cCYfcx343VfJKR2yXetDMmRB9L2P9qRzzio18osD5+TlnrTM25sSELDEsGy4kQyoWv11Ht2hhJ77bg96TaoPtQA6vNoh+wYpiTIdHG+SweNT3mVbLNdKhHEFjhLA1zl7+gFazdeManlQblIsVKnuVXgz4bX+bAhB3OG20ONo75viw2oPUK93vxcUFjWqDnUSBkDlK1JFgJ1HoGz7tdM7Z3znAowmhmTVg23QRsSXIxfJ9T152t0q4lT6UU3r082Z82iApX1pYAHQBXOjGR7BLPWjnzdi7keCZ8A7lkvCd2MvuC6mFuhBmkUMIptFHiHfdQXZ3dvG7A6TDOQLGCC6lH7PIgW3T3XX92OlL/by5GOjQbDap1+scHx+TTCZJpVK8evWKcrlMPB7vAfTlpTAYfQfQf3z1rrnpru5qYGDgDqD/1OoPBWiAP/uzP/tZAzr5fJ5MJvPW12POLZ7/7Tjrz+SInsqY/WKFxW/X+1wlTqoN5r8VQi6u9hv61TReTaDvWB5NiOnPl1j4VoToexmTnywx97WoLz2wWq6hnDIw/42IuW/WmP18mRfvTbJzzSf24uKCLd82M98tMvrRDJO/W2Dwv48TtsX63q912iJsiqGaMrB0f5OZz5aJXPOTvtrqxyeErDFMK3b0CxbyW7d70taPT9jdKpCN5qnsH7/1sbPgzVxnd7tIIVW8keh3eXlJMBgkt72LS+HpdnrD7O0c3GqfJx5UsvJAjGrSgEcVYC/3er+Liwt2twqsP5Mz/7UwQKhfsuLThajsv5ZpFNN7aGaMrD6SIB3RIB1RYxbZ+4Jxqoc1Yahs0oBsTIt0VI1yyoBT4SPfHYprnbZYGV/HsGxBMqRCNW1APCQEm0RsyR7I5RMFodO7YEYyrEIyrEY1ZcAhcfc6+42akDAoeAMb2HiuYPWRBN2ClZ34bg80C9t7hK0xrJtOpKMa5r9cRTllIBvN96D3rNUmF83j1YYwLFmRjKiwSjw3kg/1Gj2ZyA5hSwy/PkI+VaBx0rxxDZtdiD0qVThttN4KvVfa3tug9/p2enJKYbtEyBwTYDa+21tsXF3Hyr6QgqiZMWJZdxIwxchF8zS77282mznYPcSnDaOa1qOaNgrx4l3v5qvP4rBQJmyNY5d40C9asK4Lg4bbwWzPmaVarpHyZ/DpwpjXHJhFTjzqQFe/LQxUnjWFQcKgKYZbHcCy4RQkKoYI6VCu90Sk2HXi8BvCmNedGFZseFR+AqYIyUCKYqGIQWvAa/ZjFFtRLulY/H6NpWci1iekqERanHYXLpcLm82GxWLp2+x2O263G5/PRygUIhqNUq1WefXqFe12G5fL1QPodruN2+3mhx9+4H/+z//5T/SLfFf/mHrX3HRXdzUwMHAH0H9q9Y8B6H/7b//tW4cDr2+lkvCI9W2vB80xxrtOC6KnMqY+WWLuy7W+wbJG/RT5mJaZz5aY/0bEzJervPjbMYqZfmlIJpxFOqpm9qs1xj9eZPAXkzegt33WJmpPCL7M9zaY+XSZoDl847xapy30G2ZWhzbRzZvJhHO3nn+z0WJ3q0AmnOOwUH6rXVan3ekBciFVeqvW+/iwikvmwbRmJ2CMcHBL8t/+ziHil0qWHm6gnDTgVvn75CCXl5fY9A5mvl4WoPeZAu2sEZ821Gf9Vy5VUE+bWHkoQT6qRTKoRLdoIe7c6klQTutNnFIvslEt8nEt8lGt4Ogh9lDq6oM7nXMSnhTGFSvil0rUs0Ykwxo0s2aitmQP+A4LRzgVfjTzJiTDauSjGiHYZMPJYVE4/7PmGbJFBbplkwDPL1Us3xejnjGyk3itZy8XjwRnhg0X8jEts5+vIhtRk43u9K5Bp3PObqqE3xDBuGJD/FyJacVGKbfft/g7a7XZTZWI2hJ4NAGy0TyN+k3nmLOWoMM9LJRp1E9vdW9xOp00m0Jnu3napPIj0NtqnlFIC3roiC1BNprvg96rRVXEGkc9a8S4bCOgD5MJ7/R1hKvlGkFTFOW0QViQyL1ErEJH+GoRJoTBJLBL3eiXrJjXHHg1QZLebfZ3Dnvwv+XP4DdEMK05sInd2MQeAsYI6YjwnhcXF+zEC0QdSdyqgNARXnPg1YTY8r0+VmX/uOvEEcay7sQicmKTePBqgyT9KSpHFfZL+/htIawKB8oFLSvPN5l7uML6mBjlmgaHzYnb7Uar0LE2s8H84DLj92Z4+tshJu/NsjkvxWa2EwgEUKvVOIwujFILinkNkgkl+lUzUXeMg9IBJycntFqtn7Xovx7p/erVKywWS+9/N5vNnkPH//pf/+uf6Bf5rv4x9a656a7uamBg4A6g/5Tqz//8z/kX/+Jf8M/+2T/jX/7Lf8n09PTP+u/+/b//9z8qzehBWrlMNBp96+uFdJGNF3Jmv1hh8pNFXv7dJFFbfxf3/PycpDeNdETNwrfrzH62gt94E3rPWm2S3hTGVRvaORNJT+rW9zxrtSlm9siEc5Sy+2+9qe7mdwl6Q+STuxTTe32d7Deh1yH1YBY5CJqiVA5uPi4+KByx+ULB0oNN5GMa3KrAjf3KpSNET6QsfLuO6KkMxaQerybIaf01VFXLNVSTRpYfiHthHdo5M3HnVg8cz5pnSKeVTH41j2JSh3JCj2RIjXXD2esQXl5esh3Iols096BXOqpGMa4jYkv0wKt2VMel8KGcNCAZVqOc0iMeVGFas/cei3c656T8GexSN/JxHZKXKpYfipGNatlNvobe2lGdqDWBed2JbFTD3JerbDxXkA69di25uLjAbnRiFFsxrtrZfC4kKhbTpf7Exc45pdwBUUdCGOTzCcN3NxYunXOOD6sc5MvUK/W3XusrXW+r2eL4oHqrpvdqIXSQPyRsjRIyR29AbygUYq+4T8y1hXrGiG7BglcbIh3K9u3XqJ0StSZQzxhQjOsFdw1LnFz0NfQ2T5ok3NvYJW6My1aMK3ZcCj9x91ZvuLHT7pAN7+A3CPZzDpkXi8gpaISDr9+zlBHOyaX0YxJ1O8JK4VhXMddWk42oM07AEMGy4cK66cK05sCjCZLwblEpV6hUKoScEZwaN8oFHaKXYuYfrbI2vIliRY3D6sTj8WA2mFmfFbM4vMLEw1me/XaIkS+nEE1tYjFaCQQCRCIR3DYPJrkF5aIW8Zgc1YKOgD1MqbBHvV6n2WzSbrc52hd8o7d8aYrpPcHC7toi22az0W63aZ40Oak2aL0xnPqHbNcjva8Hp7x69Yp6vU4oFLoD6D/CetfcdFd3NTAwcAfQd/XT9ed//ueEQqGfvBlVq1UCgcBbX7+CL/2SFfW0kagjcSvkdNodSrl9UoEMu6niW0Ho/PycarnGTkJIcLsNgi4vBbcOh9SNec1OyBK/Fb6S4RRDv5tk6f4GkiE1Hk3wRue4elhj7bGEhW9EiL6XIhvR4NUE+walGvVTlFN6lh9sopzQsflCiWrS0Af4nXYHrybI2hMJyik9qmkDm88VGFZsfaCdTxZQzxjYHFSimTMhG9UiHVETsiZ6AH1ab6Je0jP19SKSYTWaORNrT6QYV+zUjl4/NchG80IK4ZgGyZCKlUdixC+UFLpyiiuIi9jimNcd3XTAdVYfScmE+636KvtVwuY4xlU7G09lKMa07G4VbwwulktHxJxJ3AofUXuy73x655XNEgvHOdw9onpYe2sQz9X3p3kdem/x4O50zjnIlwlZBOjNRG52es9abVLBDOoZI9p5Ey5lQADQa53es+YZcfcWmhkjigk9JpGTgDFCNvIaehOxBA6NE+umC8OyFdOaHbvUQ8Se6IHq1XX06YMY1+w45F6hi6sOkPK/ht7K/jFxd6oHvbZNNzaJkCB4ZYl31mqTjQiBJJYNJzaxG9OaA7dagOOjwyNB1xtK4VC7UC3qWBsSM/94lZWX68iXlDgsTrxeLxq1lrWZdRaHV5l8OMezD4Z5+ekoy6NrmHRm/H4/4XCYgDeAWWFFtaJDPC5HOqHEYw5QzBep1Wqcnp7SbrepV+pCkqAvzU58V7iW7ZvXstkQ0h6vLOp+7Pek0+nQqJ8K+vVrxwoGg1Qqld7ffy6WJx3aYX/n8NbvxE9t1wE6Ho9TLpd59eoVlUqFWCx2B9B/hPWuuemu7mpgYOAOoO/qp+tv/uZvMJlMP3kjOj09xeO5meL35s3q+KDKTjzPfv6mR+/VdlQ6wrbpxCyyE3MmbiTBXV4K+syNZ3KW7m8gfqnEr4/c2K9+fMLKQzGL360j+l6K+KWSoDHSd0NuNVusD8p4/N5LlBN6Np8rkQxr+qznLi4uCBojLN7fRD1rRD1tZOOZAt28qQ/I93L7PbsyzZwJxbiWjWdyoo5EH5x51EEkQ2qko5ruoJoc7by5Tw9e2N4TIo1fKpGMqFl9LGHte2kfnJ212ri1XuaeLCEeUgmpf/c3yYR3bgwuhq1xDMtW1p/KEb9QspPcvdG5u0rrc8m9BAyRWy3qLi8FrfpBvsxRqUK7/XZo6UHvYe1W6D04OCAWi1EpVYSAmq4F3JupjJ3OOdnYDppZI6ppE065l/Qb0Ntpd9gO5dBMGVFOGjCu2PHqBBnE1ffs/PycXDSPZdOJYcmKWeTEsu4iZI71Or2Xl4J0xq8LY1ix4VT4MK3ZcSl8JL3p3lOC9FYGzbogozBf6wiHTFGK23u9700uttsHveY1J065l6gzwfHRMdVqlWwqh1PjQb2oRzQkYenpOktPRUhmldgtTnw+H06HE9mqnKXRVSYfzvL8w2GefzTM/ItljBpTT9cbDIQwq6xoVvRsjMrYGJLhULvJZ3epVqs0Gg0ymQzxaILC9h5Jb5p0KMth8ejWv8ezVptG7ZRG7afDSs7Pzzk9adI8ad56rKtByJ1EgUwox152v28BenWMg91DQqYoTpmPmDNJPvnaqSOdTpPL5djPHRAyx3ArfHi1YWHB3bXz+0MB+sr/uVAokMlkePXqFQcHB2xtbfHDDz/wv//3/37XP8N3da3eNTfd1V0NDAzcAfRd/XR99NFHiMXin7wRtdtt7PabiYDXt/18mfVnClYebLLxTE7QErvRqaoUNCa+AAAgAElEQVSWqyzf3xS00k+kbDwVAPQ67LXbHaTDapbvb6Kc0LPxTMnGCzn5rX6P54ApwuK3G2jmTKhnjaw/laOZNfXdtCt7x6w/k/P8gxE0cyaUk3pWHolJXO8ad87xaYKsP5cjH9d2O70yNDOGPmg/LBxhWLKy8UKBZESN6Lmc5fub7O0c9B1ry59Gv2RlY1DB0r0NFr5cIxvd6Tv3ZqNF1J7AsGRh/XsZ68/kZKM7N6D3cK/M5pwUt8KHWxXouVy8uTVPmhzuHlEuVm54+b4JFFfQW6/U3wpClf0qYWuMgDFCLrpzKwjlt3bRzJlQTepxSDykgpm+/arVKqoNreDnPaFHv2jBrQywHcr1fS8KqRKWdReGJSvWDSfmVTt+fbgPeiv7VXy6MPplwRfYLHJi23STcKV60Ns6bbHlS+NS+DCvOXpw7NUEe9B7eXlJcXtPgN71151em8RN1JmgUj6mVquRSqTYmJWgWdazPiRldXCTucerSGYUOKwufD4fbrcblUTN8sgqU4/nGPx4jKcfDDPz/SJ6lQGv10swGCQcCmPTOtCs6tkYlbM6KMYidZDdznF8fNzT9TZPm5Sy+yR9aZLebQ7yh30uNtcXE43aKSfHjVuv9dHREeFwuHctm423Q+/Vd6eQKrIdyFDK7N0aO189rBG1JXFIvYStsVsXQkelChFrHJfSh08bJuFO9RIZr1/HlD9NwBgh7trCrw+Tiez0rvXBwQEBb1AIljFGSXi2iTmTRKxxduKFW8/tpwD68vKyJ9sIBoO8evWKUqlEOp2+A+g/wnrX3HRXdzUwMHAH0Hf10/XgwQNmZmZ+8kZ0cXGBxWJ56+udTof15wpWH0u60Ktg7bGsL7Dk8vKSoCnK/Ner16BXhnbW2AdU1XKdtadSZN0OrnrayOJ3G2Qi+b7z8WqCrD6RoJjU9+QNqil93w27elhDM2Pi4XsvkI1p2HghZ+nb9Z611tWxMqEcmnkzomcylru+0tlYvzb8rNUm4UmhnTez/kTG2mMp6VuGEpuNFqlABqfMi0vu6w1kvbmdNc84LFQ42C3fANTrAGC1WDk9bVE5qFKv1G99fH55ecnxwTERaxy/IdJzSHjzGpYy+2jnTSgmBL1uKpjt2+8qdEU9ZUAxoUe/YMEh95IJ7fS978HuIWaRA/2iGdumG8OyDa86yF7u9WKidlRj/vki+kULToVPgGORg5gz2ZM3dNodUv4MTrkX05pdgOM1By6Vn91rCY/l4hEhcxTTml0Yitt0YRbZiNrjHB9VqdfrHOwd4DH6e9ArGpYy93CFzUkpTqubQCCAx+NBp9SzPLbG5INZBn83xve/GWLi4RxauQ6Px0MgECAQCLCxLEGzpmdzTM7y0w3062bSiQxHR0c9XW+rddb1Zs4SdyYpZfdo3nItBa/lJifHDVo/IUW4uLigedqiedJ8q2zhrHlGKbtPOphlN1Xqe7rRarVwOp2cVBvEnFu45D4CxijZSL5vv8tLIYgn7tzCKffh1YUI2xLkovm+78RJtUHKnyVgiBBzbREwRkj5070Y8stLYag3F9slbI0Tc24Rd6cIGCNkov3vWcrsk4nkCJoiJDzbhMwxtoOZntyo2WxiMVrJxfOELTHhWK4twfUjtvvWv5OfA9CXl4LG+tWrV+TzeXZ2du4A+o+w3jU33dVdDQwM3AH0Xf10jY6O8uzZs591M/oxgK4fn7Bwbx3llL4Hx7NfrrJ77SZ7eXmJTxNk+cEGqmkDmjkTK48lqGfNfY+PT44bqKaMiL6XCpKJFwrmvxZxXO6Pgt6J51FM6ll7ImXlgYS5z1fIvAG9VyEcLz4eYfWJjJWHUtKhm9B71mqz7c/glHqwS93s3eLLfLVfuVhhf+eQ01tsza5D0GmjyfFhlfrxyVsfPVcPq4Stcfz6MLtbhVuBSbYuRzdvRjluwLLhIh3K3dhvf6eMatqAclKPbt6CXewmE97pe9/K/jGmVTu6BQs2sRvDkhWXwt/XQW82Wvj1YXQLAvTaxG6Myzai16znLi8vSQWz2KUeTCJHD3odUm8f9FbLNeaeL2FcsWOTCLpf/ZKFsDVG7bhGvV7n6OgIvyWEetnAxrCMjVEZcw+XWR8V47IJ0Ov1ejHpTKxMrDP5cJbBT8d48v4Qo99MoZZocbvdPV2vy+pGs6ZnY0zK0hMRqnkdW7FtyuVyT9fbarU42j9mO5Alaouzu1W49VqazWaaJ03qxyc0G82fHGZrNX8cettnbfbzh6SDOXZTxVv1+s1Gi5Q/jUvuxd8dWjx5Q6/fPGmS9GzjUvi6yZ+xG44eeq2BdCCLTxcm7k4RNMWEjvA1B5SLiwt2EgWijgRRR5KEZ5ugMcp2MEu1/FrTfuXEEeh2hCO2RLe7/PpYZy0BoKP2BBF7onesTDjXNzxbLh71ADrqSOLXh9nybnO0V+mdk9FgpJAqCZ7R6iAOiZeILcFRqfIHDxS+6cRxFZ6SyWQoFov88MMP/P73v3/XP8N3da3eNTfd1V0NDAzcAfRd/XStrq7y5Zdf/n8G6EbtFNmIBtETKYpJHZsvVcx9tUbtuB96d1MFpKMaVp9IWH0sYfrzVfLJ3Rtdo1Qgg3LKwMpjKcsPpWwH0zfes9PukAnncEo8WETOvqG5N/dTiFWUsvucVG+3netB78kpx4dVTqqNt2pCjw9rhK1xgsYIhVTp1o7wYeEI7awF1aQei8ghwOwb+5WLRygn9CjGdWhmzVjXneSiO33vW6vUGf5iAt28CZvEg27Jhl3q7evsn7XaBAwRtPNCjLRD6kW3YCFsifV17HbiBSwbLsyiK3mDA+uGq+9zO603CZtjGJas2KUeHHIv2jkzYWucerVOo9GgWq0SdsXQLBvZGJKxOSZn4dEKq0ObuGwegsEgPp8Pm9nG7OBCD3qfvj/E8JcTqMRqXC5XT9frdXpRi3Ssj8pYeLSGZFJFMrJFuVzu6XrPzs44PqySDuUIW+JkIjtvdVNpNlrUj084rZ/+JHCdtc5oNlq3Qq/NZqPVOqNcOGI7mGMnWbgBs1effzqUE4BWHSQVyPTZDF7tsx3M4pT78GhCBAyCu8b17mynI2i4vboQMdcWYavgBb0T3+1bCO1l9wVQtQmgGjBGSAWyfSEjBq2BpG+boEmA3rhri7Al1nesKyu7hDtF2BrvHitKypemfi31s145IR3OEjTFiNgTBE0xovZkL5Hx6lj7uQNSgSxebQiHTOh67+8c9l2DTrtDMb1PypfGowr00havf+ftdjuNkwbl4hH5rSJ7uYOfdS3f9jd9fZDQ7/fTaDRIpVLs7+/fAfQfYb1rbrqruxoYGLgD6Lv66dLpdLz//vs/62ZktVp/1D4sHcwiG9Wy8kjM6gMJqeDN4JVO55xsdAf7phuLyEkusXvr8a6ip0vZ/bd6LV+9b7PRpFqu/ehNVq/SEzJFCBgjlDJ7t3aEy6VjodM7qcO0ahMCON7Yr7J/jHJSh2LCgHrWjHHFTv5aV+/yUnDr0C9a0S2YsUs96BYtWNadlLtdtqt/X9AURTtnEqBX5kU3byFojvbBXDGzz8T9WQzLQkfYsu7EtGqncE3T2zptETJH0Xeh16nwoZk1EzRHOKk3aDQa1Go1Ev4tVIsG1oeliCcULD5eY+XlJh6Hl1AohN/vx2F3sD4jZuLBHIOfjPHsN0O8/HQM5YYKp9PZ0/X6PH50GwZEo1LmH66xMSojFkxwcHDQp+u1GK3E3AlCljhb3vRbFzCt0xa1Sp2TauMnQal91ub0Rzq95+fnHO0dkw7lyL8FejvtDvnELk6ZoC1P+TN9XdfLy0s8bg8xdwKX3IdXE8KnDbHlS/d1ji8uLthNFvBqg8ScW0TtCYKmKLlr4S2Xl68TEK9A9aojfD12vXXaIhPKEehCb6+LG9npkyUVt/dIeFIEzbEe9Ca821SvpWt6nB5C9gjBbiBLxBYnaIr2DalenVcqIASluBR+PGohdfLNdMr9fJltfwavJohfH2Jv5+DG30anc05lv8ruVpHC9t5br+VVXPzbnHXC4TBHR0e9Y5612j/L9/lt23WA3t7eplQq9Rw57gD6j6/eNTfd1V0NDAzcAfRd/XR5vV7++q//+mfdiFwuF63W2zWI5+fCDbSU3aP6htzize305FSA3h+RQRwf1ojaEoQsMfbz5VtvouXiEbo5E8pJHcZVG7tbhRs37ephjaFPJ9gcUqCZNaNfst7oVjcbTXQLZvRd6NUvCiEV16Hq4uKCgDGKdrYLvXIBegOG8Bv64DL6JQvWTZcgg9h0Y1i09umD22dtQuYYugULDpkXp8KHds6MXxeiedrk9PSUer3OdjzNzJNFlp6JkEwqBQeHZ2t4XV0rskAAl9OFeF7K+L1pXn4yxrMPhnj20QiKLvT2dL2+ANoNA6IRMQuP1lh7ISHij3J4eEilUunpeuvVE7LRPCFzjKQnRa1y+7U8a7WpVeo/6sscjUYpl8u02x2ajbdD78XFBccHVbKRHXYSt0Pv+fk5he0iLoUfl0JI1nsTes/PzylsFXHIvK+h17t943h7O4d41EGijiQxZ5KAIUI6lO07P787gEXu7IFqxBYnYk9wkH+taReeguwQMEauQW9MkNlcA8TDwhEJd6rXEQ5ZYkQdyZ504eo7kYvmCVpiXS1xEp8uRCFV7PtO147qbAey+PURPOoAboWPnXg/sKdSKWKBOKlAFp82hFcdYDdVvPEU5OLigmq5xm6qxG6qSO3o9mt5FRd/9jN8mYU49B+H3majRbl0xNFe5QZIZ7NZcrmc4OgR32UnLoQWvQ24fw5AXzlxHBz8v+3daXTb1ZkG8DvnzJkv/dw5ndP2Q+lhpkMmOAmEfUlZ0gyEpYECpSylUCiFsoawlCVAmkAhkIQwCZAQEsKWkJB4i+14t2XJkrXZ8qJ9sfbFkrU4JQ1+5oMixbIkWzFO/hY8v3PuOYAV6UYW+j969d57Xejt7UVPTw/8fj/GxsakfgumSaTOTURCCAZomt7AwABWrFhR0oVILpcjGJw6GHudPqibtVA16+B25J++l0ql4LZ6spXehk9aYJ90EmHmfg68V4uqD+pRs70Bdbsa8xbjRUeiqNnRgLpdTcdDbxMaPmnJq1grG9R4/5WPcOiTxuMtCU1Q1KlyLvBuuxc1Hx5Gy5ed6dC7T4aa7fVwTagQZqvGO9P3035QjtoPGyE/pEQsFsPIyAhCoRCGDEYc3FaLPZu/wlfbqvDJ23uw683PoehUQK1WQ6lUQiaTYf8nB7Hl1W3Y+NwWvL1qM956ajMOfHEweySxQqGAQq7AFx/uxYev78KHa3fjk7f2Qt2lgcvlgsfjyfb1hgIhGHUWKOrVULfq84LlxJAW9IUQ8ASn3KIulUqVFHr9wwEYNeaiobe/vx/K9h50VnanDw9p78ubW2bhYvtX6fYGWY0K+o6+vPvzOLzoOh56de19xw8ZGcyZXyQ4Al1bXzaoatp609vYTfjwkkwmMaQxZ2+TqfQa5Lm7iGhVOtTtPZxd8KZp1UN1WJNTNU4kEjDpLVC36NDTrIOuow9d1UoYteac19dIaAT9SiO663rQVaNC2/4uDKiMeTtjBDxBDCjTobfzoAJGraXg8x/yhWDtt8Oos8Dn9OdVgzMnh8aio4hGojkngk4VeqfaJi4WHYXH4YXb7im6G8ZIOApzrxVGrQXmXmvePt2Z25i0FlgMNpj7bDDrc3v/3W43lN1KmHQWOEwuuCxuWPsdOTupnGyATqXSCwmj0ShkMlm2lePIkSNSvwXTJFLnJiIhBAM0Tc/n8+Gqq64q6ULU09MDr9db9OdehxcHt9ai6oOG4wdZNGLYnrvtWiwaQ9W2etTvbspWeht2t+RVorsbNKjeVo/2g/LjLQmHoajPPbXQNxxA5Xt12baFtv1dqHqvDh7HiV7QZDKJ7jo1drz2CSp31GbvS35IhXg8jmg0inA4DIvRigMf1GDP5q9wYHs1Pt2YPqRCJVdBo9Fk+3oPfFaJd1d/gI3PbcGGp9/FW0+9kw29mb5eeZcCtXvrsfvtL7B9zcfY9cYXUHWq4XA4cvp6Q8EQTHoL5HU96GnS5vSw5oRQQz+0PXr43cEpt6jLhPyRcPEty1KpFALuQDrg6C0FF7Ilk0kMW9zorE6HXm1rb8FA7jS7T4TeaiU0rfq80NunNWDfBwfQ06LLbltmkA/kVBOjkSh07X3Z1oXM7Sa3G5h7rVDU92RDb3pRmyEnzIUDEWg7+rKhNxO0J1aNU6kUbAY7VE1aqJq00HUaIKtRpXcamRAg7VYHavfWobtODVmtCm37Zejt6s+rhIYDEQyqjOk2iANy9HcPFqyWRoIjsPbbMaQxw23zFN1NZTR2PPRO87tOJpMYjRUOvYFAAHK5HPHROLxOP9x2T94OHBODsc1gP17tLfyaiEVHYdZbYe6zwWKwwajJ38YukUjA0meDbdAJl8UN+5AT5l5rXiV62OqBtd8Ol8UNl8UNc68VPteJ11c0GkVjQxNMOmv2Ni6LG0atZUatHBMXEh45cgRNTU2QyWSIRqMM0HOQ1LmJSAjBAE3TGxsbw+LFi0u6EOl0OjidzqI/767vQfX2E6G36oN6qCcd5x1wB/HV/9VkK7htX3XhwJbavEVX8toe1BzvD24/KEf19gYoGzTpr5JjMUQiEdgtduzbWoUvt1Ti4PYafP7Ofnz090+hVmmg1Wqzfb0H99Rg43Pv4q2n38GGZ97F+iffwcG9B9HS0pLt61XIFaj9sh671n+KbWs+xo7XPkN3mwoOhwPDw8PZvt5wKAxTrxVdNUp0N2jgsRf+QBGPJxD0heBz+RGLTv3VczyeQGwkVjRQ2e12KLtUMOmtsPRai/aEu20eyGqU6DiogKa1F77h/INS3DYvOg7IIatWQlatRE+TLi/0hnwhyKqU6dDbaYD8UHpP34mhcDQ2Cl2HAYrjrQuZ21n7c1tjepUGfL5lbzb0qhq10Lb25lQmR8JR6Dv7c9oguqpVOftAp1LpA1BUTdpsS0VXjQqG7sGc5y0+GodRa0Z3Qzr0th+QQ9vWm7f9WTQSxZDGBPmhHrR/JYe+sz/vNpFIBC1NrbAPOjGkNsFhchUNtfHR+PHFiFP/rpPJJOKj8aK/68zrwe8OwG33FAyzmcezDzph1Fpg1JoLtrI0Hm5MB2O9NV2t1pgLfktgG3BmA63D5IJJa8n7e6ZPBT0RaK39jrwPJaOxUZh0lrzQO7mCPl2ATqVSqK+rh1FrhsOYqUDbs6c2ziRAT+yDbmtrQ0tLS/a/0dwidW4iEkIwQNP0xsfHUVFRUdKFqL+/HxZL4UV/qVQKXTXdqPnwROitfL8empb0ISmjo6OIRCJwWl3Y++5BfLm1CpU7avHFO/uw87VPoNXooNPpsn29VXursfmF97Dx+a3H9+rdhINfVqK5uRltbW2QyWSQyxWo3VeHHX/fjW2v7MSOdZ+gu10Fu90Ol8uV7esNBUOQNcqxb9sBKA71FA29icSJ0FtoL9+TCb2pVApBbxCmXissvYW3LEul0lX7TOhVtxRuvTD2mfDJpj3orOqGrEoJVZMmLwhFgiPpXQ2a06FXUdcDXXtfTniJxxPp6u6k0Dtx67lUKt3DLatRZsOsukUHVaMmJ/TGRmLolQ3kht4aVc7ixlQqBbvRgd2bPzsReg+p0NtpyAlo8XgCFr0V8jo1umpVaD8oR0+zNq/CGYumA1om9Gpa9QV76GMjMTiMLgyohmAbsBc8jGRi6C32u5649/l0oTeRSCDgCaZDry9UdPGc0+yGSWeFUWuG15n/ASeRSMAx5Ez3/fbbYdRYCr4mMsHTZXHDaR6GUWPO+wBwqLoOQ1pzNqjah5x5bRCZnTgmht5CB5bkB+h0AJ4894kVaNtg4Qp0NBKFSWdJt2/0WtMnEU4K2e3t7fAO+7LtIDaDfUZHeU+cWyZAazQaNDQ0ZPuiaW6ROjcRCSEYoGl6mQA9+YKfTCYRj8ezfb0+nw8ajQYqlQoWiwVDQ0Po7++HXq/P9vVW7z2ETc9txTsvvI+Nz23Bmys34+C+ajQ1NWX7euVyOar31GLb2l344OWd2LFuN7rbVbDZbHA6ndm+3mAgiCGdCbKqbnTVKOG2Fj6BL5FIIOhNh97IFKeUDQ8PQ6VUTdvnGfKF0l9T99mKbpPmdfrRVZsOvT3N+oIVYZ/Lj/YD8hOh97Am7yv0kXAUnZXd6GnKhF41tK29OUEhkUhA2dyD3e9+ng29XbUqmHpzT2X0OLzorOqeEHr16K5X54Te+Gi8YOg199kmzT0ARb0aqqZ06JUfUkPb1psTepPJJKwGO+SHeiA/lO5xVtSr84LXaGwUe3ftS4fe/XKoGrUFn9fR2CicJhf6lUMw99oKHu+eCdsj4WjRn0++7VShN5lMIuQLwePwIugtHHobGxvhtnlg0qbbGwrtRZxMJtPVVp05294wsY1o4usmE1bTodeSs0dy5jVh1J6o4jrNwzl7N2eG1WDP9gdnQu/kD2lNDc3oU/RPGaBTqfThJtkKtNGVd3pg5veTCbsWgw0mraVgH3Q0EoWlzwaTzgJLn61or3Q0EoXX6YPX6S8YjDWa9OLWRCKB0djojLawKxagzWYz6urqcOTIEXz99ddSvwXTJFLnJiIhBAM05duxYwdeeuklPP7447jvvvtwyy234D/+4z/wP//zPzjzzDPx1FNPoampCU1NTWhpacn29SqVSnR2dqKtrQ39/f0wGo2wWq05fb3BYBADmiF0VMohq1HCZSkcepPJJILeEDx275S7cKRDUHzaFf0hfxjmPhts/faiwcoyaMWn7+5BZ2U31C36ghVh/3AAHce3NeusUkJ5WJ0X9kbCI+isVGR7Z+V1PdC05odLfacB3XUngqqsWgnLpKDqdfnQeVCevY2mrTe9C8eE0BGPJ6Bt68VHG3bnhN7J9xX0hiCv6zkReuvUULfo8+ZlH3BAXtsDRV069MprVXl/x3g8XUnMhN7u+p6Cz1d8NA6XeRiG7iEY9eaiv8vGw42IhEYQCUWm7WFNJBJTfsDJ/L69Th+C3lDRHSM8Dh+MWjNMOguGrYV3cPHYvTBqjoderbngMemHDzWiV244EVS1lrzqf+YQkZzQO2nv5lQqBYfRla3OZirIk6vLpQboQhXoyWFV3aNGT6d22haOiT3QZn1+EJ94O6/TD4/DO+WJgJnQ+222njOZTBgczN8Gc6Zj4kJCv9+PmpoajI2NMUDPQVLnJiIhBAM05autrUVlZSVaW1uhVqthNptxzjnnwOl0TnvBc7lc0Gq1016s4vH4tBfQoC8MS58d9gFH0Yux3+WHolaJjkoF1K16hAtULgPuQPpwiiolOiu7oTyszgvR0UgULfs78OmWL463LaigadXnBRxdRx+6JyxS66pW5rU3+IfTj5e5jba9F/JaVc7fIZlMQtdhyNnPV1athHlS1TjkC0Feq8zuDaxoSFd9J1dN7UMubPv7R1DU9UBW3Y2uGlXec5FIJGDrt0Nek+77lR/qQbDA9nPxeALDFjcMikEMaUxFF5YlEulKbzgQQTw+/Q4OU4Xe9vZ2+D0BeJ3+oqE389xmFrK5LIVDr88VgFGT3sHBqEu3J0wOlyF/GEa1GU7zcLYyPDmoxkfjMGnz+3UnV15b6tugkelyWhfceQtjcwN0+r4K7yGeaYMoVoFOJBKwDzonhF5Lzv7OE+dvH3TCpCvcA51KpWA0GmHoM0y7iDDzmi22IFGK4fF4oFKpZu3+JgboZDKJqqoqjI2N4ejRo1K/JdMkUucmIiEEAzSV5qqrroLNZpv2IuTz+aa9qHkcvvRX+lXd0LX3FQzH/uEAOg50QValRMfBbqgatXl9qiOR6PFKr+5424IS2ra+vFCla+/NaUnorFTANpD7NbXfHUD7V134ZOsX2Z0ZZNXKnEVxyWQS2va+nPsqVDUOByKQVXefOLntsBrKw/mh12F0orO6G4q6HnTVKiGr6kYokB96rQNOdNWo0od11KoQ8OQHoUQigQNfHESvzIABlbFohTB9qExpoTfdojN1WBoJjcDnCkwZegOeIEw6K0w6C5xmd8H7bG1sh6ZDB3OfDSa9Je90usxjGTUTQ68lr0c4kUjApLNmb5NdpDbpteN1+mAx2LK3sQ3kL3grNUD3KNToqJeduI3OnHNKX+a5dJrTc7b2O2DUmgv22cfjCTiPt0iYtBZ4HL6CrQnxeAI+VwBuW/F+6szjjsZGi7apuN1uqNXqWQuhp3OMjo6itbV11u5v4k4cY2NjqKysRCqVYoCeg6TOTURCCAZoKs3NN98MjUYz7UUoFAqhq6ur6M8joRG0fyXP7ocrq+6GrsOQFwA0LbrjW5Clg2pHpSJvj+dMD3HmNpn9dfMCTrMOysYJld6q7rxDUsKBCDorFdj5zqfpPX8bNVA2aPLCntM0jI4qBbrr1JAfUkFW1Y3wpAphMpmEtd8BWVV3+ujmWmXeDiKpVDrsuSzD6JMZ0K80IugrHnojoRGE/eEp9+rt6OhAJDJ9C8RIODpt6A35QjDp0wvZioXekC8Eo8YMc58NRp0FTqMrP/SGozBqzNleXJPOmnMwSObv11jVAnWXNieoTv5g5XcHsi0JmQVok3fhSAdoS06ANhUI0CFfCMYJi+dMuvxdHlKpFIat6UBs7Xekg705v5pts9nQfrjj+G4X6XaQYgsE/e4Ahq0eBDzBaUPvdFvUzcaIRqNob28/5Y9zqkZjY+O37n2e+Lxn+qATiQRqamoQDocZoOcgqXMTkRCCAZpKc++995ZU7YnFYlNekD0OHzoOKPJC7+SA1tOky/bqZqrGjiFXzm1C/jA6Dsihaes9fvSxBsp6dV4odJpc6KiUo7tBfXwxmzyvpzcTet9/fUe68l3TXTT0Os3D0HcYYFAMTlnpjYRGEPKFpt2XOXPhnjLoRKLwuwMI+YqH3vaWDmhk+pzsSPwAACAASURBVCkrvSF/GEOa9AEWmdBbaAeEIc2JAypMemvBaqm515bdQiwTeif32Aa96cNbMrdxGF0Fd3noqJdB3qqY8r7CgQiMmhOh19xrywvj6deYF0ZtJvRaCwb7ZDIJt82TDb1O03DB53Vi6PW7AwVvEwgE0NXVddpC72yOZDKJxsZGyecx09HZ2YlIpHjbycmOTICORqNoaGiA3W7HsWPHpH77pUmkzk1EQggGaCrNE088gYMHD5Z0Qc5s61VoBL0htO+XQ9velz3oQnlYkxdw7EYn2g90QdWoOR56FXkL0JLJJCyG48c2V8ohq+7O++o8c1F0moah6+hDr8xQcJFU5v4a6g7D6/JNu1dv5vZT/Twbev3hoqE3HIjA3GubMvSGA5HsqW3FQm9sJIbDB5qgOV7FNemtBRe8WQ122IdOLFIzasx5J8GF/OGcfl2HyZVXsU+l0gF6cqV38n2l2y5OVITNvVYMW91599WvG0D9/sOwDThg7rXBNpDfb59MJtOL+rTpo5vtg86Cz1fm6GmXeRjeAifw5Txv0VHEot9uB4d4PI6WlpZZC3Gne7S0tEzbzjNXx3T7zp/sSCaTGBsbQygUQltbG/r6+hig5yCpcxOREIIBmkrzyiuvYNeuXSVdhKYK0MlkEia9Be1fydFRKUdXjbLgQrZEIgG70QlNqx69MkPRg0GSySTCgTACnuCshN721nY4rE6EA8VbIU6E3nQYLBp6jx9fbdSZi4Zek9aSreIWC722SaG3UFANByJoO9SJ7nZVNvRO7s1OpY5XjSdsbWbUmfO3SZvUa2wx2OA054fe9GI98/HQa4XNYC/4XKR3u0j39NoGnAX7cQOBAJoaWo6HXt+UW8vFoqOIjcRm7av72RhTvebn+uju7obfn7/fdDkMs9mM/v7+Wbu/zP+jfr8fCoUCXV1dDNBzkNS5iUgIwQBNpdm0aRM2bdo0K2EimUwi7A/D7w4iOjL1YSSZ20/189hIDEFvCOFApOhtJ4Zet81TMBxHgiOo/bIOmk5duve3wEK2WHQ0N/TqCrc3TA69hSq94UAk54AKh8kFc29+6LX05YZek77w3sBdjd1oP9yZ3QnCaXTl3Zd/eELo7bPBOl3o1aUPqCjUmpBMJhHwBOEyD8Pj8JYUeot9KCn3Km5bWxtisek/wM3FYTAYYLVaJZ/HTIbP54NSqZy1+8ssJHS73dDpdGhqasI333wj9dsvTSJ1biISQjBAU2l27tyJNWvWlHQRampqKin0hvxhRIIjU4ZeS58t3YPr8BYMX5lKr/H4rgWFFnnlVXoLLGRLpdKht7WuHbpu/Yk+3BJCb6FKb6mhd2Kld9rQO+iExZA+wKVQWDX2mVC7tw4mnQXWIqeyZUKvw+iC2+aZsmc3Fh1FNBL9Vnv1nswo5yquUqmEz5d/MEo5DJvNht7eXsnnMZMx2x+8MgHa4XCgv78fra2tXEQ4B0mdm4iEEAzQVJrKykqsXLmypIvQdNW4kD+cDb1GdfpwikKh16gxw2F0pffD1RU+1jivp7fA4rOQP5wXeov19Ha1KKDs6Jk29E7c8/fbhF6Pw4chjSV7KlspobfYccWRSAStLW2IRqJzZq/ekxnNzc2nLazP9ujr6ytpm8e5OAKBABQKheTzmOko5QN7qSOzoDdzkmoqlWIFeg6SOjcRCSEYoL9vXC4XlixZgl/84hc466yzsGHDhpL+XFtbG+6///6SLkJdXV0IhwvvTpFK5e/eYCqwZVnIH55294ZUKpXeZWHiQjZd8YVs04Ver9MP2WE52g93ThN6vdndG6YKvX53APbjp8oVC72pVPrDwmyE3kQigebmZskDzUzHdK+buTysVisMBoPk85jJ+C68bkKhwmskZvp8DA0NwWKxYGxsDOPj46f4XZlOltS5iUgIwQD9feP1eqFWqwEA8XgcZ555Jvr7+6f9c3q9HrfeemtJF6Cpvs5OJpM51eBMS8XkqnEkOJJf6Z20D3Qqlcoex2wfcsLaby8YerO7N2jMMOmsU4bewb4hNNe0lBR6R8Jzr9Jbzm0QGo0Gw8P5v+NyGF6vd1ZPxTvdYzaruKd76PV62O353yjNdCQSCRgMBjgcDgboOUrq3EQkhGCA/r67/vrr0dDQMO3tXC4Xli1bVtIFSKvVwuXKr/BmhsfuhVGX7km2GAovZEsmk+lDLDRmmKap9PpcAdj6HXCapw690Uh02tDr9/vR3d0teSiY6SjnIDQwMACz2Sz5PGYyyv1AktneT/l0jtmu/icSCeh0OrjdbgboOUrq3EQkhGCA/j6z2+346U9/itHR0WlvG4/HceGFF5Z0AZquHzSRSMDr9KdDr2m4aOhNJpPp0BsaOW2V3pGREXR0dEgeCmY6Ojs7MTIyIvk8ZjJsNhv6+vokn8dMxnT7n8/1odFopvzQO5fHbPdwJ5NJ9PT0wOfzMUDPUVLnJiIhBAP091UikcCiRYuwb9++km7/zTffoKKioqQL0NDQEIxGo+QX1pmMcu8HLefdIMq9DaKcF0EajcbsorlyG7P9/2wymYRCoUAwGMSRI0dO8TsxzYTUuYlICMEA/X109OhRLF26FOvXry/5z4yPj6OioqKk9gCLxTKrhxuc7lHOlUS9Xg+HI3+xZTmMaDRa1tV/uVyOYDD/UKByGMPDw1Cr1ZLPY6ajqamppA8vyWQSo6OjiEQiCAaD8Hq9cLlcsNlsMJvNGBwcRF9fHxoaGjAyMsIAPUdJnZuIhBAM0N834+PjuPPOO/Hoo4+e9J8tNUA7nU7odDrJL6rf5mIs9RxmOsq5+l/ubRCzfaz06RxzvXUpkUggGo0iFArB7/fD7XbD4XDAYrHAaDSisbERKpUKGo0GSqUSXV1daG9vR0tLC5qamnJGW1sbOjs7oVAo0NPTA51Oh76+PgwODsJsNsNut2fbWRig5yapcxOREIIB+vumo6MDQgjMnz8fFRUVqKioQE1NTUl/dtGiRRgdLb5ILzM8Hg96enokv+jOdLS2tiIeL36q3lwedru9bA/FSKXKexFkObdBJJNJNDY2zvp9Zqq9gUCgaLVXq9VCpVJBoVCgs7MTra2teaG3paUFHR0d6OrqglKphEajgV6vR39/P4xGI7q6urIL//x+P8LhMKLRmR8ClEgkkEwm8Y9//OMUvyPTTEidm4iEEAzQVLrLL7+8pG3GgsEg5HK55KFgpqOc9yMu9z7i9vZ2RKPTH+8+F8fw8DA0Go3k85jpaGlpQTwen7ba29/fD71eD7VaPWW1t7m5uWC112Aw5FV7vV4vgsEgIpEIRkdHT/pD1Gx/cMwE6K+//lrqt10qQOrcRCSEYICm0t1www0l7ZIw178Onm6oVCp4vflHfZfDiEQi6OzslHweMx3lvAgyHA5DJpNJ8thTVXtNJlNJ1d7q6mocPny4YLW3t7c3W+21Wq1wOBw51d5YLCbpAspQKISurq5ZfT4TiQQD9BwldW4iEkIwQFPp7rrrrpLCWSKRQEtLi+SBZqajnBfilfsuIr29vbN6KMbpHDPp4Z5Y7fX5fBgeHs5We4eGhopWe5ubmwv29spkMnR3d5dU7R0ZGUE8Hs9We8v5OPLZ7p/PBOijR49K/bZLBUidm4iEEAzQVLpHHnkENTU1JV2AynkxWCZwSD2PmY5yfu4zvbFSz2OqkUwmEYvFstVej8eTrfbW1dVhYGAgp9orl8un7e2Vy+VFq71OpxMej+eUV3vLeR/uVCqFw4cPIxaLzdr9MUDPXVLnJiIhBAM0le6FF17Ap59+WtLFp5xDXLlvw1fO+xEPDw9Dq9XO+v0mk0nE4/Epq70GgyFb7e3u7i5a7c309haq9jY0NGBwcBB2ux3Dw8NFq71zcfj9/lk9kOR0j+uuu+6k3neSyWT6sKZoFC6XCwaDAXK5HPX19fjyyy+xfft2DAwMSP22SwVInZuIhBAM0FS69evXY8uWLSVdnMp5NwWXy3VKQtzpGuV8LHMoFMpZgDpVtddkMmFgYAC9vb3fqto7MDAwa9Xenp4eeDweyZ/HmYx4PD7nW68yoTeRSCAQCMBisUCtVqO1tRV33303Hn74YWzduhVvvPEGXnzxRTz++OO47777cMstt+Caa67BpZdeioULF2LBggXZsXjxYlxxxRW44YYbcMcdd+DPf/4znnnmGaxduxa9vb1Sv+1SAVLnJiIhBAM0lW779u1Yt25dSRe6ct4Kzu/3o7u7W/J5zHRIvQiyWLXXbreXVO2trKwsqdo7NDSU7e2dK9XegYGBsm7/eeaZZ07JtxeFqr0KhQINDQ3Yt28fduzYgU2bNuFvf/sbnn76aTz00EO466678Otf/xpXXXUVzjvvPFRUVGDBggVYuHAhFi5ciIsuugjLli3Db37zG9x3331YsWIFLrnkErz55pv44IMP8Pnnn+PQoUPo7OxEX18fnE4notEojh07hvHxcR7RXcakzk1EQggGaCrdvn378Oyzz5Z0wSznKujIyEhZ72Qx04V4mWpvOBzOVnudTueU1d6Ojo5pq72ZAy5KrfaWc/tPue/Dff7552fblyZWe4PBIKxWKzQaDdra2lBdXY1PP/0UW7duxZtvvomXXnoJTzzxBP74xz/i1ltvzVZ7Fy1alFPtPffcc/HLX/4yW+198MEH8fTTT+Nvf/sb3nnnHezcuRMHDhxAc3MzVCoVjEYj/H4/xsbGpg29LpcLy5cvP43viCQVqXMTkRCCAZpK19TUhD//+c8lXYi7u7vh9/slDwQzGeW0k0Wm2jsyMoJgMAifzweNRgOVSpVT7dXpdNlqr0wmK6m3V61WF632+ny+U1btbWlpKdse7kAgIPm3F5ngG4vFMDw8jIGBASgUChw+fBj79+/Hzp078c4772Dt2rV45plnstXeFStWZFsaMtXezLjwwgvxq1/9CjfffDPuvfdePPbYY3jxxRfx5ptv4v3338dnn32G2tpadHR0oLe3Fw6H47RXe8fHx7FgwYJT/jgkPalzE5EQggGaSqdWq/G73/2upIu4Wq2G2+2WPNDMdJzqKmixaq/Vas2p9mbC8FTV3tbW1pxqr0wmQ1tbGwYGBmAymXKqvYFAYE7s2zvV6OrqQigUknweMxmhUAgXXnjhjF4Pk6u9Wq0W7e3tqKmpwWeffYb33nsvW+198skncf/99+O2227Dtddei8suuwyLFi3K6e8955xzsGTJElx//fXZau+qVauwZs0abNq0CR999BG++uorNDU1QaVSYWhoCK+99ho2btyIb775pixbHK644gqMjY1JPQ06xaTOTURCCAZoKp3VasXy5ctLCgTlvJ9vKlU4QBeq9mZ6e81m80lXe9vb24tWey0Wy4yrvT6fr6xPI9RqtSWdeDkXRib4jo6Owu12Y3BwEGeccUZOtXfz5s1Yu3Ytnn32WTz88MO4++67sWLFClx99dW44IILciq9mWrv0qVLcfPNN+MPf/gDHn30Ubzwwgt444038P777+PTTz9FTU0N2tvbodfrYbfbMTIygqNHj37ram9zczMee+yxWXzXOL3KMfTTyZM6NxEJIRigqXSRSASXXXZZScFiLi2mSiQS2Wqv3+/PqfYajcaC1d7q6uq8o4kLVXu1Wm22t9dkMsFms0le7S330wgbGxtRX19/Sh8jU+0NhULZam9HRwdqa2vx+eef4/3338f69euxevVqPPnkk3jggQfw29/+FsuXL8fll1+e19u7aNEiXH755bjuuuvwox/9CPfeey9WrVqFV199FRs3bsSOHTuwf/9+NDY2QqlUYmhoCF6vF8lkck5Vez0eD5YtWyb1NIimJHVuIhJCMEBT6Y4dO4aFCxeWFFDMZjMGBga+VcCZWO31er1Fq709PT3Zam9bW1te6C1U7dXr9VNWezs6OhAIBMpyK75y6uEuNLZu3Vqw135ytXdoaAhKpRKNjY346quvsGvXLmzevBnr1q3DX//6V/zlL3/B73//e6xYsQJLly6dstp700034Z577sEjjzyC559/Hn//+9/x3nvvZau9bW1t0Ol0sNlsiEQi+Prrr4tWe++8807o9XoJ/g/99sbHx/Huu+9KPQ2iKUmdm4iEEAzQVLrx8XFUVFRMG95isRiMRmN2T9xi1V6lUpnt7S1W7e3s7Cy52huJRBCLxWYl9Eq9Fdy3HXNpJ4tMtTccDsNms0Gn02WrvV988QU++OADvPXWW3j55ZexcuVK3HHHHVi4cCGWL1+OJUuW4Jxzzsmr9l522WVYvnw5br/9djzwwAN46qmn8Oqrr2LDhg348MMPsW/fPhw+fBjd3d0YHByE1+tFIpE4LdXe1atXY//+/af0MYi+z6TOTURCCAZoKq6mpiZb1Vu7di2efvppnHHGGVi2bBkuvfRSvPjii0Wrva2trWhoaJi22hsKhRCNRufcKW16vR4Oh0Pyecx0XHPNNYhGo98q9GaqvR6PB0NDQ1CpVGhqasKBAwfw8ccf4913381Wex955BHcc889uOmmm7B06VJceOGFqKioyNnN4YILLsDVV1+Nm266CXfffTf+8pe/4K9//Stef/11bN26FZ988gmqq6tx8OBBnH/++bBarQiHw1NWe+eijz/+GG+88YbU0yD6zpI6NxEJIRigqbi33noLGzZswPbt27F3717U19fj7LPPRmtrK3p7e+Hz+YqG3nI/jGRwcHDO9HDPJPhedNFF2UVmnZ2dOHToULba+/bbb+OVV17BypUr8ac//Qm33347rrvuOixZsgTnnntuXrX30ksvxbXXXovf/va3eOCBB7By5Uq88sor2dfGl19+iYaGBigUCgwMDMDj8eRUe082+Jb7dmRHjhzBkSNHpJ4G0XeW1LmJSAjBAE0n5+KLL4bP55s2yJX7QjatVnva+ogzoTcej8Pr9cJoNGarvQcPHsTu3bvxf//3f3jttdfw/PPPZ6u9N998M371q1/hoosuygbeTNX3Zz/7GS666CKsWLEiW+197rnn8Nprr2HLli3YvXs3qqqq0NraCq1WC4vFglAohH/84x9zotq7cOFCyedARHOT1LmJSAjBAE0n59prr8XQ0NC0oTAej6O1tVXyIDzTsXv3bvz+978vKfhGIpHsCXQymQyHDh3Cnj17sG3btmy196mnnsKDDz6I3/3ud7j++uvxy1/+Eueee25Oi8PChQtx6aWX4pprrsFtt92G+++/H08++SRefvllvP322znfBMjlcvT398PtdiMej+dVe1evXo0DBw5I/GqZuVdffRWpVErqaRDRHCR1biISQjBA08m5/fbbS2rNSCaTc2ohW6Fqr8/ng8lkgkqlQnNzc7bau2XLFqxcuRIXXXQRHn30UfzhD3/IVnsvvvjinBaHiooKnHfeebjyyivx61//GnfddRcefvhhPPfcc1i3bh3effddfPzxx6isrERLSws0Gg0sFguCwSCOHDlyyqq977//PrZs2TLr90tEJDWpcxOREIIBmk7Ogw8+WPIevXfeeeesB9+RkRE4HI5stbeurg579+7F9u3bsWHDBrz66qvZau8dd9yBG264AVdccUW22psZCxcuxCWXXIJrrrkGt956K/74xz/iiSeewOrVq/HWW2/hzTffxKJFi1BXV4euri4YDAYMDw9jdHT0tB5PPFPV1dV44YUXpJ4GEdGskzo3EQkhGKDp5Dz77LPYs2dPSaH3zDPPzKn2ms1m9PT0oKWlBZWVldlq7+uvv44XX3wRjz32GO6991785je/wbJly/KqvQsWLMDixYtxxRVX4MYbb8Sdd96Jhx56CM8++yzWrVuHzZs3Y9euXTh48CBaWlqgVqthNptnVO39+uuvcf7555/iZ/PUicVicDgcUk+DiGjWSZ2biIQQDNB0clatWoX77rsPGzduxJo1a7Bq1aqcau+VV16JxYsXo6KiAj/84Q8xf/58LFiwABdffDH+93//F7fccgvuu+8+PP7443jppZewfv16bNu2DV988QXq6uogk8nQ19cHl8uFWCwmabV30aJFp/0xiYhoalLnJiIhBAM0nZyPPvoIDz/8MDZv3oydO3fiwIEDaG5uRk9PD0wmEwKBAMbGxjA+Po5ly5bB7/dLPeUZu/3226WeAhERTSJ1biISQjBA06lz2223YXBwUOppEBHRd4jUuYlICMEA/X115MgRLF68GGeffTbOOussvPjii7P+GA8++CDkcvms3y8R0VSef/55zJ8/HxUVFbj66qvh8XiknhLNIqlzE5EQggH6+2p8fByJRAIAcPToUZx33nmzHnYVCgUvXER02o2Ojmb/eePGjXjggQcknA3NNqlzE5EQggGagFQqhYULF0KhUEg9FSKaI1auXIn/+q//wvz583HjjTciGo1KPaUZWbt2Lf70pz9JPQ2aRVLnJiIhBAP099mxY8dQUVGBH/zgB1i1apXU0yGiOaS+vh7//Oc/AaR33ym394jnnnsOP/nJTzBv3jwEg0Gpp0OzSOrcRCSEYIAmIBqNYsmSJejr65N6KkQ0B+3fv3/O7Upz5ZVXYt68eXlj8hH2a9euPSVrPEg6UucmIiEEAzSlrV69Gm+88YbU0yD6ztizZw/OOuss/Mu//AtUKpXU0/lWli9fjo8//ljqacyIw+HAvHnzpJ4GzSKpcxOREIIB+vsqGAxmexrHxsZwySWXoKqqSuJZEX13DAwMYGhoCJdffvmcDdClVHHXrFmDG2+8cU4fXT+ZyWTK/vOmTZtw0003STgbmm1S5yYiIQQD9PeVXq/HggULMH/+fMybNw8vv/yy1FMiyjp06BD+8z//Ez//+c+xbt06qafzrczlAD2djz76CBdccAFSqZTUUzkpK1aswLx58zB//nwsX74cbrdb6inRLJI6NxEJIRigiWhuOXbsGM444wxYrVZ8/fXXOPvss9Hf3y/1tGasXAP0oUOH8N///d9cgEdzjtS5iUgIwQBNRHNLV1cXli5dmv33tWvXYu3atRLOqLhSWiDKNUD//Oc/x09+8hNUVFSgoqKCeynTnCF1biISQjBAE30X3XPPPfjhD39Yloun9u7di3vvvTf777t27cJDDz0k4Yy+nXIN0ERzldS5iUgIwQBN9F3U1tYGtVpdlgF6z549eQH64YcflnBG3w4DNNHskjo3EQkhGKCJCnG5XFiyZAl+8Ytf4KyzzsKGDRukntJJs9vtZRmgy6mFYyr79+/Hj3/8Y/zbv/0b/v3f/z3n70REMyd1biISQjBAExXi9XqhVqsBAPF4HGeeeWbZLWQr1wD9z3/+Ez/72c9gs9myiwgNBoPU0yKiOULq3EQkhGCAJirF9ddfj4aGBqmncVLKNUADQE1NDc4880ycccYZWLNmjdTTIaI5ROrcRCSEYICmU+PIkSNYvHgxzj77bJx11lllfZSu3W7HT3/6U4yOjko9lZNSzgGaiKgYqXMTkRCCAZpOjfHxcSQSCQDA0aNHcd5550Eul0s8q5OXSCSwaNEi7Nu3T+qpnDQGaCL6LpI6NxEJIRig6dRLpVJYuHAhFAqF1FM5KUePHsXSpUuxfv16qady0m677Tb86Ec/wr/+67/ixz/+MbZt2yb1lIiIZoXUuYlICMEATafOsWPHUFFRgR/84AdYtWqV1NM5KePj47jzzjvx6KOPSj0VIiKaQOrcRCSEYICmUy8ajWLJkiXo6+uTeiol6+jogBAC8+fPz57EVlNTI/W0iIi+96TOTURCCAZoOj1Wr16NN954Q+ppEBFRmZM6NxEJIRig6dQIBoOIRqMAgLGxMVxyySWoqqqSeFZERFTupM5NREIIBmg6NfR6PRYsWID58+dj3rx5ePnll6WeEhERfQdInZuIhBAM0ERERFQ+pM5NREIIBmgiIiIqH1LnJiIhBAM0ERERlQ+pcxOREIIBmoiIiMqH1LmJSAjBAE1ERETlQ+rcRCSEYIAmIiKi8iF1biISQjBAExERUfmQOjcRCSEYoImIiKh8SJ2biIQQDNBERERUPqTOTURCCAZoIiIiKh9S5yYiIQQDNBEREZUPqXMTkRCCAZqIiIjKh9S5iUgIwQBNRERE5UPq3EQkhGCAJiIiovIhdW4iEkIwQBMREVH5kDo3EQkhGKCJiIiofEidm4iEEAzQREREVD6kzk1EQggGaCIiIiofUucmIiEEAzQRERGVD6lzE5EQggGaiIiIyofUuYlICMEATUREROVD6txEJIRggCYiIqLyIXVuIhJCMEATERFR+ZA6NxEJIRigiYiIqHxInZuIhBAM0ERERFQ+pM5NREIIBmgiIiIqH1LnJiIhBAM0ERERlQ+pcxOREIIBmoiIiMqH1LmJSAjBAE1ERETlQ+rcREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREREXvd7gwAAADpJREFURERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERz3f8DXRSc7P1nY4YAAAAASUVORK5CYII=\" width=\"720\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "cmap = cm.viridis\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(noise[:,0],noise[:,1],noise[:,2],c=colors,alpha=0.1)\n",
    "plt.title('Gaussian noise')\n",
    "plt.show()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def makePlot(self, GeN,noise, alpha=0.05 ,device=device):\n",
    "    def get_linewidth(linewidth, axis):\n",
    "        fig = axis.get_figure()\n",
    "        ppi = 72  # matplolib points per inches\n",
    "        length = fig.bbox_inches.height * axis.get_position().height\n",
    "        value_range = np.diff(axis.get_ylim())[0]\n",
    "        return linewidth * ppi * length / value_range\n",
    "#    nb_samples_plot=theta.shape[0]\n",
    "    x_lin = torch.linspace(-2.0, 2.0).unsqueeze(1)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 10)\n",
    "    plt.xlim(-2, 2) \n",
    "    plt.ylim(-4, 6)\n",
    "    plt.grid(True, which='major', linewidth=0.5)\n",
    "    my_lw=get_linewidth(0.2,ax)\n",
    "#    alpha = (.9 / torch.tensor(float(nb_samples_plot)).sqrt()).clamp(0.05, 1.)\n",
    "    \n",
    "    colors=noise[2]\n",
    "    \n",
    "    norm=Normalize(vmin=colors.min(), vmax=colors.max())\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    for i in range(colors.shape[0]):\n",
    "        for j in range(colors.shape[1]):\n",
    "            xy_noise=torch.Tensor([noise[0][i,j],noise[1][i,j]]).unsqueeze(0).to(device)\n",
    "            theta=GeN.components[0].hnet(xy_noise).detach()\n",
    "            y_pred = self._normalized_prediction(x_lin, theta, device)\n",
    "            color=m.to_rgba(colors[i,j])\n",
    "            plt.plot(x_lin.detach().cpu().numpy(), y_pred.squeeze(0).detach().cpu().numpy(), alpha=alpha, linewidth=1.0, color=color,zorder=3)\n",
    "    plt.scatter(self._X_train.cpu(), self._y_train.cpu(), marker='.',color='black',zorder=4)\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup.plot:\n",
    "    fig=makePlot(setup,GeN,noise, alpha=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20000], Loss: 723758.0, Entropy 216.88058471679688, Learning Rate: 0.01\n",
      "Epoch [1/20000], Loss: 1241614.5, Entropy 195.74867248535156, Learning Rate: 0.01\n",
      "Epoch [2/20000], Loss: 487467.34375, Entropy 192.08148193359375, Learning Rate: 0.01\n",
      "Epoch [3/20000], Loss: 334976.21875, Entropy 176.78306579589844, Learning Rate: 0.01\n",
      "Epoch [4/20000], Loss: 314977.125, Entropy 169.74192810058594, Learning Rate: 0.01\n",
      "Epoch [5/20000], Loss: 210907.828125, Entropy 138.9728240966797, Learning Rate: 0.01\n",
      "Epoch [6/20000], Loss: 229237.015625, Entropy 135.26759338378906, Learning Rate: 0.01\n",
      "Epoch [7/20000], Loss: 125905.609375, Entropy 137.01918029785156, Learning Rate: 0.01\n",
      "Epoch [8/20000], Loss: 165243.875, Entropy 133.68870544433594, Learning Rate: 0.01\n",
      "Epoch [9/20000], Loss: 100251.6875, Entropy 113.14781188964844, Learning Rate: 0.01\n",
      "Epoch [10/20000], Loss: 98115.4375, Entropy 111.21495056152344, Learning Rate: 0.01\n",
      "Epoch [11/20000], Loss: 73555.7734375, Entropy 96.98065185546875, Learning Rate: 0.01\n",
      "Epoch [12/20000], Loss: 68974.8359375, Entropy 89.42938995361328, Learning Rate: 0.01\n",
      "Epoch [13/20000], Loss: 55584.85546875, Entropy 97.19037628173828, Learning Rate: 0.01\n",
      "Epoch [14/20000], Loss: 58932.8671875, Entropy 81.27734375, Learning Rate: 0.01\n",
      "Epoch [15/20000], Loss: 56112.90234375, Entropy 68.3861312866211, Learning Rate: 0.01\n",
      "Epoch [16/20000], Loss: 80421.0390625, Entropy 77.93350982666016, Learning Rate: 0.01\n",
      "Epoch [17/20000], Loss: 49025.97265625, Entropy 68.73578643798828, Learning Rate: 0.01\n",
      "Epoch [18/20000], Loss: 48126.765625, Entropy 50.87786102294922, Learning Rate: 0.01\n",
      "Epoch [19/20000], Loss: 50765.109375, Entropy 61.037479400634766, Learning Rate: 0.01\n",
      "Epoch [20/20000], Loss: 38227.70703125, Entropy 52.17019271850586, Learning Rate: 0.01\n",
      "Epoch [21/20000], Loss: 29207.890625, Entropy 58.167781829833984, Learning Rate: 0.01\n",
      "Epoch [22/20000], Loss: 30450.333984375, Entropy 26.326078414916992, Learning Rate: 0.01\n",
      "Epoch [23/20000], Loss: 24915.35546875, Entropy 50.86974334716797, Learning Rate: 0.01\n",
      "Epoch [24/20000], Loss: 21326.765625, Entropy 35.010887145996094, Learning Rate: 0.01\n",
      "Epoch [25/20000], Loss: 18770.1953125, Entropy 46.4391975402832, Learning Rate: 0.01\n",
      "Epoch [26/20000], Loss: 24111.662109375, Entropy 21.779306411743164, Learning Rate: 0.01\n",
      "Epoch [27/20000], Loss: 18436.986328125, Entropy 27.362777709960938, Learning Rate: 0.01\n",
      "Epoch [28/20000], Loss: 19558.421875, Entropy 40.141380310058594, Learning Rate: 0.01\n",
      "Epoch [29/20000], Loss: 22895.650390625, Entropy 32.08500289916992, Learning Rate: 0.01\n",
      "Epoch [30/20000], Loss: 18200.896484375, Entropy 22.935699462890625, Learning Rate: 0.01\n",
      "Epoch [31/20000], Loss: 14923.15625, Entropy 11.057512283325195, Learning Rate: 0.01\n",
      "Epoch [32/20000], Loss: 13536.9951171875, Entropy 3.9945831298828125, Learning Rate: 0.01\n",
      "Epoch [33/20000], Loss: 16961.287109375, Entropy 14.938207626342773, Learning Rate: 0.01\n",
      "Epoch [34/20000], Loss: 14329.0068359375, Entropy 14.931318283081055, Learning Rate: 0.01\n",
      "Epoch [35/20000], Loss: 10829.9755859375, Entropy 6.566018581390381, Learning Rate: 0.01\n",
      "Epoch [36/20000], Loss: 10278.3017578125, Entropy 4.42055606842041, Learning Rate: 0.01\n",
      "Epoch [37/20000], Loss: 10000.4130859375, Entropy -3.4346935749053955, Learning Rate: 0.01\n",
      "Epoch [38/20000], Loss: 9310.3759765625, Entropy -1.5686941146850586, Learning Rate: 0.01\n",
      "Epoch [39/20000], Loss: 10432.26953125, Entropy -9.783357620239258, Learning Rate: 0.01\n",
      "Epoch [40/20000], Loss: 9313.6552734375, Entropy -8.208022117614746, Learning Rate: 0.01\n",
      "Epoch [41/20000], Loss: 8533.3173828125, Entropy 7.508615016937256, Learning Rate: 0.01\n",
      "Epoch [42/20000], Loss: 8122.95556640625, Entropy -12.323412895202637, Learning Rate: 0.01\n",
      "Epoch [43/20000], Loss: 8420.0751953125, Entropy -18.03914451599121, Learning Rate: 0.01\n",
      "Epoch [44/20000], Loss: 8461.8232421875, Entropy -16.855939865112305, Learning Rate: 0.01\n",
      "Epoch [45/20000], Loss: 7909.09228515625, Entropy -6.964977741241455, Learning Rate: 0.01\n",
      "Epoch [46/20000], Loss: 7244.62841796875, Entropy -4.651019096374512, Learning Rate: 0.01\n",
      "Epoch [47/20000], Loss: 6767.0849609375, Entropy -8.368795394897461, Learning Rate: 0.01\n",
      "Epoch [48/20000], Loss: 7311.2431640625, Entropy -17.173542022705078, Learning Rate: 0.01\n",
      "Epoch [49/20000], Loss: 6718.1015625, Entropy -22.052865982055664, Learning Rate: 0.01\n",
      "Epoch [50/20000], Loss: 5059.33251953125, Entropy -23.445846557617188, Learning Rate: 0.01\n",
      "Epoch [51/20000], Loss: 5241.42431640625, Entropy -16.935644149780273, Learning Rate: 0.01\n",
      "Epoch [52/20000], Loss: 5272.578125, Entropy -33.553165435791016, Learning Rate: 0.01\n",
      "Epoch [53/20000], Loss: 5462.193359375, Entropy -26.792211532592773, Learning Rate: 0.01\n",
      "Epoch [54/20000], Loss: 6233.65478515625, Entropy -17.692533493041992, Learning Rate: 0.01\n",
      "Epoch [55/20000], Loss: 4706.14501953125, Entropy -38.982322692871094, Learning Rate: 0.01\n",
      "Epoch [56/20000], Loss: 5074.02001953125, Entropy -35.64283752441406, Learning Rate: 0.01\n",
      "Epoch [57/20000], Loss: 5422.80712890625, Entropy -38.14097213745117, Learning Rate: 0.01\n",
      "Epoch [58/20000], Loss: 4551.515625, Entropy -16.640775680541992, Learning Rate: 0.01\n",
      "Epoch [59/20000], Loss: 4422.94873046875, Entropy -35.526119232177734, Learning Rate: 0.01\n",
      "Epoch [60/20000], Loss: 4217.833984375, Entropy -35.57244110107422, Learning Rate: 0.01\n",
      "Epoch [61/20000], Loss: 4541.533203125, Entropy -24.433055877685547, Learning Rate: 0.01\n",
      "Epoch [62/20000], Loss: 4141.0146484375, Entropy -34.52156448364258, Learning Rate: 0.01\n",
      "Epoch [63/20000], Loss: 3700.4541015625, Entropy -25.893550872802734, Learning Rate: 0.01\n",
      "Epoch [64/20000], Loss: 4292.32666015625, Entropy -34.07914352416992, Learning Rate: 0.01\n",
      "Epoch [65/20000], Loss: 4575.21435546875, Entropy -26.510299682617188, Learning Rate: 0.01\n",
      "Epoch [66/20000], Loss: 3729.22021484375, Entropy -34.960819244384766, Learning Rate: 0.01\n",
      "Epoch [67/20000], Loss: 4341.3076171875, Entropy -48.7968635559082, Learning Rate: 0.01\n",
      "Epoch [68/20000], Loss: 3726.10595703125, Entropy -36.61035919189453, Learning Rate: 0.01\n",
      "Epoch [69/20000], Loss: 3477.282470703125, Entropy -53.10883712768555, Learning Rate: 0.01\n",
      "Epoch [70/20000], Loss: 4119.6181640625, Entropy -37.51188278198242, Learning Rate: 0.01\n",
      "Epoch [71/20000], Loss: 3310.760498046875, Entropy -51.295623779296875, Learning Rate: 0.01\n",
      "Epoch [72/20000], Loss: 3646.208251953125, Entropy -39.71604919433594, Learning Rate: 0.01\n",
      "Epoch [73/20000], Loss: 3435.2099609375, Entropy -36.56979751586914, Learning Rate: 0.01\n",
      "Epoch [74/20000], Loss: 3238.83642578125, Entropy -44.99338912963867, Learning Rate: 0.01\n",
      "Epoch [75/20000], Loss: 3038.0771484375, Entropy -44.03921890258789, Learning Rate: 0.01\n",
      "Epoch [76/20000], Loss: 3003.112548828125, Entropy -53.14733123779297, Learning Rate: 0.01\n",
      "Epoch [77/20000], Loss: 2908.462890625, Entropy -48.501502990722656, Learning Rate: 0.01\n",
      "Epoch [78/20000], Loss: 3034.322021484375, Entropy -47.830223083496094, Learning Rate: 0.01\n",
      "Epoch [79/20000], Loss: 2963.626953125, Entropy -59.15829086303711, Learning Rate: 0.01\n",
      "Epoch [80/20000], Loss: 3131.35791015625, Entropy -51.19210433959961, Learning Rate: 0.01\n",
      "Epoch [81/20000], Loss: 3249.111083984375, Entropy -40.33667755126953, Learning Rate: 0.01\n",
      "Epoch [82/20000], Loss: 2782.049072265625, Entropy -41.59426498413086, Learning Rate: 0.01\n",
      "Epoch [83/20000], Loss: 3428.56494140625, Entropy -55.25553894042969, Learning Rate: 0.01\n",
      "Epoch [84/20000], Loss: 2780.983154296875, Entropy -58.05098342895508, Learning Rate: 0.01\n",
      "Epoch [85/20000], Loss: 3010.841064453125, Entropy -49.854530334472656, Learning Rate: 0.01\n",
      "Epoch [86/20000], Loss: 3479.37060546875, Entropy -57.806907653808594, Learning Rate: 0.01\n",
      "Epoch [87/20000], Loss: 3485.275634765625, Entropy -38.71255111694336, Learning Rate: 0.01\n",
      "Epoch [88/20000], Loss: 2742.775390625, Entropy -29.88528823852539, Learning Rate: 0.01\n",
      "Epoch [89/20000], Loss: 2867.624755859375, Entropy -44.924041748046875, Learning Rate: 0.01\n",
      "Epoch [90/20000], Loss: 2923.159423828125, Entropy -42.833168029785156, Learning Rate: 0.01\n",
      "Epoch [91/20000], Loss: 2808.643310546875, Entropy -41.69965744018555, Learning Rate: 0.01\n",
      "Epoch [92/20000], Loss: 2965.262939453125, Entropy -53.26469039916992, Learning Rate: 0.01\n",
      "Epoch [93/20000], Loss: 2633.713134765625, Entropy -60.7544059753418, Learning Rate: 0.01\n",
      "Epoch [94/20000], Loss: 2956.939453125, Entropy -56.59567642211914, Learning Rate: 0.01\n",
      "Epoch [95/20000], Loss: 2585.224853515625, Entropy -64.53376007080078, Learning Rate: 0.01\n",
      "Epoch [96/20000], Loss: 2560.59423828125, Entropy -40.21319580078125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/20000], Loss: 3130.330078125, Entropy -53.892024993896484, Learning Rate: 0.01\n",
      "Epoch [98/20000], Loss: 2596.9443359375, Entropy -52.62086486816406, Learning Rate: 0.01\n",
      "Epoch [99/20000], Loss: 2566.133056640625, Entropy -52.31684494018555, Learning Rate: 0.01\n",
      "Epoch [100/20000], Loss: 2726.84228515625, Entropy -49.60799789428711, Learning Rate: 0.01\n",
      "Epoch [101/20000], Loss: 2620.067626953125, Entropy -55.878662109375, Learning Rate: 0.01\n",
      "Epoch [102/20000], Loss: 2394.1865234375, Entropy -55.35234832763672, Learning Rate: 0.01\n",
      "Epoch [103/20000], Loss: 2836.488525390625, Entropy -74.89437103271484, Learning Rate: 0.01\n",
      "Epoch [104/20000], Loss: 2517.982666015625, Entropy -60.539100646972656, Learning Rate: 0.01\n",
      "Epoch [105/20000], Loss: 2365.5185546875, Entropy -63.90717697143555, Learning Rate: 0.01\n",
      "Epoch [106/20000], Loss: 2408.8330078125, Entropy -63.65753173828125, Learning Rate: 0.01\n",
      "Epoch [107/20000], Loss: 2584.061279296875, Entropy -56.61248016357422, Learning Rate: 0.01\n",
      "Epoch [108/20000], Loss: 2575.38623046875, Entropy -45.578773498535156, Learning Rate: 0.01\n",
      "Epoch [109/20000], Loss: 2522.26220703125, Entropy -53.58753967285156, Learning Rate: 0.01\n",
      "Epoch [110/20000], Loss: 2720.998046875, Entropy -51.86128616333008, Learning Rate: 0.01\n",
      "Epoch [111/20000], Loss: 2373.734619140625, Entropy -51.70806884765625, Learning Rate: 0.01\n",
      "Epoch [112/20000], Loss: 2544.219482421875, Entropy -63.42340850830078, Learning Rate: 0.01\n",
      "Epoch [113/20000], Loss: 2538.538330078125, Entropy -69.8635025024414, Learning Rate: 0.01\n",
      "Epoch [114/20000], Loss: 2592.57568359375, Entropy -56.586551666259766, Learning Rate: 0.01\n",
      "Epoch [115/20000], Loss: 2147.1455078125, Entropy -56.36539840698242, Learning Rate: 0.01\n",
      "Epoch [116/20000], Loss: 2326.474853515625, Entropy -63.92416763305664, Learning Rate: 0.01\n",
      "Epoch [117/20000], Loss: 2679.017822265625, Entropy -66.61846160888672, Learning Rate: 0.01\n",
      "Epoch [118/20000], Loss: 2225.729248046875, Entropy -64.29195404052734, Learning Rate: 0.01\n",
      "Epoch [119/20000], Loss: 2426.72509765625, Entropy -55.26058578491211, Learning Rate: 0.01\n",
      "Epoch [120/20000], Loss: 2545.193603515625, Entropy -62.60432052612305, Learning Rate: 0.01\n",
      "Epoch [121/20000], Loss: 2632.423583984375, Entropy -75.70514678955078, Learning Rate: 0.01\n",
      "Epoch [122/20000], Loss: 2253.3447265625, Entropy -59.31632614135742, Learning Rate: 0.01\n",
      "Epoch [123/20000], Loss: 2214.94189453125, Entropy -49.911746978759766, Learning Rate: 0.01\n",
      "Epoch [124/20000], Loss: 2532.87109375, Entropy -64.90678405761719, Learning Rate: 0.01\n",
      "Epoch [125/20000], Loss: 2168.974365234375, Entropy -57.9824104309082, Learning Rate: 0.01\n",
      "Epoch [126/20000], Loss: 2473.748046875, Entropy -54.82742691040039, Learning Rate: 0.01\n",
      "Epoch [127/20000], Loss: 2083.07275390625, Entropy -59.22216796875, Learning Rate: 0.01\n",
      "Epoch [128/20000], Loss: 2188.983642578125, Entropy -58.41963577270508, Learning Rate: 0.01\n",
      "Epoch [129/20000], Loss: 2360.06201171875, Entropy -71.00138854980469, Learning Rate: 0.01\n",
      "Epoch [130/20000], Loss: 2111.952880859375, Entropy -68.92599487304688, Learning Rate: 0.01\n",
      "Epoch [131/20000], Loss: 2380.41162109375, Entropy -56.4859619140625, Learning Rate: 0.01\n",
      "Epoch [132/20000], Loss: 2210.636962890625, Entropy -72.637939453125, Learning Rate: 0.01\n",
      "Epoch [133/20000], Loss: 2439.285888671875, Entropy -81.036865234375, Learning Rate: 0.01\n",
      "Epoch [134/20000], Loss: 2313.5927734375, Entropy -59.49863052368164, Learning Rate: 0.01\n",
      "Epoch [135/20000], Loss: 2591.01171875, Entropy -56.491146087646484, Learning Rate: 0.01\n",
      "Epoch [136/20000], Loss: 2158.59423828125, Entropy -64.047119140625, Learning Rate: 0.01\n",
      "Epoch [137/20000], Loss: 2082.978759765625, Entropy -65.08186340332031, Learning Rate: 0.01\n",
      "Epoch [138/20000], Loss: 2360.01953125, Entropy -67.73995208740234, Learning Rate: 0.01\n",
      "Epoch [139/20000], Loss: 2152.26513671875, Entropy -67.1331787109375, Learning Rate: 0.01\n",
      "Epoch [140/20000], Loss: 2266.255615234375, Entropy -68.93708038330078, Learning Rate: 0.01\n",
      "Epoch [141/20000], Loss: 2041.240966796875, Entropy -60.64593505859375, Learning Rate: 0.01\n",
      "Epoch [142/20000], Loss: 2125.248779296875, Entropy -61.74303436279297, Learning Rate: 0.01\n",
      "Epoch [143/20000], Loss: 2242.35888671875, Entropy -56.69822692871094, Learning Rate: 0.01\n",
      "Epoch [144/20000], Loss: 2122.16943359375, Entropy -54.11045837402344, Learning Rate: 0.01\n",
      "Epoch [145/20000], Loss: 1979.3746337890625, Entropy -86.15626525878906, Learning Rate: 0.01\n",
      "Epoch [146/20000], Loss: 2287.14404296875, Entropy -57.910858154296875, Learning Rate: 0.01\n",
      "Epoch [147/20000], Loss: 2173.73046875, Entropy -53.54845428466797, Learning Rate: 0.01\n",
      "Epoch [148/20000], Loss: 2165.0458984375, Entropy -74.2421646118164, Learning Rate: 0.01\n",
      "Epoch [149/20000], Loss: 2206.59814453125, Entropy -74.19395446777344, Learning Rate: 0.01\n",
      "Epoch [150/20000], Loss: 2006.9945068359375, Entropy -74.1600112915039, Learning Rate: 0.01\n",
      "Epoch [151/20000], Loss: 2122.50146484375, Entropy -67.14820861816406, Learning Rate: 0.01\n",
      "Epoch [152/20000], Loss: 2170.39990234375, Entropy -67.55453491210938, Learning Rate: 0.01\n",
      "Epoch [153/20000], Loss: 1939.3721923828125, Entropy -55.301185607910156, Learning Rate: 0.01\n",
      "Epoch [154/20000], Loss: 2290.510009765625, Entropy -75.16065979003906, Learning Rate: 0.01\n",
      "Epoch [155/20000], Loss: 2011.3555908203125, Entropy -74.50784301757812, Learning Rate: 0.01\n",
      "Epoch [156/20000], Loss: 2038.98486328125, Entropy -65.53153991699219, Learning Rate: 0.01\n",
      "Epoch [157/20000], Loss: 2338.13134765625, Entropy -72.04061126708984, Learning Rate: 0.01\n",
      "Epoch [158/20000], Loss: 2025.521728515625, Entropy -78.9691390991211, Learning Rate: 0.01\n",
      "Epoch [159/20000], Loss: 1835.3826904296875, Entropy -66.77672576904297, Learning Rate: 0.01\n",
      "Epoch [160/20000], Loss: 2113.9384765625, Entropy -80.87089538574219, Learning Rate: 0.01\n",
      "Epoch [161/20000], Loss: 1979.38671875, Entropy -69.49490356445312, Learning Rate: 0.01\n",
      "Epoch [162/20000], Loss: 1959.26416015625, Entropy -61.683876037597656, Learning Rate: 0.01\n",
      "Epoch [163/20000], Loss: 2342.860107421875, Entropy -70.5426254272461, Learning Rate: 0.01\n",
      "Epoch [164/20000], Loss: 1940.7650146484375, Entropy -64.69290161132812, Learning Rate: 0.01\n",
      "Epoch [165/20000], Loss: 2129.0068359375, Entropy -70.09494018554688, Learning Rate: 0.01\n",
      "Epoch [166/20000], Loss: 2061.950439453125, Entropy -86.67671966552734, Learning Rate: 0.01\n",
      "Epoch [167/20000], Loss: 1971.7874755859375, Entropy -82.4286880493164, Learning Rate: 0.01\n",
      "Epoch [168/20000], Loss: 1945.399169921875, Entropy -84.97921752929688, Learning Rate: 0.01\n",
      "Epoch [169/20000], Loss: 1950.2376708984375, Entropy -79.2452392578125, Learning Rate: 0.01\n",
      "Epoch [170/20000], Loss: 1970.4501953125, Entropy -65.26329040527344, Learning Rate: 0.01\n",
      "Epoch [171/20000], Loss: 2221.322509765625, Entropy -74.51903533935547, Learning Rate: 0.01\n",
      "Epoch [172/20000], Loss: 2116.70947265625, Entropy -83.7618637084961, Learning Rate: 0.01\n",
      "Epoch [173/20000], Loss: 1873.1514892578125, Entropy -67.50792694091797, Learning Rate: 0.01\n",
      "Epoch [174/20000], Loss: 1921.18310546875, Entropy -80.39879608154297, Learning Rate: 0.01\n",
      "Epoch [175/20000], Loss: 2002.5809326171875, Entropy -76.67969512939453, Learning Rate: 0.01\n",
      "Epoch [176/20000], Loss: 2092.384765625, Entropy -65.77819061279297, Learning Rate: 0.01\n",
      "Epoch [177/20000], Loss: 2006.9996337890625, Entropy -68.25340270996094, Learning Rate: 0.01\n",
      "Epoch [178/20000], Loss: 2020.0361328125, Entropy -70.54920196533203, Learning Rate: 0.01\n",
      "Epoch [179/20000], Loss: 2137.32421875, Entropy -81.854248046875, Learning Rate: 0.01\n",
      "Epoch [180/20000], Loss: 1891.3385009765625, Entropy -89.07839965820312, Learning Rate: 0.01\n",
      "Epoch [181/20000], Loss: 1911.8870849609375, Entropy -80.44058227539062, Learning Rate: 0.01\n",
      "Epoch [182/20000], Loss: 1933.2462158203125, Entropy -76.17284393310547, Learning Rate: 0.01\n",
      "Epoch [183/20000], Loss: 1806.8350830078125, Entropy -72.03846740722656, Learning Rate: 0.01\n",
      "Epoch [184/20000], Loss: 1871.523681640625, Entropy -81.54203796386719, Learning Rate: 0.01\n",
      "Epoch [185/20000], Loss: 2016.9320068359375, Entropy -88.23888397216797, Learning Rate: 0.01\n",
      "Epoch [186/20000], Loss: 1970.1781005859375, Entropy -72.0615005493164, Learning Rate: 0.01\n",
      "Epoch [187/20000], Loss: 1743.613525390625, Entropy -76.58537292480469, Learning Rate: 0.01\n",
      "Epoch [188/20000], Loss: 2032.17578125, Entropy -71.02864837646484, Learning Rate: 0.01\n",
      "Epoch [189/20000], Loss: 1857.9847412109375, Entropy -68.64884185791016, Learning Rate: 0.01\n",
      "Epoch [190/20000], Loss: 1855.514404296875, Entropy -65.86257934570312, Learning Rate: 0.01\n",
      "Epoch [191/20000], Loss: 2060.343994140625, Entropy -72.87907409667969, Learning Rate: 0.01\n",
      "Epoch [192/20000], Loss: 1873.627685546875, Entropy -77.88591766357422, Learning Rate: 0.01\n",
      "Epoch [193/20000], Loss: 1934.586181640625, Entropy -73.58319091796875, Learning Rate: 0.01\n",
      "Epoch [194/20000], Loss: 2007.934326171875, Entropy -68.65626525878906, Learning Rate: 0.01\n",
      "Epoch [195/20000], Loss: 1774.800048828125, Entropy -71.92256164550781, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/20000], Loss: 1858.144287109375, Entropy -78.40687561035156, Learning Rate: 0.01\n",
      "Epoch [197/20000], Loss: 1663.6707763671875, Entropy -77.83549499511719, Learning Rate: 0.01\n",
      "Epoch [198/20000], Loss: 2140.43017578125, Entropy -70.16228485107422, Learning Rate: 0.01\n",
      "Epoch [199/20000], Loss: 1744.9796142578125, Entropy -85.606689453125, Learning Rate: 0.01\n",
      "Epoch [200/20000], Loss: 2153.525390625, Entropy -85.88459014892578, Learning Rate: 0.01\n",
      "Epoch [201/20000], Loss: 1895.1507568359375, Entropy -82.65046691894531, Learning Rate: 0.01\n",
      "Epoch [202/20000], Loss: 2008.656005859375, Entropy -85.04039001464844, Learning Rate: 0.01\n",
      "Epoch [203/20000], Loss: 1684.0389404296875, Entropy -75.00527954101562, Learning Rate: 0.01\n",
      "Epoch [204/20000], Loss: 1723.1573486328125, Entropy -87.46318054199219, Learning Rate: 0.01\n",
      "Epoch [205/20000], Loss: 1788.3291015625, Entropy -68.13470458984375, Learning Rate: 0.01\n",
      "Epoch [206/20000], Loss: 1847.178955078125, Entropy -73.4771499633789, Learning Rate: 0.01\n",
      "Epoch [207/20000], Loss: 1886.9608154296875, Entropy -79.40926361083984, Learning Rate: 0.01\n",
      "Epoch [208/20000], Loss: 1832.944580078125, Entropy -68.22607421875, Learning Rate: 0.01\n",
      "Epoch [209/20000], Loss: 1727.0887451171875, Entropy -71.45812225341797, Learning Rate: 0.01\n",
      "Epoch [210/20000], Loss: 1785.2200927734375, Entropy -86.23828125, Learning Rate: 0.01\n",
      "Epoch [211/20000], Loss: 1897.2659912109375, Entropy -79.8775634765625, Learning Rate: 0.01\n",
      "Epoch [212/20000], Loss: 1689.544189453125, Entropy -87.89952850341797, Learning Rate: 0.01\n",
      "Epoch [213/20000], Loss: 1687.6956787109375, Entropy -59.242919921875, Learning Rate: 0.01\n",
      "Epoch [214/20000], Loss: 2013.6239013671875, Entropy -83.4937744140625, Learning Rate: 0.01\n",
      "Epoch [215/20000], Loss: 2058.85498046875, Entropy -83.29476165771484, Learning Rate: 0.01\n",
      "Epoch [216/20000], Loss: 1825.3773193359375, Entropy -85.69805145263672, Learning Rate: 0.01\n",
      "Epoch [217/20000], Loss: 1876.0499267578125, Entropy -77.59465026855469, Learning Rate: 0.01\n",
      "Epoch [218/20000], Loss: 1925.5162353515625, Entropy -75.94529724121094, Learning Rate: 0.01\n",
      "Epoch [219/20000], Loss: 1772.0836181640625, Entropy -81.56045532226562, Learning Rate: 0.01\n",
      "Epoch [220/20000], Loss: 1742.2342529296875, Entropy -93.2870864868164, Learning Rate: 0.01\n",
      "Epoch [221/20000], Loss: 2008.96435546875, Entropy -82.84319305419922, Learning Rate: 0.01\n",
      "Epoch [222/20000], Loss: 1718.790283203125, Entropy -81.48210144042969, Learning Rate: 0.01\n",
      "Epoch [223/20000], Loss: 1735.5570068359375, Entropy -77.5535659790039, Learning Rate: 0.01\n",
      "Epoch [224/20000], Loss: 1817.63623046875, Entropy -89.15987396240234, Learning Rate: 0.01\n",
      "Epoch [225/20000], Loss: 2043.79833984375, Entropy -71.68083953857422, Learning Rate: 0.01\n",
      "Epoch [226/20000], Loss: 1852.692138671875, Entropy -72.49846649169922, Learning Rate: 0.01\n",
      "Epoch [227/20000], Loss: 1762.82763671875, Entropy -88.15706634521484, Learning Rate: 0.01\n",
      "Epoch [228/20000], Loss: 1877.0103759765625, Entropy -84.7510757446289, Learning Rate: 0.01\n",
      "Epoch [229/20000], Loss: 1874.7164306640625, Entropy -76.8858642578125, Learning Rate: 0.01\n",
      "Epoch [230/20000], Loss: 1727.6326904296875, Entropy -78.03023529052734, Learning Rate: 0.01\n",
      "Epoch [231/20000], Loss: 1715.8389892578125, Entropy -86.50419616699219, Learning Rate: 0.01\n",
      "Epoch [232/20000], Loss: 1753.1707763671875, Entropy -94.86663055419922, Learning Rate: 0.01\n",
      "Epoch [233/20000], Loss: 1605.3798828125, Entropy -64.31877136230469, Learning Rate: 0.01\n",
      "Epoch [234/20000], Loss: 1686.5133056640625, Entropy -94.69161224365234, Learning Rate: 0.01\n",
      "Epoch [235/20000], Loss: 1719.49462890625, Entropy -76.20379638671875, Learning Rate: 0.01\n",
      "Epoch [236/20000], Loss: 2013.156005859375, Entropy -78.9911117553711, Learning Rate: 0.01\n",
      "Epoch [237/20000], Loss: 1845.2315673828125, Entropy -90.52273559570312, Learning Rate: 0.01\n",
      "Epoch [238/20000], Loss: 1854.0169677734375, Entropy -90.48383331298828, Learning Rate: 0.01\n",
      "Epoch [239/20000], Loss: 2013.5313720703125, Entropy -90.19325256347656, Learning Rate: 0.01\n",
      "Epoch [240/20000], Loss: 1783.2166748046875, Entropy -93.26349639892578, Learning Rate: 0.01\n",
      "Epoch [241/20000], Loss: 1663.2794189453125, Entropy -79.15227508544922, Learning Rate: 0.01\n",
      "Epoch [242/20000], Loss: 1695.481689453125, Entropy -79.45646667480469, Learning Rate: 0.01\n",
      "Epoch [243/20000], Loss: 1644.586669921875, Entropy -75.65261840820312, Learning Rate: 0.01\n",
      "Epoch [244/20000], Loss: 1789.576171875, Entropy -85.58011627197266, Learning Rate: 0.01\n",
      "Epoch [245/20000], Loss: 1739.5203857421875, Entropy -72.24005889892578, Learning Rate: 0.01\n",
      "Epoch [246/20000], Loss: 1750.094482421875, Entropy -86.62263488769531, Learning Rate: 0.01\n",
      "Epoch [247/20000], Loss: 1693.3612060546875, Entropy -85.53962707519531, Learning Rate: 0.01\n",
      "Epoch [248/20000], Loss: 1658.990478515625, Entropy -90.75650024414062, Learning Rate: 0.01\n",
      "Epoch [249/20000], Loss: 1724.69775390625, Entropy -92.55144500732422, Learning Rate: 0.01\n",
      "Epoch [250/20000], Loss: 1745.45654296875, Entropy -85.4852294921875, Learning Rate: 0.01\n",
      "Epoch [251/20000], Loss: 1825.094482421875, Entropy -82.31202697753906, Learning Rate: 0.01\n",
      "Epoch [252/20000], Loss: 1707.803466796875, Entropy -78.16262817382812, Learning Rate: 0.01\n",
      "Epoch [253/20000], Loss: 1665.2196044921875, Entropy -78.4828872680664, Learning Rate: 0.01\n",
      "Epoch [254/20000], Loss: 1760.968994140625, Entropy -82.91902923583984, Learning Rate: 0.01\n",
      "Epoch [255/20000], Loss: 1664.444091796875, Entropy -78.9725112915039, Learning Rate: 0.01\n",
      "Epoch [256/20000], Loss: 1800.4949951171875, Entropy -80.75930786132812, Learning Rate: 0.01\n",
      "Epoch [257/20000], Loss: 1681.3134765625, Entropy -75.0094223022461, Learning Rate: 0.01\n",
      "Epoch [258/20000], Loss: 1701.41943359375, Entropy -83.05880737304688, Learning Rate: 0.01\n",
      "Epoch [259/20000], Loss: 1629.156982421875, Entropy -93.4765625, Learning Rate: 0.01\n",
      "Epoch [260/20000], Loss: 1783.202392578125, Entropy -81.32621765136719, Learning Rate: 0.01\n",
      "Epoch [261/20000], Loss: 1596.8135986328125, Entropy -83.96914672851562, Learning Rate: 0.01\n",
      "Epoch [262/20000], Loss: 1607.587890625, Entropy -69.67265319824219, Learning Rate: 0.01\n",
      "Epoch [263/20000], Loss: 2011.55126953125, Entropy -88.76220703125, Learning Rate: 0.01\n",
      "Epoch [264/20000], Loss: 1829.041748046875, Entropy -87.08140563964844, Learning Rate: 0.01\n",
      "Epoch [265/20000], Loss: 1678.8216552734375, Entropy -91.60243225097656, Learning Rate: 0.01\n",
      "Epoch [266/20000], Loss: 1814.108642578125, Entropy -84.109130859375, Learning Rate: 0.01\n",
      "Epoch [267/20000], Loss: 1730.1998291015625, Entropy -92.08741760253906, Learning Rate: 0.01\n",
      "Epoch [268/20000], Loss: 1670.72265625, Entropy -83.92058563232422, Learning Rate: 0.01\n",
      "Epoch [269/20000], Loss: 1787.87109375, Entropy -87.4837875366211, Learning Rate: 0.01\n",
      "Epoch [270/20000], Loss: 1535.1966552734375, Entropy -88.29523468017578, Learning Rate: 0.01\n",
      "Epoch [271/20000], Loss: 1627.5289306640625, Entropy -94.6816177368164, Learning Rate: 0.01\n",
      "Epoch [272/20000], Loss: 1690.7578125, Entropy -88.2187271118164, Learning Rate: 0.01\n",
      "Epoch [273/20000], Loss: 1659.395263671875, Entropy -75.13776397705078, Learning Rate: 0.01\n",
      "Epoch [274/20000], Loss: 1622.4881591796875, Entropy -83.1481704711914, Learning Rate: 0.01\n",
      "Epoch [275/20000], Loss: 1639.09033203125, Entropy -86.76378631591797, Learning Rate: 0.01\n",
      "Epoch [276/20000], Loss: 1589.4991455078125, Entropy -80.64070892333984, Learning Rate: 0.01\n",
      "Epoch [277/20000], Loss: 1640.729736328125, Entropy -78.99627685546875, Learning Rate: 0.01\n",
      "Epoch [278/20000], Loss: 1638.3963623046875, Entropy -94.63509368896484, Learning Rate: 0.01\n",
      "Epoch [279/20000], Loss: 1528.6658935546875, Entropy -91.96392059326172, Learning Rate: 0.01\n",
      "Epoch [280/20000], Loss: 1770.08349609375, Entropy -82.8472671508789, Learning Rate: 0.01\n",
      "Epoch [281/20000], Loss: 1541.1142578125, Entropy -92.99742889404297, Learning Rate: 0.01\n",
      "Epoch [282/20000], Loss: 1752.73828125, Entropy -79.99105072021484, Learning Rate: 0.01\n",
      "Epoch [283/20000], Loss: 1508.4146728515625, Entropy -81.04387664794922, Learning Rate: 0.01\n",
      "Epoch [284/20000], Loss: 1565.42919921875, Entropy -76.39549255371094, Learning Rate: 0.01\n",
      "Epoch [285/20000], Loss: 1805.157958984375, Entropy -87.97183227539062, Learning Rate: 0.01\n",
      "Epoch [286/20000], Loss: 1539.8101806640625, Entropy -81.4818115234375, Learning Rate: 0.01\n",
      "Epoch [287/20000], Loss: 1577.1416015625, Entropy -84.88118743896484, Learning Rate: 0.01\n",
      "Epoch [288/20000], Loss: 1618.4244384765625, Entropy -76.42438507080078, Learning Rate: 0.01\n",
      "Epoch [289/20000], Loss: 1590.126953125, Entropy -84.33287048339844, Learning Rate: 0.01\n",
      "Epoch [290/20000], Loss: 1594.9775390625, Entropy -91.65567016601562, Learning Rate: 0.01\n",
      "Epoch [291/20000], Loss: 1518.7586669921875, Entropy -91.14644622802734, Learning Rate: 0.01\n",
      "Epoch [292/20000], Loss: 1605.2855224609375, Entropy -74.8691177368164, Learning Rate: 0.01\n",
      "Epoch [293/20000], Loss: 1539.1279296875, Entropy -81.21391296386719, Learning Rate: 0.01\n",
      "Epoch [294/20000], Loss: 1624.800048828125, Entropy -87.2381362915039, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [295/20000], Loss: 1718.86767578125, Entropy -93.0992202758789, Learning Rate: 0.01\n",
      "Epoch [296/20000], Loss: 1545.66845703125, Entropy -72.42769622802734, Learning Rate: 0.01\n",
      "Epoch [297/20000], Loss: 1692.7860107421875, Entropy -80.87246704101562, Learning Rate: 0.01\n",
      "Epoch [298/20000], Loss: 1577.2723388671875, Entropy -95.0589599609375, Learning Rate: 0.01\n",
      "Epoch [299/20000], Loss: 1674.562744140625, Entropy -86.4107437133789, Learning Rate: 0.01\n",
      "Epoch [300/20000], Loss: 1730.0775146484375, Entropy -110.64436340332031, Learning Rate: 0.01\n",
      "Epoch [301/20000], Loss: 1584.787841796875, Entropy -91.37800598144531, Learning Rate: 0.01\n",
      "Epoch [302/20000], Loss: 1624.6239013671875, Entropy -94.42450714111328, Learning Rate: 0.01\n",
      "Epoch [303/20000], Loss: 1768.234130859375, Entropy -88.91099548339844, Learning Rate: 0.01\n",
      "Epoch [304/20000], Loss: 1655.738525390625, Entropy -80.93913269042969, Learning Rate: 0.01\n",
      "Epoch [305/20000], Loss: 1614.9185791015625, Entropy -87.98029327392578, Learning Rate: 0.01\n",
      "Epoch [306/20000], Loss: 1541.9674072265625, Entropy -79.88406372070312, Learning Rate: 0.01\n",
      "Epoch [307/20000], Loss: 1516.7186279296875, Entropy -88.37163543701172, Learning Rate: 0.01\n",
      "Epoch [308/20000], Loss: 1707.65380859375, Entropy -88.01019287109375, Learning Rate: 0.01\n",
      "Epoch [309/20000], Loss: 1772.12646484375, Entropy -94.20242309570312, Learning Rate: 0.01\n",
      "Epoch [310/20000], Loss: 1596.675048828125, Entropy -85.26863098144531, Learning Rate: 0.01\n",
      "Epoch [311/20000], Loss: 1546.7398681640625, Entropy -85.1048583984375, Learning Rate: 0.01\n",
      "Epoch [312/20000], Loss: 2020.32373046875, Entropy -84.39056396484375, Learning Rate: 0.01\n",
      "Epoch [313/20000], Loss: 1520.8931884765625, Entropy -79.88914489746094, Learning Rate: 0.01\n",
      "Epoch [314/20000], Loss: 1589.5931396484375, Entropy -82.31893157958984, Learning Rate: 0.01\n",
      "Epoch [315/20000], Loss: 1645.327392578125, Entropy -87.72586059570312, Learning Rate: 0.01\n",
      "Epoch [316/20000], Loss: 1550.8988037109375, Entropy -92.63597106933594, Learning Rate: 0.01\n",
      "Epoch [317/20000], Loss: 1746.5428466796875, Entropy -80.02224731445312, Learning Rate: 0.01\n",
      "Epoch [318/20000], Loss: 1714.5723876953125, Entropy -98.01296997070312, Learning Rate: 0.01\n",
      "Epoch [319/20000], Loss: 1578.586181640625, Entropy -88.10008239746094, Learning Rate: 0.01\n",
      "Epoch [320/20000], Loss: 1722.41162109375, Entropy -95.19483184814453, Learning Rate: 0.01\n",
      "Epoch [321/20000], Loss: 1582.5980224609375, Entropy -81.38272094726562, Learning Rate: 0.01\n",
      "Epoch [322/20000], Loss: 1671.631591796875, Entropy -86.0213394165039, Learning Rate: 0.01\n",
      "Epoch [323/20000], Loss: 1713.7032470703125, Entropy -90.45630645751953, Learning Rate: 0.01\n",
      "Epoch [324/20000], Loss: 1628.218505859375, Entropy -101.94725036621094, Learning Rate: 0.01\n",
      "Epoch [325/20000], Loss: 1608.2154541015625, Entropy -73.9195556640625, Learning Rate: 0.01\n",
      "Epoch [326/20000], Loss: 1750.7685546875, Entropy -92.71109008789062, Learning Rate: 0.01\n",
      "Epoch [327/20000], Loss: 1667.8458251953125, Entropy -90.92594146728516, Learning Rate: 0.01\n",
      "Epoch [328/20000], Loss: 1779.7958984375, Entropy -96.46308135986328, Learning Rate: 0.01\n",
      "Epoch [329/20000], Loss: 1589.6099853515625, Entropy -72.7933349609375, Learning Rate: 0.01\n",
      "Epoch [330/20000], Loss: 1485.2064208984375, Entropy -80.50885772705078, Learning Rate: 0.01\n",
      "Epoch [331/20000], Loss: 1560.753173828125, Entropy -80.72820281982422, Learning Rate: 0.01\n",
      "Epoch [332/20000], Loss: 1594.0570068359375, Entropy -84.54660034179688, Learning Rate: 0.01\n",
      "Epoch [333/20000], Loss: 1684.1763916015625, Entropy -96.14775085449219, Learning Rate: 0.01\n",
      "Epoch [334/20000], Loss: 1600.6319580078125, Entropy -80.68254089355469, Learning Rate: 0.01\n",
      "Epoch [335/20000], Loss: 1547.6275634765625, Entropy -81.6241455078125, Learning Rate: 0.01\n",
      "Epoch [336/20000], Loss: 1834.7039794921875, Entropy -74.59761810302734, Learning Rate: 0.01\n",
      "Epoch [337/20000], Loss: 1871.6680908203125, Entropy -90.16091918945312, Learning Rate: 0.01\n",
      "Epoch [338/20000], Loss: 1848.4537353515625, Entropy -79.47474670410156, Learning Rate: 0.01\n",
      "Epoch [339/20000], Loss: 1769.39208984375, Entropy -79.33016967773438, Learning Rate: 0.01\n",
      "Epoch [340/20000], Loss: 1598.5592041015625, Entropy -74.06204223632812, Learning Rate: 0.01\n",
      "Epoch [341/20000], Loss: 1578.708740234375, Entropy -86.0282211303711, Learning Rate: 0.01\n",
      "Epoch [342/20000], Loss: 1641.4715576171875, Entropy -94.39435577392578, Learning Rate: 0.01\n",
      "Epoch [343/20000], Loss: 1685.212890625, Entropy -96.04765319824219, Learning Rate: 0.01\n",
      "Epoch [344/20000], Loss: 1566.32861328125, Entropy -79.72271728515625, Learning Rate: 0.01\n",
      "Epoch [345/20000], Loss: 1582.87109375, Entropy -88.70399475097656, Learning Rate: 0.01\n",
      "Epoch [346/20000], Loss: 1628.87548828125, Entropy -80.1551742553711, Learning Rate: 0.01\n",
      "Epoch [347/20000], Loss: 1566.0687255859375, Entropy -74.8715591430664, Learning Rate: 0.01\n",
      "Epoch [348/20000], Loss: 1613.5968017578125, Entropy -86.75460815429688, Learning Rate: 0.01\n",
      "Epoch [349/20000], Loss: 1662.8675537109375, Entropy -84.1694107055664, Learning Rate: 0.01\n",
      "Epoch [350/20000], Loss: 1745.4111328125, Entropy -93.90148162841797, Learning Rate: 0.01\n",
      "Epoch [351/20000], Loss: 1547.1539306640625, Entropy -80.71058654785156, Learning Rate: 0.01\n",
      "Epoch [352/20000], Loss: 1598.857177734375, Entropy -80.04082489013672, Learning Rate: 0.01\n",
      "Epoch [353/20000], Loss: 1526.716064453125, Entropy -70.8734130859375, Learning Rate: 0.01\n",
      "Epoch [354/20000], Loss: 1523.7325439453125, Entropy -84.20880889892578, Learning Rate: 0.01\n",
      "Epoch [355/20000], Loss: 1658.017333984375, Entropy -85.62023162841797, Learning Rate: 0.01\n",
      "Epoch [356/20000], Loss: 1526.602294921875, Entropy -100.01631927490234, Learning Rate: 0.01\n",
      "Epoch [357/20000], Loss: 1617.58203125, Entropy -88.94966888427734, Learning Rate: 0.01\n",
      "Epoch [358/20000], Loss: 1608.23388671875, Entropy -84.44171905517578, Learning Rate: 0.01\n",
      "Epoch [359/20000], Loss: 1558.1866455078125, Entropy -85.79045104980469, Learning Rate: 0.01\n",
      "Epoch [360/20000], Loss: 1669.760009765625, Entropy -75.63948822021484, Learning Rate: 0.01\n",
      "Epoch [361/20000], Loss: 1590.68310546875, Entropy -89.55194091796875, Learning Rate: 0.01\n",
      "Epoch [362/20000], Loss: 1609.599365234375, Entropy -79.74251556396484, Learning Rate: 0.01\n",
      "Epoch [363/20000], Loss: 1567.7784423828125, Entropy -73.01976776123047, Learning Rate: 0.01\n",
      "Epoch [364/20000], Loss: 1505.6632080078125, Entropy -86.54637145996094, Learning Rate: 0.01\n",
      "Epoch [365/20000], Loss: 1645.965087890625, Entropy -85.06258392333984, Learning Rate: 0.01\n",
      "Epoch [366/20000], Loss: 1486.005615234375, Entropy -85.6041488647461, Learning Rate: 0.01\n",
      "Epoch [367/20000], Loss: 1502.765869140625, Entropy -91.5430679321289, Learning Rate: 0.01\n",
      "Epoch [368/20000], Loss: 1525.082275390625, Entropy -88.43915557861328, Learning Rate: 0.01\n",
      "Epoch [369/20000], Loss: 1650.519775390625, Entropy -95.92376708984375, Learning Rate: 0.01\n",
      "Epoch [370/20000], Loss: 1617.1319580078125, Entropy -107.1727523803711, Learning Rate: 0.01\n",
      "Epoch [371/20000], Loss: 1634.0701904296875, Entropy -79.49352264404297, Learning Rate: 0.01\n",
      "Epoch [372/20000], Loss: 1587.52978515625, Entropy -81.11959075927734, Learning Rate: 0.01\n",
      "Epoch [373/20000], Loss: 1526.7740478515625, Entropy -91.19587707519531, Learning Rate: 0.01\n",
      "Epoch [374/20000], Loss: 1582.29345703125, Entropy -87.17185974121094, Learning Rate: 0.01\n",
      "Epoch [375/20000], Loss: 1524.274169921875, Entropy -92.02828979492188, Learning Rate: 0.01\n",
      "Epoch [376/20000], Loss: 1613.0634765625, Entropy -90.28585052490234, Learning Rate: 0.01\n",
      "Epoch [377/20000], Loss: 1445.3092041015625, Entropy -88.0356216430664, Learning Rate: 0.01\n",
      "Epoch [378/20000], Loss: 1498.51220703125, Entropy -80.67388153076172, Learning Rate: 0.01\n",
      "Epoch [379/20000], Loss: 1496.3079833984375, Entropy -101.27085876464844, Learning Rate: 0.01\n",
      "Epoch [380/20000], Loss: 1501.6307373046875, Entropy -86.68584442138672, Learning Rate: 0.01\n",
      "Epoch [381/20000], Loss: 1622.3912353515625, Entropy -83.6640625, Learning Rate: 0.01\n",
      "Epoch [382/20000], Loss: 1516.42919921875, Entropy -87.42056274414062, Learning Rate: 0.01\n",
      "Epoch [383/20000], Loss: 1548.472900390625, Entropy -86.07202911376953, Learning Rate: 0.01\n",
      "Epoch [384/20000], Loss: 1462.1998291015625, Entropy -88.45023345947266, Learning Rate: 0.01\n",
      "Epoch [385/20000], Loss: 1473.775390625, Entropy -81.64983367919922, Learning Rate: 0.01\n",
      "Epoch [386/20000], Loss: 1564.425537109375, Entropy -85.06494903564453, Learning Rate: 0.01\n",
      "Epoch [387/20000], Loss: 1567.726806640625, Entropy -89.3939208984375, Learning Rate: 0.01\n",
      "Epoch [388/20000], Loss: 1575.1153564453125, Entropy -96.3812484741211, Learning Rate: 0.01\n",
      "Epoch [389/20000], Loss: 1541.1695556640625, Entropy -82.61140441894531, Learning Rate: 0.01\n",
      "Epoch [390/20000], Loss: 1449.246337890625, Entropy -89.91746520996094, Learning Rate: 0.01\n",
      "Epoch [391/20000], Loss: 1477.1259765625, Entropy -84.144775390625, Learning Rate: 0.01\n",
      "Epoch [392/20000], Loss: 1508.7115478515625, Entropy -83.78340911865234, Learning Rate: 0.01\n",
      "Epoch [393/20000], Loss: 1476.6993408203125, Entropy -81.03201293945312, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [394/20000], Loss: 1424.8494873046875, Entropy -88.51472473144531, Learning Rate: 0.01\n",
      "Epoch [395/20000], Loss: 1491.1685791015625, Entropy -86.81548309326172, Learning Rate: 0.01\n",
      "Epoch [396/20000], Loss: 1528.71728515625, Entropy -96.43046569824219, Learning Rate: 0.01\n",
      "Epoch [397/20000], Loss: 1535.6580810546875, Entropy -87.14049530029297, Learning Rate: 0.01\n",
      "Epoch [398/20000], Loss: 1538.31787109375, Entropy -89.56903076171875, Learning Rate: 0.01\n",
      "Epoch [399/20000], Loss: 1594.6868896484375, Entropy -101.94501495361328, Learning Rate: 0.01\n",
      "Epoch [400/20000], Loss: 1516.3004150390625, Entropy -97.12109375, Learning Rate: 0.01\n",
      "Epoch [401/20000], Loss: 1512.094482421875, Entropy -71.77357482910156, Learning Rate: 0.01\n",
      "Epoch [402/20000], Loss: 1555.733154296875, Entropy -78.43064880371094, Learning Rate: 0.01\n",
      "Epoch [403/20000], Loss: 1514.1678466796875, Entropy -89.68956756591797, Learning Rate: 0.01\n",
      "Epoch [404/20000], Loss: 1488.8302001953125, Entropy -92.33060455322266, Learning Rate: 0.01\n",
      "Epoch [405/20000], Loss: 1483.40380859375, Entropy -84.5482177734375, Learning Rate: 0.01\n",
      "Epoch [406/20000], Loss: 1552.9979248046875, Entropy -81.28312683105469, Learning Rate: 0.01\n",
      "Epoch [407/20000], Loss: 1529.0811767578125, Entropy -83.60712432861328, Learning Rate: 0.01\n",
      "Epoch [408/20000], Loss: 1529.701416015625, Entropy -81.37432098388672, Learning Rate: 0.01\n",
      "Epoch [409/20000], Loss: 1586.798583984375, Entropy -92.12386322021484, Learning Rate: 0.01\n",
      "Epoch [410/20000], Loss: 1555.056396484375, Entropy -78.20652770996094, Learning Rate: 0.01\n",
      "Epoch [411/20000], Loss: 1604.699462890625, Entropy -87.05766296386719, Learning Rate: 0.01\n",
      "Epoch [412/20000], Loss: 1529.6341552734375, Entropy -81.67138671875, Learning Rate: 0.01\n",
      "Epoch [413/20000], Loss: 1643.1190185546875, Entropy -94.23658752441406, Learning Rate: 0.01\n",
      "Epoch [414/20000], Loss: 1581.1580810546875, Entropy -85.26185607910156, Learning Rate: 0.01\n",
      "Epoch [415/20000], Loss: 1471.34716796875, Entropy -79.77439880371094, Learning Rate: 0.01\n",
      "Epoch [416/20000], Loss: 1524.863037109375, Entropy -87.02360534667969, Learning Rate: 0.01\n",
      "Epoch [417/20000], Loss: 1522.83154296875, Entropy -82.45138549804688, Learning Rate: 0.01\n",
      "Epoch [418/20000], Loss: 1411.4239501953125, Entropy -75.84500885009766, Learning Rate: 0.01\n",
      "Epoch [419/20000], Loss: 1589.5155029296875, Entropy -77.43216705322266, Learning Rate: 0.01\n",
      "Epoch [420/20000], Loss: 1524.2762451171875, Entropy -80.16278839111328, Learning Rate: 0.01\n",
      "Epoch [421/20000], Loss: 1487.522705078125, Entropy -91.47368621826172, Learning Rate: 0.01\n",
      "Epoch [422/20000], Loss: 1593.06396484375, Entropy -91.52086639404297, Learning Rate: 0.01\n",
      "Epoch [423/20000], Loss: 1536.8662109375, Entropy -90.96220397949219, Learning Rate: 0.01\n",
      "Epoch [424/20000], Loss: 1495.330078125, Entropy -79.94009399414062, Learning Rate: 0.01\n",
      "Epoch [425/20000], Loss: 1583.0955810546875, Entropy -72.36115264892578, Learning Rate: 0.01\n",
      "Epoch [426/20000], Loss: 1510.48583984375, Entropy -82.42285919189453, Learning Rate: 0.01\n",
      "Epoch [427/20000], Loss: 1468.0184326171875, Entropy -82.2659912109375, Learning Rate: 0.01\n",
      "Epoch [428/20000], Loss: 1469.16455078125, Entropy -86.0819320678711, Learning Rate: 0.01\n",
      "Epoch [429/20000], Loss: 1475.406982421875, Entropy -68.30858612060547, Learning Rate: 0.01\n",
      "Epoch [430/20000], Loss: 1415.3916015625, Entropy -74.35948181152344, Learning Rate: 0.01\n",
      "Epoch [431/20000], Loss: 1496.135986328125, Entropy -88.5193862915039, Learning Rate: 0.01\n",
      "Epoch [432/20000], Loss: 1502.97119140625, Entropy -92.78076934814453, Learning Rate: 0.01\n",
      "Epoch [433/20000], Loss: 1488.94970703125, Entropy -74.69246673583984, Learning Rate: 0.01\n",
      "Epoch [434/20000], Loss: 1475.557861328125, Entropy -77.08287048339844, Learning Rate: 0.01\n",
      "Epoch [435/20000], Loss: 1767.8511962890625, Entropy -96.7516098022461, Learning Rate: 0.01\n",
      "Epoch [436/20000], Loss: 1593.199462890625, Entropy -78.8875503540039, Learning Rate: 0.01\n",
      "Epoch [437/20000], Loss: 1488.866455078125, Entropy -82.08344268798828, Learning Rate: 0.01\n",
      "Epoch [438/20000], Loss: 1548.102294921875, Entropy -87.45863342285156, Learning Rate: 0.01\n",
      "Epoch [439/20000], Loss: 1388.612060546875, Entropy -79.07750701904297, Learning Rate: 0.01\n",
      "Epoch [440/20000], Loss: 1605.1890869140625, Entropy -84.2256851196289, Learning Rate: 0.01\n",
      "Epoch [441/20000], Loss: 1401.74072265625, Entropy -91.00638580322266, Learning Rate: 0.01\n",
      "Epoch [442/20000], Loss: 1550.0469970703125, Entropy -65.59941101074219, Learning Rate: 0.01\n",
      "Epoch [443/20000], Loss: 1475.55029296875, Entropy -90.80806732177734, Learning Rate: 0.01\n",
      "Epoch [444/20000], Loss: 1407.27294921875, Entropy -90.3023452758789, Learning Rate: 0.01\n",
      "Epoch [445/20000], Loss: 1464.91259765625, Entropy -94.408935546875, Learning Rate: 0.01\n",
      "Epoch [446/20000], Loss: 1469.6121826171875, Entropy -88.58363342285156, Learning Rate: 0.01\n",
      "Epoch [447/20000], Loss: 1648.9869384765625, Entropy -98.53883361816406, Learning Rate: 0.01\n",
      "Epoch [448/20000], Loss: 1464.087890625, Entropy -99.44249725341797, Learning Rate: 0.01\n",
      "Epoch [449/20000], Loss: 1384.0894775390625, Entropy -73.6149673461914, Learning Rate: 0.01\n",
      "Epoch [450/20000], Loss: 1490.6485595703125, Entropy -81.3851089477539, Learning Rate: 0.01\n",
      "Epoch [451/20000], Loss: 1531.5489501953125, Entropy -87.19576263427734, Learning Rate: 0.01\n",
      "Epoch [452/20000], Loss: 1571.2384033203125, Entropy -80.26564025878906, Learning Rate: 0.01\n",
      "Epoch [453/20000], Loss: 1373.908203125, Entropy -90.9417953491211, Learning Rate: 0.01\n",
      "Epoch [454/20000], Loss: 1566.491455078125, Entropy -79.41259765625, Learning Rate: 0.01\n",
      "Epoch [455/20000], Loss: 1376.6868896484375, Entropy -83.93550872802734, Learning Rate: 0.01\n",
      "Epoch [456/20000], Loss: 1456.981201171875, Entropy -87.97671508789062, Learning Rate: 0.01\n",
      "Epoch [457/20000], Loss: 1494.8953857421875, Entropy -108.59410858154297, Learning Rate: 0.01\n",
      "Epoch [458/20000], Loss: 1404.08447265625, Entropy -83.7887954711914, Learning Rate: 0.01\n",
      "Epoch [459/20000], Loss: 1398.7430419921875, Entropy -77.12459564208984, Learning Rate: 0.01\n",
      "Epoch [460/20000], Loss: 1596.3927001953125, Entropy -88.50364685058594, Learning Rate: 0.01\n",
      "Epoch [461/20000], Loss: 1421.63134765625, Entropy -74.64794158935547, Learning Rate: 0.01\n",
      "Epoch [462/20000], Loss: 1435.3515625, Entropy -76.51998901367188, Learning Rate: 0.01\n",
      "Epoch [463/20000], Loss: 1442.2998046875, Entropy -74.62771606445312, Learning Rate: 0.01\n",
      "Epoch [464/20000], Loss: 1470.89453125, Entropy -72.25770568847656, Learning Rate: 0.01\n",
      "Epoch [465/20000], Loss: 1497.1448974609375, Entropy -71.48908996582031, Learning Rate: 0.01\n",
      "Epoch [466/20000], Loss: 1526.26025390625, Entropy -92.09430694580078, Learning Rate: 0.01\n",
      "Epoch [467/20000], Loss: 1466.093994140625, Entropy -85.3232421875, Learning Rate: 0.01\n",
      "Epoch [468/20000], Loss: 1508.2547607421875, Entropy -103.08950805664062, Learning Rate: 0.01\n",
      "Epoch [469/20000], Loss: 1449.854736328125, Entropy -86.94218444824219, Learning Rate: 0.01\n",
      "Epoch [470/20000], Loss: 1405.7064208984375, Entropy -81.09050750732422, Learning Rate: 0.01\n",
      "Epoch [471/20000], Loss: 1404.9049072265625, Entropy -89.132568359375, Learning Rate: 0.01\n",
      "Epoch [472/20000], Loss: 1409.9527587890625, Entropy -98.45771026611328, Learning Rate: 0.01\n",
      "Epoch [473/20000], Loss: 1554.482666015625, Entropy -84.47439575195312, Learning Rate: 0.01\n",
      "Epoch [474/20000], Loss: 1440.8214111328125, Entropy -76.19002532958984, Learning Rate: 0.01\n",
      "Epoch [475/20000], Loss: 1483.5445556640625, Entropy -86.85903930664062, Learning Rate: 0.01\n",
      "Epoch [476/20000], Loss: 1525.9688720703125, Entropy -98.97706604003906, Learning Rate: 0.01\n",
      "Epoch [477/20000], Loss: 1462.4072265625, Entropy -88.12162017822266, Learning Rate: 0.01\n",
      "Epoch [478/20000], Loss: 1494.0592041015625, Entropy -75.5313720703125, Learning Rate: 0.01\n",
      "Epoch [479/20000], Loss: 1477.2252197265625, Entropy -76.37120819091797, Learning Rate: 0.01\n",
      "Epoch [480/20000], Loss: 1492.77099609375, Entropy -76.4103775024414, Learning Rate: 0.01\n",
      "Epoch [481/20000], Loss: 1447.337158203125, Entropy -71.33712768554688, Learning Rate: 0.01\n",
      "Epoch [482/20000], Loss: 1450.591796875, Entropy -83.34808349609375, Learning Rate: 0.01\n",
      "Epoch [483/20000], Loss: 1405.7457275390625, Entropy -100.99459075927734, Learning Rate: 0.01\n",
      "Epoch [484/20000], Loss: 1491.0015869140625, Entropy -78.8145980834961, Learning Rate: 0.01\n",
      "Epoch [485/20000], Loss: 1399.59765625, Entropy -81.36040496826172, Learning Rate: 0.01\n",
      "Epoch [486/20000], Loss: 1392.1290283203125, Entropy -77.0009536743164, Learning Rate: 0.01\n",
      "Epoch [487/20000], Loss: 1399.46044921875, Entropy -78.51068878173828, Learning Rate: 0.01\n",
      "Epoch [488/20000], Loss: 1486.78955078125, Entropy -83.96244812011719, Learning Rate: 0.01\n",
      "Epoch [489/20000], Loss: 1405.7158203125, Entropy -87.46013641357422, Learning Rate: 0.01\n",
      "Epoch [490/20000], Loss: 1406.4688720703125, Entropy -81.09446716308594, Learning Rate: 0.01\n",
      "Epoch [491/20000], Loss: 1447.15185546875, Entropy -90.19185638427734, Learning Rate: 0.01\n",
      "Epoch [492/20000], Loss: 1419.6734619140625, Entropy -91.68017578125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [493/20000], Loss: 1393.06640625, Entropy -93.30447387695312, Learning Rate: 0.01\n",
      "Epoch [494/20000], Loss: 1411.2916259765625, Entropy -89.21968841552734, Learning Rate: 0.01\n",
      "Epoch [495/20000], Loss: 1342.604736328125, Entropy -76.37319946289062, Learning Rate: 0.01\n",
      "Epoch [496/20000], Loss: 1466.832275390625, Entropy -96.48213958740234, Learning Rate: 0.01\n",
      "Epoch [497/20000], Loss: 1374.6373291015625, Entropy -72.22637176513672, Learning Rate: 0.01\n",
      "Epoch [498/20000], Loss: 1410.5164794921875, Entropy -92.36775970458984, Learning Rate: 0.01\n",
      "Epoch [499/20000], Loss: 1388.0340576171875, Entropy -85.48954010009766, Learning Rate: 0.01\n",
      "Epoch [500/20000], Loss: 1406.99267578125, Entropy -80.09550476074219, Learning Rate: 0.01\n",
      "Epoch [501/20000], Loss: 1335.4056396484375, Entropy -72.7743148803711, Learning Rate: 0.01\n",
      "Epoch [502/20000], Loss: 1517.300537109375, Entropy -102.14759826660156, Learning Rate: 0.01\n",
      "Epoch [503/20000], Loss: 1411.7630615234375, Entropy -89.9994125366211, Learning Rate: 0.01\n",
      "Epoch [504/20000], Loss: 1376.755126953125, Entropy -82.4848403930664, Learning Rate: 0.01\n",
      "Epoch [505/20000], Loss: 1399.9932861328125, Entropy -71.4120864868164, Learning Rate: 0.01\n",
      "Epoch [506/20000], Loss: 1401.64697265625, Entropy -76.16983795166016, Learning Rate: 0.01\n",
      "Epoch [507/20000], Loss: 1441.378662109375, Entropy -88.03872680664062, Learning Rate: 0.01\n",
      "Epoch [508/20000], Loss: 1436.7783203125, Entropy -91.4027099609375, Learning Rate: 0.01\n",
      "Epoch [509/20000], Loss: 1392.6995849609375, Entropy -87.59430694580078, Learning Rate: 0.01\n",
      "Epoch [510/20000], Loss: 1374.0743408203125, Entropy -81.95059204101562, Learning Rate: 0.01\n",
      "Epoch [511/20000], Loss: 1354.3726806640625, Entropy -78.10662078857422, Learning Rate: 0.01\n",
      "Epoch [512/20000], Loss: 1439.85400390625, Entropy -82.0860366821289, Learning Rate: 0.01\n",
      "Epoch [513/20000], Loss: 1635.302001953125, Entropy -90.23622131347656, Learning Rate: 0.01\n",
      "Epoch [514/20000], Loss: 1646.155517578125, Entropy -82.64214324951172, Learning Rate: 0.01\n",
      "Epoch [515/20000], Loss: 1480.7333984375, Entropy -82.39275360107422, Learning Rate: 0.01\n",
      "Epoch [516/20000], Loss: 1390.4984130859375, Entropy -89.67766571044922, Learning Rate: 0.01\n",
      "Epoch [517/20000], Loss: 1598.98974609375, Entropy -86.8814468383789, Learning Rate: 0.01\n",
      "Epoch [518/20000], Loss: 1496.3284912109375, Entropy -88.13919830322266, Learning Rate: 0.01\n",
      "Epoch [519/20000], Loss: 1439.59130859375, Entropy -91.07667541503906, Learning Rate: 0.01\n",
      "Epoch [520/20000], Loss: 1338.7896728515625, Entropy -71.33257293701172, Learning Rate: 0.01\n",
      "Epoch [521/20000], Loss: 1405.37744140625, Entropy -80.7960205078125, Learning Rate: 0.01\n",
      "Epoch [522/20000], Loss: 1440.4593505859375, Entropy -81.49760437011719, Learning Rate: 0.01\n",
      "Epoch [523/20000], Loss: 1446.754150390625, Entropy -88.98995971679688, Learning Rate: 0.01\n",
      "Epoch [524/20000], Loss: 1385.6435546875, Entropy -79.09419250488281, Learning Rate: 0.01\n",
      "Epoch [525/20000], Loss: 1462.610595703125, Entropy -82.03312683105469, Learning Rate: 0.01\n",
      "Epoch [526/20000], Loss: 1459.736328125, Entropy -79.30355072021484, Learning Rate: 0.01\n",
      "Epoch [527/20000], Loss: 1523.240478515625, Entropy -86.4715347290039, Learning Rate: 0.01\n",
      "Epoch [528/20000], Loss: 1434.4090576171875, Entropy -79.34957122802734, Learning Rate: 0.01\n",
      "Epoch [529/20000], Loss: 1393.8466796875, Entropy -87.73726654052734, Learning Rate: 0.01\n",
      "Epoch [530/20000], Loss: 1386.487548828125, Entropy -87.73965454101562, Learning Rate: 0.01\n",
      "Epoch [531/20000], Loss: 1504.932373046875, Entropy -71.3438720703125, Learning Rate: 0.01\n",
      "Epoch [532/20000], Loss: 1366.437744140625, Entropy -95.65821075439453, Learning Rate: 0.01\n",
      "Epoch [533/20000], Loss: 1347.344970703125, Entropy -75.10160064697266, Learning Rate: 0.01\n",
      "Epoch [534/20000], Loss: 1458.2952880859375, Entropy -76.13605499267578, Learning Rate: 0.01\n",
      "Epoch [535/20000], Loss: 1400.6632080078125, Entropy -73.69396209716797, Learning Rate: 0.01\n",
      "Epoch [536/20000], Loss: 1375.2235107421875, Entropy -74.36653900146484, Learning Rate: 0.01\n",
      "Epoch [537/20000], Loss: 1400.386962890625, Entropy -84.47846221923828, Learning Rate: 0.01\n",
      "Epoch [538/20000], Loss: 1553.77734375, Entropy -93.31128692626953, Learning Rate: 0.01\n",
      "Epoch [539/20000], Loss: 1448.02392578125, Entropy -79.3882064819336, Learning Rate: 0.01\n",
      "Epoch [540/20000], Loss: 1347.69580078125, Entropy -81.65589904785156, Learning Rate: 0.01\n",
      "Epoch [541/20000], Loss: 1439.9703369140625, Entropy -77.0428466796875, Learning Rate: 0.01\n",
      "Epoch [542/20000], Loss: 1376.744140625, Entropy -78.73236083984375, Learning Rate: 0.01\n",
      "Epoch [543/20000], Loss: 1386.6767578125, Entropy -70.1402587890625, Learning Rate: 0.01\n",
      "Epoch [544/20000], Loss: 1372.199462890625, Entropy -69.75736236572266, Learning Rate: 0.01\n",
      "Epoch [545/20000], Loss: 1406.001220703125, Entropy -77.95814514160156, Learning Rate: 0.01\n",
      "Epoch [546/20000], Loss: 1508.974609375, Entropy -75.08062744140625, Learning Rate: 0.01\n",
      "Epoch [547/20000], Loss: 1431.045654296875, Entropy -95.93777465820312, Learning Rate: 0.01\n",
      "Epoch [548/20000], Loss: 1309.9578857421875, Entropy -68.82892608642578, Learning Rate: 0.01\n",
      "Epoch [549/20000], Loss: 1376.3125, Entropy -84.20700073242188, Learning Rate: 0.01\n",
      "Epoch [550/20000], Loss: 1395.65673828125, Entropy -85.33302307128906, Learning Rate: 0.01\n",
      "Epoch [551/20000], Loss: 1397.2152099609375, Entropy -80.0655746459961, Learning Rate: 0.01\n",
      "Epoch [552/20000], Loss: 1387.8814697265625, Entropy -93.16923522949219, Learning Rate: 0.01\n",
      "Epoch [553/20000], Loss: 1389.5, Entropy -84.02315521240234, Learning Rate: 0.01\n",
      "Epoch [554/20000], Loss: 1323.46923828125, Entropy -55.59833908081055, Learning Rate: 0.01\n",
      "Epoch [555/20000], Loss: 1318.4564208984375, Entropy -85.05570220947266, Learning Rate: 0.01\n",
      "Epoch [556/20000], Loss: 1386.5882568359375, Entropy -81.11811828613281, Learning Rate: 0.01\n",
      "Epoch [557/20000], Loss: 1491.235107421875, Entropy -87.26782989501953, Learning Rate: 0.01\n",
      "Epoch [558/20000], Loss: 1422.576416015625, Entropy -98.60990905761719, Learning Rate: 0.01\n",
      "Epoch [559/20000], Loss: 1365.918701171875, Entropy -79.38323974609375, Learning Rate: 0.01\n",
      "Epoch [560/20000], Loss: 1395.8427734375, Entropy -71.08314514160156, Learning Rate: 0.01\n",
      "Epoch [561/20000], Loss: 1363.2078857421875, Entropy -79.78353881835938, Learning Rate: 0.01\n",
      "Epoch [562/20000], Loss: 1421.214599609375, Entropy -89.21561431884766, Learning Rate: 0.01\n",
      "Epoch [563/20000], Loss: 1408.360595703125, Entropy -85.02737426757812, Learning Rate: 0.01\n",
      "Epoch [564/20000], Loss: 1429.15771484375, Entropy -75.8511962890625, Learning Rate: 0.01\n",
      "Epoch [565/20000], Loss: 1326.449951171875, Entropy -80.51870727539062, Learning Rate: 0.01\n",
      "Epoch [566/20000], Loss: 1423.949951171875, Entropy -73.18366241455078, Learning Rate: 0.01\n",
      "Epoch [567/20000], Loss: 1490.702392578125, Entropy -78.6522216796875, Learning Rate: 0.01\n",
      "Epoch [568/20000], Loss: 1339.9937744140625, Entropy -76.93335723876953, Learning Rate: 0.01\n",
      "Epoch [569/20000], Loss: 1383.760986328125, Entropy -65.65982055664062, Learning Rate: 0.01\n",
      "Epoch [570/20000], Loss: 1355.93115234375, Entropy -74.61894226074219, Learning Rate: 0.01\n",
      "Epoch [571/20000], Loss: 1383.72607421875, Entropy -82.44001007080078, Learning Rate: 0.01\n",
      "Epoch [572/20000], Loss: 1374.195556640625, Entropy -73.4726333618164, Learning Rate: 0.01\n",
      "Epoch [573/20000], Loss: 1349.3812255859375, Entropy -66.60193634033203, Learning Rate: 0.01\n",
      "Epoch [574/20000], Loss: 1318.860595703125, Entropy -68.5112075805664, Learning Rate: 0.01\n",
      "Epoch [575/20000], Loss: 1417.4998779296875, Entropy -84.23486328125, Learning Rate: 0.01\n",
      "Epoch [576/20000], Loss: 1311.8211669921875, Entropy -80.98033905029297, Learning Rate: 0.01\n",
      "Epoch [577/20000], Loss: 1370.9705810546875, Entropy -63.92294692993164, Learning Rate: 0.01\n",
      "Epoch [578/20000], Loss: 1335.48583984375, Entropy -60.76034164428711, Learning Rate: 0.01\n",
      "Epoch [579/20000], Loss: 1423.2921142578125, Entropy -89.43603515625, Learning Rate: 0.01\n",
      "Epoch [580/20000], Loss: 1370.330322265625, Entropy -70.43573760986328, Learning Rate: 0.01\n",
      "Epoch [581/20000], Loss: 1388.8597412109375, Entropy -79.24394226074219, Learning Rate: 0.01\n",
      "Epoch [582/20000], Loss: 1386.2701416015625, Entropy -69.6881103515625, Learning Rate: 0.01\n",
      "Epoch [583/20000], Loss: 1377.2344970703125, Entropy -68.94625091552734, Learning Rate: 0.01\n",
      "Epoch [584/20000], Loss: 1514.1939697265625, Entropy -73.74712371826172, Learning Rate: 0.01\n",
      "Epoch [585/20000], Loss: 1386.4530029296875, Entropy -77.50733184814453, Learning Rate: 0.01\n",
      "Epoch [586/20000], Loss: 1371.8365478515625, Entropy -80.12358093261719, Learning Rate: 0.01\n",
      "Epoch [587/20000], Loss: 1314.670166015625, Entropy -64.47171020507812, Learning Rate: 0.01\n",
      "Epoch [588/20000], Loss: 1405.5509033203125, Entropy -72.4934310913086, Learning Rate: 0.01\n",
      "Epoch [589/20000], Loss: 1373.9091796875, Entropy -63.3001823425293, Learning Rate: 0.01\n",
      "Epoch [590/20000], Loss: 1359.0982666015625, Entropy -69.33522033691406, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [591/20000], Loss: 1390.339599609375, Entropy -74.99195861816406, Learning Rate: 0.01\n",
      "Epoch [592/20000], Loss: 1352.342041015625, Entropy -65.25737762451172, Learning Rate: 0.01\n",
      "Epoch [593/20000], Loss: 1379.1834716796875, Entropy -63.25540542602539, Learning Rate: 0.01\n",
      "Epoch [594/20000], Loss: 1359.0523681640625, Entropy -68.0275650024414, Learning Rate: 0.01\n",
      "Epoch [595/20000], Loss: 1453.2158203125, Entropy -83.05775451660156, Learning Rate: 0.01\n",
      "Epoch [596/20000], Loss: 1399.2159423828125, Entropy -96.61528778076172, Learning Rate: 0.01\n",
      "Epoch [597/20000], Loss: 1296.0364990234375, Entropy -67.5766372680664, Learning Rate: 0.01\n",
      "Epoch [598/20000], Loss: 1330.734619140625, Entropy -86.61073303222656, Learning Rate: 0.01\n",
      "Epoch [599/20000], Loss: 1393.7266845703125, Entropy -90.6708755493164, Learning Rate: 0.01\n",
      "Epoch [600/20000], Loss: 1408.5433349609375, Entropy -66.5844497680664, Learning Rate: 0.01\n",
      "Epoch [601/20000], Loss: 1371.947021484375, Entropy -76.9684829711914, Learning Rate: 0.01\n",
      "Epoch [602/20000], Loss: 1336.7860107421875, Entropy -66.81722259521484, Learning Rate: 0.01\n",
      "Epoch [603/20000], Loss: 1364.704345703125, Entropy -76.06959533691406, Learning Rate: 0.01\n",
      "Epoch [604/20000], Loss: 1335.992919921875, Entropy -63.31797790527344, Learning Rate: 0.01\n",
      "Epoch [605/20000], Loss: 1363.85546875, Entropy -68.33397674560547, Learning Rate: 0.01\n",
      "Epoch [606/20000], Loss: 1354.940673828125, Entropy -53.43983840942383, Learning Rate: 0.01\n",
      "Epoch [607/20000], Loss: 1379.406494140625, Entropy -65.1193618774414, Learning Rate: 0.01\n",
      "Epoch [608/20000], Loss: 1337.0123291015625, Entropy -65.53133392333984, Learning Rate: 0.01\n",
      "Epoch [609/20000], Loss: 1387.70849609375, Entropy -66.61907196044922, Learning Rate: 0.01\n",
      "Epoch [610/20000], Loss: 1360.4586181640625, Entropy -69.19352722167969, Learning Rate: 0.01\n",
      "Epoch [611/20000], Loss: 1297.4613037109375, Entropy -69.617431640625, Learning Rate: 0.01\n",
      "Epoch [612/20000], Loss: 1382.3729248046875, Entropy -78.80135345458984, Learning Rate: 0.01\n",
      "Epoch [613/20000], Loss: 1383.533203125, Entropy -73.35282897949219, Learning Rate: 0.01\n",
      "Epoch [614/20000], Loss: 1307.5965576171875, Entropy -66.8134536743164, Learning Rate: 0.01\n",
      "Epoch [615/20000], Loss: 1384.3438720703125, Entropy -79.45587921142578, Learning Rate: 0.01\n",
      "Epoch [616/20000], Loss: 1341.943603515625, Entropy -76.76223754882812, Learning Rate: 0.01\n",
      "Epoch [617/20000], Loss: 1336.88623046875, Entropy -64.21994018554688, Learning Rate: 0.01\n",
      "Epoch [618/20000], Loss: 1392.495361328125, Entropy -67.18380737304688, Learning Rate: 0.01\n",
      "Epoch [619/20000], Loss: 1337.982666015625, Entropy -69.99298858642578, Learning Rate: 0.01\n",
      "Epoch [620/20000], Loss: 1334.258544921875, Entropy -82.77141571044922, Learning Rate: 0.01\n",
      "Epoch [621/20000], Loss: 1364.3353271484375, Entropy -86.07593536376953, Learning Rate: 0.01\n",
      "Epoch [622/20000], Loss: 1413.837646484375, Entropy -65.47801971435547, Learning Rate: 0.01\n",
      "Epoch [623/20000], Loss: 1334.1929931640625, Entropy -74.33194732666016, Learning Rate: 0.01\n",
      "Epoch [624/20000], Loss: 1395.1014404296875, Entropy -71.1637191772461, Learning Rate: 0.01\n",
      "Epoch [625/20000], Loss: 1393.963623046875, Entropy -78.45055389404297, Learning Rate: 0.01\n",
      "Epoch [626/20000], Loss: 1390.05322265625, Entropy -74.33418273925781, Learning Rate: 0.01\n",
      "Epoch [627/20000], Loss: 1396.55322265625, Entropy -68.14797973632812, Learning Rate: 0.01\n",
      "Epoch [628/20000], Loss: 1460.4510498046875, Entropy -78.71013641357422, Learning Rate: 0.01\n",
      "Epoch [629/20000], Loss: 1410.7652587890625, Entropy -80.51807403564453, Learning Rate: 0.01\n",
      "Epoch [630/20000], Loss: 1433.792724609375, Entropy -76.9693832397461, Learning Rate: 0.01\n",
      "Epoch [631/20000], Loss: 1362.8360595703125, Entropy -57.19493865966797, Learning Rate: 0.01\n",
      "Epoch [632/20000], Loss: 1347.762451171875, Entropy -58.20093536376953, Learning Rate: 0.01\n",
      "Epoch [633/20000], Loss: 1371.3138427734375, Entropy -71.12348175048828, Learning Rate: 0.01\n",
      "Epoch [634/20000], Loss: 1358.49267578125, Entropy -79.71623229980469, Learning Rate: 0.01\n",
      "Epoch [635/20000], Loss: 1334.2459716796875, Entropy -71.44515228271484, Learning Rate: 0.01\n",
      "Epoch [636/20000], Loss: 1371.564697265625, Entropy -72.23855590820312, Learning Rate: 0.01\n",
      "Epoch [637/20000], Loss: 1326.582275390625, Entropy -72.34368896484375, Learning Rate: 0.01\n",
      "Epoch [638/20000], Loss: 1328.3704833984375, Entropy -76.48377990722656, Learning Rate: 0.01\n",
      "Epoch [639/20000], Loss: 1381.6446533203125, Entropy -65.74819946289062, Learning Rate: 0.01\n",
      "Epoch [640/20000], Loss: 1429.908935546875, Entropy -55.23247528076172, Learning Rate: 0.01\n",
      "Epoch [641/20000], Loss: 1375.624267578125, Entropy -74.87579345703125, Learning Rate: 0.01\n",
      "Epoch [642/20000], Loss: 1373.6494140625, Entropy -82.91484832763672, Learning Rate: 0.01\n",
      "Epoch [643/20000], Loss: 1475.3995361328125, Entropy -61.47998809814453, Learning Rate: 0.01\n",
      "Epoch [644/20000], Loss: 1372.4759521484375, Entropy -69.74899291992188, Learning Rate: 0.01\n",
      "Epoch [645/20000], Loss: 1392.753662109375, Entropy -79.32881927490234, Learning Rate: 0.01\n",
      "Epoch [646/20000], Loss: 1369.359130859375, Entropy -60.83839797973633, Learning Rate: 0.01\n",
      "Epoch [647/20000], Loss: 1348.0899658203125, Entropy -66.03278350830078, Learning Rate: 0.01\n",
      "Epoch [648/20000], Loss: 1323.0697021484375, Entropy -69.26116180419922, Learning Rate: 0.01\n",
      "Epoch [649/20000], Loss: 1374.9195556640625, Entropy -74.6714859008789, Learning Rate: 0.01\n",
      "Epoch [650/20000], Loss: 1297.1943359375, Entropy -67.36006927490234, Learning Rate: 0.01\n",
      "Epoch [651/20000], Loss: 1351.8917236328125, Entropy -70.03909301757812, Learning Rate: 0.01\n",
      "Epoch [652/20000], Loss: 1385.3853759765625, Entropy -74.77873229980469, Learning Rate: 0.01\n",
      "Epoch [653/20000], Loss: 1309.90234375, Entropy -67.46917724609375, Learning Rate: 0.01\n",
      "Epoch [654/20000], Loss: 1336.154296875, Entropy -62.216854095458984, Learning Rate: 0.01\n",
      "Epoch [655/20000], Loss: 1336.291748046875, Entropy -66.097900390625, Learning Rate: 0.01\n",
      "Epoch [656/20000], Loss: 1332.2127685546875, Entropy -69.74613952636719, Learning Rate: 0.01\n",
      "Epoch [657/20000], Loss: 1406.47412109375, Entropy -71.53924560546875, Learning Rate: 0.01\n",
      "Epoch [658/20000], Loss: 1330.729736328125, Entropy -63.32998275756836, Learning Rate: 0.01\n",
      "Epoch [659/20000], Loss: 1447.13623046875, Entropy -71.86759948730469, Learning Rate: 0.01\n",
      "Epoch [660/20000], Loss: 1489.1407470703125, Entropy -79.46480560302734, Learning Rate: 0.01\n",
      "Epoch [661/20000], Loss: 1303.3287353515625, Entropy -64.59037017822266, Learning Rate: 0.01\n",
      "Epoch [662/20000], Loss: 1296.4410400390625, Entropy -64.1966323852539, Learning Rate: 0.01\n",
      "Epoch [663/20000], Loss: 1307.9814453125, Entropy -64.51530456542969, Learning Rate: 0.01\n",
      "Epoch [664/20000], Loss: 1337.2386474609375, Entropy -66.28162384033203, Learning Rate: 0.01\n",
      "Epoch [665/20000], Loss: 1360.73486328125, Entropy -64.9256591796875, Learning Rate: 0.01\n",
      "Epoch [666/20000], Loss: 1273.895751953125, Entropy -58.98511505126953, Learning Rate: 0.01\n",
      "Epoch [667/20000], Loss: 1404.7838134765625, Entropy -69.26374053955078, Learning Rate: 0.01\n",
      "Epoch [668/20000], Loss: 1379.952392578125, Entropy -63.34555435180664, Learning Rate: 0.01\n",
      "Epoch [669/20000], Loss: 1296.4990234375, Entropy -58.3475456237793, Learning Rate: 0.01\n",
      "Epoch [670/20000], Loss: 1424.143798828125, Entropy -59.118778228759766, Learning Rate: 0.01\n",
      "Epoch [671/20000], Loss: 1347.78271484375, Entropy -76.1765365600586, Learning Rate: 0.01\n",
      "Epoch [672/20000], Loss: 1316.9613037109375, Entropy -72.37201690673828, Learning Rate: 0.01\n",
      "Epoch [673/20000], Loss: 1339.4722900390625, Entropy -57.024295806884766, Learning Rate: 0.01\n",
      "Epoch [674/20000], Loss: 1331.5238037109375, Entropy -60.91408920288086, Learning Rate: 0.01\n",
      "Epoch [675/20000], Loss: 1479.8094482421875, Entropy -78.34228515625, Learning Rate: 0.01\n",
      "Epoch [676/20000], Loss: 1393.968017578125, Entropy -66.81828308105469, Learning Rate: 0.01\n",
      "Epoch [677/20000], Loss: 1382.42529296875, Entropy -73.42449188232422, Learning Rate: 0.01\n",
      "Epoch [678/20000], Loss: 1391.853515625, Entropy -73.31829071044922, Learning Rate: 0.01\n",
      "Epoch [679/20000], Loss: 1359.787841796875, Entropy -70.88849639892578, Learning Rate: 0.01\n",
      "Epoch [680/20000], Loss: 1334.48291015625, Entropy -66.00112915039062, Learning Rate: 0.01\n",
      "Epoch [681/20000], Loss: 1395.4158935546875, Entropy -73.75406646728516, Learning Rate: 0.01\n",
      "Epoch [682/20000], Loss: 1468.1385498046875, Entropy -68.2667236328125, Learning Rate: 0.01\n",
      "Epoch [683/20000], Loss: 1329.1142578125, Entropy -56.110931396484375, Learning Rate: 0.01\n",
      "Epoch [684/20000], Loss: 1338.4586181640625, Entropy -72.20331573486328, Learning Rate: 0.01\n",
      "Epoch [685/20000], Loss: 1384.2633056640625, Entropy -55.4055061340332, Learning Rate: 0.01\n",
      "Epoch [686/20000], Loss: 1308.9742431640625, Entropy -63.33881759643555, Learning Rate: 0.01\n",
      "Epoch [687/20000], Loss: 1454.017333984375, Entropy -73.52623748779297, Learning Rate: 0.01\n",
      "Epoch [688/20000], Loss: 1385.079345703125, Entropy -73.80525970458984, Learning Rate: 0.01\n",
      "Epoch [689/20000], Loss: 1408.64404296875, Entropy -80.95537567138672, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [690/20000], Loss: 1376.4716796875, Entropy -58.50550079345703, Learning Rate: 0.01\n",
      "Epoch [691/20000], Loss: 1360.3348388671875, Entropy -66.39859771728516, Learning Rate: 0.01\n",
      "Epoch [692/20000], Loss: 1461.57421875, Entropy -53.76361083984375, Learning Rate: 0.01\n",
      "Epoch [693/20000], Loss: 1305.87548828125, Entropy -67.36639404296875, Learning Rate: 0.01\n",
      "Epoch [694/20000], Loss: 1447.0262451171875, Entropy -82.15894317626953, Learning Rate: 0.01\n",
      "Epoch [695/20000], Loss: 1498.826416015625, Entropy -61.64895248413086, Learning Rate: 0.01\n",
      "Epoch [696/20000], Loss: 1321.406982421875, Entropy -51.30025100708008, Learning Rate: 0.01\n",
      "Epoch [697/20000], Loss: 1591.92626953125, Entropy -58.57222366333008, Learning Rate: 0.01\n",
      "Epoch [698/20000], Loss: 1429.354248046875, Entropy -65.20136260986328, Learning Rate: 0.01\n",
      "Epoch [699/20000], Loss: 1689.991943359375, Entropy -59.558074951171875, Learning Rate: 0.01\n",
      "Epoch [700/20000], Loss: 1353.3077392578125, Entropy -70.52838897705078, Learning Rate: 0.01\n",
      "Epoch [701/20000], Loss: 1409.024658203125, Entropy -55.11339569091797, Learning Rate: 0.01\n",
      "Epoch [702/20000], Loss: 1484.4241943359375, Entropy -68.47547912597656, Learning Rate: 0.01\n",
      "Epoch [703/20000], Loss: 1359.3623046875, Entropy -71.98165893554688, Learning Rate: 0.01\n",
      "Epoch [704/20000], Loss: 1518.5296630859375, Entropy -70.3342056274414, Learning Rate: 0.01\n",
      "Epoch [705/20000], Loss: 1374.5977783203125, Entropy -54.39687728881836, Learning Rate: 0.01\n",
      "Epoch [706/20000], Loss: 1396.3099365234375, Entropy -58.47029113769531, Learning Rate: 0.01\n",
      "Epoch [707/20000], Loss: 1452.73828125, Entropy -67.36270141601562, Learning Rate: 0.01\n",
      "Epoch [708/20000], Loss: 1363.5615234375, Entropy -62.13637924194336, Learning Rate: 0.01\n",
      "Epoch [709/20000], Loss: 1398.0133056640625, Entropy -63.63925552368164, Learning Rate: 0.01\n",
      "Epoch [710/20000], Loss: 1412.6121826171875, Entropy -67.07347869873047, Learning Rate: 0.01\n",
      "Epoch [711/20000], Loss: 1418.282958984375, Entropy -70.72769165039062, Learning Rate: 0.01\n",
      "Epoch [712/20000], Loss: 1467.343505859375, Entropy -65.61539459228516, Learning Rate: 0.01\n",
      "Epoch [713/20000], Loss: 1314.1787109375, Entropy -61.53892517089844, Learning Rate: 0.01\n",
      "Epoch [714/20000], Loss: 1457.302734375, Entropy -71.3746337890625, Learning Rate: 0.01\n",
      "Epoch [715/20000], Loss: 1384.7000732421875, Entropy -66.77535247802734, Learning Rate: 0.01\n",
      "Epoch [716/20000], Loss: 1384.6346435546875, Entropy -71.35257720947266, Learning Rate: 0.01\n",
      "Epoch [717/20000], Loss: 1410.5301513671875, Entropy -61.38765335083008, Learning Rate: 0.01\n",
      "Epoch [718/20000], Loss: 1488.3890380859375, Entropy -54.54481506347656, Learning Rate: 0.01\n",
      "Epoch [719/20000], Loss: 1358.825927734375, Entropy -56.25604248046875, Learning Rate: 0.01\n",
      "Epoch [720/20000], Loss: 1424.9049072265625, Entropy -49.409061431884766, Learning Rate: 0.01\n",
      "Epoch [721/20000], Loss: 1372.77197265625, Entropy -67.14630126953125, Learning Rate: 0.01\n",
      "Epoch [722/20000], Loss: 1487.4482421875, Entropy -73.48731994628906, Learning Rate: 0.01\n",
      "Epoch [723/20000], Loss: 1370.6644287109375, Entropy -54.50092697143555, Learning Rate: 0.01\n",
      "Epoch [724/20000], Loss: 1346.6129150390625, Entropy -50.24137496948242, Learning Rate: 0.01\n",
      "Epoch [725/20000], Loss: 1349.9443359375, Entropy -71.61763763427734, Learning Rate: 0.01\n",
      "Epoch [726/20000], Loss: 1367.595947265625, Entropy -62.00331497192383, Learning Rate: 0.01\n",
      "Epoch [727/20000], Loss: 1428.0672607421875, Entropy -65.3666763305664, Learning Rate: 0.01\n",
      "Epoch [728/20000], Loss: 1408.397705078125, Entropy -70.9518814086914, Learning Rate: 0.01\n",
      "Epoch [729/20000], Loss: 1300.81005859375, Entropy -57.37622833251953, Learning Rate: 0.01\n",
      "Epoch [730/20000], Loss: 1387.57666015625, Entropy -79.66093444824219, Learning Rate: 0.01\n",
      "Epoch [731/20000], Loss: 1284.744384765625, Entropy -63.918216705322266, Learning Rate: 0.01\n",
      "Epoch [732/20000], Loss: 1333.1243896484375, Entropy -66.65158081054688, Learning Rate: 0.01\n",
      "Epoch [733/20000], Loss: 1513.3953857421875, Entropy -60.901824951171875, Learning Rate: 0.01\n",
      "Epoch [734/20000], Loss: 1371.2960205078125, Entropy -80.6019287109375, Learning Rate: 0.01\n",
      "Epoch [735/20000], Loss: 1371.0191650390625, Entropy -63.72064971923828, Learning Rate: 0.01\n",
      "Epoch [736/20000], Loss: 1353.4053955078125, Entropy -64.7000503540039, Learning Rate: 0.01\n",
      "Epoch [737/20000], Loss: 1301.9901123046875, Entropy -55.94602584838867, Learning Rate: 0.01\n",
      "Epoch [738/20000], Loss: 1399.76708984375, Entropy -50.24981689453125, Learning Rate: 0.01\n",
      "Epoch [739/20000], Loss: 1322.8975830078125, Entropy -70.42886352539062, Learning Rate: 0.01\n",
      "Epoch [740/20000], Loss: 1294.0640869140625, Entropy -58.57622528076172, Learning Rate: 0.01\n",
      "Epoch [741/20000], Loss: 1373.4239501953125, Entropy -58.603939056396484, Learning Rate: 0.01\n",
      "Epoch [742/20000], Loss: 1311.280029296875, Entropy -61.88046646118164, Learning Rate: 0.01\n",
      "Epoch [743/20000], Loss: 1307.906982421875, Entropy -57.41892623901367, Learning Rate: 0.01\n",
      "Epoch [744/20000], Loss: 1292.79248046875, Entropy -62.20066452026367, Learning Rate: 0.01\n",
      "Epoch [745/20000], Loss: 1294.13916015625, Entropy -43.60649871826172, Learning Rate: 0.01\n",
      "Epoch [746/20000], Loss: 1326.345703125, Entropy -64.20884704589844, Learning Rate: 0.01\n",
      "Epoch [747/20000], Loss: 1299.2479248046875, Entropy -64.85834503173828, Learning Rate: 0.01\n",
      "Epoch [748/20000], Loss: 1274.430419921875, Entropy -59.19430160522461, Learning Rate: 0.01\n",
      "Epoch [749/20000], Loss: 1375.69140625, Entropy -52.16242980957031, Learning Rate: 0.01\n",
      "Epoch [750/20000], Loss: 1310.8768310546875, Entropy -61.87437438964844, Learning Rate: 0.01\n",
      "Epoch [751/20000], Loss: 1293.7301025390625, Entropy -52.02953338623047, Learning Rate: 0.01\n",
      "Epoch [752/20000], Loss: 1345.33837890625, Entropy -64.60797119140625, Learning Rate: 0.01\n",
      "Epoch [753/20000], Loss: 1283.6016845703125, Entropy -71.93709564208984, Learning Rate: 0.01\n",
      "Epoch [754/20000], Loss: 1286.020263671875, Entropy -54.74212646484375, Learning Rate: 0.01\n",
      "Epoch [755/20000], Loss: 1289.1597900390625, Entropy -47.78459930419922, Learning Rate: 0.01\n",
      "Epoch [756/20000], Loss: 1317.99462890625, Entropy -57.76054382324219, Learning Rate: 0.01\n",
      "Epoch [757/20000], Loss: 1321.1639404296875, Entropy -40.911582946777344, Learning Rate: 0.01\n",
      "Epoch [758/20000], Loss: 1369.8272705078125, Entropy -57.20254135131836, Learning Rate: 0.01\n",
      "Epoch [759/20000], Loss: 1322.0382080078125, Entropy -66.87042999267578, Learning Rate: 0.01\n",
      "Epoch [760/20000], Loss: 1258.12255859375, Entropy -46.479949951171875, Learning Rate: 0.01\n",
      "Epoch [761/20000], Loss: 1281.3770751953125, Entropy -69.47789001464844, Learning Rate: 0.01\n",
      "Epoch [762/20000], Loss: 1337.4490966796875, Entropy -57.820892333984375, Learning Rate: 0.01\n",
      "Epoch [763/20000], Loss: 1300.875244140625, Entropy -51.18846130371094, Learning Rate: 0.01\n",
      "Epoch [764/20000], Loss: 1296.96337890625, Entropy -67.44688415527344, Learning Rate: 0.01\n",
      "Epoch [765/20000], Loss: 1315.9525146484375, Entropy -62.90053939819336, Learning Rate: 0.01\n",
      "Epoch [766/20000], Loss: 1312.0322265625, Entropy -62.44086837768555, Learning Rate: 0.01\n",
      "Epoch [767/20000], Loss: 1370.73193359375, Entropy -49.325443267822266, Learning Rate: 0.01\n",
      "Epoch [768/20000], Loss: 1279.0638427734375, Entropy -61.07028579711914, Learning Rate: 0.01\n",
      "Epoch [769/20000], Loss: 1321.675537109375, Entropy -59.564334869384766, Learning Rate: 0.01\n",
      "Epoch [770/20000], Loss: 1299.710693359375, Entropy -65.49456024169922, Learning Rate: 0.01\n",
      "Epoch [771/20000], Loss: 1477.065673828125, Entropy -60.89596939086914, Learning Rate: 0.01\n",
      "Epoch [772/20000], Loss: 1254.3536376953125, Entropy -64.54092407226562, Learning Rate: 0.01\n",
      "Epoch [773/20000], Loss: 1295.682373046875, Entropy -59.23049545288086, Learning Rate: 0.01\n",
      "Epoch [774/20000], Loss: 1286.37109375, Entropy -47.89655303955078, Learning Rate: 0.01\n",
      "Epoch [775/20000], Loss: 1265.50439453125, Entropy -58.9992561340332, Learning Rate: 0.01\n",
      "Epoch [776/20000], Loss: 1286.0169677734375, Entropy -55.6152229309082, Learning Rate: 0.01\n",
      "Epoch [777/20000], Loss: 1270.5699462890625, Entropy -58.52139663696289, Learning Rate: 0.01\n",
      "Epoch [778/20000], Loss: 1324.62841796875, Entropy -57.45212936401367, Learning Rate: 0.01\n",
      "Epoch [779/20000], Loss: 1307.74609375, Entropy -63.0279426574707, Learning Rate: 0.01\n",
      "Epoch [780/20000], Loss: 1393.9869384765625, Entropy -57.465423583984375, Learning Rate: 0.01\n",
      "Epoch [781/20000], Loss: 1341.7958984375, Entropy -54.30868911743164, Learning Rate: 0.01\n",
      "Epoch [782/20000], Loss: 1296.338623046875, Entropy -53.18061447143555, Learning Rate: 0.01\n",
      "Epoch [783/20000], Loss: 1313.958251953125, Entropy -49.0068359375, Learning Rate: 0.01\n",
      "Epoch [784/20000], Loss: 1268.649658203125, Entropy -68.87297821044922, Learning Rate: 0.01\n",
      "Epoch [785/20000], Loss: 1301.6337890625, Entropy -38.249446868896484, Learning Rate: 0.01\n",
      "Epoch [786/20000], Loss: 1288.0489501953125, Entropy -56.77865982055664, Learning Rate: 0.01\n",
      "Epoch [787/20000], Loss: 1300.2069091796875, Entropy -61.57529067993164, Learning Rate: 0.01\n",
      "Epoch [788/20000], Loss: 1313.2816162109375, Entropy -54.97114944458008, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [789/20000], Loss: 1509.3765869140625, Entropy -41.99851989746094, Learning Rate: 0.01\n",
      "Epoch [790/20000], Loss: 1241.90283203125, Entropy -42.44171905517578, Learning Rate: 0.01\n",
      "Epoch [791/20000], Loss: 1340.9569091796875, Entropy -65.84477233886719, Learning Rate: 0.01\n",
      "Epoch [792/20000], Loss: 1294.8316650390625, Entropy -63.27718734741211, Learning Rate: 0.01\n",
      "Epoch [793/20000], Loss: 1345.231689453125, Entropy -63.54241943359375, Learning Rate: 0.01\n",
      "Epoch [794/20000], Loss: 1259.8822021484375, Entropy -43.497520446777344, Learning Rate: 0.01\n",
      "Epoch [795/20000], Loss: 1302.9852294921875, Entropy -46.707923889160156, Learning Rate: 0.01\n",
      "Epoch [796/20000], Loss: 1429.4169921875, Entropy -47.66912078857422, Learning Rate: 0.01\n",
      "Epoch [797/20000], Loss: 1337.2999267578125, Entropy -47.85294723510742, Learning Rate: 0.01\n",
      "Epoch [798/20000], Loss: 1374.1219482421875, Entropy -50.58319854736328, Learning Rate: 0.01\n",
      "Epoch [799/20000], Loss: 1375.6351318359375, Entropy -37.11148452758789, Learning Rate: 0.01\n",
      "Epoch [800/20000], Loss: 1368.348388671875, Entropy -49.30430221557617, Learning Rate: 0.01\n",
      "Epoch [801/20000], Loss: 1287.8760986328125, Entropy -42.34970474243164, Learning Rate: 0.01\n",
      "Epoch [802/20000], Loss: 1387.0833740234375, Entropy -50.15079116821289, Learning Rate: 0.01\n",
      "Epoch [803/20000], Loss: 1400.05712890625, Entropy -48.29926681518555, Learning Rate: 0.01\n",
      "Epoch [804/20000], Loss: 1349.2806396484375, Entropy -51.11141586303711, Learning Rate: 0.01\n",
      "Epoch [805/20000], Loss: 1455.576416015625, Entropy -50.7669563293457, Learning Rate: 0.01\n",
      "Epoch [806/20000], Loss: 1366.467529296875, Entropy -44.188499450683594, Learning Rate: 0.01\n",
      "Epoch [807/20000], Loss: 1360.4127197265625, Entropy -63.3757438659668, Learning Rate: 0.01\n",
      "Epoch [808/20000], Loss: 1340.9500732421875, Entropy -54.08456802368164, Learning Rate: 0.01\n",
      "Epoch [809/20000], Loss: 1382.8248291015625, Entropy -50.82078170776367, Learning Rate: 0.01\n",
      "Epoch [810/20000], Loss: 1299.7330322265625, Entropy -43.41575241088867, Learning Rate: 0.01\n",
      "Epoch [811/20000], Loss: 1271.754638671875, Entropy -55.42694091796875, Learning Rate: 0.01\n",
      "Epoch [812/20000], Loss: 1334.330810546875, Entropy -56.9062385559082, Learning Rate: 0.01\n",
      "Epoch [813/20000], Loss: 1288.6988525390625, Entropy -44.69516372680664, Learning Rate: 0.01\n",
      "Epoch [814/20000], Loss: 1311.2989501953125, Entropy -59.41238021850586, Learning Rate: 0.01\n",
      "Epoch [815/20000], Loss: 1307.9241943359375, Entropy -54.17450714111328, Learning Rate: 0.01\n",
      "Epoch [816/20000], Loss: 1303.1317138671875, Entropy -48.36996841430664, Learning Rate: 0.01\n",
      "Epoch [817/20000], Loss: 1379.9610595703125, Entropy -59.158016204833984, Learning Rate: 0.01\n",
      "Epoch [818/20000], Loss: 1298.9053955078125, Entropy -47.98078536987305, Learning Rate: 0.01\n",
      "Epoch [819/20000], Loss: 1295.251708984375, Entropy -48.18171691894531, Learning Rate: 0.01\n",
      "Epoch [820/20000], Loss: 1315.9244384765625, Entropy -59.65829849243164, Learning Rate: 0.01\n",
      "Epoch [821/20000], Loss: 1303.23291015625, Entropy -68.95714569091797, Learning Rate: 0.01\n",
      "Epoch [822/20000], Loss: 1321.321533203125, Entropy -41.94854736328125, Learning Rate: 0.01\n",
      "Epoch [823/20000], Loss: 1301.7425537109375, Entropy -43.23298263549805, Learning Rate: 0.01\n",
      "Epoch [824/20000], Loss: 1368.017578125, Entropy -64.17880249023438, Learning Rate: 0.01\n",
      "Epoch [825/20000], Loss: 1288.184326171875, Entropy -61.23297882080078, Learning Rate: 0.01\n",
      "Epoch [826/20000], Loss: 1264.7890625, Entropy -53.14383316040039, Learning Rate: 0.01\n",
      "Epoch [827/20000], Loss: 1353.232666015625, Entropy -62.05852508544922, Learning Rate: 0.01\n",
      "Epoch [828/20000], Loss: 1263.549072265625, Entropy -43.54214859008789, Learning Rate: 0.01\n",
      "Epoch [829/20000], Loss: 1267.1622314453125, Entropy -48.95444869995117, Learning Rate: 0.01\n",
      "Epoch [830/20000], Loss: 1297.079833984375, Entropy -45.40250015258789, Learning Rate: 0.01\n",
      "Epoch [831/20000], Loss: 1285.3758544921875, Entropy -49.83516311645508, Learning Rate: 0.01\n",
      "Epoch [832/20000], Loss: 1296.591064453125, Entropy -47.83823013305664, Learning Rate: 0.01\n",
      "Epoch [833/20000], Loss: 1324.8919677734375, Entropy -69.89140319824219, Learning Rate: 0.01\n",
      "Epoch [834/20000], Loss: 1237.9984130859375, Entropy -56.527732849121094, Learning Rate: 0.01\n",
      "Epoch [835/20000], Loss: 1239.104248046875, Entropy -35.08893585205078, Learning Rate: 0.01\n",
      "Epoch [836/20000], Loss: 1325.1800537109375, Entropy -39.66484832763672, Learning Rate: 0.01\n",
      "Epoch [837/20000], Loss: 1309.7138671875, Entropy -50.92131805419922, Learning Rate: 0.01\n",
      "Epoch [838/20000], Loss: 1266.962158203125, Entropy -62.733612060546875, Learning Rate: 0.01\n",
      "Epoch [839/20000], Loss: 1324.3245849609375, Entropy -44.437068939208984, Learning Rate: 0.01\n",
      "Epoch [840/20000], Loss: 1274.895263671875, Entropy -43.41872024536133, Learning Rate: 0.01\n",
      "Epoch [841/20000], Loss: 1303.845703125, Entropy -52.39251708984375, Learning Rate: 0.01\n",
      "Epoch [842/20000], Loss: 1260.62060546875, Entropy -42.27271270751953, Learning Rate: 0.01\n",
      "Epoch [843/20000], Loss: 1288.6900634765625, Entropy -57.63520050048828, Learning Rate: 0.01\n",
      "Epoch [844/20000], Loss: 1287.366943359375, Entropy -60.03144836425781, Learning Rate: 0.01\n",
      "Epoch [845/20000], Loss: 1331.482666015625, Entropy -45.41934585571289, Learning Rate: 0.01\n",
      "Epoch [846/20000], Loss: 1292.0595703125, Entropy -42.38208770751953, Learning Rate: 0.01\n",
      "Epoch [847/20000], Loss: 1346.0623779296875, Entropy -59.53546905517578, Learning Rate: 0.01\n",
      "Epoch [848/20000], Loss: 1374.03076171875, Entropy -60.68360137939453, Learning Rate: 0.01\n",
      "Epoch [849/20000], Loss: 1280.417724609375, Entropy -40.94959259033203, Learning Rate: 0.01\n",
      "Epoch [850/20000], Loss: 1254.5384521484375, Entropy -49.27406311035156, Learning Rate: 0.01\n",
      "Epoch [851/20000], Loss: 1329.919677734375, Entropy -57.0995979309082, Learning Rate: 0.01\n",
      "Epoch [852/20000], Loss: 1341.3970947265625, Entropy -74.7589111328125, Learning Rate: 0.01\n",
      "Epoch [853/20000], Loss: 1287.9898681640625, Entropy -50.291107177734375, Learning Rate: 0.01\n",
      "Epoch [854/20000], Loss: 1334.12109375, Entropy -38.98127746582031, Learning Rate: 0.01\n",
      "Epoch [855/20000], Loss: 1257.1768798828125, Entropy -61.66317367553711, Learning Rate: 0.01\n",
      "Epoch [856/20000], Loss: 1327.3643798828125, Entropy -37.88220977783203, Learning Rate: 0.01\n",
      "Epoch [857/20000], Loss: 1286.2572021484375, Entropy -51.174564361572266, Learning Rate: 0.01\n",
      "Epoch [858/20000], Loss: 1260.35009765625, Entropy -33.1269645690918, Learning Rate: 0.01\n",
      "Epoch [859/20000], Loss: 1323.6512451171875, Entropy -41.99909973144531, Learning Rate: 0.01\n",
      "Epoch [860/20000], Loss: 1342.2950439453125, Entropy -42.41950988769531, Learning Rate: 0.01\n",
      "Epoch [861/20000], Loss: 1248.5318603515625, Entropy -52.485076904296875, Learning Rate: 0.01\n",
      "Epoch [862/20000], Loss: 1290.55322265625, Entropy -37.46649169921875, Learning Rate: 0.01\n",
      "Epoch [863/20000], Loss: 1259.238525390625, Entropy -49.43766403198242, Learning Rate: 0.01\n",
      "Epoch [864/20000], Loss: 1264.4132080078125, Entropy -39.36989974975586, Learning Rate: 0.01\n",
      "Epoch [865/20000], Loss: 1308.791259765625, Entropy -32.3235969543457, Learning Rate: 0.01\n",
      "Epoch [866/20000], Loss: 1273.364013671875, Entropy -31.367633819580078, Learning Rate: 0.01\n",
      "Epoch [867/20000], Loss: 1320.7716064453125, Entropy -58.317508697509766, Learning Rate: 0.01\n",
      "Epoch [868/20000], Loss: 1294.1298828125, Entropy -34.92898178100586, Learning Rate: 0.01\n",
      "Epoch [869/20000], Loss: 1233.01953125, Entropy -33.72178649902344, Learning Rate: 0.01\n",
      "Epoch [870/20000], Loss: 1260.2474365234375, Entropy -45.50385284423828, Learning Rate: 0.01\n",
      "Epoch [871/20000], Loss: 1311.271240234375, Entropy -47.3712158203125, Learning Rate: 0.01\n",
      "Epoch [872/20000], Loss: 1297.3294677734375, Entropy -44.511653900146484, Learning Rate: 0.01\n",
      "Epoch [873/20000], Loss: 1260.2271728515625, Entropy -42.66685104370117, Learning Rate: 0.01\n",
      "Epoch [874/20000], Loss: 1240.878662109375, Entropy -34.3367919921875, Learning Rate: 0.01\n",
      "Epoch [875/20000], Loss: 1268.0343017578125, Entropy -28.78035545349121, Learning Rate: 0.01\n",
      "Epoch [876/20000], Loss: 1340.4010009765625, Entropy -52.94987487792969, Learning Rate: 0.01\n",
      "Epoch [877/20000], Loss: 1316.882568359375, Entropy -35.57234191894531, Learning Rate: 0.01\n",
      "Epoch [878/20000], Loss: 1286.970703125, Entropy -39.78876495361328, Learning Rate: 0.01\n",
      "Epoch [879/20000], Loss: 1283.1685791015625, Entropy -40.29322814941406, Learning Rate: 0.01\n",
      "Epoch [880/20000], Loss: 1296.63525390625, Entropy -47.35576629638672, Learning Rate: 0.01\n",
      "Epoch [881/20000], Loss: 1244.0218505859375, Entropy -38.89271545410156, Learning Rate: 0.01\n",
      "Epoch [882/20000], Loss: 1240.7196044921875, Entropy -43.012939453125, Learning Rate: 0.01\n",
      "Epoch [883/20000], Loss: 1296.859130859375, Entropy -46.62843322753906, Learning Rate: 0.01\n",
      "Epoch [884/20000], Loss: 1297.1719970703125, Entropy -28.250722885131836, Learning Rate: 0.01\n",
      "Epoch [885/20000], Loss: 1251.0157470703125, Entropy -49.32383728027344, Learning Rate: 0.01\n",
      "Epoch [886/20000], Loss: 1273.029052734375, Entropy -39.159385681152344, Learning Rate: 0.01\n",
      "Epoch [887/20000], Loss: 1264.1182861328125, Entropy -37.684226989746094, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [888/20000], Loss: 1273.6407470703125, Entropy -45.237030029296875, Learning Rate: 0.01\n",
      "Epoch [889/20000], Loss: 1222.06298828125, Entropy -27.67951774597168, Learning Rate: 0.01\n",
      "Epoch [890/20000], Loss: 1271.9788818359375, Entropy -22.37531280517578, Learning Rate: 0.01\n",
      "Epoch [891/20000], Loss: 1264.0919189453125, Entropy -42.733787536621094, Learning Rate: 0.01\n",
      "Epoch [892/20000], Loss: 1282.7454833984375, Entropy -43.63420867919922, Learning Rate: 0.01\n",
      "Epoch [893/20000], Loss: 1273.2476806640625, Entropy -38.438133239746094, Learning Rate: 0.01\n",
      "Epoch [894/20000], Loss: 1282.3720703125, Entropy -53.10859680175781, Learning Rate: 0.01\n",
      "Epoch [895/20000], Loss: 1274.2900390625, Entropy -40.19575119018555, Learning Rate: 0.01\n",
      "Epoch [896/20000], Loss: 1224.620849609375, Entropy -48.184242248535156, Learning Rate: 0.01\n",
      "Epoch [897/20000], Loss: 1273.0377197265625, Entropy -35.786380767822266, Learning Rate: 0.01\n",
      "Epoch [898/20000], Loss: 1326.7894287109375, Entropy -47.3312873840332, Learning Rate: 0.01\n",
      "Epoch [899/20000], Loss: 1268.7852783203125, Entropy -31.832767486572266, Learning Rate: 0.01\n",
      "Epoch [900/20000], Loss: 1324.1497802734375, Entropy -43.806453704833984, Learning Rate: 0.01\n",
      "Epoch [901/20000], Loss: 1287.8896484375, Entropy -31.39667320251465, Learning Rate: 0.01\n",
      "Epoch [902/20000], Loss: 1257.6336669921875, Entropy -38.84941101074219, Learning Rate: 0.01\n",
      "Epoch [903/20000], Loss: 1276.791748046875, Entropy -24.003496170043945, Learning Rate: 0.01\n",
      "Epoch [904/20000], Loss: 1307.6231689453125, Entropy -50.03567123413086, Learning Rate: 0.01\n",
      "Epoch [905/20000], Loss: 1283.952880859375, Entropy -34.746395111083984, Learning Rate: 0.01\n",
      "Epoch [906/20000], Loss: 1259.1094970703125, Entropy -29.742929458618164, Learning Rate: 0.01\n",
      "Epoch [907/20000], Loss: 1293.5135498046875, Entropy -38.570213317871094, Learning Rate: 0.01\n",
      "Epoch [908/20000], Loss: 1336.23486328125, Entropy -37.500579833984375, Learning Rate: 0.01\n",
      "Epoch [909/20000], Loss: 1330.201416015625, Entropy -32.462913513183594, Learning Rate: 0.01\n",
      "Epoch [910/20000], Loss: 1349.7081298828125, Entropy -27.82338523864746, Learning Rate: 0.01\n",
      "Epoch [911/20000], Loss: 1276.547119140625, Entropy -42.676551818847656, Learning Rate: 0.01\n",
      "Epoch [912/20000], Loss: 1339.6519775390625, Entropy -29.10874366760254, Learning Rate: 0.01\n",
      "Epoch [913/20000], Loss: 1315.3348388671875, Entropy -23.391576766967773, Learning Rate: 0.01\n",
      "Epoch [914/20000], Loss: 1256.168212890625, Entropy -37.66545867919922, Learning Rate: 0.01\n",
      "Epoch [915/20000], Loss: 1265.5994873046875, Entropy -43.271175384521484, Learning Rate: 0.01\n",
      "Epoch [916/20000], Loss: 1336.166748046875, Entropy -32.03040313720703, Learning Rate: 0.01\n",
      "Epoch [917/20000], Loss: 1285.37109375, Entropy -29.073305130004883, Learning Rate: 0.01\n",
      "Epoch [918/20000], Loss: 1300.552490234375, Entropy -36.74943923950195, Learning Rate: 0.01\n",
      "Epoch [919/20000], Loss: 1293.4293212890625, Entropy -47.0317268371582, Learning Rate: 0.01\n",
      "Epoch [920/20000], Loss: 1313.0126953125, Entropy -30.265249252319336, Learning Rate: 0.01\n",
      "Epoch [921/20000], Loss: 1251.1405029296875, Entropy -23.368793487548828, Learning Rate: 0.01\n",
      "Epoch [922/20000], Loss: 1238.034423828125, Entropy -40.29813766479492, Learning Rate: 0.01\n",
      "Epoch [923/20000], Loss: 1221.74462890625, Entropy -30.628475189208984, Learning Rate: 0.01\n",
      "Epoch [924/20000], Loss: 1251.6268310546875, Entropy -32.44340896606445, Learning Rate: 0.01\n",
      "Epoch [925/20000], Loss: 1268.6829833984375, Entropy -42.13534927368164, Learning Rate: 0.01\n",
      "Epoch [926/20000], Loss: 1280.77685546875, Entropy -43.15159606933594, Learning Rate: 0.01\n",
      "Epoch [927/20000], Loss: 1311.316650390625, Entropy -34.61389923095703, Learning Rate: 0.01\n",
      "Epoch [928/20000], Loss: 1404.2869873046875, Entropy -39.19280242919922, Learning Rate: 0.01\n",
      "Epoch [929/20000], Loss: 1244.388671875, Entropy -33.50811767578125, Learning Rate: 0.01\n",
      "Epoch [930/20000], Loss: 1324.9473876953125, Entropy -27.110734939575195, Learning Rate: 0.01\n",
      "Epoch [931/20000], Loss: 1246.443359375, Entropy -41.69552230834961, Learning Rate: 0.01\n",
      "Epoch [932/20000], Loss: 1277.615234375, Entropy -28.175859451293945, Learning Rate: 0.01\n",
      "Epoch [933/20000], Loss: 1311.9493408203125, Entropy -37.3940544128418, Learning Rate: 0.01\n",
      "Epoch [934/20000], Loss: 1269.8973388671875, Entropy -30.109935760498047, Learning Rate: 0.01\n",
      "Epoch [935/20000], Loss: 1272.061279296875, Entropy -33.99897384643555, Learning Rate: 0.01\n",
      "Epoch [936/20000], Loss: 1302.349853515625, Entropy -27.506370544433594, Learning Rate: 0.01\n",
      "Epoch [937/20000], Loss: 1243.0250244140625, Entropy -30.7592716217041, Learning Rate: 0.01\n",
      "Epoch [938/20000], Loss: 1282.8846435546875, Entropy -20.71982192993164, Learning Rate: 0.01\n",
      "Epoch [939/20000], Loss: 1232.9044189453125, Entropy -27.513490676879883, Learning Rate: 0.01\n",
      "Epoch [940/20000], Loss: 1312.7188720703125, Entropy -38.31507873535156, Learning Rate: 0.01\n",
      "Epoch [941/20000], Loss: 1280.2984619140625, Entropy -33.51493453979492, Learning Rate: 0.01\n",
      "Epoch [942/20000], Loss: 1253.96826171875, Entropy -33.21243667602539, Learning Rate: 0.01\n",
      "Epoch [943/20000], Loss: 1364.4068603515625, Entropy -30.21855926513672, Learning Rate: 0.01\n",
      "Epoch [944/20000], Loss: 1320.0140380859375, Entropy -32.437618255615234, Learning Rate: 0.01\n",
      "Epoch [945/20000], Loss: 1236.3802490234375, Entropy -15.081147193908691, Learning Rate: 0.01\n",
      "Epoch [946/20000], Loss: 1322.1900634765625, Entropy -42.276573181152344, Learning Rate: 0.01\n",
      "Epoch [947/20000], Loss: 1238.6685791015625, Entropy -42.40126037597656, Learning Rate: 0.01\n",
      "Epoch [948/20000], Loss: 1309.6275634765625, Entropy -36.652122497558594, Learning Rate: 0.01\n",
      "Epoch [949/20000], Loss: 1290.4901123046875, Entropy -38.9310302734375, Learning Rate: 0.01\n",
      "Epoch [950/20000], Loss: 1291.84619140625, Entropy -37.162837982177734, Learning Rate: 0.01\n",
      "Epoch [951/20000], Loss: 1320.6156005859375, Entropy -20.24203109741211, Learning Rate: 0.01\n",
      "Epoch [952/20000], Loss: 1338.8990478515625, Entropy -41.52360153198242, Learning Rate: 0.01\n",
      "Epoch [953/20000], Loss: 1341.25, Entropy -35.69340515136719, Learning Rate: 0.01\n",
      "Epoch [954/20000], Loss: 1323.8040771484375, Entropy -46.48668670654297, Learning Rate: 0.01\n",
      "Epoch [955/20000], Loss: 1209.3369140625, Entropy -20.591583251953125, Learning Rate: 0.01\n",
      "Epoch [956/20000], Loss: 1279.4439697265625, Entropy -25.933637619018555, Learning Rate: 0.01\n",
      "Epoch [957/20000], Loss: 1276.214111328125, Entropy -48.65809631347656, Learning Rate: 0.01\n",
      "Epoch [958/20000], Loss: 1255.2705078125, Entropy -40.681800842285156, Learning Rate: 0.01\n",
      "Epoch [959/20000], Loss: 1320.0037841796875, Entropy -13.420663833618164, Learning Rate: 0.01\n",
      "Epoch [960/20000], Loss: 1337.2706298828125, Entropy -39.885826110839844, Learning Rate: 0.01\n",
      "Epoch [961/20000], Loss: 1208.8121337890625, Entropy -29.93515968322754, Learning Rate: 0.01\n",
      "Epoch [962/20000], Loss: 1251.070556640625, Entropy -20.844003677368164, Learning Rate: 0.01\n",
      "Epoch [963/20000], Loss: 1288.069091796875, Entropy -37.00572204589844, Learning Rate: 0.01\n",
      "Epoch [964/20000], Loss: 1252.7467041015625, Entropy -31.866764068603516, Learning Rate: 0.01\n",
      "Epoch [965/20000], Loss: 1307.4993896484375, Entropy -32.79532241821289, Learning Rate: 0.01\n",
      "Epoch [966/20000], Loss: 1276.3017578125, Entropy -24.17736053466797, Learning Rate: 0.01\n",
      "Epoch [967/20000], Loss: 1300.09619140625, Entropy -28.604198455810547, Learning Rate: 0.01\n",
      "Epoch [968/20000], Loss: 1278.966064453125, Entropy -33.85924530029297, Learning Rate: 0.01\n",
      "Epoch [969/20000], Loss: 1274.6922607421875, Entropy -26.174957275390625, Learning Rate: 0.01\n",
      "Epoch [970/20000], Loss: 1269.636474609375, Entropy -35.06047058105469, Learning Rate: 0.01\n",
      "Epoch [971/20000], Loss: 1264.8741455078125, Entropy -36.44729995727539, Learning Rate: 0.01\n",
      "Epoch [972/20000], Loss: 1284.9827880859375, Entropy -29.735042572021484, Learning Rate: 0.01\n",
      "Epoch [973/20000], Loss: 1278.658447265625, Entropy -29.432348251342773, Learning Rate: 0.01\n",
      "Epoch [974/20000], Loss: 1224.849609375, Entropy -10.330893516540527, Learning Rate: 0.01\n",
      "Epoch [975/20000], Loss: 1253.3868408203125, Entropy -32.77339172363281, Learning Rate: 0.01\n",
      "Epoch [976/20000], Loss: 1237.8321533203125, Entropy -27.589086532592773, Learning Rate: 0.01\n",
      "Epoch [977/20000], Loss: 1295.7169189453125, Entropy -29.9937801361084, Learning Rate: 0.01\n",
      "Epoch [978/20000], Loss: 1259.3831787109375, Entropy -27.99848175048828, Learning Rate: 0.01\n",
      "Epoch [979/20000], Loss: 1224.983154296875, Entropy -36.290645599365234, Learning Rate: 0.01\n",
      "Epoch [980/20000], Loss: 1271.7506103515625, Entropy -20.210405349731445, Learning Rate: 0.01\n",
      "Epoch [981/20000], Loss: 1290.4073486328125, Entropy -25.488204956054688, Learning Rate: 0.01\n",
      "Epoch [982/20000], Loss: 1239.5428466796875, Entropy -10.975045204162598, Learning Rate: 0.01\n",
      "Epoch [983/20000], Loss: 1210.6859130859375, Entropy -23.892480850219727, Learning Rate: 0.01\n",
      "Epoch [984/20000], Loss: 1283.0458984375, Entropy -19.654273986816406, Learning Rate: 0.01\n",
      "Epoch [985/20000], Loss: 1243.8319091796875, Entropy -37.82380676269531, Learning Rate: 0.01\n",
      "Epoch [986/20000], Loss: 1258.1982421875, Entropy -21.164134979248047, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [987/20000], Loss: 1200.8768310546875, Entropy -31.48019790649414, Learning Rate: 0.01\n",
      "Epoch [988/20000], Loss: 1269.4432373046875, Entropy -30.303434371948242, Learning Rate: 0.01\n",
      "Epoch [989/20000], Loss: 1241.6820068359375, Entropy -27.268470764160156, Learning Rate: 0.01\n",
      "Epoch [990/20000], Loss: 1237.7337646484375, Entropy -29.765575408935547, Learning Rate: 0.01\n",
      "Epoch [991/20000], Loss: 1282.948974609375, Entropy -25.56599998474121, Learning Rate: 0.01\n",
      "Epoch [992/20000], Loss: 1217.4310302734375, Entropy -22.72678565979004, Learning Rate: 0.01\n",
      "Epoch [993/20000], Loss: 1252.4173583984375, Entropy -19.84901237487793, Learning Rate: 0.01\n",
      "Epoch [994/20000], Loss: 1338.3353271484375, Entropy -36.72761535644531, Learning Rate: 0.01\n",
      "Epoch [995/20000], Loss: 1259.5572509765625, Entropy -32.881126403808594, Learning Rate: 0.01\n",
      "Epoch [996/20000], Loss: 1222.2137451171875, Entropy -28.95254898071289, Learning Rate: 0.01\n",
      "Epoch [997/20000], Loss: 1273.5062255859375, Entropy -28.049503326416016, Learning Rate: 0.01\n",
      "Epoch [998/20000], Loss: 1301.661376953125, Entropy -20.446138381958008, Learning Rate: 0.01\n",
      "Epoch [999/20000], Loss: 1305.7607421875, Entropy -23.34337615966797, Learning Rate: 0.01\n",
      "Epoch [1000/20000], Loss: 1285.627197265625, Entropy -24.648000717163086, Learning Rate: 0.01\n",
      "Epoch [1001/20000], Loss: 1296.4364013671875, Entropy -38.57773971557617, Learning Rate: 0.01\n",
      "Epoch [1002/20000], Loss: 1280.6527099609375, Entropy -33.11765670776367, Learning Rate: 0.01\n",
      "Epoch [1003/20000], Loss: 1256.313232421875, Entropy -26.556562423706055, Learning Rate: 0.01\n",
      "Epoch [1004/20000], Loss: 1350.606689453125, Entropy -23.734464645385742, Learning Rate: 0.01\n",
      "Epoch [1005/20000], Loss: 1250.256591796875, Entropy -7.72517204284668, Learning Rate: 0.01\n",
      "Epoch [1006/20000], Loss: 1245.919189453125, Entropy -30.15298843383789, Learning Rate: 0.01\n",
      "Epoch [1007/20000], Loss: 1262.440673828125, Entropy -23.562639236450195, Learning Rate: 0.01\n",
      "Epoch [1008/20000], Loss: 1214.5670166015625, Entropy -8.358038902282715, Learning Rate: 0.01\n",
      "Epoch [1009/20000], Loss: 1228.8994140625, Entropy -24.721439361572266, Learning Rate: 0.01\n",
      "Epoch [1010/20000], Loss: 1214.5880126953125, Entropy -12.913190841674805, Learning Rate: 0.01\n",
      "Epoch [1011/20000], Loss: 1219.9591064453125, Entropy -18.465551376342773, Learning Rate: 0.01\n",
      "Epoch [1012/20000], Loss: 1258.554443359375, Entropy -21.173954010009766, Learning Rate: 0.01\n",
      "Epoch [1013/20000], Loss: 1220.1241455078125, Entropy -27.587806701660156, Learning Rate: 0.01\n",
      "Epoch [1014/20000], Loss: 1256.13916015625, Entropy -35.76020431518555, Learning Rate: 0.01\n",
      "Epoch [1015/20000], Loss: 1239.999755859375, Entropy -18.5054874420166, Learning Rate: 0.01\n",
      "Epoch [1016/20000], Loss: 1301.6507568359375, Entropy -24.111860275268555, Learning Rate: 0.01\n",
      "Epoch [1017/20000], Loss: 1226.30029296875, Entropy -24.343515396118164, Learning Rate: 0.01\n",
      "Epoch [1018/20000], Loss: 1206.7193603515625, Entropy -16.208951950073242, Learning Rate: 0.01\n",
      "Epoch [1019/20000], Loss: 1261.531982421875, Entropy -21.195600509643555, Learning Rate: 0.01\n",
      "Epoch [1020/20000], Loss: 1264.4061279296875, Entropy -3.7230424880981445, Learning Rate: 0.01\n",
      "Epoch [1021/20000], Loss: 1237.4521484375, Entropy -5.981239318847656, Learning Rate: 0.01\n",
      "Epoch [1022/20000], Loss: 1249.0006103515625, Entropy -30.015077590942383, Learning Rate: 0.01\n",
      "Epoch [1023/20000], Loss: 1261.72998046875, Entropy -29.5069580078125, Learning Rate: 0.01\n",
      "Epoch [1024/20000], Loss: 1201.84619140625, Entropy -14.573641777038574, Learning Rate: 0.01\n",
      "Epoch [1025/20000], Loss: 1270.6146240234375, Entropy -25.116762161254883, Learning Rate: 0.01\n",
      "Epoch [1026/20000], Loss: 1246.2027587890625, Entropy -23.645431518554688, Learning Rate: 0.01\n",
      "Epoch [1027/20000], Loss: 1242.1214599609375, Entropy -29.42928123474121, Learning Rate: 0.01\n",
      "Epoch [1028/20000], Loss: 1231.1175537109375, Entropy -14.800790786743164, Learning Rate: 0.01\n",
      "Epoch [1029/20000], Loss: 1290.0687255859375, Entropy -8.477478981018066, Learning Rate: 0.01\n",
      "Epoch [1030/20000], Loss: 1285.550048828125, Entropy -27.573341369628906, Learning Rate: 0.01\n",
      "Epoch [1031/20000], Loss: 1186.1812744140625, Entropy 3.253582000732422, Learning Rate: 0.01\n",
      "Epoch [1032/20000], Loss: 1253.31884765625, Entropy -16.0883731842041, Learning Rate: 0.01\n",
      "Epoch [1033/20000], Loss: 1298.909423828125, Entropy -13.472277641296387, Learning Rate: 0.01\n",
      "Epoch [1034/20000], Loss: 1314.6934814453125, Entropy -21.637407302856445, Learning Rate: 0.01\n",
      "Epoch [1035/20000], Loss: 1433.0875244140625, Entropy -24.58195686340332, Learning Rate: 0.01\n",
      "Epoch [1036/20000], Loss: 1257.6192626953125, Entropy -19.255935668945312, Learning Rate: 0.01\n",
      "Epoch [1037/20000], Loss: 1278.0029296875, Entropy -18.551830291748047, Learning Rate: 0.01\n",
      "Epoch [1038/20000], Loss: 1276.4552001953125, Entropy -19.07999610900879, Learning Rate: 0.01\n",
      "Epoch [1039/20000], Loss: 1221.0208740234375, Entropy -13.89122486114502, Learning Rate: 0.01\n",
      "Epoch [1040/20000], Loss: 1306.728759765625, Entropy -11.130189895629883, Learning Rate: 0.01\n",
      "Epoch [1041/20000], Loss: 1275.0728759765625, Entropy -25.283613204956055, Learning Rate: 0.01\n",
      "Epoch [1042/20000], Loss: 1293.35546875, Entropy -20.638656616210938, Learning Rate: 0.01\n",
      "Epoch [1043/20000], Loss: 1249.0987548828125, Entropy -35.51036071777344, Learning Rate: 0.01\n",
      "Epoch [1044/20000], Loss: 1218.3883056640625, Entropy -14.828025817871094, Learning Rate: 0.01\n",
      "Epoch [1045/20000], Loss: 1223.526611328125, Entropy -17.615747451782227, Learning Rate: 0.01\n",
      "Epoch [1046/20000], Loss: 1262.7747802734375, Entropy -15.054819107055664, Learning Rate: 0.01\n",
      "Epoch [1047/20000], Loss: 1273.5704345703125, Entropy -25.59143829345703, Learning Rate: 0.01\n",
      "Epoch [1048/20000], Loss: 1248.0152587890625, Entropy -21.584169387817383, Learning Rate: 0.01\n",
      "Epoch [1049/20000], Loss: 1221.388916015625, Entropy -30.286273956298828, Learning Rate: 0.01\n",
      "Epoch [1050/20000], Loss: 1251.53662109375, Entropy -23.078887939453125, Learning Rate: 0.01\n",
      "Epoch [1051/20000], Loss: 1222.65087890625, Entropy -13.945537567138672, Learning Rate: 0.01\n",
      "Epoch [1052/20000], Loss: 1228.0291748046875, Entropy -18.566904067993164, Learning Rate: 0.01\n",
      "Epoch [1053/20000], Loss: 1267.0595703125, Entropy -10.00384521484375, Learning Rate: 0.01\n",
      "Epoch [1054/20000], Loss: 1217.7099609375, Entropy -12.054353713989258, Learning Rate: 0.01\n",
      "Epoch [1055/20000], Loss: 1292.6180419921875, Entropy -17.0924129486084, Learning Rate: 0.01\n",
      "Epoch [1056/20000], Loss: 1225.982177734375, Entropy -22.902143478393555, Learning Rate: 0.01\n",
      "Epoch [1057/20000], Loss: 1221.0137939453125, Entropy -35.3620491027832, Learning Rate: 0.01\n",
      "Epoch [1058/20000], Loss: 1302.50537109375, Entropy -6.769913196563721, Learning Rate: 0.01\n",
      "Epoch [1059/20000], Loss: 1257.900146484375, Entropy -4.313533306121826, Learning Rate: 0.01\n",
      "Epoch [1060/20000], Loss: 1250.65380859375, Entropy -15.715282440185547, Learning Rate: 0.01\n",
      "Epoch [1061/20000], Loss: 1269.39208984375, Entropy -17.4566650390625, Learning Rate: 0.01\n",
      "Epoch [1062/20000], Loss: 1296.5963134765625, Entropy -22.345605850219727, Learning Rate: 0.01\n",
      "Epoch [1063/20000], Loss: 1239.7139892578125, Entropy -3.0316503047943115, Learning Rate: 0.01\n",
      "Epoch [1064/20000], Loss: 1290.10595703125, Entropy -27.447763442993164, Learning Rate: 0.01\n",
      "Epoch [1065/20000], Loss: 1215.904541015625, Entropy -14.763461112976074, Learning Rate: 0.01\n",
      "Epoch [1066/20000], Loss: 1300.3580322265625, Entropy -6.168107032775879, Learning Rate: 0.01\n",
      "Epoch [1067/20000], Loss: 1249.098388671875, Entropy -13.533157348632812, Learning Rate: 0.01\n",
      "Epoch [1068/20000], Loss: 1272.853759765625, Entropy -10.347112655639648, Learning Rate: 0.01\n",
      "Epoch [1069/20000], Loss: 1246.5374755859375, Entropy -13.30684757232666, Learning Rate: 0.01\n",
      "Epoch [1070/20000], Loss: 1237.189453125, Entropy -6.395274639129639, Learning Rate: 0.01\n",
      "Epoch [1071/20000], Loss: 1275.9342041015625, Entropy -16.983274459838867, Learning Rate: 0.01\n",
      "Epoch [1072/20000], Loss: 1281.2415771484375, Entropy 3.6636571884155273, Learning Rate: 0.01\n",
      "Epoch [1073/20000], Loss: 1280.6478271484375, Entropy -25.282133102416992, Learning Rate: 0.01\n",
      "Epoch [1074/20000], Loss: 1225.451416015625, Entropy -0.8011203408241272, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1075/20000], Loss: 1267.067138671875, Entropy -36.08589172363281, Learning Rate: 0.01\n",
      "Epoch [1076/20000], Loss: 1266.839599609375, Entropy -13.732600212097168, Learning Rate: 0.01\n",
      "Epoch [1077/20000], Loss: 1248.8175048828125, Entropy -16.37427520751953, Learning Rate: 0.01\n",
      "Epoch [1078/20000], Loss: 1401.608154296875, Entropy -36.52135467529297, Learning Rate: 0.01\n",
      "Epoch [1079/20000], Loss: 1234.4505615234375, Entropy -13.160798072814941, Learning Rate: 0.01\n",
      "Epoch [1080/20000], Loss: 1292.684814453125, Entropy -8.70316219329834, Learning Rate: 0.01\n",
      "Epoch [1081/20000], Loss: 1240.1844482421875, Entropy -26.51197052001953, Learning Rate: 0.01\n",
      "Epoch [1082/20000], Loss: 1270.690673828125, Entropy -12.98173999786377, Learning Rate: 0.01\n",
      "Epoch [1083/20000], Loss: 1216.8780517578125, Entropy -21.884246826171875, Learning Rate: 0.01\n",
      "Epoch [1084/20000], Loss: 1207.30810546875, Entropy -9.440372467041016, Learning Rate: 0.01\n",
      "Epoch [1085/20000], Loss: 1262.723388671875, Entropy 0.617871880531311, Learning Rate: 0.01\n",
      "Epoch [1086/20000], Loss: 1313.884033203125, Entropy -19.809627532958984, Learning Rate: 0.01\n",
      "Epoch [1087/20000], Loss: 1253.7828369140625, Entropy -15.148152351379395, Learning Rate: 0.01\n",
      "Epoch [1088/20000], Loss: 1293.335205078125, Entropy -13.553278923034668, Learning Rate: 0.01\n",
      "Epoch [1089/20000], Loss: 1234.231201171875, Entropy -8.518256187438965, Learning Rate: 0.01\n",
      "Epoch [1090/20000], Loss: 1268.0234375, Entropy -13.273874282836914, Learning Rate: 0.01\n",
      "Epoch [1091/20000], Loss: 1262.1279296875, Entropy -8.196708679199219, Learning Rate: 0.01\n",
      "Epoch [1092/20000], Loss: 1232.6519775390625, Entropy -32.967037200927734, Learning Rate: 0.01\n",
      "Epoch [1093/20000], Loss: 1274.860595703125, Entropy -31.6092529296875, Learning Rate: 0.01\n",
      "Epoch [1094/20000], Loss: 1237.0457763671875, Entropy -2.224600076675415, Learning Rate: 0.01\n",
      "Epoch [1095/20000], Loss: 1268.079833984375, Entropy -27.652259826660156, Learning Rate: 0.01\n",
      "Epoch [1096/20000], Loss: 1278.4820556640625, Entropy -18.939708709716797, Learning Rate: 0.01\n",
      "Epoch [1097/20000], Loss: 1270.2281494140625, Entropy -8.233064651489258, Learning Rate: 0.01\n",
      "Epoch [1098/20000], Loss: 1258.2515869140625, Entropy -8.734570503234863, Learning Rate: 0.01\n",
      "Epoch [1099/20000], Loss: 1258.9326171875, Entropy -21.171005249023438, Learning Rate: 0.01\n",
      "Epoch [1100/20000], Loss: 1233.4288330078125, Entropy -9.635181427001953, Learning Rate: 0.01\n",
      "Epoch [1101/20000], Loss: 1232.9957275390625, Entropy -0.4555102288722992, Learning Rate: 0.01\n",
      "Epoch [1102/20000], Loss: 1243.9505615234375, Entropy -14.279047966003418, Learning Rate: 0.01\n",
      "Epoch [1103/20000], Loss: 1247.6192626953125, Entropy -8.669594764709473, Learning Rate: 0.01\n",
      "Epoch [1104/20000], Loss: 1184.794677734375, Entropy -4.792705535888672, Learning Rate: 0.01\n",
      "Epoch [1105/20000], Loss: 1310.588623046875, Entropy 0.4912493824958801, Learning Rate: 0.01\n",
      "Epoch [1106/20000], Loss: 1238.4888916015625, Entropy -6.024937629699707, Learning Rate: 0.01\n",
      "Epoch [1107/20000], Loss: 1223.324951171875, Entropy -14.28857135772705, Learning Rate: 0.01\n",
      "Epoch [1108/20000], Loss: 1182.7867431640625, Entropy -1.8905471563339233, Learning Rate: 0.01\n",
      "Epoch [1109/20000], Loss: 1202.45947265625, Entropy 4.327727794647217, Learning Rate: 0.01\n",
      "Epoch [1110/20000], Loss: 1251.8446044921875, Entropy -14.621161460876465, Learning Rate: 0.01\n",
      "Epoch [1111/20000], Loss: 1181.9317626953125, Entropy -9.863017082214355, Learning Rate: 0.01\n",
      "Epoch [1112/20000], Loss: 1264.23681640625, Entropy -11.80423355102539, Learning Rate: 0.01\n",
      "Epoch [1113/20000], Loss: 1232.8197021484375, Entropy -8.47065258026123, Learning Rate: 0.01\n",
      "Epoch [1114/20000], Loss: 1210.5242919921875, Entropy -15.395940780639648, Learning Rate: 0.01\n",
      "Epoch [1115/20000], Loss: 1218.6771240234375, Entropy -11.787060737609863, Learning Rate: 0.01\n",
      "Epoch [1116/20000], Loss: 1201.8582763671875, Entropy -24.861547470092773, Learning Rate: 0.01\n",
      "Epoch [1117/20000], Loss: 1238.5296630859375, Entropy -4.123804092407227, Learning Rate: 0.01\n",
      "Epoch [1118/20000], Loss: 1254.5489501953125, Entropy -1.5682350397109985, Learning Rate: 0.01\n",
      "Epoch [1119/20000], Loss: 1246.7197265625, Entropy -13.28565502166748, Learning Rate: 0.01\n",
      "Epoch [1120/20000], Loss: 1179.37255859375, Entropy 6.597700119018555, Learning Rate: 0.01\n",
      "Epoch [1121/20000], Loss: 1206.8187255859375, Entropy -8.264290809631348, Learning Rate: 0.01\n",
      "Epoch [1122/20000], Loss: 1231.2242431640625, Entropy 3.5420761108398438, Learning Rate: 0.01\n",
      "Epoch [1123/20000], Loss: 1203.580810546875, Entropy -13.783109664916992, Learning Rate: 0.01\n",
      "Epoch [1124/20000], Loss: 1215.7064208984375, Entropy -11.207963943481445, Learning Rate: 0.01\n",
      "Epoch [1125/20000], Loss: 1271.6104736328125, Entropy -21.957763671875, Learning Rate: 0.01\n",
      "Epoch [1126/20000], Loss: 1220.2706298828125, Entropy -10.714373588562012, Learning Rate: 0.01\n",
      "Epoch [1127/20000], Loss: 1241.19873046875, Entropy -8.848248481750488, Learning Rate: 0.01\n",
      "Epoch [1128/20000], Loss: 1214.272705078125, Entropy 3.8594970703125, Learning Rate: 0.01\n",
      "Epoch [1129/20000], Loss: 1212.48828125, Entropy -13.517818450927734, Learning Rate: 0.01\n",
      "Epoch [1130/20000], Loss: 1243.328125, Entropy -4.775688171386719, Learning Rate: 0.01\n",
      "Epoch [1131/20000], Loss: 1219.8707275390625, Entropy -9.228652954101562, Learning Rate: 0.01\n",
      "Epoch [1132/20000], Loss: 1205.5386962890625, Entropy 3.3067448139190674, Learning Rate: 0.01\n",
      "Epoch [1133/20000], Loss: 1287.193115234375, Entropy -11.55862045288086, Learning Rate: 0.01\n",
      "Epoch [1134/20000], Loss: 1257.3675537109375, Entropy -8.134592056274414, Learning Rate: 0.01\n",
      "Epoch [1135/20000], Loss: 1181.4600830078125, Entropy 6.367432594299316, Learning Rate: 0.01\n",
      "Epoch [1136/20000], Loss: 1168.2144775390625, Entropy 2.791005849838257, Learning Rate: 0.01\n",
      "Epoch [1137/20000], Loss: 1233.06494140625, Entropy -11.637601852416992, Learning Rate: 0.01\n",
      "Epoch [1138/20000], Loss: 1221.5859375, Entropy -3.6056063175201416, Learning Rate: 0.01\n",
      "Epoch [1139/20000], Loss: 1222.288818359375, Entropy -9.004659652709961, Learning Rate: 0.01\n",
      "Epoch [1140/20000], Loss: 1194.8924560546875, Entropy 5.304473876953125, Learning Rate: 0.01\n",
      "Epoch [1141/20000], Loss: 1196.7388916015625, Entropy 14.434185028076172, Learning Rate: 0.01\n",
      "Epoch [1142/20000], Loss: 1298.77294921875, Entropy -4.272727966308594, Learning Rate: 0.01\n",
      "Epoch [1143/20000], Loss: 1270.910400390625, Entropy -17.103729248046875, Learning Rate: 0.01\n",
      "Epoch [1144/20000], Loss: 1226.965087890625, Entropy -5.462446212768555, Learning Rate: 0.01\n",
      "Epoch [1145/20000], Loss: 1258.2008056640625, Entropy -21.017704010009766, Learning Rate: 0.01\n",
      "Epoch [1146/20000], Loss: 1202.033935546875, Entropy -9.944573402404785, Learning Rate: 0.01\n",
      "Epoch [1147/20000], Loss: 1266.50341796875, Entropy 0.6130446195602417, Learning Rate: 0.01\n",
      "Epoch [1148/20000], Loss: 1209.1790771484375, Entropy -2.41158127784729, Learning Rate: 0.01\n",
      "Epoch [1149/20000], Loss: 1243.779541015625, Entropy -6.9693474769592285, Learning Rate: 0.01\n",
      "Epoch [1150/20000], Loss: 1258.2073974609375, Entropy -7.809812068939209, Learning Rate: 0.01\n",
      "Epoch [1151/20000], Loss: 1238.5650634765625, Entropy -9.053078651428223, Learning Rate: 0.01\n",
      "Epoch [1152/20000], Loss: 1187.2926025390625, Entropy 8.335349082946777, Learning Rate: 0.01\n",
      "Epoch [1153/20000], Loss: 1189.2364501953125, Entropy 10.9146728515625, Learning Rate: 0.01\n",
      "Epoch [1154/20000], Loss: 1183.3402099609375, Entropy -0.5482528805732727, Learning Rate: 0.01\n",
      "Epoch [1155/20000], Loss: 1191.144287109375, Entropy -14.674999237060547, Learning Rate: 0.01\n",
      "Epoch [1156/20000], Loss: 1243.928955078125, Entropy -4.262725830078125, Learning Rate: 0.01\n",
      "Epoch [1157/20000], Loss: 1236.6680908203125, Entropy -2.0053529739379883, Learning Rate: 0.01\n",
      "Epoch [1158/20000], Loss: 1191.7879638671875, Entropy 3.3532257080078125, Learning Rate: 0.01\n",
      "Epoch [1159/20000], Loss: 1201.359375, Entropy -0.3307037651538849, Learning Rate: 0.01\n",
      "Epoch [1160/20000], Loss: 1241.451171875, Entropy -0.06483695656061172, Learning Rate: 0.01\n",
      "Epoch [1161/20000], Loss: 1205.6083984375, Entropy 4.342807292938232, Learning Rate: 0.01\n",
      "Epoch [1162/20000], Loss: 1234.1280517578125, Entropy -3.8939080238342285, Learning Rate: 0.01\n",
      "Epoch [1163/20000], Loss: 1196.8631591796875, Entropy -7.16037654876709, Learning Rate: 0.01\n",
      "Epoch [1164/20000], Loss: 1315.295166015625, Entropy -9.454042434692383, Learning Rate: 0.01\n",
      "Epoch [1165/20000], Loss: 1190.4915771484375, Entropy 1.2983468770980835, Learning Rate: 0.01\n",
      "Epoch [1166/20000], Loss: 1240.610107421875, Entropy -12.151301383972168, Learning Rate: 0.01\n",
      "Epoch [1167/20000], Loss: 1322.9832763671875, Entropy -3.164701223373413, Learning Rate: 0.01\n",
      "Epoch [1168/20000], Loss: 1217.986328125, Entropy -4.219547748565674, Learning Rate: 0.01\n",
      "Epoch [1169/20000], Loss: 1234.188720703125, Entropy 9.12851333618164, Learning Rate: 0.01\n",
      "Epoch [1170/20000], Loss: 1211.1907958984375, Entropy 7.010326862335205, Learning Rate: 0.01\n",
      "Epoch [1171/20000], Loss: 1263.6453857421875, Entropy -4.548882484436035, Learning Rate: 0.01\n",
      "Epoch [1172/20000], Loss: 1219.6602783203125, Entropy 4.08301305770874, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1173/20000], Loss: 1231.9864501953125, Entropy -6.337256908416748, Learning Rate: 0.01\n",
      "Epoch [1174/20000], Loss: 1220.413330078125, Entropy 6.473458766937256, Learning Rate: 0.01\n",
      "Epoch [1175/20000], Loss: 1182.2401123046875, Entropy -1.630181074142456, Learning Rate: 0.01\n",
      "Epoch [1176/20000], Loss: 1260.8406982421875, Entropy 2.7893810272216797, Learning Rate: 0.01\n",
      "Epoch [1177/20000], Loss: 1237.332275390625, Entropy 6.989861488342285, Learning Rate: 0.01\n",
      "Epoch [1178/20000], Loss: 1272.5123291015625, Entropy 6.179318904876709, Learning Rate: 0.01\n",
      "Epoch [1179/20000], Loss: 1192.1917724609375, Entropy -6.656269550323486, Learning Rate: 0.01\n",
      "Epoch [1180/20000], Loss: 1178.3712158203125, Entropy 11.031246185302734, Learning Rate: 0.01\n",
      "Epoch [1181/20000], Loss: 1306.6820068359375, Entropy 13.233129501342773, Learning Rate: 0.01\n",
      "Epoch [1182/20000], Loss: 1277.0888671875, Entropy 6.792548179626465, Learning Rate: 0.01\n",
      "Epoch [1183/20000], Loss: 1256.2611083984375, Entropy 1.5824252367019653, Learning Rate: 0.01\n",
      "Epoch [1184/20000], Loss: 1201.1822509765625, Entropy 12.10976791381836, Learning Rate: 0.01\n",
      "Epoch [1185/20000], Loss: 1325.08642578125, Entropy 14.432190895080566, Learning Rate: 0.01\n",
      "Epoch [1186/20000], Loss: 1213.3958740234375, Entropy 7.433635234832764, Learning Rate: 0.01\n",
      "Epoch [1187/20000], Loss: 1188.7861328125, Entropy 9.582620620727539, Learning Rate: 0.01\n",
      "Epoch [1188/20000], Loss: 1270.4832763671875, Entropy 8.386689186096191, Learning Rate: 0.01\n",
      "Epoch [1189/20000], Loss: 1248.9444580078125, Entropy 8.74855899810791, Learning Rate: 0.01\n",
      "Epoch [1190/20000], Loss: 1228.22607421875, Entropy 4.1624860763549805, Learning Rate: 0.01\n",
      "Epoch [1191/20000], Loss: 1240.967529296875, Entropy 14.122660636901855, Learning Rate: 0.01\n",
      "Epoch [1192/20000], Loss: 1193.5247802734375, Entropy 6.549558162689209, Learning Rate: 0.01\n",
      "Epoch [1193/20000], Loss: 1222.4739990234375, Entropy 1.9619338512420654, Learning Rate: 0.01\n",
      "Epoch [1194/20000], Loss: 1186.2989501953125, Entropy 3.6990644931793213, Learning Rate: 0.01\n",
      "Epoch [1195/20000], Loss: 1211.2501220703125, Entropy 17.073232650756836, Learning Rate: 0.01\n",
      "Epoch [1196/20000], Loss: 1234.010986328125, Entropy 9.37192153930664, Learning Rate: 0.01\n",
      "Epoch [1197/20000], Loss: 1214.6536865234375, Entropy -6.266524314880371, Learning Rate: 0.01\n",
      "Epoch [1198/20000], Loss: 1209.588134765625, Entropy 13.327863693237305, Learning Rate: 0.01\n",
      "Epoch [1199/20000], Loss: 1215.2366943359375, Entropy 12.472554206848145, Learning Rate: 0.01\n",
      "Epoch [1200/20000], Loss: 1174.521240234375, Entropy 8.457971572875977, Learning Rate: 0.01\n",
      "Epoch [1201/20000], Loss: 1333.0338134765625, Entropy 11.960734367370605, Learning Rate: 0.01\n",
      "Epoch [1202/20000], Loss: 1244.450439453125, Entropy 21.87973403930664, Learning Rate: 0.01\n",
      "Epoch [1203/20000], Loss: 1302.7154541015625, Entropy -8.876996040344238, Learning Rate: 0.01\n",
      "Epoch [1204/20000], Loss: 1284.57177734375, Entropy 9.350024223327637, Learning Rate: 0.01\n",
      "Epoch [1205/20000], Loss: 1178.2557373046875, Entropy 18.247020721435547, Learning Rate: 0.01\n",
      "Epoch [1206/20000], Loss: 1186.40673828125, Entropy 12.43107795715332, Learning Rate: 0.01\n",
      "Epoch [1207/20000], Loss: 1212.5782470703125, Entropy 3.4008336067199707, Learning Rate: 0.01\n",
      "Epoch [1208/20000], Loss: 1309.6041259765625, Entropy 1.5752544403076172, Learning Rate: 0.01\n",
      "Epoch [1209/20000], Loss: 1221.6241455078125, Entropy 5.450273513793945, Learning Rate: 0.01\n",
      "Epoch [1210/20000], Loss: 1232.85791015625, Entropy 4.0344929695129395, Learning Rate: 0.01\n",
      "Epoch [1211/20000], Loss: 1260.9525146484375, Entropy 0.07994750887155533, Learning Rate: 0.01\n",
      "Epoch [1212/20000], Loss: 1197.5887451171875, Entropy 11.968505859375, Learning Rate: 0.01\n",
      "Epoch [1213/20000], Loss: 1196.7783203125, Entropy 6.456676959991455, Learning Rate: 0.01\n",
      "Epoch [1214/20000], Loss: 1301.2777099609375, Entropy 20.976852416992188, Learning Rate: 0.01\n",
      "Epoch [1215/20000], Loss: 1308.759521484375, Entropy 3.3869621753692627, Learning Rate: 0.01\n",
      "Epoch [1216/20000], Loss: 1248.113037109375, Entropy 8.124044418334961, Learning Rate: 0.01\n",
      "Epoch [1217/20000], Loss: 1352.6634521484375, Entropy 0.5663679242134094, Learning Rate: 0.01\n",
      "Epoch [1218/20000], Loss: 1244.4066162109375, Entropy 5.633738994598389, Learning Rate: 0.01\n",
      "Epoch [1219/20000], Loss: 1298.1517333984375, Entropy 15.89647388458252, Learning Rate: 0.01\n",
      "Epoch [1220/20000], Loss: 1281.47900390625, Entropy 9.918631553649902, Learning Rate: 0.01\n",
      "Epoch [1221/20000], Loss: 1238.8795166015625, Entropy 17.448266983032227, Learning Rate: 0.01\n",
      "Epoch [1222/20000], Loss: 1264.2135009765625, Entropy -6.550703048706055, Learning Rate: 0.01\n",
      "Epoch [1223/20000], Loss: 1222.3153076171875, Entropy 22.046831130981445, Learning Rate: 0.01\n",
      "Epoch [1224/20000], Loss: 1256.8564453125, Entropy 5.206022262573242, Learning Rate: 0.01\n",
      "Epoch [1225/20000], Loss: 1362.66552734375, Entropy 5.711075305938721, Learning Rate: 0.01\n",
      "Epoch [1226/20000], Loss: 1358.2427978515625, Entropy 1.2505804300308228, Learning Rate: 0.01\n",
      "Epoch [1227/20000], Loss: 1251.4322509765625, Entropy -0.03349098190665245, Learning Rate: 0.01\n",
      "Epoch [1228/20000], Loss: 1207.823486328125, Entropy 8.07538890838623, Learning Rate: 0.01\n",
      "Epoch [1229/20000], Loss: 1269.0849609375, Entropy 7.446618556976318, Learning Rate: 0.01\n",
      "Epoch [1230/20000], Loss: 1188.3634033203125, Entropy 3.4033071994781494, Learning Rate: 0.01\n",
      "Epoch [1231/20000], Loss: 1241.2298583984375, Entropy 11.270689010620117, Learning Rate: 0.01\n",
      "Epoch [1232/20000], Loss: 1189.703369140625, Entropy 14.926305770874023, Learning Rate: 0.01\n",
      "Epoch [1233/20000], Loss: 1251.0306396484375, Entropy -0.08645313233137131, Learning Rate: 0.01\n",
      "Epoch [1234/20000], Loss: 1224.3443603515625, Entropy 19.36667251586914, Learning Rate: 0.01\n",
      "Epoch [1235/20000], Loss: 1209.8956298828125, Entropy 4.524208068847656, Learning Rate: 0.01\n",
      "Epoch [1236/20000], Loss: 1221.278076171875, Entropy 7.4817423820495605, Learning Rate: 0.01\n",
      "Epoch [1237/20000], Loss: 1175.3311767578125, Entropy 1.3159273862838745, Learning Rate: 0.01\n",
      "Epoch [1238/20000], Loss: 1219.41796875, Entropy 11.254814147949219, Learning Rate: 0.01\n",
      "Epoch [1239/20000], Loss: 1179.075927734375, Entropy 18.04188346862793, Learning Rate: 0.01\n",
      "Epoch [1240/20000], Loss: 1291.081787109375, Entropy 6.870508670806885, Learning Rate: 0.01\n",
      "Epoch [1241/20000], Loss: 1169.1458740234375, Entropy 10.28754997253418, Learning Rate: 0.01\n",
      "Epoch [1242/20000], Loss: 1274.7392578125, Entropy 12.509016036987305, Learning Rate: 0.01\n",
      "Epoch [1243/20000], Loss: 1314.43408203125, Entropy 12.821990966796875, Learning Rate: 0.01\n",
      "Epoch [1244/20000], Loss: 1247.6964111328125, Entropy 19.512910842895508, Learning Rate: 0.01\n",
      "Epoch [1245/20000], Loss: 1271.6951904296875, Entropy 14.141043663024902, Learning Rate: 0.01\n",
      "Epoch [1246/20000], Loss: 1210.7545166015625, Entropy 2.096547842025757, Learning Rate: 0.01\n",
      "Epoch [1247/20000], Loss: 1306.662109375, Entropy 12.10519790649414, Learning Rate: 0.01\n",
      "Epoch [1248/20000], Loss: 1245.8125, Entropy 8.773144721984863, Learning Rate: 0.01\n",
      "Epoch [1249/20000], Loss: 1230.99755859375, Entropy 2.135258674621582, Learning Rate: 0.01\n",
      "Epoch [1250/20000], Loss: 1319.2733154296875, Entropy -0.3641311526298523, Learning Rate: 0.01\n",
      "Epoch [1251/20000], Loss: 1225.029296875, Entropy 3.99086332321167, Learning Rate: 0.01\n",
      "Epoch [1252/20000], Loss: 1200.5081787109375, Entropy 10.913492202758789, Learning Rate: 0.01\n",
      "Epoch [1253/20000], Loss: 1234.6346435546875, Entropy 10.89578628540039, Learning Rate: 0.01\n",
      "Epoch [1254/20000], Loss: 1235.48779296875, Entropy 16.857698440551758, Learning Rate: 0.01\n",
      "Epoch [1255/20000], Loss: 1197.430908203125, Entropy 15.344987869262695, Learning Rate: 0.01\n",
      "Epoch [1256/20000], Loss: 1309.241943359375, Entropy 5.1500468254089355, Learning Rate: 0.01\n",
      "Epoch [1257/20000], Loss: 1269.57470703125, Entropy 13.057188034057617, Learning Rate: 0.01\n",
      "Epoch [1258/20000], Loss: 1289.0308837890625, Entropy 9.039691925048828, Learning Rate: 0.01\n",
      "Epoch [1259/20000], Loss: 1301.218017578125, Entropy 1.83484947681427, Learning Rate: 0.01\n",
      "Epoch [1260/20000], Loss: 1245.08154296875, Entropy 22.539819717407227, Learning Rate: 0.01\n",
      "Epoch [1261/20000], Loss: 1201.0859375, Entropy 19.61214256286621, Learning Rate: 0.01\n",
      "Epoch [1262/20000], Loss: 1273.8673095703125, Entropy 20.03803062438965, Learning Rate: 0.01\n",
      "Epoch [1263/20000], Loss: 1216.6583251953125, Entropy 24.35672378540039, Learning Rate: 0.01\n",
      "Epoch [1264/20000], Loss: 1307.732177734375, Entropy 20.40217399597168, Learning Rate: 0.01\n",
      "Epoch [1265/20000], Loss: 1263.8648681640625, Entropy 3.8405375480651855, Learning Rate: 0.01\n",
      "Epoch [1266/20000], Loss: 1305.382568359375, Entropy -3.4617562294006348, Learning Rate: 0.01\n",
      "Epoch [1267/20000], Loss: 1272.8856201171875, Entropy 14.55801010131836, Learning Rate: 0.01\n",
      "Epoch [1268/20000], Loss: 1186.713134765625, Entropy 20.81635284423828, Learning Rate: 0.01\n",
      "Epoch [1269/20000], Loss: 1254.259033203125, Entropy 3.6292881965637207, Learning Rate: 0.01\n",
      "Epoch [1270/20000], Loss: 1203.5908203125, Entropy 1.5889205932617188, Learning Rate: 0.01\n",
      "Epoch [1271/20000], Loss: 1335.3297119140625, Entropy 18.669946670532227, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1272/20000], Loss: 1240.3740234375, Entropy 17.9704532623291, Learning Rate: 0.01\n",
      "Epoch [1273/20000], Loss: 1225.077880859375, Entropy 23.836299896240234, Learning Rate: 0.01\n",
      "Epoch [1274/20000], Loss: 1186.938232421875, Entropy 21.463298797607422, Learning Rate: 0.01\n",
      "Epoch [1275/20000], Loss: 1282.7403564453125, Entropy 21.079137802124023, Learning Rate: 0.01\n",
      "Epoch [1276/20000], Loss: 1205.550048828125, Entropy 23.04073143005371, Learning Rate: 0.01\n",
      "Epoch [1277/20000], Loss: 1185.598388671875, Entropy 7.157711505889893, Learning Rate: 0.01\n",
      "Epoch [1278/20000], Loss: 1182.9267578125, Entropy 19.77981948852539, Learning Rate: 0.01\n",
      "Epoch [1279/20000], Loss: 1229.2359619140625, Entropy -0.9347698092460632, Learning Rate: 0.01\n",
      "Epoch [1280/20000], Loss: 1196.9462890625, Entropy 12.811198234558105, Learning Rate: 0.01\n",
      "Epoch [1281/20000], Loss: 1261.5853271484375, Entropy 21.006759643554688, Learning Rate: 0.01\n",
      "Epoch [1282/20000], Loss: 1216.265869140625, Entropy 16.67825698852539, Learning Rate: 0.01\n",
      "Epoch [1283/20000], Loss: 1296.3902587890625, Entropy 3.5176634788513184, Learning Rate: 0.01\n",
      "Epoch [1284/20000], Loss: 1353.2783203125, Entropy 22.82906723022461, Learning Rate: 0.01\n",
      "Epoch [1285/20000], Loss: 1215.284423828125, Entropy 25.31874656677246, Learning Rate: 0.01\n",
      "Epoch [1286/20000], Loss: 1283.844970703125, Entropy 16.33063507080078, Learning Rate: 0.01\n",
      "Epoch [1287/20000], Loss: 1238.2384033203125, Entropy 4.523317337036133, Learning Rate: 0.01\n",
      "Epoch [1288/20000], Loss: 1258.93115234375, Entropy 17.9742374420166, Learning Rate: 0.01\n",
      "Epoch [1289/20000], Loss: 1197.0819091796875, Entropy 25.617244720458984, Learning Rate: 0.01\n",
      "Epoch [1290/20000], Loss: 1204.079345703125, Entropy 15.451522827148438, Learning Rate: 0.01\n",
      "Epoch [1291/20000], Loss: 1225.896484375, Entropy 19.564674377441406, Learning Rate: 0.01\n",
      "Epoch [1292/20000], Loss: 1228.0848388671875, Entropy 11.660104751586914, Learning Rate: 0.01\n",
      "Epoch [1293/20000], Loss: 1228.1470947265625, Entropy 26.260738372802734, Learning Rate: 0.01\n",
      "Epoch [1294/20000], Loss: 1196.79443359375, Entropy 17.60150909423828, Learning Rate: 0.01\n",
      "Epoch [1295/20000], Loss: 1208.4677734375, Entropy 20.314348220825195, Learning Rate: 0.01\n",
      "Epoch [1296/20000], Loss: 1281.795654296875, Entropy 17.35435676574707, Learning Rate: 0.01\n",
      "Epoch [1297/20000], Loss: 1215.48095703125, Entropy 20.179973602294922, Learning Rate: 0.01\n",
      "Epoch [1298/20000], Loss: 1242.720947265625, Entropy 8.094257354736328, Learning Rate: 0.01\n",
      "Epoch [1299/20000], Loss: 1205.43212890625, Entropy 21.165740966796875, Learning Rate: 0.01\n",
      "Epoch [1300/20000], Loss: 1229.302490234375, Entropy 17.370464324951172, Learning Rate: 0.01\n",
      "Epoch [1301/20000], Loss: 1229.035400390625, Entropy 7.412831783294678, Learning Rate: 0.01\n",
      "Epoch [1302/20000], Loss: 1263.870849609375, Entropy 26.912311553955078, Learning Rate: 0.01\n",
      "Epoch [1303/20000], Loss: 1190.728271484375, Entropy 13.570205688476562, Learning Rate: 0.01\n",
      "Epoch [1304/20000], Loss: 1262.6104736328125, Entropy 14.486225128173828, Learning Rate: 0.01\n",
      "Epoch [1305/20000], Loss: 1157.6361083984375, Entropy 30.872264862060547, Learning Rate: 0.01\n",
      "Epoch [1306/20000], Loss: 1212.2550048828125, Entropy 16.197858810424805, Learning Rate: 0.01\n",
      "Epoch [1307/20000], Loss: 1192.3956298828125, Entropy 18.51912498474121, Learning Rate: 0.01\n",
      "Epoch [1308/20000], Loss: 1211.7740478515625, Entropy 19.790000915527344, Learning Rate: 0.01\n",
      "Epoch [1309/20000], Loss: 1172.938720703125, Entropy 13.878937721252441, Learning Rate: 0.01\n",
      "Epoch [1310/20000], Loss: 1213.2821044921875, Entropy 21.054096221923828, Learning Rate: 0.01\n",
      "Epoch [1311/20000], Loss: 1149.3369140625, Entropy 7.605327129364014, Learning Rate: 0.01\n",
      "Epoch [1312/20000], Loss: 1228.146728515625, Entropy 9.001439094543457, Learning Rate: 0.01\n",
      "Epoch [1313/20000], Loss: 1171.3931884765625, Entropy 19.882490158081055, Learning Rate: 0.01\n",
      "Epoch [1314/20000], Loss: 1233.3330078125, Entropy 26.031957626342773, Learning Rate: 0.01\n",
      "Epoch [1315/20000], Loss: 1155.039306640625, Entropy 28.4766788482666, Learning Rate: 0.01\n",
      "Epoch [1316/20000], Loss: 1227.3565673828125, Entropy 20.78209114074707, Learning Rate: 0.01\n",
      "Epoch [1317/20000], Loss: 1256.0157470703125, Entropy 8.24642562866211, Learning Rate: 0.01\n",
      "Epoch [1318/20000], Loss: 1296.7459716796875, Entropy 19.745742797851562, Learning Rate: 0.01\n",
      "Epoch [1319/20000], Loss: 1257.34912109375, Entropy 24.969743728637695, Learning Rate: 0.01\n",
      "Epoch [1320/20000], Loss: 1267.2877197265625, Entropy 7.458958625793457, Learning Rate: 0.01\n",
      "Epoch [1321/20000], Loss: 1292.0321044921875, Entropy 12.761161804199219, Learning Rate: 0.01\n",
      "Epoch [1322/20000], Loss: 1369.5950927734375, Entropy 15.551431655883789, Learning Rate: 0.01\n",
      "Epoch [1323/20000], Loss: 1232.1805419921875, Entropy 17.953807830810547, Learning Rate: 0.01\n",
      "Epoch [1324/20000], Loss: 1307.692138671875, Entropy 4.985471248626709, Learning Rate: 0.01\n",
      "Epoch [1325/20000], Loss: 1231.9429931640625, Entropy 42.64751434326172, Learning Rate: 0.01\n",
      "Epoch [1326/20000], Loss: 1249.776611328125, Entropy 24.0173282623291, Learning Rate: 0.01\n",
      "Epoch [1327/20000], Loss: 1255.17236328125, Entropy 10.763995170593262, Learning Rate: 0.01\n",
      "Epoch [1328/20000], Loss: 1206.84375, Entropy 15.460549354553223, Learning Rate: 0.01\n",
      "Epoch [1329/20000], Loss: 1321.0478515625, Entropy 24.087142944335938, Learning Rate: 0.01\n",
      "Epoch [1330/20000], Loss: 1269.611572265625, Entropy 15.751216888427734, Learning Rate: 0.01\n",
      "Epoch [1331/20000], Loss: 1313.2052001953125, Entropy 23.518245697021484, Learning Rate: 0.01\n",
      "Epoch [1332/20000], Loss: 1290.707763671875, Entropy 19.31899070739746, Learning Rate: 0.01\n",
      "Epoch [1333/20000], Loss: 1469.0504150390625, Entropy 16.119426727294922, Learning Rate: 0.01\n",
      "Epoch [1334/20000], Loss: 1688.8153076171875, Entropy 23.300582885742188, Learning Rate: 0.01\n",
      "Epoch [1335/20000], Loss: 1446.98681640625, Entropy 18.04620361328125, Learning Rate: 0.01\n",
      "Epoch [1336/20000], Loss: 1777.2447509765625, Entropy 28.045833587646484, Learning Rate: 0.01\n",
      "Epoch [1337/20000], Loss: 1360.53759765625, Entropy 19.221385955810547, Learning Rate: 0.01\n",
      "Epoch [1338/20000], Loss: 1392.976318359375, Entropy 11.036787986755371, Learning Rate: 0.01\n",
      "Epoch [1339/20000], Loss: 1522.75927734375, Entropy 25.824403762817383, Learning Rate: 0.01\n",
      "Epoch [1340/20000], Loss: 1434.8046875, Entropy 20.858306884765625, Learning Rate: 0.01\n",
      "Epoch [1341/20000], Loss: 1265.4500732421875, Entropy 14.115910530090332, Learning Rate: 0.01\n",
      "Epoch [1342/20000], Loss: 1286.5784912109375, Entropy 27.763784408569336, Learning Rate: 0.01\n",
      "Epoch [1343/20000], Loss: 1345.921630859375, Entropy 25.842348098754883, Learning Rate: 0.01\n",
      "Epoch [1344/20000], Loss: 1330.3917236328125, Entropy 24.252283096313477, Learning Rate: 0.01\n",
      "Epoch [1345/20000], Loss: 1363.5543212890625, Entropy 17.680273056030273, Learning Rate: 0.01\n",
      "Epoch [1346/20000], Loss: 1385.7415771484375, Entropy 23.101797103881836, Learning Rate: 0.01\n",
      "Epoch [1347/20000], Loss: 1517.2052001953125, Entropy 23.958398818969727, Learning Rate: 0.01\n",
      "Epoch [1348/20000], Loss: 1325.36474609375, Entropy 23.879301071166992, Learning Rate: 0.01\n",
      "Epoch [1349/20000], Loss: 1365.7728271484375, Entropy 19.80118751525879, Learning Rate: 0.01\n",
      "Epoch [1350/20000], Loss: 1349.4478759765625, Entropy 8.675582885742188, Learning Rate: 0.01\n",
      "Epoch [1351/20000], Loss: 1318.7969970703125, Entropy 19.31298828125, Learning Rate: 0.01\n",
      "Epoch [1352/20000], Loss: 1390.1826171875, Entropy 27.05234718322754, Learning Rate: 0.01\n",
      "Epoch [1353/20000], Loss: 1304.310791015625, Entropy 33.44775390625, Learning Rate: 0.01\n",
      "Epoch [1354/20000], Loss: 1208.2122802734375, Entropy 16.33901023864746, Learning Rate: 0.01\n",
      "Epoch [1355/20000], Loss: 1353.3714599609375, Entropy 18.850324630737305, Learning Rate: 0.01\n",
      "Epoch [1356/20000], Loss: 1185.8284912109375, Entropy 14.003007888793945, Learning Rate: 0.01\n",
      "Epoch [1357/20000], Loss: 1325.557861328125, Entropy 14.546509742736816, Learning Rate: 0.01\n",
      "Epoch [1358/20000], Loss: 1220.2869873046875, Entropy 18.10445785522461, Learning Rate: 0.01\n",
      "Epoch [1359/20000], Loss: 1299.83984375, Entropy 25.677345275878906, Learning Rate: 0.01\n",
      "Epoch [1360/20000], Loss: 1176.52099609375, Entropy 14.222135543823242, Learning Rate: 0.01\n",
      "Epoch [1361/20000], Loss: 1267.704833984375, Entropy 23.457088470458984, Learning Rate: 0.01\n",
      "Epoch [1362/20000], Loss: 1300.7845458984375, Entropy 14.47951889038086, Learning Rate: 0.01\n",
      "Epoch [1363/20000], Loss: 1340.8367919921875, Entropy 13.374921798706055, Learning Rate: 0.01\n",
      "Epoch [1364/20000], Loss: 1321.5474853515625, Entropy 18.25739860534668, Learning Rate: 0.01\n",
      "Epoch [1365/20000], Loss: 1260.4390869140625, Entropy 14.061159133911133, Learning Rate: 0.01\n",
      "Epoch [1366/20000], Loss: 1517.9453125, Entropy 17.731794357299805, Learning Rate: 0.01\n",
      "Epoch [1367/20000], Loss: 1262.3603515625, Entropy 25.478927612304688, Learning Rate: 0.01\n",
      "Epoch [1368/20000], Loss: 1404.1875, Entropy 20.464500427246094, Learning Rate: 0.01\n",
      "Epoch [1369/20000], Loss: 1273.065185546875, Entropy 14.236034393310547, Learning Rate: 0.01\n",
      "Epoch [1370/20000], Loss: 1364.3970947265625, Entropy 22.39253807067871, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1371/20000], Loss: 1221.0101318359375, Entropy 22.489030838012695, Learning Rate: 0.01\n",
      "Epoch [1372/20000], Loss: 1327.660888671875, Entropy 3.6323602199554443, Learning Rate: 0.01\n",
      "Epoch [1373/20000], Loss: 1249.9923095703125, Entropy 14.848730087280273, Learning Rate: 0.01\n",
      "Epoch [1374/20000], Loss: 1318.9273681640625, Entropy 17.535137176513672, Learning Rate: 0.01\n",
      "Epoch [1375/20000], Loss: 1262.1109619140625, Entropy 14.796182632446289, Learning Rate: 0.01\n",
      "Epoch [1376/20000], Loss: 1241.291259765625, Entropy 14.542880058288574, Learning Rate: 0.01\n",
      "Epoch [1377/20000], Loss: 1248.7724609375, Entropy 16.235563278198242, Learning Rate: 0.01\n",
      "Epoch [1378/20000], Loss: 1212.2552490234375, Entropy 20.63234519958496, Learning Rate: 0.01\n",
      "Epoch [1379/20000], Loss: 1257.8265380859375, Entropy 25.742820739746094, Learning Rate: 0.01\n",
      "Epoch [1380/20000], Loss: 1222.283203125, Entropy 14.675132751464844, Learning Rate: 0.01\n",
      "Epoch [1381/20000], Loss: 1214.77685546875, Entropy 21.267988204956055, Learning Rate: 0.01\n",
      "Epoch [1382/20000], Loss: 1183.231689453125, Entropy 19.378339767456055, Learning Rate: 0.01\n",
      "Epoch [1383/20000], Loss: 1224.3768310546875, Entropy 20.530277252197266, Learning Rate: 0.01\n",
      "Epoch [1384/20000], Loss: 1183.5882568359375, Entropy 21.655399322509766, Learning Rate: 0.01\n",
      "Epoch [1385/20000], Loss: 1199.25537109375, Entropy 20.789379119873047, Learning Rate: 0.01\n",
      "Epoch [1386/20000], Loss: 1242.0692138671875, Entropy 8.191658973693848, Learning Rate: 0.01\n",
      "Epoch [1387/20000], Loss: 1226.6275634765625, Entropy 27.25202178955078, Learning Rate: 0.01\n",
      "Epoch [1388/20000], Loss: 1221.0423583984375, Entropy 19.763002395629883, Learning Rate: 0.01\n",
      "Epoch [1389/20000], Loss: 1144.4281005859375, Entropy 21.89374542236328, Learning Rate: 0.01\n",
      "Epoch [1390/20000], Loss: 1186.7861328125, Entropy 29.34747886657715, Learning Rate: 0.01\n",
      "Epoch [1391/20000], Loss: 1202.0555419921875, Entropy 18.702037811279297, Learning Rate: 0.01\n",
      "Epoch [1392/20000], Loss: 1232.6748046875, Entropy 27.263681411743164, Learning Rate: 0.01\n",
      "Epoch [1393/20000], Loss: 1196.7861328125, Entropy 27.636898040771484, Learning Rate: 0.01\n",
      "Epoch [1394/20000], Loss: 1153.46337890625, Entropy 23.779298782348633, Learning Rate: 0.01\n",
      "Epoch [1395/20000], Loss: 1214.26220703125, Entropy 10.56887149810791, Learning Rate: 0.01\n",
      "Epoch [1396/20000], Loss: 1227.581787109375, Entropy 9.482076644897461, Learning Rate: 0.01\n",
      "Epoch [1397/20000], Loss: 1233.7327880859375, Entropy 25.981157302856445, Learning Rate: 0.01\n",
      "Epoch [1398/20000], Loss: 1185.462158203125, Entropy 10.783927917480469, Learning Rate: 0.01\n",
      "Epoch [1399/20000], Loss: 1171.302978515625, Entropy 24.87065887451172, Learning Rate: 0.01\n",
      "Epoch [1400/20000], Loss: 1229.2900390625, Entropy 20.73396873474121, Learning Rate: 0.01\n",
      "Epoch [1401/20000], Loss: 1225.546630859375, Entropy 29.12051010131836, Learning Rate: 0.01\n",
      "Epoch [1402/20000], Loss: 1177.73779296875, Entropy 34.89855194091797, Learning Rate: 0.01\n",
      "Epoch [1403/20000], Loss: 1202.41943359375, Entropy 10.341486930847168, Learning Rate: 0.01\n",
      "Epoch [1404/20000], Loss: 1170.150146484375, Entropy 22.16608428955078, Learning Rate: 0.01\n",
      "Epoch [1405/20000], Loss: 1184.8448486328125, Entropy 15.970582008361816, Learning Rate: 0.01\n",
      "Epoch [1406/20000], Loss: 1174.025146484375, Entropy 21.43083953857422, Learning Rate: 0.01\n",
      "Epoch [1407/20000], Loss: 1215.897216796875, Entropy 21.76427459716797, Learning Rate: 0.01\n",
      "Epoch [1408/20000], Loss: 1188.913818359375, Entropy 12.113103866577148, Learning Rate: 0.01\n",
      "Epoch [1409/20000], Loss: 1155.81494140625, Entropy 30.404319763183594, Learning Rate: 0.01\n",
      "Epoch [1410/20000], Loss: 1186.7535400390625, Entropy 29.715717315673828, Learning Rate: 0.01\n",
      "Epoch [1411/20000], Loss: 1164.6407470703125, Entropy 24.210460662841797, Learning Rate: 0.01\n",
      "Epoch [1412/20000], Loss: 1129.800048828125, Entropy 25.113542556762695, Learning Rate: 0.01\n",
      "Epoch [1413/20000], Loss: 1226.93408203125, Entropy 18.99173927307129, Learning Rate: 0.01\n",
      "Epoch [1414/20000], Loss: 1165.8846435546875, Entropy 11.995573043823242, Learning Rate: 0.01\n",
      "Epoch [1415/20000], Loss: 1208.7398681640625, Entropy 26.657026290893555, Learning Rate: 0.01\n",
      "Epoch [1416/20000], Loss: 1156.2593994140625, Entropy 24.679027557373047, Learning Rate: 0.01\n",
      "Epoch [1417/20000], Loss: 1184.3582763671875, Entropy 28.981142044067383, Learning Rate: 0.01\n",
      "Epoch [1418/20000], Loss: 1216.6868896484375, Entropy 11.065810203552246, Learning Rate: 0.01\n",
      "Epoch [1419/20000], Loss: 1199.2183837890625, Entropy 19.374126434326172, Learning Rate: 0.01\n",
      "Epoch [1420/20000], Loss: 1133.8994140625, Entropy 28.392118453979492, Learning Rate: 0.01\n",
      "Epoch [1421/20000], Loss: 1183.3477783203125, Entropy 17.99396514892578, Learning Rate: 0.01\n",
      "Epoch [1422/20000], Loss: 1178.0137939453125, Entropy 23.966259002685547, Learning Rate: 0.01\n",
      "Epoch [1423/20000], Loss: 1194.0919189453125, Entropy 19.57919692993164, Learning Rate: 0.01\n",
      "Epoch [1424/20000], Loss: 1171.3907470703125, Entropy 28.72607421875, Learning Rate: 0.01\n",
      "Epoch [1425/20000], Loss: 1156.166015625, Entropy 19.848772048950195, Learning Rate: 0.01\n",
      "Epoch [1426/20000], Loss: 1152.379638671875, Entropy 25.97466278076172, Learning Rate: 0.01\n",
      "Epoch [1427/20000], Loss: 1163.0816650390625, Entropy 21.906435012817383, Learning Rate: 0.01\n",
      "Epoch [1428/20000], Loss: 1174.08056640625, Entropy 33.8079833984375, Learning Rate: 0.01\n",
      "Epoch [1429/20000], Loss: 1153.467041015625, Entropy 17.88277244567871, Learning Rate: 0.01\n",
      "Epoch [1430/20000], Loss: 1161.9736328125, Entropy 9.254725456237793, Learning Rate: 0.01\n",
      "Epoch [1431/20000], Loss: 1174.9930419921875, Entropy 5.037585258483887, Learning Rate: 0.01\n",
      "Epoch [1432/20000], Loss: 1192.5260009765625, Entropy 25.246967315673828, Learning Rate: 0.01\n",
      "Epoch [1433/20000], Loss: 1147.264892578125, Entropy 32.87453079223633, Learning Rate: 0.01\n",
      "Epoch [1434/20000], Loss: 1182.2115478515625, Entropy 32.627281188964844, Learning Rate: 0.01\n",
      "Epoch [1435/20000], Loss: 1161.211181640625, Entropy 19.000959396362305, Learning Rate: 0.01\n",
      "Epoch [1436/20000], Loss: 1136.2430419921875, Entropy 24.51325225830078, Learning Rate: 0.01\n",
      "Epoch [1437/20000], Loss: 1195.529541015625, Entropy 27.67234230041504, Learning Rate: 0.01\n",
      "Epoch [1438/20000], Loss: 1159.77392578125, Entropy 29.28387451171875, Learning Rate: 0.01\n",
      "Epoch [1439/20000], Loss: 1196.2808837890625, Entropy 28.15990447998047, Learning Rate: 0.01\n",
      "Epoch [1440/20000], Loss: 1218.6258544921875, Entropy 34.32648849487305, Learning Rate: 0.01\n",
      "Epoch [1441/20000], Loss: 1162.5467529296875, Entropy 24.438451766967773, Learning Rate: 0.01\n",
      "Epoch [1442/20000], Loss: 1161.3526611328125, Entropy 28.656293869018555, Learning Rate: 0.01\n",
      "Epoch [1443/20000], Loss: 1165.40966796875, Entropy 38.074302673339844, Learning Rate: 0.01\n",
      "Epoch [1444/20000], Loss: 1199.00927734375, Entropy 41.125701904296875, Learning Rate: 0.01\n",
      "Epoch [1445/20000], Loss: 1138.428466796875, Entropy 40.997615814208984, Learning Rate: 0.01\n",
      "Epoch [1446/20000], Loss: 1165.76806640625, Entropy 39.78055953979492, Learning Rate: 0.01\n",
      "Epoch [1447/20000], Loss: 1232.351318359375, Entropy 34.01202392578125, Learning Rate: 0.01\n",
      "Epoch [1448/20000], Loss: 1146.1866455078125, Entropy 37.59838104248047, Learning Rate: 0.01\n",
      "Epoch [1449/20000], Loss: 1141.102294921875, Entropy 29.510589599609375, Learning Rate: 0.01\n",
      "Epoch [1450/20000], Loss: 1247.228515625, Entropy 33.9570426940918, Learning Rate: 0.01\n",
      "Epoch [1451/20000], Loss: 1245.29150390625, Entropy 35.800048828125, Learning Rate: 0.01\n",
      "Epoch [1452/20000], Loss: 1144.4031982421875, Entropy 47.236629486083984, Learning Rate: 0.01\n",
      "Epoch [1453/20000], Loss: 1146.80078125, Entropy 31.697988510131836, Learning Rate: 0.01\n",
      "Epoch [1454/20000], Loss: 1156.714111328125, Entropy 34.8863525390625, Learning Rate: 0.01\n",
      "Epoch [1455/20000], Loss: 1136.055908203125, Entropy 29.204891204833984, Learning Rate: 0.01\n",
      "Epoch [1456/20000], Loss: 1200.2462158203125, Entropy 41.65569305419922, Learning Rate: 0.01\n",
      "Epoch [1457/20000], Loss: 1195.0404052734375, Entropy 23.819135665893555, Learning Rate: 0.01\n",
      "Epoch [1458/20000], Loss: 1111.94189453125, Entropy 34.899349212646484, Learning Rate: 0.01\n",
      "Epoch [1459/20000], Loss: 1189.77734375, Entropy 37.43485641479492, Learning Rate: 0.01\n",
      "Epoch [1460/20000], Loss: 1184.462646484375, Entropy 22.91897964477539, Learning Rate: 0.01\n",
      "Epoch [1461/20000], Loss: 1122.6881103515625, Entropy 47.88997268676758, Learning Rate: 0.01\n",
      "Epoch [1462/20000], Loss: 1164.846923828125, Entropy 33.32704162597656, Learning Rate: 0.01\n",
      "Epoch [1463/20000], Loss: 1163.59716796875, Entropy 24.35926628112793, Learning Rate: 0.01\n",
      "Epoch [1464/20000], Loss: 1147.1868896484375, Entropy 39.3017463684082, Learning Rate: 0.01\n",
      "Epoch [1465/20000], Loss: 1196.3597412109375, Entropy 24.93891143798828, Learning Rate: 0.01\n",
      "Epoch [1466/20000], Loss: 1129.68310546875, Entropy 40.78670883178711, Learning Rate: 0.01\n",
      "Epoch [1467/20000], Loss: 1156.7904052734375, Entropy 39.889923095703125, Learning Rate: 0.01\n",
      "Epoch [1468/20000], Loss: 1140.162353515625, Entropy 34.10614013671875, Learning Rate: 0.01\n",
      "Epoch [1469/20000], Loss: 1163.633544921875, Entropy 17.179229736328125, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1470/20000], Loss: 1191.2596435546875, Entropy 40.42884063720703, Learning Rate: 0.01\n",
      "Epoch [1471/20000], Loss: 1169.237060546875, Entropy 36.607948303222656, Learning Rate: 0.01\n",
      "Epoch [1472/20000], Loss: 1181.0701904296875, Entropy 43.40963363647461, Learning Rate: 0.01\n",
      "Epoch [1473/20000], Loss: 1128.5115966796875, Entropy 52.50603485107422, Learning Rate: 0.01\n",
      "Epoch [1474/20000], Loss: 1122.4041748046875, Entropy 34.44355773925781, Learning Rate: 0.01\n",
      "Epoch [1475/20000], Loss: 1173.3992919921875, Entropy 21.261098861694336, Learning Rate: 0.01\n",
      "Epoch [1476/20000], Loss: 1138.798095703125, Entropy 45.12257766723633, Learning Rate: 0.01\n",
      "Epoch [1477/20000], Loss: 1179.23583984375, Entropy 37.591880798339844, Learning Rate: 0.01\n",
      "Epoch [1478/20000], Loss: 1175.2838134765625, Entropy 32.54233169555664, Learning Rate: 0.01\n",
      "Epoch [1479/20000], Loss: 1199.7437744140625, Entropy 23.596914291381836, Learning Rate: 0.01\n",
      "Epoch [1480/20000], Loss: 1170.3343505859375, Entropy 36.872798919677734, Learning Rate: 0.01\n",
      "Epoch [1481/20000], Loss: 1141.693603515625, Entropy 36.136505126953125, Learning Rate: 0.01\n",
      "Epoch [1482/20000], Loss: 1146.80078125, Entropy 40.12632369995117, Learning Rate: 0.01\n",
      "Epoch [1483/20000], Loss: 1172.2412109375, Entropy 44.08089828491211, Learning Rate: 0.01\n",
      "Epoch [1484/20000], Loss: 1141.039794921875, Entropy 32.18626403808594, Learning Rate: 0.01\n",
      "Epoch [1485/20000], Loss: 1193.68701171875, Entropy 34.03592300415039, Learning Rate: 0.01\n",
      "Epoch [1486/20000], Loss: 1147.160888671875, Entropy 42.07114791870117, Learning Rate: 0.01\n",
      "Epoch [1487/20000], Loss: 1161.548583984375, Entropy 21.02692413330078, Learning Rate: 0.01\n",
      "Epoch [1488/20000], Loss: 1188.54345703125, Entropy 51.85786819458008, Learning Rate: 0.01\n",
      "Epoch [1489/20000], Loss: 1139.4896240234375, Entropy 42.558475494384766, Learning Rate: 0.01\n",
      "Epoch [1490/20000], Loss: 1144.8389892578125, Entropy 43.66514587402344, Learning Rate: 0.01\n",
      "Epoch [1491/20000], Loss: 1205.640869140625, Entropy 10.475019454956055, Learning Rate: 0.01\n",
      "Epoch [1492/20000], Loss: 1151.809814453125, Entropy 44.90142059326172, Learning Rate: 0.01\n",
      "Epoch [1493/20000], Loss: 1189.673828125, Entropy 45.249725341796875, Learning Rate: 0.01\n",
      "Epoch [1494/20000], Loss: 1178.78564453125, Entropy 28.285545349121094, Learning Rate: 0.01\n",
      "Epoch [1495/20000], Loss: 1134.4276123046875, Entropy 49.20175552368164, Learning Rate: 0.01\n",
      "Epoch [1496/20000], Loss: 1193.6123046875, Entropy 40.01606750488281, Learning Rate: 0.01\n",
      "Epoch [1497/20000], Loss: 1249.4385986328125, Entropy 45.42665100097656, Learning Rate: 0.01\n",
      "Epoch [1498/20000], Loss: 1176.5362548828125, Entropy 40.55585479736328, Learning Rate: 0.01\n",
      "Epoch [1499/20000], Loss: 1246.5743408203125, Entropy 48.24711227416992, Learning Rate: 0.01\n",
      "Epoch [1500/20000], Loss: 1191.74169921875, Entropy 38.778987884521484, Learning Rate: 0.01\n",
      "Epoch [1501/20000], Loss: 1174.2542724609375, Entropy 32.954830169677734, Learning Rate: 0.01\n",
      "Epoch [1502/20000], Loss: 1141.4796142578125, Entropy 42.365394592285156, Learning Rate: 0.01\n",
      "Epoch [1503/20000], Loss: 1166.3515625, Entropy 47.90470504760742, Learning Rate: 0.01\n",
      "Epoch [1504/20000], Loss: 1179.01171875, Entropy 40.466121673583984, Learning Rate: 0.01\n",
      "Epoch [1505/20000], Loss: 1247.9996337890625, Entropy 33.035728454589844, Learning Rate: 0.01\n",
      "Epoch [1506/20000], Loss: 1140.1639404296875, Entropy 35.03578186035156, Learning Rate: 0.01\n",
      "Epoch [1507/20000], Loss: 1151.5699462890625, Entropy 46.550994873046875, Learning Rate: 0.01\n",
      "Epoch [1508/20000], Loss: 1108.408447265625, Entropy 40.75669479370117, Learning Rate: 0.01\n",
      "Epoch [1509/20000], Loss: 1168.2645263671875, Entropy 30.099321365356445, Learning Rate: 0.01\n",
      "Epoch [1510/20000], Loss: 1177.5009765625, Entropy 46.347412109375, Learning Rate: 0.01\n",
      "Epoch [1511/20000], Loss: 1147.537109375, Entropy 44.73772048950195, Learning Rate: 0.01\n",
      "Epoch [1512/20000], Loss: 1117.3231201171875, Entropy 43.90420913696289, Learning Rate: 0.01\n",
      "Epoch [1513/20000], Loss: 1166.6282958984375, Entropy 39.5198860168457, Learning Rate: 0.01\n",
      "Epoch [1514/20000], Loss: 1161.534912109375, Entropy 44.76972198486328, Learning Rate: 0.01\n",
      "Epoch [1515/20000], Loss: 1186.6829833984375, Entropy 55.892913818359375, Learning Rate: 0.01\n",
      "Epoch [1516/20000], Loss: 1127.2880859375, Entropy 61.8035774230957, Learning Rate: 0.01\n",
      "Epoch [1517/20000], Loss: 1121.6529541015625, Entropy 41.611053466796875, Learning Rate: 0.01\n",
      "Epoch [1518/20000], Loss: 1157.1864013671875, Entropy 43.829017639160156, Learning Rate: 0.01\n",
      "Epoch [1519/20000], Loss: 1161.4183349609375, Entropy 45.45100402832031, Learning Rate: 0.01\n",
      "Epoch [1520/20000], Loss: 1158.9803466796875, Entropy 51.96158218383789, Learning Rate: 0.01\n",
      "Epoch [1521/20000], Loss: 1155.805908203125, Entropy 54.32375717163086, Learning Rate: 0.01\n",
      "Epoch [1522/20000], Loss: 1144.7894287109375, Entropy 51.94965362548828, Learning Rate: 0.01\n",
      "Epoch [1523/20000], Loss: 1154.3125, Entropy 37.22488784790039, Learning Rate: 0.01\n",
      "Epoch [1524/20000], Loss: 1195.381103515625, Entropy 40.32391357421875, Learning Rate: 0.01\n",
      "Epoch [1525/20000], Loss: 1133.9615478515625, Entropy 47.83271789550781, Learning Rate: 0.01\n",
      "Epoch [1526/20000], Loss: 1146.31396484375, Entropy 54.65435791015625, Learning Rate: 0.01\n",
      "Epoch [1527/20000], Loss: 1139.93994140625, Entropy 40.07704544067383, Learning Rate: 0.01\n",
      "Epoch [1528/20000], Loss: 1173.1026611328125, Entropy 53.1149787902832, Learning Rate: 0.01\n",
      "Epoch [1529/20000], Loss: 1160.739990234375, Entropy 53.97900390625, Learning Rate: 0.01\n",
      "Epoch [1530/20000], Loss: 1163.1629638671875, Entropy 52.02723693847656, Learning Rate: 0.01\n",
      "Epoch [1531/20000], Loss: 1125.547607421875, Entropy 54.70066452026367, Learning Rate: 0.01\n",
      "Epoch [1532/20000], Loss: 1154.4158935546875, Entropy 48.00118637084961, Learning Rate: 0.01\n",
      "Epoch [1533/20000], Loss: 1166.1187744140625, Entropy 57.687469482421875, Learning Rate: 0.01\n",
      "Epoch [1534/20000], Loss: 1216.44921875, Entropy 34.59267807006836, Learning Rate: 0.01\n",
      "Epoch [1535/20000], Loss: 1123.8433837890625, Entropy 53.27621078491211, Learning Rate: 0.01\n",
      "Epoch [1536/20000], Loss: 1250.2579345703125, Entropy 57.71251678466797, Learning Rate: 0.01\n",
      "Epoch [1537/20000], Loss: 1161.1334228515625, Entropy 53.007694244384766, Learning Rate: 0.01\n",
      "Epoch [1538/20000], Loss: 1294.5345458984375, Entropy 43.63132858276367, Learning Rate: 0.01\n",
      "Epoch [1539/20000], Loss: 1155.8233642578125, Entropy 47.64322280883789, Learning Rate: 0.01\n",
      "Epoch [1540/20000], Loss: 1243.27880859375, Entropy 49.45887756347656, Learning Rate: 0.01\n",
      "Epoch [1541/20000], Loss: 1156.990966796875, Entropy 43.86248779296875, Learning Rate: 0.01\n",
      "Epoch [1542/20000], Loss: 1239.93017578125, Entropy 57.12176513671875, Learning Rate: 0.01\n",
      "Epoch [1543/20000], Loss: 1164.5013427734375, Entropy 55.68511199951172, Learning Rate: 0.01\n",
      "Epoch [1544/20000], Loss: 1229.1751708984375, Entropy 40.85057067871094, Learning Rate: 0.01\n",
      "Epoch [1545/20000], Loss: 1250.1566162109375, Entropy 54.73278045654297, Learning Rate: 0.01\n",
      "Epoch [1546/20000], Loss: 1193.18994140625, Entropy 48.85378646850586, Learning Rate: 0.01\n",
      "Epoch [1547/20000], Loss: 1327.5286865234375, Entropy 33.3031005859375, Learning Rate: 0.01\n",
      "Epoch [1548/20000], Loss: 1313.775634765625, Entropy 48.04768753051758, Learning Rate: 0.01\n",
      "Epoch [1549/20000], Loss: 1217.572265625, Entropy 35.94194793701172, Learning Rate: 0.01\n",
      "Epoch [1550/20000], Loss: 1400.15478515625, Entropy 48.27265930175781, Learning Rate: 0.01\n",
      "Epoch [1551/20000], Loss: 1211.7684326171875, Entropy 54.07107925415039, Learning Rate: 0.01\n",
      "Epoch [1552/20000], Loss: 1360.5047607421875, Entropy 52.92569351196289, Learning Rate: 0.01\n",
      "Epoch [1553/20000], Loss: 1295.794921875, Entropy 43.9808349609375, Learning Rate: 0.01\n",
      "Epoch [1554/20000], Loss: 1287.2288818359375, Entropy 46.900760650634766, Learning Rate: 0.01\n",
      "Epoch [1555/20000], Loss: 1274.433837890625, Entropy 52.80009460449219, Learning Rate: 0.01\n",
      "Epoch [1556/20000], Loss: 1286.80322265625, Entropy 48.52070236206055, Learning Rate: 0.01\n",
      "Epoch [1557/20000], Loss: 1353.596923828125, Entropy 59.50921630859375, Learning Rate: 0.01\n",
      "Epoch [1558/20000], Loss: 1309.2320556640625, Entropy 50.61851119995117, Learning Rate: 0.01\n",
      "Epoch [1559/20000], Loss: 1489.0003662109375, Entropy 57.600379943847656, Learning Rate: 0.01\n",
      "Epoch [1560/20000], Loss: 1368.982177734375, Entropy 36.44218826293945, Learning Rate: 0.01\n",
      "Epoch [1561/20000], Loss: 1483.841796875, Entropy 41.10660171508789, Learning Rate: 0.01\n",
      "Epoch [1562/20000], Loss: 1386.6513671875, Entropy 47.35607147216797, Learning Rate: 0.01\n",
      "Epoch [1563/20000], Loss: 1564.64794921875, Entropy 52.949462890625, Learning Rate: 0.01\n",
      "Epoch [1564/20000], Loss: 1565.80078125, Entropy 46.93707275390625, Learning Rate: 0.01\n",
      "Epoch [1565/20000], Loss: 1411.0562744140625, Entropy 44.96479415893555, Learning Rate: 0.01\n",
      "Epoch [1566/20000], Loss: 1304.35986328125, Entropy 41.46319580078125, Learning Rate: 0.01\n",
      "Epoch [1567/20000], Loss: 1344.290283203125, Entropy 40.40519332885742, Learning Rate: 0.01\n",
      "Epoch [1568/20000], Loss: 1342.7889404296875, Entropy 40.417640686035156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1569/20000], Loss: 1374.9085693359375, Entropy 51.06199264526367, Learning Rate: 0.01\n",
      "Epoch [1570/20000], Loss: 1457.9085693359375, Entropy 48.17400360107422, Learning Rate: 0.01\n",
      "Epoch [1571/20000], Loss: 1199.1763916015625, Entropy 56.662376403808594, Learning Rate: 0.01\n",
      "Epoch [1572/20000], Loss: 1255.649169921875, Entropy 45.61473083496094, Learning Rate: 0.01\n",
      "Epoch [1573/20000], Loss: 1270.70556640625, Entropy 39.51274108886719, Learning Rate: 0.01\n",
      "Epoch [1574/20000], Loss: 1202.611572265625, Entropy 40.54389190673828, Learning Rate: 0.01\n",
      "Epoch [1575/20000], Loss: 1260.568115234375, Entropy 52.446311950683594, Learning Rate: 0.01\n",
      "Epoch [1576/20000], Loss: 1195.258056640625, Entropy 49.58601379394531, Learning Rate: 0.01\n",
      "Epoch [1577/20000], Loss: 1233.7947998046875, Entropy 35.13193130493164, Learning Rate: 0.01\n",
      "Epoch [1578/20000], Loss: 1262.9949951171875, Entropy 41.6039924621582, Learning Rate: 0.01\n",
      "Epoch [1579/20000], Loss: 1242.5218505859375, Entropy 44.58864212036133, Learning Rate: 0.01\n",
      "Epoch [1580/20000], Loss: 1224.663818359375, Entropy 55.29616928100586, Learning Rate: 0.01\n",
      "Epoch [1581/20000], Loss: 1191.06201171875, Entropy 49.71646499633789, Learning Rate: 0.01\n",
      "Epoch [1582/20000], Loss: 1211.6309814453125, Entropy 45.31022262573242, Learning Rate: 0.01\n",
      "Epoch [1583/20000], Loss: 1266.4532470703125, Entropy 41.01713180541992, Learning Rate: 0.01\n",
      "Epoch [1584/20000], Loss: 1145.763671875, Entropy 65.41326904296875, Learning Rate: 0.01\n",
      "Epoch [1585/20000], Loss: 1220.90478515625, Entropy 48.26093673706055, Learning Rate: 0.01\n",
      "Epoch [1586/20000], Loss: 1213.285888671875, Entropy 45.40476608276367, Learning Rate: 0.01\n",
      "Epoch [1587/20000], Loss: 1228.8341064453125, Entropy 36.14409637451172, Learning Rate: 0.01\n",
      "Epoch [1588/20000], Loss: 1176.475830078125, Entropy 48.16525650024414, Learning Rate: 0.01\n",
      "Epoch [1589/20000], Loss: 1192.194091796875, Entropy 54.744930267333984, Learning Rate: 0.01\n",
      "Epoch [1590/20000], Loss: 1137.4166259765625, Entropy 50.22706604003906, Learning Rate: 0.01\n",
      "Epoch [1591/20000], Loss: 1166.38623046875, Entropy 40.42799377441406, Learning Rate: 0.01\n",
      "Epoch [1592/20000], Loss: 1194.3385009765625, Entropy 39.9450798034668, Learning Rate: 0.01\n",
      "Epoch [1593/20000], Loss: 1188.7119140625, Entropy 40.44976806640625, Learning Rate: 0.01\n",
      "Epoch [1594/20000], Loss: 1125.9322509765625, Entropy 54.46965026855469, Learning Rate: 0.01\n",
      "Epoch [1595/20000], Loss: 1159.3436279296875, Entropy 49.928260803222656, Learning Rate: 0.01\n",
      "Epoch [1596/20000], Loss: 1144.63916015625, Entropy 55.811214447021484, Learning Rate: 0.01\n",
      "Epoch [1597/20000], Loss: 1143.72509765625, Entropy 45.00975799560547, Learning Rate: 0.01\n",
      "Epoch [1598/20000], Loss: 1223.0413818359375, Entropy 61.24030685424805, Learning Rate: 0.01\n",
      "Epoch [1599/20000], Loss: 1191.2899169921875, Entropy 48.15978240966797, Learning Rate: 0.01\n",
      "Epoch [1600/20000], Loss: 1194.545654296875, Entropy 42.62933349609375, Learning Rate: 0.01\n",
      "Epoch [1601/20000], Loss: 1167.292724609375, Entropy 56.246795654296875, Learning Rate: 0.01\n",
      "Epoch [1602/20000], Loss: 1125.1544189453125, Entropy 52.16358184814453, Learning Rate: 0.01\n",
      "Epoch [1603/20000], Loss: 1155.1424560546875, Entropy 47.34689712524414, Learning Rate: 0.01\n",
      "Epoch [1604/20000], Loss: 1162.8900146484375, Entropy 48.58352279663086, Learning Rate: 0.01\n",
      "Epoch [1605/20000], Loss: 1130.58935546875, Entropy 58.59067153930664, Learning Rate: 0.01\n",
      "Epoch [1606/20000], Loss: 1145.1444091796875, Entropy 42.161834716796875, Learning Rate: 0.01\n",
      "Epoch [1607/20000], Loss: 1143.0072021484375, Entropy 52.990814208984375, Learning Rate: 0.01\n",
      "Epoch [1608/20000], Loss: 1129.0408935546875, Entropy 53.305564880371094, Learning Rate: 0.01\n",
      "Epoch [1609/20000], Loss: 1142.6663818359375, Entropy 39.39772415161133, Learning Rate: 0.01\n",
      "Epoch [1610/20000], Loss: 1138.690185546875, Entropy 56.81087875366211, Learning Rate: 0.01\n",
      "Epoch [1611/20000], Loss: 1144.53515625, Entropy 59.96638870239258, Learning Rate: 0.01\n",
      "Epoch [1612/20000], Loss: 1145.3043212890625, Entropy 53.62376403808594, Learning Rate: 0.01\n",
      "Epoch [1613/20000], Loss: 1094.012451171875, Entropy 51.10418701171875, Learning Rate: 0.01\n",
      "Epoch [1614/20000], Loss: 1088.9783935546875, Entropy 48.55704116821289, Learning Rate: 0.01\n",
      "Epoch [1615/20000], Loss: 1149.8175048828125, Entropy 37.1307258605957, Learning Rate: 0.01\n",
      "Epoch [1616/20000], Loss: 1175.8388671875, Entropy 49.75879669189453, Learning Rate: 0.01\n",
      "Epoch [1617/20000], Loss: 1127.8084716796875, Entropy 51.36892318725586, Learning Rate: 0.01\n",
      "Epoch [1618/20000], Loss: 1165.8431396484375, Entropy 55.02849578857422, Learning Rate: 0.01\n",
      "Epoch [1619/20000], Loss: 1170.8363037109375, Entropy 44.73975372314453, Learning Rate: 0.01\n",
      "Epoch [1620/20000], Loss: 1119.7728271484375, Entropy 49.93225860595703, Learning Rate: 0.01\n",
      "Epoch [1621/20000], Loss: 1115.9609375, Entropy 47.48617935180664, Learning Rate: 0.01\n",
      "Epoch [1622/20000], Loss: 1141.036865234375, Entropy 64.95561218261719, Learning Rate: 0.01\n",
      "Epoch [1623/20000], Loss: 1121.957763671875, Entropy 57.08541488647461, Learning Rate: 0.01\n",
      "Epoch [1624/20000], Loss: 1168.1585693359375, Entropy 67.55623626708984, Learning Rate: 0.01\n",
      "Epoch [1625/20000], Loss: 1130.3192138671875, Entropy 66.84418487548828, Learning Rate: 0.01\n",
      "Epoch [1626/20000], Loss: 1135.6953125, Entropy 52.470096588134766, Learning Rate: 0.01\n",
      "Epoch [1627/20000], Loss: 1114.3126220703125, Entropy 65.53548431396484, Learning Rate: 0.01\n",
      "Epoch [1628/20000], Loss: 1135.4290771484375, Entropy 56.45063400268555, Learning Rate: 0.01\n",
      "Epoch [1629/20000], Loss: 1208.2576904296875, Entropy 37.318973541259766, Learning Rate: 0.01\n",
      "Epoch [1630/20000], Loss: 1176.2333984375, Entropy 49.17764663696289, Learning Rate: 0.01\n",
      "Epoch [1631/20000], Loss: 1158.47314453125, Entropy 51.61116409301758, Learning Rate: 0.01\n",
      "Epoch [1632/20000], Loss: 1152.0074462890625, Entropy 59.7861213684082, Learning Rate: 0.01\n",
      "Epoch [1633/20000], Loss: 1126.3851318359375, Entropy 69.78934478759766, Learning Rate: 0.01\n",
      "Epoch [1634/20000], Loss: 1173.727294921875, Entropy 56.34920883178711, Learning Rate: 0.01\n",
      "Epoch [1635/20000], Loss: 1120.6201171875, Entropy 62.07027053833008, Learning Rate: 0.01\n",
      "Epoch [1636/20000], Loss: 1150.46533203125, Entropy 68.07180786132812, Learning Rate: 0.01\n",
      "Epoch [1637/20000], Loss: 1156.2857666015625, Entropy 53.94906234741211, Learning Rate: 0.01\n",
      "Epoch [1638/20000], Loss: 1167.1837158203125, Entropy 49.56514358520508, Learning Rate: 0.01\n",
      "Epoch [1639/20000], Loss: 1117.3001708984375, Entropy 75.56448364257812, Learning Rate: 0.01\n",
      "Epoch [1640/20000], Loss: 1130.53369140625, Entropy 58.6143913269043, Learning Rate: 0.01\n",
      "Epoch [1641/20000], Loss: 1136.320556640625, Entropy 61.89155960083008, Learning Rate: 0.01\n",
      "Epoch [1642/20000], Loss: 1147.5400390625, Entropy 57.74180221557617, Learning Rate: 0.01\n",
      "Epoch [1643/20000], Loss: 1132.515380859375, Entropy 60.01887130737305, Learning Rate: 0.01\n",
      "Epoch [1644/20000], Loss: 1136.0709228515625, Entropy 52.69801712036133, Learning Rate: 0.01\n",
      "Epoch [1645/20000], Loss: 1136.126953125, Entropy 54.20296859741211, Learning Rate: 0.01\n",
      "Epoch [1646/20000], Loss: 1145.6556396484375, Entropy 57.15231704711914, Learning Rate: 0.01\n",
      "Epoch [1647/20000], Loss: 1172.5709228515625, Entropy 56.46724319458008, Learning Rate: 0.01\n",
      "Epoch [1648/20000], Loss: 1164.1239013671875, Entropy 71.09165954589844, Learning Rate: 0.01\n",
      "Epoch [1649/20000], Loss: 1125.6900634765625, Entropy 56.82553482055664, Learning Rate: 0.01\n",
      "Epoch [1650/20000], Loss: 1144.8975830078125, Entropy 73.77507019042969, Learning Rate: 0.01\n",
      "Epoch [1651/20000], Loss: 1164.0458984375, Entropy 63.765750885009766, Learning Rate: 0.01\n",
      "Epoch [1652/20000], Loss: 1153.231201171875, Entropy 66.81807708740234, Learning Rate: 0.01\n",
      "Epoch [1653/20000], Loss: 1153.9521484375, Entropy 60.8466796875, Learning Rate: 0.01\n",
      "Epoch [1654/20000], Loss: 1172.1513671875, Entropy 71.40300750732422, Learning Rate: 0.01\n",
      "Epoch [1655/20000], Loss: 1137.5543212890625, Entropy 62.92861557006836, Learning Rate: 0.01\n",
      "Epoch [1656/20000], Loss: 1165.7115478515625, Entropy 62.525150299072266, Learning Rate: 0.01\n",
      "Epoch [1657/20000], Loss: 1176.8150634765625, Entropy 66.40457916259766, Learning Rate: 0.01\n",
      "Epoch [1658/20000], Loss: 1072.2718505859375, Entropy 78.12939453125, Learning Rate: 0.01\n",
      "Epoch [1659/20000], Loss: 1134.0670166015625, Entropy 60.31968688964844, Learning Rate: 0.01\n",
      "Epoch [1660/20000], Loss: 1159.379638671875, Entropy 51.84656524658203, Learning Rate: 0.01\n",
      "Epoch [1661/20000], Loss: 1180.2496337890625, Entropy 50.09023666381836, Learning Rate: 0.01\n",
      "Epoch [1662/20000], Loss: 1136.952392578125, Entropy 64.0726089477539, Learning Rate: 0.01\n",
      "Epoch [1663/20000], Loss: 1139.4326171875, Entropy 72.02606964111328, Learning Rate: 0.01\n",
      "Epoch [1664/20000], Loss: 1096.1142578125, Entropy 70.47565460205078, Learning Rate: 0.01\n",
      "Epoch [1665/20000], Loss: 1163.071533203125, Entropy 73.98056030273438, Learning Rate: 0.01\n",
      "Epoch [1666/20000], Loss: 1160.844970703125, Entropy 61.97709655761719, Learning Rate: 0.01\n",
      "Epoch [1667/20000], Loss: 1160.528076171875, Entropy 68.82487487792969, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1668/20000], Loss: 1151.832763671875, Entropy 64.66053771972656, Learning Rate: 0.01\n",
      "Epoch [1669/20000], Loss: 1125.0662841796875, Entropy 72.83049011230469, Learning Rate: 0.01\n",
      "Epoch [1670/20000], Loss: 1163.7801513671875, Entropy 52.38936233520508, Learning Rate: 0.01\n",
      "Epoch [1671/20000], Loss: 1136.620849609375, Entropy 65.81414794921875, Learning Rate: 0.01\n",
      "Epoch [1672/20000], Loss: 1167.027099609375, Entropy 64.41658020019531, Learning Rate: 0.01\n",
      "Epoch [1673/20000], Loss: 1150.3651123046875, Entropy 71.76222229003906, Learning Rate: 0.01\n",
      "Epoch [1674/20000], Loss: 1147.738525390625, Entropy 64.26493072509766, Learning Rate: 0.01\n",
      "Epoch [1675/20000], Loss: 1135.32275390625, Entropy 61.22714614868164, Learning Rate: 0.01\n",
      "Epoch [1676/20000], Loss: 1226.9388427734375, Entropy 71.92134857177734, Learning Rate: 0.01\n",
      "Epoch [1677/20000], Loss: 1230.746826171875, Entropy 68.7297592163086, Learning Rate: 0.01\n",
      "Epoch [1678/20000], Loss: 1184.45068359375, Entropy 45.97257614135742, Learning Rate: 0.01\n",
      "Epoch [1679/20000], Loss: 1141.5286865234375, Entropy 63.15515899658203, Learning Rate: 0.01\n",
      "Epoch [1680/20000], Loss: 1193.847412109375, Entropy 75.13640594482422, Learning Rate: 0.01\n",
      "Epoch [1681/20000], Loss: 1199.9796142578125, Entropy 62.2423210144043, Learning Rate: 0.01\n",
      "Epoch [1682/20000], Loss: 1148.1024169921875, Entropy 61.59696578979492, Learning Rate: 0.01\n",
      "Epoch [1683/20000], Loss: 1181.725341796875, Entropy 83.63924407958984, Learning Rate: 0.01\n",
      "Epoch [1684/20000], Loss: 1303.69775390625, Entropy 58.32903289794922, Learning Rate: 0.01\n",
      "Epoch [1685/20000], Loss: 1227.719482421875, Entropy 55.86679458618164, Learning Rate: 0.01\n",
      "Epoch [1686/20000], Loss: 1404.07080078125, Entropy 62.445613861083984, Learning Rate: 0.01\n",
      "Epoch [1687/20000], Loss: 1169.274169921875, Entropy 52.02169418334961, Learning Rate: 0.01\n",
      "Epoch [1688/20000], Loss: 1245.48193359375, Entropy 62.40699005126953, Learning Rate: 0.01\n",
      "Epoch [1689/20000], Loss: 1295.6688232421875, Entropy 58.36266326904297, Learning Rate: 0.01\n",
      "Epoch [1690/20000], Loss: 1417.2738037109375, Entropy 82.91693878173828, Learning Rate: 0.01\n",
      "Epoch [1691/20000], Loss: 1260.139404296875, Entropy 73.29530334472656, Learning Rate: 0.01\n",
      "Epoch [1692/20000], Loss: 1315.744384765625, Entropy 73.69837951660156, Learning Rate: 0.01\n",
      "Epoch [1693/20000], Loss: 1331.2767333984375, Entropy 58.68783187866211, Learning Rate: 0.01\n",
      "Epoch [1694/20000], Loss: 1327.33642578125, Entropy 66.2529067993164, Learning Rate: 0.01\n",
      "Epoch [1695/20000], Loss: 1245.911865234375, Entropy 51.7672004699707, Learning Rate: 0.01\n",
      "Epoch [1696/20000], Loss: 1443.5537109375, Entropy 56.76179885864258, Learning Rate: 0.01\n",
      "Epoch [1697/20000], Loss: 1249.616943359375, Entropy 58.843055725097656, Learning Rate: 0.01\n",
      "Epoch [1698/20000], Loss: 1209.3800048828125, Entropy 68.56211853027344, Learning Rate: 0.01\n",
      "Epoch [1699/20000], Loss: 1306.2628173828125, Entropy 73.21379089355469, Learning Rate: 0.01\n",
      "Epoch [1700/20000], Loss: 1255.853515625, Entropy 50.86399459838867, Learning Rate: 0.01\n",
      "Epoch [1701/20000], Loss: 1166.2886962890625, Entropy 74.00948333740234, Learning Rate: 0.01\n",
      "Epoch [1702/20000], Loss: 1261.35888671875, Entropy 62.05342483520508, Learning Rate: 0.01\n",
      "Epoch [1703/20000], Loss: 1249.090087890625, Entropy 71.93575286865234, Learning Rate: 0.01\n",
      "Epoch [1704/20000], Loss: 1205.6708984375, Entropy 69.35124206542969, Learning Rate: 0.01\n",
      "Epoch [1705/20000], Loss: 1226.9306640625, Entropy 62.376747131347656, Learning Rate: 0.01\n",
      "Epoch [1706/20000], Loss: 1137.238037109375, Entropy 70.95993041992188, Learning Rate: 0.01\n",
      "Epoch [1707/20000], Loss: 1153.43896484375, Entropy 59.22203063964844, Learning Rate: 0.01\n",
      "Epoch [1708/20000], Loss: 1181.2772216796875, Entropy 62.88454818725586, Learning Rate: 0.01\n",
      "Epoch [1709/20000], Loss: 1176.1962890625, Entropy 61.50734329223633, Learning Rate: 0.01\n",
      "Epoch [1710/20000], Loss: 1207.8460693359375, Entropy 64.96195983886719, Learning Rate: 0.01\n",
      "Epoch [1711/20000], Loss: 1168.5369873046875, Entropy 49.23665237426758, Learning Rate: 0.01\n",
      "Epoch [1712/20000], Loss: 1244.300537109375, Entropy 48.7430305480957, Learning Rate: 0.01\n",
      "Epoch [1713/20000], Loss: 1139.1329345703125, Entropy 69.52448272705078, Learning Rate: 0.01\n",
      "Epoch [1714/20000], Loss: 1207.244140625, Entropy 53.575931549072266, Learning Rate: 0.01\n",
      "Epoch [1715/20000], Loss: 1142.3258056640625, Entropy 65.55144500732422, Learning Rate: 0.01\n",
      "Epoch [1716/20000], Loss: 1085.9033203125, Entropy 80.64910888671875, Learning Rate: 0.01\n",
      "Epoch [1717/20000], Loss: 1146.4327392578125, Entropy 48.88444137573242, Learning Rate: 0.01\n",
      "Epoch [1718/20000], Loss: 1163.0042724609375, Entropy 66.45838928222656, Learning Rate: 0.01\n",
      "Epoch [1719/20000], Loss: 1145.5830078125, Entropy 71.9962158203125, Learning Rate: 0.01\n",
      "Epoch [1720/20000], Loss: 1206.685791015625, Entropy 58.39695358276367, Learning Rate: 0.01\n",
      "Epoch [1721/20000], Loss: 1156.644287109375, Entropy 66.02287292480469, Learning Rate: 0.01\n",
      "Epoch [1722/20000], Loss: 1196.048095703125, Entropy 59.67287063598633, Learning Rate: 0.01\n",
      "Epoch [1723/20000], Loss: 1176.4742431640625, Entropy 77.974609375, Learning Rate: 0.01\n",
      "Epoch [1724/20000], Loss: 1143.6925048828125, Entropy 69.20205688476562, Learning Rate: 0.01\n",
      "Epoch [1725/20000], Loss: 1206.48046875, Entropy 70.75447845458984, Learning Rate: 0.01\n",
      "Epoch [1726/20000], Loss: 1234.046875, Entropy 73.9426498413086, Learning Rate: 0.01\n",
      "Epoch [1727/20000], Loss: 1136.0604248046875, Entropy 66.61122131347656, Learning Rate: 0.01\n",
      "Epoch [1728/20000], Loss: 1308.9669189453125, Entropy 61.87792205810547, Learning Rate: 0.01\n",
      "Epoch [1729/20000], Loss: 1204.7706298828125, Entropy 55.101863861083984, Learning Rate: 0.01\n",
      "Epoch [1730/20000], Loss: 1277.1195068359375, Entropy 62.05912399291992, Learning Rate: 0.01\n",
      "Epoch [1731/20000], Loss: 1180.5966796875, Entropy 70.18280792236328, Learning Rate: 0.01\n",
      "Epoch [1732/20000], Loss: 1284.352294921875, Entropy 66.50408172607422, Learning Rate: 0.01\n",
      "Epoch [1733/20000], Loss: 1171.5709228515625, Entropy 65.29425811767578, Learning Rate: 0.01\n",
      "Epoch [1734/20000], Loss: 1250.228759765625, Entropy 77.81816864013672, Learning Rate: 0.01\n",
      "Epoch [1735/20000], Loss: 1215.984619140625, Entropy 76.82398986816406, Learning Rate: 0.01\n",
      "Epoch [1736/20000], Loss: 1198.606689453125, Entropy 71.40438079833984, Learning Rate: 0.01\n",
      "Epoch [1737/20000], Loss: 1153.141357421875, Entropy 63.55658721923828, Learning Rate: 0.01\n",
      "Epoch [1738/20000], Loss: 1303.8590087890625, Entropy 72.44913482666016, Learning Rate: 0.01\n",
      "Epoch [1739/20000], Loss: 1203.0809326171875, Entropy 74.16092681884766, Learning Rate: 0.01\n",
      "Epoch [1740/20000], Loss: 1346.334716796875, Entropy 48.89148712158203, Learning Rate: 0.01\n",
      "Epoch [1741/20000], Loss: 1208.3197021484375, Entropy 55.07985305786133, Learning Rate: 0.01\n",
      "Epoch [1742/20000], Loss: 1172.6015625, Entropy 70.93294525146484, Learning Rate: 0.01\n",
      "Epoch [1743/20000], Loss: 1169.76953125, Entropy 69.48822021484375, Learning Rate: 0.01\n",
      "Epoch [1744/20000], Loss: 1174.873291015625, Entropy 62.44110870361328, Learning Rate: 0.01\n",
      "Epoch [1745/20000], Loss: 1187.714599609375, Entropy 52.10700225830078, Learning Rate: 0.01\n",
      "Epoch [1746/20000], Loss: 1164.3818359375, Entropy 66.50507354736328, Learning Rate: 0.01\n",
      "Epoch [1747/20000], Loss: 1113.738037109375, Entropy 71.77601623535156, Learning Rate: 0.01\n",
      "Epoch [1748/20000], Loss: 1168.4991455078125, Entropy 61.43737030029297, Learning Rate: 0.01\n",
      "Epoch [1749/20000], Loss: 1098.5806884765625, Entropy 74.85505676269531, Learning Rate: 0.01\n",
      "Epoch [1750/20000], Loss: 1141.3133544921875, Entropy 71.75392150878906, Learning Rate: 0.01\n",
      "Epoch [1751/20000], Loss: 1129.7728271484375, Entropy 69.62672424316406, Learning Rate: 0.01\n",
      "Epoch [1752/20000], Loss: 1158.6724853515625, Entropy 69.53614807128906, Learning Rate: 0.01\n",
      "Epoch [1753/20000], Loss: 1111.0357666015625, Entropy 73.48482513427734, Learning Rate: 0.01\n",
      "Epoch [1754/20000], Loss: 1143.2076416015625, Entropy 59.24565124511719, Learning Rate: 0.01\n",
      "Epoch [1755/20000], Loss: 1115.37109375, Entropy 66.70152282714844, Learning Rate: 0.01\n",
      "Epoch [1756/20000], Loss: 1111.880615234375, Entropy 72.74234008789062, Learning Rate: 0.01\n",
      "Epoch [1757/20000], Loss: 1115.3489990234375, Entropy 78.28123474121094, Learning Rate: 0.01\n",
      "Epoch [1758/20000], Loss: 1195.8846435546875, Entropy 71.90821838378906, Learning Rate: 0.01\n",
      "Epoch [1759/20000], Loss: 1085.74951171875, Entropy 82.01828002929688, Learning Rate: 0.01\n",
      "Epoch [1760/20000], Loss: 1184.958984375, Entropy 79.51873779296875, Learning Rate: 0.01\n",
      "Epoch [1761/20000], Loss: 1113.9154052734375, Entropy 66.74713897705078, Learning Rate: 0.01\n",
      "Epoch [1762/20000], Loss: 1169.603759765625, Entropy 70.21513366699219, Learning Rate: 0.01\n",
      "Epoch [1763/20000], Loss: 1171.2596435546875, Entropy 66.689697265625, Learning Rate: 0.01\n",
      "Epoch [1764/20000], Loss: 1136.3524169921875, Entropy 69.31548309326172, Learning Rate: 0.01\n",
      "Epoch [1765/20000], Loss: 1110.7032470703125, Entropy 67.83753967285156, Learning Rate: 0.01\n",
      "Epoch [1766/20000], Loss: 1119.2633056640625, Entropy 83.87904357910156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1767/20000], Loss: 1123.81494140625, Entropy 66.60319519042969, Learning Rate: 0.01\n",
      "Epoch [1768/20000], Loss: 1154.1251220703125, Entropy 70.09040069580078, Learning Rate: 0.01\n",
      "Epoch [1769/20000], Loss: 1109.5382080078125, Entropy 75.9444580078125, Learning Rate: 0.01\n",
      "Epoch [1770/20000], Loss: 1136.6207275390625, Entropy 76.27076721191406, Learning Rate: 0.01\n",
      "Epoch [1771/20000], Loss: 1125.97265625, Entropy 87.43751525878906, Learning Rate: 0.01\n",
      "Epoch [1772/20000], Loss: 1120.179443359375, Entropy 72.88023376464844, Learning Rate: 0.01\n",
      "Epoch [1773/20000], Loss: 1114.2047119140625, Entropy 84.9273452758789, Learning Rate: 0.01\n",
      "Epoch [1774/20000], Loss: 1229.05419921875, Entropy 52.02545928955078, Learning Rate: 0.01\n",
      "Epoch [1775/20000], Loss: 1368.6844482421875, Entropy 64.6465835571289, Learning Rate: 0.01\n",
      "Epoch [1776/20000], Loss: 1189.045166015625, Entropy 60.375457763671875, Learning Rate: 0.01\n",
      "Epoch [1777/20000], Loss: 1200.499755859375, Entropy 71.86327362060547, Learning Rate: 0.01\n",
      "Epoch [1778/20000], Loss: 1218.18115234375, Entropy 77.48472595214844, Learning Rate: 0.01\n",
      "Epoch [1779/20000], Loss: 1155.9798583984375, Entropy 80.58999633789062, Learning Rate: 0.01\n",
      "Epoch [1780/20000], Loss: 1172.1871337890625, Entropy 68.72451782226562, Learning Rate: 0.01\n",
      "Epoch [1781/20000], Loss: 1220.500732421875, Entropy 69.40129852294922, Learning Rate: 0.01\n",
      "Epoch [1782/20000], Loss: 1110.368408203125, Entropy 72.9452133178711, Learning Rate: 0.01\n",
      "Epoch [1783/20000], Loss: 1273.649169921875, Entropy 63.147186279296875, Learning Rate: 0.01\n",
      "Epoch [1784/20000], Loss: 1175.0001220703125, Entropy 52.93148422241211, Learning Rate: 0.01\n",
      "Epoch [1785/20000], Loss: 1145.990478515625, Entropy 73.66744995117188, Learning Rate: 0.01\n",
      "Epoch [1786/20000], Loss: 1159.9739990234375, Entropy 78.37939453125, Learning Rate: 0.01\n",
      "Epoch [1787/20000], Loss: 1184.101806640625, Entropy 68.8390121459961, Learning Rate: 0.01\n",
      "Epoch [1788/20000], Loss: 1127.0880126953125, Entropy 71.57008361816406, Learning Rate: 0.01\n",
      "Epoch [1789/20000], Loss: 1191.4166259765625, Entropy 82.11824798583984, Learning Rate: 0.01\n",
      "Epoch [1790/20000], Loss: 1163.9600830078125, Entropy 84.25202941894531, Learning Rate: 0.01\n",
      "Epoch [1791/20000], Loss: 1132.0775146484375, Entropy 78.31568908691406, Learning Rate: 0.01\n",
      "Epoch [1792/20000], Loss: 1158.5206298828125, Entropy 70.80719757080078, Learning Rate: 0.01\n",
      "Epoch [1793/20000], Loss: 1193.0479736328125, Entropy 78.08260345458984, Learning Rate: 0.01\n",
      "Epoch [1794/20000], Loss: 1184.50341796875, Entropy 77.07058715820312, Learning Rate: 0.01\n",
      "Epoch [1795/20000], Loss: 1224.712158203125, Entropy 61.85866165161133, Learning Rate: 0.01\n",
      "Epoch [1796/20000], Loss: 1173.1229248046875, Entropy 67.86577606201172, Learning Rate: 0.01\n",
      "Epoch [1797/20000], Loss: 1173.547119140625, Entropy 58.19049072265625, Learning Rate: 0.01\n",
      "Epoch [1798/20000], Loss: 1104.4100341796875, Entropy 72.80921936035156, Learning Rate: 0.01\n",
      "Epoch [1799/20000], Loss: 1139.9505615234375, Entropy 86.77434539794922, Learning Rate: 0.01\n",
      "Epoch [1800/20000], Loss: 1131.767822265625, Entropy 68.6922836303711, Learning Rate: 0.01\n",
      "Epoch [1801/20000], Loss: 1103.2659912109375, Entropy 76.57572937011719, Learning Rate: 0.01\n",
      "Epoch [1802/20000], Loss: 1128.43603515625, Entropy 80.64900970458984, Learning Rate: 0.01\n",
      "Epoch [1803/20000], Loss: 1114.9095458984375, Entropy 78.67215728759766, Learning Rate: 0.01\n",
      "Epoch [1804/20000], Loss: 1137.35400390625, Entropy 84.8304214477539, Learning Rate: 0.01\n",
      "Epoch [1805/20000], Loss: 1117.7625732421875, Entropy 67.96849060058594, Learning Rate: 0.01\n",
      "Epoch [1806/20000], Loss: 1155.7247314453125, Entropy 80.81352233886719, Learning Rate: 0.01\n",
      "Epoch [1807/20000], Loss: 1103.120849609375, Entropy 77.05270385742188, Learning Rate: 0.01\n",
      "Epoch [1808/20000], Loss: 1092.19970703125, Entropy 83.33158111572266, Learning Rate: 0.01\n",
      "Epoch [1809/20000], Loss: 1139.2177734375, Entropy 66.43902587890625, Learning Rate: 0.01\n",
      "Epoch [1810/20000], Loss: 1126.420654296875, Entropy 92.43528747558594, Learning Rate: 0.01\n",
      "Epoch [1811/20000], Loss: 1092.7940673828125, Entropy 84.74729919433594, Learning Rate: 0.01\n",
      "Epoch [1812/20000], Loss: 1134.4561767578125, Entropy 76.48332214355469, Learning Rate: 0.01\n",
      "Epoch [1813/20000], Loss: 1105.024169921875, Entropy 81.89817810058594, Learning Rate: 0.01\n",
      "Epoch [1814/20000], Loss: 1079.87060546875, Entropy 97.13920593261719, Learning Rate: 0.01\n",
      "Epoch [1815/20000], Loss: 1158.583251953125, Entropy 92.4523696899414, Learning Rate: 0.01\n",
      "Epoch [1816/20000], Loss: 1118.214599609375, Entropy 93.75584411621094, Learning Rate: 0.01\n",
      "Epoch [1817/20000], Loss: 1173.9893798828125, Entropy 90.39419555664062, Learning Rate: 0.01\n",
      "Epoch [1818/20000], Loss: 1100.115966796875, Entropy 82.69110107421875, Learning Rate: 0.01\n",
      "Epoch [1819/20000], Loss: 1105.8717041015625, Entropy 76.99227142333984, Learning Rate: 0.01\n",
      "Epoch [1820/20000], Loss: 1106.1995849609375, Entropy 79.17436218261719, Learning Rate: 0.01\n",
      "Epoch [1821/20000], Loss: 1129.6417236328125, Entropy 85.48650360107422, Learning Rate: 0.01\n",
      "Epoch [1822/20000], Loss: 1190.42724609375, Entropy 69.77440643310547, Learning Rate: 0.01\n",
      "Epoch [1823/20000], Loss: 1124.338623046875, Entropy 75.02325439453125, Learning Rate: 0.01\n",
      "Epoch [1824/20000], Loss: 1132.50341796875, Entropy 70.12822723388672, Learning Rate: 0.01\n",
      "Epoch [1825/20000], Loss: 1089.0511474609375, Entropy 89.435546875, Learning Rate: 0.01\n",
      "Epoch [1826/20000], Loss: 1132.6068115234375, Entropy 71.48375701904297, Learning Rate: 0.01\n",
      "Epoch [1827/20000], Loss: 1099.6644287109375, Entropy 73.37345123291016, Learning Rate: 0.01\n",
      "Epoch [1828/20000], Loss: 1122.12158203125, Entropy 91.19852447509766, Learning Rate: 0.01\n",
      "Epoch [1829/20000], Loss: 1127.5281982421875, Entropy 84.19601440429688, Learning Rate: 0.01\n",
      "Epoch [1830/20000], Loss: 1109.117431640625, Entropy 85.18303680419922, Learning Rate: 0.01\n",
      "Epoch [1831/20000], Loss: 1146.0865478515625, Entropy 80.67452239990234, Learning Rate: 0.01\n",
      "Epoch [1832/20000], Loss: 1121.2640380859375, Entropy 78.47748565673828, Learning Rate: 0.01\n",
      "Epoch [1833/20000], Loss: 1158.1507568359375, Entropy 73.8533706665039, Learning Rate: 0.01\n",
      "Epoch [1834/20000], Loss: 1122.5457763671875, Entropy 78.41643524169922, Learning Rate: 0.01\n",
      "Epoch [1835/20000], Loss: 1134.736083984375, Entropy 86.6834716796875, Learning Rate: 0.01\n",
      "Epoch [1836/20000], Loss: 1129.8885498046875, Entropy 78.57596588134766, Learning Rate: 0.01\n",
      "Epoch [1837/20000], Loss: 1147.574462890625, Entropy 81.74978637695312, Learning Rate: 0.01\n",
      "Epoch [1838/20000], Loss: 1115.7904052734375, Entropy 89.3157958984375, Learning Rate: 0.01\n",
      "Epoch [1839/20000], Loss: 1128.80322265625, Entropy 86.45169830322266, Learning Rate: 0.01\n",
      "Epoch [1840/20000], Loss: 1105.2548828125, Entropy 81.49445343017578, Learning Rate: 0.01\n",
      "Epoch [1841/20000], Loss: 1102.3114013671875, Entropy 94.58935546875, Learning Rate: 0.01\n",
      "Epoch [1842/20000], Loss: 1089.498291015625, Entropy 86.00921630859375, Learning Rate: 0.01\n",
      "Epoch [1843/20000], Loss: 1160.4007568359375, Entropy 95.9690933227539, Learning Rate: 0.01\n",
      "Epoch [1844/20000], Loss: 1104.9224853515625, Entropy 82.68017578125, Learning Rate: 0.01\n",
      "Epoch [1845/20000], Loss: 1175.899169921875, Entropy 85.01820373535156, Learning Rate: 0.01\n",
      "Epoch [1846/20000], Loss: 1076.075439453125, Entropy 95.85482025146484, Learning Rate: 0.01\n",
      "Epoch [1847/20000], Loss: 1119.9423828125, Entropy 75.62818145751953, Learning Rate: 0.01\n",
      "Epoch [1848/20000], Loss: 1100.684326171875, Entropy 95.21967315673828, Learning Rate: 0.01\n",
      "Epoch [1849/20000], Loss: 1142.865966796875, Entropy 81.62349700927734, Learning Rate: 0.01\n",
      "Epoch [1850/20000], Loss: 1141.2498779296875, Entropy 81.12135314941406, Learning Rate: 0.01\n",
      "Epoch [1851/20000], Loss: 1129.59814453125, Entropy 73.27132415771484, Learning Rate: 0.01\n",
      "Epoch [1852/20000], Loss: 1118.6474609375, Entropy 80.32585906982422, Learning Rate: 0.01\n",
      "Epoch [1853/20000], Loss: 1150.478271484375, Entropy 76.24263763427734, Learning Rate: 0.01\n",
      "Epoch [1854/20000], Loss: 1094.8004150390625, Entropy 83.32488250732422, Learning Rate: 0.01\n",
      "Epoch [1855/20000], Loss: 1113.806396484375, Entropy 101.87902069091797, Learning Rate: 0.01\n",
      "Epoch [1856/20000], Loss: 1060.699951171875, Entropy 101.43659973144531, Learning Rate: 0.01\n",
      "Epoch [1857/20000], Loss: 1129.314697265625, Entropy 72.54493713378906, Learning Rate: 0.01\n",
      "Epoch [1858/20000], Loss: 1135.607666015625, Entropy 93.46096801757812, Learning Rate: 0.01\n",
      "Epoch [1859/20000], Loss: 1105.8702392578125, Entropy 81.05187225341797, Learning Rate: 0.01\n",
      "Epoch [1860/20000], Loss: 1118.127197265625, Entropy 81.75, Learning Rate: 0.01\n",
      "Epoch [1861/20000], Loss: 1134.774658203125, Entropy 90.22259521484375, Learning Rate: 0.01\n",
      "Epoch [1862/20000], Loss: 1082.9942626953125, Entropy 94.1485824584961, Learning Rate: 0.01\n",
      "Epoch [1863/20000], Loss: 1094.0562744140625, Entropy 84.4593505859375, Learning Rate: 0.01\n",
      "Epoch [1864/20000], Loss: 1118.0716552734375, Entropy 80.87586975097656, Learning Rate: 0.01\n",
      "Epoch [1865/20000], Loss: 1115.03466796875, Entropy 94.18802642822266, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1866/20000], Loss: 1109.2989501953125, Entropy 98.1709976196289, Learning Rate: 0.01\n",
      "Epoch [1867/20000], Loss: 1127.234619140625, Entropy 75.46217346191406, Learning Rate: 0.01\n",
      "Epoch [1868/20000], Loss: 1059.259033203125, Entropy 94.03079986572266, Learning Rate: 0.01\n",
      "Epoch [1869/20000], Loss: 1088.4141845703125, Entropy 102.53784942626953, Learning Rate: 0.01\n",
      "Epoch [1870/20000], Loss: 1089.15283203125, Entropy 98.7496566772461, Learning Rate: 0.01\n",
      "Epoch [1871/20000], Loss: 1139.395751953125, Entropy 79.69364929199219, Learning Rate: 0.01\n",
      "Epoch [1872/20000], Loss: 1101.32373046875, Entropy 92.28977966308594, Learning Rate: 0.01\n",
      "Epoch [1873/20000], Loss: 1071.0196533203125, Entropy 97.41739654541016, Learning Rate: 0.01\n",
      "Epoch [1874/20000], Loss: 1100.210205078125, Entropy 86.56612396240234, Learning Rate: 0.01\n",
      "Epoch [1875/20000], Loss: 1088.212890625, Entropy 97.39810180664062, Learning Rate: 0.01\n",
      "Epoch [1876/20000], Loss: 1165.315673828125, Entropy 76.1139144897461, Learning Rate: 0.01\n",
      "Epoch [1877/20000], Loss: 1165.0849609375, Entropy 100.10017395019531, Learning Rate: 0.01\n",
      "Epoch [1878/20000], Loss: 1162.7762451171875, Entropy 80.89676666259766, Learning Rate: 0.01\n",
      "Epoch [1879/20000], Loss: 1203.0657958984375, Entropy 89.47732543945312, Learning Rate: 0.01\n",
      "Epoch [1880/20000], Loss: 1164.205810546875, Entropy 92.0240707397461, Learning Rate: 0.01\n",
      "Epoch [1881/20000], Loss: 1138.633544921875, Entropy 95.94424438476562, Learning Rate: 0.01\n",
      "Epoch [1882/20000], Loss: 1108.660888671875, Entropy 85.15351104736328, Learning Rate: 0.01\n",
      "Epoch [1883/20000], Loss: 1171.5740966796875, Entropy 100.38048553466797, Learning Rate: 0.01\n",
      "Epoch [1884/20000], Loss: 1144.546875, Entropy 97.66887664794922, Learning Rate: 0.01\n",
      "Epoch [1885/20000], Loss: 1192.787353515625, Entropy 91.58880615234375, Learning Rate: 0.01\n",
      "Epoch [1886/20000], Loss: 1195.8134765625, Entropy 94.05553436279297, Learning Rate: 0.01\n",
      "Epoch [1887/20000], Loss: 1126.4464111328125, Entropy 94.90409851074219, Learning Rate: 0.01\n",
      "Epoch [1888/20000], Loss: 1210.40087890625, Entropy 112.63163757324219, Learning Rate: 0.01\n",
      "Epoch [1889/20000], Loss: 1126.35302734375, Entropy 92.03778839111328, Learning Rate: 0.01\n",
      "Epoch [1890/20000], Loss: 1273.365478515625, Entropy 102.04302215576172, Learning Rate: 0.01\n",
      "Epoch [1891/20000], Loss: 1237.758056640625, Entropy 95.24822235107422, Learning Rate: 0.01\n",
      "Epoch [1892/20000], Loss: 1226.01416015625, Entropy 109.80120849609375, Learning Rate: 0.01\n",
      "Epoch [1893/20000], Loss: 1179.0810546875, Entropy 103.2901611328125, Learning Rate: 0.01\n",
      "Epoch [1894/20000], Loss: 1238.261962890625, Entropy 97.42012786865234, Learning Rate: 0.01\n",
      "Epoch [1895/20000], Loss: 1179.973388671875, Entropy 92.30262756347656, Learning Rate: 0.01\n",
      "Epoch [1896/20000], Loss: 1248.0491943359375, Entropy 96.19608306884766, Learning Rate: 0.01\n",
      "Epoch [1897/20000], Loss: 1350.025390625, Entropy 101.33612823486328, Learning Rate: 0.01\n",
      "Epoch [1898/20000], Loss: 1135.2841796875, Entropy 102.56257629394531, Learning Rate: 0.01\n",
      "Epoch [1899/20000], Loss: 1541.4034423828125, Entropy 91.55913543701172, Learning Rate: 0.01\n",
      "Epoch [1900/20000], Loss: 1139.8404541015625, Entropy 96.3902359008789, Learning Rate: 0.01\n",
      "Epoch [1901/20000], Loss: 1549.6805419921875, Entropy 98.91127014160156, Learning Rate: 0.01\n",
      "Epoch [1902/20000], Loss: 1233.030029296875, Entropy 99.18435668945312, Learning Rate: 0.01\n",
      "Epoch [1903/20000], Loss: 1513.1324462890625, Entropy 86.28028869628906, Learning Rate: 0.01\n",
      "Epoch [1904/20000], Loss: 1222.81591796875, Entropy 85.78028869628906, Learning Rate: 0.01\n",
      "Epoch [1905/20000], Loss: 1644.5518798828125, Entropy 92.4761734008789, Learning Rate: 0.01\n",
      "Epoch [1906/20000], Loss: 1389.324462890625, Entropy 88.28909301757812, Learning Rate: 0.01\n",
      "Epoch [1907/20000], Loss: 1293.300048828125, Entropy 97.25418090820312, Learning Rate: 0.01\n",
      "Epoch [1908/20000], Loss: 1383.146728515625, Entropy 86.57845306396484, Learning Rate: 0.01\n",
      "Epoch [1909/20000], Loss: 1302.4659423828125, Entropy 92.09327697753906, Learning Rate: 0.01\n",
      "Epoch [1910/20000], Loss: 1305.3839111328125, Entropy 92.40126037597656, Learning Rate: 0.01\n",
      "Epoch [1911/20000], Loss: 1411.61865234375, Entropy 93.73410034179688, Learning Rate: 0.01\n",
      "Epoch [1912/20000], Loss: 1297.4730224609375, Entropy 92.64693450927734, Learning Rate: 0.01\n",
      "Epoch [1913/20000], Loss: 1562.9537353515625, Entropy 99.04922485351562, Learning Rate: 0.01\n",
      "Epoch [1914/20000], Loss: 1456.8126220703125, Entropy 84.65776824951172, Learning Rate: 0.01\n",
      "Epoch [1915/20000], Loss: 1484.38720703125, Entropy 83.1705093383789, Learning Rate: 0.01\n",
      "Epoch [1916/20000], Loss: 1485.795166015625, Entropy 92.51042938232422, Learning Rate: 0.01\n",
      "Epoch [1917/20000], Loss: 1245.94482421875, Entropy 77.85419464111328, Learning Rate: 0.01\n",
      "Epoch [1918/20000], Loss: 1470.325927734375, Entropy 94.26155090332031, Learning Rate: 0.01\n",
      "Epoch [1919/20000], Loss: 1320.797119140625, Entropy 79.10009765625, Learning Rate: 0.01\n",
      "Epoch [1920/20000], Loss: 1174.11669921875, Entropy 88.73919677734375, Learning Rate: 0.01\n",
      "Epoch [1921/20000], Loss: 1436.1761474609375, Entropy 76.8501205444336, Learning Rate: 0.01\n",
      "Epoch [1922/20000], Loss: 1228.3211669921875, Entropy 95.90587615966797, Learning Rate: 0.01\n",
      "Epoch [1923/20000], Loss: 1255.9656982421875, Entropy 86.89369201660156, Learning Rate: 0.01\n",
      "Epoch [1924/20000], Loss: 1307.4493408203125, Entropy 77.54312133789062, Learning Rate: 0.01\n",
      "Epoch [1925/20000], Loss: 1148.4107666015625, Entropy 94.4405517578125, Learning Rate: 0.01\n",
      "Epoch [1926/20000], Loss: 1331.8460693359375, Entropy 98.43074035644531, Learning Rate: 0.01\n",
      "Epoch [1927/20000], Loss: 1195.9373779296875, Entropy 87.19268035888672, Learning Rate: 0.01\n",
      "Epoch [1928/20000], Loss: 1282.7734375, Entropy 86.95966339111328, Learning Rate: 0.01\n",
      "Epoch [1929/20000], Loss: 1203.9962158203125, Entropy 89.06047821044922, Learning Rate: 0.01\n",
      "Epoch [1930/20000], Loss: 1147.368896484375, Entropy 77.1381607055664, Learning Rate: 0.01\n",
      "Epoch [1931/20000], Loss: 1264.44677734375, Entropy 80.13752746582031, Learning Rate: 0.01\n",
      "Epoch [1932/20000], Loss: 1158.157470703125, Entropy 92.12175750732422, Learning Rate: 0.01\n",
      "Epoch [1933/20000], Loss: 1121.428955078125, Entropy 106.98564147949219, Learning Rate: 0.01\n",
      "Epoch [1934/20000], Loss: 1169.529052734375, Entropy 90.10694122314453, Learning Rate: 0.01\n",
      "Epoch [1935/20000], Loss: 1118.620849609375, Entropy 87.541748046875, Learning Rate: 0.01\n",
      "Epoch [1936/20000], Loss: 1243.654541015625, Entropy 86.87902069091797, Learning Rate: 0.01\n",
      "Epoch [1937/20000], Loss: 1164.6171875, Entropy 87.61808776855469, Learning Rate: 0.01\n",
      "Epoch [1938/20000], Loss: 1164.233642578125, Entropy 98.11663818359375, Learning Rate: 0.01\n",
      "Epoch [1939/20000], Loss: 1174.95947265625, Entropy 91.49945068359375, Learning Rate: 0.01\n",
      "Epoch [1940/20000], Loss: 1105.0133056640625, Entropy 79.99058532714844, Learning Rate: 0.01\n",
      "Epoch [1941/20000], Loss: 1168.431396484375, Entropy 89.47422790527344, Learning Rate: 0.01\n",
      "Epoch [1942/20000], Loss: 1173.3760986328125, Entropy 79.83051300048828, Learning Rate: 0.01\n",
      "Epoch [1943/20000], Loss: 1168.1361083984375, Entropy 93.43785095214844, Learning Rate: 0.01\n",
      "Epoch [1944/20000], Loss: 1167.2928466796875, Entropy 91.25746154785156, Learning Rate: 0.01\n",
      "Epoch [1945/20000], Loss: 1278.8160400390625, Entropy 94.30016326904297, Learning Rate: 0.01\n",
      "Epoch [1946/20000], Loss: 1128.042724609375, Entropy 83.56595611572266, Learning Rate: 0.01\n",
      "Epoch [1947/20000], Loss: 1145.747314453125, Entropy 90.28395080566406, Learning Rate: 0.01\n",
      "Epoch [1948/20000], Loss: 1196.6910400390625, Entropy 96.44734191894531, Learning Rate: 0.01\n",
      "Epoch [1949/20000], Loss: 1116.871826171875, Entropy 92.26764678955078, Learning Rate: 0.01\n",
      "Epoch [1950/20000], Loss: 1103.7392578125, Entropy 78.00727081298828, Learning Rate: 0.01\n",
      "Epoch [1951/20000], Loss: 1196.8780517578125, Entropy 78.63340759277344, Learning Rate: 0.01\n",
      "Epoch [1952/20000], Loss: 1168.8359375, Entropy 80.84276580810547, Learning Rate: 0.01\n",
      "Epoch [1953/20000], Loss: 1131.9638671875, Entropy 97.64321899414062, Learning Rate: 0.01\n",
      "Epoch [1954/20000], Loss: 1111.428466796875, Entropy 84.92776489257812, Learning Rate: 0.01\n",
      "Epoch [1955/20000], Loss: 1216.2708740234375, Entropy 68.23748016357422, Learning Rate: 0.01\n",
      "Epoch [1956/20000], Loss: 1151.41943359375, Entropy 85.49469757080078, Learning Rate: 0.01\n",
      "Epoch [1957/20000], Loss: 1419.697265625, Entropy 66.84403228759766, Learning Rate: 0.01\n",
      "Epoch [1958/20000], Loss: 1167.6121826171875, Entropy 102.87601470947266, Learning Rate: 0.01\n",
      "Epoch [1959/20000], Loss: 1297.149658203125, Entropy 101.99095153808594, Learning Rate: 0.01\n",
      "Epoch [1960/20000], Loss: 1207.0906982421875, Entropy 100.4385986328125, Learning Rate: 0.01\n",
      "Epoch [1961/20000], Loss: 1171.3240966796875, Entropy 83.550048828125, Learning Rate: 0.01\n",
      "Epoch [1962/20000], Loss: 1160.9613037109375, Entropy 88.85205078125, Learning Rate: 0.01\n",
      "Epoch [1963/20000], Loss: 1275.612060546875, Entropy 89.5704574584961, Learning Rate: 0.01\n",
      "Epoch [1964/20000], Loss: 1188.8568115234375, Entropy 74.20233917236328, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1965/20000], Loss: 1657.1004638671875, Entropy 86.3756103515625, Learning Rate: 0.01\n",
      "Epoch [1966/20000], Loss: 1219.8450927734375, Entropy 94.58634185791016, Learning Rate: 0.01\n",
      "Epoch [1967/20000], Loss: 1837.504638671875, Entropy 84.50814056396484, Learning Rate: 0.01\n",
      "Epoch [1968/20000], Loss: 1166.8966064453125, Entropy 83.01651000976562, Learning Rate: 0.01\n",
      "Epoch [1969/20000], Loss: 1764.7935791015625, Entropy 88.9369125366211, Learning Rate: 0.01\n",
      "Epoch [1970/20000], Loss: 1168.1431884765625, Entropy 84.82279205322266, Learning Rate: 0.01\n",
      "Epoch [1971/20000], Loss: 1653.9681396484375, Entropy 84.05374145507812, Learning Rate: 0.01\n",
      "Epoch [1972/20000], Loss: 1352.8648681640625, Entropy 90.27212524414062, Learning Rate: 0.01\n",
      "Epoch [1973/20000], Loss: 1475.9212646484375, Entropy 98.4799575805664, Learning Rate: 0.01\n",
      "Epoch [1974/20000], Loss: 1797.98779296875, Entropy 86.0683364868164, Learning Rate: 0.01\n",
      "Epoch [1975/20000], Loss: 1913.3624267578125, Entropy 88.811279296875, Learning Rate: 0.01\n",
      "Epoch [1976/20000], Loss: 1481.85791015625, Entropy 85.2928466796875, Learning Rate: 0.01\n",
      "Epoch [1977/20000], Loss: 1346.0113525390625, Entropy 90.04698181152344, Learning Rate: 0.01\n",
      "Epoch [1978/20000], Loss: 1921.0947265625, Entropy 75.57182312011719, Learning Rate: 0.01\n",
      "Epoch [1979/20000], Loss: 1249.387939453125, Entropy 87.2416000366211, Learning Rate: 0.01\n",
      "Epoch [1980/20000], Loss: 2056.029052734375, Entropy 94.18342590332031, Learning Rate: 0.01\n",
      "Epoch [1981/20000], Loss: 1301.77685546875, Entropy 75.74349212646484, Learning Rate: 0.01\n",
      "Epoch [1982/20000], Loss: 2649.534912109375, Entropy 77.64178466796875, Learning Rate: 0.01\n",
      "Epoch [1983/20000], Loss: 1361.53662109375, Entropy 78.69073486328125, Learning Rate: 0.01\n",
      "Epoch [1984/20000], Loss: 2474.437744140625, Entropy 78.58416748046875, Learning Rate: 0.01\n",
      "Epoch [1985/20000], Loss: 1303.7293701171875, Entropy 88.62834167480469, Learning Rate: 0.01\n",
      "Epoch [1986/20000], Loss: 2189.371826171875, Entropy 61.8278694152832, Learning Rate: 0.01\n",
      "Epoch [1987/20000], Loss: 1401.7159423828125, Entropy 84.53422546386719, Learning Rate: 0.01\n",
      "Epoch [1988/20000], Loss: 1801.20361328125, Entropy 80.8199462890625, Learning Rate: 0.01\n",
      "Epoch [1989/20000], Loss: 1179.425537109375, Entropy 71.64715576171875, Learning Rate: 0.01\n",
      "Epoch [1990/20000], Loss: 1628.7052001953125, Entropy 78.99411010742188, Learning Rate: 0.01\n",
      "Epoch [1991/20000], Loss: 1425.4102783203125, Entropy 65.95350646972656, Learning Rate: 0.01\n",
      "Epoch [1992/20000], Loss: 1609.7401123046875, Entropy 62.853607177734375, Learning Rate: 0.01\n",
      "Epoch [1993/20000], Loss: 1590.8507080078125, Entropy 80.07625579833984, Learning Rate: 0.01\n",
      "Epoch [1994/20000], Loss: 1411.6829833984375, Entropy 79.60575866699219, Learning Rate: 0.01\n",
      "Epoch [1995/20000], Loss: 1670.9984130859375, Entropy 66.86540222167969, Learning Rate: 0.01\n",
      "Epoch [1996/20000], Loss: 1745.568359375, Entropy 63.65550231933594, Learning Rate: 0.01\n",
      "Epoch [1997/20000], Loss: 1482.366455078125, Entropy 72.14161682128906, Learning Rate: 0.01\n",
      "Epoch [1998/20000], Loss: 2011.879638671875, Entropy 47.41962432861328, Learning Rate: 0.01\n",
      "Epoch [1999/20000], Loss: 1521.4749755859375, Entropy 64.15646362304688, Learning Rate: 0.01\n",
      "Epoch [2000/20000], Loss: 2002.444580078125, Entropy 65.80888366699219, Learning Rate: 0.01\n",
      "Epoch [2001/20000], Loss: 1745.9588623046875, Entropy 56.80453872680664, Learning Rate: 0.01\n",
      "Epoch [2002/20000], Loss: 1770.295166015625, Entropy 58.63535690307617, Learning Rate: 0.01\n",
      "Epoch [2003/20000], Loss: 1924.422607421875, Entropy 67.6014404296875, Learning Rate: 0.01\n",
      "Epoch [2004/20000], Loss: 1341.4114990234375, Entropy 61.527122497558594, Learning Rate: 0.01\n",
      "Epoch [2005/20000], Loss: 1635.0311279296875, Entropy 72.305908203125, Learning Rate: 0.01\n",
      "Epoch [2006/20000], Loss: 1640.422607421875, Entropy 66.74114227294922, Learning Rate: 0.01\n",
      "Epoch [2007/20000], Loss: 1275.38427734375, Entropy 59.43324661254883, Learning Rate: 0.01\n",
      "Epoch [2008/20000], Loss: 1428.84619140625, Entropy 56.702903747558594, Learning Rate: 0.01\n",
      "Epoch [2009/20000], Loss: 1626.1502685546875, Entropy 54.836669921875, Learning Rate: 0.01\n",
      "Epoch [2010/20000], Loss: 1137.447998046875, Entropy 42.39070129394531, Learning Rate: 0.01\n",
      "Epoch [2011/20000], Loss: 1560.6400146484375, Entropy 35.96401596069336, Learning Rate: 0.01\n",
      "Epoch [2012/20000], Loss: 1272.0823974609375, Entropy 44.23451232910156, Learning Rate: 0.01\n",
      "Epoch [2013/20000], Loss: 1255.5946044921875, Entropy 61.25395202636719, Learning Rate: 0.01\n",
      "Epoch [2014/20000], Loss: 1371.1077880859375, Entropy 52.57134246826172, Learning Rate: 0.01\n",
      "Epoch [2015/20000], Loss: 1315.2750244140625, Entropy 52.21517562866211, Learning Rate: 0.01\n",
      "Epoch [2016/20000], Loss: 1295.5673828125, Entropy 42.58585739135742, Learning Rate: 0.01\n",
      "Epoch [2017/20000], Loss: 1325.6031494140625, Entropy 66.87813568115234, Learning Rate: 0.01\n",
      "Epoch [2018/20000], Loss: 1321.5333251953125, Entropy 40.79429626464844, Learning Rate: 0.01\n",
      "Epoch [2019/20000], Loss: 1261.0506591796875, Entropy 49.00376892089844, Learning Rate: 0.01\n",
      "Epoch [2020/20000], Loss: 1286.572021484375, Entropy 33.5832405090332, Learning Rate: 0.01\n",
      "Epoch [2021/20000], Loss: 1245.16552734375, Entropy 45.49459457397461, Learning Rate: 0.01\n",
      "Epoch [2022/20000], Loss: 1199.6707763671875, Entropy 36.533103942871094, Learning Rate: 0.01\n",
      "Epoch [2023/20000], Loss: 1263.68798828125, Entropy 36.33268737792969, Learning Rate: 0.01\n",
      "Epoch [2024/20000], Loss: 1223.93603515625, Entropy 49.50752258300781, Learning Rate: 0.01\n",
      "Epoch [2025/20000], Loss: 1296.3538818359375, Entropy 40.67414855957031, Learning Rate: 0.01\n",
      "Epoch [2026/20000], Loss: 1229.6163330078125, Entropy 39.99833297729492, Learning Rate: 0.01\n",
      "Epoch [2027/20000], Loss: 1306.7091064453125, Entropy 41.585205078125, Learning Rate: 0.01\n",
      "Epoch [2028/20000], Loss: 1207.6944580078125, Entropy 53.65254592895508, Learning Rate: 0.01\n",
      "Epoch [2029/20000], Loss: 1174.2657470703125, Entropy 42.23928451538086, Learning Rate: 0.01\n",
      "Epoch [2030/20000], Loss: 1214.953369140625, Entropy 51.679744720458984, Learning Rate: 0.01\n",
      "Epoch [2031/20000], Loss: 1217.173583984375, Entropy 28.278451919555664, Learning Rate: 0.01\n",
      "Epoch [2032/20000], Loss: 1172.003173828125, Entropy 44.274559020996094, Learning Rate: 0.01\n",
      "Epoch [2033/20000], Loss: 1199.849853515625, Entropy 57.345672607421875, Learning Rate: 0.01\n",
      "Epoch [2034/20000], Loss: 1214.6292724609375, Entropy 25.55597686767578, Learning Rate: 0.01\n",
      "Epoch [2035/20000], Loss: 1195.56201171875, Entropy 32.47383117675781, Learning Rate: 0.01\n",
      "Epoch [2036/20000], Loss: 1161.694091796875, Entropy 56.36716842651367, Learning Rate: 0.01\n",
      "Epoch [2037/20000], Loss: 1201.2841796875, Entropy 46.069091796875, Learning Rate: 0.01\n",
      "Epoch [2038/20000], Loss: 1194.5224609375, Entropy 22.502704620361328, Learning Rate: 0.01\n",
      "Epoch [2039/20000], Loss: 1139.85205078125, Entropy 43.78874588012695, Learning Rate: 0.01\n",
      "Epoch [2040/20000], Loss: 1261.067626953125, Entropy 44.68647003173828, Learning Rate: 0.01\n",
      "Epoch [2041/20000], Loss: 1189.6343994140625, Entropy 32.77141189575195, Learning Rate: 0.01\n",
      "Epoch [2042/20000], Loss: 1168.8604736328125, Entropy 42.202293395996094, Learning Rate: 0.01\n",
      "Epoch [2043/20000], Loss: 1228.318359375, Entropy 32.188621520996094, Learning Rate: 0.01\n",
      "Epoch [2044/20000], Loss: 1164.141357421875, Entropy 37.01841735839844, Learning Rate: 0.01\n",
      "Epoch [2045/20000], Loss: 1175.59228515625, Entropy 59.98338317871094, Learning Rate: 0.01\n",
      "Epoch [2046/20000], Loss: 1154.0054931640625, Entropy 52.63947296142578, Learning Rate: 0.01\n",
      "Epoch [2047/20000], Loss: 1175.1611328125, Entropy 48.07159423828125, Learning Rate: 0.01\n",
      "Epoch [2048/20000], Loss: 1109.039306640625, Entropy 56.71884536743164, Learning Rate: 0.01\n",
      "Epoch [2049/20000], Loss: 1155.6824951171875, Entropy 50.2554931640625, Learning Rate: 0.01\n",
      "Epoch [2050/20000], Loss: 1156.3980712890625, Entropy 43.62055969238281, Learning Rate: 0.01\n",
      "Epoch [2051/20000], Loss: 1189.048583984375, Entropy 41.6064338684082, Learning Rate: 0.01\n",
      "Epoch [2052/20000], Loss: 1147.99462890625, Entropy 56.24268341064453, Learning Rate: 0.01\n",
      "Epoch [2053/20000], Loss: 1145.93603515625, Entropy 48.185829162597656, Learning Rate: 0.01\n",
      "Epoch [2054/20000], Loss: 1144.8408203125, Entropy 51.55389404296875, Learning Rate: 0.01\n",
      "Epoch [2055/20000], Loss: 1146.0726318359375, Entropy 56.63322067260742, Learning Rate: 0.01\n",
      "Epoch [2056/20000], Loss: 1116.109130859375, Entropy 49.42152786254883, Learning Rate: 0.01\n",
      "Epoch [2057/20000], Loss: 1174.7293701171875, Entropy 45.33849334716797, Learning Rate: 0.01\n",
      "Epoch [2058/20000], Loss: 1129.35302734375, Entropy 49.192928314208984, Learning Rate: 0.01\n",
      "Epoch [2059/20000], Loss: 1159.8822021484375, Entropy 38.39704132080078, Learning Rate: 0.01\n",
      "Epoch [2060/20000], Loss: 1179.3157958984375, Entropy 50.009159088134766, Learning Rate: 0.01\n",
      "Epoch [2061/20000], Loss: 1170.1231689453125, Entropy 38.66276931762695, Learning Rate: 0.01\n",
      "Epoch [2062/20000], Loss: 1148.311767578125, Entropy 46.17084884643555, Learning Rate: 0.01\n",
      "Epoch [2063/20000], Loss: 1167.23876953125, Entropy 53.525184631347656, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2064/20000], Loss: 1138.5272216796875, Entropy 44.62822341918945, Learning Rate: 0.01\n",
      "Epoch [2065/20000], Loss: 1142.9403076171875, Entropy 42.011199951171875, Learning Rate: 0.01\n",
      "Epoch [2066/20000], Loss: 1101.6531982421875, Entropy 59.799617767333984, Learning Rate: 0.01\n",
      "Epoch [2067/20000], Loss: 1146.6788330078125, Entropy 46.355751037597656, Learning Rate: 0.01\n",
      "Epoch [2068/20000], Loss: 1117.083251953125, Entropy 59.590946197509766, Learning Rate: 0.01\n",
      "Epoch [2069/20000], Loss: 1101.46533203125, Entropy 55.592166900634766, Learning Rate: 0.01\n",
      "Epoch [2070/20000], Loss: 1124.3828125, Entropy 50.018333435058594, Learning Rate: 0.01\n",
      "Epoch [2071/20000], Loss: 1120.0755615234375, Entropy 44.56114959716797, Learning Rate: 0.01\n",
      "Epoch [2072/20000], Loss: 1122.6807861328125, Entropy 41.219329833984375, Learning Rate: 0.01\n",
      "Epoch [2073/20000], Loss: 1105.3812255859375, Entropy 51.23972702026367, Learning Rate: 0.01\n",
      "Epoch [2074/20000], Loss: 1154.919921875, Entropy 40.46921920776367, Learning Rate: 0.01\n",
      "Epoch [2075/20000], Loss: 1118.48876953125, Entropy 60.901771545410156, Learning Rate: 0.01\n",
      "Epoch [2076/20000], Loss: 1135.7509765625, Entropy 59.18968963623047, Learning Rate: 0.01\n",
      "Epoch [2077/20000], Loss: 1143.779052734375, Entropy 62.26473617553711, Learning Rate: 0.01\n",
      "Epoch [2078/20000], Loss: 1108.1754150390625, Entropy 59.12395477294922, Learning Rate: 0.01\n",
      "Epoch [2079/20000], Loss: 1125.58544921875, Entropy 63.31935501098633, Learning Rate: 0.01\n",
      "Epoch [2080/20000], Loss: 1123.647705078125, Entropy 46.3604621887207, Learning Rate: 0.01\n",
      "Epoch [2081/20000], Loss: 1107.810546875, Entropy 53.226409912109375, Learning Rate: 0.01\n",
      "Epoch [2082/20000], Loss: 1131.1314697265625, Entropy 51.17412185668945, Learning Rate: 0.01\n",
      "Epoch [2083/20000], Loss: 1129.987548828125, Entropy 48.792850494384766, Learning Rate: 0.01\n",
      "Epoch [2084/20000], Loss: 1130.9989013671875, Entropy 60.43760681152344, Learning Rate: 0.01\n",
      "Epoch [2085/20000], Loss: 1135.202392578125, Entropy 56.35565185546875, Learning Rate: 0.01\n",
      "Epoch [2086/20000], Loss: 1095.30859375, Entropy 59.14643859863281, Learning Rate: 0.01\n",
      "Epoch [2087/20000], Loss: 1167.8187255859375, Entropy 48.19248962402344, Learning Rate: 0.01\n",
      "Epoch [2088/20000], Loss: 1100.4036865234375, Entropy 57.731536865234375, Learning Rate: 0.01\n",
      "Epoch [2089/20000], Loss: 1118.11474609375, Entropy 67.71409606933594, Learning Rate: 0.01\n",
      "Epoch [2090/20000], Loss: 1142.2030029296875, Entropy 52.75510787963867, Learning Rate: 0.01\n",
      "Epoch [2091/20000], Loss: 1111.7999267578125, Entropy 51.39808654785156, Learning Rate: 0.01\n",
      "Epoch [2092/20000], Loss: 1109.271240234375, Entropy 60.11700439453125, Learning Rate: 0.01\n",
      "Epoch [2093/20000], Loss: 1064.014404296875, Entropy 73.74394226074219, Learning Rate: 0.01\n",
      "Epoch [2094/20000], Loss: 1115.1685791015625, Entropy 41.21056365966797, Learning Rate: 0.01\n",
      "Epoch [2095/20000], Loss: 1142.62451171875, Entropy 56.76895523071289, Learning Rate: 0.01\n",
      "Epoch [2096/20000], Loss: 1089.2620849609375, Entropy 67.41024017333984, Learning Rate: 0.01\n",
      "Epoch [2097/20000], Loss: 1142.738525390625, Entropy 53.52932357788086, Learning Rate: 0.01\n",
      "Epoch [2098/20000], Loss: 1109.20068359375, Entropy 68.82042694091797, Learning Rate: 0.01\n",
      "Epoch [2099/20000], Loss: 1082.909912109375, Entropy 73.49579620361328, Learning Rate: 0.01\n",
      "Epoch [2100/20000], Loss: 1086.8323974609375, Entropy 65.7184829711914, Learning Rate: 0.01\n",
      "Epoch [2101/20000], Loss: 1100.74169921875, Entropy 64.18427276611328, Learning Rate: 0.01\n",
      "Epoch [2102/20000], Loss: 1109.012451171875, Entropy 71.8156967163086, Learning Rate: 0.01\n",
      "Epoch [2103/20000], Loss: 1087.62109375, Entropy 72.74748992919922, Learning Rate: 0.01\n",
      "Epoch [2104/20000], Loss: 1098.80322265625, Entropy 66.52228546142578, Learning Rate: 0.01\n",
      "Epoch [2105/20000], Loss: 1143.383544921875, Entropy 73.59242248535156, Learning Rate: 0.01\n",
      "Epoch [2106/20000], Loss: 1121.2586669921875, Entropy 66.3143310546875, Learning Rate: 0.01\n",
      "Epoch [2107/20000], Loss: 1094.6707763671875, Entropy 64.54535675048828, Learning Rate: 0.01\n",
      "Epoch [2108/20000], Loss: 1109.506591796875, Entropy 62.7490119934082, Learning Rate: 0.01\n",
      "Epoch [2109/20000], Loss: 1137.9202880859375, Entropy 61.38665008544922, Learning Rate: 0.01\n",
      "Epoch [2110/20000], Loss: 1111.9788818359375, Entropy 70.3257064819336, Learning Rate: 0.01\n",
      "Epoch [2111/20000], Loss: 1096.655517578125, Entropy 77.73954772949219, Learning Rate: 0.01\n",
      "Epoch [2112/20000], Loss: 1117.70556640625, Entropy 65.89002990722656, Learning Rate: 0.01\n",
      "Epoch [2113/20000], Loss: 1127.607421875, Entropy 73.88787078857422, Learning Rate: 0.01\n",
      "Epoch [2114/20000], Loss: 1120.092041015625, Entropy 55.85899353027344, Learning Rate: 0.01\n",
      "Epoch [2115/20000], Loss: 1133.8726806640625, Entropy 53.77255630493164, Learning Rate: 0.01\n",
      "Epoch [2116/20000], Loss: 1130.0906982421875, Entropy 50.25638961791992, Learning Rate: 0.01\n",
      "Epoch [2117/20000], Loss: 1135.76220703125, Entropy 58.13999557495117, Learning Rate: 0.01\n",
      "Epoch [2118/20000], Loss: 1124.2637939453125, Entropy 65.61888122558594, Learning Rate: 0.01\n",
      "Epoch [2119/20000], Loss: 1085.6336669921875, Entropy 74.64805603027344, Learning Rate: 0.01\n",
      "Epoch [2120/20000], Loss: 1075.2220458984375, Entropy 75.2010269165039, Learning Rate: 0.01\n",
      "Epoch [2121/20000], Loss: 1076.8033447265625, Entropy 83.76045989990234, Learning Rate: 0.01\n",
      "Epoch [2122/20000], Loss: 1079.403564453125, Entropy 86.47158813476562, Learning Rate: 0.01\n",
      "Epoch [2123/20000], Loss: 1144.311767578125, Entropy 70.07777404785156, Learning Rate: 0.01\n",
      "Epoch [2124/20000], Loss: 1111.0267333984375, Entropy 73.13862609863281, Learning Rate: 0.01\n",
      "Epoch [2125/20000], Loss: 1145.7303466796875, Entropy 70.05003356933594, Learning Rate: 0.01\n",
      "Epoch [2126/20000], Loss: 1105.7799072265625, Entropy 78.01077270507812, Learning Rate: 0.01\n",
      "Epoch [2127/20000], Loss: 1132.9681396484375, Entropy 83.921630859375, Learning Rate: 0.01\n",
      "Epoch [2128/20000], Loss: 1214.0789794921875, Entropy 58.77283477783203, Learning Rate: 0.01\n",
      "Epoch [2129/20000], Loss: 1111.8380126953125, Entropy 78.68704986572266, Learning Rate: 0.01\n",
      "Epoch [2130/20000], Loss: 1090.9835205078125, Entropy 75.41254425048828, Learning Rate: 0.01\n",
      "Epoch [2131/20000], Loss: 1110.3685302734375, Entropy 73.28799438476562, Learning Rate: 0.01\n",
      "Epoch [2132/20000], Loss: 1134.578857421875, Entropy 72.0592269897461, Learning Rate: 0.01\n",
      "Epoch [2133/20000], Loss: 1174.5155029296875, Entropy 80.43199157714844, Learning Rate: 0.01\n",
      "Epoch [2134/20000], Loss: 1114.2252197265625, Entropy 73.04373168945312, Learning Rate: 0.01\n",
      "Epoch [2135/20000], Loss: 1172.7808837890625, Entropy 80.04165649414062, Learning Rate: 0.01\n",
      "Epoch [2136/20000], Loss: 1118.75439453125, Entropy 82.8216781616211, Learning Rate: 0.01\n",
      "Epoch [2137/20000], Loss: 1130.1630859375, Entropy 87.75010681152344, Learning Rate: 0.01\n",
      "Epoch [2138/20000], Loss: 1117.407470703125, Entropy 83.24562072753906, Learning Rate: 0.01\n",
      "Epoch [2139/20000], Loss: 1118.3765869140625, Entropy 66.84040069580078, Learning Rate: 0.01\n",
      "Epoch [2140/20000], Loss: 1111.3365478515625, Entropy 81.8824234008789, Learning Rate: 0.01\n",
      "Epoch [2141/20000], Loss: 1090.06005859375, Entropy 81.99878692626953, Learning Rate: 0.01\n",
      "Epoch [2142/20000], Loss: 1176.83056640625, Entropy 85.95140075683594, Learning Rate: 0.01\n",
      "Epoch [2143/20000], Loss: 1132.593994140625, Entropy 97.11031341552734, Learning Rate: 0.01\n",
      "Epoch [2144/20000], Loss: 1117.137451171875, Entropy 75.96284484863281, Learning Rate: 0.01\n",
      "Epoch [2145/20000], Loss: 1103.2174072265625, Entropy 72.04108428955078, Learning Rate: 0.01\n",
      "Epoch [2146/20000], Loss: 1148.69580078125, Entropy 74.8326416015625, Learning Rate: 0.01\n",
      "Epoch [2147/20000], Loss: 1094.780029296875, Entropy 75.85357666015625, Learning Rate: 0.01\n",
      "Epoch [2148/20000], Loss: 1083.037353515625, Entropy 79.35596466064453, Learning Rate: 0.01\n",
      "Epoch [2149/20000], Loss: 1151.39794921875, Entropy 70.54405975341797, Learning Rate: 0.01\n",
      "Epoch [2150/20000], Loss: 1118.9339599609375, Entropy 74.44905853271484, Learning Rate: 0.01\n",
      "Epoch [2151/20000], Loss: 1120.587646484375, Entropy 87.41117095947266, Learning Rate: 0.01\n",
      "Epoch [2152/20000], Loss: 1123.546630859375, Entropy 72.04009246826172, Learning Rate: 0.01\n",
      "Epoch [2153/20000], Loss: 1105.07275390625, Entropy 88.0483169555664, Learning Rate: 0.01\n",
      "Epoch [2154/20000], Loss: 1101.515869140625, Entropy 81.06941986083984, Learning Rate: 0.01\n",
      "Epoch [2155/20000], Loss: 1123.201416015625, Entropy 78.11555480957031, Learning Rate: 0.01\n",
      "Epoch [2156/20000], Loss: 1107.761474609375, Entropy 89.2198257446289, Learning Rate: 0.01\n",
      "Epoch [2157/20000], Loss: 1120.4693603515625, Entropy 80.8883285522461, Learning Rate: 0.01\n",
      "Epoch [2158/20000], Loss: 1136.798583984375, Entropy 79.31155395507812, Learning Rate: 0.01\n",
      "Epoch [2159/20000], Loss: 1113.1761474609375, Entropy 79.10171508789062, Learning Rate: 0.01\n",
      "Epoch [2160/20000], Loss: 1121.5579833984375, Entropy 77.14289855957031, Learning Rate: 0.01\n",
      "Epoch [2161/20000], Loss: 1116.299072265625, Entropy 88.37834930419922, Learning Rate: 0.01\n",
      "Epoch [2162/20000], Loss: 1139.82666015625, Entropy 77.55742645263672, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2163/20000], Loss: 1105.46142578125, Entropy 76.5443115234375, Learning Rate: 0.01\n",
      "Epoch [2164/20000], Loss: 1059.1024169921875, Entropy 90.5694351196289, Learning Rate: 0.01\n",
      "Epoch [2165/20000], Loss: 1095.66455078125, Entropy 87.22103118896484, Learning Rate: 0.01\n",
      "Epoch [2166/20000], Loss: 1104.114501953125, Entropy 84.93234252929688, Learning Rate: 0.01\n",
      "Epoch [2167/20000], Loss: 1089.1517333984375, Entropy 95.46369934082031, Learning Rate: 0.01\n",
      "Epoch [2168/20000], Loss: 1085.7227783203125, Entropy 84.71663665771484, Learning Rate: 0.01\n",
      "Epoch [2169/20000], Loss: 1084.24658203125, Entropy 94.27214813232422, Learning Rate: 0.01\n",
      "Epoch [2170/20000], Loss: 1093.33056640625, Entropy 73.89232635498047, Learning Rate: 0.01\n",
      "Epoch [2171/20000], Loss: 1092.7906494140625, Entropy 97.81880950927734, Learning Rate: 0.01\n",
      "Epoch [2172/20000], Loss: 1094.2529296875, Entropy 90.25261688232422, Learning Rate: 0.01\n",
      "Epoch [2173/20000], Loss: 1105.131103515625, Entropy 83.82465362548828, Learning Rate: 0.01\n",
      "Epoch [2174/20000], Loss: 1063.7998046875, Entropy 88.95407104492188, Learning Rate: 0.01\n",
      "Epoch [2175/20000], Loss: 1183.5560302734375, Entropy 107.30577850341797, Learning Rate: 0.01\n",
      "Epoch [2176/20000], Loss: 1115.486083984375, Entropy 94.77222442626953, Learning Rate: 0.01\n",
      "Epoch [2177/20000], Loss: 1084.2877197265625, Entropy 78.41178894042969, Learning Rate: 0.01\n",
      "Epoch [2178/20000], Loss: 1081.8345947265625, Entropy 92.63435363769531, Learning Rate: 0.01\n",
      "Epoch [2179/20000], Loss: 1154.0919189453125, Entropy 79.30257415771484, Learning Rate: 0.01\n",
      "Epoch [2180/20000], Loss: 1096.0155029296875, Entropy 94.16446685791016, Learning Rate: 0.01\n",
      "Epoch [2181/20000], Loss: 1082.803466796875, Entropy 95.42152404785156, Learning Rate: 0.01\n",
      "Epoch [2182/20000], Loss: 1072.926513671875, Entropy 88.96791076660156, Learning Rate: 0.01\n",
      "Epoch [2183/20000], Loss: 1060.3345947265625, Entropy 81.10581970214844, Learning Rate: 0.01\n",
      "Epoch [2184/20000], Loss: 1121.8040771484375, Entropy 71.9212875366211, Learning Rate: 0.01\n",
      "Epoch [2185/20000], Loss: 1069.6922607421875, Entropy 97.55306243896484, Learning Rate: 0.01\n",
      "Epoch [2186/20000], Loss: 1085.781982421875, Entropy 89.72657775878906, Learning Rate: 0.01\n",
      "Epoch [2187/20000], Loss: 1100.6671142578125, Entropy 91.5540771484375, Learning Rate: 0.01\n",
      "Epoch [2188/20000], Loss: 1073.078369140625, Entropy 90.83778381347656, Learning Rate: 0.01\n",
      "Epoch [2189/20000], Loss: 1095.0897216796875, Entropy 91.6771240234375, Learning Rate: 0.01\n",
      "Epoch [2190/20000], Loss: 1093.1669921875, Entropy 88.46331787109375, Learning Rate: 0.01\n",
      "Epoch [2191/20000], Loss: 1089.2637939453125, Entropy 88.8548583984375, Learning Rate: 0.01\n",
      "Epoch [2192/20000], Loss: 1092.5777587890625, Entropy 85.45030212402344, Learning Rate: 0.01\n",
      "Epoch [2193/20000], Loss: 1118.677734375, Entropy 96.14060974121094, Learning Rate: 0.01\n",
      "Epoch [2194/20000], Loss: 1105.455078125, Entropy 89.45700073242188, Learning Rate: 0.01\n",
      "Epoch [2195/20000], Loss: 1083.9080810546875, Entropy 96.85648345947266, Learning Rate: 0.01\n",
      "Epoch [2196/20000], Loss: 1082.309326171875, Entropy 90.96498107910156, Learning Rate: 0.01\n",
      "Epoch [2197/20000], Loss: 1067.6103515625, Entropy 97.99897003173828, Learning Rate: 0.01\n",
      "Epoch [2198/20000], Loss: 1124.780517578125, Entropy 104.5705337524414, Learning Rate: 0.01\n",
      "Epoch [2199/20000], Loss: 1072.3564453125, Entropy 98.3858871459961, Learning Rate: 0.01\n",
      "Epoch [2200/20000], Loss: 1062.023193359375, Entropy 114.6756591796875, Learning Rate: 0.01\n",
      "Epoch [2201/20000], Loss: 1086.001953125, Entropy 82.54432678222656, Learning Rate: 0.01\n",
      "Epoch [2202/20000], Loss: 1072.8729248046875, Entropy 93.4667739868164, Learning Rate: 0.01\n",
      "Epoch [2203/20000], Loss: 1119.588134765625, Entropy 94.74440002441406, Learning Rate: 0.01\n",
      "Epoch [2204/20000], Loss: 1071.437255859375, Entropy 99.8670654296875, Learning Rate: 0.01\n",
      "Epoch [2205/20000], Loss: 1114.1365966796875, Entropy 74.49469757080078, Learning Rate: 0.01\n",
      "Epoch [2206/20000], Loss: 1063.81689453125, Entropy 113.9090805053711, Learning Rate: 0.01\n",
      "Epoch [2207/20000], Loss: 1079.5772705078125, Entropy 114.48120880126953, Learning Rate: 0.01\n",
      "Epoch [2208/20000], Loss: 1104.28759765625, Entropy 107.58222198486328, Learning Rate: 0.01\n",
      "Epoch [2209/20000], Loss: 1064.0638427734375, Entropy 90.77825164794922, Learning Rate: 0.01\n",
      "Epoch [2210/20000], Loss: 1102.500244140625, Entropy 99.783203125, Learning Rate: 0.01\n",
      "Epoch [2211/20000], Loss: 1076.6480712890625, Entropy 97.60960388183594, Learning Rate: 0.01\n",
      "Epoch [2212/20000], Loss: 1119.2740478515625, Entropy 107.21391296386719, Learning Rate: 0.01\n",
      "Epoch [2213/20000], Loss: 1079.9677734375, Entropy 104.73554229736328, Learning Rate: 0.01\n",
      "Epoch [2214/20000], Loss: 1085.9371337890625, Entropy 102.79994201660156, Learning Rate: 0.01\n",
      "Epoch [2215/20000], Loss: 1082.3656005859375, Entropy 100.72412872314453, Learning Rate: 0.01\n",
      "Epoch [2216/20000], Loss: 1077.930419921875, Entropy 106.51798248291016, Learning Rate: 0.01\n",
      "Epoch [2217/20000], Loss: 1101.1044921875, Entropy 99.16486358642578, Learning Rate: 0.01\n",
      "Epoch [2218/20000], Loss: 1051.277099609375, Entropy 95.48735809326172, Learning Rate: 0.01\n",
      "Epoch [2219/20000], Loss: 1057.2957763671875, Entropy 105.1166763305664, Learning Rate: 0.01\n",
      "Epoch [2220/20000], Loss: 1076.388427734375, Entropy 105.21060180664062, Learning Rate: 0.01\n",
      "Epoch [2221/20000], Loss: 1139.4014892578125, Entropy 104.82968139648438, Learning Rate: 0.01\n",
      "Epoch [2222/20000], Loss: 1083.3590087890625, Entropy 85.96330261230469, Learning Rate: 0.01\n",
      "Epoch [2223/20000], Loss: 1095.5211181640625, Entropy 99.97541046142578, Learning Rate: 0.01\n",
      "Epoch [2224/20000], Loss: 1071.017333984375, Entropy 109.12622833251953, Learning Rate: 0.01\n",
      "Epoch [2225/20000], Loss: 1078.4822998046875, Entropy 98.09246063232422, Learning Rate: 0.01\n",
      "Epoch [2226/20000], Loss: 1084.97705078125, Entropy 111.69944763183594, Learning Rate: 0.01\n",
      "Epoch [2227/20000], Loss: 1052.8961181640625, Entropy 107.67851257324219, Learning Rate: 0.01\n",
      "Epoch [2228/20000], Loss: 1102.9271240234375, Entropy 93.8197250366211, Learning Rate: 0.01\n",
      "Epoch [2229/20000], Loss: 1109.001953125, Entropy 115.05183410644531, Learning Rate: 0.01\n",
      "Epoch [2230/20000], Loss: 1116.65869140625, Entropy 92.38470458984375, Learning Rate: 0.01\n",
      "Epoch [2231/20000], Loss: 1073.359619140625, Entropy 124.13983154296875, Learning Rate: 0.01\n",
      "Epoch [2232/20000], Loss: 1061.955078125, Entropy 112.73707580566406, Learning Rate: 0.01\n",
      "Epoch [2233/20000], Loss: 1081.5526123046875, Entropy 99.08423614501953, Learning Rate: 0.01\n",
      "Epoch [2234/20000], Loss: 1091.902099609375, Entropy 113.22987365722656, Learning Rate: 0.01\n",
      "Epoch [2235/20000], Loss: 1068.8125, Entropy 112.68646240234375, Learning Rate: 0.01\n",
      "Epoch [2236/20000], Loss: 1080.8194580078125, Entropy 117.1765365600586, Learning Rate: 0.01\n",
      "Epoch [2237/20000], Loss: 1081.376708984375, Entropy 99.15699768066406, Learning Rate: 0.01\n",
      "Epoch [2238/20000], Loss: 1065.6644287109375, Entropy 110.78794860839844, Learning Rate: 0.01\n",
      "Epoch [2239/20000], Loss: 1083.2164306640625, Entropy 111.95097351074219, Learning Rate: 0.01\n",
      "Epoch [2240/20000], Loss: 1098.00732421875, Entropy 102.29155731201172, Learning Rate: 0.01\n",
      "Epoch [2241/20000], Loss: 1120.750732421875, Entropy 97.3721694946289, Learning Rate: 0.01\n",
      "Epoch [2242/20000], Loss: 1111.8612060546875, Entropy 93.7774429321289, Learning Rate: 0.01\n",
      "Epoch [2243/20000], Loss: 1065.1258544921875, Entropy 110.05992889404297, Learning Rate: 0.01\n",
      "Epoch [2244/20000], Loss: 1043.49560546875, Entropy 113.10370635986328, Learning Rate: 0.01\n",
      "Epoch [2245/20000], Loss: 1072.2646484375, Entropy 103.16378784179688, Learning Rate: 0.01\n",
      "Epoch [2246/20000], Loss: 1077.49072265625, Entropy 131.400146484375, Learning Rate: 0.01\n",
      "Epoch [2247/20000], Loss: 1116.7215576171875, Entropy 113.3790283203125, Learning Rate: 0.01\n",
      "Epoch [2248/20000], Loss: 1073.9451904296875, Entropy 96.57383728027344, Learning Rate: 0.01\n",
      "Epoch [2249/20000], Loss: 1085.7213134765625, Entropy 100.8077392578125, Learning Rate: 0.01\n",
      "Epoch [2250/20000], Loss: 1059.75830078125, Entropy 113.99974060058594, Learning Rate: 0.01\n",
      "Epoch [2251/20000], Loss: 1079.53076171875, Entropy 104.10640716552734, Learning Rate: 0.01\n",
      "Epoch [2252/20000], Loss: 1088.1727294921875, Entropy 123.56736755371094, Learning Rate: 0.01\n",
      "Epoch [2253/20000], Loss: 1076.222412109375, Entropy 100.0732192993164, Learning Rate: 0.01\n",
      "Epoch [2254/20000], Loss: 1053.695068359375, Entropy 119.30821990966797, Learning Rate: 0.01\n",
      "Epoch [2255/20000], Loss: 1074.752685546875, Entropy 108.94558715820312, Learning Rate: 0.01\n",
      "Epoch [2256/20000], Loss: 1087.356201171875, Entropy 111.35356903076172, Learning Rate: 0.01\n",
      "Epoch [2257/20000], Loss: 1069.606201171875, Entropy 109.07977294921875, Learning Rate: 0.01\n",
      "Epoch [2258/20000], Loss: 1070.033447265625, Entropy 126.08677673339844, Learning Rate: 0.01\n",
      "Epoch [2259/20000], Loss: 1069.1322021484375, Entropy 116.74590301513672, Learning Rate: 0.01\n",
      "Epoch [2260/20000], Loss: 1040.3033447265625, Entropy 124.8401107788086, Learning Rate: 0.01\n",
      "Epoch [2261/20000], Loss: 1119.2886962890625, Entropy 111.14680480957031, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2262/20000], Loss: 1070.026123046875, Entropy 113.2636489868164, Learning Rate: 0.01\n",
      "Epoch [2263/20000], Loss: 1098.06396484375, Entropy 117.55480194091797, Learning Rate: 0.01\n",
      "Epoch [2264/20000], Loss: 1072.5360107421875, Entropy 123.42677307128906, Learning Rate: 0.01\n",
      "Epoch [2265/20000], Loss: 1083.52294921875, Entropy 115.99122619628906, Learning Rate: 0.01\n",
      "Epoch [2266/20000], Loss: 1083.30810546875, Entropy 123.45262145996094, Learning Rate: 0.01\n",
      "Epoch [2267/20000], Loss: 1088.5048828125, Entropy 105.82158660888672, Learning Rate: 0.01\n",
      "Epoch [2268/20000], Loss: 1067.3914794921875, Entropy 114.32882690429688, Learning Rate: 0.01\n",
      "Epoch [2269/20000], Loss: 1072.7166748046875, Entropy 118.98658752441406, Learning Rate: 0.01\n",
      "Epoch [2270/20000], Loss: 1059.8858642578125, Entropy 113.64116668701172, Learning Rate: 0.01\n",
      "Epoch [2271/20000], Loss: 1100.8477783203125, Entropy 111.5976333618164, Learning Rate: 0.01\n",
      "Epoch [2272/20000], Loss: 1049.1070556640625, Entropy 131.89100646972656, Learning Rate: 0.01\n",
      "Epoch [2273/20000], Loss: 1081.098876953125, Entropy 116.5545883178711, Learning Rate: 0.01\n",
      "Epoch [2274/20000], Loss: 1074.827880859375, Entropy 128.6041717529297, Learning Rate: 0.01\n",
      "Epoch [2275/20000], Loss: 1097.3084716796875, Entropy 110.74710845947266, Learning Rate: 0.01\n",
      "Epoch [2276/20000], Loss: 1074.704833984375, Entropy 112.94775390625, Learning Rate: 0.01\n",
      "Epoch [2277/20000], Loss: 1072.2882080078125, Entropy 118.54503631591797, Learning Rate: 0.01\n",
      "Epoch [2278/20000], Loss: 1046.0657958984375, Entropy 125.57249450683594, Learning Rate: 0.01\n",
      "Epoch [2279/20000], Loss: 1049.015625, Entropy 123.01671600341797, Learning Rate: 0.01\n",
      "Epoch [2280/20000], Loss: 1135.2919921875, Entropy 107.63394927978516, Learning Rate: 0.01\n",
      "Epoch [2281/20000], Loss: 1058.9703369140625, Entropy 119.07564544677734, Learning Rate: 0.01\n",
      "Epoch [2282/20000], Loss: 1062.021240234375, Entropy 118.65865325927734, Learning Rate: 0.01\n",
      "Epoch [2283/20000], Loss: 1097.6309814453125, Entropy 114.30502319335938, Learning Rate: 0.01\n",
      "Epoch [2284/20000], Loss: 1076.7998046875, Entropy 117.91222381591797, Learning Rate: 0.01\n",
      "Epoch [2285/20000], Loss: 1097.8468017578125, Entropy 127.68214416503906, Learning Rate: 0.01\n",
      "Epoch [2286/20000], Loss: 1062.933837890625, Entropy 110.64366912841797, Learning Rate: 0.01\n",
      "Epoch [2287/20000], Loss: 1080.47802734375, Entropy 113.73651885986328, Learning Rate: 0.01\n",
      "Epoch [2288/20000], Loss: 1097.62646484375, Entropy 128.15301513671875, Learning Rate: 0.01\n",
      "Epoch [2289/20000], Loss: 1068.6337890625, Entropy 133.81002807617188, Learning Rate: 0.01\n",
      "Epoch [2290/20000], Loss: 1084.856689453125, Entropy 102.21241760253906, Learning Rate: 0.01\n",
      "Epoch [2291/20000], Loss: 1058.722412109375, Entropy 130.90599060058594, Learning Rate: 0.01\n",
      "Epoch [2292/20000], Loss: 1063.3863525390625, Entropy 120.8892822265625, Learning Rate: 0.01\n",
      "Epoch [2293/20000], Loss: 1063.926513671875, Entropy 119.71200561523438, Learning Rate: 0.01\n",
      "Epoch [2294/20000], Loss: 1057.234375, Entropy 133.71998596191406, Learning Rate: 0.01\n",
      "Epoch [2295/20000], Loss: 1046.1485595703125, Entropy 117.49624633789062, Learning Rate: 0.01\n",
      "Epoch [2296/20000], Loss: 1053.9483642578125, Entropy 117.82528686523438, Learning Rate: 0.01\n",
      "Epoch [2297/20000], Loss: 1098.2093505859375, Entropy 122.18830108642578, Learning Rate: 0.01\n",
      "Epoch [2298/20000], Loss: 1074.749267578125, Entropy 119.22757720947266, Learning Rate: 0.01\n",
      "Epoch [2299/20000], Loss: 1081.9814453125, Entropy 121.6452865600586, Learning Rate: 0.01\n",
      "Epoch [2300/20000], Loss: 1060.967529296875, Entropy 127.95464324951172, Learning Rate: 0.01\n",
      "Epoch [2301/20000], Loss: 1070.427978515625, Entropy 118.19786834716797, Learning Rate: 0.01\n",
      "Epoch [2302/20000], Loss: 1053.097900390625, Entropy 127.24393463134766, Learning Rate: 0.01\n",
      "Epoch [2303/20000], Loss: 1087.8841552734375, Entropy 112.82402038574219, Learning Rate: 0.01\n",
      "Epoch [2304/20000], Loss: 1063.7711181640625, Entropy 124.63290405273438, Learning Rate: 0.01\n",
      "Epoch [2305/20000], Loss: 1047.71923828125, Entropy 138.37554931640625, Learning Rate: 0.01\n",
      "Epoch [2306/20000], Loss: 1073.352294921875, Entropy 127.19839477539062, Learning Rate: 0.01\n",
      "Epoch [2307/20000], Loss: 1042.8193359375, Entropy 134.96421813964844, Learning Rate: 0.01\n",
      "Epoch [2308/20000], Loss: 1070.6280517578125, Entropy 137.146728515625, Learning Rate: 0.01\n",
      "Epoch [2309/20000], Loss: 1100.9659423828125, Entropy 123.8021469116211, Learning Rate: 0.01\n",
      "Epoch [2310/20000], Loss: 1065.1663818359375, Entropy 111.18941497802734, Learning Rate: 0.01\n",
      "Epoch [2311/20000], Loss: 1077.6663818359375, Entropy 129.7979278564453, Learning Rate: 0.01\n",
      "Epoch [2312/20000], Loss: 1105.13134765625, Entropy 119.3576431274414, Learning Rate: 0.01\n",
      "Epoch [2313/20000], Loss: 1037.994384765625, Entropy 131.223388671875, Learning Rate: 0.01\n",
      "Epoch [2314/20000], Loss: 1069.7391357421875, Entropy 128.78147888183594, Learning Rate: 0.01\n",
      "Epoch [2315/20000], Loss: 1062.9891357421875, Entropy 132.20152282714844, Learning Rate: 0.01\n",
      "Epoch [2316/20000], Loss: 1052.478271484375, Entropy 123.12913513183594, Learning Rate: 0.01\n",
      "Epoch [2317/20000], Loss: 1049.45751953125, Entropy 117.6893310546875, Learning Rate: 0.01\n",
      "Epoch [2318/20000], Loss: 1053.9989013671875, Entropy 141.70338439941406, Learning Rate: 0.01\n",
      "Epoch [2319/20000], Loss: 1058.271728515625, Entropy 132.98654174804688, Learning Rate: 0.01\n",
      "Epoch [2320/20000], Loss: 1086.535888671875, Entropy 118.7402114868164, Learning Rate: 0.01\n",
      "Epoch [2321/20000], Loss: 1045.4100341796875, Entropy 116.51081848144531, Learning Rate: 0.01\n",
      "Epoch [2322/20000], Loss: 1094.5831298828125, Entropy 126.26173400878906, Learning Rate: 0.01\n",
      "Epoch [2323/20000], Loss: 1081.3099365234375, Entropy 137.25650024414062, Learning Rate: 0.01\n",
      "Epoch [2324/20000], Loss: 1066.9052734375, Entropy 133.85049438476562, Learning Rate: 0.01\n",
      "Epoch [2325/20000], Loss: 1148.04345703125, Entropy 122.45232391357422, Learning Rate: 0.01\n",
      "Epoch [2326/20000], Loss: 1090.4134521484375, Entropy 123.63955688476562, Learning Rate: 0.01\n",
      "Epoch [2327/20000], Loss: 1072.3822021484375, Entropy 129.2147979736328, Learning Rate: 0.01\n",
      "Epoch [2328/20000], Loss: 1047.5985107421875, Entropy 135.67774963378906, Learning Rate: 0.01\n",
      "Epoch [2329/20000], Loss: 1074.018798828125, Entropy 136.93804931640625, Learning Rate: 0.01\n",
      "Epoch [2330/20000], Loss: 1084.080322265625, Entropy 145.892333984375, Learning Rate: 0.01\n",
      "Epoch [2331/20000], Loss: 1059.02734375, Entropy 137.85427856445312, Learning Rate: 0.01\n",
      "Epoch [2332/20000], Loss: 1073.80419921875, Entropy 129.836181640625, Learning Rate: 0.01\n",
      "Epoch [2333/20000], Loss: 1068.9503173828125, Entropy 158.25119018554688, Learning Rate: 0.01\n",
      "Epoch [2334/20000], Loss: 1069.786376953125, Entropy 125.40443420410156, Learning Rate: 0.01\n",
      "Epoch [2335/20000], Loss: 1130.7569580078125, Entropy 140.61045837402344, Learning Rate: 0.01\n",
      "Epoch [2336/20000], Loss: 1057.660400390625, Entropy 135.402587890625, Learning Rate: 0.01\n",
      "Epoch [2337/20000], Loss: 1054.5655517578125, Entropy 139.50503540039062, Learning Rate: 0.01\n",
      "Epoch [2338/20000], Loss: 1096.9862060546875, Entropy 113.29443359375, Learning Rate: 0.01\n",
      "Epoch [2339/20000], Loss: 1069.0523681640625, Entropy 145.59664916992188, Learning Rate: 0.01\n",
      "Epoch [2340/20000], Loss: 1092.42333984375, Entropy 136.71429443359375, Learning Rate: 0.01\n",
      "Epoch [2341/20000], Loss: 1052.511962890625, Entropy 130.64208984375, Learning Rate: 0.01\n",
      "Epoch [2342/20000], Loss: 1047.568603515625, Entropy 135.93470764160156, Learning Rate: 0.01\n",
      "Epoch [2343/20000], Loss: 1062.9036865234375, Entropy 137.7039337158203, Learning Rate: 0.01\n",
      "Epoch [2344/20000], Loss: 1082.8531494140625, Entropy 137.2741241455078, Learning Rate: 0.01\n",
      "Epoch [2345/20000], Loss: 1069.7373046875, Entropy 124.4554672241211, Learning Rate: 0.01\n",
      "Epoch [2346/20000], Loss: 1075.2938232421875, Entropy 141.4501495361328, Learning Rate: 0.01\n",
      "Epoch [2347/20000], Loss: 1090.0032958984375, Entropy 135.2102813720703, Learning Rate: 0.01\n",
      "Epoch [2348/20000], Loss: 1156.43017578125, Entropy 122.60103607177734, Learning Rate: 0.01\n",
      "Epoch [2349/20000], Loss: 1012.13427734375, Entropy 146.64942932128906, Learning Rate: 0.01\n",
      "Epoch [2350/20000], Loss: 1110.571533203125, Entropy 131.063232421875, Learning Rate: 0.01\n",
      "Epoch [2351/20000], Loss: 1077.825439453125, Entropy 138.50527954101562, Learning Rate: 0.01\n",
      "Epoch [2352/20000], Loss: 1107.0546875, Entropy 136.5495147705078, Learning Rate: 0.01\n",
      "Epoch [2353/20000], Loss: 1061.07568359375, Entropy 153.36715698242188, Learning Rate: 0.01\n",
      "Epoch [2354/20000], Loss: 1055.2996826171875, Entropy 137.7848358154297, Learning Rate: 0.01\n",
      "Epoch [2355/20000], Loss: 1105.29833984375, Entropy 140.51980590820312, Learning Rate: 0.01\n",
      "Epoch [2356/20000], Loss: 1141.8017578125, Entropy 131.9589385986328, Learning Rate: 0.01\n",
      "Epoch [2357/20000], Loss: 1114.0655517578125, Entropy 123.1805419921875, Learning Rate: 0.01\n",
      "Epoch [2358/20000], Loss: 1093.9136962890625, Entropy 130.029541015625, Learning Rate: 0.01\n",
      "Epoch [2359/20000], Loss: 1041.63037109375, Entropy 143.17904663085938, Learning Rate: 0.01\n",
      "Epoch [2360/20000], Loss: 1105.551513671875, Entropy 141.51016235351562, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2361/20000], Loss: 1084.863037109375, Entropy 126.8134994506836, Learning Rate: 0.01\n",
      "Epoch [2362/20000], Loss: 1103.9447021484375, Entropy 136.2898712158203, Learning Rate: 0.01\n",
      "Epoch [2363/20000], Loss: 1050.220947265625, Entropy 141.67686462402344, Learning Rate: 0.01\n",
      "Epoch [2364/20000], Loss: 1173.3184814453125, Entropy 139.09580993652344, Learning Rate: 0.01\n",
      "Epoch [2365/20000], Loss: 1105.124267578125, Entropy 127.85101318359375, Learning Rate: 0.01\n",
      "Epoch [2366/20000], Loss: 1124.1337890625, Entropy 152.32989501953125, Learning Rate: 0.01\n",
      "Epoch [2367/20000], Loss: 1157.568115234375, Entropy 135.3076934814453, Learning Rate: 0.01\n",
      "Epoch [2368/20000], Loss: 1055.3419189453125, Entropy 137.7305145263672, Learning Rate: 0.01\n",
      "Epoch [2369/20000], Loss: 1093.869140625, Entropy 145.44749450683594, Learning Rate: 0.01\n",
      "Epoch [2370/20000], Loss: 1126.312255859375, Entropy 121.10933685302734, Learning Rate: 0.01\n",
      "Epoch [2371/20000], Loss: 1052.43408203125, Entropy 140.1158905029297, Learning Rate: 0.01\n",
      "Epoch [2372/20000], Loss: 1113.50146484375, Entropy 131.9873504638672, Learning Rate: 0.01\n",
      "Epoch [2373/20000], Loss: 1042.27783203125, Entropy 147.56011962890625, Learning Rate: 0.01\n",
      "Epoch [2374/20000], Loss: 1139.9056396484375, Entropy 138.14915466308594, Learning Rate: 0.01\n",
      "Epoch [2375/20000], Loss: 1112.2996826171875, Entropy 132.5346221923828, Learning Rate: 0.01\n",
      "Epoch [2376/20000], Loss: 1118.1591796875, Entropy 141.73171997070312, Learning Rate: 0.01\n",
      "Epoch [2377/20000], Loss: 1174.564453125, Entropy 138.49330139160156, Learning Rate: 0.01\n",
      "Epoch [2378/20000], Loss: 1122.802734375, Entropy 151.4539337158203, Learning Rate: 0.01\n",
      "Epoch [2379/20000], Loss: 1144.7464599609375, Entropy 133.4367218017578, Learning Rate: 0.01\n",
      "Epoch [2380/20000], Loss: 1085.804931640625, Entropy 124.75376892089844, Learning Rate: 0.01\n",
      "Epoch [2381/20000], Loss: 1084.7872314453125, Entropy 139.8849334716797, Learning Rate: 0.01\n",
      "Epoch [2382/20000], Loss: 1063.90576171875, Entropy 130.79283142089844, Learning Rate: 0.01\n",
      "Epoch [2383/20000], Loss: 1160.8570556640625, Entropy 140.73910522460938, Learning Rate: 0.01\n",
      "Epoch [2384/20000], Loss: 1078.4422607421875, Entropy 147.96397399902344, Learning Rate: 0.01\n",
      "Epoch [2385/20000], Loss: 1011.793701171875, Entropy 151.57955932617188, Learning Rate: 0.01\n",
      "Epoch [2386/20000], Loss: 1076.7330322265625, Entropy 147.3653106689453, Learning Rate: 0.01\n",
      "Epoch [2387/20000], Loss: 1056.77783203125, Entropy 140.7045135498047, Learning Rate: 0.01\n",
      "Epoch [2388/20000], Loss: 1037.167236328125, Entropy 154.94049072265625, Learning Rate: 0.01\n",
      "Epoch [2389/20000], Loss: 1104.7557373046875, Entropy 128.67465209960938, Learning Rate: 0.01\n",
      "Epoch [2390/20000], Loss: 1107.258056640625, Entropy 133.29962158203125, Learning Rate: 0.01\n",
      "Epoch [2391/20000], Loss: 1049.869140625, Entropy 140.53456115722656, Learning Rate: 0.01\n",
      "Epoch [2392/20000], Loss: 1120.6024169921875, Entropy 135.07470703125, Learning Rate: 0.01\n",
      "Epoch [2393/20000], Loss: 1084.794921875, Entropy 149.80328369140625, Learning Rate: 0.01\n",
      "Epoch [2394/20000], Loss: 1051.6588134765625, Entropy 142.13943481445312, Learning Rate: 0.01\n",
      "Epoch [2395/20000], Loss: 1041.1298828125, Entropy 152.19235229492188, Learning Rate: 0.01\n",
      "Epoch [2396/20000], Loss: 1091.37646484375, Entropy 160.30227661132812, Learning Rate: 0.01\n",
      "Epoch [2397/20000], Loss: 1106.538818359375, Entropy 142.22857666015625, Learning Rate: 0.01\n",
      "Epoch [2398/20000], Loss: 1069.37841796875, Entropy 149.75360107421875, Learning Rate: 0.01\n",
      "Epoch [2399/20000], Loss: 1026.77978515625, Entropy 157.97352600097656, Learning Rate: 0.01\n",
      "Epoch [2400/20000], Loss: 1085.382568359375, Entropy 137.64334106445312, Learning Rate: 0.01\n",
      "Epoch [2401/20000], Loss: 1041.4688720703125, Entropy 157.89122009277344, Learning Rate: 0.01\n",
      "Epoch [2402/20000], Loss: 1083.722412109375, Entropy 131.710205078125, Learning Rate: 0.01\n",
      "Epoch [2403/20000], Loss: 1075.57421875, Entropy 132.40867614746094, Learning Rate: 0.01\n",
      "Epoch [2404/20000], Loss: 1083.807861328125, Entropy 144.6946258544922, Learning Rate: 0.01\n",
      "Epoch [2405/20000], Loss: 1037.870361328125, Entropy 158.04554748535156, Learning Rate: 0.01\n",
      "Epoch [2406/20000], Loss: 1050.55419921875, Entropy 146.01007080078125, Learning Rate: 0.01\n",
      "Epoch [2407/20000], Loss: 1065.0184326171875, Entropy 139.527587890625, Learning Rate: 0.01\n",
      "Epoch [2408/20000], Loss: 1049.52587890625, Entropy 146.26112365722656, Learning Rate: 0.01\n",
      "Epoch [2409/20000], Loss: 1042.6851806640625, Entropy 153.76303100585938, Learning Rate: 0.01\n",
      "Epoch [2410/20000], Loss: 1098.3538818359375, Entropy 153.30284118652344, Learning Rate: 0.01\n",
      "Epoch [2411/20000], Loss: 1043.8697509765625, Entropy 148.91934204101562, Learning Rate: 0.01\n",
      "Epoch [2412/20000], Loss: 1060.3709716796875, Entropy 144.05226135253906, Learning Rate: 0.01\n",
      "Epoch [2413/20000], Loss: 1045.054931640625, Entropy 147.15411376953125, Learning Rate: 0.01\n",
      "Epoch [2414/20000], Loss: 1038.0643310546875, Entropy 138.366943359375, Learning Rate: 0.01\n",
      "Epoch [2415/20000], Loss: 1014.66796875, Entropy 153.42819213867188, Learning Rate: 0.01\n",
      "Epoch [2416/20000], Loss: 1037.54443359375, Entropy 144.84165954589844, Learning Rate: 0.01\n",
      "Epoch [2417/20000], Loss: 1035.7232666015625, Entropy 151.05809020996094, Learning Rate: 0.01\n",
      "Epoch [2418/20000], Loss: 1095.1329345703125, Entropy 149.47251892089844, Learning Rate: 0.01\n",
      "Epoch [2419/20000], Loss: 1051.648193359375, Entropy 146.44558715820312, Learning Rate: 0.01\n",
      "Epoch [2420/20000], Loss: 1046.7080078125, Entropy 154.65736389160156, Learning Rate: 0.01\n",
      "Epoch [2421/20000], Loss: 1047.5426025390625, Entropy 149.48411560058594, Learning Rate: 0.01\n",
      "Epoch [2422/20000], Loss: 1095.0108642578125, Entropy 138.8804473876953, Learning Rate: 0.01\n",
      "Epoch [2423/20000], Loss: 1093.8607177734375, Entropy 150.36508178710938, Learning Rate: 0.01\n",
      "Epoch [2424/20000], Loss: 1032.9595947265625, Entropy 149.45530700683594, Learning Rate: 0.01\n",
      "Epoch [2425/20000], Loss: 1084.788818359375, Entropy 144.20689392089844, Learning Rate: 0.01\n",
      "Epoch [2426/20000], Loss: 1060.671630859375, Entropy 141.6667938232422, Learning Rate: 0.01\n",
      "Epoch [2427/20000], Loss: 1073.474853515625, Entropy 137.1248321533203, Learning Rate: 0.01\n",
      "Epoch [2428/20000], Loss: 1050.3988037109375, Entropy 132.34681701660156, Learning Rate: 0.01\n",
      "Epoch [2429/20000], Loss: 1115.9161376953125, Entropy 150.9639129638672, Learning Rate: 0.01\n",
      "Epoch [2430/20000], Loss: 1080.2720947265625, Entropy 144.81739807128906, Learning Rate: 0.01\n",
      "Epoch [2431/20000], Loss: 1003.7681884765625, Entropy 150.67591857910156, Learning Rate: 0.01\n",
      "Epoch [2432/20000], Loss: 1055.8089599609375, Entropy 157.7540283203125, Learning Rate: 0.01\n",
      "Epoch [2433/20000], Loss: 1066.30615234375, Entropy 151.02159118652344, Learning Rate: 0.01\n",
      "Epoch [2434/20000], Loss: 1075.566162109375, Entropy 151.29019165039062, Learning Rate: 0.01\n",
      "Epoch [2435/20000], Loss: 1024.9918212890625, Entropy 148.87904357910156, Learning Rate: 0.01\n",
      "Epoch [2436/20000], Loss: 1061.0289306640625, Entropy 146.81179809570312, Learning Rate: 0.01\n",
      "Epoch [2437/20000], Loss: 1038.7269287109375, Entropy 147.72325134277344, Learning Rate: 0.01\n",
      "Epoch [2438/20000], Loss: 1042.606201171875, Entropy 156.4335174560547, Learning Rate: 0.01\n",
      "Epoch [2439/20000], Loss: 1059.789306640625, Entropy 150.53598022460938, Learning Rate: 0.01\n",
      "Epoch [2440/20000], Loss: 1057.982177734375, Entropy 150.39556884765625, Learning Rate: 0.01\n",
      "Epoch [2441/20000], Loss: 1066.5521240234375, Entropy 152.67771911621094, Learning Rate: 0.01\n",
      "Epoch [2442/20000], Loss: 1081.76513671875, Entropy 146.68698120117188, Learning Rate: 0.01\n",
      "Epoch [2443/20000], Loss: 1087.240966796875, Entropy 164.49618530273438, Learning Rate: 0.01\n",
      "Epoch [2444/20000], Loss: 1118.1973876953125, Entropy 151.9081573486328, Learning Rate: 0.01\n",
      "Epoch [2445/20000], Loss: 1106.0352783203125, Entropy 137.9339141845703, Learning Rate: 0.01\n",
      "Epoch [2446/20000], Loss: 1068.729736328125, Entropy 154.4827880859375, Learning Rate: 0.01\n",
      "Epoch [2447/20000], Loss: 1069.1142578125, Entropy 165.3804473876953, Learning Rate: 0.01\n",
      "Epoch [2448/20000], Loss: 1131.054443359375, Entropy 146.8174591064453, Learning Rate: 0.01\n",
      "Epoch [2449/20000], Loss: 1084.536376953125, Entropy 146.22947692871094, Learning Rate: 0.01\n",
      "Epoch [2450/20000], Loss: 1149.2763671875, Entropy 147.36839294433594, Learning Rate: 0.01\n",
      "Epoch [2451/20000], Loss: 1079.49560546875, Entropy 178.7467498779297, Learning Rate: 0.01\n",
      "Epoch [2452/20000], Loss: 1084.2257080078125, Entropy 146.41903686523438, Learning Rate: 0.01\n",
      "Epoch [2453/20000], Loss: 1070.5233154296875, Entropy 164.12289428710938, Learning Rate: 0.01\n",
      "Epoch [2454/20000], Loss: 1109.322021484375, Entropy 149.78851318359375, Learning Rate: 0.01\n",
      "Epoch [2455/20000], Loss: 1070.3990478515625, Entropy 153.21559143066406, Learning Rate: 0.01\n",
      "Epoch [2456/20000], Loss: 1046.126953125, Entropy 153.0031280517578, Learning Rate: 0.01\n",
      "Epoch [2457/20000], Loss: 1095.505615234375, Entropy 150.1249542236328, Learning Rate: 0.01\n",
      "Epoch [2458/20000], Loss: 1105.7388916015625, Entropy 160.5558319091797, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2459/20000], Loss: 1151.04248046875, Entropy 142.78382873535156, Learning Rate: 0.01\n",
      "Epoch [2460/20000], Loss: 1228.9151611328125, Entropy 156.60107421875, Learning Rate: 0.01\n",
      "Epoch [2461/20000], Loss: 1197.574462890625, Entropy 147.52972412109375, Learning Rate: 0.01\n",
      "Epoch [2462/20000], Loss: 1120.5638427734375, Entropy 156.12667846679688, Learning Rate: 0.01\n",
      "Epoch [2463/20000], Loss: 1140.2664794921875, Entropy 142.7588348388672, Learning Rate: 0.01\n",
      "Epoch [2464/20000], Loss: 1120.1796875, Entropy 165.23275756835938, Learning Rate: 0.01\n",
      "Epoch [2465/20000], Loss: 1106.3726806640625, Entropy 160.91049194335938, Learning Rate: 0.01\n",
      "Epoch [2466/20000], Loss: 1233.4884033203125, Entropy 158.65879821777344, Learning Rate: 0.01\n",
      "Epoch [2467/20000], Loss: 1200.4246826171875, Entropy 146.53370666503906, Learning Rate: 0.01\n",
      "Epoch [2468/20000], Loss: 1354.34716796875, Entropy 160.99935913085938, Learning Rate: 0.01\n",
      "Epoch [2469/20000], Loss: 1176.36865234375, Entropy 155.4933624267578, Learning Rate: 0.01\n",
      "Epoch [2470/20000], Loss: 1412.4658203125, Entropy 152.101318359375, Learning Rate: 0.01\n",
      "Epoch [2471/20000], Loss: 1268.6932373046875, Entropy 168.37545776367188, Learning Rate: 0.01\n",
      "Epoch [2472/20000], Loss: 1497.1060791015625, Entropy 169.95260620117188, Learning Rate: 0.01\n",
      "Epoch [2473/20000], Loss: 1168.8900146484375, Entropy 154.9355010986328, Learning Rate: 0.01\n",
      "Epoch [2474/20000], Loss: 1509.7967529296875, Entropy 155.85012817382812, Learning Rate: 0.01\n",
      "Epoch [2475/20000], Loss: 1338.157470703125, Entropy 146.14630126953125, Learning Rate: 0.01\n",
      "Epoch [2476/20000], Loss: 1210.6607666015625, Entropy 162.8727264404297, Learning Rate: 0.01\n",
      "Epoch [2477/20000], Loss: 1219.798095703125, Entropy 158.141845703125, Learning Rate: 0.01\n",
      "Epoch [2478/20000], Loss: 1327.1551513671875, Entropy 139.77413940429688, Learning Rate: 0.01\n",
      "Epoch [2479/20000], Loss: 1117.4775390625, Entropy 156.8201141357422, Learning Rate: 0.01\n",
      "Epoch [2480/20000], Loss: 1302.4681396484375, Entropy 134.38839721679688, Learning Rate: 0.01\n",
      "Epoch [2481/20000], Loss: 1286.2919921875, Entropy 155.17538452148438, Learning Rate: 0.01\n",
      "Epoch [2482/20000], Loss: 1270.703369140625, Entropy 140.9832763671875, Learning Rate: 0.01\n",
      "Epoch [2483/20000], Loss: 1430.082763671875, Entropy 161.9711151123047, Learning Rate: 0.01\n",
      "Epoch [2484/20000], Loss: 1087.2894287109375, Entropy 169.35923767089844, Learning Rate: 0.01\n",
      "Epoch [2485/20000], Loss: 1204.798095703125, Entropy 155.19541931152344, Learning Rate: 0.01\n",
      "Epoch [2486/20000], Loss: 1462.298828125, Entropy 144.2045135498047, Learning Rate: 0.01\n",
      "Epoch [2487/20000], Loss: 1718.6322021484375, Entropy 161.449462890625, Learning Rate: 0.01\n",
      "Epoch [2488/20000], Loss: 1368.480712890625, Entropy 144.1021270751953, Learning Rate: 0.01\n",
      "Epoch [2489/20000], Loss: 1815.8848876953125, Entropy 150.1376190185547, Learning Rate: 0.01\n",
      "Epoch [2490/20000], Loss: 1488.7032470703125, Entropy 157.65188598632812, Learning Rate: 0.01\n",
      "Epoch [2491/20000], Loss: 1636.69970703125, Entropy 133.81332397460938, Learning Rate: 0.01\n",
      "Epoch [2492/20000], Loss: 1371.2579345703125, Entropy 147.59884643554688, Learning Rate: 0.01\n",
      "Epoch [2493/20000], Loss: 1659.8900146484375, Entropy 147.08981323242188, Learning Rate: 0.01\n",
      "Epoch [2494/20000], Loss: 1682.670166015625, Entropy 141.35243225097656, Learning Rate: 0.01\n",
      "Epoch [2495/20000], Loss: 1548.6138916015625, Entropy 128.03500366210938, Learning Rate: 0.01\n",
      "Epoch [2496/20000], Loss: 1249.2415771484375, Entropy 145.08157348632812, Learning Rate: 0.01\n",
      "Epoch [2497/20000], Loss: 1318.052734375, Entropy 144.29690551757812, Learning Rate: 0.01\n",
      "Epoch [2498/20000], Loss: 1298.06640625, Entropy 152.37625122070312, Learning Rate: 0.01\n",
      "Epoch [2499/20000], Loss: 1336.965087890625, Entropy 144.02713012695312, Learning Rate: 0.01\n",
      "Epoch [2500/20000], Loss: 1376.184814453125, Entropy 142.9990692138672, Learning Rate: 0.01\n",
      "Epoch [2501/20000], Loss: 1335.593017578125, Entropy 145.90155029296875, Learning Rate: 0.01\n",
      "Epoch [2502/20000], Loss: 1385.482666015625, Entropy 146.9148712158203, Learning Rate: 0.01\n",
      "Epoch [2503/20000], Loss: 1226.6480712890625, Entropy 134.75064086914062, Learning Rate: 0.01\n",
      "Epoch [2504/20000], Loss: 1587.453857421875, Entropy 143.71934509277344, Learning Rate: 0.01\n",
      "Epoch [2505/20000], Loss: 1138.583984375, Entropy 141.2731475830078, Learning Rate: 0.01\n",
      "Epoch [2506/20000], Loss: 1826.140380859375, Entropy 116.68387603759766, Learning Rate: 0.01\n",
      "Epoch [2507/20000], Loss: 1263.1192626953125, Entropy 129.16859436035156, Learning Rate: 0.01\n",
      "Epoch [2508/20000], Loss: 1569.4036865234375, Entropy 134.30784606933594, Learning Rate: 0.01\n",
      "Epoch [2509/20000], Loss: 1272.0484619140625, Entropy 125.20894622802734, Learning Rate: 0.01\n",
      "Epoch [2510/20000], Loss: 1322.8226318359375, Entropy 116.82109069824219, Learning Rate: 0.01\n",
      "Epoch [2511/20000], Loss: 1476.229248046875, Entropy 116.13790893554688, Learning Rate: 0.01\n",
      "Epoch [2512/20000], Loss: 1311.2467041015625, Entropy 108.21920013427734, Learning Rate: 0.01\n",
      "Epoch [2513/20000], Loss: 1604.1424560546875, Entropy 117.337158203125, Learning Rate: 0.01\n",
      "Epoch [2514/20000], Loss: 1196.3204345703125, Entropy 126.6874008178711, Learning Rate: 0.01\n",
      "Epoch [2515/20000], Loss: 1393.7978515625, Entropy 139.6659698486328, Learning Rate: 0.01\n",
      "Epoch [2516/20000], Loss: 1346.7557373046875, Entropy 122.22909545898438, Learning Rate: 0.01\n",
      "Epoch [2517/20000], Loss: 1263.8671875, Entropy 123.42620849609375, Learning Rate: 0.01\n",
      "Epoch [2518/20000], Loss: 1296.488037109375, Entropy 119.26284790039062, Learning Rate: 0.01\n",
      "Epoch [2519/20000], Loss: 1236.663330078125, Entropy 122.13326263427734, Learning Rate: 0.01\n",
      "Epoch [2520/20000], Loss: 1467.3126220703125, Entropy 119.856689453125, Learning Rate: 0.01\n",
      "Epoch [2521/20000], Loss: 1298.25341796875, Entropy 113.7909164428711, Learning Rate: 0.01\n",
      "Epoch [2522/20000], Loss: 1365.2757568359375, Entropy 122.1064453125, Learning Rate: 0.01\n",
      "Epoch [2523/20000], Loss: 1337.9697265625, Entropy 108.4740219116211, Learning Rate: 0.01\n",
      "Epoch [2524/20000], Loss: 1398.9510498046875, Entropy 125.24846649169922, Learning Rate: 0.01\n",
      "Epoch [2525/20000], Loss: 1302.35107421875, Entropy 128.9098358154297, Learning Rate: 0.01\n",
      "Epoch [2526/20000], Loss: 1194.8140869140625, Entropy 131.2184295654297, Learning Rate: 0.01\n",
      "Epoch [2527/20000], Loss: 1337.3096923828125, Entropy 123.17146301269531, Learning Rate: 0.01\n",
      "Epoch [2528/20000], Loss: 1385.843994140625, Entropy 118.48442840576172, Learning Rate: 0.01\n",
      "Epoch [2529/20000], Loss: 1160.1275634765625, Entropy 119.11610412597656, Learning Rate: 0.01\n",
      "Epoch [2530/20000], Loss: 1299.0074462890625, Entropy 114.689453125, Learning Rate: 0.01\n",
      "Epoch [2531/20000], Loss: 1300.4886474609375, Entropy 107.24449920654297, Learning Rate: 0.01\n",
      "Epoch [2532/20000], Loss: 1295.32373046875, Entropy 110.17911529541016, Learning Rate: 0.01\n",
      "Epoch [2533/20000], Loss: 1355.80419921875, Entropy 114.70982360839844, Learning Rate: 0.01\n",
      "Epoch [2534/20000], Loss: 1149.5364990234375, Entropy 119.6733169555664, Learning Rate: 0.01\n",
      "Epoch [2535/20000], Loss: 1330.8380126953125, Entropy 110.81160736083984, Learning Rate: 0.01\n",
      "Epoch [2536/20000], Loss: 1274.378173828125, Entropy 111.49983215332031, Learning Rate: 0.01\n",
      "Epoch [2537/20000], Loss: 1195.5623779296875, Entropy 118.98912811279297, Learning Rate: 0.01\n",
      "Epoch [2538/20000], Loss: 1336.1744384765625, Entropy 98.07743835449219, Learning Rate: 0.01\n",
      "Epoch [2539/20000], Loss: 1148.9833984375, Entropy 109.5740966796875, Learning Rate: 0.01\n",
      "Epoch [2540/20000], Loss: 1307.2210693359375, Entropy 107.4051742553711, Learning Rate: 0.01\n",
      "Epoch [2541/20000], Loss: 1091.147705078125, Entropy 114.72248077392578, Learning Rate: 0.01\n",
      "Epoch [2542/20000], Loss: 1146.887451171875, Entropy 103.95503997802734, Learning Rate: 0.01\n",
      "Epoch [2543/20000], Loss: 1168.9915771484375, Entropy 109.52426147460938, Learning Rate: 0.01\n",
      "Epoch [2544/20000], Loss: 1161.247802734375, Entropy 118.4215087890625, Learning Rate: 0.01\n",
      "Epoch [2545/20000], Loss: 1143.0484619140625, Entropy 123.38589477539062, Learning Rate: 0.01\n",
      "Epoch [2546/20000], Loss: 1242.16650390625, Entropy 102.74872589111328, Learning Rate: 0.01\n",
      "Epoch [2547/20000], Loss: 1107.555908203125, Entropy 115.50814056396484, Learning Rate: 0.01\n",
      "Epoch [2548/20000], Loss: 1180.7757568359375, Entropy 96.81187438964844, Learning Rate: 0.01\n",
      "Epoch [2549/20000], Loss: 1163.8828125, Entropy 104.0279769897461, Learning Rate: 0.01\n",
      "Epoch [2550/20000], Loss: 1080.486572265625, Entropy 98.10103607177734, Learning Rate: 0.01\n",
      "Epoch [2551/20000], Loss: 1229.013427734375, Entropy 117.76685333251953, Learning Rate: 0.01\n",
      "Epoch [2552/20000], Loss: 1119.1846923828125, Entropy 111.86630249023438, Learning Rate: 0.01\n",
      "Epoch [2553/20000], Loss: 1143.4610595703125, Entropy 108.53095245361328, Learning Rate: 0.01\n",
      "Epoch [2554/20000], Loss: 1210.6627197265625, Entropy 114.20027923583984, Learning Rate: 0.01\n",
      "Epoch [2555/20000], Loss: 1119.2686767578125, Entropy 101.2840805053711, Learning Rate: 0.01\n",
      "Epoch [2556/20000], Loss: 1138.5947265625, Entropy 113.04747009277344, Learning Rate: 0.01\n",
      "Epoch [2557/20000], Loss: 1143.3765869140625, Entropy 109.44789123535156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2558/20000], Loss: 1095.981201171875, Entropy 102.49769592285156, Learning Rate: 0.01\n",
      "Epoch [2559/20000], Loss: 1271.049072265625, Entropy 100.53558349609375, Learning Rate: 0.01\n",
      "Epoch [2560/20000], Loss: 1125.282958984375, Entropy 105.60787200927734, Learning Rate: 0.01\n",
      "Epoch [2561/20000], Loss: 1178.043701171875, Entropy 96.7028579711914, Learning Rate: 0.01\n",
      "Epoch [2562/20000], Loss: 1173.0322265625, Entropy 115.8358383178711, Learning Rate: 0.01\n",
      "Epoch [2563/20000], Loss: 1106.2784423828125, Entropy 104.13124084472656, Learning Rate: 0.01\n",
      "Epoch [2564/20000], Loss: 1221.677490234375, Entropy 101.02526092529297, Learning Rate: 0.01\n",
      "Epoch [2565/20000], Loss: 1134.0411376953125, Entropy 117.8110122680664, Learning Rate: 0.01\n",
      "Epoch [2566/20000], Loss: 1147.434326171875, Entropy 107.57594299316406, Learning Rate: 0.01\n",
      "Epoch [2567/20000], Loss: 1179.3846435546875, Entropy 104.41098022460938, Learning Rate: 0.01\n",
      "Epoch [2568/20000], Loss: 1062.776611328125, Entropy 107.85163116455078, Learning Rate: 0.01\n",
      "Epoch [2569/20000], Loss: 1155.419677734375, Entropy 112.07552337646484, Learning Rate: 0.01\n",
      "Epoch [2570/20000], Loss: 1187.6519775390625, Entropy 99.28858947753906, Learning Rate: 0.01\n",
      "Epoch [2571/20000], Loss: 1077.047119140625, Entropy 103.65602111816406, Learning Rate: 0.01\n",
      "Epoch [2572/20000], Loss: 1129.20947265625, Entropy 120.959716796875, Learning Rate: 0.01\n",
      "Epoch [2573/20000], Loss: 1135.4639892578125, Entropy 104.10520935058594, Learning Rate: 0.01\n",
      "Epoch [2574/20000], Loss: 1121.7435302734375, Entropy 110.31700897216797, Learning Rate: 0.01\n",
      "Epoch [2575/20000], Loss: 1190.5758056640625, Entropy 97.84224700927734, Learning Rate: 0.01\n",
      "Epoch [2576/20000], Loss: 1095.471435546875, Entropy 102.59220123291016, Learning Rate: 0.01\n",
      "Epoch [2577/20000], Loss: 1130.7020263671875, Entropy 104.89530944824219, Learning Rate: 0.01\n",
      "Epoch [2578/20000], Loss: 1110.0723876953125, Entropy 115.71366882324219, Learning Rate: 0.01\n",
      "Epoch [2579/20000], Loss: 1071.93701171875, Entropy 121.115966796875, Learning Rate: 0.01\n",
      "Epoch [2580/20000], Loss: 1096.8370361328125, Entropy 110.38020324707031, Learning Rate: 0.01\n",
      "Epoch [2581/20000], Loss: 1094.19189453125, Entropy 109.04603576660156, Learning Rate: 0.01\n",
      "Epoch [2582/20000], Loss: 1111.2899169921875, Entropy 115.6059341430664, Learning Rate: 0.01\n",
      "Epoch [2583/20000], Loss: 1081.196044921875, Entropy 118.84323120117188, Learning Rate: 0.01\n",
      "Epoch [2584/20000], Loss: 1081.9241943359375, Entropy 108.38666534423828, Learning Rate: 0.01\n",
      "Epoch [2585/20000], Loss: 1098.671875, Entropy 114.92476654052734, Learning Rate: 0.01\n",
      "Epoch [2586/20000], Loss: 1093.11572265625, Entropy 107.335205078125, Learning Rate: 0.01\n",
      "Epoch [2587/20000], Loss: 1063.44775390625, Entropy 116.87598419189453, Learning Rate: 0.01\n",
      "Epoch [2588/20000], Loss: 1074.09814453125, Entropy 103.07010650634766, Learning Rate: 0.01\n",
      "Epoch [2589/20000], Loss: 1096.4688720703125, Entropy 113.55809020996094, Learning Rate: 0.01\n",
      "Epoch [2590/20000], Loss: 1088.185302734375, Entropy 108.57868957519531, Learning Rate: 0.01\n",
      "Epoch [2591/20000], Loss: 1217.1361083984375, Entropy 91.95814514160156, Learning Rate: 0.01\n",
      "Epoch [2592/20000], Loss: 1056.439453125, Entropy 127.52261352539062, Learning Rate: 0.01\n",
      "Epoch [2593/20000], Loss: 1101.6116943359375, Entropy 120.04839324951172, Learning Rate: 0.01\n",
      "Epoch [2594/20000], Loss: 1113.584716796875, Entropy 99.3739013671875, Learning Rate: 0.01\n",
      "Epoch [2595/20000], Loss: 1059.0411376953125, Entropy 108.93241119384766, Learning Rate: 0.01\n",
      "Epoch [2596/20000], Loss: 1088.2618408203125, Entropy 108.48149871826172, Learning Rate: 0.01\n",
      "Epoch [2597/20000], Loss: 1080.1719970703125, Entropy 110.65161895751953, Learning Rate: 0.01\n",
      "Epoch [2598/20000], Loss: 1045.8648681640625, Entropy 118.21498107910156, Learning Rate: 0.01\n",
      "Epoch [2599/20000], Loss: 1076.9251708984375, Entropy 110.48873138427734, Learning Rate: 0.01\n",
      "Epoch [2600/20000], Loss: 1117.9051513671875, Entropy 93.2469482421875, Learning Rate: 0.01\n",
      "Epoch [2601/20000], Loss: 1086.2459716796875, Entropy 116.93598175048828, Learning Rate: 0.01\n",
      "Epoch [2602/20000], Loss: 1050.356201171875, Entropy 116.76848602294922, Learning Rate: 0.01\n",
      "Epoch [2603/20000], Loss: 1084.8284912109375, Entropy 102.59036254882812, Learning Rate: 0.01\n",
      "Epoch [2604/20000], Loss: 1060.4774169921875, Entropy 107.00687408447266, Learning Rate: 0.01\n",
      "Epoch [2605/20000], Loss: 1100.19873046875, Entropy 110.5135726928711, Learning Rate: 0.01\n",
      "Epoch [2606/20000], Loss: 1050.87890625, Entropy 123.57011413574219, Learning Rate: 0.01\n",
      "Epoch [2607/20000], Loss: 1062.6636962890625, Entropy 121.40097045898438, Learning Rate: 0.01\n",
      "Epoch [2608/20000], Loss: 1056.587158203125, Entropy 119.4885025024414, Learning Rate: 0.01\n",
      "Epoch [2609/20000], Loss: 1076.435302734375, Entropy 120.1279067993164, Learning Rate: 0.01\n",
      "Epoch [2610/20000], Loss: 1103.90380859375, Entropy 108.16844177246094, Learning Rate: 0.01\n",
      "Epoch [2611/20000], Loss: 1078.23095703125, Entropy 108.04241943359375, Learning Rate: 0.01\n",
      "Epoch [2612/20000], Loss: 1080.14453125, Entropy 118.68016052246094, Learning Rate: 0.01\n",
      "Epoch [2613/20000], Loss: 1041.4111328125, Entropy 121.11112976074219, Learning Rate: 0.01\n",
      "Epoch [2614/20000], Loss: 1060.43212890625, Entropy 119.93196868896484, Learning Rate: 0.01\n",
      "Epoch [2615/20000], Loss: 1080.060302734375, Entropy 119.55675506591797, Learning Rate: 0.01\n",
      "Epoch [2616/20000], Loss: 1055.2283935546875, Entropy 120.0921859741211, Learning Rate: 0.01\n",
      "Epoch [2617/20000], Loss: 1067.434814453125, Entropy 122.8119888305664, Learning Rate: 0.01\n",
      "Epoch [2618/20000], Loss: 1052.8941650390625, Entropy 113.44850158691406, Learning Rate: 0.01\n",
      "Epoch [2619/20000], Loss: 1095.7198486328125, Entropy 122.32923889160156, Learning Rate: 0.01\n",
      "Epoch [2620/20000], Loss: 1043.21484375, Entropy 129.34291076660156, Learning Rate: 0.01\n",
      "Epoch [2621/20000], Loss: 1033.6864013671875, Entropy 128.65830993652344, Learning Rate: 0.01\n",
      "Epoch [2622/20000], Loss: 1088.718017578125, Entropy 126.14134216308594, Learning Rate: 0.01\n",
      "Epoch [2623/20000], Loss: 1052.1595458984375, Entropy 122.50728607177734, Learning Rate: 0.01\n",
      "Epoch [2624/20000], Loss: 1041.2305908203125, Entropy 121.46513366699219, Learning Rate: 0.01\n",
      "Epoch [2625/20000], Loss: 1037.9959716796875, Entropy 120.5625, Learning Rate: 0.01\n",
      "Epoch [2626/20000], Loss: 1055.1588134765625, Entropy 128.21060180664062, Learning Rate: 0.01\n",
      "Epoch [2627/20000], Loss: 1039.1776123046875, Entropy 142.0985870361328, Learning Rate: 0.01\n",
      "Epoch [2628/20000], Loss: 1099.277099609375, Entropy 118.72481536865234, Learning Rate: 0.01\n",
      "Epoch [2629/20000], Loss: 1072.02587890625, Entropy 115.95450592041016, Learning Rate: 0.01\n",
      "Epoch [2630/20000], Loss: 1093.8707275390625, Entropy 142.00416564941406, Learning Rate: 0.01\n",
      "Epoch [2631/20000], Loss: 1026.839111328125, Entropy 135.8096160888672, Learning Rate: 0.01\n",
      "Epoch [2632/20000], Loss: 1047.4073486328125, Entropy 135.61331176757812, Learning Rate: 0.01\n",
      "Epoch [2633/20000], Loss: 1036.81005859375, Entropy 141.58392333984375, Learning Rate: 0.01\n",
      "Epoch [2634/20000], Loss: 1059.3465576171875, Entropy 130.45590209960938, Learning Rate: 0.01\n",
      "Epoch [2635/20000], Loss: 1067.1763916015625, Entropy 124.43025970458984, Learning Rate: 0.01\n",
      "Epoch [2636/20000], Loss: 1027.8135986328125, Entropy 139.2002716064453, Learning Rate: 0.01\n",
      "Epoch [2637/20000], Loss: 1029.550048828125, Entropy 139.05702209472656, Learning Rate: 0.01\n",
      "Epoch [2638/20000], Loss: 1031.999755859375, Entropy 136.82923889160156, Learning Rate: 0.01\n",
      "Epoch [2639/20000], Loss: 1062.644775390625, Entropy 129.16773986816406, Learning Rate: 0.01\n",
      "Epoch [2640/20000], Loss: 1031.8795166015625, Entropy 137.68222045898438, Learning Rate: 0.01\n",
      "Epoch [2641/20000], Loss: 1054.6771240234375, Entropy 136.7637481689453, Learning Rate: 0.01\n",
      "Epoch [2642/20000], Loss: 1011.830322265625, Entropy 134.38246154785156, Learning Rate: 0.01\n",
      "Epoch [2643/20000], Loss: 1047.9141845703125, Entropy 136.9593963623047, Learning Rate: 0.01\n",
      "Epoch [2644/20000], Loss: 1045.2325439453125, Entropy 123.96289825439453, Learning Rate: 0.01\n",
      "Epoch [2645/20000], Loss: 1047.965576171875, Entropy 129.44100952148438, Learning Rate: 0.01\n",
      "Epoch [2646/20000], Loss: 1026.28173828125, Entropy 121.54200744628906, Learning Rate: 0.01\n",
      "Epoch [2647/20000], Loss: 1050.542236328125, Entropy 144.3497314453125, Learning Rate: 0.01\n",
      "Epoch [2648/20000], Loss: 1039.600341796875, Entropy 135.09104919433594, Learning Rate: 0.01\n",
      "Epoch [2649/20000], Loss: 1093.0516357421875, Entropy 128.81491088867188, Learning Rate: 0.01\n",
      "Epoch [2650/20000], Loss: 1069.1002197265625, Entropy 123.71003723144531, Learning Rate: 0.01\n",
      "Epoch [2651/20000], Loss: 1074.2647705078125, Entropy 143.93661499023438, Learning Rate: 0.01\n",
      "Epoch [2652/20000], Loss: 1041.6986083984375, Entropy 140.07835388183594, Learning Rate: 0.01\n",
      "Epoch [2653/20000], Loss: 1037.732421875, Entropy 125.52058410644531, Learning Rate: 0.01\n",
      "Epoch [2654/20000], Loss: 1092.050048828125, Entropy 132.04623413085938, Learning Rate: 0.01\n",
      "Epoch [2655/20000], Loss: 1021.725341796875, Entropy 144.36997985839844, Learning Rate: 0.01\n",
      "Epoch [2656/20000], Loss: 1034.205078125, Entropy 138.60804748535156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2657/20000], Loss: 1054.4708251953125, Entropy 139.21104431152344, Learning Rate: 0.01\n",
      "Epoch [2658/20000], Loss: 1024.645751953125, Entropy 144.78466796875, Learning Rate: 0.01\n",
      "Epoch [2659/20000], Loss: 1052.85107421875, Entropy 136.35479736328125, Learning Rate: 0.01\n",
      "Epoch [2660/20000], Loss: 1059.1409912109375, Entropy 133.83447265625, Learning Rate: 0.01\n",
      "Epoch [2661/20000], Loss: 1037.3642578125, Entropy 143.28611755371094, Learning Rate: 0.01\n",
      "Epoch [2662/20000], Loss: 1058.9227294921875, Entropy 144.43226623535156, Learning Rate: 0.01\n",
      "Epoch [2663/20000], Loss: 1039.4688720703125, Entropy 137.26248168945312, Learning Rate: 0.01\n",
      "Epoch [2664/20000], Loss: 1030.895751953125, Entropy 140.50743103027344, Learning Rate: 0.01\n",
      "Epoch [2665/20000], Loss: 1072.71142578125, Entropy 136.49610900878906, Learning Rate: 0.01\n",
      "Epoch [2666/20000], Loss: 1003.3762817382812, Entropy 160.87103271484375, Learning Rate: 0.01\n",
      "Epoch [2667/20000], Loss: 1045.234130859375, Entropy 138.13514709472656, Learning Rate: 0.01\n",
      "Epoch [2668/20000], Loss: 1049.391845703125, Entropy 143.41893005371094, Learning Rate: 0.01\n",
      "Epoch [2669/20000], Loss: 1048.978515625, Entropy 155.5611114501953, Learning Rate: 0.01\n",
      "Epoch [2670/20000], Loss: 1062.635986328125, Entropy 129.96694946289062, Learning Rate: 0.01\n",
      "Epoch [2671/20000], Loss: 1029.0950927734375, Entropy 135.30726623535156, Learning Rate: 0.01\n",
      "Epoch [2672/20000], Loss: 1041.2608642578125, Entropy 131.0271453857422, Learning Rate: 0.01\n",
      "Epoch [2673/20000], Loss: 1093.250244140625, Entropy 134.74591064453125, Learning Rate: 0.01\n",
      "Epoch [2674/20000], Loss: 1051.789306640625, Entropy 147.43466186523438, Learning Rate: 0.01\n",
      "Epoch [2675/20000], Loss: 1103.6912841796875, Entropy 138.34471130371094, Learning Rate: 0.01\n",
      "Epoch [2676/20000], Loss: 1087.272705078125, Entropy 137.1055450439453, Learning Rate: 0.01\n",
      "Epoch [2677/20000], Loss: 1052.86083984375, Entropy 151.29986572265625, Learning Rate: 0.01\n",
      "Epoch [2678/20000], Loss: 1025.6285400390625, Entropy 132.8742218017578, Learning Rate: 0.01\n",
      "Epoch [2679/20000], Loss: 1040.3675537109375, Entropy 152.4560546875, Learning Rate: 0.01\n",
      "Epoch [2680/20000], Loss: 1054.1241455078125, Entropy 143.55014038085938, Learning Rate: 0.01\n",
      "Epoch [2681/20000], Loss: 1023.6851806640625, Entropy 149.51986694335938, Learning Rate: 0.01\n",
      "Epoch [2682/20000], Loss: 1040.462890625, Entropy 147.56736755371094, Learning Rate: 0.01\n",
      "Epoch [2683/20000], Loss: 1058.8839111328125, Entropy 138.6477508544922, Learning Rate: 0.01\n",
      "Epoch [2684/20000], Loss: 1107.682373046875, Entropy 143.50396728515625, Learning Rate: 0.01\n",
      "Epoch [2685/20000], Loss: 996.4923095703125, Entropy 160.73692321777344, Learning Rate: 0.01\n",
      "Epoch [2686/20000], Loss: 1073.541259765625, Entropy 146.89759826660156, Learning Rate: 0.01\n",
      "Epoch [2687/20000], Loss: 1007.7772216796875, Entropy 156.75198364257812, Learning Rate: 0.01\n",
      "Epoch [2688/20000], Loss: 1027.75732421875, Entropy 149.89532470703125, Learning Rate: 0.01\n",
      "Epoch [2689/20000], Loss: 1023.74658203125, Entropy 140.90652465820312, Learning Rate: 0.01\n",
      "Epoch [2690/20000], Loss: 1024.4080810546875, Entropy 164.34925842285156, Learning Rate: 0.01\n",
      "Epoch [2691/20000], Loss: 1056.3238525390625, Entropy 148.3246612548828, Learning Rate: 0.01\n",
      "Epoch [2692/20000], Loss: 1037.2589111328125, Entropy 163.9482421875, Learning Rate: 0.01\n",
      "Epoch [2693/20000], Loss: 1045.8350830078125, Entropy 143.3038330078125, Learning Rate: 0.01\n",
      "Epoch [2694/20000], Loss: 1007.0460205078125, Entropy 152.7879638671875, Learning Rate: 0.01\n",
      "Epoch [2695/20000], Loss: 1045.8856201171875, Entropy 160.46861267089844, Learning Rate: 0.01\n",
      "Epoch [2696/20000], Loss: 1056.4981689453125, Entropy 142.31320190429688, Learning Rate: 0.01\n",
      "Epoch [2697/20000], Loss: 1072.3916015625, Entropy 154.7671661376953, Learning Rate: 0.01\n",
      "Epoch [2698/20000], Loss: 1056.3680419921875, Entropy 123.97954559326172, Learning Rate: 0.01\n",
      "Epoch [2699/20000], Loss: 1059.9403076171875, Entropy 146.4498748779297, Learning Rate: 0.01\n",
      "Epoch [2700/20000], Loss: 1056.3040771484375, Entropy 150.66688537597656, Learning Rate: 0.01\n",
      "Epoch [2701/20000], Loss: 1054.85498046875, Entropy 141.0531768798828, Learning Rate: 0.01\n",
      "Epoch [2702/20000], Loss: 1028.30029296875, Entropy 146.97784423828125, Learning Rate: 0.01\n",
      "Epoch [2703/20000], Loss: 1049.8226318359375, Entropy 156.0416717529297, Learning Rate: 0.01\n",
      "Epoch [2704/20000], Loss: 1036.802490234375, Entropy 158.8146209716797, Learning Rate: 0.01\n",
      "Epoch [2705/20000], Loss: 1060.7969970703125, Entropy 145.8598175048828, Learning Rate: 0.01\n",
      "Epoch [2706/20000], Loss: 1059.672607421875, Entropy 152.4191436767578, Learning Rate: 0.01\n",
      "Epoch [2707/20000], Loss: 1064.01416015625, Entropy 135.54376220703125, Learning Rate: 0.01\n",
      "Epoch [2708/20000], Loss: 1032.5533447265625, Entropy 154.1538543701172, Learning Rate: 0.01\n",
      "Epoch [2709/20000], Loss: 1023.3349609375, Entropy 149.48866271972656, Learning Rate: 0.01\n",
      "Epoch [2710/20000], Loss: 1054.67626953125, Entropy 155.3038787841797, Learning Rate: 0.01\n",
      "Epoch [2711/20000], Loss: 1057.2530517578125, Entropy 161.931640625, Learning Rate: 0.01\n",
      "Epoch [2712/20000], Loss: 1058.463623046875, Entropy 159.24464416503906, Learning Rate: 0.01\n",
      "Epoch [2713/20000], Loss: 1032.023193359375, Entropy 175.82745361328125, Learning Rate: 0.01\n",
      "Epoch [2714/20000], Loss: 1085.8837890625, Entropy 153.3441162109375, Learning Rate: 0.01\n",
      "Epoch [2715/20000], Loss: 1089.7025146484375, Entropy 158.2194061279297, Learning Rate: 0.01\n",
      "Epoch [2716/20000], Loss: 1119.12060546875, Entropy 164.37893676757812, Learning Rate: 0.01\n",
      "Epoch [2717/20000], Loss: 1136.6148681640625, Entropy 172.33993530273438, Learning Rate: 0.01\n",
      "Epoch [2718/20000], Loss: 1073.575927734375, Entropy 172.50140380859375, Learning Rate: 0.01\n",
      "Epoch [2719/20000], Loss: 1122.504638671875, Entropy 146.26707458496094, Learning Rate: 0.01\n",
      "Epoch [2720/20000], Loss: 1036.767822265625, Entropy 160.36138916015625, Learning Rate: 0.01\n",
      "Epoch [2721/20000], Loss: 1169.342041015625, Entropy 155.9191436767578, Learning Rate: 0.01\n",
      "Epoch [2722/20000], Loss: 1029.7442626953125, Entropy 150.40115356445312, Learning Rate: 0.01\n",
      "Epoch [2723/20000], Loss: 1155.0943603515625, Entropy 149.38943481445312, Learning Rate: 0.01\n",
      "Epoch [2724/20000], Loss: 1136.7413330078125, Entropy 154.95651245117188, Learning Rate: 0.01\n",
      "Epoch [2725/20000], Loss: 1135.541015625, Entropy 148.79876708984375, Learning Rate: 0.01\n",
      "Epoch [2726/20000], Loss: 1161.25390625, Entropy 151.0560760498047, Learning Rate: 0.01\n",
      "Epoch [2727/20000], Loss: 1126.26708984375, Entropy 162.4713897705078, Learning Rate: 0.01\n",
      "Epoch [2728/20000], Loss: 1064.198486328125, Entropy 169.35850524902344, Learning Rate: 0.01\n",
      "Epoch [2729/20000], Loss: 1150.00732421875, Entropy 161.8458709716797, Learning Rate: 0.01\n",
      "Epoch [2730/20000], Loss: 1118.70068359375, Entropy 163.2247772216797, Learning Rate: 0.01\n",
      "Epoch [2731/20000], Loss: 1101.0888671875, Entropy 153.4203338623047, Learning Rate: 0.01\n",
      "Epoch [2732/20000], Loss: 1063.8631591796875, Entropy 159.08877563476562, Learning Rate: 0.01\n",
      "Epoch [2733/20000], Loss: 1057.86767578125, Entropy 161.4727325439453, Learning Rate: 0.01\n",
      "Epoch [2734/20000], Loss: 1088.3057861328125, Entropy 166.84396362304688, Learning Rate: 0.01\n",
      "Epoch [2735/20000], Loss: 1147.0985107421875, Entropy 165.97732543945312, Learning Rate: 0.01\n",
      "Epoch [2736/20000], Loss: 1046.7489013671875, Entropy 157.12010192871094, Learning Rate: 0.01\n",
      "Epoch [2737/20000], Loss: 1172.041748046875, Entropy 154.36395263671875, Learning Rate: 0.01\n",
      "Epoch [2738/20000], Loss: 1068.0487060546875, Entropy 153.7821502685547, Learning Rate: 0.01\n",
      "Epoch [2739/20000], Loss: 1076.984130859375, Entropy 171.856201171875, Learning Rate: 0.01\n",
      "Epoch [2740/20000], Loss: 1136.7406005859375, Entropy 160.4028778076172, Learning Rate: 0.01\n",
      "Epoch [2741/20000], Loss: 1085.9398193359375, Entropy 160.27188110351562, Learning Rate: 0.01\n",
      "Epoch [2742/20000], Loss: 1127.031494140625, Entropy 164.23983764648438, Learning Rate: 0.01\n",
      "Epoch [2743/20000], Loss: 1037.5218505859375, Entropy 155.8676300048828, Learning Rate: 0.01\n",
      "Epoch [2744/20000], Loss: 1088.0562744140625, Entropy 174.8770294189453, Learning Rate: 0.01\n",
      "Epoch [2745/20000], Loss: 1091.7742919921875, Entropy 152.08163452148438, Learning Rate: 0.01\n",
      "Epoch [2746/20000], Loss: 1083.5865478515625, Entropy 172.24484252929688, Learning Rate: 0.01\n",
      "Epoch [2747/20000], Loss: 1142.0345458984375, Entropy 163.0478515625, Learning Rate: 0.01\n",
      "Epoch [2748/20000], Loss: 1050.5235595703125, Entropy 166.5858612060547, Learning Rate: 0.01\n",
      "Epoch [2749/20000], Loss: 1159.527099609375, Entropy 175.36244201660156, Learning Rate: 0.01\n",
      "Epoch [2750/20000], Loss: 1031.942138671875, Entropy 168.53140258789062, Learning Rate: 0.01\n",
      "Epoch [2751/20000], Loss: 1153.943359375, Entropy 157.29881286621094, Learning Rate: 0.01\n",
      "Epoch [2752/20000], Loss: 1066.321044921875, Entropy 169.25035095214844, Learning Rate: 0.01\n",
      "Epoch [2753/20000], Loss: 1061.16259765625, Entropy 160.5475311279297, Learning Rate: 0.01\n",
      "Epoch [2754/20000], Loss: 1093.877685546875, Entropy 167.92218017578125, Learning Rate: 0.01\n",
      "Epoch [2755/20000], Loss: 1050.787109375, Entropy 160.49610900878906, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2756/20000], Loss: 1095.9940185546875, Entropy 172.78921508789062, Learning Rate: 0.01\n",
      "Epoch [2757/20000], Loss: 1124.554931640625, Entropy 165.20411682128906, Learning Rate: 0.01\n",
      "Epoch [2758/20000], Loss: 1107.1800537109375, Entropy 168.4753875732422, Learning Rate: 0.01\n",
      "Epoch [2759/20000], Loss: 1051.013916015625, Entropy 160.27366638183594, Learning Rate: 0.01\n",
      "Epoch [2760/20000], Loss: 1311.15625, Entropy 158.28086853027344, Learning Rate: 0.01\n",
      "Epoch [2761/20000], Loss: 1430.6822509765625, Entropy 174.625732421875, Learning Rate: 0.01\n",
      "Epoch [2762/20000], Loss: 1086.464599609375, Entropy 157.90060424804688, Learning Rate: 0.01\n",
      "Epoch [2763/20000], Loss: 1299.1424560546875, Entropy 173.21031188964844, Learning Rate: 0.01\n",
      "Epoch [2764/20000], Loss: 1136.46630859375, Entropy 154.15704345703125, Learning Rate: 0.01\n",
      "Epoch [2765/20000], Loss: 1219.399169921875, Entropy 170.59803771972656, Learning Rate: 0.01\n",
      "Epoch [2766/20000], Loss: 1130.701416015625, Entropy 172.31390380859375, Learning Rate: 0.01\n",
      "Epoch [2767/20000], Loss: 1202.8272705078125, Entropy 166.9512481689453, Learning Rate: 0.01\n",
      "Epoch [2768/20000], Loss: 1051.5782470703125, Entropy 157.29396057128906, Learning Rate: 0.01\n",
      "Epoch [2769/20000], Loss: 1233.90625, Entropy 161.32220458984375, Learning Rate: 0.01\n",
      "Epoch [2770/20000], Loss: 1214.51513671875, Entropy 156.12782287597656, Learning Rate: 0.01\n",
      "Epoch [2771/20000], Loss: 1145.74462890625, Entropy 166.7575225830078, Learning Rate: 0.01\n",
      "Epoch [2772/20000], Loss: 1291.8656005859375, Entropy 164.94581604003906, Learning Rate: 0.01\n",
      "Epoch [2773/20000], Loss: 1103.862548828125, Entropy 153.00860595703125, Learning Rate: 0.01\n",
      "Epoch [2774/20000], Loss: 1206.920166015625, Entropy 153.26315307617188, Learning Rate: 0.01\n",
      "Epoch [2775/20000], Loss: 1167.9425048828125, Entropy 170.48568725585938, Learning Rate: 0.01\n",
      "Epoch [2776/20000], Loss: 1175.434326171875, Entropy 161.31068420410156, Learning Rate: 0.01\n",
      "Epoch [2777/20000], Loss: 1185.07080078125, Entropy 171.60769653320312, Learning Rate: 0.01\n",
      "Epoch [2778/20000], Loss: 1273.712158203125, Entropy 157.0290069580078, Learning Rate: 0.01\n",
      "Epoch [2779/20000], Loss: 1170.1328125, Entropy 160.12554931640625, Learning Rate: 0.01\n",
      "Epoch [2780/20000], Loss: 1168.8253173828125, Entropy 162.0028533935547, Learning Rate: 0.01\n",
      "Epoch [2781/20000], Loss: 1263.56005859375, Entropy 157.13894653320312, Learning Rate: 0.01\n",
      "Epoch [2782/20000], Loss: 1196.0992431640625, Entropy 174.51712036132812, Learning Rate: 0.01\n",
      "Epoch [2783/20000], Loss: 1146.8375244140625, Entropy 170.755859375, Learning Rate: 0.01\n",
      "Epoch [2784/20000], Loss: 1156.58447265625, Entropy 159.8827667236328, Learning Rate: 0.01\n",
      "Epoch [2785/20000], Loss: 1249.69140625, Entropy 163.001953125, Learning Rate: 0.01\n",
      "Epoch [2786/20000], Loss: 1065.0433349609375, Entropy 160.4408721923828, Learning Rate: 0.01\n",
      "Epoch [2787/20000], Loss: 1631.2041015625, Entropy 170.75035095214844, Learning Rate: 0.01\n",
      "Epoch [2788/20000], Loss: 1141.1898193359375, Entropy 150.85484313964844, Learning Rate: 0.01\n",
      "Epoch [2789/20000], Loss: 1504.6036376953125, Entropy 151.94287109375, Learning Rate: 0.01\n",
      "Epoch [2790/20000], Loss: 1119.169189453125, Entropy 162.09414672851562, Learning Rate: 0.01\n",
      "Epoch [2791/20000], Loss: 1641.228759765625, Entropy 153.1642608642578, Learning Rate: 0.01\n",
      "Epoch [2792/20000], Loss: 1073.1153564453125, Entropy 167.67916870117188, Learning Rate: 0.01\n",
      "Epoch [2793/20000], Loss: 1451.119384765625, Entropy 150.46900939941406, Learning Rate: 0.01\n",
      "Epoch [2794/20000], Loss: 1240.2716064453125, Entropy 151.585205078125, Learning Rate: 0.01\n",
      "Epoch [2795/20000], Loss: 1285.069091796875, Entropy 158.2155303955078, Learning Rate: 0.01\n",
      "Epoch [2796/20000], Loss: 1391.3148193359375, Entropy 151.74899291992188, Learning Rate: 0.01\n",
      "Epoch [2797/20000], Loss: 1091.6982421875, Entropy 149.03260803222656, Learning Rate: 0.01\n",
      "Epoch [2798/20000], Loss: 1386.6890869140625, Entropy 150.27035522460938, Learning Rate: 0.01\n",
      "Epoch [2799/20000], Loss: 1326.08203125, Entropy 143.5872802734375, Learning Rate: 0.01\n",
      "Epoch [2800/20000], Loss: 1492.6533203125, Entropy 161.7406463623047, Learning Rate: 0.01\n",
      "Epoch [2801/20000], Loss: 1536.983154296875, Entropy 159.13734436035156, Learning Rate: 0.01\n",
      "Epoch [2802/20000], Loss: 1507.203369140625, Entropy 143.37503051757812, Learning Rate: 0.01\n",
      "Epoch [2803/20000], Loss: 2097.55322265625, Entropy 156.414794921875, Learning Rate: 0.01\n",
      "Epoch [2804/20000], Loss: 2078.855712890625, Entropy 144.30921936035156, Learning Rate: 0.01\n",
      "Epoch [2805/20000], Loss: 2364.824951171875, Entropy 145.95904541015625, Learning Rate: 0.01\n",
      "Epoch [2806/20000], Loss: 2684.852783203125, Entropy 154.96372985839844, Learning Rate: 0.01\n",
      "Epoch [2807/20000], Loss: 1922.0443115234375, Entropy 148.5003662109375, Learning Rate: 0.01\n",
      "Epoch [2808/20000], Loss: 1914.10205078125, Entropy 131.88539123535156, Learning Rate: 0.01\n",
      "Epoch [2809/20000], Loss: 2765.89892578125, Entropy 146.3134002685547, Learning Rate: 0.01\n",
      "Epoch [2810/20000], Loss: 1434.44140625, Entropy 148.20106506347656, Learning Rate: 0.01\n",
      "Epoch [2811/20000], Loss: 1982.96630859375, Entropy 117.91964721679688, Learning Rate: 0.01\n",
      "Epoch [2812/20000], Loss: 2278.63232421875, Entropy 144.01327514648438, Learning Rate: 0.01\n",
      "Epoch [2813/20000], Loss: 1373.833740234375, Entropy 134.3308563232422, Learning Rate: 0.01\n",
      "Epoch [2814/20000], Loss: 2578.5615234375, Entropy 126.01270294189453, Learning Rate: 0.01\n",
      "Epoch [2815/20000], Loss: 2189.94189453125, Entropy 121.64569854736328, Learning Rate: 0.01\n",
      "Epoch [2816/20000], Loss: 1741.5577392578125, Entropy 115.42631530761719, Learning Rate: 0.01\n",
      "Epoch [2817/20000], Loss: 4713.6640625, Entropy 110.07040405273438, Learning Rate: 0.01\n",
      "Epoch [2818/20000], Loss: 1170.4169921875, Entropy 105.26596069335938, Learning Rate: 0.01\n",
      "Epoch [2819/20000], Loss: 2458.203125, Entropy 102.77294921875, Learning Rate: 0.01\n",
      "Epoch [2820/20000], Loss: 4899.880859375, Entropy 105.89280700683594, Learning Rate: 0.01\n",
      "Epoch [2821/20000], Loss: 1491.177001953125, Entropy 91.60513305664062, Learning Rate: 0.01\n",
      "Epoch [2822/20000], Loss: 1609.929443359375, Entropy 83.7039794921875, Learning Rate: 0.01\n",
      "Epoch [2823/20000], Loss: 2737.33740234375, Entropy 98.27256774902344, Learning Rate: 0.01\n",
      "Epoch [2824/20000], Loss: 3233.179443359375, Entropy 82.49644470214844, Learning Rate: 0.01\n",
      "Epoch [2825/20000], Loss: 2031.71484375, Entropy 72.68187713623047, Learning Rate: 0.01\n",
      "Epoch [2826/20000], Loss: 1698.45458984375, Entropy 71.53106689453125, Learning Rate: 0.01\n",
      "Epoch [2827/20000], Loss: 2409.50390625, Entropy 63.0561408996582, Learning Rate: 0.01\n",
      "Epoch [2828/20000], Loss: 2618.992431640625, Entropy 55.51646423339844, Learning Rate: 0.01\n",
      "Epoch [2829/20000], Loss: 1812.3861083984375, Entropy 41.06564712524414, Learning Rate: 0.01\n",
      "Epoch [2830/20000], Loss: 1334.902099609375, Entropy 41.27175521850586, Learning Rate: 0.01\n",
      "Epoch [2831/20000], Loss: 1520.614501953125, Entropy 52.1154670715332, Learning Rate: 0.01\n",
      "Epoch [2832/20000], Loss: 2853.299560546875, Entropy 45.25912857055664, Learning Rate: 0.01\n",
      "Epoch [2833/20000], Loss: 1600.822265625, Entropy 45.25362014770508, Learning Rate: 0.01\n",
      "Epoch [2834/20000], Loss: 1443.608154296875, Entropy 26.572050094604492, Learning Rate: 0.01\n",
      "Epoch [2835/20000], Loss: 1303.7833251953125, Entropy 23.529117584228516, Learning Rate: 0.01\n",
      "Epoch [2836/20000], Loss: 1634.9107666015625, Entropy 14.498302459716797, Learning Rate: 0.01\n",
      "Epoch [2837/20000], Loss: 1440.269287109375, Entropy 20.916175842285156, Learning Rate: 0.01\n",
      "Epoch [2838/20000], Loss: 1502.0174560546875, Entropy 17.370485305786133, Learning Rate: 0.01\n",
      "Epoch [2839/20000], Loss: 1322.1060791015625, Entropy 7.4657793045043945, Learning Rate: 0.01\n",
      "Epoch [2840/20000], Loss: 1235.98046875, Entropy -3.6399710178375244, Learning Rate: 0.01\n",
      "Epoch [2841/20000], Loss: 1295.025146484375, Entropy -11.003252029418945, Learning Rate: 0.01\n",
      "Epoch [2842/20000], Loss: 1476.2459716796875, Entropy 22.260488510131836, Learning Rate: 0.01\n",
      "Epoch [2843/20000], Loss: 1405.8179931640625, Entropy -9.599653244018555, Learning Rate: 0.01\n",
      "Epoch [2844/20000], Loss: 1331.8533935546875, Entropy -1.9524743556976318, Learning Rate: 0.01\n",
      "Epoch [2845/20000], Loss: 1230.385986328125, Entropy -9.062881469726562, Learning Rate: 0.01\n",
      "Epoch [2846/20000], Loss: 1233.50732421875, Entropy 2.3181746006011963, Learning Rate: 0.01\n",
      "Epoch [2847/20000], Loss: 1285.6922607421875, Entropy 3.678327798843384, Learning Rate: 0.01\n",
      "Epoch [2848/20000], Loss: 1369.4605712890625, Entropy -3.5594072341918945, Learning Rate: 0.01\n",
      "Epoch [2849/20000], Loss: 1260.755859375, Entropy -0.7863125205039978, Learning Rate: 0.01\n",
      "Epoch [2850/20000], Loss: 1229.7843017578125, Entropy -12.768952369689941, Learning Rate: 0.01\n",
      "Epoch [2851/20000], Loss: 1185.7669677734375, Entropy -0.6450463533401489, Learning Rate: 0.01\n",
      "Epoch [2852/20000], Loss: 1238.360107421875, Entropy -5.292372226715088, Learning Rate: 0.01\n",
      "Epoch [2853/20000], Loss: 1302.3399658203125, Entropy -17.620378494262695, Learning Rate: 0.01\n",
      "Epoch [2854/20000], Loss: 1237.8612060546875, Entropy 7.536850929260254, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2855/20000], Loss: 1225.3038330078125, Entropy 3.2601284980773926, Learning Rate: 0.01\n",
      "Epoch [2856/20000], Loss: 1194.9461669921875, Entropy 9.126415252685547, Learning Rate: 0.01\n",
      "Epoch [2857/20000], Loss: 1235.163818359375, Entropy 11.579252243041992, Learning Rate: 0.01\n",
      "Epoch [2858/20000], Loss: 1211.9559326171875, Entropy 3.684760093688965, Learning Rate: 0.01\n",
      "Epoch [2859/20000], Loss: 1233.1480712890625, Entropy 6.560944080352783, Learning Rate: 0.01\n",
      "Epoch [2860/20000], Loss: 1240.05419921875, Entropy -0.14745604991912842, Learning Rate: 0.01\n",
      "Epoch [2861/20000], Loss: 1188.242431640625, Entropy -2.6830191612243652, Learning Rate: 0.01\n",
      "Epoch [2862/20000], Loss: 1157.8795166015625, Entropy 10.181020736694336, Learning Rate: 0.01\n",
      "Epoch [2863/20000], Loss: 1203.8507080078125, Entropy -3.7785637378692627, Learning Rate: 0.01\n",
      "Epoch [2864/20000], Loss: 1218.4146728515625, Entropy -1.5831905603408813, Learning Rate: 0.01\n",
      "Epoch [2865/20000], Loss: 1175.0625, Entropy 10.053332328796387, Learning Rate: 0.01\n",
      "Epoch [2866/20000], Loss: 1163.72705078125, Entropy 9.534162521362305, Learning Rate: 0.01\n",
      "Epoch [2867/20000], Loss: 1227.4205322265625, Entropy -14.568720817565918, Learning Rate: 0.01\n",
      "Epoch [2868/20000], Loss: 1180.447021484375, Entropy 14.8768949508667, Learning Rate: 0.01\n",
      "Epoch [2869/20000], Loss: 1186.641845703125, Entropy 15.425451278686523, Learning Rate: 0.01\n",
      "Epoch [2870/20000], Loss: 1215.32177734375, Entropy -4.750089168548584, Learning Rate: 0.01\n",
      "Epoch [2871/20000], Loss: 1167.8597412109375, Entropy 10.451019287109375, Learning Rate: 0.01\n",
      "Epoch [2872/20000], Loss: 1186.57421875, Entropy -3.3794021606445312, Learning Rate: 0.01\n",
      "Epoch [2873/20000], Loss: 1188.955322265625, Entropy -1.4500497579574585, Learning Rate: 0.01\n",
      "Epoch [2874/20000], Loss: 1193.2049560546875, Entropy -1.2897253036499023, Learning Rate: 0.01\n",
      "Epoch [2875/20000], Loss: 1200.134521484375, Entropy 20.665863037109375, Learning Rate: 0.01\n",
      "Epoch [2876/20000], Loss: 1156.8243408203125, Entropy 9.44789981842041, Learning Rate: 0.01\n",
      "Epoch [2877/20000], Loss: 1159.415771484375, Entropy 17.848527908325195, Learning Rate: 0.01\n",
      "Epoch [2878/20000], Loss: 1128.736328125, Entropy 20.43829345703125, Learning Rate: 0.01\n",
      "Epoch [2879/20000], Loss: 1151.662353515625, Entropy 19.09512710571289, Learning Rate: 0.01\n",
      "Epoch [2880/20000], Loss: 1166.350830078125, Entropy 10.431889533996582, Learning Rate: 0.01\n",
      "Epoch [2881/20000], Loss: 1168.461181640625, Entropy 24.137340545654297, Learning Rate: 0.01\n",
      "Epoch [2882/20000], Loss: 1146.268310546875, Entropy 15.03311824798584, Learning Rate: 0.01\n",
      "Epoch [2883/20000], Loss: 1137.74951171875, Entropy 20.6500244140625, Learning Rate: 0.01\n",
      "Epoch [2884/20000], Loss: 1147.9974365234375, Entropy 16.341196060180664, Learning Rate: 0.01\n",
      "Epoch [2885/20000], Loss: 1143.547607421875, Entropy 32.1296272277832, Learning Rate: 0.01\n",
      "Epoch [2886/20000], Loss: 1154.7049560546875, Entropy 25.178955078125, Learning Rate: 0.01\n",
      "Epoch [2887/20000], Loss: 1147.6495361328125, Entropy 12.483821868896484, Learning Rate: 0.01\n",
      "Epoch [2888/20000], Loss: 1144.6348876953125, Entropy 10.219106674194336, Learning Rate: 0.01\n",
      "Epoch [2889/20000], Loss: 1126.180419921875, Entropy 29.102035522460938, Learning Rate: 0.01\n",
      "Epoch [2890/20000], Loss: 1142.2569580078125, Entropy 14.685989379882812, Learning Rate: 0.01\n",
      "Epoch [2891/20000], Loss: 1137.4364013671875, Entropy 23.968374252319336, Learning Rate: 0.01\n",
      "Epoch [2892/20000], Loss: 1151.92919921875, Entropy 17.40538215637207, Learning Rate: 0.01\n",
      "Epoch [2893/20000], Loss: 1135.138427734375, Entropy 26.17669677734375, Learning Rate: 0.01\n",
      "Epoch [2894/20000], Loss: 1135.2398681640625, Entropy 24.192455291748047, Learning Rate: 0.01\n",
      "Epoch [2895/20000], Loss: 1146.9932861328125, Entropy 30.64111328125, Learning Rate: 0.01\n",
      "Epoch [2896/20000], Loss: 1122.7098388671875, Entropy 22.12051773071289, Learning Rate: 0.01\n",
      "Epoch [2897/20000], Loss: 1130.333740234375, Entropy 29.174901962280273, Learning Rate: 0.01\n",
      "Epoch [2898/20000], Loss: 1155.6297607421875, Entropy 31.039037704467773, Learning Rate: 0.01\n",
      "Epoch [2899/20000], Loss: 1144.9573974609375, Entropy 31.43569564819336, Learning Rate: 0.01\n",
      "Epoch [2900/20000], Loss: 1114.2696533203125, Entropy 29.12485694885254, Learning Rate: 0.01\n",
      "Epoch [2901/20000], Loss: 1145.014404296875, Entropy 28.293563842773438, Learning Rate: 0.01\n",
      "Epoch [2902/20000], Loss: 1121.57421875, Entropy 22.401716232299805, Learning Rate: 0.01\n",
      "Epoch [2903/20000], Loss: 1138.523193359375, Entropy 36.97309112548828, Learning Rate: 0.01\n",
      "Epoch [2904/20000], Loss: 1124.4658203125, Entropy 34.466102600097656, Learning Rate: 0.01\n",
      "Epoch [2905/20000], Loss: 1133.1302490234375, Entropy 35.51478576660156, Learning Rate: 0.01\n",
      "Epoch [2906/20000], Loss: 1095.8953857421875, Entropy 39.39457702636719, Learning Rate: 0.01\n",
      "Epoch [2907/20000], Loss: 1112.7305908203125, Entropy 49.66169738769531, Learning Rate: 0.01\n",
      "Epoch [2908/20000], Loss: 1116.802734375, Entropy 42.53955078125, Learning Rate: 0.01\n",
      "Epoch [2909/20000], Loss: 1103.010498046875, Entropy 46.359432220458984, Learning Rate: 0.01\n",
      "Epoch [2910/20000], Loss: 1124.7230224609375, Entropy 34.585628509521484, Learning Rate: 0.01\n",
      "Epoch [2911/20000], Loss: 1138.6949462890625, Entropy 37.82670211791992, Learning Rate: 0.01\n",
      "Epoch [2912/20000], Loss: 1167.8740234375, Entropy 35.96134567260742, Learning Rate: 0.01\n",
      "Epoch [2913/20000], Loss: 1145.5411376953125, Entropy 52.50490188598633, Learning Rate: 0.01\n",
      "Epoch [2914/20000], Loss: 1126.20361328125, Entropy 39.56154251098633, Learning Rate: 0.01\n",
      "Epoch [2915/20000], Loss: 1150.3568115234375, Entropy 45.01216506958008, Learning Rate: 0.01\n",
      "Epoch [2916/20000], Loss: 1122.17431640625, Entropy 43.79863357543945, Learning Rate: 0.01\n",
      "Epoch [2917/20000], Loss: 1098.693115234375, Entropy 44.76801681518555, Learning Rate: 0.01\n",
      "Epoch [2918/20000], Loss: 1091.482421875, Entropy 57.50709533691406, Learning Rate: 0.01\n",
      "Epoch [2919/20000], Loss: 1130.20947265625, Entropy 53.34965133666992, Learning Rate: 0.01\n",
      "Epoch [2920/20000], Loss: 1112.135498046875, Entropy 47.714866638183594, Learning Rate: 0.01\n",
      "Epoch [2921/20000], Loss: 1129.92041015625, Entropy 62.11394500732422, Learning Rate: 0.01\n",
      "Epoch [2922/20000], Loss: 1092.8397216796875, Entropy 58.03009796142578, Learning Rate: 0.01\n",
      "Epoch [2923/20000], Loss: 1095.9251708984375, Entropy 59.38536071777344, Learning Rate: 0.01\n",
      "Epoch [2924/20000], Loss: 1132.455322265625, Entropy 46.54539108276367, Learning Rate: 0.01\n",
      "Epoch [2925/20000], Loss: 1123.341064453125, Entropy 59.67193603515625, Learning Rate: 0.01\n",
      "Epoch [2926/20000], Loss: 1110.2125244140625, Entropy 58.79328918457031, Learning Rate: 0.01\n",
      "Epoch [2927/20000], Loss: 1118.4031982421875, Entropy 48.99634552001953, Learning Rate: 0.01\n",
      "Epoch [2928/20000], Loss: 1118.251953125, Entropy 50.19240951538086, Learning Rate: 0.01\n",
      "Epoch [2929/20000], Loss: 1080.6966552734375, Entropy 71.11157989501953, Learning Rate: 0.01\n",
      "Epoch [2930/20000], Loss: 1129.8585205078125, Entropy 64.57662963867188, Learning Rate: 0.01\n",
      "Epoch [2931/20000], Loss: 1108.787353515625, Entropy 52.05584716796875, Learning Rate: 0.01\n",
      "Epoch [2932/20000], Loss: 1101.1156005859375, Entropy 67.70616149902344, Learning Rate: 0.01\n",
      "Epoch [2933/20000], Loss: 1119.2945556640625, Entropy 58.426395416259766, Learning Rate: 0.01\n",
      "Epoch [2934/20000], Loss: 1090.986572265625, Entropy 51.08375930786133, Learning Rate: 0.01\n",
      "Epoch [2935/20000], Loss: 1108.2626953125, Entropy 64.32442474365234, Learning Rate: 0.01\n",
      "Epoch [2936/20000], Loss: 1080.3677978515625, Entropy 62.1684455871582, Learning Rate: 0.01\n",
      "Epoch [2937/20000], Loss: 1076.7470703125, Entropy 75.20708465576172, Learning Rate: 0.01\n",
      "Epoch [2938/20000], Loss: 1114.3148193359375, Entropy 64.57217407226562, Learning Rate: 0.01\n",
      "Epoch [2939/20000], Loss: 1104.521484375, Entropy 58.395408630371094, Learning Rate: 0.01\n",
      "Epoch [2940/20000], Loss: 1094.4312744140625, Entropy 59.77499771118164, Learning Rate: 0.01\n",
      "Epoch [2941/20000], Loss: 1094.9453125, Entropy 67.12552642822266, Learning Rate: 0.01\n",
      "Epoch [2942/20000], Loss: 1077.9576416015625, Entropy 70.64836883544922, Learning Rate: 0.01\n",
      "Epoch [2943/20000], Loss: 1061.808837890625, Entropy 74.58816528320312, Learning Rate: 0.01\n",
      "Epoch [2944/20000], Loss: 1099.19580078125, Entropy 67.4443359375, Learning Rate: 0.01\n",
      "Epoch [2945/20000], Loss: 1120.581298828125, Entropy 60.65658950805664, Learning Rate: 0.01\n",
      "Epoch [2946/20000], Loss: 1089.1708984375, Entropy 65.0810546875, Learning Rate: 0.01\n",
      "Epoch [2947/20000], Loss: 1108.5372314453125, Entropy 72.83586883544922, Learning Rate: 0.01\n",
      "Epoch [2948/20000], Loss: 1105.81787109375, Entropy 71.00363159179688, Learning Rate: 0.01\n",
      "Epoch [2949/20000], Loss: 1096.052734375, Entropy 62.78842544555664, Learning Rate: 0.01\n",
      "Epoch [2950/20000], Loss: 1097.3883056640625, Entropy 77.02558898925781, Learning Rate: 0.01\n",
      "Epoch [2951/20000], Loss: 1108.7742919921875, Entropy 68.23379516601562, Learning Rate: 0.01\n",
      "Epoch [2952/20000], Loss: 1084.9005126953125, Entropy 71.11176300048828, Learning Rate: 0.01\n",
      "Epoch [2953/20000], Loss: 1059.0533447265625, Entropy 80.22734069824219, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2954/20000], Loss: 1112.6700439453125, Entropy 65.06038665771484, Learning Rate: 0.01\n",
      "Epoch [2955/20000], Loss: 1104.19677734375, Entropy 59.232303619384766, Learning Rate: 0.01\n",
      "Epoch [2956/20000], Loss: 1079.293212890625, Entropy 77.44058990478516, Learning Rate: 0.01\n",
      "Epoch [2957/20000], Loss: 1126.88525390625, Entropy 54.117835998535156, Learning Rate: 0.01\n",
      "Epoch [2958/20000], Loss: 1102.53662109375, Entropy 64.04171752929688, Learning Rate: 0.01\n",
      "Epoch [2959/20000], Loss: 1090.606201171875, Entropy 66.86751556396484, Learning Rate: 0.01\n",
      "Epoch [2960/20000], Loss: 1082.5615234375, Entropy 83.17362976074219, Learning Rate: 0.01\n",
      "Epoch [2961/20000], Loss: 1119.2410888671875, Entropy 56.94859313964844, Learning Rate: 0.01\n",
      "Epoch [2962/20000], Loss: 1056.8878173828125, Entropy 85.18560028076172, Learning Rate: 0.01\n",
      "Epoch [2963/20000], Loss: 1094.99267578125, Entropy 82.5951156616211, Learning Rate: 0.01\n",
      "Epoch [2964/20000], Loss: 1081.86279296875, Entropy 74.48562622070312, Learning Rate: 0.01\n",
      "Epoch [2965/20000], Loss: 1062.3260498046875, Entropy 83.1298599243164, Learning Rate: 0.01\n",
      "Epoch [2966/20000], Loss: 1078.4404296875, Entropy 87.48308563232422, Learning Rate: 0.01\n",
      "Epoch [2967/20000], Loss: 1080.0596923828125, Entropy 83.05001068115234, Learning Rate: 0.01\n",
      "Epoch [2968/20000], Loss: 1087.75927734375, Entropy 81.81963348388672, Learning Rate: 0.01\n",
      "Epoch [2969/20000], Loss: 1063.978515625, Entropy 95.527587890625, Learning Rate: 0.01\n",
      "Epoch [2970/20000], Loss: 1064.6260986328125, Entropy 93.9000473022461, Learning Rate: 0.01\n",
      "Epoch [2971/20000], Loss: 1083.3572998046875, Entropy 67.89464569091797, Learning Rate: 0.01\n",
      "Epoch [2972/20000], Loss: 1110.305908203125, Entropy 87.08877563476562, Learning Rate: 0.01\n",
      "Epoch [2973/20000], Loss: 1090.1004638671875, Entropy 85.57383728027344, Learning Rate: 0.01\n",
      "Epoch [2974/20000], Loss: 1121.4146728515625, Entropy 84.76046752929688, Learning Rate: 0.01\n",
      "Epoch [2975/20000], Loss: 1097.202392578125, Entropy 72.41082000732422, Learning Rate: 0.01\n",
      "Epoch [2976/20000], Loss: 1080.968017578125, Entropy 85.85728454589844, Learning Rate: 0.01\n",
      "Epoch [2977/20000], Loss: 1080.908447265625, Entropy 100.06871795654297, Learning Rate: 0.01\n",
      "Epoch [2978/20000], Loss: 1093.4747314453125, Entropy 88.01203155517578, Learning Rate: 0.01\n",
      "Epoch [2979/20000], Loss: 1046.6826171875, Entropy 102.00022888183594, Learning Rate: 0.01\n",
      "Epoch [2980/20000], Loss: 1078.212646484375, Entropy 88.65342712402344, Learning Rate: 0.01\n",
      "Epoch [2981/20000], Loss: 1077.651611328125, Entropy 99.08120727539062, Learning Rate: 0.01\n",
      "Epoch [2982/20000], Loss: 1072.7681884765625, Entropy 93.5358657836914, Learning Rate: 0.01\n",
      "Epoch [2983/20000], Loss: 1069.74658203125, Entropy 101.24434661865234, Learning Rate: 0.01\n",
      "Epoch [2984/20000], Loss: 1057.185791015625, Entropy 107.23462677001953, Learning Rate: 0.01\n",
      "Epoch [2985/20000], Loss: 1103.24609375, Entropy 85.9123306274414, Learning Rate: 0.01\n",
      "Epoch [2986/20000], Loss: 1099.2783203125, Entropy 80.77005004882812, Learning Rate: 0.01\n",
      "Epoch [2987/20000], Loss: 1059.2606201171875, Entropy 93.990234375, Learning Rate: 0.01\n",
      "Epoch [2988/20000], Loss: 1063.5771484375, Entropy 103.66664123535156, Learning Rate: 0.01\n",
      "Epoch [2989/20000], Loss: 1091.716064453125, Entropy 82.04347229003906, Learning Rate: 0.01\n",
      "Epoch [2990/20000], Loss: 1093.4635009765625, Entropy 81.23348236083984, Learning Rate: 0.01\n",
      "Epoch [2991/20000], Loss: 1060.727294921875, Entropy 98.9632568359375, Learning Rate: 0.01\n",
      "Epoch [2992/20000], Loss: 1062.25830078125, Entropy 98.47869873046875, Learning Rate: 0.01\n",
      "Epoch [2993/20000], Loss: 1062.8804931640625, Entropy 107.25296020507812, Learning Rate: 0.01\n",
      "Epoch [2994/20000], Loss: 1093.144287109375, Entropy 99.87298583984375, Learning Rate: 0.01\n",
      "Epoch [2995/20000], Loss: 1060.5428466796875, Entropy 112.24777221679688, Learning Rate: 0.01\n",
      "Epoch [2996/20000], Loss: 1082.62646484375, Entropy 89.21378326416016, Learning Rate: 0.01\n",
      "Epoch [2997/20000], Loss: 1093.8201904296875, Entropy 97.16165924072266, Learning Rate: 0.01\n",
      "Epoch [2998/20000], Loss: 1068.2623291015625, Entropy 103.87527465820312, Learning Rate: 0.01\n",
      "Epoch [2999/20000], Loss: 1057.2982177734375, Entropy 98.18049621582031, Learning Rate: 0.01\n",
      "Epoch [3000/20000], Loss: 1072.0958251953125, Entropy 107.90681457519531, Learning Rate: 0.01\n",
      "Epoch [3001/20000], Loss: 1059.3909912109375, Entropy 122.24991607666016, Learning Rate: 0.01\n",
      "Epoch [3002/20000], Loss: 1057.4625244140625, Entropy 98.02413177490234, Learning Rate: 0.01\n",
      "Epoch [3003/20000], Loss: 1092.760498046875, Entropy 103.7034912109375, Learning Rate: 0.01\n",
      "Epoch [3004/20000], Loss: 1074.6015625, Entropy 94.02810668945312, Learning Rate: 0.01\n",
      "Epoch [3005/20000], Loss: 1069.6829833984375, Entropy 107.72283172607422, Learning Rate: 0.01\n",
      "Epoch [3006/20000], Loss: 1060.1158447265625, Entropy 109.53526306152344, Learning Rate: 0.01\n",
      "Epoch [3007/20000], Loss: 1053.7568359375, Entropy 117.0941162109375, Learning Rate: 0.01\n",
      "Epoch [3008/20000], Loss: 1067.7611083984375, Entropy 103.88617706298828, Learning Rate: 0.01\n",
      "Epoch [3009/20000], Loss: 1051.815185546875, Entropy 119.54181671142578, Learning Rate: 0.01\n",
      "Epoch [3010/20000], Loss: 1065.6363525390625, Entropy 110.94779205322266, Learning Rate: 0.01\n",
      "Epoch [3011/20000], Loss: 1058.44189453125, Entropy 112.37847137451172, Learning Rate: 0.01\n",
      "Epoch [3012/20000], Loss: 1054.4774169921875, Entropy 120.37490844726562, Learning Rate: 0.01\n",
      "Epoch [3013/20000], Loss: 1088.414794921875, Entropy 100.9237289428711, Learning Rate: 0.01\n",
      "Epoch [3014/20000], Loss: 1061.6856689453125, Entropy 111.67261505126953, Learning Rate: 0.01\n",
      "Epoch [3015/20000], Loss: 1056.01806640625, Entropy 123.25062561035156, Learning Rate: 0.01\n",
      "Epoch [3016/20000], Loss: 1068.3096923828125, Entropy 126.12535095214844, Learning Rate: 0.01\n",
      "Epoch [3017/20000], Loss: 1023.3436889648438, Entropy 123.88858795166016, Learning Rate: 0.01\n",
      "Epoch [3018/20000], Loss: 1077.59716796875, Entropy 99.9373550415039, Learning Rate: 0.01\n",
      "Epoch [3019/20000], Loss: 1059.64794921875, Entropy 111.21817779541016, Learning Rate: 0.01\n",
      "Epoch [3020/20000], Loss: 1082.45361328125, Entropy 107.03154754638672, Learning Rate: 0.01\n",
      "Epoch [3021/20000], Loss: 1048.308349609375, Entropy 133.11810302734375, Learning Rate: 0.01\n",
      "Epoch [3022/20000], Loss: 1044.3975830078125, Entropy 115.45012664794922, Learning Rate: 0.01\n",
      "Epoch [3023/20000], Loss: 1082.0645751953125, Entropy 107.95218658447266, Learning Rate: 0.01\n",
      "Epoch [3024/20000], Loss: 1046.06689453125, Entropy 113.60606384277344, Learning Rate: 0.01\n",
      "Epoch [3025/20000], Loss: 1041.5059814453125, Entropy 128.84347534179688, Learning Rate: 0.01\n",
      "Epoch [3026/20000], Loss: 1068.2884521484375, Entropy 115.48939514160156, Learning Rate: 0.01\n",
      "Epoch [3027/20000], Loss: 1054.3563232421875, Entropy 117.92848205566406, Learning Rate: 0.01\n",
      "Epoch [3028/20000], Loss: 1042.763916015625, Entropy 126.5624771118164, Learning Rate: 0.01\n",
      "Epoch [3029/20000], Loss: 1052.8099365234375, Entropy 116.24183654785156, Learning Rate: 0.01\n",
      "Epoch [3030/20000], Loss: 1052.1212158203125, Entropy 129.9994354248047, Learning Rate: 0.01\n",
      "Epoch [3031/20000], Loss: 1026.3265380859375, Entropy 131.8182373046875, Learning Rate: 0.01\n",
      "Epoch [3032/20000], Loss: 1059.08447265625, Entropy 120.95077514648438, Learning Rate: 0.01\n",
      "Epoch [3033/20000], Loss: 1053.965576171875, Entropy 120.29720306396484, Learning Rate: 0.01\n",
      "Epoch [3034/20000], Loss: 1079.5938720703125, Entropy 120.33028411865234, Learning Rate: 0.01\n",
      "Epoch [3035/20000], Loss: 1084.389404296875, Entropy 121.1856689453125, Learning Rate: 0.01\n",
      "Epoch [3036/20000], Loss: 1144.19140625, Entropy 115.54117584228516, Learning Rate: 0.01\n",
      "Epoch [3037/20000], Loss: 1069.884033203125, Entropy 114.1976318359375, Learning Rate: 0.01\n",
      "Epoch [3038/20000], Loss: 1052.8619384765625, Entropy 142.06565856933594, Learning Rate: 0.01\n",
      "Epoch [3039/20000], Loss: 1055.2088623046875, Entropy 125.65239715576172, Learning Rate: 0.01\n",
      "Epoch [3040/20000], Loss: 1050.3917236328125, Entropy 115.0072250366211, Learning Rate: 0.01\n",
      "Epoch [3041/20000], Loss: 1051.7752685546875, Entropy 125.62850189208984, Learning Rate: 0.01\n",
      "Epoch [3042/20000], Loss: 1066.744140625, Entropy 122.5387954711914, Learning Rate: 0.01\n",
      "Epoch [3043/20000], Loss: 1030.03564453125, Entropy 138.51763916015625, Learning Rate: 0.01\n",
      "Epoch [3044/20000], Loss: 1085.6904296875, Entropy 112.29668426513672, Learning Rate: 0.01\n",
      "Epoch [3045/20000], Loss: 1054.899658203125, Entropy 127.30937194824219, Learning Rate: 0.01\n",
      "Epoch [3046/20000], Loss: 1085.5906982421875, Entropy 104.89999389648438, Learning Rate: 0.01\n",
      "Epoch [3047/20000], Loss: 1067.7698974609375, Entropy 136.54237365722656, Learning Rate: 0.01\n",
      "Epoch [3048/20000], Loss: 1065.9168701171875, Entropy 130.25888061523438, Learning Rate: 0.01\n",
      "Epoch [3049/20000], Loss: 1046.359130859375, Entropy 131.5939483642578, Learning Rate: 0.01\n",
      "Epoch [3050/20000], Loss: 1059.1514892578125, Entropy 139.55763244628906, Learning Rate: 0.01\n",
      "Epoch [3051/20000], Loss: 1059.7930908203125, Entropy 140.8126678466797, Learning Rate: 0.01\n",
      "Epoch [3052/20000], Loss: 1059.45751953125, Entropy 133.3737030029297, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3053/20000], Loss: 1051.2935791015625, Entropy 129.66371154785156, Learning Rate: 0.01\n",
      "Epoch [3054/20000], Loss: 1035.8531494140625, Entropy 136.41624450683594, Learning Rate: 0.01\n",
      "Epoch [3055/20000], Loss: 1014.4884033203125, Entropy 148.61947631835938, Learning Rate: 0.01\n",
      "Epoch [3056/20000], Loss: 1079.1402587890625, Entropy 114.78559112548828, Learning Rate: 0.01\n",
      "Epoch [3057/20000], Loss: 1066.481689453125, Entropy 120.21272277832031, Learning Rate: 0.01\n",
      "Epoch [3058/20000], Loss: 1095.3878173828125, Entropy 136.70091247558594, Learning Rate: 0.01\n",
      "Epoch [3059/20000], Loss: 1052.2425537109375, Entropy 124.52464294433594, Learning Rate: 0.01\n",
      "Epoch [3060/20000], Loss: 1098.877197265625, Entropy 149.0066680908203, Learning Rate: 0.01\n",
      "Epoch [3061/20000], Loss: 1068.5068359375, Entropy 128.83363342285156, Learning Rate: 0.01\n",
      "Epoch [3062/20000], Loss: 1063.00927734375, Entropy 162.07113647460938, Learning Rate: 0.01\n",
      "Epoch [3063/20000], Loss: 1047.1800537109375, Entropy 136.78489685058594, Learning Rate: 0.01\n",
      "Epoch [3064/20000], Loss: 1072.7979736328125, Entropy 134.34829711914062, Learning Rate: 0.01\n",
      "Epoch [3065/20000], Loss: 1083.0428466796875, Entropy 128.75564575195312, Learning Rate: 0.01\n",
      "Epoch [3066/20000], Loss: 1061.582275390625, Entropy 145.95082092285156, Learning Rate: 0.01\n",
      "Epoch [3067/20000], Loss: 1094.954833984375, Entropy 132.2758331298828, Learning Rate: 0.01\n",
      "Epoch [3068/20000], Loss: 1038.687744140625, Entropy 131.42860412597656, Learning Rate: 0.01\n",
      "Epoch [3069/20000], Loss: 1052.38623046875, Entropy 139.4479522705078, Learning Rate: 0.01\n",
      "Epoch [3070/20000], Loss: 1066.156005859375, Entropy 136.579833984375, Learning Rate: 0.01\n",
      "Epoch [3071/20000], Loss: 1051.8525390625, Entropy 130.4889373779297, Learning Rate: 0.01\n",
      "Epoch [3072/20000], Loss: 1024.47509765625, Entropy 144.08428955078125, Learning Rate: 0.01\n",
      "Epoch [3073/20000], Loss: 1062.400634765625, Entropy 130.0369110107422, Learning Rate: 0.01\n",
      "Epoch [3074/20000], Loss: 1050.80419921875, Entropy 145.44244384765625, Learning Rate: 0.01\n",
      "Epoch [3075/20000], Loss: 1061.87890625, Entropy 138.80311584472656, Learning Rate: 0.01\n",
      "Epoch [3076/20000], Loss: 1054.9620361328125, Entropy 138.4606170654297, Learning Rate: 0.01\n",
      "Epoch [3077/20000], Loss: 1023.015869140625, Entropy 142.39974975585938, Learning Rate: 0.01\n",
      "Epoch [3078/20000], Loss: 1040.888916015625, Entropy 145.25889587402344, Learning Rate: 0.01\n",
      "Epoch [3079/20000], Loss: 1073.7041015625, Entropy 133.71212768554688, Learning Rate: 0.01\n",
      "Epoch [3080/20000], Loss: 1043.88623046875, Entropy 145.38746643066406, Learning Rate: 0.01\n",
      "Epoch [3081/20000], Loss: 1011.7861328125, Entropy 148.23744201660156, Learning Rate: 0.01\n",
      "Epoch [3082/20000], Loss: 1086.468505859375, Entropy 130.02716064453125, Learning Rate: 0.01\n",
      "Epoch [3083/20000], Loss: 1044.81787109375, Entropy 144.00933837890625, Learning Rate: 0.01\n",
      "Epoch [3084/20000], Loss: 1050.1953125, Entropy 153.6399688720703, Learning Rate: 0.01\n",
      "Epoch [3085/20000], Loss: 1071.54443359375, Entropy 134.762451171875, Learning Rate: 0.01\n",
      "Epoch [3086/20000], Loss: 1012.3472900390625, Entropy 157.45118713378906, Learning Rate: 0.01\n",
      "Epoch [3087/20000], Loss: 1030.369873046875, Entropy 132.31890869140625, Learning Rate: 0.01\n",
      "Epoch [3088/20000], Loss: 1068.5997314453125, Entropy 144.98074340820312, Learning Rate: 0.01\n",
      "Epoch [3089/20000], Loss: 1059.66552734375, Entropy 127.5931625366211, Learning Rate: 0.01\n",
      "Epoch [3090/20000], Loss: 1022.2705688476562, Entropy 154.25640869140625, Learning Rate: 0.01\n",
      "Epoch [3091/20000], Loss: 1032.914306640625, Entropy 155.0543975830078, Learning Rate: 0.01\n",
      "Epoch [3092/20000], Loss: 1064.868896484375, Entropy 159.1685333251953, Learning Rate: 0.01\n",
      "Epoch [3093/20000], Loss: 1035.3804931640625, Entropy 150.11436462402344, Learning Rate: 0.01\n",
      "Epoch [3094/20000], Loss: 1050.573974609375, Entropy 132.75057983398438, Learning Rate: 0.01\n",
      "Epoch [3095/20000], Loss: 1064.02294921875, Entropy 145.55911254882812, Learning Rate: 0.01\n",
      "Epoch [3096/20000], Loss: 1024.501220703125, Entropy 152.07861328125, Learning Rate: 0.01\n",
      "Epoch [3097/20000], Loss: 1044.59521484375, Entropy 154.56224060058594, Learning Rate: 0.01\n",
      "Epoch [3098/20000], Loss: 1032.3385009765625, Entropy 155.3917999267578, Learning Rate: 0.01\n",
      "Epoch [3099/20000], Loss: 1037.931396484375, Entropy 154.68414306640625, Learning Rate: 0.01\n",
      "Epoch [3100/20000], Loss: 1034.409912109375, Entropy 149.36380004882812, Learning Rate: 0.01\n",
      "Epoch [3101/20000], Loss: 1055.9017333984375, Entropy 158.14561462402344, Learning Rate: 0.01\n",
      "Epoch [3102/20000], Loss: 1011.455322265625, Entropy 162.13868713378906, Learning Rate: 0.01\n",
      "Epoch [3103/20000], Loss: 1024.863037109375, Entropy 166.41065979003906, Learning Rate: 0.01\n",
      "Epoch [3104/20000], Loss: 1017.8523559570312, Entropy 172.60101318359375, Learning Rate: 0.01\n",
      "Epoch [3105/20000], Loss: 1052.383056640625, Entropy 154.408935546875, Learning Rate: 0.01\n",
      "Epoch [3106/20000], Loss: 1054.387451171875, Entropy 161.34600830078125, Learning Rate: 0.01\n",
      "Epoch [3107/20000], Loss: 1021.3432006835938, Entropy 153.7906951904297, Learning Rate: 0.01\n",
      "Epoch [3108/20000], Loss: 1031.3544921875, Entropy 153.16854858398438, Learning Rate: 0.01\n",
      "Epoch [3109/20000], Loss: 1083.2518310546875, Entropy 147.3944549560547, Learning Rate: 0.01\n",
      "Epoch [3110/20000], Loss: 1036.9190673828125, Entropy 153.00857543945312, Learning Rate: 0.01\n",
      "Epoch [3111/20000], Loss: 1068.3597412109375, Entropy 153.4205322265625, Learning Rate: 0.01\n",
      "Epoch [3112/20000], Loss: 1024.8367919921875, Entropy 164.00106811523438, Learning Rate: 0.01\n",
      "Epoch [3113/20000], Loss: 1123.802978515625, Entropy 151.19924926757812, Learning Rate: 0.01\n",
      "Epoch [3114/20000], Loss: 1088.062255859375, Entropy 157.32281494140625, Learning Rate: 0.01\n",
      "Epoch [3115/20000], Loss: 1021.5576782226562, Entropy 162.22906494140625, Learning Rate: 0.01\n",
      "Epoch [3116/20000], Loss: 1061.0220947265625, Entropy 164.36398315429688, Learning Rate: 0.01\n",
      "Epoch [3117/20000], Loss: 1029.1724853515625, Entropy 157.51779174804688, Learning Rate: 0.01\n",
      "Epoch [3118/20000], Loss: 1078.95556640625, Entropy 144.60691833496094, Learning Rate: 0.01\n",
      "Epoch [3119/20000], Loss: 1045.4710693359375, Entropy 170.81710815429688, Learning Rate: 0.01\n",
      "Epoch [3120/20000], Loss: 1067.482666015625, Entropy 143.86111450195312, Learning Rate: 0.01\n",
      "Epoch [3121/20000], Loss: 1072.3880615234375, Entropy 163.59715270996094, Learning Rate: 0.01\n",
      "Epoch [3122/20000], Loss: 1060.4559326171875, Entropy 157.93362426757812, Learning Rate: 0.01\n",
      "Epoch [3123/20000], Loss: 1012.2598876953125, Entropy 157.35731506347656, Learning Rate: 0.01\n",
      "Epoch [3124/20000], Loss: 1034.4984130859375, Entropy 161.96725463867188, Learning Rate: 0.01\n",
      "Epoch [3125/20000], Loss: 1060.498046875, Entropy 154.79434204101562, Learning Rate: 0.01\n",
      "Epoch [3126/20000], Loss: 1015.1380615234375, Entropy 166.0517578125, Learning Rate: 0.01\n",
      "Epoch [3127/20000], Loss: 1003.7378540039062, Entropy 171.72711181640625, Learning Rate: 0.01\n",
      "Epoch [3128/20000], Loss: 1050.009521484375, Entropy 163.90760803222656, Learning Rate: 0.01\n",
      "Epoch [3129/20000], Loss: 988.7227783203125, Entropy 181.90109252929688, Learning Rate: 0.01\n",
      "Epoch [3130/20000], Loss: 983.7791748046875, Entropy 174.03616333007812, Learning Rate: 0.01\n",
      "Epoch [3131/20000], Loss: 1016.4119873046875, Entropy 168.67124938964844, Learning Rate: 0.01\n",
      "Epoch [3132/20000], Loss: 1063.4210205078125, Entropy 153.2476806640625, Learning Rate: 0.01\n",
      "Epoch [3133/20000], Loss: 972.927001953125, Entropy 183.99880981445312, Learning Rate: 0.01\n",
      "Epoch [3134/20000], Loss: 1028.869140625, Entropy 166.0673370361328, Learning Rate: 0.01\n",
      "Epoch [3135/20000], Loss: 1029.109619140625, Entropy 161.72959899902344, Learning Rate: 0.01\n",
      "Epoch [3136/20000], Loss: 1031.925537109375, Entropy 157.970458984375, Learning Rate: 0.01\n",
      "Epoch [3137/20000], Loss: 1020.3326416015625, Entropy 152.25547790527344, Learning Rate: 0.01\n",
      "Epoch [3138/20000], Loss: 1004.6116333007812, Entropy 164.8361358642578, Learning Rate: 0.01\n",
      "Epoch [3139/20000], Loss: 1078.5189208984375, Entropy 168.3653106689453, Learning Rate: 0.01\n",
      "Epoch [3140/20000], Loss: 1083.8721923828125, Entropy 159.23658752441406, Learning Rate: 0.01\n",
      "Epoch [3141/20000], Loss: 1050.479736328125, Entropy 183.8855438232422, Learning Rate: 0.01\n",
      "Epoch [3142/20000], Loss: 1036.59375, Entropy 163.36148071289062, Learning Rate: 0.01\n",
      "Epoch [3143/20000], Loss: 1046.292236328125, Entropy 169.61636352539062, Learning Rate: 0.01\n",
      "Epoch [3144/20000], Loss: 1016.0126342773438, Entropy 180.08575439453125, Learning Rate: 0.01\n",
      "Epoch [3145/20000], Loss: 1043.503662109375, Entropy 166.05776977539062, Learning Rate: 0.01\n",
      "Epoch [3146/20000], Loss: 1055.911376953125, Entropy 161.4704132080078, Learning Rate: 0.01\n",
      "Epoch [3147/20000], Loss: 1010.9453125, Entropy 189.07272338867188, Learning Rate: 0.01\n",
      "Epoch [3148/20000], Loss: 1080.6942138671875, Entropy 170.47901916503906, Learning Rate: 0.01\n",
      "Epoch [3149/20000], Loss: 1041.4215087890625, Entropy 164.79270935058594, Learning Rate: 0.01\n",
      "Epoch [3150/20000], Loss: 1041.6778564453125, Entropy 176.82386779785156, Learning Rate: 0.01\n",
      "Epoch [3151/20000], Loss: 1001.1998901367188, Entropy 170.3974151611328, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3152/20000], Loss: 1073.777099609375, Entropy 183.20635986328125, Learning Rate: 0.01\n",
      "Epoch [3153/20000], Loss: 1072.0142822265625, Entropy 177.0247802734375, Learning Rate: 0.01\n",
      "Epoch [3154/20000], Loss: 1055.10302734375, Entropy 175.20550537109375, Learning Rate: 0.01\n",
      "Epoch [3155/20000], Loss: 1062.9593505859375, Entropy 162.49349975585938, Learning Rate: 0.01\n",
      "Epoch [3156/20000], Loss: 1159.8953857421875, Entropy 164.15724182128906, Learning Rate: 0.01\n",
      "Epoch [3157/20000], Loss: 1080.191650390625, Entropy 183.9344024658203, Learning Rate: 0.01\n",
      "Epoch [3158/20000], Loss: 1152.01904296875, Entropy 167.33694458007812, Learning Rate: 0.01\n",
      "Epoch [3159/20000], Loss: 1098.8958740234375, Entropy 164.46630859375, Learning Rate: 0.01\n",
      "Epoch [3160/20000], Loss: 1195.4527587890625, Entropy 170.1669158935547, Learning Rate: 0.01\n",
      "Epoch [3161/20000], Loss: 1051.8521728515625, Entropy 165.82777404785156, Learning Rate: 0.01\n",
      "Epoch [3162/20000], Loss: 1147.089599609375, Entropy 169.3400421142578, Learning Rate: 0.01\n",
      "Epoch [3163/20000], Loss: 1069.0767822265625, Entropy 169.37876892089844, Learning Rate: 0.01\n",
      "Epoch [3164/20000], Loss: 1149.6915283203125, Entropy 183.29312133789062, Learning Rate: 0.01\n",
      "Epoch [3165/20000], Loss: 1091.9571533203125, Entropy 183.447998046875, Learning Rate: 0.01\n",
      "Epoch [3166/20000], Loss: 1168.981201171875, Entropy 179.06077575683594, Learning Rate: 0.01\n",
      "Epoch [3167/20000], Loss: 1087.5699462890625, Entropy 169.407470703125, Learning Rate: 0.01\n",
      "Epoch [3168/20000], Loss: 1137.7625732421875, Entropy 176.56625366210938, Learning Rate: 0.01\n",
      "Epoch [3169/20000], Loss: 1062.67138671875, Entropy 180.13877868652344, Learning Rate: 0.01\n",
      "Epoch [3170/20000], Loss: 1104.915283203125, Entropy 174.50352478027344, Learning Rate: 0.01\n",
      "Epoch [3171/20000], Loss: 1123.47314453125, Entropy 179.38198852539062, Learning Rate: 0.01\n",
      "Epoch [3172/20000], Loss: 1066.6492919921875, Entropy 179.4591827392578, Learning Rate: 0.01\n",
      "Epoch [3173/20000], Loss: 1084.2071533203125, Entropy 172.2242889404297, Learning Rate: 0.01\n",
      "Epoch [3174/20000], Loss: 1197.465087890625, Entropy 181.52456665039062, Learning Rate: 0.01\n",
      "Epoch [3175/20000], Loss: 1083.7369384765625, Entropy 168.03468322753906, Learning Rate: 0.01\n",
      "Epoch [3176/20000], Loss: 1185.9766845703125, Entropy 186.4423370361328, Learning Rate: 0.01\n",
      "Epoch [3177/20000], Loss: 1083.900390625, Entropy 167.9364471435547, Learning Rate: 0.01\n",
      "Epoch [3178/20000], Loss: 1210.25927734375, Entropy 174.93191528320312, Learning Rate: 0.01\n",
      "Epoch [3179/20000], Loss: 1177.34619140625, Entropy 188.65687561035156, Learning Rate: 0.01\n",
      "Epoch [3180/20000], Loss: 1162.845947265625, Entropy 169.494140625, Learning Rate: 0.01\n",
      "Epoch [3181/20000], Loss: 1077.848388671875, Entropy 178.95465087890625, Learning Rate: 0.01\n",
      "Epoch [3182/20000], Loss: 1286.3389892578125, Entropy 179.1177520751953, Learning Rate: 0.01\n",
      "Epoch [3183/20000], Loss: 1049.0926513671875, Entropy 179.60569763183594, Learning Rate: 0.01\n",
      "Epoch [3184/20000], Loss: 1191.294189453125, Entropy 172.8202362060547, Learning Rate: 0.01\n",
      "Epoch [3185/20000], Loss: 1172.9158935546875, Entropy 173.24002075195312, Learning Rate: 0.01\n",
      "Epoch [3186/20000], Loss: 1207.760498046875, Entropy 169.63284301757812, Learning Rate: 0.01\n",
      "Epoch [3187/20000], Loss: 1108.6629638671875, Entropy 167.26600646972656, Learning Rate: 0.01\n",
      "Epoch [3188/20000], Loss: 1096.182861328125, Entropy 178.94737243652344, Learning Rate: 0.01\n",
      "Epoch [3189/20000], Loss: 1338.02734375, Entropy 171.21597290039062, Learning Rate: 0.01\n",
      "Epoch [3190/20000], Loss: 1107.4609375, Entropy 162.98204040527344, Learning Rate: 0.01\n",
      "Epoch [3191/20000], Loss: 1729.59130859375, Entropy 178.00210571289062, Learning Rate: 0.01\n",
      "Epoch [3192/20000], Loss: 1647.16455078125, Entropy 185.48171997070312, Learning Rate: 0.01\n",
      "Epoch [3193/20000], Loss: 1463.2034912109375, Entropy 170.3810272216797, Learning Rate: 0.01\n",
      "Epoch [3194/20000], Loss: 1519.6998291015625, Entropy 180.02113342285156, Learning Rate: 0.01\n",
      "Epoch [3195/20000], Loss: 1560.1026611328125, Entropy 167.18605041503906, Learning Rate: 0.01\n",
      "Epoch [3196/20000], Loss: 1150.5, Entropy 174.11289978027344, Learning Rate: 0.01\n",
      "Epoch [3197/20000], Loss: 1737.895263671875, Entropy 152.33799743652344, Learning Rate: 0.01\n",
      "Epoch [3198/20000], Loss: 1282.2779541015625, Entropy 165.65736389160156, Learning Rate: 0.01\n",
      "Epoch [3199/20000], Loss: 1478.62939453125, Entropy 172.59738159179688, Learning Rate: 0.01\n",
      "Epoch [3200/20000], Loss: 1307.7891845703125, Entropy 149.66030883789062, Learning Rate: 0.01\n",
      "Epoch [3201/20000], Loss: 1202.6700439453125, Entropy 157.2587432861328, Learning Rate: 0.01\n",
      "Epoch [3202/20000], Loss: 1311.90234375, Entropy 147.1578369140625, Learning Rate: 0.01\n",
      "Epoch [3203/20000], Loss: 1133.148193359375, Entropy 159.04833984375, Learning Rate: 0.01\n",
      "Epoch [3204/20000], Loss: 1190.27880859375, Entropy 152.66879272460938, Learning Rate: 0.01\n",
      "Epoch [3205/20000], Loss: 1202.4183349609375, Entropy 134.9701385498047, Learning Rate: 0.01\n",
      "Epoch [3206/20000], Loss: 1168.7838134765625, Entropy 159.6752166748047, Learning Rate: 0.01\n",
      "Epoch [3207/20000], Loss: 1098.7310791015625, Entropy 172.25552368164062, Learning Rate: 0.01\n",
      "Epoch [3208/20000], Loss: 1184.7451171875, Entropy 146.0882568359375, Learning Rate: 0.01\n",
      "Epoch [3209/20000], Loss: 1124.2061767578125, Entropy 151.99244689941406, Learning Rate: 0.01\n",
      "Epoch [3210/20000], Loss: 1229.4384765625, Entropy 159.68777465820312, Learning Rate: 0.01\n",
      "Epoch [3211/20000], Loss: 1110.8927001953125, Entropy 161.80540466308594, Learning Rate: 0.01\n",
      "Epoch [3212/20000], Loss: 1054.93994140625, Entropy 150.1705322265625, Learning Rate: 0.01\n",
      "Epoch [3213/20000], Loss: 1344.387451171875, Entropy 157.02122497558594, Learning Rate: 0.01\n",
      "Epoch [3214/20000], Loss: 1097.35693359375, Entropy 147.41561889648438, Learning Rate: 0.01\n",
      "Epoch [3215/20000], Loss: 1177.2611083984375, Entropy 150.6291961669922, Learning Rate: 0.01\n",
      "Epoch [3216/20000], Loss: 1156.316650390625, Entropy 141.196533203125, Learning Rate: 0.01\n",
      "Epoch [3217/20000], Loss: 1065.999267578125, Entropy 148.94021606445312, Learning Rate: 0.01\n",
      "Epoch [3218/20000], Loss: 1145.5390625, Entropy 146.14125061035156, Learning Rate: 0.01\n",
      "Epoch [3219/20000], Loss: 1221.333740234375, Entropy 163.10707092285156, Learning Rate: 0.01\n",
      "Epoch [3220/20000], Loss: 1127.93359375, Entropy 131.28536987304688, Learning Rate: 0.01\n",
      "Epoch [3221/20000], Loss: 1331.543701171875, Entropy 157.6696014404297, Learning Rate: 0.01\n",
      "Epoch [3222/20000], Loss: 1160.8248291015625, Entropy 148.1729278564453, Learning Rate: 0.01\n",
      "Epoch [3223/20000], Loss: 1196.5040283203125, Entropy 161.54591369628906, Learning Rate: 0.01\n",
      "Epoch [3224/20000], Loss: 1124.373046875, Entropy 138.8539581298828, Learning Rate: 0.01\n",
      "Epoch [3225/20000], Loss: 1110.00732421875, Entropy 132.10325622558594, Learning Rate: 0.01\n",
      "Epoch [3226/20000], Loss: 1236.3360595703125, Entropy 140.9827423095703, Learning Rate: 0.01\n",
      "Epoch [3227/20000], Loss: 1107.086181640625, Entropy 121.76273345947266, Learning Rate: 0.01\n",
      "Epoch [3228/20000], Loss: 1356.78857421875, Entropy 143.63134765625, Learning Rate: 0.01\n",
      "Epoch [3229/20000], Loss: 1076.02294921875, Entropy 138.33090209960938, Learning Rate: 0.01\n",
      "Epoch [3230/20000], Loss: 1171.593994140625, Entropy 146.05064392089844, Learning Rate: 0.01\n",
      "Epoch [3231/20000], Loss: 1227.1297607421875, Entropy 138.02146911621094, Learning Rate: 0.01\n",
      "Epoch [3232/20000], Loss: 1074.6708984375, Entropy 145.1605224609375, Learning Rate: 0.01\n",
      "Epoch [3233/20000], Loss: 1152.6749267578125, Entropy 130.1466064453125, Learning Rate: 0.01\n",
      "Epoch [3234/20000], Loss: 1255.418701171875, Entropy 142.4110565185547, Learning Rate: 0.01\n",
      "Epoch [3235/20000], Loss: 1056.9588623046875, Entropy 136.45008850097656, Learning Rate: 0.01\n",
      "Epoch [3236/20000], Loss: 1233.3919677734375, Entropy 147.8958282470703, Learning Rate: 0.01\n",
      "Epoch [3237/20000], Loss: 1099.750244140625, Entropy 133.15625, Learning Rate: 0.01\n",
      "Epoch [3238/20000], Loss: 1057.845458984375, Entropy 140.7275390625, Learning Rate: 0.01\n",
      "Epoch [3239/20000], Loss: 1226.396728515625, Entropy 128.4894561767578, Learning Rate: 0.01\n",
      "Epoch [3240/20000], Loss: 1052.1483154296875, Entropy 135.09104919433594, Learning Rate: 0.01\n",
      "Epoch [3241/20000], Loss: 1080.0308837890625, Entropy 135.64622497558594, Learning Rate: 0.01\n",
      "Epoch [3242/20000], Loss: 1111.422607421875, Entropy 133.80503845214844, Learning Rate: 0.01\n",
      "Epoch [3243/20000], Loss: 1117.211669921875, Entropy 140.12208557128906, Learning Rate: 0.01\n",
      "Epoch [3244/20000], Loss: 1047.5167236328125, Entropy 150.04344177246094, Learning Rate: 0.01\n",
      "Epoch [3245/20000], Loss: 1195.225830078125, Entropy 137.8240966796875, Learning Rate: 0.01\n",
      "Epoch [3246/20000], Loss: 1045.990478515625, Entropy 140.57034301757812, Learning Rate: 0.01\n",
      "Epoch [3247/20000], Loss: 1097.7838134765625, Entropy 132.3763885498047, Learning Rate: 0.01\n",
      "Epoch [3248/20000], Loss: 1129.420166015625, Entropy 150.95492553710938, Learning Rate: 0.01\n",
      "Epoch [3249/20000], Loss: 1049.7900390625, Entropy 140.60403442382812, Learning Rate: 0.01\n",
      "Epoch [3250/20000], Loss: 1059.8565673828125, Entropy 133.52818298339844, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3251/20000], Loss: 1088.175537109375, Entropy 129.80079650878906, Learning Rate: 0.01\n",
      "Epoch [3252/20000], Loss: 1083.28564453125, Entropy 148.49465942382812, Learning Rate: 0.01\n",
      "Epoch [3253/20000], Loss: 1091.23388671875, Entropy 147.58517456054688, Learning Rate: 0.01\n",
      "Epoch [3254/20000], Loss: 1171.1533203125, Entropy 157.93780517578125, Learning Rate: 0.01\n",
      "Epoch [3255/20000], Loss: 1082.943603515625, Entropy 142.3082733154297, Learning Rate: 0.01\n",
      "Epoch [3256/20000], Loss: 1133.1058349609375, Entropy 148.54063415527344, Learning Rate: 0.01\n",
      "Epoch [3257/20000], Loss: 1026.988037109375, Entropy 157.33506774902344, Learning Rate: 0.01\n",
      "Epoch [3258/20000], Loss: 1040.880615234375, Entropy 155.06689453125, Learning Rate: 0.01\n",
      "Epoch [3259/20000], Loss: 1125.283447265625, Entropy 154.07325744628906, Learning Rate: 0.01\n",
      "Epoch [3260/20000], Loss: 1114.160888671875, Entropy 133.18649291992188, Learning Rate: 0.01\n",
      "Epoch [3261/20000], Loss: 1063.0673828125, Entropy 147.59954833984375, Learning Rate: 0.01\n",
      "Epoch [3262/20000], Loss: 1121.79541015625, Entropy 167.31402587890625, Learning Rate: 0.01\n",
      "Epoch [3263/20000], Loss: 1082.2425537109375, Entropy 141.66514587402344, Learning Rate: 0.01\n",
      "Epoch [3264/20000], Loss: 1095.4869384765625, Entropy 147.30789184570312, Learning Rate: 0.01\n",
      "Epoch [3265/20000], Loss: 1188.428955078125, Entropy 148.99794006347656, Learning Rate: 0.01\n",
      "Epoch [3266/20000], Loss: 1095.161376953125, Entropy 138.93077087402344, Learning Rate: 0.01\n",
      "Epoch [3267/20000], Loss: 1094.830810546875, Entropy 129.81008911132812, Learning Rate: 0.01\n",
      "Epoch [3268/20000], Loss: 1166.345947265625, Entropy 147.76014709472656, Learning Rate: 0.01\n",
      "Epoch [3269/20000], Loss: 1089.0416259765625, Entropy 153.8842010498047, Learning Rate: 0.01\n",
      "Epoch [3270/20000], Loss: 1050.121337890625, Entropy 153.59869384765625, Learning Rate: 0.01\n",
      "Epoch [3271/20000], Loss: 1105.0357666015625, Entropy 157.27017211914062, Learning Rate: 0.01\n",
      "Epoch [3272/20000], Loss: 1114.8199462890625, Entropy 155.9795684814453, Learning Rate: 0.01\n",
      "Epoch [3273/20000], Loss: 1036.574462890625, Entropy 149.25320434570312, Learning Rate: 0.01\n",
      "Epoch [3274/20000], Loss: 1168.532958984375, Entropy 149.56883239746094, Learning Rate: 0.01\n",
      "Epoch [3275/20000], Loss: 1054.049072265625, Entropy 161.92930603027344, Learning Rate: 0.01\n",
      "Epoch [3276/20000], Loss: 1132.5477294921875, Entropy 145.58860778808594, Learning Rate: 0.01\n",
      "Epoch [3277/20000], Loss: 1031.9718017578125, Entropy 144.24256896972656, Learning Rate: 0.01\n",
      "Epoch [3278/20000], Loss: 1058.5087890625, Entropy 145.25094604492188, Learning Rate: 0.01\n",
      "Epoch [3279/20000], Loss: 1075.1768798828125, Entropy 134.11814880371094, Learning Rate: 0.01\n",
      "Epoch [3280/20000], Loss: 1031.8717041015625, Entropy 143.50767517089844, Learning Rate: 0.01\n",
      "Epoch [3281/20000], Loss: 1053.994873046875, Entropy 145.37022399902344, Learning Rate: 0.01\n",
      "Epoch [3282/20000], Loss: 1109.540771484375, Entropy 133.36776733398438, Learning Rate: 0.01\n",
      "Epoch [3283/20000], Loss: 1058.298095703125, Entropy 160.7099609375, Learning Rate: 0.01\n",
      "Epoch [3284/20000], Loss: 1038.1868896484375, Entropy 148.64735412597656, Learning Rate: 0.01\n",
      "Epoch [3285/20000], Loss: 1085.297607421875, Entropy 134.52171325683594, Learning Rate: 0.01\n",
      "Epoch [3286/20000], Loss: 1049.018798828125, Entropy 146.9210205078125, Learning Rate: 0.01\n",
      "Epoch [3287/20000], Loss: 1019.5860595703125, Entropy 154.13723754882812, Learning Rate: 0.01\n",
      "Epoch [3288/20000], Loss: 1030.987060546875, Entropy 153.05889892578125, Learning Rate: 0.01\n",
      "Epoch [3289/20000], Loss: 1094.851318359375, Entropy 140.6645050048828, Learning Rate: 0.01\n",
      "Epoch [3290/20000], Loss: 1069.135009765625, Entropy 154.39651489257812, Learning Rate: 0.01\n",
      "Epoch [3291/20000], Loss: 1049.2366943359375, Entropy 148.94712829589844, Learning Rate: 0.01\n",
      "Epoch [3292/20000], Loss: 1041.4488525390625, Entropy 169.49417114257812, Learning Rate: 0.01\n",
      "Epoch [3293/20000], Loss: 1096.148681640625, Entropy 154.20706176757812, Learning Rate: 0.01\n",
      "Epoch [3294/20000], Loss: 1036.0836181640625, Entropy 148.03993225097656, Learning Rate: 0.01\n",
      "Epoch [3295/20000], Loss: 1051.2481689453125, Entropy 161.74673461914062, Learning Rate: 0.01\n",
      "Epoch [3296/20000], Loss: 1022.1392211914062, Entropy 166.4673614501953, Learning Rate: 0.01\n",
      "Epoch [3297/20000], Loss: 1085.5604248046875, Entropy 159.93235778808594, Learning Rate: 0.01\n",
      "Epoch [3298/20000], Loss: 1096.29541015625, Entropy 156.15850830078125, Learning Rate: 0.01\n",
      "Epoch [3299/20000], Loss: 1106.7305908203125, Entropy 162.818603515625, Learning Rate: 0.01\n",
      "Epoch [3300/20000], Loss: 1038.986572265625, Entropy 154.9409942626953, Learning Rate: 0.01\n",
      "Epoch [3301/20000], Loss: 1071.5489501953125, Entropy 154.5927276611328, Learning Rate: 0.01\n",
      "Epoch [3302/20000], Loss: 1048.16455078125, Entropy 173.44949340820312, Learning Rate: 0.01\n",
      "Epoch [3303/20000], Loss: 1110.102294921875, Entropy 139.6481170654297, Learning Rate: 0.01\n",
      "Epoch [3304/20000], Loss: 1026.15234375, Entropy 154.4816131591797, Learning Rate: 0.01\n",
      "Epoch [3305/20000], Loss: 1068.121337890625, Entropy 177.5439453125, Learning Rate: 0.01\n",
      "Epoch [3306/20000], Loss: 1040.52685546875, Entropy 170.30972290039062, Learning Rate: 0.01\n",
      "Epoch [3307/20000], Loss: 1054.858154296875, Entropy 163.24989318847656, Learning Rate: 0.01\n",
      "Epoch [3308/20000], Loss: 1073.822265625, Entropy 165.6356964111328, Learning Rate: 0.01\n",
      "Epoch [3309/20000], Loss: 1054.7427978515625, Entropy 165.5360870361328, Learning Rate: 0.01\n",
      "Epoch [3310/20000], Loss: 1087.0902099609375, Entropy 145.51084899902344, Learning Rate: 0.01\n",
      "Epoch [3311/20000], Loss: 1043.1077880859375, Entropy 172.6024169921875, Learning Rate: 0.01\n",
      "Epoch [3312/20000], Loss: 1060.9615478515625, Entropy 162.52842712402344, Learning Rate: 0.01\n",
      "Epoch [3313/20000], Loss: 1054.0438232421875, Entropy 164.66246032714844, Learning Rate: 0.01\n",
      "Epoch [3314/20000], Loss: 1063.8525390625, Entropy 165.44114685058594, Learning Rate: 0.01\n",
      "Epoch [3315/20000], Loss: 1009.6859130859375, Entropy 160.78176879882812, Learning Rate: 0.01\n",
      "Epoch [3316/20000], Loss: 1057.7557373046875, Entropy 162.60391235351562, Learning Rate: 0.01\n",
      "Epoch [3317/20000], Loss: 1018.9496459960938, Entropy 175.84515380859375, Learning Rate: 0.01\n",
      "Epoch [3318/20000], Loss: 1028.647216796875, Entropy 184.36029052734375, Learning Rate: 0.01\n",
      "Epoch [3319/20000], Loss: 1027.751953125, Entropy 163.14788818359375, Learning Rate: 0.01\n",
      "Epoch [3320/20000], Loss: 1062.505859375, Entropy 164.229736328125, Learning Rate: 0.01\n",
      "Epoch [3321/20000], Loss: 1005.8200073242188, Entropy 169.53985595703125, Learning Rate: 0.01\n",
      "Epoch [3322/20000], Loss: 1027.1322021484375, Entropy 166.853515625, Learning Rate: 0.01\n",
      "Epoch [3323/20000], Loss: 1053.834228515625, Entropy 169.6781768798828, Learning Rate: 0.01\n",
      "Epoch [3324/20000], Loss: 1085.1688232421875, Entropy 159.61119079589844, Learning Rate: 0.01\n",
      "Epoch [3325/20000], Loss: 1020.3386840820312, Entropy 174.1034393310547, Learning Rate: 0.01\n",
      "Epoch [3326/20000], Loss: 1087.9027099609375, Entropy 168.28378295898438, Learning Rate: 0.01\n",
      "Epoch [3327/20000], Loss: 1043.0972900390625, Entropy 164.63172912597656, Learning Rate: 0.01\n",
      "Epoch [3328/20000], Loss: 1059.06640625, Entropy 173.26284790039062, Learning Rate: 0.01\n",
      "Epoch [3329/20000], Loss: 1045.0267333984375, Entropy 168.66586303710938, Learning Rate: 0.01\n",
      "Epoch [3330/20000], Loss: 1037.177001953125, Entropy 169.14572143554688, Learning Rate: 0.01\n",
      "Epoch [3331/20000], Loss: 1055.2978515625, Entropy 152.35305786132812, Learning Rate: 0.01\n",
      "Epoch [3332/20000], Loss: 1038.6776123046875, Entropy 169.1942596435547, Learning Rate: 0.01\n",
      "Epoch [3333/20000], Loss: 1022.8057250976562, Entropy 175.7175750732422, Learning Rate: 0.01\n",
      "Epoch [3334/20000], Loss: 1041.590576171875, Entropy 170.22320556640625, Learning Rate: 0.01\n",
      "Epoch [3335/20000], Loss: 1060.408447265625, Entropy 168.22064208984375, Learning Rate: 0.01\n",
      "Epoch [3336/20000], Loss: 1040.65966796875, Entropy 183.47128295898438, Learning Rate: 0.01\n",
      "Epoch [3337/20000], Loss: 1067.5089111328125, Entropy 167.75343322753906, Learning Rate: 0.01\n",
      "Epoch [3338/20000], Loss: 1037.781982421875, Entropy 174.80133056640625, Learning Rate: 0.01\n",
      "Epoch [3339/20000], Loss: 1056.1357421875, Entropy 177.73570251464844, Learning Rate: 0.01\n",
      "Epoch [3340/20000], Loss: 1044.77685546875, Entropy 167.9434356689453, Learning Rate: 0.01\n",
      "Epoch [3341/20000], Loss: 1030.005859375, Entropy 176.13931274414062, Learning Rate: 0.01\n",
      "Epoch [3342/20000], Loss: 1074.02197265625, Entropy 181.78038024902344, Learning Rate: 0.01\n",
      "Epoch [3343/20000], Loss: 1037.7620849609375, Entropy 158.11929321289062, Learning Rate: 0.01\n",
      "Epoch [3344/20000], Loss: 1039.8253173828125, Entropy 174.27894592285156, Learning Rate: 0.01\n",
      "Epoch [3345/20000], Loss: 1048.0537109375, Entropy 175.64144897460938, Learning Rate: 0.01\n",
      "Epoch [3346/20000], Loss: 1051.91357421875, Entropy 176.8404998779297, Learning Rate: 0.01\n",
      "Epoch [3347/20000], Loss: 1048.6417236328125, Entropy 180.1822052001953, Learning Rate: 0.01\n",
      "Epoch [3348/20000], Loss: 1038.997314453125, Entropy 170.2674560546875, Learning Rate: 0.01\n",
      "Epoch [3349/20000], Loss: 1102.818603515625, Entropy 175.05433654785156, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3350/20000], Loss: 1031.7208251953125, Entropy 168.97915649414062, Learning Rate: 0.01\n",
      "Epoch [3351/20000], Loss: 1220.99951171875, Entropy 166.8273468017578, Learning Rate: 0.01\n",
      "Epoch [3352/20000], Loss: 1086.54931640625, Entropy 181.0740203857422, Learning Rate: 0.01\n",
      "Epoch [3353/20000], Loss: 1153.56005859375, Entropy 181.908203125, Learning Rate: 0.01\n",
      "Epoch [3354/20000], Loss: 1025.1038818359375, Entropy 188.68527221679688, Learning Rate: 0.01\n",
      "Epoch [3355/20000], Loss: 1170.00439453125, Entropy 187.1781463623047, Learning Rate: 0.01\n",
      "Epoch [3356/20000], Loss: 1022.5728759765625, Entropy 175.85812377929688, Learning Rate: 0.01\n",
      "Epoch [3357/20000], Loss: 1116.2698974609375, Entropy 172.6614227294922, Learning Rate: 0.01\n",
      "Epoch [3358/20000], Loss: 1038.397216796875, Entropy 174.80465698242188, Learning Rate: 0.01\n",
      "Epoch [3359/20000], Loss: 1056.923095703125, Entropy 173.71478271484375, Learning Rate: 0.01\n",
      "Epoch [3360/20000], Loss: 1020.3974609375, Entropy 184.34866333007812, Learning Rate: 0.01\n",
      "Epoch [3361/20000], Loss: 1044.6937255859375, Entropy 185.7422637939453, Learning Rate: 0.01\n",
      "Epoch [3362/20000], Loss: 1083.65380859375, Entropy 192.2351531982422, Learning Rate: 0.01\n",
      "Epoch [3363/20000], Loss: 1042.4144287109375, Entropy 173.34718322753906, Learning Rate: 0.01\n",
      "Epoch [3364/20000], Loss: 1039.3494873046875, Entropy 182.21632385253906, Learning Rate: 0.01\n",
      "Epoch [3365/20000], Loss: 1025.6038818359375, Entropy 178.8748779296875, Learning Rate: 0.01\n",
      "Epoch [3366/20000], Loss: 1068.759521484375, Entropy 173.62936401367188, Learning Rate: 0.01\n",
      "Epoch [3367/20000], Loss: 1053.99853515625, Entropy 182.28347778320312, Learning Rate: 0.01\n",
      "Epoch [3368/20000], Loss: 1016.14111328125, Entropy 181.20291137695312, Learning Rate: 0.01\n",
      "Epoch [3369/20000], Loss: 1047.66796875, Entropy 190.89727783203125, Learning Rate: 0.01\n",
      "Epoch [3370/20000], Loss: 1030.6993408203125, Entropy 172.8143310546875, Learning Rate: 0.01\n",
      "Epoch [3371/20000], Loss: 1025.747314453125, Entropy 181.66575622558594, Learning Rate: 0.01\n",
      "Epoch [3372/20000], Loss: 1083.9197998046875, Entropy 180.618896484375, Learning Rate: 0.01\n",
      "Epoch [3373/20000], Loss: 1015.9280395507812, Entropy 198.8690643310547, Learning Rate: 0.01\n",
      "Epoch [3374/20000], Loss: 1018.563720703125, Entropy 185.66748046875, Learning Rate: 0.01\n",
      "Epoch [3375/20000], Loss: 1048.346435546875, Entropy 175.3544464111328, Learning Rate: 0.01\n",
      "Epoch [3376/20000], Loss: 1050.720947265625, Entropy 183.215087890625, Learning Rate: 0.01\n",
      "Epoch [3377/20000], Loss: 1043.97998046875, Entropy 175.609130859375, Learning Rate: 0.01\n",
      "Epoch [3378/20000], Loss: 1019.1094360351562, Entropy 180.2781219482422, Learning Rate: 0.01\n",
      "Epoch [3379/20000], Loss: 1058.489990234375, Entropy 181.1925506591797, Learning Rate: 0.01\n",
      "Epoch [3380/20000], Loss: 1022.3585815429688, Entropy 175.15386962890625, Learning Rate: 0.01\n",
      "Epoch [3381/20000], Loss: 1025.05078125, Entropy 182.3400421142578, Learning Rate: 0.01\n",
      "Epoch [3382/20000], Loss: 1046.324462890625, Entropy 178.61874389648438, Learning Rate: 0.01\n",
      "Epoch [3383/20000], Loss: 1025.544921875, Entropy 183.38253784179688, Learning Rate: 0.01\n",
      "Epoch [3384/20000], Loss: 1031.0489501953125, Entropy 187.78530883789062, Learning Rate: 0.01\n",
      "Epoch [3385/20000], Loss: 1010.4317626953125, Entropy 190.41275024414062, Learning Rate: 0.01\n",
      "Epoch [3386/20000], Loss: 1049.7457275390625, Entropy 194.8549346923828, Learning Rate: 0.01\n",
      "Epoch [3387/20000], Loss: 1020.82421875, Entropy 188.92176818847656, Learning Rate: 0.01\n",
      "Epoch [3388/20000], Loss: 1024.630859375, Entropy 192.99185180664062, Learning Rate: 0.01\n",
      "Epoch [3389/20000], Loss: 1017.4006958007812, Entropy 189.3258819580078, Learning Rate: 0.01\n",
      "Epoch [3390/20000], Loss: 1026.00244140625, Entropy 186.28399658203125, Learning Rate: 0.01\n",
      "Epoch [3391/20000], Loss: 1040.15087890625, Entropy 183.04879760742188, Learning Rate: 0.01\n",
      "Epoch [3392/20000], Loss: 1074.5941162109375, Entropy 195.0261688232422, Learning Rate: 0.01\n",
      "Epoch [3393/20000], Loss: 1059.70263671875, Entropy 189.3860626220703, Learning Rate: 0.01\n",
      "Epoch [3394/20000], Loss: 1026.88818359375, Entropy 193.2865447998047, Learning Rate: 0.01\n",
      "Epoch [3395/20000], Loss: 1099.39208984375, Entropy 207.58909606933594, Learning Rate: 0.01\n",
      "Epoch [3396/20000], Loss: 1022.6715087890625, Entropy 202.38986206054688, Learning Rate: 0.01\n",
      "Epoch [3397/20000], Loss: 1145.26513671875, Entropy 194.3699188232422, Learning Rate: 0.01\n",
      "Epoch [3398/20000], Loss: 1047.580810546875, Entropy 186.89907836914062, Learning Rate: 0.01\n",
      "Epoch [3399/20000], Loss: 1271.6796875, Entropy 197.91632080078125, Learning Rate: 0.01\n",
      "Epoch [3400/20000], Loss: 1098.45654296875, Entropy 191.39906311035156, Learning Rate: 0.01\n",
      "Epoch [3401/20000], Loss: 1210.112060546875, Entropy 180.38172912597656, Learning Rate: 0.01\n",
      "Epoch [3402/20000], Loss: 1263.3470458984375, Entropy 188.76473999023438, Learning Rate: 0.01\n",
      "Epoch [3403/20000], Loss: 1352.243896484375, Entropy 185.91119384765625, Learning Rate: 0.01\n",
      "Epoch [3404/20000], Loss: 1129.3360595703125, Entropy 184.8699493408203, Learning Rate: 0.01\n",
      "Epoch [3405/20000], Loss: 1138.02978515625, Entropy 218.19461059570312, Learning Rate: 0.01\n",
      "Epoch [3406/20000], Loss: 1069.3404541015625, Entropy 197.96766662597656, Learning Rate: 0.01\n",
      "Epoch [3407/20000], Loss: 1199.240234375, Entropy 187.4324493408203, Learning Rate: 0.01\n",
      "Epoch [3408/20000], Loss: 1045.591796875, Entropy 189.18011474609375, Learning Rate: 0.01\n",
      "Epoch [3409/20000], Loss: 1145.841064453125, Entropy 204.4104766845703, Learning Rate: 0.01\n",
      "Epoch [3410/20000], Loss: 1107.1593017578125, Entropy 186.70326232910156, Learning Rate: 0.01\n",
      "Epoch [3411/20000], Loss: 1065.50732421875, Entropy 183.42539978027344, Learning Rate: 0.01\n",
      "Epoch [3412/20000], Loss: 1073.7177734375, Entropy 188.48590087890625, Learning Rate: 0.01\n",
      "Epoch [3413/20000], Loss: 1050.46435546875, Entropy 195.54733276367188, Learning Rate: 0.01\n",
      "Epoch [3414/20000], Loss: 1158.25634765625, Entropy 190.02610778808594, Learning Rate: 0.01\n",
      "Epoch [3415/20000], Loss: 1105.4263916015625, Entropy 181.9084014892578, Learning Rate: 0.01\n",
      "Epoch [3416/20000], Loss: 1015.105712890625, Entropy 190.93946838378906, Learning Rate: 0.01\n",
      "Epoch [3417/20000], Loss: 1082.7825927734375, Entropy 188.65261840820312, Learning Rate: 0.01\n",
      "Epoch [3418/20000], Loss: 1079.56591796875, Entropy 176.64498901367188, Learning Rate: 0.01\n",
      "Epoch [3419/20000], Loss: 1009.41845703125, Entropy 182.48081970214844, Learning Rate: 0.01\n",
      "Epoch [3420/20000], Loss: 1018.0172119140625, Entropy 196.32347106933594, Learning Rate: 0.01\n",
      "Epoch [3421/20000], Loss: 1024.0655517578125, Entropy 191.39126586914062, Learning Rate: 0.01\n",
      "Epoch [3422/20000], Loss: 1050.9130859375, Entropy 176.14483642578125, Learning Rate: 0.01\n",
      "Epoch [3423/20000], Loss: 1045.54833984375, Entropy 187.03733825683594, Learning Rate: 0.01\n",
      "Epoch [3424/20000], Loss: 1064.544677734375, Entropy 194.20753479003906, Learning Rate: 0.01\n",
      "Epoch [3425/20000], Loss: 1025.5360107421875, Entropy 197.2740020751953, Learning Rate: 0.01\n",
      "Epoch [3426/20000], Loss: 1006.4656982421875, Entropy 190.17176818847656, Learning Rate: 0.01\n",
      "Epoch [3427/20000], Loss: 1010.2128295898438, Entropy 184.17803955078125, Learning Rate: 0.01\n",
      "Epoch [3428/20000], Loss: 1047.254150390625, Entropy 192.92135620117188, Learning Rate: 0.01\n",
      "Epoch [3429/20000], Loss: 1045.455078125, Entropy 179.2797393798828, Learning Rate: 0.01\n",
      "Epoch [3430/20000], Loss: 1012.6892700195312, Entropy 195.64495849609375, Learning Rate: 0.01\n",
      "Epoch [3431/20000], Loss: 1053.1019287109375, Entropy 183.0888671875, Learning Rate: 0.01\n",
      "Epoch [3432/20000], Loss: 1048.4501953125, Entropy 182.80429077148438, Learning Rate: 0.01\n",
      "Epoch [3433/20000], Loss: 1020.4481201171875, Entropy 197.164306640625, Learning Rate: 0.01\n",
      "Epoch [3434/20000], Loss: 1027.94140625, Entropy 186.2605438232422, Learning Rate: 0.01\n",
      "Epoch [3435/20000], Loss: 1004.7545166015625, Entropy 182.43955993652344, Learning Rate: 0.01\n",
      "Epoch [3436/20000], Loss: 1037.7584228515625, Entropy 181.9454803466797, Learning Rate: 0.01\n",
      "Epoch [3437/20000], Loss: 1001.6630859375, Entropy 185.77975463867188, Learning Rate: 0.01\n",
      "Epoch [3438/20000], Loss: 1011.862548828125, Entropy 195.57044982910156, Learning Rate: 0.01\n",
      "Epoch [3439/20000], Loss: 997.3330688476562, Entropy 198.3855743408203, Learning Rate: 0.01\n",
      "Epoch [3440/20000], Loss: 1017.622314453125, Entropy 193.05284118652344, Learning Rate: 0.01\n",
      "Epoch [3441/20000], Loss: 998.107421875, Entropy 195.70042419433594, Learning Rate: 0.01\n",
      "Epoch [3442/20000], Loss: 1010.5819091796875, Entropy 195.93104553222656, Learning Rate: 0.01\n",
      "Epoch [3443/20000], Loss: 991.9633178710938, Entropy 192.33441162109375, Learning Rate: 0.01\n",
      "Epoch [3444/20000], Loss: 1011.62841796875, Entropy 191.37962341308594, Learning Rate: 0.01\n",
      "Epoch [3445/20000], Loss: 1019.9136962890625, Entropy 209.50901794433594, Learning Rate: 0.01\n",
      "Epoch [3446/20000], Loss: 981.2372436523438, Entropy 195.9240264892578, Learning Rate: 0.01\n",
      "Epoch [3447/20000], Loss: 1019.2474975585938, Entropy 195.48468017578125, Learning Rate: 0.01\n",
      "Epoch [3448/20000], Loss: 1020.7984008789062, Entropy 205.4989776611328, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3449/20000], Loss: 987.054443359375, Entropy 206.59378051757812, Learning Rate: 0.01\n",
      "Epoch [3450/20000], Loss: 1038.1041259765625, Entropy 198.9745635986328, Learning Rate: 0.01\n",
      "Epoch [3451/20000], Loss: 1044.0673828125, Entropy 181.798828125, Learning Rate: 0.01\n",
      "Epoch [3452/20000], Loss: 1043.544189453125, Entropy 190.84877014160156, Learning Rate: 0.01\n",
      "Epoch [3453/20000], Loss: 1003.9473266601562, Entropy 196.5556182861328, Learning Rate: 0.01\n",
      "Epoch [3454/20000], Loss: 992.787109375, Entropy 198.68753051757812, Learning Rate: 0.01\n",
      "Epoch [3455/20000], Loss: 1025.9603271484375, Entropy 209.29478454589844, Learning Rate: 0.01\n",
      "Epoch [3456/20000], Loss: 1013.8851928710938, Entropy 188.75714111328125, Learning Rate: 0.01\n",
      "Epoch [3457/20000], Loss: 1056.9140625, Entropy 192.76402282714844, Learning Rate: 0.01\n",
      "Epoch [3458/20000], Loss: 1010.3582763671875, Entropy 208.76199340820312, Learning Rate: 0.01\n",
      "Epoch [3459/20000], Loss: 986.4518432617188, Entropy 209.82037353515625, Learning Rate: 0.01\n",
      "Epoch [3460/20000], Loss: 1009.256103515625, Entropy 194.9632568359375, Learning Rate: 0.01\n",
      "Epoch [3461/20000], Loss: 1005.8270263671875, Entropy 209.04124450683594, Learning Rate: 0.01\n",
      "Epoch [3462/20000], Loss: 1039.2412109375, Entropy 195.67300415039062, Learning Rate: 0.01\n",
      "Epoch [3463/20000], Loss: 997.6139526367188, Entropy 197.85357666015625, Learning Rate: 0.01\n",
      "Epoch [3464/20000], Loss: 971.9217529296875, Entropy 211.31698608398438, Learning Rate: 0.01\n",
      "Epoch [3465/20000], Loss: 1005.810302734375, Entropy 217.29991149902344, Learning Rate: 0.01\n",
      "Epoch [3466/20000], Loss: 1002.1287231445312, Entropy 205.75811767578125, Learning Rate: 0.01\n",
      "Epoch [3467/20000], Loss: 1005.0792846679688, Entropy 214.5843048095703, Learning Rate: 0.01\n",
      "Epoch [3468/20000], Loss: 998.7452392578125, Entropy 217.60874938964844, Learning Rate: 0.01\n",
      "Epoch [3469/20000], Loss: 992.431640625, Entropy 204.26622009277344, Learning Rate: 0.01\n",
      "Epoch [3470/20000], Loss: 970.2667846679688, Entropy 207.74847412109375, Learning Rate: 0.01\n",
      "Epoch [3471/20000], Loss: 983.7921752929688, Entropy 216.50604248046875, Learning Rate: 0.01\n",
      "Epoch [3472/20000], Loss: 997.05078125, Entropy 207.66183471679688, Learning Rate: 0.01\n",
      "Epoch [3473/20000], Loss: 1007.0071411132812, Entropy 204.6005401611328, Learning Rate: 0.01\n",
      "Epoch [3474/20000], Loss: 966.0549926757812, Entropy 217.8211212158203, Learning Rate: 0.01\n",
      "Epoch [3475/20000], Loss: 995.5518188476562, Entropy 205.88677978515625, Learning Rate: 0.01\n",
      "Epoch [3476/20000], Loss: 1058.1568603515625, Entropy 198.09243774414062, Learning Rate: 0.01\n",
      "Epoch [3477/20000], Loss: 997.4846801757812, Entropy 222.0076446533203, Learning Rate: 0.01\n",
      "Epoch [3478/20000], Loss: 985.688232421875, Entropy 207.22569274902344, Learning Rate: 0.01\n",
      "Epoch [3479/20000], Loss: 1007.7955322265625, Entropy 216.6142578125, Learning Rate: 0.01\n",
      "Epoch [3480/20000], Loss: 994.9456787109375, Entropy 202.76161193847656, Learning Rate: 0.01\n",
      "Epoch [3481/20000], Loss: 976.0913696289062, Entropy 211.7863006591797, Learning Rate: 0.01\n",
      "Epoch [3482/20000], Loss: 1025.24951171875, Entropy 205.77764892578125, Learning Rate: 0.01\n",
      "Epoch [3483/20000], Loss: 1039.9161376953125, Entropy 203.465576171875, Learning Rate: 0.01\n",
      "Epoch [3484/20000], Loss: 973.7066650390625, Entropy 215.296630859375, Learning Rate: 0.01\n",
      "Epoch [3485/20000], Loss: 990.4544067382812, Entropy 211.6863250732422, Learning Rate: 0.01\n",
      "Epoch [3486/20000], Loss: 997.3092651367188, Entropy 221.3365936279297, Learning Rate: 0.01\n",
      "Epoch [3487/20000], Loss: 1004.4171142578125, Entropy 222.42140197753906, Learning Rate: 0.01\n",
      "Epoch [3488/20000], Loss: 942.6909790039062, Entropy 228.9384307861328, Learning Rate: 0.01\n",
      "Epoch [3489/20000], Loss: 995.0340576171875, Entropy 209.10006713867188, Learning Rate: 0.01\n",
      "Epoch [3490/20000], Loss: 972.6026611328125, Entropy 224.32186889648438, Learning Rate: 0.01\n",
      "Epoch [3491/20000], Loss: 990.99267578125, Entropy 208.28099060058594, Learning Rate: 0.01\n",
      "Epoch [3492/20000], Loss: 1019.2267456054688, Entropy 211.0364227294922, Learning Rate: 0.01\n",
      "Epoch [3493/20000], Loss: 978.57861328125, Entropy 231.8203125, Learning Rate: 0.01\n",
      "Epoch [3494/20000], Loss: 996.90283203125, Entropy 205.46878051757812, Learning Rate: 0.01\n",
      "Epoch [3495/20000], Loss: 982.141845703125, Entropy 218.36288452148438, Learning Rate: 0.01\n",
      "Epoch [3496/20000], Loss: 1000.5599365234375, Entropy 206.42884826660156, Learning Rate: 0.01\n",
      "Epoch [3497/20000], Loss: 967.2322387695312, Entropy 227.4654998779297, Learning Rate: 0.01\n",
      "Epoch [3498/20000], Loss: 978.7418212890625, Entropy 217.54893493652344, Learning Rate: 0.01\n",
      "Epoch [3499/20000], Loss: 998.6931762695312, Entropy 221.04522705078125, Learning Rate: 0.01\n",
      "Epoch [3500/20000], Loss: 1021.48779296875, Entropy 215.15562438964844, Learning Rate: 0.01\n",
      "Epoch [3501/20000], Loss: 967.146240234375, Entropy 220.93038940429688, Learning Rate: 0.01\n",
      "Epoch [3502/20000], Loss: 978.6210327148438, Entropy 229.7870635986328, Learning Rate: 0.01\n",
      "Epoch [3503/20000], Loss: 1009.831787109375, Entropy 226.18185424804688, Learning Rate: 0.01\n",
      "Epoch [3504/20000], Loss: 982.0518798828125, Entropy 224.72523498535156, Learning Rate: 0.01\n",
      "Epoch [3505/20000], Loss: 986.4784545898438, Entropy 233.48675537109375, Learning Rate: 0.01\n",
      "Epoch [3506/20000], Loss: 990.6358642578125, Entropy 208.93826293945312, Learning Rate: 0.01\n",
      "Epoch [3507/20000], Loss: 961.990234375, Entropy 231.20057678222656, Learning Rate: 0.01\n",
      "Epoch [3508/20000], Loss: 965.0799560546875, Entropy 217.65550231933594, Learning Rate: 0.01\n",
      "Epoch [3509/20000], Loss: 981.471435546875, Entropy 219.23851013183594, Learning Rate: 0.01\n",
      "Epoch [3510/20000], Loss: 993.9453735351562, Entropy 224.61273193359375, Learning Rate: 0.01\n",
      "Epoch [3511/20000], Loss: 986.9055786132812, Entropy 231.55938720703125, Learning Rate: 0.01\n",
      "Epoch [3512/20000], Loss: 983.4904174804688, Entropy 226.81976318359375, Learning Rate: 0.01\n",
      "Epoch [3513/20000], Loss: 1013.8289794921875, Entropy 215.815185546875, Learning Rate: 0.01\n",
      "Epoch [3514/20000], Loss: 987.1138916015625, Entropy 234.56382751464844, Learning Rate: 0.01\n",
      "Epoch [3515/20000], Loss: 989.6730346679688, Entropy 228.42633056640625, Learning Rate: 0.01\n",
      "Epoch [3516/20000], Loss: 969.3250732421875, Entropy 231.61595153808594, Learning Rate: 0.01\n",
      "Epoch [3517/20000], Loss: 989.3748168945312, Entropy 229.2422637939453, Learning Rate: 0.01\n",
      "Epoch [3518/20000], Loss: 976.65869140625, Entropy 211.56089782714844, Learning Rate: 0.01\n",
      "Epoch [3519/20000], Loss: 1034.76806640625, Entropy 218.54251098632812, Learning Rate: 0.01\n",
      "Epoch [3520/20000], Loss: 996.3054809570312, Entropy 218.52386474609375, Learning Rate: 0.01\n",
      "Epoch [3521/20000], Loss: 973.6990966796875, Entropy 235.57737731933594, Learning Rate: 0.01\n",
      "Epoch [3522/20000], Loss: 989.2472534179688, Entropy 239.6083221435547, Learning Rate: 0.01\n",
      "Epoch [3523/20000], Loss: 968.00830078125, Entropy 228.29446411132812, Learning Rate: 0.01\n",
      "Epoch [3524/20000], Loss: 972.63330078125, Entropy 222.75497436523438, Learning Rate: 0.01\n",
      "Epoch [3525/20000], Loss: 986.238525390625, Entropy 219.44058227539062, Learning Rate: 0.01\n",
      "Epoch [3526/20000], Loss: 988.3594970703125, Entropy 228.893798828125, Learning Rate: 0.01\n",
      "Epoch [3527/20000], Loss: 1025.4705810546875, Entropy 229.7947998046875, Learning Rate: 0.01\n",
      "Epoch [3528/20000], Loss: 955.5341186523438, Entropy 236.1466522216797, Learning Rate: 0.01\n",
      "Epoch [3529/20000], Loss: 1013.2838134765625, Entropy 229.03713989257812, Learning Rate: 0.01\n",
      "Epoch [3530/20000], Loss: 973.9799194335938, Entropy 237.2002716064453, Learning Rate: 0.01\n",
      "Epoch [3531/20000], Loss: 988.2439575195312, Entropy 233.4188690185547, Learning Rate: 0.01\n",
      "Epoch [3532/20000], Loss: 964.57958984375, Entropy 237.30294799804688, Learning Rate: 0.01\n",
      "Epoch [3533/20000], Loss: 994.1671142578125, Entropy 230.35877990722656, Learning Rate: 0.01\n",
      "Epoch [3534/20000], Loss: 975.1929321289062, Entropy 230.43109130859375, Learning Rate: 0.01\n",
      "Epoch [3535/20000], Loss: 956.71875, Entropy 227.24801635742188, Learning Rate: 0.01\n",
      "Epoch [3536/20000], Loss: 948.1044921875, Entropy 245.94789123535156, Learning Rate: 0.01\n",
      "Epoch [3537/20000], Loss: 1002.0595092773438, Entropy 235.66143798828125, Learning Rate: 0.01\n",
      "Epoch [3538/20000], Loss: 977.051025390625, Entropy 242.14132690429688, Learning Rate: 0.01\n",
      "Epoch [3539/20000], Loss: 978.6928100585938, Entropy 232.0385284423828, Learning Rate: 0.01\n",
      "Epoch [3540/20000], Loss: 968.9703979492188, Entropy 250.3104705810547, Learning Rate: 0.01\n",
      "Epoch [3541/20000], Loss: 949.37060546875, Entropy 245.33824157714844, Learning Rate: 0.01\n",
      "Epoch [3542/20000], Loss: 968.97265625, Entropy 233.38436889648438, Learning Rate: 0.01\n",
      "Epoch [3543/20000], Loss: 989.3276977539062, Entropy 225.64703369140625, Learning Rate: 0.01\n",
      "Epoch [3544/20000], Loss: 951.3294067382812, Entropy 236.2226104736328, Learning Rate: 0.01\n",
      "Epoch [3545/20000], Loss: 986.9789428710938, Entropy 232.29327392578125, Learning Rate: 0.01\n",
      "Epoch [3546/20000], Loss: 958.7457275390625, Entropy 227.83116149902344, Learning Rate: 0.01\n",
      "Epoch [3547/20000], Loss: 949.6804809570312, Entropy 258.84686279296875, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3548/20000], Loss: 1036.5628662109375, Entropy 232.31690979003906, Learning Rate: 0.01\n",
      "Epoch [3549/20000], Loss: 995.9489135742188, Entropy 236.86468505859375, Learning Rate: 0.01\n",
      "Epoch [3550/20000], Loss: 992.4622802734375, Entropy 244.88597106933594, Learning Rate: 0.01\n",
      "Epoch [3551/20000], Loss: 958.84130859375, Entropy 247.13414001464844, Learning Rate: 0.01\n",
      "Epoch [3552/20000], Loss: 1033.744140625, Entropy 242.2623748779297, Learning Rate: 0.01\n",
      "Epoch [3553/20000], Loss: 956.051025390625, Entropy 256.5204772949219, Learning Rate: 0.01\n",
      "Epoch [3554/20000], Loss: 993.1807861328125, Entropy 240.06466674804688, Learning Rate: 0.01\n",
      "Epoch [3555/20000], Loss: 1015.191650390625, Entropy 237.26119995117188, Learning Rate: 0.01\n",
      "Epoch [3556/20000], Loss: 1006.2266235351562, Entropy 239.10394287109375, Learning Rate: 0.01\n",
      "Epoch [3557/20000], Loss: 971.0031127929688, Entropy 240.1610870361328, Learning Rate: 0.01\n",
      "Epoch [3558/20000], Loss: 950.7727661132812, Entropy 246.90069580078125, Learning Rate: 0.01\n",
      "Epoch [3559/20000], Loss: 967.5989990234375, Entropy 246.28712463378906, Learning Rate: 0.01\n",
      "Epoch [3560/20000], Loss: 1011.0153198242188, Entropy 231.0039825439453, Learning Rate: 0.01\n",
      "Epoch [3561/20000], Loss: 1038.3692626953125, Entropy 238.82994079589844, Learning Rate: 0.01\n",
      "Epoch [3562/20000], Loss: 1038.2835693359375, Entropy 237.89845275878906, Learning Rate: 0.01\n",
      "Epoch [3563/20000], Loss: 997.2689208984375, Entropy 245.3265380859375, Learning Rate: 0.01\n",
      "Epoch [3564/20000], Loss: 975.206298828125, Entropy 238.80435180664062, Learning Rate: 0.01\n",
      "Epoch [3565/20000], Loss: 1035.7130126953125, Entropy 231.3614044189453, Learning Rate: 0.01\n",
      "Epoch [3566/20000], Loss: 962.5994873046875, Entropy 237.49647521972656, Learning Rate: 0.01\n",
      "Epoch [3567/20000], Loss: 1008.0370483398438, Entropy 246.06280517578125, Learning Rate: 0.01\n",
      "Epoch [3568/20000], Loss: 995.8255615234375, Entropy 240.85972595214844, Learning Rate: 0.01\n",
      "Epoch [3569/20000], Loss: 1037.622802734375, Entropy 238.16958618164062, Learning Rate: 0.01\n",
      "Epoch [3570/20000], Loss: 974.4786376953125, Entropy 248.62399291992188, Learning Rate: 0.01\n",
      "Epoch [3571/20000], Loss: 1039.17822265625, Entropy 236.71395874023438, Learning Rate: 0.01\n",
      "Epoch [3572/20000], Loss: 1030.3525390625, Entropy 235.96499633789062, Learning Rate: 0.01\n",
      "Epoch [3573/20000], Loss: 1060.8497314453125, Entropy 246.25875854492188, Learning Rate: 0.01\n",
      "Epoch [3574/20000], Loss: 1024.89453125, Entropy 226.41336059570312, Learning Rate: 0.01\n",
      "Epoch [3575/20000], Loss: 1081.026611328125, Entropy 243.9749298095703, Learning Rate: 0.01\n",
      "Epoch [3576/20000], Loss: 1081.328369140625, Entropy 260.76092529296875, Learning Rate: 0.01\n",
      "Epoch [3577/20000], Loss: 1103.202392578125, Entropy 253.6650848388672, Learning Rate: 0.01\n",
      "Epoch [3578/20000], Loss: 1096.2015380859375, Entropy 246.0604248046875, Learning Rate: 0.01\n",
      "Epoch [3579/20000], Loss: 1063.8282470703125, Entropy 246.7028045654297, Learning Rate: 0.01\n",
      "Epoch [3580/20000], Loss: 1341.1483154296875, Entropy 229.3646240234375, Learning Rate: 0.01\n",
      "Epoch [3581/20000], Loss: 1641.280029296875, Entropy 259.50030517578125, Learning Rate: 0.01\n",
      "Epoch [3582/20000], Loss: 1070.8538818359375, Entropy 255.11734008789062, Learning Rate: 0.01\n",
      "Epoch [3583/20000], Loss: 2288.98828125, Entropy 248.6180419921875, Learning Rate: 0.01\n",
      "Epoch [3584/20000], Loss: 2094.967041015625, Entropy 248.31021118164062, Learning Rate: 0.01\n",
      "Epoch [3585/20000], Loss: 1190.10986328125, Entropy 242.04698181152344, Learning Rate: 0.01\n",
      "Epoch [3586/20000], Loss: 1599.0076904296875, Entropy 240.44100952148438, Learning Rate: 0.01\n",
      "Epoch [3587/20000], Loss: 1716.2015380859375, Entropy 240.85948181152344, Learning Rate: 0.01\n",
      "Epoch [3588/20000], Loss: 1338.316650390625, Entropy 241.1728057861328, Learning Rate: 0.01\n",
      "Epoch [3589/20000], Loss: 1388.8231201171875, Entropy 225.62942504882812, Learning Rate: 0.01\n",
      "Epoch [3590/20000], Loss: 1534.6075439453125, Entropy 233.3784942626953, Learning Rate: 0.01\n",
      "Epoch [3591/20000], Loss: 1151.3780517578125, Entropy 240.9461212158203, Learning Rate: 0.01\n",
      "Epoch [3592/20000], Loss: 1620.65771484375, Entropy 232.72909545898438, Learning Rate: 0.01\n",
      "Epoch [3593/20000], Loss: 1315.636962890625, Entropy 234.525634765625, Learning Rate: 0.01\n",
      "Epoch [3594/20000], Loss: 1142.74267578125, Entropy 217.60308837890625, Learning Rate: 0.01\n",
      "Epoch [3595/20000], Loss: 1361.7467041015625, Entropy 218.67909240722656, Learning Rate: 0.01\n",
      "Epoch [3596/20000], Loss: 1293.5111083984375, Entropy 235.07679748535156, Learning Rate: 0.01\n",
      "Epoch [3597/20000], Loss: 1171.6337890625, Entropy 219.53636169433594, Learning Rate: 0.01\n",
      "Epoch [3598/20000], Loss: 1283.8538818359375, Entropy 223.8863983154297, Learning Rate: 0.01\n",
      "Epoch [3599/20000], Loss: 1246.9459228515625, Entropy 216.856201171875, Learning Rate: 0.01\n",
      "Epoch [3600/20000], Loss: 1133.17578125, Entropy 214.5992889404297, Learning Rate: 0.01\n",
      "Epoch [3601/20000], Loss: 1083.1361083984375, Entropy 200.32115173339844, Learning Rate: 0.01\n",
      "Epoch [3602/20000], Loss: 1180.697509765625, Entropy 201.5836944580078, Learning Rate: 0.01\n",
      "Epoch [3603/20000], Loss: 1077.62109375, Entropy 209.39190673828125, Learning Rate: 0.01\n",
      "Epoch [3604/20000], Loss: 1090.5791015625, Entropy 203.6412811279297, Learning Rate: 0.01\n",
      "Epoch [3605/20000], Loss: 1144.09423828125, Entropy 201.4119873046875, Learning Rate: 0.01\n",
      "Epoch [3606/20000], Loss: 995.8775634765625, Entropy 221.314697265625, Learning Rate: 0.01\n",
      "Epoch [3607/20000], Loss: 1156.1220703125, Entropy 195.12411499023438, Learning Rate: 0.01\n",
      "Epoch [3608/20000], Loss: 1065.47509765625, Entropy 199.3986358642578, Learning Rate: 0.01\n",
      "Epoch [3609/20000], Loss: 1109.297119140625, Entropy 187.86968994140625, Learning Rate: 0.01\n",
      "Epoch [3610/20000], Loss: 1066.7557373046875, Entropy 205.0154266357422, Learning Rate: 0.01\n",
      "Epoch [3611/20000], Loss: 1055.5018310546875, Entropy 212.88198852539062, Learning Rate: 0.01\n",
      "Epoch [3612/20000], Loss: 1060.5902099609375, Entropy 206.9188690185547, Learning Rate: 0.01\n",
      "Epoch [3613/20000], Loss: 1030.1195068359375, Entropy 207.04147338867188, Learning Rate: 0.01\n",
      "Epoch [3614/20000], Loss: 1020.8687744140625, Entropy 208.89930725097656, Learning Rate: 0.01\n",
      "Epoch [3615/20000], Loss: 1104.96240234375, Entropy 204.77944946289062, Learning Rate: 0.01\n",
      "Epoch [3616/20000], Loss: 1031.21435546875, Entropy 194.8041229248047, Learning Rate: 0.01\n",
      "Epoch [3617/20000], Loss: 1114.9178466796875, Entropy 209.0906219482422, Learning Rate: 0.01\n",
      "Epoch [3618/20000], Loss: 1052.8653564453125, Entropy 198.8969268798828, Learning Rate: 0.01\n",
      "Epoch [3619/20000], Loss: 990.7609252929688, Entropy 209.7428436279297, Learning Rate: 0.01\n",
      "Epoch [3620/20000], Loss: 1023.1168212890625, Entropy 204.57046508789062, Learning Rate: 0.01\n",
      "Epoch [3621/20000], Loss: 1064.57177734375, Entropy 209.5560302734375, Learning Rate: 0.01\n",
      "Epoch [3622/20000], Loss: 1083.153564453125, Entropy 203.92140197753906, Learning Rate: 0.01\n",
      "Epoch [3623/20000], Loss: 1060.0457763671875, Entropy 181.3523406982422, Learning Rate: 0.01\n",
      "Epoch [3624/20000], Loss: 1044.3367919921875, Entropy 206.48678588867188, Learning Rate: 0.01\n",
      "Epoch [3625/20000], Loss: 1011.7371826171875, Entropy 193.67642211914062, Learning Rate: 0.01\n",
      "Epoch [3626/20000], Loss: 1025.4017333984375, Entropy 202.3308868408203, Learning Rate: 0.01\n",
      "Epoch [3627/20000], Loss: 1036.839111328125, Entropy 208.3895263671875, Learning Rate: 0.01\n",
      "Epoch [3628/20000], Loss: 998.5990600585938, Entropy 203.8196258544922, Learning Rate: 0.01\n",
      "Epoch [3629/20000], Loss: 1023.6514282226562, Entropy 200.3626251220703, Learning Rate: 0.01\n",
      "Epoch [3630/20000], Loss: 1003.1958618164062, Entropy 210.1104278564453, Learning Rate: 0.01\n",
      "Epoch [3631/20000], Loss: 1039.23388671875, Entropy 205.551025390625, Learning Rate: 0.01\n",
      "Epoch [3632/20000], Loss: 999.3855590820312, Entropy 202.3245086669922, Learning Rate: 0.01\n",
      "Epoch [3633/20000], Loss: 1015.3848876953125, Entropy 210.76382446289062, Learning Rate: 0.01\n",
      "Epoch [3634/20000], Loss: 1024.4244384765625, Entropy 205.2081756591797, Learning Rate: 0.01\n",
      "Epoch [3635/20000], Loss: 995.4645385742188, Entropy 210.1522979736328, Learning Rate: 0.01\n",
      "Epoch [3636/20000], Loss: 1042.4378662109375, Entropy 200.42166137695312, Learning Rate: 0.01\n",
      "Epoch [3637/20000], Loss: 990.4863891601562, Entropy 221.2486114501953, Learning Rate: 0.01\n",
      "Epoch [3638/20000], Loss: 991.51318359375, Entropy 219.24354553222656, Learning Rate: 0.01\n",
      "Epoch [3639/20000], Loss: 1002.292724609375, Entropy 221.48851013183594, Learning Rate: 0.01\n",
      "Epoch [3640/20000], Loss: 991.929443359375, Entropy 216.29519653320312, Learning Rate: 0.01\n",
      "Epoch [3641/20000], Loss: 1012.1495971679688, Entropy 185.82476806640625, Learning Rate: 0.01\n",
      "Epoch [3642/20000], Loss: 990.4197998046875, Entropy 214.84548950195312, Learning Rate: 0.01\n",
      "Epoch [3643/20000], Loss: 999.0789794921875, Entropy 211.59487915039062, Learning Rate: 0.01\n",
      "Epoch [3644/20000], Loss: 986.6937866210938, Entropy 199.17425537109375, Learning Rate: 0.01\n",
      "Epoch [3645/20000], Loss: 1013.1190795898438, Entropy 207.97137451171875, Learning Rate: 0.01\n",
      "Epoch [3646/20000], Loss: 968.90234375, Entropy 208.54429626464844, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3647/20000], Loss: 1016.9676513671875, Entropy 207.20265197753906, Learning Rate: 0.01\n",
      "Epoch [3648/20000], Loss: 988.0540771484375, Entropy 207.03042602539062, Learning Rate: 0.01\n",
      "Epoch [3649/20000], Loss: 1007.1109008789062, Entropy 216.5148162841797, Learning Rate: 0.01\n",
      "Epoch [3650/20000], Loss: 972.814697265625, Entropy 231.61129760742188, Learning Rate: 0.01\n",
      "Epoch [3651/20000], Loss: 989.8287963867188, Entropy 220.8262481689453, Learning Rate: 0.01\n",
      "Epoch [3652/20000], Loss: 974.8717041015625, Entropy 209.10435485839844, Learning Rate: 0.01\n",
      "Epoch [3653/20000], Loss: 973.873291015625, Entropy 220.82923889160156, Learning Rate: 0.01\n",
      "Epoch [3654/20000], Loss: 995.9957275390625, Entropy 226.49441528320312, Learning Rate: 0.01\n",
      "Epoch [3655/20000], Loss: 982.3037109375, Entropy 216.618408203125, Learning Rate: 0.01\n",
      "Epoch [3656/20000], Loss: 1009.2809448242188, Entropy 192.1276092529297, Learning Rate: 0.01\n",
      "Epoch [3657/20000], Loss: 996.134033203125, Entropy 215.06495666503906, Learning Rate: 0.01\n",
      "Epoch [3658/20000], Loss: 977.5159912109375, Entropy 221.19595336914062, Learning Rate: 0.01\n",
      "Epoch [3659/20000], Loss: 1001.2039794921875, Entropy 203.86634826660156, Learning Rate: 0.01\n",
      "Epoch [3660/20000], Loss: 978.76953125, Entropy 218.04660034179688, Learning Rate: 0.01\n",
      "Epoch [3661/20000], Loss: 1000.78271484375, Entropy 222.87403869628906, Learning Rate: 0.01\n",
      "Epoch [3662/20000], Loss: 1000.5195922851562, Entropy 206.4812774658203, Learning Rate: 0.01\n",
      "Epoch [3663/20000], Loss: 982.5680541992188, Entropy 213.4124298095703, Learning Rate: 0.01\n",
      "Epoch [3664/20000], Loss: 972.3677368164062, Entropy 225.32281494140625, Learning Rate: 0.01\n",
      "Epoch [3665/20000], Loss: 1006.9463500976562, Entropy 229.7154998779297, Learning Rate: 0.01\n",
      "Epoch [3666/20000], Loss: 1006.0587158203125, Entropy 213.74343872070312, Learning Rate: 0.01\n",
      "Epoch [3667/20000], Loss: 957.318359375, Entropy 238.38827514648438, Learning Rate: 0.01\n",
      "Epoch [3668/20000], Loss: 992.6799926757812, Entropy 220.2498016357422, Learning Rate: 0.01\n",
      "Epoch [3669/20000], Loss: 975.6708984375, Entropy 231.9691162109375, Learning Rate: 0.01\n",
      "Epoch [3670/20000], Loss: 958.8554077148438, Entropy 222.44036865234375, Learning Rate: 0.01\n",
      "Epoch [3671/20000], Loss: 993.4984130859375, Entropy 220.364013671875, Learning Rate: 0.01\n",
      "Epoch [3672/20000], Loss: 978.080810546875, Entropy 233.87667846679688, Learning Rate: 0.01\n",
      "Epoch [3673/20000], Loss: 983.3681030273438, Entropy 221.77252197265625, Learning Rate: 0.01\n",
      "Epoch [3674/20000], Loss: 1024.4432373046875, Entropy 219.28553771972656, Learning Rate: 0.01\n",
      "Epoch [3675/20000], Loss: 1026.0474853515625, Entropy 216.79257202148438, Learning Rate: 0.01\n",
      "Epoch [3676/20000], Loss: 1002.6517944335938, Entropy 218.8907012939453, Learning Rate: 0.01\n",
      "Epoch [3677/20000], Loss: 1018.888916015625, Entropy 227.277587890625, Learning Rate: 0.01\n",
      "Epoch [3678/20000], Loss: 1000.3298950195312, Entropy 215.0782928466797, Learning Rate: 0.01\n",
      "Epoch [3679/20000], Loss: 1008.7910766601562, Entropy 225.9442596435547, Learning Rate: 0.01\n",
      "Epoch [3680/20000], Loss: 1021.41650390625, Entropy 208.7279052734375, Learning Rate: 0.01\n",
      "Epoch [3681/20000], Loss: 995.54150390625, Entropy 213.90711975097656, Learning Rate: 0.01\n",
      "Epoch [3682/20000], Loss: 997.690673828125, Entropy 217.98341369628906, Learning Rate: 0.01\n",
      "Epoch [3683/20000], Loss: 1024.422119140625, Entropy 227.91465759277344, Learning Rate: 0.01\n",
      "Epoch [3684/20000], Loss: 1017.1334228515625, Entropy 242.14871215820312, Learning Rate: 0.01\n",
      "Epoch [3685/20000], Loss: 993.4945068359375, Entropy 221.37039184570312, Learning Rate: 0.01\n",
      "Epoch [3686/20000], Loss: 1012.29052734375, Entropy 233.20323181152344, Learning Rate: 0.01\n",
      "Epoch [3687/20000], Loss: 1012.8280029296875, Entropy 215.82034301757812, Learning Rate: 0.01\n",
      "Epoch [3688/20000], Loss: 972.899658203125, Entropy 247.63917541503906, Learning Rate: 0.01\n",
      "Epoch [3689/20000], Loss: 996.4261474609375, Entropy 231.47581481933594, Learning Rate: 0.01\n",
      "Epoch [3690/20000], Loss: 1035.8138427734375, Entropy 239.75027465820312, Learning Rate: 0.01\n",
      "Epoch [3691/20000], Loss: 978.804931640625, Entropy 239.64816284179688, Learning Rate: 0.01\n",
      "Epoch [3692/20000], Loss: 1013.1243896484375, Entropy 230.13706970214844, Learning Rate: 0.01\n",
      "Epoch [3693/20000], Loss: 1019.273681640625, Entropy 221.53488159179688, Learning Rate: 0.01\n",
      "Epoch [3694/20000], Loss: 1020.4025268554688, Entropy 236.2290496826172, Learning Rate: 0.01\n",
      "Epoch [3695/20000], Loss: 1021.2825927734375, Entropy 244.09974670410156, Learning Rate: 0.01\n",
      "Epoch [3696/20000], Loss: 1020.5291137695312, Entropy 239.7306365966797, Learning Rate: 0.01\n",
      "Epoch [3697/20000], Loss: 1041.1009521484375, Entropy 226.33901977539062, Learning Rate: 0.01\n",
      "Epoch [3698/20000], Loss: 1045.1182861328125, Entropy 218.76242065429688, Learning Rate: 0.01\n",
      "Epoch [3699/20000], Loss: 1012.929443359375, Entropy 228.75148010253906, Learning Rate: 0.01\n",
      "Epoch [3700/20000], Loss: 1069.96630859375, Entropy 211.7188262939453, Learning Rate: 0.01\n",
      "Epoch [3701/20000], Loss: 1026.059814453125, Entropy 235.64288330078125, Learning Rate: 0.01\n",
      "Epoch [3702/20000], Loss: 1010.8719482421875, Entropy 239.13241577148438, Learning Rate: 0.01\n",
      "Epoch [3703/20000], Loss: 1014.360595703125, Entropy 240.57066345214844, Learning Rate: 0.01\n",
      "Epoch [3704/20000], Loss: 1003.522705078125, Entropy 247.39401245117188, Learning Rate: 0.01\n",
      "Epoch [3705/20000], Loss: 1064.892578125, Entropy 226.07186889648438, Learning Rate: 0.01\n",
      "Epoch [3706/20000], Loss: 1018.7034912109375, Entropy 234.70999145507812, Learning Rate: 0.01\n",
      "Epoch [3707/20000], Loss: 1030.8951416015625, Entropy 249.68760681152344, Learning Rate: 0.01\n",
      "Epoch [3708/20000], Loss: 1017.279052734375, Entropy 231.53623962402344, Learning Rate: 0.01\n",
      "Epoch [3709/20000], Loss: 993.335205078125, Entropy 247.58116149902344, Learning Rate: 0.01\n",
      "Epoch [3710/20000], Loss: 980.4033813476562, Entropy 237.55889892578125, Learning Rate: 0.01\n",
      "Epoch [3711/20000], Loss: 989.032958984375, Entropy 234.9150390625, Learning Rate: 0.01\n",
      "Epoch [3712/20000], Loss: 991.775634765625, Entropy 236.491943359375, Learning Rate: 0.01\n",
      "Epoch [3713/20000], Loss: 986.5654907226562, Entropy 234.3134307861328, Learning Rate: 0.01\n",
      "Epoch [3714/20000], Loss: 988.4007568359375, Entropy 242.382568359375, Learning Rate: 0.01\n",
      "Epoch [3715/20000], Loss: 1003.4974365234375, Entropy 213.40335083007812, Learning Rate: 0.01\n",
      "Epoch [3716/20000], Loss: 1016.6671142578125, Entropy 231.82337951660156, Learning Rate: 0.01\n",
      "Epoch [3717/20000], Loss: 984.2803955078125, Entropy 251.63536071777344, Learning Rate: 0.01\n",
      "Epoch [3718/20000], Loss: 1008.0745849609375, Entropy 225.25741577148438, Learning Rate: 0.01\n",
      "Epoch [3719/20000], Loss: 993.5174560546875, Entropy 228.07972717285156, Learning Rate: 0.01\n",
      "Epoch [3720/20000], Loss: 967.484130859375, Entropy 242.820556640625, Learning Rate: 0.01\n",
      "Epoch [3721/20000], Loss: 995.5137939453125, Entropy 233.02854919433594, Learning Rate: 0.01\n",
      "Epoch [3722/20000], Loss: 990.2021484375, Entropy 238.35421752929688, Learning Rate: 0.01\n",
      "Epoch [3723/20000], Loss: 998.7282104492188, Entropy 232.3369598388672, Learning Rate: 0.01\n",
      "Epoch [3724/20000], Loss: 983.836181640625, Entropy 246.82955932617188, Learning Rate: 0.01\n",
      "Epoch [3725/20000], Loss: 994.3800659179688, Entropy 237.8019256591797, Learning Rate: 0.01\n",
      "Epoch [3726/20000], Loss: 987.491455078125, Entropy 238.75985717773438, Learning Rate: 0.01\n",
      "Epoch [3727/20000], Loss: 1022.636474609375, Entropy 239.17245483398438, Learning Rate: 0.01\n",
      "Epoch [3728/20000], Loss: 962.6277465820312, Entropy 231.8112030029297, Learning Rate: 0.01\n",
      "Epoch [3729/20000], Loss: 1022.4393920898438, Entropy 237.36712646484375, Learning Rate: 0.01\n",
      "Epoch [3730/20000], Loss: 985.7471923828125, Entropy 234.82472229003906, Learning Rate: 0.01\n",
      "Epoch [3731/20000], Loss: 1005.7117919921875, Entropy 241.04660034179688, Learning Rate: 0.01\n",
      "Epoch [3732/20000], Loss: 1008.7565307617188, Entropy 243.1811981201172, Learning Rate: 0.01\n",
      "Epoch [3733/20000], Loss: 979.779296875, Entropy 245.48399353027344, Learning Rate: 0.01\n",
      "Epoch [3734/20000], Loss: 1034.7218017578125, Entropy 236.63479614257812, Learning Rate: 0.01\n",
      "Epoch [3735/20000], Loss: 994.27685546875, Entropy 236.544677734375, Learning Rate: 0.01\n",
      "Epoch [3736/20000], Loss: 980.5787963867188, Entropy 236.1063995361328, Learning Rate: 0.01\n",
      "Epoch [3737/20000], Loss: 992.850341796875, Entropy 237.73336791992188, Learning Rate: 0.01\n",
      "Epoch [3738/20000], Loss: 991.655029296875, Entropy 250.5086669921875, Learning Rate: 0.01\n",
      "Epoch [3739/20000], Loss: 972.6411743164062, Entropy 241.89007568359375, Learning Rate: 0.01\n",
      "Epoch [3740/20000], Loss: 969.01513671875, Entropy 244.10227966308594, Learning Rate: 0.01\n",
      "Epoch [3741/20000], Loss: 992.5560302734375, Entropy 251.80514526367188, Learning Rate: 0.01\n",
      "Epoch [3742/20000], Loss: 1004.099365234375, Entropy 257.5072937011719, Learning Rate: 0.01\n",
      "Epoch [3743/20000], Loss: 990.1079711914062, Entropy 239.00238037109375, Learning Rate: 0.01\n",
      "Epoch [3744/20000], Loss: 1001.4085693359375, Entropy 242.59202575683594, Learning Rate: 0.01\n",
      "Epoch [3745/20000], Loss: 1012.30810546875, Entropy 240.64761352539062, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3746/20000], Loss: 936.3770751953125, Entropy 247.06668090820312, Learning Rate: 0.01\n",
      "Epoch [3747/20000], Loss: 996.1378784179688, Entropy 244.39288330078125, Learning Rate: 0.01\n",
      "Epoch [3748/20000], Loss: 961.9533081054688, Entropy 241.35076904296875, Learning Rate: 0.01\n",
      "Epoch [3749/20000], Loss: 1000.7130126953125, Entropy 246.40042114257812, Learning Rate: 0.01\n",
      "Epoch [3750/20000], Loss: 1041.8914794921875, Entropy 240.44241333007812, Learning Rate: 0.01\n",
      "Epoch [3751/20000], Loss: 1011.97607421875, Entropy 251.50999450683594, Learning Rate: 0.01\n",
      "Epoch [3752/20000], Loss: 973.1097412109375, Entropy 255.31214904785156, Learning Rate: 0.01\n",
      "Epoch [3753/20000], Loss: 1018.7777709960938, Entropy 258.51885986328125, Learning Rate: 0.01\n",
      "Epoch [3754/20000], Loss: 1092.6463623046875, Entropy 254.89561462402344, Learning Rate: 0.01\n",
      "Epoch [3755/20000], Loss: 1075.039306640625, Entropy 252.18109130859375, Learning Rate: 0.01\n",
      "Epoch [3756/20000], Loss: 1105.137939453125, Entropy 239.5701904296875, Learning Rate: 0.01\n",
      "Epoch [3757/20000], Loss: 1157.9906005859375, Entropy 252.7830810546875, Learning Rate: 0.01\n",
      "Epoch [3758/20000], Loss: 1042.44384765625, Entropy 255.00909423828125, Learning Rate: 0.01\n",
      "Epoch [3759/20000], Loss: 1102.902587890625, Entropy 254.74151611328125, Learning Rate: 0.01\n",
      "Epoch [3760/20000], Loss: 1049.937744140625, Entropy 247.68638610839844, Learning Rate: 0.01\n",
      "Epoch [3761/20000], Loss: 1071.6162109375, Entropy 245.8497772216797, Learning Rate: 0.01\n",
      "Epoch [3762/20000], Loss: 1100.4439697265625, Entropy 243.15345764160156, Learning Rate: 0.01\n",
      "Epoch [3763/20000], Loss: 1048.256591796875, Entropy 258.88421630859375, Learning Rate: 0.01\n",
      "Epoch [3764/20000], Loss: 1017.6343994140625, Entropy 259.8409729003906, Learning Rate: 0.01\n",
      "Epoch [3765/20000], Loss: 1025.1129150390625, Entropy 242.05210876464844, Learning Rate: 0.01\n",
      "Epoch [3766/20000], Loss: 1030.013671875, Entropy 257.1208190917969, Learning Rate: 0.01\n",
      "Epoch [3767/20000], Loss: 1048.79541015625, Entropy 258.1722412109375, Learning Rate: 0.01\n",
      "Epoch [3768/20000], Loss: 1156.0888671875, Entropy 238.6804656982422, Learning Rate: 0.01\n",
      "Epoch [3769/20000], Loss: 1136.5999755859375, Entropy 260.7079772949219, Learning Rate: 0.01\n",
      "Epoch [3770/20000], Loss: 1236.8905029296875, Entropy 240.10128784179688, Learning Rate: 0.01\n",
      "Epoch [3771/20000], Loss: 1023.2034301757812, Entropy 249.7949981689453, Learning Rate: 0.01\n",
      "Epoch [3772/20000], Loss: 1148.8963623046875, Entropy 262.0062561035156, Learning Rate: 0.01\n",
      "Epoch [3773/20000], Loss: 1065.1875, Entropy 248.263671875, Learning Rate: 0.01\n",
      "Epoch [3774/20000], Loss: 1049.154296875, Entropy 241.92791748046875, Learning Rate: 0.01\n",
      "Epoch [3775/20000], Loss: 1125.4248046875, Entropy 259.4865417480469, Learning Rate: 0.01\n",
      "Epoch [3776/20000], Loss: 1081.0596923828125, Entropy 242.44374084472656, Learning Rate: 0.01\n",
      "Epoch [3777/20000], Loss: 1185.60986328125, Entropy 251.21449279785156, Learning Rate: 0.01\n",
      "Epoch [3778/20000], Loss: 1161.13134765625, Entropy 249.31268310546875, Learning Rate: 0.01\n",
      "Epoch [3779/20000], Loss: 1284.028076171875, Entropy 239.51312255859375, Learning Rate: 0.01\n",
      "Epoch [3780/20000], Loss: 1360.0302734375, Entropy 242.43746948242188, Learning Rate: 0.01\n",
      "Epoch [3781/20000], Loss: 1179.00732421875, Entropy 244.28070068359375, Learning Rate: 0.01\n",
      "Epoch [3782/20000], Loss: 1260.796875, Entropy 231.3414764404297, Learning Rate: 0.01\n",
      "Epoch [3783/20000], Loss: 1277.58447265625, Entropy 251.0194854736328, Learning Rate: 0.01\n",
      "Epoch [3784/20000], Loss: 1081.1666259765625, Entropy 221.42117309570312, Learning Rate: 0.01\n",
      "Epoch [3785/20000], Loss: 1176.92529296875, Entropy 233.37713623046875, Learning Rate: 0.01\n",
      "Epoch [3786/20000], Loss: 1222.024658203125, Entropy 250.7303009033203, Learning Rate: 0.01\n",
      "Epoch [3787/20000], Loss: 1079.5250244140625, Entropy 241.2245635986328, Learning Rate: 0.01\n",
      "Epoch [3788/20000], Loss: 1191.0408935546875, Entropy 247.52749633789062, Learning Rate: 0.01\n",
      "Epoch [3789/20000], Loss: 1237.4268798828125, Entropy 246.4817657470703, Learning Rate: 0.01\n",
      "Epoch [3790/20000], Loss: 1183.4329833984375, Entropy 240.6050262451172, Learning Rate: 0.01\n",
      "Epoch [3791/20000], Loss: 1310.5860595703125, Entropy 237.25770568847656, Learning Rate: 0.01\n",
      "Epoch [3792/20000], Loss: 1131.8726806640625, Entropy 240.4973907470703, Learning Rate: 0.01\n",
      "Epoch [3793/20000], Loss: 1316.9967041015625, Entropy 240.96206665039062, Learning Rate: 0.01\n",
      "Epoch [3794/20000], Loss: 1163.5703125, Entropy 224.96617126464844, Learning Rate: 0.01\n",
      "Epoch [3795/20000], Loss: 1113.4163818359375, Entropy 238.30113220214844, Learning Rate: 0.01\n",
      "Epoch [3796/20000], Loss: 1306.7764892578125, Entropy 231.10787963867188, Learning Rate: 0.01\n",
      "Epoch [3797/20000], Loss: 1257.001220703125, Entropy 223.02191162109375, Learning Rate: 0.01\n",
      "Epoch [3798/20000], Loss: 1221.13330078125, Entropy 235.67694091796875, Learning Rate: 0.01\n",
      "Epoch [3799/20000], Loss: 1664.5504150390625, Entropy 232.4701690673828, Learning Rate: 0.01\n",
      "Epoch [3800/20000], Loss: 1067.49853515625, Entropy 220.70565795898438, Learning Rate: 0.01\n",
      "Epoch [3801/20000], Loss: 1501.2943115234375, Entropy 230.5480194091797, Learning Rate: 0.01\n",
      "Epoch [3802/20000], Loss: 1227.885986328125, Entropy 222.38742065429688, Learning Rate: 0.01\n",
      "Epoch [3803/20000], Loss: 1077.1885986328125, Entropy 204.13796997070312, Learning Rate: 0.01\n",
      "Epoch [3804/20000], Loss: 1278.7568359375, Entropy 223.38458251953125, Learning Rate: 0.01\n",
      "Epoch [3805/20000], Loss: 1103.1868896484375, Entropy 222.2184295654297, Learning Rate: 0.01\n",
      "Epoch [3806/20000], Loss: 1058.04736328125, Entropy 219.50421142578125, Learning Rate: 0.01\n",
      "Epoch [3807/20000], Loss: 1170.65625, Entropy 233.7142333984375, Learning Rate: 0.01\n",
      "Epoch [3808/20000], Loss: 1057.6719970703125, Entropy 227.02389526367188, Learning Rate: 0.01\n",
      "Epoch [3809/20000], Loss: 1020.3493041992188, Entropy 222.9400177001953, Learning Rate: 0.01\n",
      "Epoch [3810/20000], Loss: 1110.85107421875, Entropy 222.18414306640625, Learning Rate: 0.01\n",
      "Epoch [3811/20000], Loss: 1036.853515625, Entropy 223.90611267089844, Learning Rate: 0.01\n",
      "Epoch [3812/20000], Loss: 1008.0371704101562, Entropy 216.20806884765625, Learning Rate: 0.01\n",
      "Epoch [3813/20000], Loss: 1074.24951171875, Entropy 220.008544921875, Learning Rate: 0.01\n",
      "Epoch [3814/20000], Loss: 1072.3035888671875, Entropy 212.84323120117188, Learning Rate: 0.01\n",
      "Epoch [3815/20000], Loss: 1067.7950439453125, Entropy 215.85826110839844, Learning Rate: 0.01\n",
      "Epoch [3816/20000], Loss: 1012.7330932617188, Entropy 222.1807403564453, Learning Rate: 0.01\n",
      "Epoch [3817/20000], Loss: 1053.962158203125, Entropy 220.63194274902344, Learning Rate: 0.01\n",
      "Epoch [3818/20000], Loss: 1043.650634765625, Entropy 225.36874389648438, Learning Rate: 0.01\n",
      "Epoch [3819/20000], Loss: 1062.764892578125, Entropy 211.61439514160156, Learning Rate: 0.01\n",
      "Epoch [3820/20000], Loss: 1123.6739501953125, Entropy 227.68624877929688, Learning Rate: 0.01\n",
      "Epoch [3821/20000], Loss: 1013.2840576171875, Entropy 206.17518615722656, Learning Rate: 0.01\n",
      "Epoch [3822/20000], Loss: 1178.608642578125, Entropy 220.0470428466797, Learning Rate: 0.01\n",
      "Epoch [3823/20000], Loss: 1059.6689453125, Entropy 220.26516723632812, Learning Rate: 0.01\n",
      "Epoch [3824/20000], Loss: 1222.8304443359375, Entropy 212.94847106933594, Learning Rate: 0.01\n",
      "Epoch [3825/20000], Loss: 1053.706298828125, Entropy 217.28042602539062, Learning Rate: 0.01\n",
      "Epoch [3826/20000], Loss: 1209.5516357421875, Entropy 220.1570587158203, Learning Rate: 0.01\n",
      "Epoch [3827/20000], Loss: 1220.635009765625, Entropy 199.35023498535156, Learning Rate: 0.01\n",
      "Epoch [3828/20000], Loss: 1173.792236328125, Entropy 215.8246612548828, Learning Rate: 0.01\n",
      "Epoch [3829/20000], Loss: 1267.56298828125, Entropy 219.02870178222656, Learning Rate: 0.01\n",
      "Epoch [3830/20000], Loss: 1057.0087890625, Entropy 214.14044189453125, Learning Rate: 0.01\n",
      "Epoch [3831/20000], Loss: 1196.4254150390625, Entropy 208.21034240722656, Learning Rate: 0.01\n",
      "Epoch [3832/20000], Loss: 1105.832763671875, Entropy 206.9229278564453, Learning Rate: 0.01\n",
      "Epoch [3833/20000], Loss: 1142.949951171875, Entropy 209.3279266357422, Learning Rate: 0.01\n",
      "Epoch [3834/20000], Loss: 1133.379150390625, Entropy 209.57135009765625, Learning Rate: 0.01\n",
      "Epoch [3835/20000], Loss: 1177.146484375, Entropy 227.09375, Learning Rate: 0.01\n",
      "Epoch [3836/20000], Loss: 1091.14599609375, Entropy 208.49163818359375, Learning Rate: 0.01\n",
      "Epoch [3837/20000], Loss: 1262.926513671875, Entropy 209.22059631347656, Learning Rate: 0.01\n",
      "Epoch [3838/20000], Loss: 1000.0383911132812, Entropy 207.4551544189453, Learning Rate: 0.01\n",
      "Epoch [3839/20000], Loss: 1240.80322265625, Entropy 205.056396484375, Learning Rate: 0.01\n",
      "Epoch [3840/20000], Loss: 1043.8778076171875, Entropy 205.99171447753906, Learning Rate: 0.01\n",
      "Epoch [3841/20000], Loss: 1177.5489501953125, Entropy 213.03982543945312, Learning Rate: 0.01\n",
      "Epoch [3842/20000], Loss: 1021.3388671875, Entropy 212.7347412109375, Learning Rate: 0.01\n",
      "Epoch [3843/20000], Loss: 1087.15380859375, Entropy 204.2668914794922, Learning Rate: 0.01\n",
      "Epoch [3844/20000], Loss: 1048.73876953125, Entropy 197.963134765625, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3845/20000], Loss: 1025.6571044921875, Entropy 202.17257690429688, Learning Rate: 0.01\n",
      "Epoch [3846/20000], Loss: 1049.530029296875, Entropy 210.42335510253906, Learning Rate: 0.01\n",
      "Epoch [3847/20000], Loss: 1030.7177734375, Entropy 200.71652221679688, Learning Rate: 0.01\n",
      "Epoch [3848/20000], Loss: 1047.2342529296875, Entropy 208.74229431152344, Learning Rate: 0.01\n",
      "Epoch [3849/20000], Loss: 1020.0980834960938, Entropy 211.67999267578125, Learning Rate: 0.01\n",
      "Epoch [3850/20000], Loss: 1033.6259765625, Entropy 214.0212860107422, Learning Rate: 0.01\n",
      "Epoch [3851/20000], Loss: 1040.9998779296875, Entropy 201.7744140625, Learning Rate: 0.01\n",
      "Epoch [3852/20000], Loss: 1051.4664306640625, Entropy 192.09713745117188, Learning Rate: 0.01\n",
      "Epoch [3853/20000], Loss: 1020.922119140625, Entropy 198.62551879882812, Learning Rate: 0.01\n",
      "Epoch [3854/20000], Loss: 1086.0628662109375, Entropy 218.45835876464844, Learning Rate: 0.01\n",
      "Epoch [3855/20000], Loss: 1042.3072509765625, Entropy 204.51283264160156, Learning Rate: 0.01\n",
      "Epoch [3856/20000], Loss: 1072.8038330078125, Entropy 206.69003295898438, Learning Rate: 0.01\n",
      "Epoch [3857/20000], Loss: 1037.918212890625, Entropy 201.2333984375, Learning Rate: 0.01\n",
      "Epoch [3858/20000], Loss: 1020.439697265625, Entropy 196.8935546875, Learning Rate: 0.01\n",
      "Epoch [3859/20000], Loss: 1054.638427734375, Entropy 201.5995330810547, Learning Rate: 0.01\n",
      "Epoch [3860/20000], Loss: 996.064697265625, Entropy 217.051513671875, Learning Rate: 0.01\n",
      "Epoch [3861/20000], Loss: 1012.7733154296875, Entropy 207.82400512695312, Learning Rate: 0.01\n",
      "Epoch [3862/20000], Loss: 972.90283203125, Entropy 220.55270385742188, Learning Rate: 0.01\n",
      "Epoch [3863/20000], Loss: 1015.9215087890625, Entropy 203.34530639648438, Learning Rate: 0.01\n",
      "Epoch [3864/20000], Loss: 1004.290283203125, Entropy 205.64552307128906, Learning Rate: 0.01\n",
      "Epoch [3865/20000], Loss: 1002.3120727539062, Entropy 208.1853790283203, Learning Rate: 0.01\n",
      "Epoch [3866/20000], Loss: 1000.4013061523438, Entropy 207.1171417236328, Learning Rate: 0.01\n",
      "Epoch [3867/20000], Loss: 1023.4855346679688, Entropy 196.0573272705078, Learning Rate: 0.01\n",
      "Epoch [3868/20000], Loss: 970.7008666992188, Entropy 206.71038818359375, Learning Rate: 0.01\n",
      "Epoch [3869/20000], Loss: 1019.3091430664062, Entropy 210.2869415283203, Learning Rate: 0.01\n",
      "Epoch [3870/20000], Loss: 993.4014282226562, Entropy 212.3522186279297, Learning Rate: 0.01\n",
      "Epoch [3871/20000], Loss: 1015.9603271484375, Entropy 209.19827270507812, Learning Rate: 0.01\n",
      "Epoch [3872/20000], Loss: 1014.94921875, Entropy 224.58058166503906, Learning Rate: 0.01\n",
      "Epoch [3873/20000], Loss: 975.5126342773438, Entropy 225.2880096435547, Learning Rate: 0.01\n",
      "Epoch [3874/20000], Loss: 1033.613525390625, Entropy 210.4675750732422, Learning Rate: 0.01\n",
      "Epoch [3875/20000], Loss: 1024.364990234375, Entropy 210.3651123046875, Learning Rate: 0.01\n",
      "Epoch [3876/20000], Loss: 1014.2142333984375, Entropy 208.03330993652344, Learning Rate: 0.01\n",
      "Epoch [3877/20000], Loss: 1052.1724853515625, Entropy 219.2415313720703, Learning Rate: 0.01\n",
      "Epoch [3878/20000], Loss: 1043.709716796875, Entropy 221.54136657714844, Learning Rate: 0.01\n",
      "Epoch [3879/20000], Loss: 1009.8314208984375, Entropy 228.68795776367188, Learning Rate: 0.01\n",
      "Epoch [3880/20000], Loss: 1037.423583984375, Entropy 227.07537841796875, Learning Rate: 0.01\n",
      "Epoch [3881/20000], Loss: 1039.9906005859375, Entropy 231.07997131347656, Learning Rate: 0.01\n",
      "Epoch [3882/20000], Loss: 1014.1041870117188, Entropy 218.81146240234375, Learning Rate: 0.01\n",
      "Epoch [3883/20000], Loss: 1022.0786743164062, Entropy 224.3005828857422, Learning Rate: 0.01\n",
      "Epoch [3884/20000], Loss: 998.3278198242188, Entropy 227.8699188232422, Learning Rate: 0.01\n",
      "Epoch [3885/20000], Loss: 972.8716430664062, Entropy 225.35797119140625, Learning Rate: 0.01\n",
      "Epoch [3886/20000], Loss: 1039.8802490234375, Entropy 224.27354431152344, Learning Rate: 0.01\n",
      "Epoch [3887/20000], Loss: 988.1473388671875, Entropy 215.74668884277344, Learning Rate: 0.01\n",
      "Epoch [3888/20000], Loss: 1030.74755859375, Entropy 219.49766540527344, Learning Rate: 0.01\n",
      "Epoch [3889/20000], Loss: 1010.2713623046875, Entropy 231.76278686523438, Learning Rate: 0.01\n",
      "Epoch [3890/20000], Loss: 992.080810546875, Entropy 221.51210021972656, Learning Rate: 0.01\n",
      "Epoch [3891/20000], Loss: 1036.353515625, Entropy 226.32208251953125, Learning Rate: 0.01\n",
      "Epoch [3892/20000], Loss: 1049.753173828125, Entropy 225.3210906982422, Learning Rate: 0.01\n",
      "Epoch [3893/20000], Loss: 1010.4737548828125, Entropy 228.90347290039062, Learning Rate: 0.01\n",
      "Epoch [3894/20000], Loss: 1007.3679809570312, Entropy 228.6453094482422, Learning Rate: 0.01\n",
      "Epoch [3895/20000], Loss: 1054.7264404296875, Entropy 225.83604431152344, Learning Rate: 0.01\n",
      "Epoch [3896/20000], Loss: 1029.2064208984375, Entropy 229.48995971679688, Learning Rate: 0.01\n",
      "Epoch [3897/20000], Loss: 986.4124755859375, Entropy 229.76026916503906, Learning Rate: 0.01\n",
      "Epoch [3898/20000], Loss: 1031.8704833984375, Entropy 230.88365173339844, Learning Rate: 0.01\n",
      "Epoch [3899/20000], Loss: 989.6583251953125, Entropy 238.4451904296875, Learning Rate: 0.01\n",
      "Epoch [3900/20000], Loss: 1024.0831298828125, Entropy 234.58226013183594, Learning Rate: 0.01\n",
      "Epoch [3901/20000], Loss: 995.6113891601562, Entropy 217.5175018310547, Learning Rate: 0.01\n",
      "Epoch [3902/20000], Loss: 1010.0347900390625, Entropy 218.130615234375, Learning Rate: 0.01\n",
      "Epoch [3903/20000], Loss: 1039.8643798828125, Entropy 226.2986297607422, Learning Rate: 0.01\n",
      "Epoch [3904/20000], Loss: 1008.8486328125, Entropy 228.53970336914062, Learning Rate: 0.01\n",
      "Epoch [3905/20000], Loss: 984.03466796875, Entropy 219.53921508789062, Learning Rate: 0.01\n",
      "Epoch [3906/20000], Loss: 1047.702880859375, Entropy 214.46905517578125, Learning Rate: 0.01\n",
      "Epoch [3907/20000], Loss: 996.3308715820312, Entropy 237.65179443359375, Learning Rate: 0.01\n",
      "Epoch [3908/20000], Loss: 1022.7256469726562, Entropy 218.43365478515625, Learning Rate: 0.01\n",
      "Epoch [3909/20000], Loss: 957.0659790039062, Entropy 245.96160888671875, Learning Rate: 0.01\n",
      "Epoch [3910/20000], Loss: 1009.3016357421875, Entropy 222.55490112304688, Learning Rate: 0.01\n",
      "Epoch [3911/20000], Loss: 1014.3600463867188, Entropy 223.56903076171875, Learning Rate: 0.01\n",
      "Epoch [3912/20000], Loss: 1075.635498046875, Entropy 227.14495849609375, Learning Rate: 0.01\n",
      "Epoch [3913/20000], Loss: 1024.0140380859375, Entropy 217.6679229736328, Learning Rate: 0.01\n",
      "Epoch [3914/20000], Loss: 1071.971435546875, Entropy 233.7290802001953, Learning Rate: 0.01\n",
      "Epoch [3915/20000], Loss: 1025.2080078125, Entropy 228.67041015625, Learning Rate: 0.01\n",
      "Epoch [3916/20000], Loss: 1083.3736572265625, Entropy 238.10704040527344, Learning Rate: 0.01\n",
      "Epoch [3917/20000], Loss: 1048.7630615234375, Entropy 222.385498046875, Learning Rate: 0.01\n",
      "Epoch [3918/20000], Loss: 1024.55810546875, Entropy 222.3074951171875, Learning Rate: 0.01\n",
      "Epoch [3919/20000], Loss: 1004.8643188476562, Entropy 235.6285858154297, Learning Rate: 0.01\n",
      "Epoch [3920/20000], Loss: 1043.4560546875, Entropy 226.7323455810547, Learning Rate: 0.01\n",
      "Epoch [3921/20000], Loss: 1028.71240234375, Entropy 228.89524841308594, Learning Rate: 0.01\n",
      "Epoch [3922/20000], Loss: 1040.5113525390625, Entropy 236.9774932861328, Learning Rate: 0.01\n",
      "Epoch [3923/20000], Loss: 1002.595458984375, Entropy 226.97157287597656, Learning Rate: 0.01\n",
      "Epoch [3924/20000], Loss: 1046.2508544921875, Entropy 231.31796264648438, Learning Rate: 0.01\n",
      "Epoch [3925/20000], Loss: 1024.0234375, Entropy 228.28463745117188, Learning Rate: 0.01\n",
      "Epoch [3926/20000], Loss: 998.1337890625, Entropy 243.5682373046875, Learning Rate: 0.01\n",
      "Epoch [3927/20000], Loss: 991.5485229492188, Entropy 225.3297576904297, Learning Rate: 0.01\n",
      "Epoch [3928/20000], Loss: 1025.307861328125, Entropy 223.4004669189453, Learning Rate: 0.01\n",
      "Epoch [3929/20000], Loss: 1009.5825805664062, Entropy 228.8210906982422, Learning Rate: 0.01\n",
      "Epoch [3930/20000], Loss: 990.2738647460938, Entropy 252.4015350341797, Learning Rate: 0.01\n",
      "Epoch [3931/20000], Loss: 980.20458984375, Entropy 244.17117309570312, Learning Rate: 0.01\n",
      "Epoch [3932/20000], Loss: 963.40478515625, Entropy 258.1337585449219, Learning Rate: 0.01\n",
      "Epoch [3933/20000], Loss: 1057.82275390625, Entropy 230.75054931640625, Learning Rate: 0.01\n",
      "Epoch [3934/20000], Loss: 1009.17578125, Entropy 250.85275268554688, Learning Rate: 0.01\n",
      "Epoch [3935/20000], Loss: 1046.3721923828125, Entropy 248.2864532470703, Learning Rate: 0.01\n",
      "Epoch [3936/20000], Loss: 1039.5869140625, Entropy 247.66714477539062, Learning Rate: 0.01\n",
      "Epoch [3937/20000], Loss: 1017.3336181640625, Entropy 244.81455993652344, Learning Rate: 0.01\n",
      "Epoch [3938/20000], Loss: 991.4635009765625, Entropy 241.64378356933594, Learning Rate: 0.01\n",
      "Epoch [3939/20000], Loss: 1039.6949462890625, Entropy 251.9324188232422, Learning Rate: 0.01\n",
      "Epoch [3940/20000], Loss: 993.2750244140625, Entropy 255.24339294433594, Learning Rate: 0.01\n",
      "Epoch [3941/20000], Loss: 985.190185546875, Entropy 238.24620056152344, Learning Rate: 0.01\n",
      "Epoch [3942/20000], Loss: 1030.455322265625, Entropy 232.4539337158203, Learning Rate: 0.01\n",
      "Epoch [3943/20000], Loss: 985.1349487304688, Entropy 239.6615753173828, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3944/20000], Loss: 1029.6026611328125, Entropy 241.75979614257812, Learning Rate: 0.01\n",
      "Epoch [3945/20000], Loss: 980.9968872070312, Entropy 241.30889892578125, Learning Rate: 0.01\n",
      "Epoch [3946/20000], Loss: 1075.914794921875, Entropy 240.97463989257812, Learning Rate: 0.01\n",
      "Epoch [3947/20000], Loss: 1007.1807250976562, Entropy 240.0834503173828, Learning Rate: 0.01\n",
      "Epoch [3948/20000], Loss: 1106.78759765625, Entropy 248.0639190673828, Learning Rate: 0.01\n",
      "Epoch [3949/20000], Loss: 1103.259521484375, Entropy 230.76007080078125, Learning Rate: 0.01\n",
      "Epoch [3950/20000], Loss: 988.0216064453125, Entropy 246.33035278320312, Learning Rate: 0.01\n",
      "Epoch [3951/20000], Loss: 1059.440673828125, Entropy 243.0970916748047, Learning Rate: 0.01\n",
      "Epoch [3952/20000], Loss: 1093.5140380859375, Entropy 239.1781463623047, Learning Rate: 0.01\n",
      "Epoch [3953/20000], Loss: 1036.6240234375, Entropy 239.75714111328125, Learning Rate: 0.01\n",
      "Epoch [3954/20000], Loss: 1051.2254638671875, Entropy 241.1221160888672, Learning Rate: 0.01\n",
      "Epoch [3955/20000], Loss: 1012.2987670898438, Entropy 245.9148712158203, Learning Rate: 0.01\n",
      "Epoch [3956/20000], Loss: 1090.0413818359375, Entropy 230.34835815429688, Learning Rate: 0.01\n",
      "Epoch [3957/20000], Loss: 1025.8797607421875, Entropy 239.586181640625, Learning Rate: 0.01\n",
      "Epoch [3958/20000], Loss: 964.01611328125, Entropy 243.54444885253906, Learning Rate: 0.01\n",
      "Epoch [3959/20000], Loss: 1014.0037231445312, Entropy 250.13909912109375, Learning Rate: 0.01\n",
      "Epoch [3960/20000], Loss: 999.2899169921875, Entropy 250.6385498046875, Learning Rate: 0.01\n",
      "Epoch [3961/20000], Loss: 1060.3515625, Entropy 235.90206909179688, Learning Rate: 0.01\n",
      "Epoch [3962/20000], Loss: 1007.7770385742188, Entropy 234.81329345703125, Learning Rate: 0.01\n",
      "Epoch [3963/20000], Loss: 1016.8714599609375, Entropy 244.696044921875, Learning Rate: 0.01\n",
      "Epoch [3964/20000], Loss: 985.2850341796875, Entropy 239.64749145507812, Learning Rate: 0.01\n",
      "Epoch [3965/20000], Loss: 951.6463623046875, Entropy 251.7412109375, Learning Rate: 0.01\n",
      "Epoch [3966/20000], Loss: 977.0293579101562, Entropy 248.0387420654297, Learning Rate: 0.01\n",
      "Epoch [3967/20000], Loss: 1000.9260864257812, Entropy 243.6394805908203, Learning Rate: 0.01\n",
      "Epoch [3968/20000], Loss: 1003.6984252929688, Entropy 236.1558380126953, Learning Rate: 0.01\n",
      "Epoch [3969/20000], Loss: 994.110107421875, Entropy 242.57423400878906, Learning Rate: 0.01\n",
      "Epoch [3970/20000], Loss: 978.0332641601562, Entropy 246.0567169189453, Learning Rate: 0.01\n",
      "Epoch [3971/20000], Loss: 1077.7032470703125, Entropy 241.2048797607422, Learning Rate: 0.01\n",
      "Epoch [3972/20000], Loss: 982.285400390625, Entropy 256.661376953125, Learning Rate: 0.01\n",
      "Epoch [3973/20000], Loss: 1016.2546997070312, Entropy 252.68768310546875, Learning Rate: 0.01\n",
      "Epoch [3974/20000], Loss: 1062.9373779296875, Entropy 248.84510803222656, Learning Rate: 0.01\n",
      "Epoch [3975/20000], Loss: 993.425048828125, Entropy 249.95999145507812, Learning Rate: 0.01\n",
      "Epoch [3976/20000], Loss: 1029.358642578125, Entropy 248.76629638671875, Learning Rate: 0.01\n",
      "Epoch [3977/20000], Loss: 1003.0926513671875, Entropy 258.8932800292969, Learning Rate: 0.01\n",
      "Epoch [3978/20000], Loss: 1035.5177001953125, Entropy 241.5046844482422, Learning Rate: 0.01\n",
      "Epoch [3979/20000], Loss: 1053.2669677734375, Entropy 248.27780151367188, Learning Rate: 0.01\n",
      "Epoch [3980/20000], Loss: 1008.6259155273438, Entropy 250.8865203857422, Learning Rate: 0.01\n",
      "Epoch [3981/20000], Loss: 1045.483154296875, Entropy 236.17495727539062, Learning Rate: 0.01\n",
      "Epoch [3982/20000], Loss: 1005.9736328125, Entropy 248.73606872558594, Learning Rate: 0.01\n",
      "Epoch [3983/20000], Loss: 1018.9833984375, Entropy 250.79701232910156, Learning Rate: 0.01\n",
      "Epoch [3984/20000], Loss: 956.2442016601562, Entropy 251.32855224609375, Learning Rate: 0.01\n",
      "Epoch [3985/20000], Loss: 973.86376953125, Entropy 257.7265930175781, Learning Rate: 0.01\n",
      "Epoch [3986/20000], Loss: 990.6353149414062, Entropy 255.9882354736328, Learning Rate: 0.01\n",
      "Epoch [3987/20000], Loss: 991.7653198242188, Entropy 253.20794677734375, Learning Rate: 0.01\n",
      "Epoch [3988/20000], Loss: 993.2141723632812, Entropy 254.97088623046875, Learning Rate: 0.01\n",
      "Epoch [3989/20000], Loss: 952.765380859375, Entropy 256.33154296875, Learning Rate: 0.01\n",
      "Epoch [3990/20000], Loss: 1004.906005859375, Entropy 241.972900390625, Learning Rate: 0.01\n",
      "Epoch [3991/20000], Loss: 978.5390014648438, Entropy 235.7123260498047, Learning Rate: 0.01\n",
      "Epoch [3992/20000], Loss: 991.5758666992188, Entropy 244.99847412109375, Learning Rate: 0.01\n",
      "Epoch [3993/20000], Loss: 967.1998291015625, Entropy 244.31503295898438, Learning Rate: 0.01\n",
      "Epoch [3994/20000], Loss: 998.1325073242188, Entropy 261.99578857421875, Learning Rate: 0.01\n",
      "Epoch [3995/20000], Loss: 1018.3380737304688, Entropy 256.58209228515625, Learning Rate: 0.01\n",
      "Epoch [3996/20000], Loss: 1027.2823486328125, Entropy 250.8769073486328, Learning Rate: 0.01\n",
      "Epoch [3997/20000], Loss: 961.6427001953125, Entropy 255.86817932128906, Learning Rate: 0.01\n",
      "Epoch [3998/20000], Loss: 987.3756103515625, Entropy 250.59754943847656, Learning Rate: 0.01\n",
      "Epoch [3999/20000], Loss: 1023.59130859375, Entropy 252.67823791503906, Learning Rate: 0.01\n",
      "Epoch [4000/20000], Loss: 987.1196899414062, Entropy 259.11358642578125, Learning Rate: 0.01\n",
      "Epoch [4001/20000], Loss: 1059.5833740234375, Entropy 246.420654296875, Learning Rate: 0.01\n",
      "Epoch [4002/20000], Loss: 1037.1446533203125, Entropy 265.1620788574219, Learning Rate: 0.01\n",
      "Epoch [4003/20000], Loss: 1031.048828125, Entropy 239.59176635742188, Learning Rate: 0.01\n",
      "Epoch [4004/20000], Loss: 1018.7625122070312, Entropy 248.9266815185547, Learning Rate: 0.01\n",
      "Epoch [4005/20000], Loss: 1057.5130615234375, Entropy 240.82986450195312, Learning Rate: 0.01\n",
      "Epoch [4006/20000], Loss: 996.39404296875, Entropy 232.76206970214844, Learning Rate: 0.01\n",
      "Epoch [4007/20000], Loss: 1026.649169921875, Entropy 247.9853057861328, Learning Rate: 0.01\n",
      "Epoch [4008/20000], Loss: 974.4532470703125, Entropy 258.31201171875, Learning Rate: 0.01\n",
      "Epoch [4009/20000], Loss: 1044.3216552734375, Entropy 249.8296661376953, Learning Rate: 0.01\n",
      "Epoch [4010/20000], Loss: 1009.449462890625, Entropy 259.0132141113281, Learning Rate: 0.01\n",
      "Epoch [4011/20000], Loss: 981.701904296875, Entropy 252.00253295898438, Learning Rate: 0.01\n",
      "Epoch [4012/20000], Loss: 973.3997802734375, Entropy 263.4792175292969, Learning Rate: 0.01\n",
      "Epoch [4013/20000], Loss: 965.5799560546875, Entropy 258.4358825683594, Learning Rate: 0.01\n",
      "Epoch [4014/20000], Loss: 1031.703369140625, Entropy 237.9145965576172, Learning Rate: 0.01\n",
      "Epoch [4015/20000], Loss: 992.47509765625, Entropy 244.791015625, Learning Rate: 0.01\n",
      "Epoch [4016/20000], Loss: 976.71533203125, Entropy 233.72496032714844, Learning Rate: 0.01\n",
      "Epoch [4017/20000], Loss: 996.9857177734375, Entropy 256.038818359375, Learning Rate: 0.01\n",
      "Epoch [4018/20000], Loss: 996.9343872070312, Entropy 245.3689727783203, Learning Rate: 0.01\n",
      "Epoch [4019/20000], Loss: 1025.9395751953125, Entropy 264.4158630371094, Learning Rate: 0.01\n",
      "Epoch [4020/20000], Loss: 975.036865234375, Entropy 248.02296447753906, Learning Rate: 0.01\n",
      "Epoch [4021/20000], Loss: 1069.37451171875, Entropy 265.5052795410156, Learning Rate: 0.01\n",
      "Epoch [4022/20000], Loss: 957.7626342773438, Entropy 261.95355224609375, Learning Rate: 0.01\n",
      "Epoch [4023/20000], Loss: 1015.0496826171875, Entropy 259.6959228515625, Learning Rate: 0.01\n",
      "Epoch [4024/20000], Loss: 989.1612548828125, Entropy 246.080810546875, Learning Rate: 0.01\n",
      "Epoch [4025/20000], Loss: 1017.371826171875, Entropy 245.96311950683594, Learning Rate: 0.01\n",
      "Epoch [4026/20000], Loss: 1034.3642578125, Entropy 250.01492309570312, Learning Rate: 0.01\n",
      "Epoch [4027/20000], Loss: 999.14306640625, Entropy 248.42002868652344, Learning Rate: 0.01\n",
      "Epoch [4028/20000], Loss: 1008.3485717773438, Entropy 253.8403778076172, Learning Rate: 0.01\n",
      "Epoch [4029/20000], Loss: 994.3035888671875, Entropy 244.66647338867188, Learning Rate: 0.01\n",
      "Epoch [4030/20000], Loss: 1093.1212158203125, Entropy 261.3547668457031, Learning Rate: 0.01\n",
      "Epoch [4031/20000], Loss: 1034.305419921875, Entropy 266.9322204589844, Learning Rate: 0.01\n",
      "Epoch [4032/20000], Loss: 1043.086181640625, Entropy 259.3791198730469, Learning Rate: 0.01\n",
      "Epoch [4033/20000], Loss: 978.0552978515625, Entropy 276.29931640625, Learning Rate: 0.01\n",
      "Epoch [4034/20000], Loss: 1035.993408203125, Entropy 264.0417175292969, Learning Rate: 0.01\n",
      "Epoch [4035/20000], Loss: 956.375, Entropy 256.1462097167969, Learning Rate: 0.01\n",
      "Epoch [4036/20000], Loss: 1100.02978515625, Entropy 255.76165771484375, Learning Rate: 0.01\n",
      "Epoch [4037/20000], Loss: 1054.877197265625, Entropy 257.1352233886719, Learning Rate: 0.01\n",
      "Epoch [4038/20000], Loss: 1020.7919921875, Entropy 266.3327941894531, Learning Rate: 0.01\n",
      "Epoch [4039/20000], Loss: 972.947265625, Entropy 265.7529602050781, Learning Rate: 0.01\n",
      "Epoch [4040/20000], Loss: 1025.5830078125, Entropy 266.8885192871094, Learning Rate: 0.01\n",
      "Epoch [4041/20000], Loss: 1016.5783081054688, Entropy 265.97576904296875, Learning Rate: 0.01\n",
      "Epoch [4042/20000], Loss: 1104.83251953125, Entropy 252.38987731933594, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4043/20000], Loss: 1006.0797119140625, Entropy 261.5619201660156, Learning Rate: 0.01\n",
      "Epoch [4044/20000], Loss: 1145.519775390625, Entropy 264.10992431640625, Learning Rate: 0.01\n",
      "Epoch [4045/20000], Loss: 1006.69921875, Entropy 266.1002197265625, Learning Rate: 0.01\n",
      "Epoch [4046/20000], Loss: 1176.7542724609375, Entropy 266.6394348144531, Learning Rate: 0.01\n",
      "Epoch [4047/20000], Loss: 1227.5716552734375, Entropy 259.6433410644531, Learning Rate: 0.01\n",
      "Epoch [4048/20000], Loss: 1058.0172119140625, Entropy 258.5574645996094, Learning Rate: 0.01\n",
      "Epoch [4049/20000], Loss: 1378.9798583984375, Entropy 262.2550964355469, Learning Rate: 0.01\n",
      "Epoch [4050/20000], Loss: 1330.2607421875, Entropy 240.94015502929688, Learning Rate: 0.01\n",
      "Epoch [4051/20000], Loss: 1183.4342041015625, Entropy 243.95643615722656, Learning Rate: 0.01\n",
      "Epoch [4052/20000], Loss: 1506.0438232421875, Entropy 256.5379943847656, Learning Rate: 0.01\n",
      "Epoch [4053/20000], Loss: 1298.5057373046875, Entropy 262.5966491699219, Learning Rate: 0.01\n",
      "Epoch [4054/20000], Loss: 1374.861083984375, Entropy 251.6717071533203, Learning Rate: 0.01\n",
      "Epoch [4055/20000], Loss: 1293.5159912109375, Entropy 236.1910858154297, Learning Rate: 0.01\n",
      "Epoch [4056/20000], Loss: 1480.02490234375, Entropy 267.9203796386719, Learning Rate: 0.01\n",
      "Epoch [4057/20000], Loss: 1261.0491943359375, Entropy 241.99452209472656, Learning Rate: 0.01\n",
      "Epoch [4058/20000], Loss: 1432.562744140625, Entropy 253.91378784179688, Learning Rate: 0.01\n",
      "Epoch [4059/20000], Loss: 1576.9256591796875, Entropy 243.9227752685547, Learning Rate: 0.01\n",
      "Epoch [4060/20000], Loss: 1538.4881591796875, Entropy 234.90306091308594, Learning Rate: 0.01\n",
      "Epoch [4061/20000], Loss: 1645.8035888671875, Entropy 243.7771453857422, Learning Rate: 0.01\n",
      "Epoch [4062/20000], Loss: 1845.7822265625, Entropy 246.49484252929688, Learning Rate: 0.01\n",
      "Epoch [4063/20000], Loss: 1229.496826171875, Entropy 230.5194091796875, Learning Rate: 0.01\n",
      "Epoch [4064/20000], Loss: 1623.2825927734375, Entropy 236.45913696289062, Learning Rate: 0.01\n",
      "Epoch [4065/20000], Loss: 1342.9755859375, Entropy 228.8171844482422, Learning Rate: 0.01\n",
      "Epoch [4066/20000], Loss: 1646.0509033203125, Entropy 232.64552307128906, Learning Rate: 0.01\n",
      "Epoch [4067/20000], Loss: 1565.9879150390625, Entropy 233.0066680908203, Learning Rate: 0.01\n",
      "Epoch [4068/20000], Loss: 1352.5606689453125, Entropy 221.70657348632812, Learning Rate: 0.01\n",
      "Epoch [4069/20000], Loss: 2098.3037109375, Entropy 212.8223419189453, Learning Rate: 0.01\n",
      "Epoch [4070/20000], Loss: 1659.2508544921875, Entropy 210.50564575195312, Learning Rate: 0.01\n",
      "Epoch [4071/20000], Loss: 2089.126708984375, Entropy 199.05616760253906, Learning Rate: 0.01\n",
      "Epoch [4072/20000], Loss: 2032.581787109375, Entropy 221.77413940429688, Learning Rate: 0.01\n",
      "Epoch [4073/20000], Loss: 1609.005615234375, Entropy 205.33616638183594, Learning Rate: 0.01\n",
      "Epoch [4074/20000], Loss: 3053.6005859375, Entropy 199.4877166748047, Learning Rate: 0.01\n",
      "Epoch [4075/20000], Loss: 1930.226806640625, Entropy 197.78761291503906, Learning Rate: 0.01\n",
      "Epoch [4076/20000], Loss: 1846.11865234375, Entropy 189.87936401367188, Learning Rate: 0.01\n",
      "Epoch [4077/20000], Loss: 2230.561279296875, Entropy 175.11077880859375, Learning Rate: 0.01\n",
      "Epoch [4078/20000], Loss: 1836.3104248046875, Entropy 167.8793182373047, Learning Rate: 0.01\n",
      "Epoch [4079/20000], Loss: 1374.9312744140625, Entropy 158.46998596191406, Learning Rate: 0.01\n",
      "Epoch [4080/20000], Loss: 1667.3748779296875, Entropy 157.941162109375, Learning Rate: 0.01\n",
      "Epoch [4081/20000], Loss: 1806.467529296875, Entropy 161.8433837890625, Learning Rate: 0.01\n",
      "Epoch [4082/20000], Loss: 1741.3839111328125, Entropy 149.23777770996094, Learning Rate: 0.01\n",
      "Epoch [4083/20000], Loss: 1862.1571044921875, Entropy 140.97311401367188, Learning Rate: 0.01\n",
      "Epoch [4084/20000], Loss: 1422.0516357421875, Entropy 149.5923614501953, Learning Rate: 0.01\n",
      "Epoch [4085/20000], Loss: 1243.365478515625, Entropy 136.3803253173828, Learning Rate: 0.01\n",
      "Epoch [4086/20000], Loss: 1507.2608642578125, Entropy 125.689208984375, Learning Rate: 0.01\n",
      "Epoch [4087/20000], Loss: 1421.5792236328125, Entropy 116.32359313964844, Learning Rate: 0.01\n",
      "Epoch [4088/20000], Loss: 1347.6837158203125, Entropy 103.98468780517578, Learning Rate: 0.01\n",
      "Epoch [4089/20000], Loss: 1185.0977783203125, Entropy 120.92569732666016, Learning Rate: 0.01\n",
      "Epoch [4090/20000], Loss: 1249.170654296875, Entropy 115.79510498046875, Learning Rate: 0.01\n",
      "Epoch [4091/20000], Loss: 1243.490966796875, Entropy 111.21126556396484, Learning Rate: 0.01\n",
      "Epoch [4092/20000], Loss: 1242.3682861328125, Entropy 109.46428680419922, Learning Rate: 0.01\n",
      "Epoch [4093/20000], Loss: 1252.615966796875, Entropy 95.24125671386719, Learning Rate: 0.01\n",
      "Epoch [4094/20000], Loss: 1306.2093505859375, Entropy 98.47900390625, Learning Rate: 0.01\n",
      "Epoch [4095/20000], Loss: 1234.0521240234375, Entropy 96.44449615478516, Learning Rate: 0.01\n",
      "Epoch [4096/20000], Loss: 1159.225830078125, Entropy 107.478271484375, Learning Rate: 0.01\n",
      "Epoch [4097/20000], Loss: 1162.8408203125, Entropy 99.07789611816406, Learning Rate: 0.01\n",
      "Epoch [4098/20000], Loss: 1142.497314453125, Entropy 100.62545013427734, Learning Rate: 0.01\n",
      "Epoch [4099/20000], Loss: 1187.912841796875, Entropy 96.65050506591797, Learning Rate: 0.01\n",
      "Epoch [4100/20000], Loss: 1207.6318359375, Entropy 105.79579162597656, Learning Rate: 0.01\n",
      "Epoch [4101/20000], Loss: 1207.18505859375, Entropy 87.66912078857422, Learning Rate: 0.01\n",
      "Epoch [4102/20000], Loss: 1127.764404296875, Entropy 95.24515533447266, Learning Rate: 0.01\n",
      "Epoch [4103/20000], Loss: 1126.9033203125, Entropy 81.27874755859375, Learning Rate: 0.01\n",
      "Epoch [4104/20000], Loss: 1106.46240234375, Entropy 95.38633728027344, Learning Rate: 0.01\n",
      "Epoch [4105/20000], Loss: 1203.967041015625, Entropy 88.26998901367188, Learning Rate: 0.01\n",
      "Epoch [4106/20000], Loss: 1181.39306640625, Entropy 94.41160583496094, Learning Rate: 0.01\n",
      "Epoch [4107/20000], Loss: 1153.096435546875, Entropy 80.6866455078125, Learning Rate: 0.01\n",
      "Epoch [4108/20000], Loss: 1142.3548583984375, Entropy 94.55738067626953, Learning Rate: 0.01\n",
      "Epoch [4109/20000], Loss: 1090.4327392578125, Entropy 99.49613189697266, Learning Rate: 0.01\n",
      "Epoch [4110/20000], Loss: 1124.3636474609375, Entropy 99.14545440673828, Learning Rate: 0.01\n",
      "Epoch [4111/20000], Loss: 1130.63232421875, Entropy 83.34529876708984, Learning Rate: 0.01\n",
      "Epoch [4112/20000], Loss: 1145.22802734375, Entropy 100.4599380493164, Learning Rate: 0.01\n",
      "Epoch [4113/20000], Loss: 1096.5611572265625, Entropy 101.52599334716797, Learning Rate: 0.01\n",
      "Epoch [4114/20000], Loss: 1098.432373046875, Entropy 97.10831451416016, Learning Rate: 0.01\n",
      "Epoch [4115/20000], Loss: 1092.2041015625, Entropy 96.56380462646484, Learning Rate: 0.01\n",
      "Epoch [4116/20000], Loss: 1137.8056640625, Entropy 76.7168960571289, Learning Rate: 0.01\n",
      "Epoch [4117/20000], Loss: 1108.4267578125, Entropy 98.66246032714844, Learning Rate: 0.01\n",
      "Epoch [4118/20000], Loss: 1121.220947265625, Entropy 99.68701171875, Learning Rate: 0.01\n",
      "Epoch [4119/20000], Loss: 1090.4254150390625, Entropy 100.42554473876953, Learning Rate: 0.01\n",
      "Epoch [4120/20000], Loss: 1137.815185546875, Entropy 109.57222747802734, Learning Rate: 0.01\n",
      "Epoch [4121/20000], Loss: 1072.727783203125, Entropy 103.20763397216797, Learning Rate: 0.01\n",
      "Epoch [4122/20000], Loss: 1112.8170166015625, Entropy 96.8226089477539, Learning Rate: 0.01\n",
      "Epoch [4123/20000], Loss: 1100.291015625, Entropy 120.09344482421875, Learning Rate: 0.01\n",
      "Epoch [4124/20000], Loss: 1118.2550048828125, Entropy 101.7957763671875, Learning Rate: 0.01\n",
      "Epoch [4125/20000], Loss: 1066.6988525390625, Entropy 112.88844299316406, Learning Rate: 0.01\n",
      "Epoch [4126/20000], Loss: 1070.3865966796875, Entropy 104.94479370117188, Learning Rate: 0.01\n",
      "Epoch [4127/20000], Loss: 1086.693603515625, Entropy 106.3530044555664, Learning Rate: 0.01\n",
      "Epoch [4128/20000], Loss: 1082.0987548828125, Entropy 101.55476379394531, Learning Rate: 0.01\n",
      "Epoch [4129/20000], Loss: 1086.8720703125, Entropy 102.04584503173828, Learning Rate: 0.01\n",
      "Epoch [4130/20000], Loss: 1066.7657470703125, Entropy 119.06982421875, Learning Rate: 0.01\n",
      "Epoch [4131/20000], Loss: 1082.1038818359375, Entropy 105.21244049072266, Learning Rate: 0.01\n",
      "Epoch [4132/20000], Loss: 1071.19140625, Entropy 119.41587829589844, Learning Rate: 0.01\n",
      "Epoch [4133/20000], Loss: 1082.5853271484375, Entropy 131.3669891357422, Learning Rate: 0.01\n",
      "Epoch [4134/20000], Loss: 1070.1990966796875, Entropy 108.20323944091797, Learning Rate: 0.01\n",
      "Epoch [4135/20000], Loss: 1084.9603271484375, Entropy 107.87451171875, Learning Rate: 0.01\n",
      "Epoch [4136/20000], Loss: 1067.9814453125, Entropy 130.49644470214844, Learning Rate: 0.01\n",
      "Epoch [4137/20000], Loss: 1067.2406005859375, Entropy 115.83309936523438, Learning Rate: 0.01\n",
      "Epoch [4138/20000], Loss: 1045.980224609375, Entropy 121.48677825927734, Learning Rate: 0.01\n",
      "Epoch [4139/20000], Loss: 1071.13232421875, Entropy 115.26410675048828, Learning Rate: 0.01\n",
      "Epoch [4140/20000], Loss: 1065.164306640625, Entropy 132.62611389160156, Learning Rate: 0.01\n",
      "Epoch [4141/20000], Loss: 1064.0252685546875, Entropy 119.32310485839844, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4142/20000], Loss: 1081.562255859375, Entropy 118.40657806396484, Learning Rate: 0.01\n",
      "Epoch [4143/20000], Loss: 1041.702880859375, Entropy 121.96502685546875, Learning Rate: 0.01\n",
      "Epoch [4144/20000], Loss: 1085.825927734375, Entropy 125.2690658569336, Learning Rate: 0.01\n",
      "Epoch [4145/20000], Loss: 1032.575439453125, Entropy 135.34751892089844, Learning Rate: 0.01\n",
      "Epoch [4146/20000], Loss: 1034.65234375, Entropy 136.24339294433594, Learning Rate: 0.01\n",
      "Epoch [4147/20000], Loss: 1043.691650390625, Entropy 130.8989715576172, Learning Rate: 0.01\n",
      "Epoch [4148/20000], Loss: 1041.258056640625, Entropy 147.50323486328125, Learning Rate: 0.01\n",
      "Epoch [4149/20000], Loss: 1053.345703125, Entropy 128.72860717773438, Learning Rate: 0.01\n",
      "Epoch [4150/20000], Loss: 1053.478271484375, Entropy 136.89451599121094, Learning Rate: 0.01\n",
      "Epoch [4151/20000], Loss: 1052.81787109375, Entropy 132.94317626953125, Learning Rate: 0.01\n",
      "Epoch [4152/20000], Loss: 1036.8001708984375, Entropy 135.20040893554688, Learning Rate: 0.01\n",
      "Epoch [4153/20000], Loss: 1068.5750732421875, Entropy 132.30064392089844, Learning Rate: 0.01\n",
      "Epoch [4154/20000], Loss: 1041.9892578125, Entropy 139.95816040039062, Learning Rate: 0.01\n",
      "Epoch [4155/20000], Loss: 1028.6673583984375, Entropy 145.06309509277344, Learning Rate: 0.01\n",
      "Epoch [4156/20000], Loss: 1055.427978515625, Entropy 140.10877990722656, Learning Rate: 0.01\n",
      "Epoch [4157/20000], Loss: 1054.181396484375, Entropy 139.30810546875, Learning Rate: 0.01\n",
      "Epoch [4158/20000], Loss: 1054.935302734375, Entropy 134.9403076171875, Learning Rate: 0.01\n",
      "Epoch [4159/20000], Loss: 1041.1849365234375, Entropy 139.04061889648438, Learning Rate: 0.01\n",
      "Epoch [4160/20000], Loss: 1040.798095703125, Entropy 146.3649444580078, Learning Rate: 0.01\n",
      "Epoch [4161/20000], Loss: 1048.762939453125, Entropy 144.39610290527344, Learning Rate: 0.01\n",
      "Epoch [4162/20000], Loss: 1036.3023681640625, Entropy 143.61367797851562, Learning Rate: 0.01\n",
      "Epoch [4163/20000], Loss: 1031.427734375, Entropy 148.88368225097656, Learning Rate: 0.01\n",
      "Epoch [4164/20000], Loss: 1033.1690673828125, Entropy 140.6124725341797, Learning Rate: 0.01\n",
      "Epoch [4165/20000], Loss: 1015.9014892578125, Entropy 156.47265625, Learning Rate: 0.01\n",
      "Epoch [4166/20000], Loss: 1034.5823974609375, Entropy 149.1522216796875, Learning Rate: 0.01\n",
      "Epoch [4167/20000], Loss: 1054.74072265625, Entropy 148.40554809570312, Learning Rate: 0.01\n",
      "Epoch [4168/20000], Loss: 1025.586181640625, Entropy 168.21371459960938, Learning Rate: 0.01\n",
      "Epoch [4169/20000], Loss: 1028.32177734375, Entropy 156.37417602539062, Learning Rate: 0.01\n",
      "Epoch [4170/20000], Loss: 1054.87841796875, Entropy 159.87796020507812, Learning Rate: 0.01\n",
      "Epoch [4171/20000], Loss: 1024.912353515625, Entropy 167.89242553710938, Learning Rate: 0.01\n",
      "Epoch [4172/20000], Loss: 1030.964111328125, Entropy 161.989013671875, Learning Rate: 0.01\n",
      "Epoch [4173/20000], Loss: 1013.9342041015625, Entropy 157.92857360839844, Learning Rate: 0.01\n",
      "Epoch [4174/20000], Loss: 1050.7681884765625, Entropy 159.28672790527344, Learning Rate: 0.01\n",
      "Epoch [4175/20000], Loss: 1060.048828125, Entropy 158.79368591308594, Learning Rate: 0.01\n",
      "Epoch [4176/20000], Loss: 1025.234619140625, Entropy 155.82395935058594, Learning Rate: 0.01\n",
      "Epoch [4177/20000], Loss: 1053.2900390625, Entropy 162.86708068847656, Learning Rate: 0.01\n",
      "Epoch [4178/20000], Loss: 1016.90576171875, Entropy 163.65794372558594, Learning Rate: 0.01\n",
      "Epoch [4179/20000], Loss: 1022.7459106445312, Entropy 175.56536865234375, Learning Rate: 0.01\n",
      "Epoch [4180/20000], Loss: 1047.796875, Entropy 154.75003051757812, Learning Rate: 0.01\n",
      "Epoch [4181/20000], Loss: 1038.9569091796875, Entropy 169.8830108642578, Learning Rate: 0.01\n",
      "Epoch [4182/20000], Loss: 1015.9268798828125, Entropy 166.68226623535156, Learning Rate: 0.01\n",
      "Epoch [4183/20000], Loss: 999.92578125, Entropy 176.59873962402344, Learning Rate: 0.01\n",
      "Epoch [4184/20000], Loss: 1025.98388671875, Entropy 161.32469177246094, Learning Rate: 0.01\n",
      "Epoch [4185/20000], Loss: 993.240966796875, Entropy 188.766357421875, Learning Rate: 0.01\n",
      "Epoch [4186/20000], Loss: 1015.3392333984375, Entropy 166.24136352539062, Learning Rate: 0.01\n",
      "Epoch [4187/20000], Loss: 1007.0789794921875, Entropy 168.07847595214844, Learning Rate: 0.01\n",
      "Epoch [4188/20000], Loss: 984.0071411132812, Entropy 175.57403564453125, Learning Rate: 0.01\n",
      "Epoch [4189/20000], Loss: 1041.76123046875, Entropy 169.76780700683594, Learning Rate: 0.01\n",
      "Epoch [4190/20000], Loss: 1004.397216796875, Entropy 185.41615295410156, Learning Rate: 0.01\n",
      "Epoch [4191/20000], Loss: 994.274169921875, Entropy 187.684326171875, Learning Rate: 0.01\n",
      "Epoch [4192/20000], Loss: 1007.1815185546875, Entropy 163.20188903808594, Learning Rate: 0.01\n",
      "Epoch [4193/20000], Loss: 1027.719970703125, Entropy 181.8546905517578, Learning Rate: 0.01\n",
      "Epoch [4194/20000], Loss: 1049.188232421875, Entropy 159.08721923828125, Learning Rate: 0.01\n",
      "Epoch [4195/20000], Loss: 1020.0393676757812, Entropy 177.1667938232422, Learning Rate: 0.01\n",
      "Epoch [4196/20000], Loss: 1002.1207885742188, Entropy 183.9575958251953, Learning Rate: 0.01\n",
      "Epoch [4197/20000], Loss: 993.7069702148438, Entropy 186.2256622314453, Learning Rate: 0.01\n",
      "Epoch [4198/20000], Loss: 995.0206298828125, Entropy 184.19273376464844, Learning Rate: 0.01\n",
      "Epoch [4199/20000], Loss: 1003.3741455078125, Entropy 188.50819396972656, Learning Rate: 0.01\n",
      "Epoch [4200/20000], Loss: 1022.1258544921875, Entropy 173.37680053710938, Learning Rate: 0.01\n",
      "Epoch [4201/20000], Loss: 1010.1764526367188, Entropy 203.8717498779297, Learning Rate: 0.01\n",
      "Epoch [4202/20000], Loss: 994.8751220703125, Entropy 197.34432983398438, Learning Rate: 0.01\n",
      "Epoch [4203/20000], Loss: 976.251220703125, Entropy 211.9295654296875, Learning Rate: 0.01\n",
      "Epoch [4204/20000], Loss: 980.0078125, Entropy 202.11489868164062, Learning Rate: 0.01\n",
      "Epoch [4205/20000], Loss: 985.909423828125, Entropy 186.37600708007812, Learning Rate: 0.01\n",
      "Epoch [4206/20000], Loss: 979.611572265625, Entropy 201.697265625, Learning Rate: 0.01\n",
      "Epoch [4207/20000], Loss: 1008.5059814453125, Entropy 193.45901489257812, Learning Rate: 0.01\n",
      "Epoch [4208/20000], Loss: 993.578857421875, Entropy 202.01492309570312, Learning Rate: 0.01\n",
      "Epoch [4209/20000], Loss: 988.1578369140625, Entropy 203.80099487304688, Learning Rate: 0.01\n",
      "Epoch [4210/20000], Loss: 1010.526123046875, Entropy 196.61587524414062, Learning Rate: 0.01\n",
      "Epoch [4211/20000], Loss: 1004.5459594726562, Entropy 203.1493377685547, Learning Rate: 0.01\n",
      "Epoch [4212/20000], Loss: 968.7923583984375, Entropy 209.84092712402344, Learning Rate: 0.01\n",
      "Epoch [4213/20000], Loss: 1020.551513671875, Entropy 193.837646484375, Learning Rate: 0.01\n",
      "Epoch [4214/20000], Loss: 984.6563720703125, Entropy 202.2069091796875, Learning Rate: 0.01\n",
      "Epoch [4215/20000], Loss: 989.0643920898438, Entropy 216.7468719482422, Learning Rate: 0.01\n",
      "Epoch [4216/20000], Loss: 1001.96240234375, Entropy 202.26026916503906, Learning Rate: 0.01\n",
      "Epoch [4217/20000], Loss: 1012.922119140625, Entropy 193.90074157714844, Learning Rate: 0.01\n",
      "Epoch [4218/20000], Loss: 991.4546508789062, Entropy 214.84442138671875, Learning Rate: 0.01\n",
      "Epoch [4219/20000], Loss: 999.9248046875, Entropy 212.4139404296875, Learning Rate: 0.01\n",
      "Epoch [4220/20000], Loss: 1014.3582153320312, Entropy 216.71405029296875, Learning Rate: 0.01\n",
      "Epoch [4221/20000], Loss: 1001.3610229492188, Entropy 206.2881622314453, Learning Rate: 0.01\n",
      "Epoch [4222/20000], Loss: 996.6921997070312, Entropy 207.9122772216797, Learning Rate: 0.01\n",
      "Epoch [4223/20000], Loss: 1017.1738891601562, Entropy 197.92767333984375, Learning Rate: 0.01\n",
      "Epoch [4224/20000], Loss: 1037.962158203125, Entropy 208.7166748046875, Learning Rate: 0.01\n",
      "Epoch [4225/20000], Loss: 992.862060546875, Entropy 206.98733520507812, Learning Rate: 0.01\n",
      "Epoch [4226/20000], Loss: 986.556396484375, Entropy 214.88046264648438, Learning Rate: 0.01\n",
      "Epoch [4227/20000], Loss: 1018.9464721679688, Entropy 200.4469757080078, Learning Rate: 0.01\n",
      "Epoch [4228/20000], Loss: 1004.8621826171875, Entropy 198.64146423339844, Learning Rate: 0.01\n",
      "Epoch [4229/20000], Loss: 998.0186157226562, Entropy 216.0927276611328, Learning Rate: 0.01\n",
      "Epoch [4230/20000], Loss: 1012.27001953125, Entropy 202.1898193359375, Learning Rate: 0.01\n",
      "Epoch [4231/20000], Loss: 995.8931274414062, Entropy 228.6609649658203, Learning Rate: 0.01\n",
      "Epoch [4232/20000], Loss: 1008.4401245117188, Entropy 226.15838623046875, Learning Rate: 0.01\n",
      "Epoch [4233/20000], Loss: 966.989013671875, Entropy 230.54690551757812, Learning Rate: 0.01\n",
      "Epoch [4234/20000], Loss: 995.4423217773438, Entropy 220.7438201904297, Learning Rate: 0.01\n",
      "Epoch [4235/20000], Loss: 990.3162841796875, Entropy 214.99636840820312, Learning Rate: 0.01\n",
      "Epoch [4236/20000], Loss: 999.2049560546875, Entropy 220.96327209472656, Learning Rate: 0.01\n",
      "Epoch [4237/20000], Loss: 972.3310546875, Entropy 222.47900390625, Learning Rate: 0.01\n",
      "Epoch [4238/20000], Loss: 982.2510986328125, Entropy 229.73947143554688, Learning Rate: 0.01\n",
      "Epoch [4239/20000], Loss: 997.4862670898438, Entropy 218.2334747314453, Learning Rate: 0.01\n",
      "Epoch [4240/20000], Loss: 988.6759033203125, Entropy 217.10379028320312, Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4241/20000], Loss: 989.6234741210938, Entropy 228.12847900390625, Learning Rate: 0.01\n",
      "Epoch [4242/20000], Loss: 967.9984741210938, Entropy 224.2696075439453, Learning Rate: 0.01\n",
      "Epoch [4243/20000], Loss: 1027.436279296875, Entropy 213.30300903320312, Learning Rate: 0.01\n",
      "Epoch [4244/20000], Loss: 994.3515014648438, Entropy 226.7056427001953, Learning Rate: 0.01\n",
      "Epoch [4245/20000], Loss: 1001.0838012695312, Entropy 231.0458526611328, Learning Rate: 0.01\n",
      "Epoch [4246/20000], Loss: 956.0646362304688, Entropy 235.5877227783203, Learning Rate: 0.01\n",
      "Epoch [4247/20000], Loss: 1020.8707885742188, Entropy 222.8058319091797, Learning Rate: 0.01\n",
      "Epoch [4248/20000], Loss: 981.828857421875, Entropy 229.60354614257812, Learning Rate: 0.005\n",
      "Epoch [4249/20000], Loss: 972.6473388671875, Entropy 228.33937072753906, Learning Rate: 0.005\n",
      "Epoch [4250/20000], Loss: 979.832275390625, Entropy 233.6668701171875, Learning Rate: 0.005\n",
      "Epoch [4251/20000], Loss: 1015.1201782226562, Entropy 227.3335723876953, Learning Rate: 0.005\n",
      "Epoch [4252/20000], Loss: 988.5299072265625, Entropy 230.520263671875, Learning Rate: 0.005\n",
      "Epoch [4253/20000], Loss: 982.0875244140625, Entropy 224.96847534179688, Learning Rate: 0.005\n",
      "Epoch [4254/20000], Loss: 989.8389892578125, Entropy 227.36581420898438, Learning Rate: 0.005\n",
      "Epoch [4255/20000], Loss: 1020.0000610351562, Entropy 218.59979248046875, Learning Rate: 0.005\n",
      "Epoch [4256/20000], Loss: 969.6411743164062, Entropy 238.0806121826172, Learning Rate: 0.005\n",
      "Epoch [4257/20000], Loss: 1005.89794921875, Entropy 228.18980407714844, Learning Rate: 0.005\n",
      "Epoch [4258/20000], Loss: 1009.5274658203125, Entropy 221.19412231445312, Learning Rate: 0.005\n",
      "Epoch [4259/20000], Loss: 967.7312622070312, Entropy 236.6014862060547, Learning Rate: 0.005\n",
      "Epoch [4260/20000], Loss: 974.95068359375, Entropy 240.1048583984375, Learning Rate: 0.005\n",
      "Epoch [4261/20000], Loss: 999.1773681640625, Entropy 237.51370239257812, Learning Rate: 0.005\n",
      "Epoch [4262/20000], Loss: 977.99267578125, Entropy 249.93362426757812, Learning Rate: 0.005\n",
      "Epoch [4263/20000], Loss: 962.964111328125, Entropy 248.789794921875, Learning Rate: 0.005\n",
      "Epoch [4264/20000], Loss: 1053.749267578125, Entropy 219.3802947998047, Learning Rate: 0.005\n",
      "Epoch [4265/20000], Loss: 976.0399169921875, Entropy 226.91163635253906, Learning Rate: 0.005\n",
      "Epoch [4266/20000], Loss: 1003.606201171875, Entropy 232.79049682617188, Learning Rate: 0.005\n",
      "Epoch [4267/20000], Loss: 1003.359130859375, Entropy 218.31163024902344, Learning Rate: 0.005\n",
      "Epoch [4268/20000], Loss: 982.4873046875, Entropy 250.85997009277344, Learning Rate: 0.005\n",
      "Epoch [4269/20000], Loss: 985.3366088867188, Entropy 235.7403106689453, Learning Rate: 0.005\n",
      "Epoch [4270/20000], Loss: 988.225830078125, Entropy 236.02491760253906, Learning Rate: 0.005\n",
      "Epoch [4271/20000], Loss: 967.7134399414062, Entropy 237.8686065673828, Learning Rate: 0.005\n",
      "Epoch [4272/20000], Loss: 983.7731323242188, Entropy 242.0221405029297, Learning Rate: 0.005\n",
      "Epoch [4273/20000], Loss: 996.4501342773438, Entropy 233.0154571533203, Learning Rate: 0.005\n",
      "Epoch [4274/20000], Loss: 978.2595825195312, Entropy 235.0462188720703, Learning Rate: 0.005\n",
      "Epoch [4275/20000], Loss: 984.9364013671875, Entropy 233.57907104492188, Learning Rate: 0.005\n",
      "Epoch [4276/20000], Loss: 1013.7284545898438, Entropy 227.6239776611328, Learning Rate: 0.005\n",
      "Epoch [4277/20000], Loss: 1010.8343505859375, Entropy 244.227783203125, Learning Rate: 0.005\n",
      "Epoch [4278/20000], Loss: 1008.710693359375, Entropy 238.17796325683594, Learning Rate: 0.005\n",
      "Epoch [4279/20000], Loss: 986.982177734375, Entropy 241.12939453125, Learning Rate: 0.005\n",
      "Epoch [4280/20000], Loss: 1014.5986938476562, Entropy 220.09222412109375, Learning Rate: 0.005\n",
      "Epoch [4281/20000], Loss: 966.27734375, Entropy 226.11239624023438, Learning Rate: 0.005\n",
      "Epoch [4282/20000], Loss: 980.9588012695312, Entropy 240.04034423828125, Learning Rate: 0.005\n",
      "Epoch [4283/20000], Loss: 975.254150390625, Entropy 239.11257934570312, Learning Rate: 0.005\n",
      "Epoch [4284/20000], Loss: 959.3831787109375, Entropy 253.35169982910156, Learning Rate: 0.005\n",
      "Epoch [4285/20000], Loss: 987.4796142578125, Entropy 251.74473571777344, Learning Rate: 0.005\n",
      "Epoch [4286/20000], Loss: 977.4220581054688, Entropy 243.4069061279297, Learning Rate: 0.005\n",
      "Epoch [4287/20000], Loss: 983.9618530273438, Entropy 235.3355255126953, Learning Rate: 0.005\n",
      "Epoch [4288/20000], Loss: 991.23681640625, Entropy 231.92721557617188, Learning Rate: 0.005\n",
      "Epoch [4289/20000], Loss: 1002.7615966796875, Entropy 235.65296936035156, Learning Rate: 0.005\n",
      "Epoch [4290/20000], Loss: 964.9669799804688, Entropy 231.4141387939453, Learning Rate: 0.005\n",
      "Epoch [4291/20000], Loss: 1017.86865234375, Entropy 222.22476196289062, Learning Rate: 0.005\n",
      "Epoch [4292/20000], Loss: 984.5270385742188, Entropy 234.7184295654297, Learning Rate: 0.005\n",
      "Epoch [4293/20000], Loss: 990.5479125976562, Entropy 245.3751678466797, Learning Rate: 0.005\n",
      "Epoch [4294/20000], Loss: 977.490234375, Entropy 241.18515014648438, Learning Rate: 0.005\n",
      "Epoch [4295/20000], Loss: 969.6395874023438, Entropy 249.9744415283203, Learning Rate: 0.005\n",
      "Epoch [4296/20000], Loss: 970.8436279296875, Entropy 244.7596435546875, Learning Rate: 0.005\n",
      "Epoch [4297/20000], Loss: 972.7941284179688, Entropy 244.9336700439453, Learning Rate: 0.005\n",
      "Epoch [4298/20000], Loss: 1001.44580078125, Entropy 229.059326171875, Learning Rate: 0.005\n",
      "Epoch [4299/20000], Loss: 979.3952026367188, Entropy 233.8252410888672, Learning Rate: 0.005\n",
      "Epoch [4300/20000], Loss: 1001.0153198242188, Entropy 242.83929443359375, Learning Rate: 0.005\n",
      "Epoch [4301/20000], Loss: 1010.0426635742188, Entropy 249.56170654296875, Learning Rate: 0.005\n",
      "Epoch [4302/20000], Loss: 963.9432983398438, Entropy 229.7476348876953, Learning Rate: 0.005\n",
      "Epoch [4303/20000], Loss: 944.8411865234375, Entropy 241.78041076660156, Learning Rate: 0.005\n",
      "Epoch [4304/20000], Loss: 969.8944091796875, Entropy 248.34886169433594, Learning Rate: 0.005\n",
      "Epoch [4305/20000], Loss: 979.256103515625, Entropy 246.54251098632812, Learning Rate: 0.005\n",
      "Epoch [4306/20000], Loss: 939.418701171875, Entropy 238.23744201660156, Learning Rate: 0.005\n",
      "Epoch [4307/20000], Loss: 984.9419555664062, Entropy 232.19842529296875, Learning Rate: 0.005\n",
      "Epoch [4308/20000], Loss: 1006.9557495117188, Entropy 234.3675079345703, Learning Rate: 0.005\n",
      "Epoch [4309/20000], Loss: 991.8223266601562, Entropy 255.3682098388672, Learning Rate: 0.005\n",
      "Epoch [4310/20000], Loss: 983.818603515625, Entropy 239.45445251464844, Learning Rate: 0.005\n",
      "Epoch [4311/20000], Loss: 989.2720947265625, Entropy 243.62196350097656, Learning Rate: 0.005\n",
      "Epoch [4312/20000], Loss: 971.4465942382812, Entropy 257.13482666015625, Learning Rate: 0.005\n",
      "Epoch [4313/20000], Loss: 992.9049072265625, Entropy 241.992919921875, Learning Rate: 0.005\n",
      "Epoch [4314/20000], Loss: 974.970458984375, Entropy 243.56497192382812, Learning Rate: 0.005\n",
      "Epoch [4315/20000], Loss: 966.0731201171875, Entropy 255.53993225097656, Learning Rate: 0.005\n",
      "Epoch [4316/20000], Loss: 959.4312744140625, Entropy 254.16409301757812, Learning Rate: 0.005\n",
      "Epoch [4317/20000], Loss: 988.5633544921875, Entropy 257.9176025390625, Learning Rate: 0.005\n",
      "Epoch [4318/20000], Loss: 945.5896606445312, Entropy 251.5142059326172, Learning Rate: 0.005\n",
      "Epoch [4319/20000], Loss: 967.489501953125, Entropy 264.8681335449219, Learning Rate: 0.005\n",
      "Epoch [4320/20000], Loss: 963.8204345703125, Entropy 243.04940795898438, Learning Rate: 0.005\n",
      "Epoch [4321/20000], Loss: 967.25341796875, Entropy 253.67892456054688, Learning Rate: 0.005\n",
      "Epoch [4322/20000], Loss: 986.153076171875, Entropy 248.8441162109375, Learning Rate: 0.005\n",
      "Epoch [4323/20000], Loss: 982.1943969726562, Entropy 247.2970428466797, Learning Rate: 0.005\n",
      "Epoch [4324/20000], Loss: 954.2681884765625, Entropy 260.4318542480469, Learning Rate: 0.005\n",
      "Epoch [4325/20000], Loss: 951.7315673828125, Entropy 245.83985900878906, Learning Rate: 0.005\n",
      "Epoch [4326/20000], Loss: 970.6491088867188, Entropy 253.5028533935547, Learning Rate: 0.005\n",
      "Epoch [4327/20000], Loss: 997.2376098632812, Entropy 241.7048797607422, Learning Rate: 0.005\n",
      "Epoch [4328/20000], Loss: 947.6447143554688, Entropy 244.5173797607422, Learning Rate: 0.005\n",
      "Epoch [4329/20000], Loss: 944.275390625, Entropy 256.087890625, Learning Rate: 0.005\n",
      "Epoch [4330/20000], Loss: 986.573974609375, Entropy 257.3586730957031, Learning Rate: 0.005\n",
      "Epoch [4331/20000], Loss: 948.7473754882812, Entropy 244.32879638671875, Learning Rate: 0.005\n",
      "Epoch [4332/20000], Loss: 978.090576171875, Entropy 237.37342834472656, Learning Rate: 0.005\n",
      "Epoch [4333/20000], Loss: 986.9583129882812, Entropy 254.4579620361328, Learning Rate: 0.005\n",
      "Epoch [4334/20000], Loss: 954.921875, Entropy 258.2400207519531, Learning Rate: 0.005\n",
      "Epoch [4335/20000], Loss: 965.9461669921875, Entropy 264.1386413574219, Learning Rate: 0.005\n",
      "Epoch [4336/20000], Loss: 1009.1135864257812, Entropy 236.14202880859375, Learning Rate: 0.005\n",
      "Epoch [4337/20000], Loss: 974.6635131835938, Entropy 242.43377685546875, Learning Rate: 0.005\n",
      "Epoch [4338/20000], Loss: 955.9652709960938, Entropy 270.64947509765625, Learning Rate: 0.005\n",
      "Epoch [4339/20000], Loss: 975.9472045898438, Entropy 232.4179229736328, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4340/20000], Loss: 994.082763671875, Entropy 234.86669921875, Learning Rate: 0.005\n",
      "Epoch [4341/20000], Loss: 974.517822265625, Entropy 264.3052978515625, Learning Rate: 0.005\n",
      "Epoch [4342/20000], Loss: 1000.1099853515625, Entropy 239.43484497070312, Learning Rate: 0.005\n",
      "Epoch [4343/20000], Loss: 953.4857177734375, Entropy 251.5301513671875, Learning Rate: 0.005\n",
      "Epoch [4344/20000], Loss: 996.3758544921875, Entropy 244.62879943847656, Learning Rate: 0.005\n",
      "Epoch [4345/20000], Loss: 955.0944213867188, Entropy 247.2984161376953, Learning Rate: 0.005\n",
      "Epoch [4346/20000], Loss: 988.2171630859375, Entropy 259.8304748535156, Learning Rate: 0.005\n",
      "Epoch [4347/20000], Loss: 964.2930908203125, Entropy 256.8532409667969, Learning Rate: 0.005\n",
      "Epoch [4348/20000], Loss: 942.2059326171875, Entropy 259.8098449707031, Learning Rate: 0.005\n",
      "Epoch [4349/20000], Loss: 961.287109375, Entropy 260.7561950683594, Learning Rate: 0.005\n",
      "Epoch [4350/20000], Loss: 971.857177734375, Entropy 255.95651245117188, Learning Rate: 0.005\n",
      "Epoch [4351/20000], Loss: 959.45654296875, Entropy 249.98670959472656, Learning Rate: 0.005\n",
      "Epoch [4352/20000], Loss: 973.390869140625, Entropy 243.21792602539062, Learning Rate: 0.005\n",
      "Epoch [4353/20000], Loss: 957.228271484375, Entropy 265.770263671875, Learning Rate: 0.005\n",
      "Epoch [4354/20000], Loss: 966.4407958984375, Entropy 265.8279113769531, Learning Rate: 0.005\n",
      "Epoch [4355/20000], Loss: 976.3868408203125, Entropy 259.8175964355469, Learning Rate: 0.005\n",
      "Epoch [4356/20000], Loss: 942.7037353515625, Entropy 262.8918151855469, Learning Rate: 0.005\n",
      "Epoch [4357/20000], Loss: 975.6117553710938, Entropy 251.0037078857422, Learning Rate: 0.005\n",
      "Epoch [4358/20000], Loss: 982.0726928710938, Entropy 251.3173370361328, Learning Rate: 0.005\n",
      "Epoch [4359/20000], Loss: 980.209716796875, Entropy 244.41409301757812, Learning Rate: 0.005\n",
      "Epoch [4360/20000], Loss: 953.0298461914062, Entropy 249.6704559326172, Learning Rate: 0.005\n",
      "Epoch [4361/20000], Loss: 982.0563354492188, Entropy 249.3075408935547, Learning Rate: 0.005\n",
      "Epoch [4362/20000], Loss: 971.2391357421875, Entropy 254.76980590820312, Learning Rate: 0.005\n",
      "Epoch [4363/20000], Loss: 960.6934814453125, Entropy 265.42724609375, Learning Rate: 0.005\n",
      "Epoch [4364/20000], Loss: 948.9852905273438, Entropy 263.27545166015625, Learning Rate: 0.005\n",
      "Epoch [4365/20000], Loss: 962.4615478515625, Entropy 257.950927734375, Learning Rate: 0.005\n",
      "Epoch [4366/20000], Loss: 979.778076171875, Entropy 254.60055541992188, Learning Rate: 0.005\n",
      "Epoch [4367/20000], Loss: 949.638427734375, Entropy 258.7243347167969, Learning Rate: 0.005\n",
      "Epoch [4368/20000], Loss: 960.9644775390625, Entropy 264.56787109375, Learning Rate: 0.005\n",
      "Epoch [4369/20000], Loss: 964.8499755859375, Entropy 250.57595825195312, Learning Rate: 0.005\n",
      "Epoch [4370/20000], Loss: 958.9607543945312, Entropy 264.79290771484375, Learning Rate: 0.005\n",
      "Epoch [4371/20000], Loss: 976.9142456054688, Entropy 256.45086669921875, Learning Rate: 0.005\n",
      "Epoch [4372/20000], Loss: 925.66650390625, Entropy 272.4307861328125, Learning Rate: 0.005\n",
      "Epoch [4373/20000], Loss: 965.0853881835938, Entropy 256.96405029296875, Learning Rate: 0.005\n",
      "Epoch [4374/20000], Loss: 963.5645141601562, Entropy 261.11260986328125, Learning Rate: 0.005\n",
      "Epoch [4375/20000], Loss: 969.1728515625, Entropy 271.0423278808594, Learning Rate: 0.005\n",
      "Epoch [4376/20000], Loss: 971.5194091796875, Entropy 267.8416748046875, Learning Rate: 0.005\n",
      "Epoch [4377/20000], Loss: 948.1466674804688, Entropy 273.32183837890625, Learning Rate: 0.005\n",
      "Epoch [4378/20000], Loss: 954.75390625, Entropy 277.3422546386719, Learning Rate: 0.005\n",
      "Epoch [4379/20000], Loss: 1012.2824096679688, Entropy 254.9224090576172, Learning Rate: 0.005\n",
      "Epoch [4380/20000], Loss: 937.99072265625, Entropy 268.0792541503906, Learning Rate: 0.005\n",
      "Epoch [4381/20000], Loss: 958.291015625, Entropy 272.8731994628906, Learning Rate: 0.005\n",
      "Epoch [4382/20000], Loss: 957.9483642578125, Entropy 268.1913146972656, Learning Rate: 0.005\n",
      "Epoch [4383/20000], Loss: 948.8347778320312, Entropy 280.04022216796875, Learning Rate: 0.005\n",
      "Epoch [4384/20000], Loss: 978.1209716796875, Entropy 268.3020324707031, Learning Rate: 0.005\n",
      "Epoch [4385/20000], Loss: 994.4952392578125, Entropy 256.8832092285156, Learning Rate: 0.005\n",
      "Epoch [4386/20000], Loss: 956.9888305664062, Entropy 268.51312255859375, Learning Rate: 0.005\n",
      "Epoch [4387/20000], Loss: 958.612548828125, Entropy 257.8150329589844, Learning Rate: 0.005\n",
      "Epoch [4388/20000], Loss: 965.2081909179688, Entropy 268.76190185546875, Learning Rate: 0.005\n",
      "Epoch [4389/20000], Loss: 943.28515625, Entropy 263.9783020019531, Learning Rate: 0.005\n",
      "Epoch [4390/20000], Loss: 926.8543701171875, Entropy 285.85400390625, Learning Rate: 0.005\n",
      "Epoch [4391/20000], Loss: 977.5697021484375, Entropy 253.11045837402344, Learning Rate: 0.005\n",
      "Epoch [4392/20000], Loss: 936.1357421875, Entropy 264.1886901855469, Learning Rate: 0.005\n",
      "Epoch [4393/20000], Loss: 974.208251953125, Entropy 259.8058776855469, Learning Rate: 0.005\n",
      "Epoch [4394/20000], Loss: 967.62841796875, Entropy 267.1854553222656, Learning Rate: 0.005\n",
      "Epoch [4395/20000], Loss: 944.50634765625, Entropy 283.2840270996094, Learning Rate: 0.005\n",
      "Epoch [4396/20000], Loss: 973.9854125976562, Entropy 265.01763916015625, Learning Rate: 0.005\n",
      "Epoch [4397/20000], Loss: 973.6648559570312, Entropy 257.69927978515625, Learning Rate: 0.005\n",
      "Epoch [4398/20000], Loss: 961.892822265625, Entropy 260.0984191894531, Learning Rate: 0.005\n",
      "Epoch [4399/20000], Loss: 978.61962890625, Entropy 267.9630432128906, Learning Rate: 0.005\n",
      "Epoch [4400/20000], Loss: 932.3755493164062, Entropy 279.96051025390625, Learning Rate: 0.005\n",
      "Epoch [4401/20000], Loss: 943.7951049804688, Entropy 274.22076416015625, Learning Rate: 0.005\n",
      "Epoch [4402/20000], Loss: 944.57666015625, Entropy 269.22265625, Learning Rate: 0.005\n",
      "Epoch [4403/20000], Loss: 946.830078125, Entropy 266.5577087402344, Learning Rate: 0.005\n",
      "Epoch [4404/20000], Loss: 947.8756713867188, Entropy 270.70220947265625, Learning Rate: 0.005\n",
      "Epoch [4405/20000], Loss: 942.7904052734375, Entropy 270.2432861328125, Learning Rate: 0.005\n",
      "Epoch [4406/20000], Loss: 979.7318115234375, Entropy 273.3919372558594, Learning Rate: 0.005\n",
      "Epoch [4407/20000], Loss: 963.144775390625, Entropy 256.91748046875, Learning Rate: 0.005\n",
      "Epoch [4408/20000], Loss: 997.1681518554688, Entropy 270.90789794921875, Learning Rate: 0.005\n",
      "Epoch [4409/20000], Loss: 927.0283203125, Entropy 285.6501159667969, Learning Rate: 0.005\n",
      "Epoch [4410/20000], Loss: 968.1329345703125, Entropy 265.21630859375, Learning Rate: 0.005\n",
      "Epoch [4411/20000], Loss: 966.0716552734375, Entropy 270.2330322265625, Learning Rate: 0.005\n",
      "Epoch [4412/20000], Loss: 992.6307983398438, Entropy 263.23577880859375, Learning Rate: 0.005\n",
      "Epoch [4413/20000], Loss: 989.645751953125, Entropy 272.9403076171875, Learning Rate: 0.005\n",
      "Epoch [4414/20000], Loss: 960.0738525390625, Entropy 277.8052978515625, Learning Rate: 0.005\n",
      "Epoch [4415/20000], Loss: 972.0097045898438, Entropy 260.20904541015625, Learning Rate: 0.005\n",
      "Epoch [4416/20000], Loss: 983.049560546875, Entropy 264.8664245605469, Learning Rate: 0.005\n",
      "Epoch [4417/20000], Loss: 951.1231689453125, Entropy 264.1967468261719, Learning Rate: 0.005\n",
      "Epoch [4418/20000], Loss: 953.090087890625, Entropy 275.4516296386719, Learning Rate: 0.005\n",
      "Epoch [4419/20000], Loss: 925.12646484375, Entropy 286.6150207519531, Learning Rate: 0.005\n",
      "Epoch [4420/20000], Loss: 981.5208740234375, Entropy 272.982421875, Learning Rate: 0.005\n",
      "Epoch [4421/20000], Loss: 929.8438720703125, Entropy 281.4415283203125, Learning Rate: 0.005\n",
      "Epoch [4422/20000], Loss: 963.029296875, Entropy 270.6774597167969, Learning Rate: 0.005\n",
      "Epoch [4423/20000], Loss: 961.9688110351562, Entropy 277.21844482421875, Learning Rate: 0.005\n",
      "Epoch [4424/20000], Loss: 979.0842895507812, Entropy 253.3737030029297, Learning Rate: 0.005\n",
      "Epoch [4425/20000], Loss: 925.1378173828125, Entropy 290.8421936035156, Learning Rate: 0.005\n",
      "Epoch [4426/20000], Loss: 947.116943359375, Entropy 281.9943542480469, Learning Rate: 0.005\n",
      "Epoch [4427/20000], Loss: 947.9528198242188, Entropy 267.87493896484375, Learning Rate: 0.005\n",
      "Epoch [4428/20000], Loss: 978.138427734375, Entropy 272.95556640625, Learning Rate: 0.005\n",
      "Epoch [4429/20000], Loss: 971.8812255859375, Entropy 285.1934814453125, Learning Rate: 0.005\n",
      "Epoch [4430/20000], Loss: 939.8402099609375, Entropy 290.7937927246094, Learning Rate: 0.005\n",
      "Epoch [4431/20000], Loss: 909.1170654296875, Entropy 288.931640625, Learning Rate: 0.005\n",
      "Epoch [4432/20000], Loss: 927.4002685546875, Entropy 269.6242370605469, Learning Rate: 0.005\n",
      "Epoch [4433/20000], Loss: 943.746337890625, Entropy 279.68896484375, Learning Rate: 0.005\n",
      "Epoch [4434/20000], Loss: 973.9922485351562, Entropy 284.55792236328125, Learning Rate: 0.005\n",
      "Epoch [4435/20000], Loss: 946.894287109375, Entropy 286.9446105957031, Learning Rate: 0.005\n",
      "Epoch [4436/20000], Loss: 937.954345703125, Entropy 270.0274963378906, Learning Rate: 0.005\n",
      "Epoch [4437/20000], Loss: 993.725341796875, Entropy 280.0879211425781, Learning Rate: 0.005\n",
      "Epoch [4438/20000], Loss: 948.8616333007812, Entropy 267.86041259765625, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4439/20000], Loss: 951.4418334960938, Entropy 283.40155029296875, Learning Rate: 0.005\n",
      "Epoch [4440/20000], Loss: 939.0881958007812, Entropy 277.20892333984375, Learning Rate: 0.005\n",
      "Epoch [4441/20000], Loss: 956.7138671875, Entropy 287.7940673828125, Learning Rate: 0.005\n",
      "Epoch [4442/20000], Loss: 981.9024658203125, Entropy 265.0692443847656, Learning Rate: 0.005\n",
      "Epoch [4443/20000], Loss: 937.5612182617188, Entropy 293.77447509765625, Learning Rate: 0.005\n",
      "Epoch [4444/20000], Loss: 993.7140502929688, Entropy 294.22894287109375, Learning Rate: 0.005\n",
      "Epoch [4445/20000], Loss: 932.4029541015625, Entropy 287.1923522949219, Learning Rate: 0.005\n",
      "Epoch [4446/20000], Loss: 958.73876953125, Entropy 271.9422607421875, Learning Rate: 0.005\n",
      "Epoch [4447/20000], Loss: 947.093505859375, Entropy 282.1241455078125, Learning Rate: 0.005\n",
      "Epoch [4448/20000], Loss: 972.0659790039062, Entropy 281.07196044921875, Learning Rate: 0.005\n",
      "Epoch [4449/20000], Loss: 956.9638671875, Entropy 287.0280456542969, Learning Rate: 0.005\n",
      "Epoch [4450/20000], Loss: 951.6461181640625, Entropy 296.5190124511719, Learning Rate: 0.005\n",
      "Epoch [4451/20000], Loss: 961.851318359375, Entropy 285.8860168457031, Learning Rate: 0.005\n",
      "Epoch [4452/20000], Loss: 960.888427734375, Entropy 286.1880187988281, Learning Rate: 0.005\n",
      "Epoch [4453/20000], Loss: 969.2463989257812, Entropy 281.43890380859375, Learning Rate: 0.005\n",
      "Epoch [4454/20000], Loss: 944.2742919921875, Entropy 287.5593566894531, Learning Rate: 0.005\n",
      "Epoch [4455/20000], Loss: 968.4124755859375, Entropy 280.3014831542969, Learning Rate: 0.005\n",
      "Epoch [4456/20000], Loss: 933.5040283203125, Entropy 279.372802734375, Learning Rate: 0.005\n",
      "Epoch [4457/20000], Loss: 961.1456298828125, Entropy 285.4969177246094, Learning Rate: 0.005\n",
      "Epoch [4458/20000], Loss: 941.3201904296875, Entropy 284.8957214355469, Learning Rate: 0.005\n",
      "Epoch [4459/20000], Loss: 954.6697998046875, Entropy 281.2549743652344, Learning Rate: 0.005\n",
      "Epoch [4460/20000], Loss: 951.82763671875, Entropy 289.8644714355469, Learning Rate: 0.005\n",
      "Epoch [4461/20000], Loss: 939.1851806640625, Entropy 276.3987731933594, Learning Rate: 0.005\n",
      "Epoch [4462/20000], Loss: 976.4444580078125, Entropy 280.8509826660156, Learning Rate: 0.005\n",
      "Epoch [4463/20000], Loss: 988.5989990234375, Entropy 283.0844421386719, Learning Rate: 0.005\n",
      "Epoch [4464/20000], Loss: 940.2835693359375, Entropy 294.9693603515625, Learning Rate: 0.005\n",
      "Epoch [4465/20000], Loss: 952.485595703125, Entropy 280.8999328613281, Learning Rate: 0.005\n",
      "Epoch [4466/20000], Loss: 944.725341796875, Entropy 295.4033203125, Learning Rate: 0.005\n",
      "Epoch [4467/20000], Loss: 954.2755737304688, Entropy 289.89849853515625, Learning Rate: 0.005\n",
      "Epoch [4468/20000], Loss: 946.1024169921875, Entropy 290.5169372558594, Learning Rate: 0.005\n",
      "Epoch [4469/20000], Loss: 980.449951171875, Entropy 282.8925476074219, Learning Rate: 0.005\n",
      "Epoch [4470/20000], Loss: 967.07177734375, Entropy 291.0428466796875, Learning Rate: 0.005\n",
      "Epoch [4471/20000], Loss: 968.6622924804688, Entropy 280.39910888671875, Learning Rate: 0.005\n",
      "Epoch [4472/20000], Loss: 952.774169921875, Entropy 300.4679870605469, Learning Rate: 0.005\n",
      "Epoch [4473/20000], Loss: 942.3076171875, Entropy 291.173095703125, Learning Rate: 0.005\n",
      "Epoch [4474/20000], Loss: 949.347412109375, Entropy 281.9424133300781, Learning Rate: 0.005\n",
      "Epoch [4475/20000], Loss: 949.658447265625, Entropy 285.3262023925781, Learning Rate: 0.005\n",
      "Epoch [4476/20000], Loss: 943.76220703125, Entropy 284.8343811035156, Learning Rate: 0.005\n",
      "Epoch [4477/20000], Loss: 930.98193359375, Entropy 301.7028503417969, Learning Rate: 0.005\n",
      "Epoch [4478/20000], Loss: 966.66796875, Entropy 285.5015869140625, Learning Rate: 0.005\n",
      "Epoch [4479/20000], Loss: 917.4343872070312, Entropy 294.91656494140625, Learning Rate: 0.005\n",
      "Epoch [4480/20000], Loss: 937.294677734375, Entropy 290.3111572265625, Learning Rate: 0.005\n",
      "Epoch [4481/20000], Loss: 955.5177001953125, Entropy 282.8829345703125, Learning Rate: 0.005\n",
      "Epoch [4482/20000], Loss: 938.163330078125, Entropy 287.9578552246094, Learning Rate: 0.005\n",
      "Epoch [4483/20000], Loss: 948.3701171875, Entropy 277.6918640136719, Learning Rate: 0.005\n",
      "Epoch [4484/20000], Loss: 915.1188354492188, Entropy 297.20733642578125, Learning Rate: 0.005\n",
      "Epoch [4485/20000], Loss: 941.533935546875, Entropy 288.421875, Learning Rate: 0.005\n",
      "Epoch [4486/20000], Loss: 920.3233032226562, Entropy 297.41082763671875, Learning Rate: 0.005\n",
      "Epoch [4487/20000], Loss: 962.5611572265625, Entropy 291.5043640136719, Learning Rate: 0.005\n",
      "Epoch [4488/20000], Loss: 943.4422607421875, Entropy 280.5111389160156, Learning Rate: 0.005\n",
      "Epoch [4489/20000], Loss: 960.9644775390625, Entropy 286.4457702636719, Learning Rate: 0.005\n",
      "Epoch [4490/20000], Loss: 956.9779052734375, Entropy 279.6420593261719, Learning Rate: 0.005\n",
      "Epoch [4491/20000], Loss: 934.1049194335938, Entropy 301.79046630859375, Learning Rate: 0.005\n",
      "Epoch [4492/20000], Loss: 930.730224609375, Entropy 300.7482604980469, Learning Rate: 0.005\n",
      "Epoch [4493/20000], Loss: 947.69384765625, Entropy 293.1347351074219, Learning Rate: 0.005\n",
      "Epoch [4494/20000], Loss: 963.4869384765625, Entropy 283.8794860839844, Learning Rate: 0.005\n",
      "Epoch [4495/20000], Loss: 928.288330078125, Entropy 301.9022216796875, Learning Rate: 0.005\n",
      "Epoch [4496/20000], Loss: 913.1490478515625, Entropy 294.1834716796875, Learning Rate: 0.005\n",
      "Epoch [4497/20000], Loss: 967.182861328125, Entropy 280.5835266113281, Learning Rate: 0.005\n",
      "Epoch [4498/20000], Loss: 948.6005859375, Entropy 279.6166687011719, Learning Rate: 0.005\n",
      "Epoch [4499/20000], Loss: 949.2698364257812, Entropy 303.28375244140625, Learning Rate: 0.005\n",
      "Epoch [4500/20000], Loss: 946.9075927734375, Entropy 303.6955261230469, Learning Rate: 0.005\n",
      "Epoch [4501/20000], Loss: 929.146728515625, Entropy 292.1138916015625, Learning Rate: 0.005\n",
      "Epoch [4502/20000], Loss: 928.5015869140625, Entropy 295.5719909667969, Learning Rate: 0.005\n",
      "Epoch [4503/20000], Loss: 958.712158203125, Entropy 291.8489074707031, Learning Rate: 0.005\n",
      "Epoch [4504/20000], Loss: 949.6103515625, Entropy 302.6140441894531, Learning Rate: 0.005\n",
      "Epoch [4505/20000], Loss: 950.945068359375, Entropy 286.6219787597656, Learning Rate: 0.005\n",
      "Epoch [4506/20000], Loss: 983.15869140625, Entropy 303.2121887207031, Learning Rate: 0.005\n",
      "Epoch [4507/20000], Loss: 960.7950439453125, Entropy 296.4168701171875, Learning Rate: 0.005\n",
      "Epoch [4508/20000], Loss: 935.6884155273438, Entropy 301.74273681640625, Learning Rate: 0.005\n",
      "Epoch [4509/20000], Loss: 985.142578125, Entropy 288.9059753417969, Learning Rate: 0.005\n",
      "Epoch [4510/20000], Loss: 943.85546875, Entropy 294.58447265625, Learning Rate: 0.005\n",
      "Epoch [4511/20000], Loss: 917.2664794921875, Entropy 303.62890625, Learning Rate: 0.005\n",
      "Epoch [4512/20000], Loss: 938.94287109375, Entropy 296.3367004394531, Learning Rate: 0.005\n",
      "Epoch [4513/20000], Loss: 957.177978515625, Entropy 301.79931640625, Learning Rate: 0.005\n",
      "Epoch [4514/20000], Loss: 949.6615600585938, Entropy 287.09600830078125, Learning Rate: 0.005\n",
      "Epoch [4515/20000], Loss: 949.0411376953125, Entropy 308.5211181640625, Learning Rate: 0.005\n",
      "Epoch [4516/20000], Loss: 946.0807495117188, Entropy 308.12408447265625, Learning Rate: 0.005\n",
      "Epoch [4517/20000], Loss: 958.3973388671875, Entropy 303.0251159667969, Learning Rate: 0.005\n",
      "Epoch [4518/20000], Loss: 957.8140258789062, Entropy 296.30609130859375, Learning Rate: 0.005\n",
      "Epoch [4519/20000], Loss: 912.2035522460938, Entropy 304.96722412109375, Learning Rate: 0.005\n",
      "Epoch [4520/20000], Loss: 942.0385131835938, Entropy 301.76007080078125, Learning Rate: 0.005\n",
      "Epoch [4521/20000], Loss: 924.3894653320312, Entropy 308.51983642578125, Learning Rate: 0.005\n",
      "Epoch [4522/20000], Loss: 933.8357543945312, Entropy 306.44049072265625, Learning Rate: 0.005\n",
      "Epoch [4523/20000], Loss: 953.1094970703125, Entropy 302.2655334472656, Learning Rate: 0.005\n",
      "Epoch [4524/20000], Loss: 928.060791015625, Entropy 288.9520263671875, Learning Rate: 0.005\n",
      "Epoch [4525/20000], Loss: 943.7574462890625, Entropy 297.6453857421875, Learning Rate: 0.005\n",
      "Epoch [4526/20000], Loss: 945.1663818359375, Entropy 298.0016784667969, Learning Rate: 0.005\n",
      "Epoch [4527/20000], Loss: 943.674560546875, Entropy 297.2997741699219, Learning Rate: 0.005\n",
      "Epoch [4528/20000], Loss: 939.76904296875, Entropy 293.7375793457031, Learning Rate: 0.005\n",
      "Epoch [4529/20000], Loss: 966.609130859375, Entropy 302.6761779785156, Learning Rate: 0.005\n",
      "Epoch [4530/20000], Loss: 974.546875, Entropy 288.9533996582031, Learning Rate: 0.005\n",
      "Epoch [4531/20000], Loss: 967.4006958007812, Entropy 292.39227294921875, Learning Rate: 0.005\n",
      "Epoch [4532/20000], Loss: 961.900146484375, Entropy 308.9288330078125, Learning Rate: 0.005\n",
      "Epoch [4533/20000], Loss: 946.8103637695312, Entropy 302.57525634765625, Learning Rate: 0.005\n",
      "Epoch [4534/20000], Loss: 910.042724609375, Entropy 317.0119934082031, Learning Rate: 0.005\n",
      "Epoch [4535/20000], Loss: 909.495849609375, Entropy 314.7702941894531, Learning Rate: 0.005\n",
      "Epoch [4536/20000], Loss: 913.78076171875, Entropy 304.8528747558594, Learning Rate: 0.005\n",
      "Epoch [4537/20000], Loss: 968.3283081054688, Entropy 302.72845458984375, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4538/20000], Loss: 956.5975952148438, Entropy 300.35443115234375, Learning Rate: 0.005\n",
      "Epoch [4539/20000], Loss: 951.2883911132812, Entropy 304.15545654296875, Learning Rate: 0.005\n",
      "Epoch [4540/20000], Loss: 953.1199340820312, Entropy 295.51141357421875, Learning Rate: 0.005\n",
      "Epoch [4541/20000], Loss: 943.8291015625, Entropy 309.2528381347656, Learning Rate: 0.005\n",
      "Epoch [4542/20000], Loss: 960.5029296875, Entropy 303.0406494140625, Learning Rate: 0.005\n",
      "Epoch [4543/20000], Loss: 958.68896484375, Entropy 294.2520751953125, Learning Rate: 0.005\n",
      "Epoch [4544/20000], Loss: 934.2481689453125, Entropy 309.26318359375, Learning Rate: 0.005\n",
      "Epoch [4545/20000], Loss: 964.0244140625, Entropy 304.645751953125, Learning Rate: 0.005\n",
      "Epoch [4546/20000], Loss: 963.5963134765625, Entropy 302.9173889160156, Learning Rate: 0.005\n",
      "Epoch [4547/20000], Loss: 914.8057861328125, Entropy 295.0134582519531, Learning Rate: 0.005\n",
      "Epoch [4548/20000], Loss: 952.9411010742188, Entropy 297.17242431640625, Learning Rate: 0.005\n",
      "Epoch [4549/20000], Loss: 939.6531372070312, Entropy 297.62078857421875, Learning Rate: 0.005\n",
      "Epoch [4550/20000], Loss: 925.2833251953125, Entropy 310.166748046875, Learning Rate: 0.005\n",
      "Epoch [4551/20000], Loss: 951.4644165039062, Entropy 321.42889404296875, Learning Rate: 0.005\n",
      "Epoch [4552/20000], Loss: 918.5758056640625, Entropy 297.7332458496094, Learning Rate: 0.005\n",
      "Epoch [4553/20000], Loss: 932.0267333984375, Entropy 306.2659912109375, Learning Rate: 0.005\n",
      "Epoch [4554/20000], Loss: 962.2498779296875, Entropy 312.3441162109375, Learning Rate: 0.005\n",
      "Epoch [4555/20000], Loss: 944.0516357421875, Entropy 306.8207702636719, Learning Rate: 0.005\n",
      "Epoch [4556/20000], Loss: 950.1002197265625, Entropy 309.0896911621094, Learning Rate: 0.005\n",
      "Epoch [4557/20000], Loss: 953.5186767578125, Entropy 313.052490234375, Learning Rate: 0.005\n",
      "Epoch [4558/20000], Loss: 911.661376953125, Entropy 314.9188537597656, Learning Rate: 0.005\n",
      "Epoch [4559/20000], Loss: 961.4112548828125, Entropy 289.5718688964844, Learning Rate: 0.005\n",
      "Epoch [4560/20000], Loss: 945.0178833007812, Entropy 303.67388916015625, Learning Rate: 0.005\n",
      "Epoch [4561/20000], Loss: 945.0439453125, Entropy 301.0943603515625, Learning Rate: 0.005\n",
      "Epoch [4562/20000], Loss: 904.880126953125, Entropy 328.025146484375, Learning Rate: 0.005\n",
      "Epoch [4563/20000], Loss: 944.3543701171875, Entropy 302.8591003417969, Learning Rate: 0.005\n",
      "Epoch [4564/20000], Loss: 973.4725341796875, Entropy 292.699462890625, Learning Rate: 0.005\n",
      "Epoch [4565/20000], Loss: 924.5294189453125, Entropy 314.7290954589844, Learning Rate: 0.005\n",
      "Epoch [4566/20000], Loss: 969.0659790039062, Entropy 304.60760498046875, Learning Rate: 0.005\n",
      "Epoch [4567/20000], Loss: 916.9588623046875, Entropy 324.4776611328125, Learning Rate: 0.005\n",
      "Epoch [4568/20000], Loss: 929.161865234375, Entropy 311.5629577636719, Learning Rate: 0.005\n",
      "Epoch [4569/20000], Loss: 907.1680908203125, Entropy 305.1854553222656, Learning Rate: 0.005\n",
      "Epoch [4570/20000], Loss: 943.5880126953125, Entropy 318.6103820800781, Learning Rate: 0.005\n",
      "Epoch [4571/20000], Loss: 935.7088623046875, Entropy 314.21875, Learning Rate: 0.005\n",
      "Epoch [4572/20000], Loss: 927.4176025390625, Entropy 319.2432861328125, Learning Rate: 0.005\n",
      "Epoch [4573/20000], Loss: 938.029541015625, Entropy 318.4465026855469, Learning Rate: 0.005\n",
      "Epoch [4574/20000], Loss: 940.8490600585938, Entropy 298.41119384765625, Learning Rate: 0.005\n",
      "Epoch [4575/20000], Loss: 908.6727294921875, Entropy 318.2457275390625, Learning Rate: 0.005\n",
      "Epoch [4576/20000], Loss: 896.5868530273438, Entropy 319.53326416015625, Learning Rate: 0.005\n",
      "Epoch [4577/20000], Loss: 927.4612426757812, Entropy 310.00213623046875, Learning Rate: 0.005\n",
      "Epoch [4578/20000], Loss: 925.3170166015625, Entropy 304.5362548828125, Learning Rate: 0.005\n",
      "Epoch [4579/20000], Loss: 960.7308349609375, Entropy 298.1180419921875, Learning Rate: 0.005\n",
      "Epoch [4580/20000], Loss: 945.7440185546875, Entropy 306.1377868652344, Learning Rate: 0.005\n",
      "Epoch [4581/20000], Loss: 975.0145263671875, Entropy 297.2040710449219, Learning Rate: 0.005\n",
      "Epoch [4582/20000], Loss: 949.7881469726562, Entropy 301.66058349609375, Learning Rate: 0.005\n",
      "Epoch [4583/20000], Loss: 903.796142578125, Entropy 326.6212463378906, Learning Rate: 0.005\n",
      "Epoch [4584/20000], Loss: 940.6058959960938, Entropy 310.47491455078125, Learning Rate: 0.005\n",
      "Epoch [4585/20000], Loss: 971.7423095703125, Entropy 315.2922058105469, Learning Rate: 0.005\n",
      "Epoch [4586/20000], Loss: 935.2452392578125, Entropy 331.3908386230469, Learning Rate: 0.005\n",
      "Epoch [4587/20000], Loss: 958.1517333984375, Entropy 328.8548278808594, Learning Rate: 0.005\n",
      "Epoch [4588/20000], Loss: 965.15283203125, Entropy 301.4051818847656, Learning Rate: 0.005\n",
      "Epoch [4589/20000], Loss: 949.785888671875, Entropy 306.1862487792969, Learning Rate: 0.005\n",
      "Epoch [4590/20000], Loss: 912.31494140625, Entropy 312.224853515625, Learning Rate: 0.005\n",
      "Epoch [4591/20000], Loss: 944.4461669921875, Entropy 310.8668518066406, Learning Rate: 0.005\n",
      "Epoch [4592/20000], Loss: 930.3901977539062, Entropy 323.34454345703125, Learning Rate: 0.005\n",
      "Epoch [4593/20000], Loss: 901.7727661132812, Entropy 323.98541259765625, Learning Rate: 0.005\n",
      "Epoch [4594/20000], Loss: 949.95703125, Entropy 320.4945068359375, Learning Rate: 0.005\n",
      "Epoch [4595/20000], Loss: 947.27392578125, Entropy 308.2430114746094, Learning Rate: 0.005\n",
      "Epoch [4596/20000], Loss: 922.9086303710938, Entropy 323.71356201171875, Learning Rate: 0.005\n",
      "Epoch [4597/20000], Loss: 947.8878173828125, Entropy 322.8502197265625, Learning Rate: 0.005\n",
      "Epoch [4598/20000], Loss: 909.8829345703125, Entropy 308.3094177246094, Learning Rate: 0.005\n",
      "Epoch [4599/20000], Loss: 923.5283813476562, Entropy 314.54888916015625, Learning Rate: 0.005\n",
      "Epoch [4600/20000], Loss: 932.6250610351562, Entropy 304.31817626953125, Learning Rate: 0.005\n",
      "Epoch [4601/20000], Loss: 949.2861328125, Entropy 319.32666015625, Learning Rate: 0.005\n",
      "Epoch [4602/20000], Loss: 960.5821533203125, Entropy 314.2392578125, Learning Rate: 0.005\n",
      "Epoch [4603/20000], Loss: 954.113525390625, Entropy 326.6428527832031, Learning Rate: 0.005\n",
      "Epoch [4604/20000], Loss: 938.0084228515625, Entropy 306.6480712890625, Learning Rate: 0.005\n",
      "Epoch [4605/20000], Loss: 906.4515380859375, Entropy 318.3918762207031, Learning Rate: 0.005\n",
      "Epoch [4606/20000], Loss: 960.4061279296875, Entropy 320.9465637207031, Learning Rate: 0.005\n",
      "Epoch [4607/20000], Loss: 1004.69970703125, Entropy 314.3824157714844, Learning Rate: 0.005\n",
      "Epoch [4608/20000], Loss: 959.544921875, Entropy 304.5470886230469, Learning Rate: 0.005\n",
      "Epoch [4609/20000], Loss: 927.957763671875, Entropy 308.3754577636719, Learning Rate: 0.005\n",
      "Epoch [4610/20000], Loss: 882.7730712890625, Entropy 330.7481689453125, Learning Rate: 0.005\n",
      "Epoch [4611/20000], Loss: 907.7052001953125, Entropy 318.8188781738281, Learning Rate: 0.005\n",
      "Epoch [4612/20000], Loss: 935.9798583984375, Entropy 308.638427734375, Learning Rate: 0.005\n",
      "Epoch [4613/20000], Loss: 920.327880859375, Entropy 319.2130432128906, Learning Rate: 0.005\n",
      "Epoch [4614/20000], Loss: 963.93115234375, Entropy 323.5372314453125, Learning Rate: 0.005\n",
      "Epoch [4615/20000], Loss: 947.154296875, Entropy 317.9578552246094, Learning Rate: 0.005\n",
      "Epoch [4616/20000], Loss: 963.1116943359375, Entropy 330.8820495605469, Learning Rate: 0.005\n",
      "Epoch [4617/20000], Loss: 945.844482421875, Entropy 329.712646484375, Learning Rate: 0.005\n",
      "Epoch [4618/20000], Loss: 948.5760498046875, Entropy 322.983642578125, Learning Rate: 0.005\n",
      "Epoch [4619/20000], Loss: 879.650146484375, Entropy 336.8910827636719, Learning Rate: 0.005\n",
      "Epoch [4620/20000], Loss: 955.2825317382812, Entropy 316.47662353515625, Learning Rate: 0.005\n",
      "Epoch [4621/20000], Loss: 943.407470703125, Entropy 326.0204772949219, Learning Rate: 0.005\n",
      "Epoch [4622/20000], Loss: 916.73828125, Entropy 333.8080139160156, Learning Rate: 0.005\n",
      "Epoch [4623/20000], Loss: 942.3375244140625, Entropy 318.6222229003906, Learning Rate: 0.005\n",
      "Epoch [4624/20000], Loss: 933.7805786132812, Entropy 318.39532470703125, Learning Rate: 0.005\n",
      "Epoch [4625/20000], Loss: 943.9739990234375, Entropy 317.8895568847656, Learning Rate: 0.005\n",
      "Epoch [4626/20000], Loss: 1003.3677368164062, Entropy 315.36956787109375, Learning Rate: 0.005\n",
      "Epoch [4627/20000], Loss: 910.2296752929688, Entropy 318.03326416015625, Learning Rate: 0.005\n",
      "Epoch [4628/20000], Loss: 950.1927490234375, Entropy 320.8748474121094, Learning Rate: 0.005\n",
      "Epoch [4629/20000], Loss: 930.9188842773438, Entropy 327.36187744140625, Learning Rate: 0.005\n",
      "Epoch [4630/20000], Loss: 946.560302734375, Entropy 330.43603515625, Learning Rate: 0.005\n",
      "Epoch [4631/20000], Loss: 926.95556640625, Entropy 322.10498046875, Learning Rate: 0.005\n",
      "Epoch [4632/20000], Loss: 962.8433837890625, Entropy 320.8644714355469, Learning Rate: 0.005\n",
      "Epoch [4633/20000], Loss: 954.5181274414062, Entropy 322.16888427734375, Learning Rate: 0.005\n",
      "Epoch [4634/20000], Loss: 962.282470703125, Entropy 329.6463317871094, Learning Rate: 0.005\n",
      "Epoch [4635/20000], Loss: 989.917236328125, Entropy 322.0627746582031, Learning Rate: 0.005\n",
      "Epoch [4636/20000], Loss: 956.2094116210938, Entropy 312.89031982421875, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4637/20000], Loss: 990.3402099609375, Entropy 322.0119934082031, Learning Rate: 0.005\n",
      "Epoch [4638/20000], Loss: 935.9251708984375, Entropy 318.8304138183594, Learning Rate: 0.005\n",
      "Epoch [4639/20000], Loss: 999.8919677734375, Entropy 327.3039245605469, Learning Rate: 0.005\n",
      "Epoch [4640/20000], Loss: 943.3209228515625, Entropy 329.3994445800781, Learning Rate: 0.005\n",
      "Epoch [4641/20000], Loss: 974.89208984375, Entropy 307.0293884277344, Learning Rate: 0.005\n",
      "Epoch [4642/20000], Loss: 991.7298583984375, Entropy 326.6229248046875, Learning Rate: 0.005\n",
      "Epoch [4643/20000], Loss: 987.4161987304688, Entropy 311.48529052734375, Learning Rate: 0.005\n",
      "Epoch [4644/20000], Loss: 983.8154296875, Entropy 332.12158203125, Learning Rate: 0.005\n",
      "Epoch [4645/20000], Loss: 951.1576538085938, Entropy 323.09014892578125, Learning Rate: 0.005\n",
      "Epoch [4646/20000], Loss: 994.1461181640625, Entropy 323.9580993652344, Learning Rate: 0.005\n",
      "Epoch [4647/20000], Loss: 990.861572265625, Entropy 325.3537292480469, Learning Rate: 0.005\n",
      "Epoch [4648/20000], Loss: 993.8662109375, Entropy 318.4104919433594, Learning Rate: 0.005\n",
      "Epoch [4649/20000], Loss: 984.498291015625, Entropy 327.2831726074219, Learning Rate: 0.005\n",
      "Epoch [4650/20000], Loss: 928.304931640625, Entropy 328.6553955078125, Learning Rate: 0.005\n",
      "Epoch [4651/20000], Loss: 1048.719482421875, Entropy 334.75872802734375, Learning Rate: 0.005\n",
      "Epoch [4652/20000], Loss: 1076.275390625, Entropy 325.0425720214844, Learning Rate: 0.005\n",
      "Epoch [4653/20000], Loss: 1016.5101318359375, Entropy 322.5245361328125, Learning Rate: 0.005\n",
      "Epoch [4654/20000], Loss: 1036.072998046875, Entropy 326.94830322265625, Learning Rate: 0.005\n",
      "Epoch [4655/20000], Loss: 990.5894775390625, Entropy 330.1273498535156, Learning Rate: 0.005\n",
      "Epoch [4656/20000], Loss: 1021.08544921875, Entropy 319.9041442871094, Learning Rate: 0.005\n",
      "Epoch [4657/20000], Loss: 994.6823120117188, Entropy 329.99700927734375, Learning Rate: 0.005\n",
      "Epoch [4658/20000], Loss: 986.4156494140625, Entropy 310.9015808105469, Learning Rate: 0.005\n",
      "Epoch [4659/20000], Loss: 992.248046875, Entropy 318.5195007324219, Learning Rate: 0.005\n",
      "Epoch [4660/20000], Loss: 1033.630126953125, Entropy 319.8360290527344, Learning Rate: 0.005\n",
      "Epoch [4661/20000], Loss: 1002.9552001953125, Entropy 326.1732482910156, Learning Rate: 0.005\n",
      "Epoch [4662/20000], Loss: 919.0174560546875, Entropy 315.9754333496094, Learning Rate: 0.005\n",
      "Epoch [4663/20000], Loss: 977.6332397460938, Entropy 315.77813720703125, Learning Rate: 0.005\n",
      "Epoch [4664/20000], Loss: 949.4124755859375, Entropy 327.6670227050781, Learning Rate: 0.005\n",
      "Epoch [4665/20000], Loss: 997.9898681640625, Entropy 313.6438293457031, Learning Rate: 0.005\n",
      "Epoch [4666/20000], Loss: 957.9202880859375, Entropy 324.9920959472656, Learning Rate: 0.005\n",
      "Epoch [4667/20000], Loss: 953.4453125, Entropy 318.0281066894531, Learning Rate: 0.005\n",
      "Epoch [4668/20000], Loss: 989.1788940429688, Entropy 310.58807373046875, Learning Rate: 0.005\n",
      "Epoch [4669/20000], Loss: 949.539306640625, Entropy 316.1783447265625, Learning Rate: 0.005\n",
      "Epoch [4670/20000], Loss: 983.9365234375, Entropy 319.106201171875, Learning Rate: 0.005\n",
      "Epoch [4671/20000], Loss: 923.3692016601562, Entropy 319.46453857421875, Learning Rate: 0.005\n",
      "Epoch [4672/20000], Loss: 913.203857421875, Entropy 326.166015625, Learning Rate: 0.005\n",
      "Epoch [4673/20000], Loss: 925.3546752929688, Entropy 327.08306884765625, Learning Rate: 0.005\n",
      "Epoch [4674/20000], Loss: 955.3756103515625, Entropy 325.1704406738281, Learning Rate: 0.005\n",
      "Epoch [4675/20000], Loss: 981.6232299804688, Entropy 315.82025146484375, Learning Rate: 0.005\n",
      "Epoch [4676/20000], Loss: 978.713134765625, Entropy 313.5767822265625, Learning Rate: 0.005\n",
      "Epoch [4677/20000], Loss: 975.172607421875, Entropy 314.2707214355469, Learning Rate: 0.005\n",
      "Epoch [4678/20000], Loss: 924.408203125, Entropy 319.8192138671875, Learning Rate: 0.005\n",
      "Epoch [4679/20000], Loss: 972.1495361328125, Entropy 312.9642028808594, Learning Rate: 0.005\n",
      "Epoch [4680/20000], Loss: 961.8419189453125, Entropy 311.2379150390625, Learning Rate: 0.005\n",
      "Epoch [4681/20000], Loss: 993.2643432617188, Entropy 314.71575927734375, Learning Rate: 0.005\n",
      "Epoch [4682/20000], Loss: 917.61474609375, Entropy 323.3041076660156, Learning Rate: 0.005\n",
      "Epoch [4683/20000], Loss: 957.340576171875, Entropy 331.8609619140625, Learning Rate: 0.005\n",
      "Epoch [4684/20000], Loss: 917.879150390625, Entropy 340.6370544433594, Learning Rate: 0.005\n",
      "Epoch [4685/20000], Loss: 1007.4010009765625, Entropy 319.2377014160156, Learning Rate: 0.005\n",
      "Epoch [4686/20000], Loss: 937.8909912109375, Entropy 326.1042175292969, Learning Rate: 0.005\n",
      "Epoch [4687/20000], Loss: 1048.926025390625, Entropy 313.1000671386719, Learning Rate: 0.005\n",
      "Epoch [4688/20000], Loss: 945.9028930664062, Entropy 329.13116455078125, Learning Rate: 0.005\n",
      "Epoch [4689/20000], Loss: 966.052490234375, Entropy 335.4703063964844, Learning Rate: 0.005\n",
      "Epoch [4690/20000], Loss: 951.4159545898438, Entropy 310.11676025390625, Learning Rate: 0.005\n",
      "Epoch [4691/20000], Loss: 957.620849609375, Entropy 318.9092102050781, Learning Rate: 0.005\n",
      "Epoch [4692/20000], Loss: 946.178466796875, Entropy 326.5244445800781, Learning Rate: 0.005\n",
      "Epoch [4693/20000], Loss: 955.12109375, Entropy 314.8394775390625, Learning Rate: 0.005\n",
      "Epoch [4694/20000], Loss: 973.055419921875, Entropy 328.5216369628906, Learning Rate: 0.005\n",
      "Epoch [4695/20000], Loss: 952.4444580078125, Entropy 329.6683654785156, Learning Rate: 0.005\n",
      "Epoch [4696/20000], Loss: 939.9223022460938, Entropy 314.29681396484375, Learning Rate: 0.005\n",
      "Epoch [4697/20000], Loss: 957.212890625, Entropy 321.5518798828125, Learning Rate: 0.005\n",
      "Epoch [4698/20000], Loss: 922.9008178710938, Entropy 323.25115966796875, Learning Rate: 0.005\n",
      "Epoch [4699/20000], Loss: 907.0357055664062, Entropy 323.00030517578125, Learning Rate: 0.005\n",
      "Epoch [4700/20000], Loss: 947.2459716796875, Entropy 305.1498718261719, Learning Rate: 0.005\n",
      "Epoch [4701/20000], Loss: 920.4610595703125, Entropy 319.9671325683594, Learning Rate: 0.005\n",
      "Epoch [4702/20000], Loss: 959.1787109375, Entropy 311.44140625, Learning Rate: 0.005\n",
      "Epoch [4703/20000], Loss: 919.4081420898438, Entropy 328.75164794921875, Learning Rate: 0.005\n",
      "Epoch [4704/20000], Loss: 932.8994750976562, Entropy 329.83624267578125, Learning Rate: 0.005\n",
      "Epoch [4705/20000], Loss: 950.1581420898438, Entropy 311.77996826171875, Learning Rate: 0.005\n",
      "Epoch [4706/20000], Loss: 912.6318359375, Entropy 329.4173889160156, Learning Rate: 0.005\n",
      "Epoch [4707/20000], Loss: 909.872314453125, Entropy 330.7732849121094, Learning Rate: 0.005\n",
      "Epoch [4708/20000], Loss: 936.841064453125, Entropy 325.4609069824219, Learning Rate: 0.005\n",
      "Epoch [4709/20000], Loss: 925.6527709960938, Entropy 327.81842041015625, Learning Rate: 0.005\n",
      "Epoch [4710/20000], Loss: 921.734375, Entropy 324.9773864746094, Learning Rate: 0.005\n",
      "Epoch [4711/20000], Loss: 920.60595703125, Entropy 328.534912109375, Learning Rate: 0.005\n",
      "Epoch [4712/20000], Loss: 909.469970703125, Entropy 332.3288879394531, Learning Rate: 0.005\n",
      "Epoch [4713/20000], Loss: 958.5738525390625, Entropy 320.3016662597656, Learning Rate: 0.005\n",
      "Epoch [4714/20000], Loss: 972.6913452148438, Entropy 318.58795166015625, Learning Rate: 0.005\n",
      "Epoch [4715/20000], Loss: 953.0513305664062, Entropy 327.21600341796875, Learning Rate: 0.005\n",
      "Epoch [4716/20000], Loss: 933.7249755859375, Entropy 329.7527160644531, Learning Rate: 0.005\n",
      "Epoch [4717/20000], Loss: 948.7406616210938, Entropy 318.60296630859375, Learning Rate: 0.005\n",
      "Epoch [4718/20000], Loss: 972.2232055664062, Entropy 314.08123779296875, Learning Rate: 0.005\n",
      "Epoch [4719/20000], Loss: 948.54296875, Entropy 327.6966857910156, Learning Rate: 0.005\n",
      "Epoch [4720/20000], Loss: 910.5103149414062, Entropy 331.76922607421875, Learning Rate: 0.005\n",
      "Epoch [4721/20000], Loss: 940.7247314453125, Entropy 338.5583801269531, Learning Rate: 0.005\n",
      "Epoch [4722/20000], Loss: 908.4339599609375, Entropy 336.9017639160156, Learning Rate: 0.005\n",
      "Epoch [4723/20000], Loss: 950.8067016601562, Entropy 343.05413818359375, Learning Rate: 0.005\n",
      "Epoch [4724/20000], Loss: 932.7122802734375, Entropy 321.8728942871094, Learning Rate: 0.005\n",
      "Epoch [4725/20000], Loss: 958.0451049804688, Entropy 339.24652099609375, Learning Rate: 0.005\n",
      "Epoch [4726/20000], Loss: 972.5086669921875, Entropy 319.321044921875, Learning Rate: 0.005\n",
      "Epoch [4727/20000], Loss: 987.9921875, Entropy 317.6291809082031, Learning Rate: 0.005\n",
      "Epoch [4728/20000], Loss: 971.6485595703125, Entropy 319.8827819824219, Learning Rate: 0.005\n",
      "Epoch [4729/20000], Loss: 923.640869140625, Entropy 327.5568542480469, Learning Rate: 0.005\n",
      "Epoch [4730/20000], Loss: 927.0008544921875, Entropy 337.5158386230469, Learning Rate: 0.005\n",
      "Epoch [4731/20000], Loss: 945.155029296875, Entropy 329.5480651855469, Learning Rate: 0.005\n",
      "Epoch [4732/20000], Loss: 915.9520263671875, Entropy 323.6901550292969, Learning Rate: 0.005\n",
      "Epoch [4733/20000], Loss: 939.767578125, Entropy 336.9793701171875, Learning Rate: 0.005\n",
      "Epoch [4734/20000], Loss: 911.4449462890625, Entropy 331.05615234375, Learning Rate: 0.005\n",
      "Epoch [4735/20000], Loss: 933.0216064453125, Entropy 321.5976867675781, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4736/20000], Loss: 900.6690063476562, Entropy 340.28411865234375, Learning Rate: 0.005\n",
      "Epoch [4737/20000], Loss: 1000.00048828125, Entropy 330.5231628417969, Learning Rate: 0.005\n",
      "Epoch [4738/20000], Loss: 888.1480712890625, Entropy 337.0594787597656, Learning Rate: 0.005\n",
      "Epoch [4739/20000], Loss: 931.286865234375, Entropy 338.7265930175781, Learning Rate: 0.005\n",
      "Epoch [4740/20000], Loss: 939.0354614257812, Entropy 326.27496337890625, Learning Rate: 0.005\n",
      "Epoch [4741/20000], Loss: 974.9345092773438, Entropy 324.71759033203125, Learning Rate: 0.005\n",
      "Epoch [4742/20000], Loss: 919.46484375, Entropy 315.0933837890625, Learning Rate: 0.005\n",
      "Epoch [4743/20000], Loss: 1036.205322265625, Entropy 334.1043701171875, Learning Rate: 0.005\n",
      "Epoch [4744/20000], Loss: 1056.3314208984375, Entropy 335.9819030761719, Learning Rate: 0.005\n",
      "Epoch [4745/20000], Loss: 940.2724609375, Entropy 338.2699279785156, Learning Rate: 0.005\n",
      "Epoch [4746/20000], Loss: 1022.923583984375, Entropy 328.4357604980469, Learning Rate: 0.005\n",
      "Epoch [4747/20000], Loss: 937.8695068359375, Entropy 328.6985168457031, Learning Rate: 0.005\n",
      "Epoch [4748/20000], Loss: 978.30859375, Entropy 326.5874938964844, Learning Rate: 0.005\n",
      "Epoch [4749/20000], Loss: 917.3242797851562, Entropy 331.90130615234375, Learning Rate: 0.005\n",
      "Epoch [4750/20000], Loss: 1017.9417724609375, Entropy 341.186279296875, Learning Rate: 0.005\n",
      "Epoch [4751/20000], Loss: 999.7615966796875, Entropy 317.8541564941406, Learning Rate: 0.005\n",
      "Epoch [4752/20000], Loss: 941.032958984375, Entropy 316.4915466308594, Learning Rate: 0.005\n",
      "Epoch [4753/20000], Loss: 1020.8289794921875, Entropy 327.9324035644531, Learning Rate: 0.005\n",
      "Epoch [4754/20000], Loss: 977.3532104492188, Entropy 330.81707763671875, Learning Rate: 0.005\n",
      "Epoch [4755/20000], Loss: 1084.52685546875, Entropy 325.1466064453125, Learning Rate: 0.005\n",
      "Epoch [4756/20000], Loss: 1070.879638671875, Entropy 320.16571044921875, Learning Rate: 0.005\n",
      "Epoch [4757/20000], Loss: 999.748779296875, Entropy 322.0965881347656, Learning Rate: 0.005\n",
      "Epoch [4758/20000], Loss: 934.0266723632812, Entropy 324.04595947265625, Learning Rate: 0.005\n",
      "Epoch [4759/20000], Loss: 1010.4942016601562, Entropy 322.91827392578125, Learning Rate: 0.005\n",
      "Epoch [4760/20000], Loss: 1000.1385498046875, Entropy 335.4632873535156, Learning Rate: 0.005\n",
      "Epoch [4761/20000], Loss: 1063.586669921875, Entropy 318.35394287109375, Learning Rate: 0.005\n",
      "Epoch [4762/20000], Loss: 1084.4649658203125, Entropy 328.6941223144531, Learning Rate: 0.005\n",
      "Epoch [4763/20000], Loss: 945.2435302734375, Entropy 308.4601135253906, Learning Rate: 0.005\n",
      "Epoch [4764/20000], Loss: 1045.0321044921875, Entropy 322.8267822265625, Learning Rate: 0.005\n",
      "Epoch [4765/20000], Loss: 1003.710205078125, Entropy 334.3416442871094, Learning Rate: 0.005\n",
      "Epoch [4766/20000], Loss: 1043.591064453125, Entropy 339.29803466796875, Learning Rate: 0.005\n",
      "Epoch [4767/20000], Loss: 1021.5745849609375, Entropy 320.8306579589844, Learning Rate: 0.005\n",
      "Epoch [4768/20000], Loss: 980.279541015625, Entropy 327.577880859375, Learning Rate: 0.005\n",
      "Epoch [4769/20000], Loss: 944.0504760742188, Entropy 319.58746337890625, Learning Rate: 0.005\n",
      "Epoch [4770/20000], Loss: 1015.4511108398438, Entropy 339.40850830078125, Learning Rate: 0.005\n",
      "Epoch [4771/20000], Loss: 962.722900390625, Entropy 315.8002014160156, Learning Rate: 0.005\n",
      "Epoch [4772/20000], Loss: 1003.912841796875, Entropy 324.0751647949219, Learning Rate: 0.005\n",
      "Epoch [4773/20000], Loss: 974.457275390625, Entropy 337.9217834472656, Learning Rate: 0.005\n",
      "Epoch [4774/20000], Loss: 975.0912475585938, Entropy 343.57843017578125, Learning Rate: 0.005\n",
      "Epoch [4775/20000], Loss: 1061.46044921875, Entropy 334.3439025878906, Learning Rate: 0.005\n",
      "Epoch [4776/20000], Loss: 1167.107666015625, Entropy 339.2816467285156, Learning Rate: 0.005\n",
      "Epoch [4777/20000], Loss: 1011.885498046875, Entropy 337.7138977050781, Learning Rate: 0.005\n",
      "Epoch [4778/20000], Loss: 1193.471435546875, Entropy 309.4203186035156, Learning Rate: 0.005\n",
      "Epoch [4779/20000], Loss: 1048.5333251953125, Entropy 337.9962463378906, Learning Rate: 0.005\n",
      "Epoch [4780/20000], Loss: 1364.6376953125, Entropy 315.0956726074219, Learning Rate: 0.005\n",
      "Epoch [4781/20000], Loss: 1199.396484375, Entropy 323.32916259765625, Learning Rate: 0.005\n",
      "Epoch [4782/20000], Loss: 1530.70703125, Entropy 310.0638732910156, Learning Rate: 0.005\n",
      "Epoch [4783/20000], Loss: 1108.6962890625, Entropy 315.87567138671875, Learning Rate: 0.005\n",
      "Epoch [4784/20000], Loss: 1419.1370849609375, Entropy 324.4343566894531, Learning Rate: 0.005\n",
      "Epoch [4785/20000], Loss: 1175.2529296875, Entropy 318.7253112792969, Learning Rate: 0.005\n",
      "Epoch [4786/20000], Loss: 1147.644287109375, Entropy 322.60345458984375, Learning Rate: 0.005\n",
      "Epoch [4787/20000], Loss: 1037.488037109375, Entropy 322.0775146484375, Learning Rate: 0.005\n",
      "Epoch [4788/20000], Loss: 1229.62548828125, Entropy 325.04217529296875, Learning Rate: 0.005\n",
      "Epoch [4789/20000], Loss: 1017.558349609375, Entropy 315.5233459472656, Learning Rate: 0.005\n",
      "Epoch [4790/20000], Loss: 1027.087646484375, Entropy 311.0553894042969, Learning Rate: 0.005\n",
      "Epoch [4791/20000], Loss: 1382.114990234375, Entropy 301.3023986816406, Learning Rate: 0.005\n",
      "Epoch [4792/20000], Loss: 1038.874267578125, Entropy 320.54205322265625, Learning Rate: 0.005\n",
      "Epoch [4793/20000], Loss: 1355.409912109375, Entropy 307.3412780761719, Learning Rate: 0.005\n",
      "Epoch [4794/20000], Loss: 1294.985107421875, Entropy 309.1460876464844, Learning Rate: 0.005\n",
      "Epoch [4795/20000], Loss: 1068.1468505859375, Entropy 307.1276550292969, Learning Rate: 0.005\n",
      "Epoch [4796/20000], Loss: 1186.4896240234375, Entropy 315.4175109863281, Learning Rate: 0.005\n",
      "Epoch [4797/20000], Loss: 1100.1607666015625, Entropy 306.2882385253906, Learning Rate: 0.005\n",
      "Epoch [4798/20000], Loss: 1198.755859375, Entropy 303.52984619140625, Learning Rate: 0.005\n",
      "Epoch [4799/20000], Loss: 1272.6319580078125, Entropy 312.1995544433594, Learning Rate: 0.005\n",
      "Epoch [4800/20000], Loss: 1120.2520751953125, Entropy 302.6012878417969, Learning Rate: 0.005\n",
      "Epoch [4801/20000], Loss: 1293.913818359375, Entropy 276.7889099121094, Learning Rate: 0.005\n",
      "Epoch [4802/20000], Loss: 1084.1160888671875, Entropy 310.8101806640625, Learning Rate: 0.005\n",
      "Epoch [4803/20000], Loss: 1019.4244384765625, Entropy 309.15283203125, Learning Rate: 0.005\n",
      "Epoch [4804/20000], Loss: 1243.25341796875, Entropy 304.6383972167969, Learning Rate: 0.005\n",
      "Epoch [4805/20000], Loss: 1185.547607421875, Entropy 301.1848449707031, Learning Rate: 0.005\n",
      "Epoch [4806/20000], Loss: 1248.467529296875, Entropy 300.95501708984375, Learning Rate: 0.005\n",
      "Epoch [4807/20000], Loss: 998.9473876953125, Entropy 308.3991394042969, Learning Rate: 0.005\n",
      "Epoch [4808/20000], Loss: 1258.93701171875, Entropy 292.58355712890625, Learning Rate: 0.005\n",
      "Epoch [4809/20000], Loss: 1009.5140991210938, Entropy 296.70831298828125, Learning Rate: 0.005\n",
      "Epoch [4810/20000], Loss: 1053.77099609375, Entropy 305.80780029296875, Learning Rate: 0.005\n",
      "Epoch [4811/20000], Loss: 1101.6446533203125, Entropy 295.7113037109375, Learning Rate: 0.005\n",
      "Epoch [4812/20000], Loss: 979.58056640625, Entropy 291.1623229980469, Learning Rate: 0.005\n",
      "Epoch [4813/20000], Loss: 1119.227294921875, Entropy 304.6054382324219, Learning Rate: 0.005\n",
      "Epoch [4814/20000], Loss: 1008.530517578125, Entropy 308.9557189941406, Learning Rate: 0.005\n",
      "Epoch [4815/20000], Loss: 973.843017578125, Entropy 289.5395202636719, Learning Rate: 0.005\n",
      "Epoch [4816/20000], Loss: 1084.8857421875, Entropy 291.0650329589844, Learning Rate: 0.005\n",
      "Epoch [4817/20000], Loss: 992.3237915039062, Entropy 287.19598388671875, Learning Rate: 0.005\n",
      "Epoch [4818/20000], Loss: 1106.953125, Entropy 282.7761535644531, Learning Rate: 0.005\n",
      "Epoch [4819/20000], Loss: 1025.6678466796875, Entropy 286.4209289550781, Learning Rate: 0.005\n",
      "Epoch [4820/20000], Loss: 1005.9564208984375, Entropy 296.0433044433594, Learning Rate: 0.005\n",
      "Epoch [4821/20000], Loss: 1014.922119140625, Entropy 279.6665954589844, Learning Rate: 0.005\n",
      "Epoch [4822/20000], Loss: 1052.8834228515625, Entropy 298.0234069824219, Learning Rate: 0.005\n",
      "Epoch [4823/20000], Loss: 976.0241088867188, Entropy 287.69732666015625, Learning Rate: 0.005\n",
      "Epoch [4824/20000], Loss: 986.2935791015625, Entropy 269.8517150878906, Learning Rate: 0.005\n",
      "Epoch [4825/20000], Loss: 991.3719482421875, Entropy 286.7471618652344, Learning Rate: 0.005\n",
      "Epoch [4826/20000], Loss: 942.1204223632812, Entropy 287.89935302734375, Learning Rate: 0.005\n",
      "Epoch [4827/20000], Loss: 974.9483642578125, Entropy 282.4690856933594, Learning Rate: 0.005\n",
      "Epoch [4828/20000], Loss: 993.2349853515625, Entropy 296.0030517578125, Learning Rate: 0.005\n",
      "Epoch [4829/20000], Loss: 947.8806762695312, Entropy 290.20550537109375, Learning Rate: 0.005\n",
      "Epoch [4830/20000], Loss: 984.1939697265625, Entropy 291.4886779785156, Learning Rate: 0.005\n",
      "Epoch [4831/20000], Loss: 987.2528076171875, Entropy 293.9207763671875, Learning Rate: 0.005\n",
      "Epoch [4832/20000], Loss: 969.2235107421875, Entropy 299.1543273925781, Learning Rate: 0.005\n",
      "Epoch [4833/20000], Loss: 991.0018310546875, Entropy 278.9074401855469, Learning Rate: 0.005\n",
      "Epoch [4834/20000], Loss: 994.925537109375, Entropy 284.3166198730469, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4835/20000], Loss: 977.3514404296875, Entropy 284.61279296875, Learning Rate: 0.005\n",
      "Epoch [4836/20000], Loss: 995.132080078125, Entropy 293.5197448730469, Learning Rate: 0.005\n",
      "Epoch [4837/20000], Loss: 982.4954833984375, Entropy 282.1971740722656, Learning Rate: 0.005\n",
      "Epoch [4838/20000], Loss: 942.0396728515625, Entropy 311.4307861328125, Learning Rate: 0.005\n",
      "Epoch [4839/20000], Loss: 958.412353515625, Entropy 288.7195739746094, Learning Rate: 0.005\n",
      "Epoch [4840/20000], Loss: 931.654541015625, Entropy 285.0417175292969, Learning Rate: 0.005\n",
      "Epoch [4841/20000], Loss: 1041.763427734375, Entropy 294.9890441894531, Learning Rate: 0.005\n",
      "Epoch [4842/20000], Loss: 1029.376953125, Entropy 278.5566101074219, Learning Rate: 0.005\n",
      "Epoch [4843/20000], Loss: 1012.3046875, Entropy 287.1084899902344, Learning Rate: 0.005\n",
      "Epoch [4844/20000], Loss: 994.5360107421875, Entropy 290.6658630371094, Learning Rate: 0.005\n",
      "Epoch [4845/20000], Loss: 942.7283935546875, Entropy 301.9778137207031, Learning Rate: 0.005\n",
      "Epoch [4846/20000], Loss: 990.848388671875, Entropy 287.0110168457031, Learning Rate: 0.005\n",
      "Epoch [4847/20000], Loss: 973.1932373046875, Entropy 297.0921325683594, Learning Rate: 0.005\n",
      "Epoch [4848/20000], Loss: 976.3250732421875, Entropy 294.7775573730469, Learning Rate: 0.005\n",
      "Epoch [4849/20000], Loss: 949.748291015625, Entropy 294.0862121582031, Learning Rate: 0.005\n",
      "Epoch [4850/20000], Loss: 956.1524658203125, Entropy 281.3251037597656, Learning Rate: 0.005\n",
      "Epoch [4851/20000], Loss: 987.7706909179688, Entropy 283.43316650390625, Learning Rate: 0.005\n",
      "Epoch [4852/20000], Loss: 961.99853515625, Entropy 297.894287109375, Learning Rate: 0.005\n",
      "Epoch [4853/20000], Loss: 993.364501953125, Entropy 296.060791015625, Learning Rate: 0.005\n",
      "Epoch [4854/20000], Loss: 968.534912109375, Entropy 280.8108825683594, Learning Rate: 0.005\n",
      "Epoch [4855/20000], Loss: 993.8084716796875, Entropy 269.7219543457031, Learning Rate: 0.005\n",
      "Epoch [4856/20000], Loss: 944.1582641601562, Entropy 292.53448486328125, Learning Rate: 0.005\n",
      "Epoch [4857/20000], Loss: 957.4036865234375, Entropy 291.8063049316406, Learning Rate: 0.005\n",
      "Epoch [4858/20000], Loss: 950.2887573242188, Entropy 291.50360107421875, Learning Rate: 0.005\n",
      "Epoch [4859/20000], Loss: 905.2942504882812, Entropy 290.37896728515625, Learning Rate: 0.005\n",
      "Epoch [4860/20000], Loss: 948.2249755859375, Entropy 289.3187561035156, Learning Rate: 0.005\n",
      "Epoch [4861/20000], Loss: 955.6463623046875, Entropy 298.8519592285156, Learning Rate: 0.005\n",
      "Epoch [4862/20000], Loss: 941.6005249023438, Entropy 307.37908935546875, Learning Rate: 0.005\n",
      "Epoch [4863/20000], Loss: 975.400390625, Entropy 289.2743225097656, Learning Rate: 0.005\n",
      "Epoch [4864/20000], Loss: 940.988037109375, Entropy 294.52392578125, Learning Rate: 0.005\n",
      "Epoch [4865/20000], Loss: 996.8623046875, Entropy 291.8484191894531, Learning Rate: 0.005\n",
      "Epoch [4866/20000], Loss: 955.7687377929688, Entropy 295.67254638671875, Learning Rate: 0.005\n",
      "Epoch [4867/20000], Loss: 950.1253051757812, Entropy 288.66046142578125, Learning Rate: 0.005\n",
      "Epoch [4868/20000], Loss: 1015.191162109375, Entropy 296.0518798828125, Learning Rate: 0.005\n",
      "Epoch [4869/20000], Loss: 964.2947387695312, Entropy 308.33978271484375, Learning Rate: 0.005\n",
      "Epoch [4870/20000], Loss: 961.7359619140625, Entropy 295.6669921875, Learning Rate: 0.005\n",
      "Epoch [4871/20000], Loss: 952.0150146484375, Entropy 298.4534912109375, Learning Rate: 0.005\n",
      "Epoch [4872/20000], Loss: 1001.6240844726562, Entropy 295.17376708984375, Learning Rate: 0.005\n",
      "Epoch [4873/20000], Loss: 943.4332275390625, Entropy 292.1648864746094, Learning Rate: 0.005\n",
      "Epoch [4874/20000], Loss: 989.078125, Entropy 309.1671142578125, Learning Rate: 0.005\n",
      "Epoch [4875/20000], Loss: 922.72998046875, Entropy 294.361328125, Learning Rate: 0.005\n",
      "Epoch [4876/20000], Loss: 998.916015625, Entropy 303.2939758300781, Learning Rate: 0.005\n",
      "Epoch [4877/20000], Loss: 927.568359375, Entropy 307.835205078125, Learning Rate: 0.005\n",
      "Epoch [4878/20000], Loss: 959.8697509765625, Entropy 311.608154296875, Learning Rate: 0.005\n",
      "Epoch [4879/20000], Loss: 956.14013671875, Entropy 298.6505126953125, Learning Rate: 0.005\n",
      "Epoch [4880/20000], Loss: 953.160400390625, Entropy 297.2351379394531, Learning Rate: 0.005\n",
      "Epoch [4881/20000], Loss: 995.704833984375, Entropy 286.6042785644531, Learning Rate: 0.005\n",
      "Epoch [4882/20000], Loss: 993.892822265625, Entropy 293.5956726074219, Learning Rate: 0.005\n",
      "Epoch [4883/20000], Loss: 954.1026611328125, Entropy 304.0353698730469, Learning Rate: 0.005\n",
      "Epoch [4884/20000], Loss: 948.7942504882812, Entropy 308.48187255859375, Learning Rate: 0.005\n",
      "Epoch [4885/20000], Loss: 950.353271484375, Entropy 302.433837890625, Learning Rate: 0.005\n",
      "Epoch [4886/20000], Loss: 952.84326171875, Entropy 294.2688293457031, Learning Rate: 0.005\n",
      "Epoch [4887/20000], Loss: 990.6373291015625, Entropy 304.406005859375, Learning Rate: 0.005\n",
      "Epoch [4888/20000], Loss: 966.0191040039062, Entropy 294.42926025390625, Learning Rate: 0.005\n",
      "Epoch [4889/20000], Loss: 982.4913330078125, Entropy 288.8899841308594, Learning Rate: 0.005\n",
      "Epoch [4890/20000], Loss: 939.1192016601562, Entropy 297.72381591796875, Learning Rate: 0.005\n",
      "Epoch [4891/20000], Loss: 961.9044799804688, Entropy 302.43890380859375, Learning Rate: 0.005\n",
      "Epoch [4892/20000], Loss: 964.9214477539062, Entropy 298.36480712890625, Learning Rate: 0.005\n",
      "Epoch [4893/20000], Loss: 946.2216796875, Entropy 305.594482421875, Learning Rate: 0.005\n",
      "Epoch [4894/20000], Loss: 909.975341796875, Entropy 297.8590393066406, Learning Rate: 0.005\n",
      "Epoch [4895/20000], Loss: 970.21533203125, Entropy 299.7128601074219, Learning Rate: 0.005\n",
      "Epoch [4896/20000], Loss: 934.7769165039062, Entropy 291.46478271484375, Learning Rate: 0.005\n",
      "Epoch [4897/20000], Loss: 964.6248168945312, Entropy 303.80926513671875, Learning Rate: 0.005\n",
      "Epoch [4898/20000], Loss: 994.1690673828125, Entropy 299.35693359375, Learning Rate: 0.005\n",
      "Epoch [4899/20000], Loss: 942.0260009765625, Entropy 307.525634765625, Learning Rate: 0.005\n",
      "Epoch [4900/20000], Loss: 941.2080078125, Entropy 301.7607727050781, Learning Rate: 0.005\n",
      "Epoch [4901/20000], Loss: 910.6610717773438, Entropy 305.77606201171875, Learning Rate: 0.005\n",
      "Epoch [4902/20000], Loss: 922.484619140625, Entropy 309.3182067871094, Learning Rate: 0.005\n",
      "Epoch [4903/20000], Loss: 946.4131469726562, Entropy 304.53924560546875, Learning Rate: 0.005\n",
      "Epoch [4904/20000], Loss: 924.888671875, Entropy 307.1692810058594, Learning Rate: 0.005\n",
      "Epoch [4905/20000], Loss: 977.4595336914062, Entropy 309.28179931640625, Learning Rate: 0.005\n",
      "Epoch [4906/20000], Loss: 926.8408203125, Entropy 299.9242248535156, Learning Rate: 0.005\n",
      "Epoch [4907/20000], Loss: 951.0010986328125, Entropy 292.2032775878906, Learning Rate: 0.005\n",
      "Epoch [4908/20000], Loss: 882.1203002929688, Entropy 321.04840087890625, Learning Rate: 0.005\n",
      "Epoch [4909/20000], Loss: 943.817138671875, Entropy 303.947509765625, Learning Rate: 0.005\n",
      "Epoch [4910/20000], Loss: 970.0972900390625, Entropy 304.2154541015625, Learning Rate: 0.005\n",
      "Epoch [4911/20000], Loss: 951.4797973632812, Entropy 316.28607177734375, Learning Rate: 0.005\n",
      "Epoch [4912/20000], Loss: 928.0909423828125, Entropy 312.0450439453125, Learning Rate: 0.005\n",
      "Epoch [4913/20000], Loss: 876.0123291015625, Entropy 332.6496276855469, Learning Rate: 0.005\n",
      "Epoch [4914/20000], Loss: 971.3753662109375, Entropy 288.4312744140625, Learning Rate: 0.005\n",
      "Epoch [4915/20000], Loss: 927.1616821289062, Entropy 311.23455810546875, Learning Rate: 0.005\n",
      "Epoch [4916/20000], Loss: 922.34521484375, Entropy 312.3570556640625, Learning Rate: 0.005\n",
      "Epoch [4917/20000], Loss: 952.1091918945312, Entropy 302.57757568359375, Learning Rate: 0.005\n",
      "Epoch [4918/20000], Loss: 911.11669921875, Entropy 321.8912658691406, Learning Rate: 0.005\n",
      "Epoch [4919/20000], Loss: 916.9766845703125, Entropy 307.9906005859375, Learning Rate: 0.005\n",
      "Epoch [4920/20000], Loss: 969.8276977539062, Entropy 309.47967529296875, Learning Rate: 0.005\n",
      "Epoch [4921/20000], Loss: 931.947021484375, Entropy 299.1706237792969, Learning Rate: 0.005\n",
      "Epoch [4922/20000], Loss: 921.9650268554688, Entropy 309.57232666015625, Learning Rate: 0.005\n",
      "Epoch [4923/20000], Loss: 923.5681762695312, Entropy 310.53118896484375, Learning Rate: 0.005\n",
      "Epoch [4924/20000], Loss: 929.4202880859375, Entropy 302.62939453125, Learning Rate: 0.005\n",
      "Epoch [4925/20000], Loss: 941.4208984375, Entropy 304.4830017089844, Learning Rate: 0.005\n",
      "Epoch [4926/20000], Loss: 924.7722778320312, Entropy 305.14459228515625, Learning Rate: 0.005\n",
      "Epoch [4927/20000], Loss: 929.6165771484375, Entropy 306.431640625, Learning Rate: 0.005\n",
      "Epoch [4928/20000], Loss: 924.0858764648438, Entropy 301.29656982421875, Learning Rate: 0.005\n",
      "Epoch [4929/20000], Loss: 955.5474853515625, Entropy 306.2109680175781, Learning Rate: 0.005\n",
      "Epoch [4930/20000], Loss: 916.9192504882812, Entropy 309.33148193359375, Learning Rate: 0.005\n",
      "Epoch [4931/20000], Loss: 947.01123046875, Entropy 314.2247619628906, Learning Rate: 0.005\n",
      "Epoch [4932/20000], Loss: 929.637451171875, Entropy 304.7839660644531, Learning Rate: 0.005\n",
      "Epoch [4933/20000], Loss: 905.5400390625, Entropy 325.309814453125, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4934/20000], Loss: 923.2174072265625, Entropy 305.9836120605469, Learning Rate: 0.005\n",
      "Epoch [4935/20000], Loss: 949.2340087890625, Entropy 301.2381286621094, Learning Rate: 0.005\n",
      "Epoch [4936/20000], Loss: 901.9448852539062, Entropy 309.39569091796875, Learning Rate: 0.005\n",
      "Epoch [4937/20000], Loss: 941.2945556640625, Entropy 294.6008605957031, Learning Rate: 0.005\n",
      "Epoch [4938/20000], Loss: 908.063720703125, Entropy 309.7635192871094, Learning Rate: 0.005\n",
      "Epoch [4939/20000], Loss: 910.3310546875, Entropy 313.539794921875, Learning Rate: 0.005\n",
      "Epoch [4940/20000], Loss: 980.80322265625, Entropy 304.7024230957031, Learning Rate: 0.005\n",
      "Epoch [4941/20000], Loss: 935.4765625, Entropy 305.312255859375, Learning Rate: 0.005\n",
      "Epoch [4942/20000], Loss: 936.0877685546875, Entropy 315.2718811035156, Learning Rate: 0.005\n",
      "Epoch [4943/20000], Loss: 943.1032104492188, Entropy 312.41546630859375, Learning Rate: 0.005\n",
      "Epoch [4944/20000], Loss: 919.2767944335938, Entropy 315.54595947265625, Learning Rate: 0.005\n",
      "Epoch [4945/20000], Loss: 924.2595825195312, Entropy 322.08453369140625, Learning Rate: 0.005\n",
      "Epoch [4946/20000], Loss: 937.746337890625, Entropy 331.148193359375, Learning Rate: 0.005\n",
      "Epoch [4947/20000], Loss: 976.29833984375, Entropy 292.4701843261719, Learning Rate: 0.005\n",
      "Epoch [4948/20000], Loss: 914.6668701171875, Entropy 321.3045959472656, Learning Rate: 0.005\n",
      "Epoch [4949/20000], Loss: 947.3565673828125, Entropy 319.0147705078125, Learning Rate: 0.005\n",
      "Epoch [4950/20000], Loss: 915.048828125, Entropy 311.4533996582031, Learning Rate: 0.005\n",
      "Epoch [4951/20000], Loss: 902.6407470703125, Entropy 326.2101745605469, Learning Rate: 0.005\n",
      "Epoch [4952/20000], Loss: 931.18798828125, Entropy 326.8778076171875, Learning Rate: 0.005\n",
      "Epoch [4953/20000], Loss: 909.9373779296875, Entropy 319.4399719238281, Learning Rate: 0.005\n",
      "Epoch [4954/20000], Loss: 958.0221557617188, Entropy 305.58416748046875, Learning Rate: 0.005\n",
      "Epoch [4955/20000], Loss: 901.9989013671875, Entropy 326.09814453125, Learning Rate: 0.005\n",
      "Epoch [4956/20000], Loss: 931.9326171875, Entropy 320.8408508300781, Learning Rate: 0.005\n",
      "Epoch [4957/20000], Loss: 946.2925415039062, Entropy 313.73529052734375, Learning Rate: 0.005\n",
      "Epoch [4958/20000], Loss: 886.76025390625, Entropy 322.941162109375, Learning Rate: 0.005\n",
      "Epoch [4959/20000], Loss: 916.5406494140625, Entropy 324.85986328125, Learning Rate: 0.005\n",
      "Epoch [4960/20000], Loss: 924.9136962890625, Entropy 318.5619812011719, Learning Rate: 0.005\n",
      "Epoch [4961/20000], Loss: 939.8310546875, Entropy 313.6781311035156, Learning Rate: 0.005\n",
      "Epoch [4962/20000], Loss: 963.5474853515625, Entropy 324.4179992675781, Learning Rate: 0.005\n",
      "Epoch [4963/20000], Loss: 942.498046875, Entropy 323.544921875, Learning Rate: 0.005\n",
      "Epoch [4964/20000], Loss: 928.72802734375, Entropy 307.4165344238281, Learning Rate: 0.005\n",
      "Epoch [4965/20000], Loss: 894.419921875, Entropy 327.7185363769531, Learning Rate: 0.005\n",
      "Epoch [4966/20000], Loss: 959.4887084960938, Entropy 328.59796142578125, Learning Rate: 0.005\n",
      "Epoch [4967/20000], Loss: 911.400146484375, Entropy 332.7925720214844, Learning Rate: 0.005\n",
      "Epoch [4968/20000], Loss: 905.0325317382812, Entropy 322.44842529296875, Learning Rate: 0.005\n",
      "Epoch [4969/20000], Loss: 944.352783203125, Entropy 311.2197570800781, Learning Rate: 0.005\n",
      "Epoch [4970/20000], Loss: 959.31494140625, Entropy 317.1874694824219, Learning Rate: 0.005\n",
      "Epoch [4971/20000], Loss: 924.69580078125, Entropy 315.1935119628906, Learning Rate: 0.005\n",
      "Epoch [4972/20000], Loss: 934.0977172851562, Entropy 328.33172607421875, Learning Rate: 0.005\n",
      "Epoch [4973/20000], Loss: 911.3772583007812, Entropy 326.02398681640625, Learning Rate: 0.005\n",
      "Epoch [4974/20000], Loss: 893.8963623046875, Entropy 348.6682434082031, Learning Rate: 0.005\n",
      "Epoch [4975/20000], Loss: 922.080322265625, Entropy 323.5089111328125, Learning Rate: 0.005\n",
      "Epoch [4976/20000], Loss: 898.76953125, Entropy 318.8719177246094, Learning Rate: 0.005\n",
      "Epoch [4977/20000], Loss: 921.0905151367188, Entropy 322.16461181640625, Learning Rate: 0.005\n",
      "Epoch [4978/20000], Loss: 968.8515625, Entropy 326.1572570800781, Learning Rate: 0.005\n",
      "Epoch [4979/20000], Loss: 922.1480712890625, Entropy 328.1768798828125, Learning Rate: 0.005\n",
      "Epoch [4980/20000], Loss: 912.0244750976562, Entropy 330.62554931640625, Learning Rate: 0.005\n",
      "Epoch [4981/20000], Loss: 905.5194091796875, Entropy 331.7206115722656, Learning Rate: 0.005\n",
      "Epoch [4982/20000], Loss: 924.7897338867188, Entropy 331.25543212890625, Learning Rate: 0.005\n",
      "Epoch [4983/20000], Loss: 967.4783325195312, Entropy 316.52166748046875, Learning Rate: 0.005\n",
      "Epoch [4984/20000], Loss: 936.9337768554688, Entropy 315.27655029296875, Learning Rate: 0.005\n",
      "Epoch [4985/20000], Loss: 934.1027221679688, Entropy 325.91668701171875, Learning Rate: 0.005\n",
      "Epoch [4986/20000], Loss: 927.2896728515625, Entropy 336.7787170410156, Learning Rate: 0.005\n",
      "Epoch [4987/20000], Loss: 924.7573852539062, Entropy 319.26849365234375, Learning Rate: 0.005\n",
      "Epoch [4988/20000], Loss: 946.88037109375, Entropy 315.0712890625, Learning Rate: 0.005\n",
      "Epoch [4989/20000], Loss: 924.5311279296875, Entropy 322.2884521484375, Learning Rate: 0.005\n",
      "Epoch [4990/20000], Loss: 923.5867919921875, Entropy 331.6120300292969, Learning Rate: 0.005\n",
      "Epoch [4991/20000], Loss: 925.635986328125, Entropy 331.2322998046875, Learning Rate: 0.005\n",
      "Epoch [4992/20000], Loss: 952.0723876953125, Entropy 310.7117614746094, Learning Rate: 0.005\n",
      "Epoch [4993/20000], Loss: 926.7052001953125, Entropy 317.0847473144531, Learning Rate: 0.005\n",
      "Epoch [4994/20000], Loss: 932.21142578125, Entropy 323.2031555175781, Learning Rate: 0.005\n",
      "Epoch [4995/20000], Loss: 957.948974609375, Entropy 337.8713684082031, Learning Rate: 0.005\n",
      "Epoch [4996/20000], Loss: 939.6197509765625, Entropy 313.3423767089844, Learning Rate: 0.005\n",
      "Epoch [4997/20000], Loss: 951.368408203125, Entropy 333.6301574707031, Learning Rate: 0.005\n",
      "Epoch [4998/20000], Loss: 918.6201171875, Entropy 337.12646484375, Learning Rate: 0.005\n",
      "Epoch [4999/20000], Loss: 908.8842163085938, Entropy 319.94366455078125, Learning Rate: 0.005\n",
      "Epoch [5000/20000], Loss: 910.3172607421875, Entropy 334.0649108886719, Learning Rate: 0.005\n",
      "Epoch [5001/20000], Loss: 958.4369506835938, Entropy 325.10211181640625, Learning Rate: 0.005\n",
      "Epoch [5002/20000], Loss: 885.155029296875, Entropy 338.6011657714844, Learning Rate: 0.005\n",
      "Epoch [5003/20000], Loss: 896.8497924804688, Entropy 329.54803466796875, Learning Rate: 0.005\n",
      "Epoch [5004/20000], Loss: 919.48974609375, Entropy 344.0421447753906, Learning Rate: 0.005\n",
      "Epoch [5005/20000], Loss: 936.3819580078125, Entropy 331.9735412597656, Learning Rate: 0.005\n",
      "Epoch [5006/20000], Loss: 928.6742553710938, Entropy 330.92669677734375, Learning Rate: 0.005\n",
      "Epoch [5007/20000], Loss: 915.0616455078125, Entropy 326.9263916015625, Learning Rate: 0.005\n",
      "Epoch [5008/20000], Loss: 892.6573486328125, Entropy 341.3976135253906, Learning Rate: 0.005\n",
      "Epoch [5009/20000], Loss: 921.700439453125, Entropy 324.35888671875, Learning Rate: 0.005\n",
      "Epoch [5010/20000], Loss: 893.5630493164062, Entropy 350.79010009765625, Learning Rate: 0.005\n",
      "Epoch [5011/20000], Loss: 945.9395141601562, Entropy 337.59576416015625, Learning Rate: 0.005\n",
      "Epoch [5012/20000], Loss: 932.176025390625, Entropy 326.2352294921875, Learning Rate: 0.005\n",
      "Epoch [5013/20000], Loss: 910.11865234375, Entropy 342.9563903808594, Learning Rate: 0.005\n",
      "Epoch [5014/20000], Loss: 925.081787109375, Entropy 332.5791015625, Learning Rate: 0.005\n",
      "Epoch [5015/20000], Loss: 890.4033203125, Entropy 346.4129333496094, Learning Rate: 0.005\n",
      "Epoch [5016/20000], Loss: 921.5870361328125, Entropy 347.2575988769531, Learning Rate: 0.005\n",
      "Epoch [5017/20000], Loss: 922.9134521484375, Entropy 343.0542907714844, Learning Rate: 0.005\n",
      "Epoch [5018/20000], Loss: 983.86767578125, Entropy 327.2143249511719, Learning Rate: 0.005\n",
      "Epoch [5019/20000], Loss: 908.83056640625, Entropy 325.8415222167969, Learning Rate: 0.005\n",
      "Epoch [5020/20000], Loss: 972.40087890625, Entropy 330.6634826660156, Learning Rate: 0.005\n",
      "Epoch [5021/20000], Loss: 1000.92431640625, Entropy 344.7119445800781, Learning Rate: 0.005\n",
      "Epoch [5022/20000], Loss: 931.514404296875, Entropy 346.4984436035156, Learning Rate: 0.005\n",
      "Epoch [5023/20000], Loss: 906.07177734375, Entropy 338.302734375, Learning Rate: 0.005\n",
      "Epoch [5024/20000], Loss: 940.66552734375, Entropy 317.1452941894531, Learning Rate: 0.005\n",
      "Epoch [5025/20000], Loss: 896.3775024414062, Entropy 346.35540771484375, Learning Rate: 0.005\n",
      "Epoch [5026/20000], Loss: 949.457763671875, Entropy 347.3680114746094, Learning Rate: 0.005\n",
      "Epoch [5027/20000], Loss: 930.87255859375, Entropy 327.5478820800781, Learning Rate: 0.005\n",
      "Epoch [5028/20000], Loss: 986.404052734375, Entropy 335.2736511230469, Learning Rate: 0.005\n",
      "Epoch [5029/20000], Loss: 950.47265625, Entropy 322.892822265625, Learning Rate: 0.005\n",
      "Epoch [5030/20000], Loss: 961.2052001953125, Entropy 328.3576965332031, Learning Rate: 0.005\n",
      "Epoch [5031/20000], Loss: 924.5806884765625, Entropy 334.4053039550781, Learning Rate: 0.005\n",
      "Epoch [5032/20000], Loss: 986.2364501953125, Entropy 340.551513671875, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5033/20000], Loss: 902.025146484375, Entropy 344.655029296875, Learning Rate: 0.005\n",
      "Epoch [5034/20000], Loss: 943.0127563476562, Entropy 336.18426513671875, Learning Rate: 0.005\n",
      "Epoch [5035/20000], Loss: 929.2222900390625, Entropy 336.9203796386719, Learning Rate: 0.005\n",
      "Epoch [5036/20000], Loss: 957.812255859375, Entropy 334.4949035644531, Learning Rate: 0.005\n",
      "Epoch [5037/20000], Loss: 895.3291015625, Entropy 334.504638671875, Learning Rate: 0.005\n",
      "Epoch [5038/20000], Loss: 958.8043212890625, Entropy 336.49658203125, Learning Rate: 0.005\n",
      "Epoch [5039/20000], Loss: 932.5828857421875, Entropy 332.1922607421875, Learning Rate: 0.005\n",
      "Epoch [5040/20000], Loss: 941.5625610351562, Entropy 345.59039306640625, Learning Rate: 0.005\n",
      "Epoch [5041/20000], Loss: 951.3906860351562, Entropy 339.28363037109375, Learning Rate: 0.005\n",
      "Epoch [5042/20000], Loss: 946.5110473632812, Entropy 329.98699951171875, Learning Rate: 0.005\n",
      "Epoch [5043/20000], Loss: 935.945556640625, Entropy 341.0585021972656, Learning Rate: 0.005\n",
      "Epoch [5044/20000], Loss: 1068.11181640625, Entropy 344.57073974609375, Learning Rate: 0.005\n",
      "Epoch [5045/20000], Loss: 972.0397338867188, Entropy 343.30560302734375, Learning Rate: 0.005\n",
      "Epoch [5046/20000], Loss: 1058.2352294921875, Entropy 332.2990417480469, Learning Rate: 0.005\n",
      "Epoch [5047/20000], Loss: 935.795654296875, Entropy 348.4376525878906, Learning Rate: 0.005\n",
      "Epoch [5048/20000], Loss: 1024.9061279296875, Entropy 344.6621398925781, Learning Rate: 0.005\n",
      "Epoch [5049/20000], Loss: 937.6964111328125, Entropy 338.5499267578125, Learning Rate: 0.005\n",
      "Epoch [5050/20000], Loss: 1110.45166015625, Entropy 341.2174072265625, Learning Rate: 0.005\n",
      "Epoch [5051/20000], Loss: 980.3817138671875, Entropy 337.5889892578125, Learning Rate: 0.005\n",
      "Epoch [5052/20000], Loss: 1231.471435546875, Entropy 357.96185302734375, Learning Rate: 0.005\n",
      "Epoch [5053/20000], Loss: 1191.077880859375, Entropy 341.06951904296875, Learning Rate: 0.005\n",
      "Epoch [5054/20000], Loss: 1192.63330078125, Entropy 334.7752990722656, Learning Rate: 0.005\n",
      "Epoch [5055/20000], Loss: 1022.1114501953125, Entropy 348.4022521972656, Learning Rate: 0.005\n",
      "Epoch [5056/20000], Loss: 1285.6142578125, Entropy 341.5855407714844, Learning Rate: 0.005\n",
      "Epoch [5057/20000], Loss: 1000.3106689453125, Entropy 341.5415954589844, Learning Rate: 0.005\n",
      "Epoch [5058/20000], Loss: 1362.26025390625, Entropy 342.71136474609375, Learning Rate: 0.005\n",
      "Epoch [5059/20000], Loss: 1111.666259765625, Entropy 349.8322448730469, Learning Rate: 0.005\n",
      "Epoch [5060/20000], Loss: 1600.364990234375, Entropy 331.03485107421875, Learning Rate: 0.005\n",
      "Epoch [5061/20000], Loss: 1151.76220703125, Entropy 327.38531494140625, Learning Rate: 0.005\n",
      "Epoch [5062/20000], Loss: 1833.5867919921875, Entropy 334.4037170410156, Learning Rate: 0.005\n",
      "Epoch [5063/20000], Loss: 1770.6156005859375, Entropy 320.1695861816406, Learning Rate: 0.005\n",
      "Epoch [5064/20000], Loss: 1356.1552734375, Entropy 328.09881591796875, Learning Rate: 0.005\n",
      "Epoch [5065/20000], Loss: 1367.56689453125, Entropy 329.1305847167969, Learning Rate: 0.005\n",
      "Epoch [5066/20000], Loss: 1330.6259765625, Entropy 316.7272644042969, Learning Rate: 0.005\n",
      "Epoch [5067/20000], Loss: 1198.953369140625, Entropy 331.37841796875, Learning Rate: 0.005\n",
      "Epoch [5068/20000], Loss: 1192.921875, Entropy 300.7102966308594, Learning Rate: 0.005\n",
      "Epoch [5069/20000], Loss: 1147.440673828125, Entropy 313.22003173828125, Learning Rate: 0.005\n",
      "Epoch [5070/20000], Loss: 1111.0843505859375, Entropy 316.22900390625, Learning Rate: 0.005\n",
      "Epoch [5071/20000], Loss: 1035.773193359375, Entropy 306.74176025390625, Learning Rate: 0.005\n",
      "Epoch [5072/20000], Loss: 1419.758544921875, Entropy 308.09710693359375, Learning Rate: 0.005\n",
      "Epoch [5073/20000], Loss: 1204.3282470703125, Entropy 315.1355285644531, Learning Rate: 0.005\n",
      "Epoch [5074/20000], Loss: 1642.6693115234375, Entropy 320.4201354980469, Learning Rate: 0.005\n",
      "Epoch [5075/20000], Loss: 1215.88427734375, Entropy 307.27008056640625, Learning Rate: 0.005\n",
      "Epoch [5076/20000], Loss: 1313.55810546875, Entropy 313.7555847167969, Learning Rate: 0.005\n",
      "Epoch [5077/20000], Loss: 1184.8590087890625, Entropy 314.9568786621094, Learning Rate: 0.005\n",
      "Epoch [5078/20000], Loss: 1377.090576171875, Entropy 305.39166259765625, Learning Rate: 0.005\n",
      "Epoch [5079/20000], Loss: 1418.7059326171875, Entropy 299.3618469238281, Learning Rate: 0.005\n",
      "Epoch [5080/20000], Loss: 1460.57373046875, Entropy 309.83514404296875, Learning Rate: 0.005\n",
      "Epoch [5081/20000], Loss: 1867.8326416015625, Entropy 285.8297119140625, Learning Rate: 0.005\n",
      "Epoch [5082/20000], Loss: 1706.3975830078125, Entropy 306.9881896972656, Learning Rate: 0.005\n",
      "Epoch [5083/20000], Loss: 1747.1168212890625, Entropy 295.0818786621094, Learning Rate: 0.005\n",
      "Epoch [5084/20000], Loss: 1831.251220703125, Entropy 289.67529296875, Learning Rate: 0.005\n",
      "Epoch [5085/20000], Loss: 1430.61572265625, Entropy 299.6739196777344, Learning Rate: 0.005\n",
      "Epoch [5086/20000], Loss: 1934.580810546875, Entropy 286.6510925292969, Learning Rate: 0.005\n",
      "Epoch [5087/20000], Loss: 1745.308837890625, Entropy 283.2510986328125, Learning Rate: 0.005\n",
      "Epoch [5088/20000], Loss: 2512.432861328125, Entropy 279.73016357421875, Learning Rate: 0.005\n",
      "Epoch [5089/20000], Loss: 1606.7177734375, Entropy 279.51434326171875, Learning Rate: 0.005\n",
      "Epoch [5090/20000], Loss: 2461.52490234375, Entropy 283.15631103515625, Learning Rate: 0.005\n",
      "Epoch [5091/20000], Loss: 1683.44873046875, Entropy 269.42645263671875, Learning Rate: 0.005\n",
      "Epoch [5092/20000], Loss: 1345.376708984375, Entropy 271.77642822265625, Learning Rate: 0.005\n",
      "Epoch [5093/20000], Loss: 2701.143310546875, Entropy 270.2040710449219, Learning Rate: 0.005\n",
      "Epoch [5094/20000], Loss: 1924.9683837890625, Entropy 255.83457946777344, Learning Rate: 0.005\n",
      "Epoch [5095/20000], Loss: 1336.480712890625, Entropy 253.95016479492188, Learning Rate: 0.005\n",
      "Epoch [5096/20000], Loss: 1600.52490234375, Entropy 253.4413299560547, Learning Rate: 0.005\n",
      "Epoch [5097/20000], Loss: 2091.74462890625, Entropy 232.935302734375, Learning Rate: 0.005\n",
      "Epoch [5098/20000], Loss: 1302.739013671875, Entropy 233.36203002929688, Learning Rate: 0.005\n",
      "Epoch [5099/20000], Loss: 1268.4202880859375, Entropy 239.864013671875, Learning Rate: 0.005\n",
      "Epoch [5100/20000], Loss: 1570.281494140625, Entropy 229.720703125, Learning Rate: 0.005\n",
      "Epoch [5101/20000], Loss: 1332.937744140625, Entropy 220.31304931640625, Learning Rate: 0.005\n",
      "Epoch [5102/20000], Loss: 1236.3760986328125, Entropy 226.55819702148438, Learning Rate: 0.005\n",
      "Epoch [5103/20000], Loss: 1147.1087646484375, Entropy 210.28915405273438, Learning Rate: 0.005\n",
      "Epoch [5104/20000], Loss: 1284.6490478515625, Entropy 209.45553588867188, Learning Rate: 0.005\n",
      "Epoch [5105/20000], Loss: 1301.2781982421875, Entropy 206.4905242919922, Learning Rate: 0.005\n",
      "Epoch [5106/20000], Loss: 1131.387451171875, Entropy 207.45819091796875, Learning Rate: 0.005\n",
      "Epoch [5107/20000], Loss: 1157.54833984375, Entropy 186.44293212890625, Learning Rate: 0.005\n",
      "Epoch [5108/20000], Loss: 1313.38330078125, Entropy 205.83831787109375, Learning Rate: 0.005\n",
      "Epoch [5109/20000], Loss: 1130.30322265625, Entropy 187.88897705078125, Learning Rate: 0.005\n",
      "Epoch [5110/20000], Loss: 1221.317138671875, Entropy 193.58132934570312, Learning Rate: 0.005\n",
      "Epoch [5111/20000], Loss: 1161.9984130859375, Entropy 198.7186737060547, Learning Rate: 0.005\n",
      "Epoch [5112/20000], Loss: 1099.6134033203125, Entropy 188.75511169433594, Learning Rate: 0.005\n",
      "Epoch [5113/20000], Loss: 1117.9161376953125, Entropy 205.31459045410156, Learning Rate: 0.005\n",
      "Epoch [5114/20000], Loss: 1128.769287109375, Entropy 187.82855224609375, Learning Rate: 0.005\n",
      "Epoch [5115/20000], Loss: 1080.119384765625, Entropy 182.3121795654297, Learning Rate: 0.005\n",
      "Epoch [5116/20000], Loss: 1033.2088623046875, Entropy 191.9845733642578, Learning Rate: 0.005\n",
      "Epoch [5117/20000], Loss: 1067.76123046875, Entropy 196.502197265625, Learning Rate: 0.005\n",
      "Epoch [5118/20000], Loss: 1031.33935546875, Entropy 196.4344024658203, Learning Rate: 0.005\n",
      "Epoch [5119/20000], Loss: 1054.41748046875, Entropy 188.5144500732422, Learning Rate: 0.005\n",
      "Epoch [5120/20000], Loss: 1088.10888671875, Entropy 194.51101684570312, Learning Rate: 0.005\n",
      "Epoch [5121/20000], Loss: 1052.084228515625, Entropy 184.3292999267578, Learning Rate: 0.005\n",
      "Epoch [5122/20000], Loss: 1013.04638671875, Entropy 204.75796508789062, Learning Rate: 0.005\n",
      "Epoch [5123/20000], Loss: 1120.17626953125, Entropy 176.43138122558594, Learning Rate: 0.005\n",
      "Epoch [5124/20000], Loss: 1073.95068359375, Entropy 202.5751495361328, Learning Rate: 0.005\n",
      "Epoch [5125/20000], Loss: 1030.588623046875, Entropy 185.3465576171875, Learning Rate: 0.005\n",
      "Epoch [5126/20000], Loss: 1030.05517578125, Entropy 188.83656311035156, Learning Rate: 0.005\n",
      "Epoch [5127/20000], Loss: 1055.4267578125, Entropy 180.44512939453125, Learning Rate: 0.005\n",
      "Epoch [5128/20000], Loss: 1057.7215576171875, Entropy 195.3035888671875, Learning Rate: 0.005\n",
      "Epoch [5129/20000], Loss: 1022.192626953125, Entropy 182.66650390625, Learning Rate: 0.005\n",
      "Epoch [5130/20000], Loss: 1051.51025390625, Entropy 191.84280395507812, Learning Rate: 0.005\n",
      "Epoch [5131/20000], Loss: 1013.5150146484375, Entropy 186.90670776367188, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5132/20000], Loss: 1016.8184814453125, Entropy 195.61537170410156, Learning Rate: 0.005\n",
      "Epoch [5133/20000], Loss: 1064.6796875, Entropy 190.1931610107422, Learning Rate: 0.005\n",
      "Epoch [5134/20000], Loss: 997.1439208984375, Entropy 194.35374450683594, Learning Rate: 0.005\n",
      "Epoch [5135/20000], Loss: 1012.0706176757812, Entropy 200.5183868408203, Learning Rate: 0.005\n",
      "Epoch [5136/20000], Loss: 1063.51220703125, Entropy 176.146484375, Learning Rate: 0.005\n",
      "Epoch [5137/20000], Loss: 1019.5557861328125, Entropy 194.55406188964844, Learning Rate: 0.005\n",
      "Epoch [5138/20000], Loss: 990.5762939453125, Entropy 191.38734436035156, Learning Rate: 0.005\n",
      "Epoch [5139/20000], Loss: 1023.3280029296875, Entropy 189.96511840820312, Learning Rate: 0.005\n",
      "Epoch [5140/20000], Loss: 1059.630615234375, Entropy 193.9091339111328, Learning Rate: 0.005\n",
      "Epoch [5141/20000], Loss: 1017.0572509765625, Entropy 194.38748168945312, Learning Rate: 0.005\n",
      "Epoch [5142/20000], Loss: 1006.6493530273438, Entropy 188.86163330078125, Learning Rate: 0.005\n",
      "Epoch [5143/20000], Loss: 1032.2769775390625, Entropy 190.8535919189453, Learning Rate: 0.005\n",
      "Epoch [5144/20000], Loss: 1020.3260498046875, Entropy 192.52999877929688, Learning Rate: 0.005\n",
      "Epoch [5145/20000], Loss: 1019.5675659179688, Entropy 212.3174591064453, Learning Rate: 0.005\n",
      "Epoch [5146/20000], Loss: 979.4464111328125, Entropy 211.43600463867188, Learning Rate: 0.005\n",
      "Epoch [5147/20000], Loss: 1001.8658447265625, Entropy 211.75875854492188, Learning Rate: 0.005\n",
      "Epoch [5148/20000], Loss: 1010.9827880859375, Entropy 191.47328186035156, Learning Rate: 0.005\n",
      "Epoch [5149/20000], Loss: 1010.3417358398438, Entropy 187.89312744140625, Learning Rate: 0.005\n",
      "Epoch [5150/20000], Loss: 990.609619140625, Entropy 206.00631713867188, Learning Rate: 0.005\n",
      "Epoch [5151/20000], Loss: 1007.1715698242188, Entropy 209.9959259033203, Learning Rate: 0.005\n",
      "Epoch [5152/20000], Loss: 1028.031982421875, Entropy 193.63815307617188, Learning Rate: 0.005\n",
      "Epoch [5153/20000], Loss: 977.0690307617188, Entropy 219.4968719482422, Learning Rate: 0.005\n",
      "Epoch [5154/20000], Loss: 990.3580322265625, Entropy 218.17166137695312, Learning Rate: 0.005\n",
      "Epoch [5155/20000], Loss: 993.8635864257812, Entropy 219.7267303466797, Learning Rate: 0.005\n",
      "Epoch [5156/20000], Loss: 992.837646484375, Entropy 197.11622619628906, Learning Rate: 0.005\n",
      "Epoch [5157/20000], Loss: 994.643798828125, Entropy 203.76380920410156, Learning Rate: 0.005\n",
      "Epoch [5158/20000], Loss: 1021.0436401367188, Entropy 198.67425537109375, Learning Rate: 0.005\n",
      "Epoch [5159/20000], Loss: 987.3023071289062, Entropy 210.36859130859375, Learning Rate: 0.005\n",
      "Epoch [5160/20000], Loss: 987.0139770507812, Entropy 211.51910400390625, Learning Rate: 0.005\n",
      "Epoch [5161/20000], Loss: 996.5208129882812, Entropy 196.5935516357422, Learning Rate: 0.005\n",
      "Epoch [5162/20000], Loss: 980.4788818359375, Entropy 213.63671875, Learning Rate: 0.005\n",
      "Epoch [5163/20000], Loss: 1004.9046020507812, Entropy 206.55450439453125, Learning Rate: 0.005\n",
      "Epoch [5164/20000], Loss: 1004.8442993164062, Entropy 219.4850311279297, Learning Rate: 0.005\n",
      "Epoch [5165/20000], Loss: 990.4781494140625, Entropy 210.42942810058594, Learning Rate: 0.005\n",
      "Epoch [5166/20000], Loss: 980.3243408203125, Entropy 212.43418884277344, Learning Rate: 0.005\n",
      "Epoch [5167/20000], Loss: 979.1187133789062, Entropy 219.36968994140625, Learning Rate: 0.005\n",
      "Epoch [5168/20000], Loss: 1001.946044921875, Entropy 195.20468139648438, Learning Rate: 0.005\n",
      "Epoch [5169/20000], Loss: 979.2276611328125, Entropy 212.8250732421875, Learning Rate: 0.005\n",
      "Epoch [5170/20000], Loss: 976.6410522460938, Entropy 216.89996337890625, Learning Rate: 0.005\n",
      "Epoch [5171/20000], Loss: 983.7401123046875, Entropy 214.49766540527344, Learning Rate: 0.005\n",
      "Epoch [5172/20000], Loss: 969.7573852539062, Entropy 222.7276153564453, Learning Rate: 0.005\n",
      "Epoch [5173/20000], Loss: 974.0986938476562, Entropy 233.1280059814453, Learning Rate: 0.005\n",
      "Epoch [5174/20000], Loss: 973.0025634765625, Entropy 218.61732482910156, Learning Rate: 0.005\n",
      "Epoch [5175/20000], Loss: 997.3387451171875, Entropy 226.40293884277344, Learning Rate: 0.005\n",
      "Epoch [5176/20000], Loss: 994.6009521484375, Entropy 238.41946411132812, Learning Rate: 0.005\n",
      "Epoch [5177/20000], Loss: 982.6904296875, Entropy 220.40945434570312, Learning Rate: 0.005\n",
      "Epoch [5178/20000], Loss: 973.2684326171875, Entropy 230.19224548339844, Learning Rate: 0.005\n",
      "Epoch [5179/20000], Loss: 993.0413208007812, Entropy 208.6785125732422, Learning Rate: 0.005\n",
      "Epoch [5180/20000], Loss: 964.7223510742188, Entropy 233.40936279296875, Learning Rate: 0.005\n",
      "Epoch [5181/20000], Loss: 959.3637084960938, Entropy 220.3137969970703, Learning Rate: 0.005\n",
      "Epoch [5182/20000], Loss: 985.4031372070312, Entropy 216.38275146484375, Learning Rate: 0.005\n",
      "Epoch [5183/20000], Loss: 998.0241088867188, Entropy 229.4075164794922, Learning Rate: 0.005\n",
      "Epoch [5184/20000], Loss: 987.5192260742188, Entropy 237.62811279296875, Learning Rate: 0.005\n",
      "Epoch [5185/20000], Loss: 967.1860961914062, Entropy 230.0409393310547, Learning Rate: 0.005\n",
      "Epoch [5186/20000], Loss: 963.81884765625, Entropy 234.74253845214844, Learning Rate: 0.005\n",
      "Epoch [5187/20000], Loss: 952.740966796875, Entropy 230.83253479003906, Learning Rate: 0.005\n",
      "Epoch [5188/20000], Loss: 958.7160034179688, Entropy 237.8872528076172, Learning Rate: 0.005\n",
      "Epoch [5189/20000], Loss: 1007.8726196289062, Entropy 223.04998779296875, Learning Rate: 0.005\n",
      "Epoch [5190/20000], Loss: 993.1113891601562, Entropy 223.7246856689453, Learning Rate: 0.005\n",
      "Epoch [5191/20000], Loss: 962.6516723632812, Entropy 227.6067657470703, Learning Rate: 0.005\n",
      "Epoch [5192/20000], Loss: 946.7365112304688, Entropy 239.0131378173828, Learning Rate: 0.005\n",
      "Epoch [5193/20000], Loss: 989.3115844726562, Entropy 225.15179443359375, Learning Rate: 0.005\n",
      "Epoch [5194/20000], Loss: 990.312744140625, Entropy 238.76304626464844, Learning Rate: 0.005\n",
      "Epoch [5195/20000], Loss: 987.2735595703125, Entropy 235.71560668945312, Learning Rate: 0.005\n",
      "Epoch [5196/20000], Loss: 968.384765625, Entropy 239.10995483398438, Learning Rate: 0.005\n",
      "Epoch [5197/20000], Loss: 997.2220458984375, Entropy 238.09347534179688, Learning Rate: 0.005\n",
      "Epoch [5198/20000], Loss: 975.2388916015625, Entropy 235.13394165039062, Learning Rate: 0.005\n",
      "Epoch [5199/20000], Loss: 978.2636108398438, Entropy 240.8533172607422, Learning Rate: 0.005\n",
      "Epoch [5200/20000], Loss: 962.8133544921875, Entropy 253.87474060058594, Learning Rate: 0.005\n",
      "Epoch [5201/20000], Loss: 953.2314453125, Entropy 258.6452941894531, Learning Rate: 0.005\n",
      "Epoch [5202/20000], Loss: 977.374267578125, Entropy 237.53759765625, Learning Rate: 0.005\n",
      "Epoch [5203/20000], Loss: 970.9448852539062, Entropy 240.37957763671875, Learning Rate: 0.005\n",
      "Epoch [5204/20000], Loss: 946.2091674804688, Entropy 235.9763946533203, Learning Rate: 0.005\n",
      "Epoch [5205/20000], Loss: 970.22119140625, Entropy 238.12257385253906, Learning Rate: 0.005\n",
      "Epoch [5206/20000], Loss: 972.9910278320312, Entropy 241.8214569091797, Learning Rate: 0.005\n",
      "Epoch [5207/20000], Loss: 962.3876342773438, Entropy 233.58135986328125, Learning Rate: 0.005\n",
      "Epoch [5208/20000], Loss: 954.2540893554688, Entropy 248.08087158203125, Learning Rate: 0.005\n",
      "Epoch [5209/20000], Loss: 984.7872314453125, Entropy 238.79786682128906, Learning Rate: 0.005\n",
      "Epoch [5210/20000], Loss: 967.275634765625, Entropy 249.83230590820312, Learning Rate: 0.005\n",
      "Epoch [5211/20000], Loss: 965.060302734375, Entropy 239.6141357421875, Learning Rate: 0.005\n",
      "Epoch [5212/20000], Loss: 971.9297485351562, Entropy 251.2802276611328, Learning Rate: 0.005\n",
      "Epoch [5213/20000], Loss: 948.2254638671875, Entropy 263.12060546875, Learning Rate: 0.005\n",
      "Epoch [5214/20000], Loss: 965.650390625, Entropy 248.07589721679688, Learning Rate: 0.005\n",
      "Epoch [5215/20000], Loss: 959.8629150390625, Entropy 257.51220703125, Learning Rate: 0.005\n",
      "Epoch [5216/20000], Loss: 970.3690795898438, Entropy 256.50396728515625, Learning Rate: 0.005\n",
      "Epoch [5217/20000], Loss: 942.5419311523438, Entropy 255.6497039794922, Learning Rate: 0.005\n",
      "Epoch [5218/20000], Loss: 937.7457885742188, Entropy 256.05499267578125, Learning Rate: 0.005\n",
      "Epoch [5219/20000], Loss: 956.48486328125, Entropy 252.85606384277344, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5220/20000], Loss: 975.6917724609375, Entropy 258.6478576660156, Learning Rate: 0.005\n",
      "Epoch [5221/20000], Loss: 971.5491943359375, Entropy 252.09022521972656, Learning Rate: 0.005\n",
      "Epoch [5222/20000], Loss: 942.410400390625, Entropy 262.8252868652344, Learning Rate: 0.005\n",
      "Epoch [5223/20000], Loss: 938.114013671875, Entropy 254.13278198242188, Learning Rate: 0.005\n",
      "Epoch [5224/20000], Loss: 926.52197265625, Entropy 275.0264892578125, Learning Rate: 0.005\n",
      "Epoch [5225/20000], Loss: 964.4249267578125, Entropy 256.7449951171875, Learning Rate: 0.005\n",
      "Epoch [5226/20000], Loss: 956.215576171875, Entropy 260.7606506347656, Learning Rate: 0.005\n",
      "Epoch [5227/20000], Loss: 942.430908203125, Entropy 265.3178405761719, Learning Rate: 0.005\n",
      "Epoch [5228/20000], Loss: 941.4050903320312, Entropy 267.17303466796875, Learning Rate: 0.005\n",
      "Epoch [5229/20000], Loss: 927.296142578125, Entropy 269.3241271972656, Learning Rate: 0.005\n",
      "Epoch [5230/20000], Loss: 950.551513671875, Entropy 248.56358337402344, Learning Rate: 0.005\n",
      "Epoch [5231/20000], Loss: 960.15087890625, Entropy 252.97532653808594, Learning Rate: 0.005\n",
      "Epoch [5232/20000], Loss: 960.8546142578125, Entropy 248.39659118652344, Learning Rate: 0.005\n",
      "Epoch [5233/20000], Loss: 929.1988525390625, Entropy 265.7232666015625, Learning Rate: 0.005\n",
      "Epoch [5234/20000], Loss: 955.0789184570312, Entropy 267.82135009765625, Learning Rate: 0.005\n",
      "Epoch [5235/20000], Loss: 946.2794799804688, Entropy 254.90155029296875, Learning Rate: 0.005\n",
      "Epoch [5236/20000], Loss: 940.745361328125, Entropy 270.4664001464844, Learning Rate: 0.005\n",
      "Epoch [5237/20000], Loss: 922.89208984375, Entropy 267.6890869140625, Learning Rate: 0.005\n",
      "Epoch [5238/20000], Loss: 959.6795654296875, Entropy 249.22059631347656, Learning Rate: 0.005\n",
      "Epoch [5239/20000], Loss: 938.23828125, Entropy 272.1686706542969, Learning Rate: 0.005\n",
      "Epoch [5240/20000], Loss: 970.6838989257812, Entropy 254.29913330078125, Learning Rate: 0.005\n",
      "Epoch [5241/20000], Loss: 950.7698974609375, Entropy 276.9377136230469, Learning Rate: 0.005\n",
      "Epoch [5242/20000], Loss: 981.2396850585938, Entropy 249.2478790283203, Learning Rate: 0.005\n",
      "Epoch [5243/20000], Loss: 949.1415405273438, Entropy 267.41046142578125, Learning Rate: 0.005\n",
      "Epoch [5244/20000], Loss: 953.985107421875, Entropy 260.7207336425781, Learning Rate: 0.005\n",
      "Epoch [5245/20000], Loss: 992.2324829101562, Entropy 254.9638214111328, Learning Rate: 0.005\n",
      "Epoch [5246/20000], Loss: 934.8148193359375, Entropy 268.5489196777344, Learning Rate: 0.005\n",
      "Epoch [5247/20000], Loss: 929.1356201171875, Entropy 279.5683288574219, Learning Rate: 0.005\n",
      "Epoch [5248/20000], Loss: 941.1524658203125, Entropy 283.1986999511719, Learning Rate: 0.005\n",
      "Epoch [5249/20000], Loss: 987.7869873046875, Entropy 263.8818359375, Learning Rate: 0.005\n",
      "Epoch [5250/20000], Loss: 981.1810913085938, Entropy 263.07867431640625, Learning Rate: 0.005\n",
      "Epoch [5251/20000], Loss: 942.1204223632812, Entropy 282.00982666015625, Learning Rate: 0.005\n",
      "Epoch [5252/20000], Loss: 936.727294921875, Entropy 281.1036376953125, Learning Rate: 0.005\n",
      "Epoch [5253/20000], Loss: 955.5447998046875, Entropy 278.2640686035156, Learning Rate: 0.005\n",
      "Epoch [5254/20000], Loss: 957.2501220703125, Entropy 262.7232971191406, Learning Rate: 0.005\n",
      "Epoch [5255/20000], Loss: 961.4970092773438, Entropy 262.88946533203125, Learning Rate: 0.005\n",
      "Epoch [5256/20000], Loss: 943.6884765625, Entropy 269.0119934082031, Learning Rate: 0.005\n",
      "Epoch [5257/20000], Loss: 921.40478515625, Entropy 288.79296875, Learning Rate: 0.005\n",
      "Epoch [5258/20000], Loss: 932.6241455078125, Entropy 283.6183166503906, Learning Rate: 0.005\n",
      "Epoch [5259/20000], Loss: 945.6577758789062, Entropy 264.77056884765625, Learning Rate: 0.005\n",
      "Epoch [5260/20000], Loss: 950.0587158203125, Entropy 274.6833801269531, Learning Rate: 0.005\n",
      "Epoch [5261/20000], Loss: 955.105712890625, Entropy 274.8161315917969, Learning Rate: 0.005\n",
      "Epoch [5262/20000], Loss: 931.9501953125, Entropy 287.9548034667969, Learning Rate: 0.005\n",
      "Epoch [5263/20000], Loss: 931.3577880859375, Entropy 276.67041015625, Learning Rate: 0.005\n",
      "Epoch [5264/20000], Loss: 899.8397216796875, Entropy 285.6572570800781, Learning Rate: 0.005\n",
      "Epoch [5265/20000], Loss: 932.2760009765625, Entropy 291.3949890136719, Learning Rate: 0.005\n",
      "Epoch [5266/20000], Loss: 967.6761474609375, Entropy 271.547607421875, Learning Rate: 0.005\n",
      "Epoch [5267/20000], Loss: 949.441162109375, Entropy 286.3450927734375, Learning Rate: 0.005\n",
      "Epoch [5268/20000], Loss: 934.79248046875, Entropy 278.70361328125, Learning Rate: 0.005\n",
      "Epoch [5269/20000], Loss: 983.6085205078125, Entropy 288.456787109375, Learning Rate: 0.005\n",
      "Epoch [5270/20000], Loss: 952.8713989257812, Entropy 290.76275634765625, Learning Rate: 0.005\n",
      "Epoch [5271/20000], Loss: 923.1492309570312, Entropy 302.82391357421875, Learning Rate: 0.005\n",
      "Epoch [5272/20000], Loss: 944.0932006835938, Entropy 288.21356201171875, Learning Rate: 0.005\n",
      "Epoch [5273/20000], Loss: 930.8021240234375, Entropy 272.0589904785156, Learning Rate: 0.005\n",
      "Epoch [5274/20000], Loss: 975.3079833984375, Entropy 273.5203552246094, Learning Rate: 0.005\n",
      "Epoch [5275/20000], Loss: 926.1112060546875, Entropy 295.19287109375, Learning Rate: 0.005\n",
      "Epoch [5276/20000], Loss: 944.1427612304688, Entropy 284.53045654296875, Learning Rate: 0.005\n",
      "Epoch [5277/20000], Loss: 915.742431640625, Entropy 276.8385925292969, Learning Rate: 0.005\n",
      "Epoch [5278/20000], Loss: 939.7510986328125, Entropy 277.3068542480469, Learning Rate: 0.005\n",
      "Epoch [5279/20000], Loss: 964.31591796875, Entropy 269.0565185546875, Learning Rate: 0.005\n",
      "Epoch [5280/20000], Loss: 973.127685546875, Entropy 277.3362731933594, Learning Rate: 0.005\n",
      "Epoch [5281/20000], Loss: 918.2317504882812, Entropy 279.64324951171875, Learning Rate: 0.005\n",
      "Epoch [5282/20000], Loss: 946.7042846679688, Entropy 296.33856201171875, Learning Rate: 0.005\n",
      "Epoch [5283/20000], Loss: 924.6424560546875, Entropy 302.5704650878906, Learning Rate: 0.005\n",
      "Epoch [5284/20000], Loss: 946.9462890625, Entropy 289.7121887207031, Learning Rate: 0.005\n",
      "Epoch [5285/20000], Loss: 938.4036254882812, Entropy 297.72625732421875, Learning Rate: 0.005\n",
      "Epoch [5286/20000], Loss: 965.919189453125, Entropy 285.6600341796875, Learning Rate: 0.005\n",
      "Epoch [5287/20000], Loss: 933.608154296875, Entropy 291.9697265625, Learning Rate: 0.005\n",
      "Epoch [5288/20000], Loss: 945.6224365234375, Entropy 297.1028747558594, Learning Rate: 0.005\n",
      "Epoch [5289/20000], Loss: 953.52294921875, Entropy 295.4104919433594, Learning Rate: 0.005\n",
      "Epoch [5290/20000], Loss: 950.9178466796875, Entropy 288.6486511230469, Learning Rate: 0.005\n",
      "Epoch [5291/20000], Loss: 960.1868896484375, Entropy 285.2662353515625, Learning Rate: 0.005\n",
      "Epoch [5292/20000], Loss: 961.9580688476562, Entropy 291.90557861328125, Learning Rate: 0.005\n",
      "Epoch [5293/20000], Loss: 964.514892578125, Entropy 303.4276428222656, Learning Rate: 0.005\n",
      "Epoch [5294/20000], Loss: 964.8892822265625, Entropy 290.3085021972656, Learning Rate: 0.005\n",
      "Epoch [5295/20000], Loss: 952.9683227539062, Entropy 296.64459228515625, Learning Rate: 0.005\n",
      "Epoch [5296/20000], Loss: 971.5231323242188, Entropy 286.24969482421875, Learning Rate: 0.005\n",
      "Epoch [5297/20000], Loss: 953.9840087890625, Entropy 278.5808410644531, Learning Rate: 0.005\n",
      "Epoch [5298/20000], Loss: 948.134521484375, Entropy 288.64306640625, Learning Rate: 0.005\n",
      "Epoch [5299/20000], Loss: 935.62255859375, Entropy 298.7406311035156, Learning Rate: 0.005\n",
      "Epoch [5300/20000], Loss: 956.8216552734375, Entropy 295.3020324707031, Learning Rate: 0.005\n",
      "Epoch [5301/20000], Loss: 907.1927490234375, Entropy 307.5852355957031, Learning Rate: 0.005\n",
      "Epoch [5302/20000], Loss: 943.0152587890625, Entropy 290.7521667480469, Learning Rate: 0.005\n",
      "Epoch [5303/20000], Loss: 941.3619384765625, Entropy 304.1037292480469, Learning Rate: 0.005\n",
      "Epoch [5304/20000], Loss: 912.5011596679688, Entropy 304.26531982421875, Learning Rate: 0.005\n",
      "Epoch [5305/20000], Loss: 926.241943359375, Entropy 303.8498229980469, Learning Rate: 0.005\n",
      "Epoch [5306/20000], Loss: 947.3775634765625, Entropy 305.9201354980469, Learning Rate: 0.005\n",
      "Epoch [5307/20000], Loss: 980.581787109375, Entropy 293.3735046386719, Learning Rate: 0.005\n",
      "Epoch [5308/20000], Loss: 972.8084716796875, Entropy 294.0838623046875, Learning Rate: 0.005\n",
      "Epoch [5309/20000], Loss: 919.3492431640625, Entropy 299.0568542480469, Learning Rate: 0.005\n",
      "Epoch [5310/20000], Loss: 916.92529296875, Entropy 285.7257080078125, Learning Rate: 0.005\n",
      "Epoch [5311/20000], Loss: 914.859375, Entropy 312.3882751464844, Learning Rate: 0.005\n",
      "Epoch [5312/20000], Loss: 921.4118041992188, Entropy 305.33477783203125, Learning Rate: 0.005\n",
      "Epoch [5313/20000], Loss: 950.449951171875, Entropy 297.8310241699219, Learning Rate: 0.005\n",
      "Epoch [5314/20000], Loss: 942.122314453125, Entropy 291.1212158203125, Learning Rate: 0.005\n",
      "Epoch [5315/20000], Loss: 959.30908203125, Entropy 289.1833190917969, Learning Rate: 0.005\n",
      "Epoch [5316/20000], Loss: 930.82421875, Entropy 287.6468200683594, Learning Rate: 0.005\n",
      "Epoch [5317/20000], Loss: 982.569091796875, Entropy 282.1047058105469, Learning Rate: 0.005\n",
      "Epoch [5318/20000], Loss: 975.9793701171875, Entropy 293.4748840332031, Learning Rate: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5319/20000], Loss: 934.2244873046875, Entropy 299.9886474609375, Learning Rate: 0.005\n",
      "Epoch [5320/20000], Loss: 910.15966796875, Entropy 312.9920349121094, Learning Rate: 0.005\n",
      "Epoch [5321/20000], Loss: 898.7178955078125, Entropy 314.8802490234375, Learning Rate: 0.005\n",
      "Epoch [5322/20000], Loss: 934.3243408203125, Entropy 308.7377014160156, Learning Rate: 0.005\n",
      "Epoch [5323/20000], Loss: 895.4921264648438, Entropy 306.26898193359375, Learning Rate: 0.005\n",
      "Epoch [5324/20000], Loss: 906.8203125, Entropy 306.2082214355469, Learning Rate: 0.005\n",
      "Epoch [5325/20000], Loss: 921.271240234375, Entropy 299.1564025878906, Learning Rate: 0.005\n",
      "Epoch [5326/20000], Loss: 900.9824829101562, Entropy 313.87469482421875, Learning Rate: 0.005\n",
      "Epoch [5327/20000], Loss: 948.405517578125, Entropy 293.1268005371094, Learning Rate: 0.005\n",
      "Epoch [5328/20000], Loss: 930.3282470703125, Entropy 316.4074401855469, Learning Rate: 0.005\n",
      "Epoch [5329/20000], Loss: 929.4189453125, Entropy 308.1824035644531, Learning Rate: 0.005\n",
      "Epoch [5330/20000], Loss: 917.755859375, Entropy 304.0260009765625, Learning Rate: 0.005\n",
      "Epoch [5331/20000], Loss: 886.5509033203125, Entropy 310.9440612792969, Learning Rate: 0.005\n",
      "Epoch [5332/20000], Loss: 927.40087890625, Entropy 305.0047912597656, Learning Rate: 0.005\n",
      "Epoch [5333/20000], Loss: 927.3107299804688, Entropy 326.10308837890625, Learning Rate: 0.005\n",
      "Epoch [5334/20000], Loss: 952.8602294921875, Entropy 317.2435302734375, Learning Rate: 0.005\n",
      "Epoch [5335/20000], Loss: 941.3507080078125, Entropy 313.1004333496094, Learning Rate: 0.005\n",
      "Epoch [5336/20000], Loss: 927.9866943359375, Entropy 314.3650207519531, Learning Rate: 0.005\n",
      "Epoch [5337/20000], Loss: 946.698486328125, Entropy 310.8059387207031, Learning Rate: 0.005\n",
      "Epoch [5338/20000], Loss: 946.715576171875, Entropy 312.2088928222656, Learning Rate: 0.005\n",
      "Epoch [5339/20000], Loss: 947.3512573242188, Entropy 304.70745849609375, Learning Rate: 0.005\n",
      "Epoch [5340/20000], Loss: 956.9277954101562, Entropy 308.26129150390625, Learning Rate: 0.005\n",
      "Epoch [5341/20000], Loss: 898.3351440429688, Entropy 311.07135009765625, Learning Rate: 0.005\n",
      "Epoch [5342/20000], Loss: 886.1448364257812, Entropy 331.07269287109375, Learning Rate: 0.005\n",
      "Epoch [5343/20000], Loss: 915.43505859375, Entropy 319.8251037597656, Learning Rate: 0.005\n",
      "Epoch [5344/20000], Loss: 923.0542602539062, Entropy 304.69915771484375, Learning Rate: 0.005\n",
      "Epoch [5345/20000], Loss: 956.5848388671875, Entropy 308.7246398925781, Learning Rate: 0.005\n",
      "Epoch [5346/20000], Loss: 922.8390502929688, Entropy 308.88079833984375, Learning Rate: 0.005\n",
      "Epoch [5347/20000], Loss: 928.74169921875, Entropy 306.2442626953125, Learning Rate: 0.005\n",
      "Epoch [5348/20000], Loss: 929.246337890625, Entropy 319.9906921386719, Learning Rate: 0.005\n",
      "Epoch [5349/20000], Loss: 934.7311401367188, Entropy 303.76824951171875, Learning Rate: 0.005\n",
      "Epoch [5350/20000], Loss: 906.1194458007812, Entropy 315.98773193359375, Learning Rate: 0.005\n",
      "Epoch [5351/20000], Loss: 961.8203125, Entropy 306.5174865722656, Learning Rate: 0.005\n",
      "Epoch [5352/20000], Loss: 952.626953125, Entropy 309.6478271484375, Learning Rate: 0.005\n",
      "Epoch [5353/20000], Loss: 908.619384765625, Entropy 312.5169372558594, Learning Rate: 0.005\n",
      "Epoch [5354/20000], Loss: 939.825927734375, Entropy 325.1824035644531, Learning Rate: 0.005\n",
      "Epoch [5355/20000], Loss: 975.16455078125, Entropy 324.1933898925781, Learning Rate: 0.005\n",
      "Epoch [5356/20000], Loss: 923.8416137695312, Entropy 308.94769287109375, Learning Rate: 0.005\n",
      "Epoch [5357/20000], Loss: 937.8081665039062, Entropy 312.67071533203125, Learning Rate: 0.005\n",
      "Epoch [5358/20000], Loss: 933.886474609375, Entropy 319.8009948730469, Learning Rate: 0.005\n",
      "Epoch [5359/20000], Loss: 942.44873046875, Entropy 310.9777526855469, Learning Rate: 0.005\n",
      "Epoch [5360/20000], Loss: 912.7958984375, Entropy 328.5934753417969, Learning Rate: 0.005\n",
      "Epoch [5361/20000], Loss: 900.9349365234375, Entropy 324.0517883300781, Learning Rate: 0.005\n",
      "Epoch [5362/20000], Loss: 928.6951904296875, Entropy 320.1990661621094, Learning Rate: 0.005\n",
      "Epoch [5363/20000], Loss: 921.5215454101562, Entropy 316.18853759765625, Learning Rate: 0.005\n",
      "Epoch [5364/20000], Loss: 928.1048583984375, Entropy 321.8645935058594, Learning Rate: 0.005\n",
      "Epoch [5365/20000], Loss: 981.2713623046875, Entropy 304.50390625, Learning Rate: 0.005\n",
      "Epoch [5366/20000], Loss: 924.936767578125, Entropy 321.3417053222656, Learning Rate: 0.005\n",
      "Epoch [5367/20000], Loss: 920.0589599609375, Entropy 325.3577575683594, Learning Rate: 0.005\n",
      "Epoch [5368/20000], Loss: 922.6297607421875, Entropy 329.86083984375, Learning Rate: 0.005\n",
      "Epoch [5369/20000], Loss: 910.65625, Entropy 342.2057800292969, Learning Rate: 0.005\n",
      "Epoch [5370/20000], Loss: 928.43994140625, Entropy 322.3757629394531, Learning Rate: 0.005\n",
      "Epoch [5371/20000], Loss: 912.5611572265625, Entropy 319.8503112792969, Learning Rate: 0.005\n",
      "Epoch [5372/20000], Loss: 909.2897338867188, Entropy 328.31378173828125, Learning Rate: 0.005\n",
      "Epoch [5373/20000], Loss: 959.1441650390625, Entropy 308.4881896972656, Learning Rate: 0.005\n",
      "Epoch [5374/20000], Loss: 922.7201538085938, Entropy 312.88922119140625, Learning Rate: 0.005\n",
      "Epoch [5375/20000], Loss: 931.392333984375, Entropy 321.8998718261719, Learning Rate: 0.005\n",
      "Epoch [5376/20000], Loss: 921.5650634765625, Entropy 309.201904296875, Learning Rate: 0.005\n",
      "Epoch [5377/20000], Loss: 933.2333374023438, Entropy 318.82049560546875, Learning Rate: 0.005\n",
      "Epoch [5378/20000], Loss: 927.9569702148438, Entropy 325.83929443359375, Learning Rate: 0.005\n",
      "Epoch [5379/20000], Loss: 950.655517578125, Entropy 323.4602355957031, Learning Rate: 0.005\n",
      "Epoch [5380/20000], Loss: 920.75439453125, Entropy 310.9925231933594, Learning Rate: 0.005\n",
      "Epoch [5381/20000], Loss: 909.8052978515625, Entropy 312.3543701171875, Learning Rate: 0.005\n",
      "Epoch [5382/20000], Loss: 934.6212158203125, Entropy 341.2785949707031, Learning Rate: 0.005\n",
      "Epoch [5383/20000], Loss: 930.43505859375, Entropy 312.8797912597656, Learning Rate: 0.005\n",
      "Epoch [5384/20000], Loss: 918.09326171875, Entropy 327.2466735839844, Learning Rate: 0.005\n",
      "Epoch [5385/20000], Loss: 920.1600341796875, Entropy 324.9465637207031, Learning Rate: 0.005\n",
      "Epoch [5386/20000], Loss: 919.4859619140625, Entropy 322.3753356933594, Learning Rate: 0.005\n",
      "Epoch [5387/20000], Loss: 947.7816162109375, Entropy 333.3828125, Learning Rate: 0.005\n",
      "Epoch [5388/20000], Loss: 923.409423828125, Entropy 321.1094970703125, Learning Rate: 0.005\n",
      "Epoch [5389/20000], Loss: 905.960205078125, Entropy 329.3121337890625, Learning Rate: 0.005\n",
      "Epoch [5390/20000], Loss: 904.846435546875, Entropy 343.2673645019531, Learning Rate: 0.005\n",
      "Epoch [5391/20000], Loss: 941.1163330078125, Entropy 315.0636901855469, Learning Rate: 0.005\n",
      "Epoch [5392/20000], Loss: 926.595947265625, Entropy 325.7143249511719, Learning Rate: 0.005\n",
      "Epoch [5393/20000], Loss: 905.287353515625, Entropy 332.5965576171875, Learning Rate: 0.005\n",
      "Epoch [5394/20000], Loss: 910.4224853515625, Entropy 328.5726623535156, Learning Rate: 0.005\n",
      "Epoch [5395/20000], Loss: 932.4158325195312, Entropy 321.49517822265625, Learning Rate: 0.005\n",
      "Epoch [5396/20000], Loss: 935.459228515625, Entropy 333.5150451660156, Learning Rate: 0.005\n",
      "Epoch [5397/20000], Loss: 941.624755859375, Entropy 324.50390625, Learning Rate: 0.005\n",
      "Epoch [5398/20000], Loss: 897.2459716796875, Entropy 331.5648498535156, Learning Rate: 0.005\n",
      "Epoch [5399/20000], Loss: 948.5469970703125, Entropy 324.8923034667969, Learning Rate: 0.005\n",
      "Epoch [5400/20000], Loss: 912.893798828125, Entropy 340.7743225097656, Learning Rate: 0.005\n",
      "Epoch [5401/20000], Loss: 916.6951904296875, Entropy 332.2601623535156, Learning Rate: 0.005\n",
      "Epoch [5402/20000], Loss: 913.3033447265625, Entropy 341.621826171875, Learning Rate: 0.005\n",
      "Epoch [5403/20000], Loss: 929.769287109375, Entropy 333.6539001464844, Learning Rate: 0.005\n",
      "Epoch [5404/20000], Loss: 907.9755859375, Entropy 327.2366638183594, Learning Rate: 0.005\n",
      "Epoch [5405/20000], Loss: 904.2566528320312, Entropy 323.31341552734375, Learning Rate: 0.005\n",
      "Epoch [5406/20000], Loss: 893.7584228515625, Entropy 340.4949951171875, Learning Rate: 0.005\n",
      "Epoch [5407/20000], Loss: 958.4069213867188, Entropy 340.49700927734375, Learning Rate: 0.005\n",
      "Epoch [5408/20000], Loss: 925.4390258789062, Entropy 318.79595947265625, Learning Rate: 0.005\n",
      "Epoch [5409/20000], Loss: 910.21875, Entropy 338.6589660644531, Learning Rate: 0.005\n",
      "Epoch [5410/20000], Loss: 904.7991333007812, Entropy 332.82330322265625, Learning Rate: 0.005\n",
      "Epoch [5411/20000], Loss: 923.321044921875, Entropy 330.5915832519531, Learning Rate: 0.005\n",
      "Epoch [5412/20000], Loss: 922.806640625, Entropy 329.8049011230469, Learning Rate: 0.005\n",
      "Epoch [5413/20000], Loss: 932.5760498046875, Entropy 338.8734436035156, Learning Rate: 0.005\n",
      "Epoch [5414/20000], Loss: 921.497314453125, Entropy 346.212646484375, Learning Rate: 0.005\n",
      "Epoch [5415/20000], Loss: 935.3985595703125, Entropy 334.3572692871094, Learning Rate: 0.0025\n",
      "Epoch [5416/20000], Loss: 911.771484375, Entropy 341.2043762207031, Learning Rate: 0.0025\n",
      "Epoch [5417/20000], Loss: 924.945068359375, Entropy 339.0699157714844, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5418/20000], Loss: 939.8115234375, Entropy 334.6312561035156, Learning Rate: 0.0025\n",
      "Epoch [5419/20000], Loss: 860.5261840820312, Entropy 338.18853759765625, Learning Rate: 0.0025\n",
      "Epoch [5420/20000], Loss: 933.1298828125, Entropy 315.0207214355469, Learning Rate: 0.0025\n",
      "Epoch [5421/20000], Loss: 894.4286499023438, Entropy 343.02447509765625, Learning Rate: 0.0025\n",
      "Epoch [5422/20000], Loss: 931.329345703125, Entropy 335.1008605957031, Learning Rate: 0.0025\n",
      "Epoch [5423/20000], Loss: 894.6292114257812, Entropy 343.40545654296875, Learning Rate: 0.0025\n",
      "Epoch [5424/20000], Loss: 926.6788330078125, Entropy 345.4930114746094, Learning Rate: 0.0025\n",
      "Epoch [5425/20000], Loss: 918.6102294921875, Entropy 328.0767517089844, Learning Rate: 0.0025\n",
      "Epoch [5426/20000], Loss: 908.2010498046875, Entropy 347.386474609375, Learning Rate: 0.0025\n",
      "Epoch [5427/20000], Loss: 888.951416015625, Entropy 349.9767761230469, Learning Rate: 0.0025\n",
      "Epoch [5428/20000], Loss: 900.9921264648438, Entropy 350.90826416015625, Learning Rate: 0.0025\n",
      "Epoch [5429/20000], Loss: 897.8211669921875, Entropy 340.3331604003906, Learning Rate: 0.0025\n",
      "Epoch [5430/20000], Loss: 916.091796875, Entropy 351.6922607421875, Learning Rate: 0.0025\n",
      "Epoch [5431/20000], Loss: 902.4566650390625, Entropy 338.8426208496094, Learning Rate: 0.0025\n",
      "Epoch [5432/20000], Loss: 933.748046875, Entropy 318.7541809082031, Learning Rate: 0.0025\n",
      "Epoch [5433/20000], Loss: 928.2369995117188, Entropy 340.09234619140625, Learning Rate: 0.0025\n",
      "Epoch [5434/20000], Loss: 946.954833984375, Entropy 329.6330261230469, Learning Rate: 0.0025\n",
      "Epoch [5435/20000], Loss: 909.0761108398438, Entropy 335.53045654296875, Learning Rate: 0.0025\n",
      "Epoch [5436/20000], Loss: 908.7451782226562, Entropy 343.27117919921875, Learning Rate: 0.0025\n",
      "Epoch [5437/20000], Loss: 916.0016479492188, Entropy 345.99053955078125, Learning Rate: 0.0025\n",
      "Epoch [5438/20000], Loss: 932.1587524414062, Entropy 334.55975341796875, Learning Rate: 0.0025\n",
      "Epoch [5439/20000], Loss: 927.4404296875, Entropy 345.5880126953125, Learning Rate: 0.0025\n",
      "Epoch [5440/20000], Loss: 881.6679077148438, Entropy 348.96673583984375, Learning Rate: 0.0025\n",
      "Epoch [5441/20000], Loss: 944.2437744140625, Entropy 343.2523498535156, Learning Rate: 0.0025\n",
      "Epoch [5442/20000], Loss: 917.6524658203125, Entropy 340.7386169433594, Learning Rate: 0.0025\n",
      "Epoch [5443/20000], Loss: 896.2492065429688, Entropy 329.05950927734375, Learning Rate: 0.0025\n",
      "Epoch [5444/20000], Loss: 898.91748046875, Entropy 343.0419006347656, Learning Rate: 0.0025\n",
      "Epoch [5445/20000], Loss: 911.342041015625, Entropy 344.2780456542969, Learning Rate: 0.0025\n",
      "Epoch [5446/20000], Loss: 984.158203125, Entropy 332.6029357910156, Learning Rate: 0.0025\n",
      "Epoch [5447/20000], Loss: 929.2301025390625, Entropy 345.4752197265625, Learning Rate: 0.0025\n",
      "Epoch [5448/20000], Loss: 872.81005859375, Entropy 340.1163330078125, Learning Rate: 0.0025\n",
      "Epoch [5449/20000], Loss: 930.6552734375, Entropy 343.7183532714844, Learning Rate: 0.0025\n",
      "Epoch [5450/20000], Loss: 895.6636962890625, Entropy 347.09375, Learning Rate: 0.0025\n",
      "Epoch [5451/20000], Loss: 938.2426147460938, Entropy 334.29559326171875, Learning Rate: 0.0025\n",
      "Epoch [5452/20000], Loss: 934.9347534179688, Entropy 349.48297119140625, Learning Rate: 0.0025\n",
      "Epoch [5453/20000], Loss: 945.9849243164062, Entropy 333.63250732421875, Learning Rate: 0.0025\n",
      "Epoch [5454/20000], Loss: 921.5791015625, Entropy 347.1622619628906, Learning Rate: 0.0025\n",
      "Epoch [5455/20000], Loss: 913.2535400390625, Entropy 345.8692626953125, Learning Rate: 0.0025\n",
      "Epoch [5456/20000], Loss: 912.95703125, Entropy 337.2567138671875, Learning Rate: 0.0025\n",
      "Epoch [5457/20000], Loss: 926.429443359375, Entropy 329.413818359375, Learning Rate: 0.0025\n",
      "Epoch [5458/20000], Loss: 894.621826171875, Entropy 360.9693908691406, Learning Rate: 0.0025\n",
      "Epoch [5459/20000], Loss: 933.5345458984375, Entropy 336.08056640625, Learning Rate: 0.0025\n",
      "Epoch [5460/20000], Loss: 907.3704223632812, Entropy 341.43060302734375, Learning Rate: 0.0025\n",
      "Epoch [5461/20000], Loss: 888.8233642578125, Entropy 345.3961181640625, Learning Rate: 0.0025\n",
      "Epoch [5462/20000], Loss: 952.787109375, Entropy 349.3512878417969, Learning Rate: 0.0025\n",
      "Epoch [5463/20000], Loss: 881.2053833007812, Entropy 345.80523681640625, Learning Rate: 0.0025\n",
      "Epoch [5464/20000], Loss: 898.438720703125, Entropy 340.8855285644531, Learning Rate: 0.0025\n",
      "Epoch [5465/20000], Loss: 928.5775146484375, Entropy 332.6985778808594, Learning Rate: 0.0025\n",
      "Epoch [5466/20000], Loss: 928.7440185546875, Entropy 334.0198669433594, Learning Rate: 0.0025\n",
      "Epoch [5467/20000], Loss: 928.7325439453125, Entropy 351.8831481933594, Learning Rate: 0.0025\n",
      "Epoch [5468/20000], Loss: 929.618896484375, Entropy 344.8537902832031, Learning Rate: 0.0025\n",
      "Epoch [5469/20000], Loss: 903.8741455078125, Entropy 350.3528747558594, Learning Rate: 0.0025\n",
      "Epoch [5470/20000], Loss: 930.8690185546875, Entropy 349.0152282714844, Learning Rate: 0.0025\n",
      "Epoch [5471/20000], Loss: 937.69091796875, Entropy 353.6617126464844, Learning Rate: 0.0025\n",
      "Epoch [5472/20000], Loss: 916.73583984375, Entropy 351.6765441894531, Learning Rate: 0.0025\n",
      "Epoch [5473/20000], Loss: 945.4189453125, Entropy 333.646484375, Learning Rate: 0.0025\n",
      "Epoch [5474/20000], Loss: 913.89501953125, Entropy 346.6413879394531, Learning Rate: 0.0025\n",
      "Epoch [5475/20000], Loss: 877.02978515625, Entropy 363.7536315917969, Learning Rate: 0.0025\n",
      "Epoch [5476/20000], Loss: 933.4688720703125, Entropy 347.8326416015625, Learning Rate: 0.0025\n",
      "Epoch [5477/20000], Loss: 931.4412841796875, Entropy 333.1253967285156, Learning Rate: 0.0025\n",
      "Epoch [5478/20000], Loss: 898.0809326171875, Entropy 345.8006286621094, Learning Rate: 0.0025\n",
      "Epoch [5479/20000], Loss: 931.3377685546875, Entropy 346.9823303222656, Learning Rate: 0.0025\n",
      "Epoch [5480/20000], Loss: 897.0174560546875, Entropy 355.3352355957031, Learning Rate: 0.0025\n",
      "Epoch [5481/20000], Loss: 912.4713134765625, Entropy 342.2856140136719, Learning Rate: 0.0025\n",
      "Epoch [5482/20000], Loss: 927.8302001953125, Entropy 335.7071533203125, Learning Rate: 0.0025\n",
      "Epoch [5483/20000], Loss: 962.74951171875, Entropy 339.0900573730469, Learning Rate: 0.0025\n",
      "Epoch [5484/20000], Loss: 913.173828125, Entropy 338.8171691894531, Learning Rate: 0.0025\n",
      "Epoch [5485/20000], Loss: 949.5897216796875, Entropy 345.9017028808594, Learning Rate: 0.0025\n",
      "Epoch [5486/20000], Loss: 924.5367431640625, Entropy 344.8694763183594, Learning Rate: 0.0025\n",
      "Epoch [5487/20000], Loss: 932.607421875, Entropy 342.18212890625, Learning Rate: 0.0025\n",
      "Epoch [5488/20000], Loss: 906.5538330078125, Entropy 355.9273681640625, Learning Rate: 0.0025\n",
      "Epoch [5489/20000], Loss: 887.5816650390625, Entropy 345.2891845703125, Learning Rate: 0.0025\n",
      "Epoch [5490/20000], Loss: 914.3593139648438, Entropy 332.25335693359375, Learning Rate: 0.0025\n",
      "Epoch [5491/20000], Loss: 876.7905883789062, Entropy 366.75128173828125, Learning Rate: 0.0025\n",
      "Epoch [5492/20000], Loss: 944.71630859375, Entropy 344.6697692871094, Learning Rate: 0.0025\n",
      "Epoch [5493/20000], Loss: 914.3699951171875, Entropy 350.39990234375, Learning Rate: 0.0025\n",
      "Epoch [5494/20000], Loss: 928.011962890625, Entropy 342.8742980957031, Learning Rate: 0.0025\n",
      "Epoch [5495/20000], Loss: 915.9506225585938, Entropy 343.62432861328125, Learning Rate: 0.0025\n",
      "Epoch [5496/20000], Loss: 922.187255859375, Entropy 339.6356201171875, Learning Rate: 0.0025\n",
      "Epoch [5497/20000], Loss: 920.4065551757812, Entropy 342.37249755859375, Learning Rate: 0.0025\n",
      "Epoch [5498/20000], Loss: 922.8280029296875, Entropy 343.902099609375, Learning Rate: 0.0025\n",
      "Epoch [5499/20000], Loss: 945.7280883789062, Entropy 337.96612548828125, Learning Rate: 0.0025\n",
      "Epoch [5500/20000], Loss: 908.6690673828125, Entropy 339.7711181640625, Learning Rate: 0.0025\n",
      "Epoch [5501/20000], Loss: 895.7632446289062, Entropy 349.36029052734375, Learning Rate: 0.0025\n",
      "Epoch [5502/20000], Loss: 923.0706787109375, Entropy 345.6767883300781, Learning Rate: 0.0025\n",
      "Epoch [5503/20000], Loss: 911.4910278320312, Entropy 344.80584716796875, Learning Rate: 0.0025\n",
      "Epoch [5504/20000], Loss: 944.603271484375, Entropy 351.9100646972656, Learning Rate: 0.0025\n",
      "Epoch [5505/20000], Loss: 902.28076171875, Entropy 365.2142028808594, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5506/20000], Loss: 969.6090087890625, Entropy 348.2500305175781, Learning Rate: 0.0025\n",
      "Epoch [5507/20000], Loss: 889.9998779296875, Entropy 354.45068359375, Learning Rate: 0.0025\n",
      "Epoch [5508/20000], Loss: 924.1650390625, Entropy 343.1835021972656, Learning Rate: 0.0025\n",
      "Epoch [5509/20000], Loss: 879.388427734375, Entropy 354.6240539550781, Learning Rate: 0.0025\n",
      "Epoch [5510/20000], Loss: 925.2692260742188, Entropy 353.63507080078125, Learning Rate: 0.0025\n",
      "Epoch [5511/20000], Loss: 929.2362060546875, Entropy 351.3270263671875, Learning Rate: 0.0025\n",
      "Epoch [5512/20000], Loss: 928.5104370117188, Entropy 345.40057373046875, Learning Rate: 0.0025\n",
      "Epoch [5513/20000], Loss: 878.39892578125, Entropy 345.4453125, Learning Rate: 0.0025\n",
      "Epoch [5514/20000], Loss: 908.8695068359375, Entropy 353.8678894042969, Learning Rate: 0.0025\n",
      "Epoch [5515/20000], Loss: 919.43017578125, Entropy 339.3446350097656, Learning Rate: 0.0025\n",
      "Epoch [5516/20000], Loss: 900.7623291015625, Entropy 348.50927734375, Learning Rate: 0.0025\n",
      "Epoch [5517/20000], Loss: 928.7114868164062, Entropy 352.41986083984375, Learning Rate: 0.0025\n",
      "Epoch [5518/20000], Loss: 970.665771484375, Entropy 350.5956115722656, Learning Rate: 0.0025\n",
      "Epoch [5519/20000], Loss: 933.1375732421875, Entropy 350.2283630371094, Learning Rate: 0.0025\n",
      "Epoch [5520/20000], Loss: 926.7627563476562, Entropy 338.41461181640625, Learning Rate: 0.0025\n",
      "Epoch [5521/20000], Loss: 930.6380004882812, Entropy 351.13104248046875, Learning Rate: 0.0025\n",
      "Epoch [5522/20000], Loss: 911.8833618164062, Entropy 354.01007080078125, Learning Rate: 0.0025\n",
      "Epoch [5523/20000], Loss: 874.8142700195312, Entropy 360.09320068359375, Learning Rate: 0.0025\n",
      "Epoch [5524/20000], Loss: 938.1661376953125, Entropy 338.4774475097656, Learning Rate: 0.0025\n",
      "Epoch [5525/20000], Loss: 894.0820922851562, Entropy 345.81414794921875, Learning Rate: 0.0025\n",
      "Epoch [5526/20000], Loss: 883.0010986328125, Entropy 361.1968994140625, Learning Rate: 0.0025\n",
      "Epoch [5527/20000], Loss: 947.5881958007812, Entropy 348.82330322265625, Learning Rate: 0.0025\n",
      "Epoch [5528/20000], Loss: 933.6207275390625, Entropy 347.6357727050781, Learning Rate: 0.0025\n",
      "Epoch [5529/20000], Loss: 910.5819091796875, Entropy 345.0708923339844, Learning Rate: 0.0025\n",
      "Epoch [5530/20000], Loss: 945.5689697265625, Entropy 331.9789733886719, Learning Rate: 0.0025\n",
      "Epoch [5531/20000], Loss: 936.188232421875, Entropy 347.3203125, Learning Rate: 0.0025\n",
      "Epoch [5532/20000], Loss: 894.7823486328125, Entropy 361.74609375, Learning Rate: 0.0025\n",
      "Epoch [5533/20000], Loss: 942.4454345703125, Entropy 350.9275207519531, Learning Rate: 0.0025\n",
      "Epoch [5534/20000], Loss: 890.24072265625, Entropy 355.4082336425781, Learning Rate: 0.0025\n",
      "Epoch [5535/20000], Loss: 885.9290771484375, Entropy 366.982177734375, Learning Rate: 0.0025\n",
      "Epoch [5536/20000], Loss: 918.2146606445312, Entropy 355.58013916015625, Learning Rate: 0.0025\n",
      "Epoch [5537/20000], Loss: 920.3448486328125, Entropy 341.4203186035156, Learning Rate: 0.0025\n",
      "Epoch [5538/20000], Loss: 909.7232666015625, Entropy 361.0518798828125, Learning Rate: 0.0025\n",
      "Epoch [5539/20000], Loss: 893.663330078125, Entropy 360.209716796875, Learning Rate: 0.0025\n",
      "Epoch [5540/20000], Loss: 930.2973022460938, Entropy 332.50836181640625, Learning Rate: 0.0025\n",
      "Epoch [5541/20000], Loss: 885.63916015625, Entropy 358.5879211425781, Learning Rate: 0.0025\n",
      "Epoch [5542/20000], Loss: 917.1499633789062, Entropy 351.82769775390625, Learning Rate: 0.0025\n",
      "Epoch [5543/20000], Loss: 897.055908203125, Entropy 361.9953918457031, Learning Rate: 0.0025\n",
      "Epoch [5544/20000], Loss: 888.509033203125, Entropy 356.3090515136719, Learning Rate: 0.0025\n",
      "Epoch [5545/20000], Loss: 892.8438720703125, Entropy 356.6594543457031, Learning Rate: 0.0025\n",
      "Epoch [5546/20000], Loss: 923.3799438476562, Entropy 336.25592041015625, Learning Rate: 0.0025\n",
      "Epoch [5547/20000], Loss: 889.3090209960938, Entropy 342.34014892578125, Learning Rate: 0.0025\n",
      "Epoch [5548/20000], Loss: 895.080322265625, Entropy 365.7021789550781, Learning Rate: 0.0025\n",
      "Epoch [5549/20000], Loss: 926.0923461914062, Entropy 330.34820556640625, Learning Rate: 0.0025\n",
      "Epoch [5550/20000], Loss: 906.2218017578125, Entropy 368.21484375, Learning Rate: 0.0025\n",
      "Epoch [5551/20000], Loss: 881.7392578125, Entropy 348.5418701171875, Learning Rate: 0.0025\n",
      "Epoch [5552/20000], Loss: 908.0296630859375, Entropy 357.2273254394531, Learning Rate: 0.0025\n",
      "Epoch [5553/20000], Loss: 898.2186279296875, Entropy 342.1073303222656, Learning Rate: 0.0025\n",
      "Epoch [5554/20000], Loss: 868.495849609375, Entropy 358.9002380371094, Learning Rate: 0.0025\n",
      "Epoch [5555/20000], Loss: 889.3778076171875, Entropy 358.7110900878906, Learning Rate: 0.0025\n",
      "Epoch [5556/20000], Loss: 986.9696044921875, Entropy 356.5280456542969, Learning Rate: 0.0025\n",
      "Epoch [5557/20000], Loss: 921.0924072265625, Entropy 354.3289794921875, Learning Rate: 0.0025\n",
      "Epoch [5558/20000], Loss: 933.8306274414062, Entropy 351.52337646484375, Learning Rate: 0.0025\n",
      "Epoch [5559/20000], Loss: 924.9940185546875, Entropy 344.1247253417969, Learning Rate: 0.0025\n",
      "Epoch [5560/20000], Loss: 928.6511840820312, Entropy 366.55609130859375, Learning Rate: 0.0025\n",
      "Epoch [5561/20000], Loss: 963.1022338867188, Entropy 344.20306396484375, Learning Rate: 0.0025\n",
      "Epoch [5562/20000], Loss: 876.363037109375, Entropy 360.6974792480469, Learning Rate: 0.0025\n",
      "Epoch [5563/20000], Loss: 940.654541015625, Entropy 352.6221008300781, Learning Rate: 0.0025\n",
      "Epoch [5564/20000], Loss: 916.760009765625, Entropy 362.13671875, Learning Rate: 0.0025\n",
      "Epoch [5565/20000], Loss: 897.06640625, Entropy 365.4468688964844, Learning Rate: 0.0025\n",
      "Epoch [5566/20000], Loss: 943.92822265625, Entropy 346.6071472167969, Learning Rate: 0.0025\n",
      "Epoch [5567/20000], Loss: 924.9617919921875, Entropy 353.6672058105469, Learning Rate: 0.0025\n",
      "Epoch [5568/20000], Loss: 894.2879638671875, Entropy 342.7574157714844, Learning Rate: 0.0025\n",
      "Epoch [5569/20000], Loss: 858.110107421875, Entropy 372.1418762207031, Learning Rate: 0.0025\n",
      "Epoch [5570/20000], Loss: 939.0914916992188, Entropy 362.07476806640625, Learning Rate: 0.0025\n",
      "Epoch [5571/20000], Loss: 879.6810913085938, Entropy 352.75335693359375, Learning Rate: 0.0025\n",
      "Epoch [5572/20000], Loss: 895.705810546875, Entropy 353.2497863769531, Learning Rate: 0.0025\n",
      "Epoch [5573/20000], Loss: 952.3474731445312, Entropy 351.82952880859375, Learning Rate: 0.0025\n",
      "Epoch [5574/20000], Loss: 933.7569580078125, Entropy 361.5858459472656, Learning Rate: 0.0025\n",
      "Epoch [5575/20000], Loss: 885.096923828125, Entropy 378.1153869628906, Learning Rate: 0.0025\n",
      "Epoch [5576/20000], Loss: 910.0882568359375, Entropy 359.8046875, Learning Rate: 0.0025\n",
      "Epoch [5577/20000], Loss: 912.6446533203125, Entropy 363.0018005371094, Learning Rate: 0.0025\n",
      "Epoch [5578/20000], Loss: 894.7588500976562, Entropy 356.59014892578125, Learning Rate: 0.0025\n",
      "Epoch [5579/20000], Loss: 909.39892578125, Entropy 350.7390441894531, Learning Rate: 0.0025\n",
      "Epoch [5580/20000], Loss: 909.3887329101562, Entropy 357.77655029296875, Learning Rate: 0.0025\n",
      "Epoch [5581/20000], Loss: 935.9384765625, Entropy 355.662109375, Learning Rate: 0.0025\n",
      "Epoch [5582/20000], Loss: 877.5494384765625, Entropy 354.9047546386719, Learning Rate: 0.0025\n",
      "Epoch [5583/20000], Loss: 901.376220703125, Entropy 352.7947998046875, Learning Rate: 0.0025\n",
      "Epoch [5584/20000], Loss: 926.1000366210938, Entropy 364.05950927734375, Learning Rate: 0.0025\n",
      "Epoch [5585/20000], Loss: 901.2616577148438, Entropy 361.34124755859375, Learning Rate: 0.0025\n",
      "Epoch [5586/20000], Loss: 892.3883666992188, Entropy 366.95416259765625, Learning Rate: 0.0025\n",
      "Epoch [5587/20000], Loss: 943.09912109375, Entropy 360.2669372558594, Learning Rate: 0.0025\n",
      "Epoch [5588/20000], Loss: 944.7525634765625, Entropy 358.4954528808594, Learning Rate: 0.0025\n",
      "Epoch [5589/20000], Loss: 903.5933837890625, Entropy 355.4087829589844, Learning Rate: 0.0025\n",
      "Epoch [5590/20000], Loss: 898.643310546875, Entropy 356.1546936035156, Learning Rate: 0.0025\n",
      "Epoch [5591/20000], Loss: 871.2134399414062, Entropy 372.71307373046875, Learning Rate: 0.0025\n",
      "Epoch [5592/20000], Loss: 930.6683959960938, Entropy 350.14971923828125, Learning Rate: 0.0025\n",
      "Epoch [5593/20000], Loss: 880.8423461914062, Entropy 364.45611572265625, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5594/20000], Loss: 901.397705078125, Entropy 370.2464294433594, Learning Rate: 0.0025\n",
      "Epoch [5595/20000], Loss: 896.8909912109375, Entropy 377.9192810058594, Learning Rate: 0.0025\n",
      "Epoch [5596/20000], Loss: 929.3792114257812, Entropy 355.32049560546875, Learning Rate: 0.0025\n",
      "Epoch [5597/20000], Loss: 901.8157958984375, Entropy 349.6653747558594, Learning Rate: 0.0025\n",
      "Epoch [5598/20000], Loss: 894.1703491210938, Entropy 345.51983642578125, Learning Rate: 0.0025\n",
      "Epoch [5599/20000], Loss: 875.385498046875, Entropy 366.4054870605469, Learning Rate: 0.0025\n",
      "Epoch [5600/20000], Loss: 957.6744384765625, Entropy 359.6764831542969, Learning Rate: 0.0025\n",
      "Epoch [5601/20000], Loss: 918.20068359375, Entropy 376.4684143066406, Learning Rate: 0.0025\n",
      "Epoch [5602/20000], Loss: 963.9989013671875, Entropy 360.1901550292969, Learning Rate: 0.0025\n",
      "Epoch [5603/20000], Loss: 896.718994140625, Entropy 368.9892578125, Learning Rate: 0.0025\n",
      "Epoch [5604/20000], Loss: 933.1468505859375, Entropy 361.4384765625, Learning Rate: 0.0025\n",
      "Epoch [5605/20000], Loss: 939.36181640625, Entropy 358.2530517578125, Learning Rate: 0.0025\n",
      "Epoch [5606/20000], Loss: 860.3054809570312, Entropy 369.61517333984375, Learning Rate: 0.0025\n",
      "Epoch [5607/20000], Loss: 935.7906494140625, Entropy 355.1918029785156, Learning Rate: 0.0025\n",
      "Epoch [5608/20000], Loss: 871.0748291015625, Entropy 359.6500549316406, Learning Rate: 0.0025\n",
      "Epoch [5609/20000], Loss: 929.6160888671875, Entropy 367.1124267578125, Learning Rate: 0.0025\n",
      "Epoch [5610/20000], Loss: 888.7000732421875, Entropy 371.13427734375, Learning Rate: 0.0025\n",
      "Epoch [5611/20000], Loss: 953.0986328125, Entropy 353.833984375, Learning Rate: 0.0025\n",
      "Epoch [5612/20000], Loss: 888.266845703125, Entropy 361.953125, Learning Rate: 0.0025\n",
      "Epoch [5613/20000], Loss: 904.2705688476562, Entropy 366.45123291015625, Learning Rate: 0.0025\n",
      "Epoch [5614/20000], Loss: 883.2615966796875, Entropy 364.1942138671875, Learning Rate: 0.0025\n",
      "Epoch [5615/20000], Loss: 913.673583984375, Entropy 359.0198059082031, Learning Rate: 0.0025\n",
      "Epoch [5616/20000], Loss: 922.2833251953125, Entropy 363.959716796875, Learning Rate: 0.0025\n",
      "Epoch [5617/20000], Loss: 863.89697265625, Entropy 370.0828552246094, Learning Rate: 0.0025\n",
      "Epoch [5618/20000], Loss: 906.77294921875, Entropy 359.4246826171875, Learning Rate: 0.0025\n",
      "Epoch [5619/20000], Loss: 949.8073120117188, Entropy 351.37078857421875, Learning Rate: 0.0025\n",
      "Epoch [5620/20000], Loss: 898.1036376953125, Entropy 368.2394714355469, Learning Rate: 0.0025\n",
      "Epoch [5621/20000], Loss: 896.19482421875, Entropy 359.5193786621094, Learning Rate: 0.0025\n",
      "Epoch [5622/20000], Loss: 915.832763671875, Entropy 356.8426208496094, Learning Rate: 0.0025\n",
      "Epoch [5623/20000], Loss: 930.0586547851562, Entropy 371.91534423828125, Learning Rate: 0.0025\n",
      "Epoch [5624/20000], Loss: 915.8128662109375, Entropy 368.1563720703125, Learning Rate: 0.0025\n",
      "Epoch [5625/20000], Loss: 922.360595703125, Entropy 372.8927307128906, Learning Rate: 0.0025\n",
      "Epoch [5626/20000], Loss: 908.6585693359375, Entropy 358.5227355957031, Learning Rate: 0.0025\n",
      "Epoch [5627/20000], Loss: 905.4917602539062, Entropy 370.66339111328125, Learning Rate: 0.0025\n",
      "Epoch [5628/20000], Loss: 948.3779296875, Entropy 369.6004943847656, Learning Rate: 0.0025\n",
      "Epoch [5629/20000], Loss: 941.6072998046875, Entropy 354.2406311035156, Learning Rate: 0.0025\n",
      "Epoch [5630/20000], Loss: 892.792724609375, Entropy 361.3091735839844, Learning Rate: 0.0025\n",
      "Epoch [5631/20000], Loss: 949.777099609375, Entropy 361.5035705566406, Learning Rate: 0.0025\n",
      "Epoch [5632/20000], Loss: 909.110107421875, Entropy 342.95263671875, Learning Rate: 0.0025\n",
      "Epoch [5633/20000], Loss: 927.0401611328125, Entropy 367.3176574707031, Learning Rate: 0.0025\n",
      "Epoch [5634/20000], Loss: 930.3900146484375, Entropy 367.7131042480469, Learning Rate: 0.0025\n",
      "Epoch [5635/20000], Loss: 913.232421875, Entropy 356.9737548828125, Learning Rate: 0.0025\n",
      "Epoch [5636/20000], Loss: 882.7058715820312, Entropy 375.88909912109375, Learning Rate: 0.0025\n",
      "Epoch [5637/20000], Loss: 871.2902221679688, Entropy 370.79156494140625, Learning Rate: 0.0025\n",
      "Epoch [5638/20000], Loss: 895.0347900390625, Entropy 369.0372619628906, Learning Rate: 0.0025\n",
      "Epoch [5639/20000], Loss: 886.010986328125, Entropy 367.5008850097656, Learning Rate: 0.0025\n",
      "Epoch [5640/20000], Loss: 925.6681518554688, Entropy 355.46527099609375, Learning Rate: 0.0025\n",
      "Epoch [5641/20000], Loss: 930.576416015625, Entropy 362.6483154296875, Learning Rate: 0.0025\n",
      "Epoch [5642/20000], Loss: 940.8511962890625, Entropy 359.2974853515625, Learning Rate: 0.0025\n",
      "Epoch [5643/20000], Loss: 913.5275268554688, Entropy 372.22015380859375, Learning Rate: 0.0025\n",
      "Epoch [5644/20000], Loss: 880.2392578125, Entropy 356.8610534667969, Learning Rate: 0.0025\n",
      "Epoch [5645/20000], Loss: 974.70166015625, Entropy 353.3504943847656, Learning Rate: 0.0025\n",
      "Epoch [5646/20000], Loss: 929.8847045898438, Entropy 362.41607666015625, Learning Rate: 0.0025\n",
      "Epoch [5647/20000], Loss: 918.4916381835938, Entropy 352.99127197265625, Learning Rate: 0.0025\n",
      "Epoch [5648/20000], Loss: 915.8997802734375, Entropy 361.9435729980469, Learning Rate: 0.0025\n",
      "Epoch [5649/20000], Loss: 907.1478271484375, Entropy 365.25146484375, Learning Rate: 0.0025\n",
      "Epoch [5650/20000], Loss: 890.22998046875, Entropy 375.430419921875, Learning Rate: 0.0025\n",
      "Epoch [5651/20000], Loss: 895.813720703125, Entropy 362.4971008300781, Learning Rate: 0.0025\n",
      "Epoch [5652/20000], Loss: 957.7760009765625, Entropy 364.6374206542969, Learning Rate: 0.0025\n",
      "Epoch [5653/20000], Loss: 931.5449829101562, Entropy 376.22576904296875, Learning Rate: 0.0025\n",
      "Epoch [5654/20000], Loss: 909.142333984375, Entropy 352.2769470214844, Learning Rate: 0.0025\n",
      "Epoch [5655/20000], Loss: 924.1301879882812, Entropy 374.68853759765625, Learning Rate: 0.0025\n",
      "Epoch [5656/20000], Loss: 902.0902099609375, Entropy 368.9735107421875, Learning Rate: 0.0025\n",
      "Epoch [5657/20000], Loss: 941.5833740234375, Entropy 349.9902648925781, Learning Rate: 0.0025\n",
      "Epoch [5658/20000], Loss: 883.5301513671875, Entropy 369.5794982910156, Learning Rate: 0.0025\n",
      "Epoch [5659/20000], Loss: 963.107666015625, Entropy 351.5965576171875, Learning Rate: 0.0025\n",
      "Epoch [5660/20000], Loss: 899.28564453125, Entropy 356.9933166503906, Learning Rate: 0.0025\n",
      "Epoch [5661/20000], Loss: 899.7189331054688, Entropy 368.22222900390625, Learning Rate: 0.0025\n",
      "Epoch [5662/20000], Loss: 934.8385620117188, Entropy 366.29913330078125, Learning Rate: 0.0025\n",
      "Epoch [5663/20000], Loss: 965.213623046875, Entropy 358.2427978515625, Learning Rate: 0.0025\n",
      "Epoch [5664/20000], Loss: 903.8203125, Entropy 361.1246643066406, Learning Rate: 0.0025\n",
      "Epoch [5665/20000], Loss: 877.9867553710938, Entropy 367.04705810546875, Learning Rate: 0.0025\n",
      "Epoch [5666/20000], Loss: 871.068603515625, Entropy 377.0050354003906, Learning Rate: 0.0025\n",
      "Epoch [5667/20000], Loss: 896.4782104492188, Entropy 361.76849365234375, Learning Rate: 0.0025\n",
      "Epoch [5668/20000], Loss: 920.843505859375, Entropy 353.1237487792969, Learning Rate: 0.0025\n",
      "Epoch [5669/20000], Loss: 938.68212890625, Entropy 358.4543151855469, Learning Rate: 0.0025\n",
      "Epoch [5670/20000], Loss: 935.815673828125, Entropy 362.6053466796875, Learning Rate: 0.0025\n",
      "Epoch [5671/20000], Loss: 888.4850463867188, Entropy 376.24249267578125, Learning Rate: 0.0025\n",
      "Epoch [5672/20000], Loss: 872.245849609375, Entropy 375.8558044433594, Learning Rate: 0.0025\n",
      "Epoch [5673/20000], Loss: 915.8124389648438, Entropy 371.58343505859375, Learning Rate: 0.0025\n",
      "Epoch [5674/20000], Loss: 892.3785400390625, Entropy 371.9696350097656, Learning Rate: 0.0025\n",
      "Epoch [5675/20000], Loss: 910.5472412109375, Entropy 372.5007629394531, Learning Rate: 0.0025\n",
      "Epoch [5676/20000], Loss: 902.9129638671875, Entropy 367.4884948730469, Learning Rate: 0.0025\n",
      "Epoch [5677/20000], Loss: 946.2064819335938, Entropy 361.92279052734375, Learning Rate: 0.0025\n",
      "Epoch [5678/20000], Loss: 921.4212646484375, Entropy 353.6346130371094, Learning Rate: 0.0025\n",
      "Epoch [5679/20000], Loss: 934.0130615234375, Entropy 356.236328125, Learning Rate: 0.0025\n",
      "Epoch [5680/20000], Loss: 940.380126953125, Entropy 367.3521728515625, Learning Rate: 0.0025\n",
      "Epoch [5681/20000], Loss: 905.0455322265625, Entropy 364.6080627441406, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5682/20000], Loss: 998.86865234375, Entropy 357.1882019042969, Learning Rate: 0.0025\n",
      "Epoch [5683/20000], Loss: 920.76611328125, Entropy 353.9715270996094, Learning Rate: 0.0025\n",
      "Epoch [5684/20000], Loss: 886.6202392578125, Entropy 375.2448425292969, Learning Rate: 0.0025\n",
      "Epoch [5685/20000], Loss: 888.6021728515625, Entropy 363.8590393066406, Learning Rate: 0.0025\n",
      "Epoch [5686/20000], Loss: 944.6859741210938, Entropy 360.07452392578125, Learning Rate: 0.0025\n",
      "Epoch [5687/20000], Loss: 885.4385375976562, Entropy 374.11712646484375, Learning Rate: 0.0025\n",
      "Epoch [5688/20000], Loss: 918.2191772460938, Entropy 365.52557373046875, Learning Rate: 0.0025\n",
      "Epoch [5689/20000], Loss: 955.5648193359375, Entropy 364.1133117675781, Learning Rate: 0.0025\n",
      "Epoch [5690/20000], Loss: 905.4047241210938, Entropy 364.79412841796875, Learning Rate: 0.0025\n",
      "Epoch [5691/20000], Loss: 934.6646118164062, Entropy 370.77496337890625, Learning Rate: 0.0025\n",
      "Epoch [5692/20000], Loss: 917.2372436523438, Entropy 376.79705810546875, Learning Rate: 0.0025\n",
      "Epoch [5693/20000], Loss: 859.40185546875, Entropy 372.4360046386719, Learning Rate: 0.0025\n",
      "Epoch [5694/20000], Loss: 933.2550659179688, Entropy 355.09271240234375, Learning Rate: 0.0025\n",
      "Epoch [5695/20000], Loss: 946.006591796875, Entropy 369.1374206542969, Learning Rate: 0.0025\n",
      "Epoch [5696/20000], Loss: 903.1595458984375, Entropy 365.416015625, Learning Rate: 0.0025\n",
      "Epoch [5697/20000], Loss: 938.7620849609375, Entropy 374.451171875, Learning Rate: 0.0025\n",
      "Epoch [5698/20000], Loss: 893.259521484375, Entropy 377.0738220214844, Learning Rate: 0.0025\n",
      "Epoch [5699/20000], Loss: 894.3526611328125, Entropy 375.7613525390625, Learning Rate: 0.0025\n",
      "Epoch [5700/20000], Loss: 903.01513671875, Entropy 371.1742858886719, Learning Rate: 0.0025\n",
      "Epoch [5701/20000], Loss: 939.704833984375, Entropy 370.1531982421875, Learning Rate: 0.0025\n",
      "Epoch [5702/20000], Loss: 943.2064208984375, Entropy 368.6314697265625, Learning Rate: 0.0025\n",
      "Epoch [5703/20000], Loss: 904.927490234375, Entropy 376.2038879394531, Learning Rate: 0.0025\n",
      "Epoch [5704/20000], Loss: 914.16943359375, Entropy 369.4767761230469, Learning Rate: 0.0025\n",
      "Epoch [5705/20000], Loss: 896.583251953125, Entropy 369.1298828125, Learning Rate: 0.0025\n",
      "Epoch [5706/20000], Loss: 892.0186157226562, Entropy 380.48638916015625, Learning Rate: 0.0025\n",
      "Epoch [5707/20000], Loss: 941.45751953125, Entropy 363.8097839355469, Learning Rate: 0.0025\n",
      "Epoch [5708/20000], Loss: 878.0455322265625, Entropy 374.69482421875, Learning Rate: 0.0025\n",
      "Epoch [5709/20000], Loss: 896.3910522460938, Entropy 371.56573486328125, Learning Rate: 0.0025\n",
      "Epoch [5710/20000], Loss: 900.41748046875, Entropy 370.5924072265625, Learning Rate: 0.0025\n",
      "Epoch [5711/20000], Loss: 905.3990478515625, Entropy 362.1667785644531, Learning Rate: 0.0025\n",
      "Epoch [5712/20000], Loss: 875.4388427734375, Entropy 372.8133239746094, Learning Rate: 0.0025\n",
      "Epoch [5713/20000], Loss: 910.44873046875, Entropy 365.6181640625, Learning Rate: 0.0025\n",
      "Epoch [5714/20000], Loss: 954.6842041015625, Entropy 359.3450012207031, Learning Rate: 0.0025\n",
      "Epoch [5715/20000], Loss: 930.4812622070312, Entropy 368.20074462890625, Learning Rate: 0.0025\n",
      "Epoch [5716/20000], Loss: 862.6868286132812, Entropy 371.70404052734375, Learning Rate: 0.0025\n",
      "Epoch [5717/20000], Loss: 880.1544799804688, Entropy 369.13507080078125, Learning Rate: 0.0025\n",
      "Epoch [5718/20000], Loss: 912.319580078125, Entropy 363.5235595703125, Learning Rate: 0.0025\n",
      "Epoch [5719/20000], Loss: 928.853759765625, Entropy 355.1974792480469, Learning Rate: 0.0025\n",
      "Epoch [5720/20000], Loss: 922.662109375, Entropy 369.1900634765625, Learning Rate: 0.0025\n",
      "Epoch [5721/20000], Loss: 898.924560546875, Entropy 372.2563171386719, Learning Rate: 0.0025\n",
      "Epoch [5722/20000], Loss: 926.021484375, Entropy 352.9926452636719, Learning Rate: 0.0025\n",
      "Epoch [5723/20000], Loss: 933.453125, Entropy 356.9119873046875, Learning Rate: 0.0025\n",
      "Epoch [5724/20000], Loss: 892.8485107421875, Entropy 380.4047546386719, Learning Rate: 0.0025\n",
      "Epoch [5725/20000], Loss: 849.230224609375, Entropy 362.9312438964844, Learning Rate: 0.0025\n",
      "Epoch [5726/20000], Loss: 861.1351318359375, Entropy 378.5531921386719, Learning Rate: 0.0025\n",
      "Epoch [5727/20000], Loss: 893.7628173828125, Entropy 379.5911560058594, Learning Rate: 0.0025\n",
      "Epoch [5728/20000], Loss: 894.40869140625, Entropy 380.43896484375, Learning Rate: 0.0025\n",
      "Epoch [5729/20000], Loss: 932.397705078125, Entropy 361.6745300292969, Learning Rate: 0.0025\n",
      "Epoch [5730/20000], Loss: 873.4078369140625, Entropy 386.0470886230469, Learning Rate: 0.0025\n",
      "Epoch [5731/20000], Loss: 941.2271728515625, Entropy 347.7236633300781, Learning Rate: 0.0025\n",
      "Epoch [5732/20000], Loss: 884.101806640625, Entropy 384.4563903808594, Learning Rate: 0.0025\n",
      "Epoch [5733/20000], Loss: 894.1411743164062, Entropy 367.71795654296875, Learning Rate: 0.0025\n",
      "Epoch [5734/20000], Loss: 894.6060791015625, Entropy 369.3263854980469, Learning Rate: 0.0025\n",
      "Epoch [5735/20000], Loss: 925.8310546875, Entropy 370.0096130371094, Learning Rate: 0.0025\n",
      "Epoch [5736/20000], Loss: 914.8238525390625, Entropy 379.9499816894531, Learning Rate: 0.0025\n",
      "Epoch [5737/20000], Loss: 878.70068359375, Entropy 380.1300048828125, Learning Rate: 0.0025\n",
      "Epoch [5738/20000], Loss: 915.671142578125, Entropy 379.4002380371094, Learning Rate: 0.0025\n",
      "Epoch [5739/20000], Loss: 928.1768798828125, Entropy 366.1685791015625, Learning Rate: 0.0025\n",
      "Epoch [5740/20000], Loss: 889.4662475585938, Entropy 373.62237548828125, Learning Rate: 0.0025\n",
      "Epoch [5741/20000], Loss: 895.598388671875, Entropy 374.702880859375, Learning Rate: 0.0025\n",
      "Epoch [5742/20000], Loss: 928.869384765625, Entropy 370.5325622558594, Learning Rate: 0.0025\n",
      "Epoch [5743/20000], Loss: 903.2191162109375, Entropy 377.4814453125, Learning Rate: 0.0025\n",
      "Epoch [5744/20000], Loss: 858.5203857421875, Entropy 387.4457092285156, Learning Rate: 0.0025\n",
      "Epoch [5745/20000], Loss: 874.11962890625, Entropy 377.953125, Learning Rate: 0.0025\n",
      "Epoch [5746/20000], Loss: 947.2424926757812, Entropy 359.51080322265625, Learning Rate: 0.0025\n",
      "Epoch [5747/20000], Loss: 925.4010620117188, Entropy 372.24456787109375, Learning Rate: 0.0025\n",
      "Epoch [5748/20000], Loss: 917.7621459960938, Entropy 374.49725341796875, Learning Rate: 0.0025\n",
      "Epoch [5749/20000], Loss: 888.1453857421875, Entropy 367.8892822265625, Learning Rate: 0.0025\n",
      "Epoch [5750/20000], Loss: 894.385986328125, Entropy 372.0813293457031, Learning Rate: 0.0025\n",
      "Epoch [5751/20000], Loss: 913.045166015625, Entropy 361.2611999511719, Learning Rate: 0.0025\n",
      "Epoch [5752/20000], Loss: 912.699951171875, Entropy 376.8737487792969, Learning Rate: 0.0025\n",
      "Epoch [5753/20000], Loss: 895.9566650390625, Entropy 372.1959228515625, Learning Rate: 0.0025\n",
      "Epoch [5754/20000], Loss: 879.63623046875, Entropy 382.5866394042969, Learning Rate: 0.0025\n",
      "Epoch [5755/20000], Loss: 947.198486328125, Entropy 365.4418029785156, Learning Rate: 0.0025\n",
      "Epoch [5756/20000], Loss: 894.8109130859375, Entropy 374.6517028808594, Learning Rate: 0.0025\n",
      "Epoch [5757/20000], Loss: 925.007080078125, Entropy 350.9837341308594, Learning Rate: 0.0025\n",
      "Epoch [5758/20000], Loss: 886.5450439453125, Entropy 375.8506164550781, Learning Rate: 0.0025\n",
      "Epoch [5759/20000], Loss: 897.2335205078125, Entropy 361.5030517578125, Learning Rate: 0.0025\n",
      "Epoch [5760/20000], Loss: 903.1920166015625, Entropy 366.2455139160156, Learning Rate: 0.0025\n",
      "Epoch [5761/20000], Loss: 916.499267578125, Entropy 364.6363525390625, Learning Rate: 0.0025\n",
      "Epoch [5762/20000], Loss: 886.045166015625, Entropy 365.0303955078125, Learning Rate: 0.0025\n",
      "Epoch [5763/20000], Loss: 940.8560180664062, Entropy 376.92962646484375, Learning Rate: 0.0025\n",
      "Epoch [5764/20000], Loss: 874.5045776367188, Entropy 376.78802490234375, Learning Rate: 0.0025\n",
      "Epoch [5765/20000], Loss: 920.3453979492188, Entropy 384.38421630859375, Learning Rate: 0.0025\n",
      "Epoch [5766/20000], Loss: 890.5760498046875, Entropy 366.0696716308594, Learning Rate: 0.0025\n",
      "Epoch [5767/20000], Loss: 874.0098876953125, Entropy 368.9749450683594, Learning Rate: 0.0025\n",
      "Epoch [5768/20000], Loss: 910.5748291015625, Entropy 375.7471923828125, Learning Rate: 0.0025\n",
      "Epoch [5769/20000], Loss: 897.5033569335938, Entropy 379.82757568359375, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5770/20000], Loss: 919.8359375, Entropy 378.5739440917969, Learning Rate: 0.0025\n",
      "Epoch [5771/20000], Loss: 917.73828125, Entropy 367.8774108886719, Learning Rate: 0.0025\n",
      "Epoch [5772/20000], Loss: 902.3795166015625, Entropy 379.3468017578125, Learning Rate: 0.0025\n",
      "Epoch [5773/20000], Loss: 913.1541748046875, Entropy 371.3582763671875, Learning Rate: 0.0025\n",
      "Epoch [5774/20000], Loss: 922.9058837890625, Entropy 366.5133972167969, Learning Rate: 0.0025\n",
      "Epoch [5775/20000], Loss: 902.4169921875, Entropy 363.8295593261719, Learning Rate: 0.0025\n",
      "Epoch [5776/20000], Loss: 916.74267578125, Entropy 369.1236572265625, Learning Rate: 0.0025\n",
      "Epoch [5777/20000], Loss: 883.11474609375, Entropy 376.7170104980469, Learning Rate: 0.0025\n",
      "Epoch [5778/20000], Loss: 909.5252685546875, Entropy 383.7595520019531, Learning Rate: 0.0025\n",
      "Epoch [5779/20000], Loss: 876.6499633789062, Entropy 376.83331298828125, Learning Rate: 0.0025\n",
      "Epoch [5780/20000], Loss: 871.99755859375, Entropy 374.3263244628906, Learning Rate: 0.0025\n",
      "Epoch [5781/20000], Loss: 903.7510986328125, Entropy 374.6901550292969, Learning Rate: 0.0025\n",
      "Epoch [5782/20000], Loss: 883.6521606445312, Entropy 380.24468994140625, Learning Rate: 0.0025\n",
      "Epoch [5783/20000], Loss: 897.1642456054688, Entropy 376.46429443359375, Learning Rate: 0.0025\n",
      "Epoch [5784/20000], Loss: 884.4613037109375, Entropy 383.7706298828125, Learning Rate: 0.0025\n",
      "Epoch [5785/20000], Loss: 882.6298828125, Entropy 372.0676574707031, Learning Rate: 0.0025\n",
      "Epoch [5786/20000], Loss: 880.3651123046875, Entropy 371.0897521972656, Learning Rate: 0.0025\n",
      "Epoch [5787/20000], Loss: 856.3953247070312, Entropy 377.66156005859375, Learning Rate: 0.0025\n",
      "Epoch [5788/20000], Loss: 883.1949462890625, Entropy 386.1661376953125, Learning Rate: 0.0025\n",
      "Epoch [5789/20000], Loss: 922.44921875, Entropy 380.6858825683594, Learning Rate: 0.0025\n",
      "Epoch [5790/20000], Loss: 936.787841796875, Entropy 368.2496032714844, Learning Rate: 0.0025\n",
      "Epoch [5791/20000], Loss: 867.3308715820312, Entropy 378.05072021484375, Learning Rate: 0.0025\n",
      "Epoch [5792/20000], Loss: 895.4881591796875, Entropy 376.6499938964844, Learning Rate: 0.0025\n",
      "Epoch [5793/20000], Loss: 901.7530517578125, Entropy 373.9810791015625, Learning Rate: 0.0025\n",
      "Epoch [5794/20000], Loss: 884.526123046875, Entropy 383.5759582519531, Learning Rate: 0.0025\n",
      "Epoch [5795/20000], Loss: 889.5777587890625, Entropy 372.5616760253906, Learning Rate: 0.0025\n",
      "Epoch [5796/20000], Loss: 906.0176391601562, Entropy 372.63372802734375, Learning Rate: 0.0025\n",
      "Epoch [5797/20000], Loss: 831.9393920898438, Entropy 382.79144287109375, Learning Rate: 0.0025\n",
      "Epoch [5798/20000], Loss: 865.188232421875, Entropy 382.8912353515625, Learning Rate: 0.0025\n",
      "Epoch [5799/20000], Loss: 926.7337646484375, Entropy 376.6631164550781, Learning Rate: 0.0025\n",
      "Epoch [5800/20000], Loss: 918.3812255859375, Entropy 376.8933410644531, Learning Rate: 0.0025\n",
      "Epoch [5801/20000], Loss: 873.0426025390625, Entropy 372.0513916015625, Learning Rate: 0.0025\n",
      "Epoch [5802/20000], Loss: 914.7313232421875, Entropy 385.1171875, Learning Rate: 0.0025\n",
      "Epoch [5803/20000], Loss: 945.4202270507812, Entropy 381.41790771484375, Learning Rate: 0.0025\n",
      "Epoch [5804/20000], Loss: 928.8434448242188, Entropy 371.74224853515625, Learning Rate: 0.0025\n",
      "Epoch [5805/20000], Loss: 885.752197265625, Entropy 381.1525573730469, Learning Rate: 0.0025\n",
      "Epoch [5806/20000], Loss: 897.244140625, Entropy 372.3685607910156, Learning Rate: 0.0025\n",
      "Epoch [5807/20000], Loss: 952.4775390625, Entropy 374.9485168457031, Learning Rate: 0.0025\n",
      "Epoch [5808/20000], Loss: 918.1929931640625, Entropy 378.07568359375, Learning Rate: 0.0025\n",
      "Epoch [5809/20000], Loss: 947.5235595703125, Entropy 362.0400390625, Learning Rate: 0.0025\n",
      "Epoch [5810/20000], Loss: 867.0949096679688, Entropy 373.87933349609375, Learning Rate: 0.0025\n",
      "Epoch [5811/20000], Loss: 920.9459228515625, Entropy 360.6490478515625, Learning Rate: 0.0025\n",
      "Epoch [5812/20000], Loss: 908.32080078125, Entropy 383.8974609375, Learning Rate: 0.0025\n",
      "Epoch [5813/20000], Loss: 913.5496826171875, Entropy 384.0679626464844, Learning Rate: 0.0025\n",
      "Epoch [5814/20000], Loss: 896.8201904296875, Entropy 387.3402404785156, Learning Rate: 0.0025\n",
      "Epoch [5815/20000], Loss: 923.9194946289062, Entropy 377.62200927734375, Learning Rate: 0.0025\n",
      "Epoch [5816/20000], Loss: 923.04150390625, Entropy 365.7332763671875, Learning Rate: 0.0025\n",
      "Epoch [5817/20000], Loss: 917.42724609375, Entropy 374.1695861816406, Learning Rate: 0.0025\n",
      "Epoch [5818/20000], Loss: 880.1696166992188, Entropy 379.17242431640625, Learning Rate: 0.0025\n",
      "Epoch [5819/20000], Loss: 880.1795043945312, Entropy 373.53021240234375, Learning Rate: 0.0025\n",
      "Epoch [5820/20000], Loss: 858.140380859375, Entropy 386.6264343261719, Learning Rate: 0.0025\n",
      "Epoch [5821/20000], Loss: 925.093017578125, Entropy 383.35888671875, Learning Rate: 0.0025\n",
      "Epoch [5822/20000], Loss: 922.8400268554688, Entropy 372.78082275390625, Learning Rate: 0.0025\n",
      "Epoch [5823/20000], Loss: 910.4219970703125, Entropy 386.7961730957031, Learning Rate: 0.0025\n",
      "Epoch [5824/20000], Loss: 913.715087890625, Entropy 376.9089660644531, Learning Rate: 0.0025\n",
      "Epoch [5825/20000], Loss: 915.68505859375, Entropy 374.1197509765625, Learning Rate: 0.0025\n",
      "Epoch [5826/20000], Loss: 932.360107421875, Entropy 375.8586730957031, Learning Rate: 0.0025\n",
      "Epoch [5827/20000], Loss: 916.8614501953125, Entropy 360.8319091796875, Learning Rate: 0.0025\n",
      "Epoch [5828/20000], Loss: 901.8817749023438, Entropy 382.31878662109375, Learning Rate: 0.0025\n",
      "Epoch [5829/20000], Loss: 918.4452514648438, Entropy 384.18780517578125, Learning Rate: 0.0025\n",
      "Epoch [5830/20000], Loss: 917.0821533203125, Entropy 377.4948425292969, Learning Rate: 0.0025\n",
      "Epoch [5831/20000], Loss: 907.47265625, Entropy 377.2857360839844, Learning Rate: 0.0025\n",
      "Epoch [5832/20000], Loss: 870.185791015625, Entropy 383.9338073730469, Learning Rate: 0.0025\n",
      "Epoch [5833/20000], Loss: 909.27783203125, Entropy 384.9992980957031, Learning Rate: 0.0025\n",
      "Epoch [5834/20000], Loss: 935.695556640625, Entropy 383.2492370605469, Learning Rate: 0.0025\n",
      "Epoch [5835/20000], Loss: 875.6328735351562, Entropy 377.65338134765625, Learning Rate: 0.0025\n",
      "Epoch [5836/20000], Loss: 875.789794921875, Entropy 393.1203918457031, Learning Rate: 0.0025\n",
      "Epoch [5837/20000], Loss: 891.886962890625, Entropy 368.62890625, Learning Rate: 0.0025\n",
      "Epoch [5838/20000], Loss: 900.4061279296875, Entropy 378.6223449707031, Learning Rate: 0.0025\n",
      "Epoch [5839/20000], Loss: 906.1160278320312, Entropy 366.09210205078125, Learning Rate: 0.0025\n",
      "Epoch [5840/20000], Loss: 920.177001953125, Entropy 375.4488220214844, Learning Rate: 0.0025\n",
      "Epoch [5841/20000], Loss: 859.563720703125, Entropy 389.1472473144531, Learning Rate: 0.0025\n",
      "Epoch [5842/20000], Loss: 947.4482421875, Entropy 380.93701171875, Learning Rate: 0.0025\n",
      "Epoch [5843/20000], Loss: 945.58740234375, Entropy 386.1592102050781, Learning Rate: 0.0025\n",
      "Epoch [5844/20000], Loss: 895.2034912109375, Entropy 390.6248474121094, Learning Rate: 0.0025\n",
      "Epoch [5845/20000], Loss: 877.5473022460938, Entropy 382.56097412109375, Learning Rate: 0.0025\n",
      "Epoch [5846/20000], Loss: 892.4405517578125, Entropy 378.7176208496094, Learning Rate: 0.0025\n",
      "Epoch [5847/20000], Loss: 886.9881591796875, Entropy 389.7853088378906, Learning Rate: 0.0025\n",
      "Epoch [5848/20000], Loss: 916.7142333984375, Entropy 394.7503356933594, Learning Rate: 0.0025\n",
      "Epoch [5849/20000], Loss: 892.8289794921875, Entropy 390.4581298828125, Learning Rate: 0.0025\n",
      "Epoch [5850/20000], Loss: 885.0191650390625, Entropy 387.3467102050781, Learning Rate: 0.0025\n",
      "Epoch [5851/20000], Loss: 913.6522216796875, Entropy 381.8994445800781, Learning Rate: 0.0025\n",
      "Epoch [5852/20000], Loss: 901.852783203125, Entropy 382.2080078125, Learning Rate: 0.0025\n",
      "Epoch [5853/20000], Loss: 922.2138671875, Entropy 380.3829650878906, Learning Rate: 0.0025\n",
      "Epoch [5854/20000], Loss: 885.632568359375, Entropy 377.4262390136719, Learning Rate: 0.0025\n",
      "Epoch [5855/20000], Loss: 940.8851318359375, Entropy 382.0635986328125, Learning Rate: 0.0025\n",
      "Epoch [5856/20000], Loss: 890.1031494140625, Entropy 371.3086242675781, Learning Rate: 0.0025\n",
      "Epoch [5857/20000], Loss: 965.7164306640625, Entropy 373.77294921875, Learning Rate: 0.0025\n",
      "Epoch [5858/20000], Loss: 895.3026123046875, Entropy 372.5164794921875, Learning Rate: 0.0025\n",
      "Epoch [5859/20000], Loss: 916.7967529296875, Entropy 382.7927551269531, Learning Rate: 0.0025\n",
      "Epoch [5860/20000], Loss: 909.3787231445312, Entropy 375.80523681640625, Learning Rate: 0.0025\n",
      "Epoch [5861/20000], Loss: 899.5914306640625, Entropy 387.9263916015625, Learning Rate: 0.0025\n",
      "Epoch [5862/20000], Loss: 891.2149658203125, Entropy 362.7829284667969, Learning Rate: 0.0025\n",
      "Epoch [5863/20000], Loss: 947.8408203125, Entropy 371.1316223144531, Learning Rate: 0.0025\n",
      "Epoch [5864/20000], Loss: 876.4446411132812, Entropy 395.17694091796875, Learning Rate: 0.0025\n",
      "Epoch [5865/20000], Loss: 928.201904296875, Entropy 385.1392822265625, Learning Rate: 0.0025\n",
      "Epoch [5866/20000], Loss: 906.1536865234375, Entropy 386.203125, Learning Rate: 0.0025\n",
      "Epoch [5867/20000], Loss: 909.738037109375, Entropy 376.2671813964844, Learning Rate: 0.0025\n",
      "Epoch [5868/20000], Loss: 901.9765625, Entropy 376.0621643066406, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5869/20000], Loss: 924.535888671875, Entropy 381.4381103515625, Learning Rate: 0.0025\n",
      "Epoch [5870/20000], Loss: 876.4345703125, Entropy 391.1424255371094, Learning Rate: 0.0025\n",
      "Epoch [5871/20000], Loss: 934.2183837890625, Entropy 377.2840576171875, Learning Rate: 0.0025\n",
      "Epoch [5872/20000], Loss: 925.0089111328125, Entropy 384.67724609375, Learning Rate: 0.0025\n",
      "Epoch [5873/20000], Loss: 970.1990966796875, Entropy 386.4164123535156, Learning Rate: 0.0025\n",
      "Epoch [5874/20000], Loss: 928.298095703125, Entropy 393.8946838378906, Learning Rate: 0.0025\n",
      "Epoch [5875/20000], Loss: 899.91015625, Entropy 380.3394470214844, Learning Rate: 0.0025\n",
      "Epoch [5876/20000], Loss: 930.989990234375, Entropy 382.0588073730469, Learning Rate: 0.0025\n",
      "Epoch [5877/20000], Loss: 874.8584594726562, Entropy 392.52752685546875, Learning Rate: 0.0025\n",
      "Epoch [5878/20000], Loss: 883.3846435546875, Entropy 385.0295715332031, Learning Rate: 0.0025\n",
      "Epoch [5879/20000], Loss: 908.1375732421875, Entropy 388.2922668457031, Learning Rate: 0.0025\n",
      "Epoch [5880/20000], Loss: 882.82275390625, Entropy 387.4874572753906, Learning Rate: 0.0025\n",
      "Epoch [5881/20000], Loss: 906.595947265625, Entropy 388.4004211425781, Learning Rate: 0.0025\n",
      "Epoch [5882/20000], Loss: 928.3482666015625, Entropy 387.4057312011719, Learning Rate: 0.0025\n",
      "Epoch [5883/20000], Loss: 867.5537109375, Entropy 385.2113342285156, Learning Rate: 0.0025\n",
      "Epoch [5884/20000], Loss: 895.7249755859375, Entropy 382.4784240722656, Learning Rate: 0.0025\n",
      "Epoch [5885/20000], Loss: 971.2115478515625, Entropy 372.0749816894531, Learning Rate: 0.0025\n",
      "Epoch [5886/20000], Loss: 906.9996948242188, Entropy 380.38592529296875, Learning Rate: 0.0025\n",
      "Epoch [5887/20000], Loss: 905.8408813476562, Entropy 382.92486572265625, Learning Rate: 0.0025\n",
      "Epoch [5888/20000], Loss: 892.1373291015625, Entropy 387.5460205078125, Learning Rate: 0.0025\n",
      "Epoch [5889/20000], Loss: 937.63232421875, Entropy 384.5699157714844, Learning Rate: 0.0025\n",
      "Epoch [5890/20000], Loss: 935.2100830078125, Entropy 385.2494201660156, Learning Rate: 0.0025\n",
      "Epoch [5891/20000], Loss: 930.63671875, Entropy 373.3306884765625, Learning Rate: 0.0025\n",
      "Epoch [5892/20000], Loss: 908.3093872070312, Entropy 395.76519775390625, Learning Rate: 0.0025\n",
      "Epoch [5893/20000], Loss: 930.448974609375, Entropy 387.1107482910156, Learning Rate: 0.0025\n",
      "Epoch [5894/20000], Loss: 926.5975341796875, Entropy 384.9920654296875, Learning Rate: 0.0025\n",
      "Epoch [5895/20000], Loss: 886.9424438476562, Entropy 399.01580810546875, Learning Rate: 0.0025\n",
      "Epoch [5896/20000], Loss: 915.02880859375, Entropy 376.4054260253906, Learning Rate: 0.0025\n",
      "Epoch [5897/20000], Loss: 917.4349365234375, Entropy 381.1671142578125, Learning Rate: 0.0025\n",
      "Epoch [5898/20000], Loss: 940.1665649414062, Entropy 379.16937255859375, Learning Rate: 0.0025\n",
      "Epoch [5899/20000], Loss: 880.062744140625, Entropy 388.5678405761719, Learning Rate: 0.0025\n",
      "Epoch [5900/20000], Loss: 922.2222290039062, Entropy 391.92889404296875, Learning Rate: 0.0025\n",
      "Epoch [5901/20000], Loss: 918.9443969726562, Entropy 382.77264404296875, Learning Rate: 0.0025\n",
      "Epoch [5902/20000], Loss: 852.3702392578125, Entropy 392.1347961425781, Learning Rate: 0.0025\n",
      "Epoch [5903/20000], Loss: 951.7620849609375, Entropy 383.1703186035156, Learning Rate: 0.0025\n",
      "Epoch [5904/20000], Loss: 908.8651123046875, Entropy 394.6672668457031, Learning Rate: 0.0025\n",
      "Epoch [5905/20000], Loss: 886.3209228515625, Entropy 392.8088073730469, Learning Rate: 0.0025\n",
      "Epoch [5906/20000], Loss: 917.09228515625, Entropy 380.7508850097656, Learning Rate: 0.0025\n",
      "Epoch [5907/20000], Loss: 956.6241455078125, Entropy 394.8908386230469, Learning Rate: 0.0025\n",
      "Epoch [5908/20000], Loss: 919.5257568359375, Entropy 373.7995910644531, Learning Rate: 0.0025\n",
      "Epoch [5909/20000], Loss: 897.9805908203125, Entropy 390.4578857421875, Learning Rate: 0.0025\n",
      "Epoch [5910/20000], Loss: 889.689453125, Entropy 384.3308410644531, Learning Rate: 0.0025\n",
      "Epoch [5911/20000], Loss: 925.4408569335938, Entropy 400.41827392578125, Learning Rate: 0.0025\n",
      "Epoch [5912/20000], Loss: 947.2020263671875, Entropy 392.9773864746094, Learning Rate: 0.0025\n",
      "Epoch [5913/20000], Loss: 928.6114501953125, Entropy 382.698974609375, Learning Rate: 0.0025\n",
      "Epoch [5914/20000], Loss: 896.0906982421875, Entropy 382.0705871582031, Learning Rate: 0.0025\n",
      "Epoch [5915/20000], Loss: 915.99755859375, Entropy 383.1491394042969, Learning Rate: 0.0025\n",
      "Epoch [5916/20000], Loss: 927.1614990234375, Entropy 382.24951171875, Learning Rate: 0.0025\n",
      "Epoch [5917/20000], Loss: 907.593017578125, Entropy 382.9611511230469, Learning Rate: 0.0025\n",
      "Epoch [5918/20000], Loss: 914.9873046875, Entropy 380.2242126464844, Learning Rate: 0.0025\n",
      "Epoch [5919/20000], Loss: 906.67822265625, Entropy 373.4261779785156, Learning Rate: 0.0025\n",
      "Epoch [5920/20000], Loss: 878.6287231445312, Entropy 384.81829833984375, Learning Rate: 0.0025\n",
      "Epoch [5921/20000], Loss: 912.4044799804688, Entropy 380.54779052734375, Learning Rate: 0.0025\n",
      "Epoch [5922/20000], Loss: 889.34912109375, Entropy 387.4348449707031, Learning Rate: 0.0025\n",
      "Epoch [5923/20000], Loss: 862.76171875, Entropy 404.6844482421875, Learning Rate: 0.0025\n",
      "Epoch [5924/20000], Loss: 916.5673828125, Entropy 384.060302734375, Learning Rate: 0.0025\n",
      "Epoch [5925/20000], Loss: 929.393798828125, Entropy 378.4215393066406, Learning Rate: 0.0025\n",
      "Epoch [5926/20000], Loss: 891.4353637695312, Entropy 388.60308837890625, Learning Rate: 0.0025\n",
      "Epoch [5927/20000], Loss: 916.1461791992188, Entropy 392.80023193359375, Learning Rate: 0.0025\n",
      "Epoch [5928/20000], Loss: 903.5205688476562, Entropy 383.00701904296875, Learning Rate: 0.0025\n",
      "Epoch [5929/20000], Loss: 917.4765014648438, Entropy 381.69732666015625, Learning Rate: 0.0025\n",
      "Epoch [5930/20000], Loss: 893.3484497070312, Entropy 383.71490478515625, Learning Rate: 0.0025\n",
      "Epoch [5931/20000], Loss: 880.797119140625, Entropy 388.4794006347656, Learning Rate: 0.0025\n",
      "Epoch [5932/20000], Loss: 919.2166748046875, Entropy 390.1301574707031, Learning Rate: 0.0025\n",
      "Epoch [5933/20000], Loss: 875.5352783203125, Entropy 392.268310546875, Learning Rate: 0.0025\n",
      "Epoch [5934/20000], Loss: 949.5903930664062, Entropy 377.32269287109375, Learning Rate: 0.0025\n",
      "Epoch [5935/20000], Loss: 933.492431640625, Entropy 381.6903381347656, Learning Rate: 0.0025\n",
      "Epoch [5936/20000], Loss: 864.3719482421875, Entropy 390.5169372558594, Learning Rate: 0.0025\n",
      "Epoch [5937/20000], Loss: 918.529052734375, Entropy 379.7350158691406, Learning Rate: 0.0025\n",
      "Epoch [5938/20000], Loss: 861.8713989257812, Entropy 390.53216552734375, Learning Rate: 0.0025\n",
      "Epoch [5939/20000], Loss: 910.810791015625, Entropy 386.4460144042969, Learning Rate: 0.0025\n",
      "Epoch [5940/20000], Loss: 891.18310546875, Entropy 385.907958984375, Learning Rate: 0.0025\n",
      "Epoch [5941/20000], Loss: 894.8847045898438, Entropy 390.47894287109375, Learning Rate: 0.0025\n",
      "Epoch [5942/20000], Loss: 870.859375, Entropy 394.2566223144531, Learning Rate: 0.0025\n",
      "Epoch [5943/20000], Loss: 930.8472290039062, Entropy 391.79803466796875, Learning Rate: 0.0025\n",
      "Epoch [5944/20000], Loss: 895.5361328125, Entropy 392.7789001464844, Learning Rate: 0.0025\n",
      "Epoch [5945/20000], Loss: 881.50537109375, Entropy 381.4197082519531, Learning Rate: 0.0025\n",
      "Epoch [5946/20000], Loss: 938.5726318359375, Entropy 377.0329284667969, Learning Rate: 0.0025\n",
      "Epoch [5947/20000], Loss: 900.918212890625, Entropy 409.5517578125, Learning Rate: 0.0025\n",
      "Epoch [5948/20000], Loss: 875.1799926757812, Entropy 389.31195068359375, Learning Rate: 0.0025\n",
      "Epoch [5949/20000], Loss: 923.3480224609375, Entropy 378.230224609375, Learning Rate: 0.0025\n",
      "Epoch [5950/20000], Loss: 898.37744140625, Entropy 379.2352294921875, Learning Rate: 0.0025\n",
      "Epoch [5951/20000], Loss: 879.19140625, Entropy 402.0181884765625, Learning Rate: 0.0025\n",
      "Epoch [5952/20000], Loss: 858.3887939453125, Entropy 394.2384338378906, Learning Rate: 0.0025\n",
      "Epoch [5953/20000], Loss: 885.0706787109375, Entropy 395.3821105957031, Learning Rate: 0.0025\n",
      "Epoch [5954/20000], Loss: 936.379638671875, Entropy 375.9920654296875, Learning Rate: 0.0025\n",
      "Epoch [5955/20000], Loss: 906.0462646484375, Entropy 399.6375732421875, Learning Rate: 0.0025\n",
      "Epoch [5956/20000], Loss: 924.856689453125, Entropy 388.9497985839844, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5957/20000], Loss: 931.0947875976562, Entropy 382.73529052734375, Learning Rate: 0.0025\n",
      "Epoch [5958/20000], Loss: 905.7006225585938, Entropy 405.27203369140625, Learning Rate: 0.0025\n",
      "Epoch [5959/20000], Loss: 853.4219360351562, Entropy 402.08392333984375, Learning Rate: 0.0025\n",
      "Epoch [5960/20000], Loss: 889.8265380859375, Entropy 390.6497497558594, Learning Rate: 0.0025\n",
      "Epoch [5961/20000], Loss: 876.1724853515625, Entropy 400.2203063964844, Learning Rate: 0.0025\n",
      "Epoch [5962/20000], Loss: 922.7567749023438, Entropy 392.92913818359375, Learning Rate: 0.0025\n",
      "Epoch [5963/20000], Loss: 887.6702880859375, Entropy 387.035888671875, Learning Rate: 0.0025\n",
      "Epoch [5964/20000], Loss: 863.9171142578125, Entropy 378.8018798828125, Learning Rate: 0.0025\n",
      "Epoch [5965/20000], Loss: 895.724853515625, Entropy 371.32470703125, Learning Rate: 0.0025\n",
      "Epoch [5966/20000], Loss: 906.111083984375, Entropy 395.795654296875, Learning Rate: 0.0025\n",
      "Epoch [5967/20000], Loss: 966.1024780273438, Entropy 369.74139404296875, Learning Rate: 0.0025\n",
      "Epoch [5968/20000], Loss: 896.7830200195312, Entropy 384.85589599609375, Learning Rate: 0.0025\n",
      "Epoch [5969/20000], Loss: 857.1378173828125, Entropy 391.9348449707031, Learning Rate: 0.0025\n",
      "Epoch [5970/20000], Loss: 889.13623046875, Entropy 396.3582763671875, Learning Rate: 0.0025\n",
      "Epoch [5971/20000], Loss: 926.5018920898438, Entropy 383.11431884765625, Learning Rate: 0.0025\n",
      "Epoch [5972/20000], Loss: 899.49755859375, Entropy 387.3587951660156, Learning Rate: 0.0025\n",
      "Epoch [5973/20000], Loss: 894.7490844726562, Entropy 400.12786865234375, Learning Rate: 0.0025\n",
      "Epoch [5974/20000], Loss: 935.519287109375, Entropy 389.2497863769531, Learning Rate: 0.0025\n",
      "Epoch [5975/20000], Loss: 925.0590209960938, Entropy 390.71905517578125, Learning Rate: 0.0025\n",
      "Epoch [5976/20000], Loss: 890.3628540039062, Entropy 399.60784912109375, Learning Rate: 0.0025\n",
      "Epoch [5977/20000], Loss: 911.8423461914062, Entropy 381.64898681640625, Learning Rate: 0.0025\n",
      "Epoch [5978/20000], Loss: 951.4873657226562, Entropy 391.48297119140625, Learning Rate: 0.0025\n",
      "Epoch [5979/20000], Loss: 899.8226318359375, Entropy 379.4482421875, Learning Rate: 0.0025\n",
      "Epoch [5980/20000], Loss: 907.9616088867188, Entropy 384.57525634765625, Learning Rate: 0.0025\n",
      "Epoch [5981/20000], Loss: 882.788330078125, Entropy 390.7413330078125, Learning Rate: 0.0025\n",
      "Epoch [5982/20000], Loss: 935.3038330078125, Entropy 370.5189514160156, Learning Rate: 0.0025\n",
      "Epoch [5983/20000], Loss: 875.81396484375, Entropy 380.788818359375, Learning Rate: 0.0025\n",
      "Epoch [5984/20000], Loss: 902.6854248046875, Entropy 387.708984375, Learning Rate: 0.0025\n",
      "Epoch [5985/20000], Loss: 881.1115112304688, Entropy 405.47552490234375, Learning Rate: 0.0025\n",
      "Epoch [5986/20000], Loss: 839.15087890625, Entropy 404.3375549316406, Learning Rate: 0.0025\n",
      "Epoch [5987/20000], Loss: 905.0888671875, Entropy 381.3143310546875, Learning Rate: 0.0025\n",
      "Epoch [5988/20000], Loss: 909.848388671875, Entropy 408.1286315917969, Learning Rate: 0.0025\n",
      "Epoch [5989/20000], Loss: 912.1828002929688, Entropy 383.22406005859375, Learning Rate: 0.0025\n",
      "Epoch [5990/20000], Loss: 866.3179931640625, Entropy 395.4272155761719, Learning Rate: 0.0025\n",
      "Epoch [5991/20000], Loss: 887.3255615234375, Entropy 388.4651184082031, Learning Rate: 0.0025\n",
      "Epoch [5992/20000], Loss: 865.2286987304688, Entropy 403.84295654296875, Learning Rate: 0.0025\n",
      "Epoch [5993/20000], Loss: 894.8936767578125, Entropy 385.0918273925781, Learning Rate: 0.0025\n",
      "Epoch [5994/20000], Loss: 872.30712890625, Entropy 390.8175048828125, Learning Rate: 0.0025\n",
      "Epoch [5995/20000], Loss: 885.9880981445312, Entropy 383.78729248046875, Learning Rate: 0.0025\n",
      "Epoch [5996/20000], Loss: 886.3199462890625, Entropy 398.9816589355469, Learning Rate: 0.0025\n",
      "Epoch [5997/20000], Loss: 908.4349365234375, Entropy 396.4856262207031, Learning Rate: 0.0025\n",
      "Epoch [5998/20000], Loss: 920.0881958007812, Entropy 385.38616943359375, Learning Rate: 0.0025\n",
      "Epoch [5999/20000], Loss: 918.0109252929688, Entropy 387.96234130859375, Learning Rate: 0.0025\n",
      "Epoch [6000/20000], Loss: 912.0947265625, Entropy 395.8860168457031, Learning Rate: 0.0025\n",
      "Epoch [6001/20000], Loss: 926.2686767578125, Entropy 379.400390625, Learning Rate: 0.0025\n",
      "Epoch [6002/20000], Loss: 870.9874267578125, Entropy 394.2628173828125, Learning Rate: 0.0025\n",
      "Epoch [6003/20000], Loss: 869.852783203125, Entropy 391.4853820800781, Learning Rate: 0.0025\n",
      "Epoch [6004/20000], Loss: 925.0109252929688, Entropy 383.05816650390625, Learning Rate: 0.0025\n",
      "Epoch [6005/20000], Loss: 906.87646484375, Entropy 384.5715637207031, Learning Rate: 0.0025\n",
      "Epoch [6006/20000], Loss: 892.38232421875, Entropy 397.8201904296875, Learning Rate: 0.0025\n",
      "Epoch [6007/20000], Loss: 875.1156616210938, Entropy 393.78277587890625, Learning Rate: 0.0025\n",
      "Epoch [6008/20000], Loss: 879.7479248046875, Entropy 391.0459289550781, Learning Rate: 0.0025\n",
      "Epoch [6009/20000], Loss: 880.65673828125, Entropy 393.296875, Learning Rate: 0.0025\n",
      "Epoch [6010/20000], Loss: 916.8574829101562, Entropy 397.73577880859375, Learning Rate: 0.0025\n",
      "Epoch [6011/20000], Loss: 908.9730224609375, Entropy 391.6497497558594, Learning Rate: 0.0025\n",
      "Epoch [6012/20000], Loss: 929.3838500976562, Entropy 374.20904541015625, Learning Rate: 0.0025\n",
      "Epoch [6013/20000], Loss: 862.87109375, Entropy 395.3944396972656, Learning Rate: 0.0025\n",
      "Epoch [6014/20000], Loss: 879.96337890625, Entropy 390.111083984375, Learning Rate: 0.0025\n",
      "Epoch [6015/20000], Loss: 912.25244140625, Entropy 395.566162109375, Learning Rate: 0.0025\n",
      "Epoch [6016/20000], Loss: 919.20166015625, Entropy 377.2660827636719, Learning Rate: 0.0025\n",
      "Epoch [6017/20000], Loss: 893.69482421875, Entropy 399.5810546875, Learning Rate: 0.0025\n",
      "Epoch [6018/20000], Loss: 875.2113037109375, Entropy 405.2967834472656, Learning Rate: 0.0025\n",
      "Epoch [6019/20000], Loss: 863.554443359375, Entropy 390.106201171875, Learning Rate: 0.0025\n",
      "Epoch [6020/20000], Loss: 901.1661376953125, Entropy 399.3744812011719, Learning Rate: 0.0025\n",
      "Epoch [6021/20000], Loss: 876.9400634765625, Entropy 388.9523620605469, Learning Rate: 0.0025\n",
      "Epoch [6022/20000], Loss: 894.77294921875, Entropy 396.64501953125, Learning Rate: 0.0025\n",
      "Epoch [6023/20000], Loss: 907.826416015625, Entropy 399.2823791503906, Learning Rate: 0.0025\n",
      "Epoch [6024/20000], Loss: 891.5, Entropy 398.9900817871094, Learning Rate: 0.0025\n",
      "Epoch [6025/20000], Loss: 913.82958984375, Entropy 397.0306091308594, Learning Rate: 0.0025\n",
      "Epoch [6026/20000], Loss: 893.9908447265625, Entropy 399.68115234375, Learning Rate: 0.0025\n",
      "Epoch [6027/20000], Loss: 897.800048828125, Entropy 380.1223449707031, Learning Rate: 0.0025\n",
      "Epoch [6028/20000], Loss: 898.1078491210938, Entropy 399.55230712890625, Learning Rate: 0.0025\n",
      "Epoch [6029/20000], Loss: 908.2177734375, Entropy 383.1915588378906, Learning Rate: 0.0025\n",
      "Epoch [6030/20000], Loss: 897.435302734375, Entropy 387.3940124511719, Learning Rate: 0.0025\n",
      "Epoch [6031/20000], Loss: 876.1981811523438, Entropy 381.53265380859375, Learning Rate: 0.0025\n",
      "Epoch [6032/20000], Loss: 947.60009765625, Entropy 395.0189514160156, Learning Rate: 0.0025\n",
      "Epoch [6033/20000], Loss: 954.0765380859375, Entropy 396.8852233886719, Learning Rate: 0.0025\n",
      "Epoch [6034/20000], Loss: 898.2660522460938, Entropy 406.61529541015625, Learning Rate: 0.0025\n",
      "Epoch [6035/20000], Loss: 938.609619140625, Entropy 381.60595703125, Learning Rate: 0.0025\n",
      "Epoch [6036/20000], Loss: 971.2911376953125, Entropy 399.0357666015625, Learning Rate: 0.0025\n",
      "Epoch [6037/20000], Loss: 906.6544189453125, Entropy 400.722412109375, Learning Rate: 0.0025\n",
      "Epoch [6038/20000], Loss: 919.886962890625, Entropy 385.5926818847656, Learning Rate: 0.0025\n",
      "Epoch [6039/20000], Loss: 900.041015625, Entropy 389.1882019042969, Learning Rate: 0.0025\n",
      "Epoch [6040/20000], Loss: 920.470703125, Entropy 392.5906982421875, Learning Rate: 0.0025\n",
      "Epoch [6041/20000], Loss: 886.2833251953125, Entropy 382.2804870605469, Learning Rate: 0.0025\n",
      "Epoch [6042/20000], Loss: 877.6990966796875, Entropy 389.3324279785156, Learning Rate: 0.0025\n",
      "Epoch [6043/20000], Loss: 939.3602294921875, Entropy 394.7742919921875, Learning Rate: 0.0025\n",
      "Epoch [6044/20000], Loss: 875.065185546875, Entropy 403.03515625, Learning Rate: 0.0025\n",
      "Epoch [6045/20000], Loss: 922.66650390625, Entropy 386.2965393066406, Learning Rate: 0.0025\n",
      "Epoch [6046/20000], Loss: 921.0589599609375, Entropy 385.2258605957031, Learning Rate: 0.0025\n",
      "Epoch [6047/20000], Loss: 878.6302490234375, Entropy 396.9606018066406, Learning Rate: 0.0025\n",
      "Epoch [6048/20000], Loss: 874.1785888671875, Entropy 409.0336608886719, Learning Rate: 0.0025\n",
      "Epoch [6049/20000], Loss: 898.736083984375, Entropy 389.7110595703125, Learning Rate: 0.0025\n",
      "Epoch [6050/20000], Loss: 890.6728515625, Entropy 412.3435974121094, Learning Rate: 0.0025\n",
      "Epoch [6051/20000], Loss: 924.401611328125, Entropy 374.1028747558594, Learning Rate: 0.0025\n",
      "Epoch [6052/20000], Loss: 890.8313598632812, Entropy 390.74749755859375, Learning Rate: 0.0025\n",
      "Epoch [6053/20000], Loss: 892.6942749023438, Entropy 400.75189208984375, Learning Rate: 0.0025\n",
      "Epoch [6054/20000], Loss: 940.7177734375, Entropy 379.1925048828125, Learning Rate: 0.0025\n",
      "Epoch [6055/20000], Loss: 923.644287109375, Entropy 392.80615234375, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6056/20000], Loss: 899.8209228515625, Entropy 401.2176208496094, Learning Rate: 0.0025\n",
      "Epoch [6057/20000], Loss: 921.9755249023438, Entropy 393.53851318359375, Learning Rate: 0.0025\n",
      "Epoch [6058/20000], Loss: 918.4588012695312, Entropy 399.09283447265625, Learning Rate: 0.0025\n",
      "Epoch [6059/20000], Loss: 863.7548828125, Entropy 394.1687316894531, Learning Rate: 0.0025\n",
      "Epoch [6060/20000], Loss: 870.77392578125, Entropy 396.4115905761719, Learning Rate: 0.0025\n",
      "Epoch [6061/20000], Loss: 913.261962890625, Entropy 400.2200622558594, Learning Rate: 0.0025\n",
      "Epoch [6062/20000], Loss: 872.8642578125, Entropy 392.5007629394531, Learning Rate: 0.0025\n",
      "Epoch [6063/20000], Loss: 856.8685302734375, Entropy 402.4457092285156, Learning Rate: 0.0025\n",
      "Epoch [6064/20000], Loss: 912.7167358398438, Entropy 393.70648193359375, Learning Rate: 0.0025\n",
      "Epoch [6065/20000], Loss: 953.255615234375, Entropy 390.0116271972656, Learning Rate: 0.0025\n",
      "Epoch [6066/20000], Loss: 925.4422607421875, Entropy 393.4273376464844, Learning Rate: 0.0025\n",
      "Epoch [6067/20000], Loss: 876.9627685546875, Entropy 389.8330383300781, Learning Rate: 0.0025\n",
      "Epoch [6068/20000], Loss: 935.678466796875, Entropy 405.1397705078125, Learning Rate: 0.0025\n",
      "Epoch [6069/20000], Loss: 931.1879272460938, Entropy 400.92779541015625, Learning Rate: 0.0025\n",
      "Epoch [6070/20000], Loss: 923.8465576171875, Entropy 396.0398254394531, Learning Rate: 0.0025\n",
      "Epoch [6071/20000], Loss: 943.4064331054688, Entropy 389.40850830078125, Learning Rate: 0.0025\n",
      "Epoch [6072/20000], Loss: 964.3375854492188, Entropy 402.30865478515625, Learning Rate: 0.0025\n",
      "Epoch [6073/20000], Loss: 884.4866943359375, Entropy 398.3152160644531, Learning Rate: 0.0025\n",
      "Epoch [6074/20000], Loss: 921.5030517578125, Entropy 386.0933532714844, Learning Rate: 0.0025\n",
      "Epoch [6075/20000], Loss: 899.5089111328125, Entropy 396.568115234375, Learning Rate: 0.0025\n",
      "Epoch [6076/20000], Loss: 927.9116821289062, Entropy 383.39202880859375, Learning Rate: 0.0025\n",
      "Epoch [6077/20000], Loss: 926.9569091796875, Entropy 388.1480407714844, Learning Rate: 0.0025\n",
      "Epoch [6078/20000], Loss: 908.6285400390625, Entropy 396.3096008300781, Learning Rate: 0.0025\n",
      "Epoch [6079/20000], Loss: 944.0118408203125, Entropy 386.9506530761719, Learning Rate: 0.0025\n",
      "Epoch [6080/20000], Loss: 940.0332641601562, Entropy 392.23187255859375, Learning Rate: 0.0025\n",
      "Epoch [6081/20000], Loss: 873.2318115234375, Entropy 408.0128173828125, Learning Rate: 0.0025\n",
      "Epoch [6082/20000], Loss: 894.9791259765625, Entropy 393.5751953125, Learning Rate: 0.0025\n",
      "Epoch [6083/20000], Loss: 882.5274658203125, Entropy 404.96044921875, Learning Rate: 0.0025\n",
      "Epoch [6084/20000], Loss: 888.4210205078125, Entropy 403.5819091796875, Learning Rate: 0.0025\n",
      "Epoch [6085/20000], Loss: 889.100830078125, Entropy 393.4918518066406, Learning Rate: 0.0025\n",
      "Epoch [6086/20000], Loss: 912.435302734375, Entropy 391.9476623535156, Learning Rate: 0.0025\n",
      "Epoch [6087/20000], Loss: 882.7196044921875, Entropy 394.0799255371094, Learning Rate: 0.0025\n",
      "Epoch [6088/20000], Loss: 884.4271240234375, Entropy 395.2882995605469, Learning Rate: 0.0025\n",
      "Epoch [6089/20000], Loss: 911.7947998046875, Entropy 397.8464660644531, Learning Rate: 0.0025\n",
      "Epoch [6090/20000], Loss: 922.6681518554688, Entropy 410.90631103515625, Learning Rate: 0.0025\n",
      "Epoch [6091/20000], Loss: 905.1548461914062, Entropy 399.44671630859375, Learning Rate: 0.0025\n",
      "Epoch [6092/20000], Loss: 935.895751953125, Entropy 395.5926818847656, Learning Rate: 0.0025\n",
      "Epoch [6093/20000], Loss: 854.466064453125, Entropy 390.0024108886719, Learning Rate: 0.0025\n",
      "Epoch [6094/20000], Loss: 907.221923828125, Entropy 386.11376953125, Learning Rate: 0.0025\n",
      "Epoch [6095/20000], Loss: 937.0499267578125, Entropy 398.615966796875, Learning Rate: 0.0025\n",
      "Epoch [6096/20000], Loss: 910.6639404296875, Entropy 399.08544921875, Learning Rate: 0.0025\n",
      "Epoch [6097/20000], Loss: 909.892578125, Entropy 396.9069519042969, Learning Rate: 0.0025\n",
      "Epoch [6098/20000], Loss: 909.8660888671875, Entropy 398.0203857421875, Learning Rate: 0.0025\n",
      "Epoch [6099/20000], Loss: 894.1063232421875, Entropy 402.9667053222656, Learning Rate: 0.0025\n",
      "Epoch [6100/20000], Loss: 921.0982666015625, Entropy 393.7541198730469, Learning Rate: 0.0025\n",
      "Epoch [6101/20000], Loss: 936.0128784179688, Entropy 401.44366455078125, Learning Rate: 0.0025\n",
      "Epoch [6102/20000], Loss: 937.9144287109375, Entropy 389.7610778808594, Learning Rate: 0.0025\n",
      "Epoch [6103/20000], Loss: 904.2716064453125, Entropy 401.0149230957031, Learning Rate: 0.0025\n",
      "Epoch [6104/20000], Loss: 894.77197265625, Entropy 395.00341796875, Learning Rate: 0.0025\n",
      "Epoch [6105/20000], Loss: 893.6866455078125, Entropy 398.7275695800781, Learning Rate: 0.0025\n",
      "Epoch [6106/20000], Loss: 896.5362548828125, Entropy 394.2525939941406, Learning Rate: 0.0025\n",
      "Epoch [6107/20000], Loss: 833.283203125, Entropy 397.2287292480469, Learning Rate: 0.0025\n",
      "Epoch [6108/20000], Loss: 931.3958740234375, Entropy 380.7704162597656, Learning Rate: 0.0025\n",
      "Epoch [6109/20000], Loss: 919.3172607421875, Entropy 390.4533386230469, Learning Rate: 0.0025\n",
      "Epoch [6110/20000], Loss: 933.0391845703125, Entropy 370.5278015136719, Learning Rate: 0.0025\n",
      "Epoch [6111/20000], Loss: 882.0745849609375, Entropy 400.4209289550781, Learning Rate: 0.0025\n",
      "Epoch [6112/20000], Loss: 925.860107421875, Entropy 394.2447814941406, Learning Rate: 0.0025\n",
      "Epoch [6113/20000], Loss: 949.3828735351562, Entropy 391.20611572265625, Learning Rate: 0.0025\n",
      "Epoch [6114/20000], Loss: 873.255126953125, Entropy 401.3863830566406, Learning Rate: 0.0025\n",
      "Epoch [6115/20000], Loss: 895.941650390625, Entropy 393.1584167480469, Learning Rate: 0.0025\n",
      "Epoch [6116/20000], Loss: 913.3719482421875, Entropy 402.2828674316406, Learning Rate: 0.0025\n",
      "Epoch [6117/20000], Loss: 902.791748046875, Entropy 409.2768249511719, Learning Rate: 0.0025\n",
      "Epoch [6118/20000], Loss: 910.2855224609375, Entropy 403.8238830566406, Learning Rate: 0.0025\n",
      "Epoch [6119/20000], Loss: 869.354248046875, Entropy 402.4951477050781, Learning Rate: 0.0025\n",
      "Epoch [6120/20000], Loss: 883.2833251953125, Entropy 399.7321472167969, Learning Rate: 0.0025\n",
      "Epoch [6121/20000], Loss: 932.3514404296875, Entropy 389.0186767578125, Learning Rate: 0.0025\n",
      "Epoch [6122/20000], Loss: 881.223388671875, Entropy 414.0329284667969, Learning Rate: 0.0025\n",
      "Epoch [6123/20000], Loss: 931.132080078125, Entropy 387.8363342285156, Learning Rate: 0.0025\n",
      "Epoch [6124/20000], Loss: 911.1336669921875, Entropy 393.0422668457031, Learning Rate: 0.0025\n",
      "Epoch [6125/20000], Loss: 896.7594604492188, Entropy 395.02301025390625, Learning Rate: 0.0025\n",
      "Epoch [6126/20000], Loss: 879.760009765625, Entropy 398.06787109375, Learning Rate: 0.0025\n",
      "Epoch [6127/20000], Loss: 880.645263671875, Entropy 410.9871520996094, Learning Rate: 0.0025\n",
      "Epoch [6128/20000], Loss: 938.2952880859375, Entropy 387.4978332519531, Learning Rate: 0.0025\n",
      "Epoch [6129/20000], Loss: 901.9769897460938, Entropy 387.49310302734375, Learning Rate: 0.0025\n",
      "Epoch [6130/20000], Loss: 878.8929443359375, Entropy 411.6653747558594, Learning Rate: 0.0025\n",
      "Epoch [6131/20000], Loss: 924.7413330078125, Entropy 392.1232604980469, Learning Rate: 0.0025\n",
      "Epoch [6132/20000], Loss: 960.7688598632812, Entropy 391.61639404296875, Learning Rate: 0.0025\n",
      "Epoch [6133/20000], Loss: 875.3737182617188, Entropy 401.00823974609375, Learning Rate: 0.0025\n",
      "Epoch [6134/20000], Loss: 882.6263427734375, Entropy 386.5670471191406, Learning Rate: 0.0025\n",
      "Epoch [6135/20000], Loss: 920.4374389648438, Entropy 405.59185791015625, Learning Rate: 0.0025\n",
      "Epoch [6136/20000], Loss: 893.26953125, Entropy 397.39453125, Learning Rate: 0.0025\n",
      "Epoch [6137/20000], Loss: 882.6785888671875, Entropy 400.3469543457031, Learning Rate: 0.0025\n",
      "Epoch [6138/20000], Loss: 916.11328125, Entropy 398.5832214355469, Learning Rate: 0.0025\n",
      "Epoch [6139/20000], Loss: 906.8064575195312, Entropy 396.04290771484375, Learning Rate: 0.0025\n",
      "Epoch [6140/20000], Loss: 923.988037109375, Entropy 406.3057861328125, Learning Rate: 0.0025\n",
      "Epoch [6141/20000], Loss: 953.0343017578125, Entropy 393.77099609375, Learning Rate: 0.0025\n",
      "Epoch [6142/20000], Loss: 934.0721435546875, Entropy 386.7117919921875, Learning Rate: 0.0025\n",
      "Epoch [6143/20000], Loss: 900.8897705078125, Entropy 380.658935546875, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6144/20000], Loss: 907.2005004882812, Entropy 397.39739990234375, Learning Rate: 0.0025\n",
      "Epoch [6145/20000], Loss: 906.485107421875, Entropy 387.3761901855469, Learning Rate: 0.0025\n",
      "Epoch [6146/20000], Loss: 867.0020751953125, Entropy 399.513671875, Learning Rate: 0.0025\n",
      "Epoch [6147/20000], Loss: 913.4525146484375, Entropy 387.2963562011719, Learning Rate: 0.0025\n",
      "Epoch [6148/20000], Loss: 867.0488891601562, Entropy 395.33843994140625, Learning Rate: 0.0025\n",
      "Epoch [6149/20000], Loss: 963.4991455078125, Entropy 401.3305358886719, Learning Rate: 0.0025\n",
      "Epoch [6150/20000], Loss: 914.3272705078125, Entropy 403.0951232910156, Learning Rate: 0.0025\n",
      "Epoch [6151/20000], Loss: 861.4600830078125, Entropy 410.4214782714844, Learning Rate: 0.0025\n",
      "Epoch [6152/20000], Loss: 913.7479248046875, Entropy 397.1663513183594, Learning Rate: 0.0025\n",
      "Epoch [6153/20000], Loss: 908.073486328125, Entropy 397.1899108886719, Learning Rate: 0.0025\n",
      "Epoch [6154/20000], Loss: 863.131591796875, Entropy 393.9723815917969, Learning Rate: 0.0025\n",
      "Epoch [6155/20000], Loss: 946.135009765625, Entropy 391.3372497558594, Learning Rate: 0.0025\n",
      "Epoch [6156/20000], Loss: 926.6051025390625, Entropy 389.264404296875, Learning Rate: 0.0025\n",
      "Epoch [6157/20000], Loss: 870.2451171875, Entropy 412.0704650878906, Learning Rate: 0.0025\n",
      "Epoch [6158/20000], Loss: 895.946533203125, Entropy 391.9538879394531, Learning Rate: 0.0025\n",
      "Epoch [6159/20000], Loss: 916.392822265625, Entropy 388.33349609375, Learning Rate: 0.0025\n",
      "Epoch [6160/20000], Loss: 896.275146484375, Entropy 379.8612060546875, Learning Rate: 0.0025\n",
      "Epoch [6161/20000], Loss: 898.5071411132812, Entropy 402.70318603515625, Learning Rate: 0.0025\n",
      "Epoch [6162/20000], Loss: 892.5335693359375, Entropy 392.5401916503906, Learning Rate: 0.0025\n",
      "Epoch [6163/20000], Loss: 949.2615966796875, Entropy 397.1275939941406, Learning Rate: 0.0025\n",
      "Epoch [6164/20000], Loss: 927.3637084960938, Entropy 403.08892822265625, Learning Rate: 0.0025\n",
      "Epoch [6165/20000], Loss: 884.6096801757812, Entropy 391.75335693359375, Learning Rate: 0.0025\n",
      "Epoch [6166/20000], Loss: 925.6412353515625, Entropy 394.0258483886719, Learning Rate: 0.0025\n",
      "Epoch [6167/20000], Loss: 928.58740234375, Entropy 404.9864807128906, Learning Rate: 0.0025\n",
      "Epoch [6168/20000], Loss: 964.7650146484375, Entropy 402.6833801269531, Learning Rate: 0.0025\n",
      "Epoch [6169/20000], Loss: 936.8543701171875, Entropy 400.0158386230469, Learning Rate: 0.0025\n",
      "Epoch [6170/20000], Loss: 936.818115234375, Entropy 394.4503173828125, Learning Rate: 0.0025\n",
      "Epoch [6171/20000], Loss: 921.053955078125, Entropy 398.5516662597656, Learning Rate: 0.0025\n",
      "Epoch [6172/20000], Loss: 859.6727905273438, Entropy 397.38470458984375, Learning Rate: 0.0025\n",
      "Epoch [6173/20000], Loss: 874.4215087890625, Entropy 389.4591369628906, Learning Rate: 0.0025\n",
      "Epoch [6174/20000], Loss: 925.862060546875, Entropy 391.1580810546875, Learning Rate: 0.0025\n",
      "Epoch [6175/20000], Loss: 883.6116943359375, Entropy 389.5325012207031, Learning Rate: 0.0025\n",
      "Epoch [6176/20000], Loss: 949.416259765625, Entropy 396.5774841308594, Learning Rate: 0.0025\n",
      "Epoch [6177/20000], Loss: 938.783447265625, Entropy 394.1041564941406, Learning Rate: 0.0025\n",
      "Epoch [6178/20000], Loss: 948.60791015625, Entropy 409.1646728515625, Learning Rate: 0.0025\n",
      "Epoch [6179/20000], Loss: 837.36865234375, Entropy 405.2261962890625, Learning Rate: 0.0025\n",
      "Epoch [6180/20000], Loss: 1050.5318603515625, Entropy 390.849609375, Learning Rate: 0.0025\n",
      "Epoch [6181/20000], Loss: 926.990966796875, Entropy 398.1085205078125, Learning Rate: 0.0025\n",
      "Epoch [6182/20000], Loss: 1051.46044921875, Entropy 400.1793212890625, Learning Rate: 0.0025\n",
      "Epoch [6183/20000], Loss: 993.7431640625, Entropy 402.8783874511719, Learning Rate: 0.0025\n",
      "Epoch [6184/20000], Loss: 1039.02490234375, Entropy 405.2839050292969, Learning Rate: 0.0025\n",
      "Epoch [6185/20000], Loss: 1014.2060546875, Entropy 396.120849609375, Learning Rate: 0.0025\n",
      "Epoch [6186/20000], Loss: 1145.35498046875, Entropy 388.2695617675781, Learning Rate: 0.0025\n",
      "Epoch [6187/20000], Loss: 1032.197998046875, Entropy 417.52435302734375, Learning Rate: 0.0025\n",
      "Epoch [6188/20000], Loss: 944.6879272460938, Entropy 406.31732177734375, Learning Rate: 0.0025\n",
      "Epoch [6189/20000], Loss: 1100.662841796875, Entropy 397.04058837890625, Learning Rate: 0.0025\n",
      "Epoch [6190/20000], Loss: 1179.36572265625, Entropy 405.69287109375, Learning Rate: 0.0025\n",
      "Epoch [6191/20000], Loss: 1084.6552734375, Entropy 398.3834228515625, Learning Rate: 0.0025\n",
      "Epoch [6192/20000], Loss: 1161.158203125, Entropy 401.816162109375, Learning Rate: 0.0025\n",
      "Epoch [6193/20000], Loss: 1115.4544677734375, Entropy 385.46484375, Learning Rate: 0.0025\n",
      "Epoch [6194/20000], Loss: 1314.234619140625, Entropy 390.4403076171875, Learning Rate: 0.0025\n",
      "Epoch [6195/20000], Loss: 1047.5391845703125, Entropy 382.5216979980469, Learning Rate: 0.0025\n",
      "Epoch [6196/20000], Loss: 1214.820556640625, Entropy 390.8520202636719, Learning Rate: 0.0025\n",
      "Epoch [6197/20000], Loss: 1059.91748046875, Entropy 391.41363525390625, Learning Rate: 0.0025\n",
      "Epoch [6198/20000], Loss: 1063.7149658203125, Entropy 404.880615234375, Learning Rate: 0.0025\n",
      "Epoch [6199/20000], Loss: 910.598388671875, Entropy 387.1800231933594, Learning Rate: 0.0025\n",
      "Epoch [6200/20000], Loss: 971.841796875, Entropy 392.4084167480469, Learning Rate: 0.0025\n",
      "Epoch [6201/20000], Loss: 1050.9765625, Entropy 387.1050720214844, Learning Rate: 0.0025\n",
      "Epoch [6202/20000], Loss: 1004.7802734375, Entropy 389.3788146972656, Learning Rate: 0.0025\n",
      "Epoch [6203/20000], Loss: 983.5077514648438, Entropy 393.81732177734375, Learning Rate: 0.0025\n",
      "Epoch [6204/20000], Loss: 975.099365234375, Entropy 388.1021423339844, Learning Rate: 0.0025\n",
      "Epoch [6205/20000], Loss: 927.2413940429688, Entropy 394.70916748046875, Learning Rate: 0.0025\n",
      "Epoch [6206/20000], Loss: 914.61865234375, Entropy 381.8958435058594, Learning Rate: 0.0025\n",
      "Epoch [6207/20000], Loss: 1004.284912109375, Entropy 378.770263671875, Learning Rate: 0.0025\n",
      "Epoch [6208/20000], Loss: 963.476318359375, Entropy 383.7589111328125, Learning Rate: 0.0025\n",
      "Epoch [6209/20000], Loss: 912.7360229492188, Entropy 391.42327880859375, Learning Rate: 0.0025\n",
      "Epoch [6210/20000], Loss: 946.5328369140625, Entropy 393.5788879394531, Learning Rate: 0.0025\n",
      "Epoch [6211/20000], Loss: 957.5100708007812, Entropy 380.93609619140625, Learning Rate: 0.0025\n",
      "Epoch [6212/20000], Loss: 964.2684326171875, Entropy 378.6658630371094, Learning Rate: 0.0025\n",
      "Epoch [6213/20000], Loss: 945.62255859375, Entropy 385.3363952636719, Learning Rate: 0.0025\n",
      "Epoch [6214/20000], Loss: 894.9988403320312, Entropy 384.27789306640625, Learning Rate: 0.0025\n",
      "Epoch [6215/20000], Loss: 950.70654296875, Entropy 389.08154296875, Learning Rate: 0.0025\n",
      "Epoch [6216/20000], Loss: 920.2530517578125, Entropy 371.9714660644531, Learning Rate: 0.0025\n",
      "Epoch [6217/20000], Loss: 903.4256591796875, Entropy 388.0459289550781, Learning Rate: 0.0025\n",
      "Epoch [6218/20000], Loss: 931.9930419921875, Entropy 386.3914489746094, Learning Rate: 0.0025\n",
      "Epoch [6219/20000], Loss: 915.4053955078125, Entropy 395.9112548828125, Learning Rate: 0.0025\n",
      "Epoch [6220/20000], Loss: 951.66748046875, Entropy 387.5541076660156, Learning Rate: 0.0025\n",
      "Epoch [6221/20000], Loss: 939.36669921875, Entropy 374.853271484375, Learning Rate: 0.0025\n",
      "Epoch [6222/20000], Loss: 916.74853515625, Entropy 391.6023864746094, Learning Rate: 0.0025\n",
      "Epoch [6223/20000], Loss: 870.2987670898438, Entropy 390.70147705078125, Learning Rate: 0.0025\n",
      "Epoch [6224/20000], Loss: 952.0623779296875, Entropy 372.7765808105469, Learning Rate: 0.0025\n",
      "Epoch [6225/20000], Loss: 958.4124755859375, Entropy 381.5820617675781, Learning Rate: 0.0025\n",
      "Epoch [6226/20000], Loss: 898.175048828125, Entropy 389.3547668457031, Learning Rate: 0.0025\n",
      "Epoch [6227/20000], Loss: 936.6407470703125, Entropy 380.53076171875, Learning Rate: 0.0025\n",
      "Epoch [6228/20000], Loss: 922.82080078125, Entropy 397.5174865722656, Learning Rate: 0.0025\n",
      "Epoch [6229/20000], Loss: 944.8372802734375, Entropy 376.2857666015625, Learning Rate: 0.0025\n",
      "Epoch [6230/20000], Loss: 894.6660766601562, Entropy 398.09368896484375, Learning Rate: 0.0025\n",
      "Epoch [6231/20000], Loss: 914.7293090820312, Entropy 384.31988525390625, Learning Rate: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6232/20000], Loss: 909.4652099609375, Entropy 386.1022644042969, Learning Rate: 0.0025\n",
      "Epoch [6233/20000], Loss: 921.5311279296875, Entropy 376.04638671875, Learning Rate: 0.0025\n",
      "Epoch [6234/20000], Loss: 918.6043701171875, Entropy 378.4211730957031, Learning Rate: 0.0025\n",
      "Epoch [6235/20000], Loss: 892.8453979492188, Entropy 382.53265380859375, Learning Rate: 0.0025\n",
      "Epoch [6236/20000], Loss: 915.357421875, Entropy 382.535888671875, Learning Rate: 0.0025\n",
      "Epoch [6237/20000], Loss: 860.6768798828125, Entropy 399.1820373535156, Learning Rate: 0.0025\n",
      "Epoch [6238/20000], Loss: 976.2355346679688, Entropy 385.50689697265625, Learning Rate: 0.0025\n",
      "Epoch [6239/20000], Loss: 895.0830078125, Entropy 404.5392150878906, Learning Rate: 0.0025\n",
      "Epoch [6240/20000], Loss: 907.139404296875, Entropy 380.3678894042969, Learning Rate: 0.0025\n",
      "Epoch [6241/20000], Loss: 878.13916015625, Entropy 388.2174377441406, Learning Rate: 0.0025\n",
      "Epoch [6242/20000], Loss: 950.3106689453125, Entropy 386.9685974121094, Learning Rate: 0.0025\n",
      "Epoch [6243/20000], Loss: 896.93603515625, Entropy 388.1788330078125, Learning Rate: 0.0025\n",
      "Epoch [6244/20000], Loss: 898.9938354492188, Entropy 395.68255615234375, Learning Rate: 0.0025\n",
      "Epoch [6245/20000], Loss: 911.695068359375, Entropy 382.2196044921875, Learning Rate: 0.0025\n",
      "Epoch [6246/20000], Loss: 924.2523193359375, Entropy 381.7311706542969, Learning Rate: 0.0025\n",
      "Epoch [6247/20000], Loss: 926.2399291992188, Entropy 383.65350341796875, Learning Rate: 0.0025\n",
      "Epoch [6248/20000], Loss: 934.6636962890625, Entropy 383.4635009765625, Learning Rate: 0.0025\n",
      "Epoch [6249/20000], Loss: 935.20654296875, Entropy 378.8469543457031, Learning Rate: 0.0025\n",
      "Epoch [6250/20000], Loss: 899.376220703125, Entropy 369.8731994628906, Learning Rate: 0.0025\n",
      "Epoch [6251/20000], Loss: 923.8215942382812, Entropy 382.88580322265625, Learning Rate: 0.0025\n",
      "Epoch [6252/20000], Loss: 956.92333984375, Entropy 374.8503723144531, Learning Rate: 0.0025\n",
      "Epoch [6253/20000], Loss: 943.2926635742188, Entropy 379.88922119140625, Learning Rate: 0.0025\n",
      "Epoch [6254/20000], Loss: 897.334716796875, Entropy 385.8644714355469, Learning Rate: 0.0025\n",
      "Epoch [6255/20000], Loss: 903.01025390625, Entropy 382.9933166503906, Learning Rate: 0.0025\n",
      "Epoch [6256/20000], Loss: 929.78125, Entropy 386.9376525878906, Learning Rate: 0.0025\n",
      "Epoch [6257/20000], Loss: 884.985107421875, Entropy 384.0385437011719, Learning Rate: 0.0025\n",
      "Epoch [6258/20000], Loss: 854.3388671875, Entropy 390.3727111816406, Learning Rate: 0.0025\n",
      "Epoch [6259/20000], Loss: 903.2091064453125, Entropy 384.5094299316406, Learning Rate: 0.0025\n",
      "Epoch [6260/20000], Loss: 885.4092407226562, Entropy 391.67999267578125, Learning Rate: 0.0025\n",
      "Epoch [6261/20000], Loss: 894.2840576171875, Entropy 385.4558410644531, Learning Rate: 0.0025\n",
      "Epoch [6262/20000], Loss: 900.3741455078125, Entropy 400.7518615722656, Learning Rate: 0.0025\n",
      "Epoch [6263/20000], Loss: 894.7496337890625, Entropy 391.724609375, Learning Rate: 0.0025\n",
      "Epoch [6264/20000], Loss: 894.8433227539062, Entropy 391.79888916015625, Learning Rate: 0.0025\n",
      "Epoch [6265/20000], Loss: 864.6275634765625, Entropy 382.6219482421875, Learning Rate: 0.0025\n",
      "Epoch [6266/20000], Loss: 886.508544921875, Entropy 385.0118713378906, Learning Rate: 0.0025\n",
      "Epoch [6267/20000], Loss: 865.387939453125, Entropy 387.883544921875, Learning Rate: 0.0025\n",
      "Epoch [6268/20000], Loss: 892.36767578125, Entropy 392.41796875, Learning Rate: 0.0025\n",
      "Epoch [6269/20000], Loss: 921.8840942382812, Entropy 379.57855224609375, Learning Rate: 0.0025\n",
      "Epoch [6270/20000], Loss: 876.7556762695312, Entropy 396.61553955078125, Learning Rate: 0.0025\n",
      "Epoch [6271/20000], Loss: 939.5374755859375, Entropy 369.4097595214844, Learning Rate: 0.0025\n",
      "Epoch [6272/20000], Loss: 891.0780029296875, Entropy 374.8717041015625, Learning Rate: 0.0025\n",
      "Epoch [6273/20000], Loss: 923.9081420898438, Entropy 398.80963134765625, Learning Rate: 0.0025\n",
      "Epoch [6274/20000], Loss: 894.2703857421875, Entropy 396.0013732910156, Learning Rate: 0.0025\n",
      "Epoch [6275/20000], Loss: 893.511962890625, Entropy 396.4097595214844, Learning Rate: 0.0025\n",
      "Epoch [6276/20000], Loss: 893.175048828125, Entropy 386.9493713378906, Learning Rate: 0.0025\n",
      "Epoch [6277/20000], Loss: 878.9775390625, Entropy 393.679443359375, Learning Rate: 0.0025\n",
      "Epoch [6278/20000], Loss: 930.1541748046875, Entropy 382.0205383300781, Learning Rate: 0.0025\n",
      "Epoch [6279/20000], Loss: 947.6934814453125, Entropy 382.5414733886719, Learning Rate: 0.0025\n",
      "Epoch [6280/20000], Loss: 887.2765502929688, Entropy 384.17572021484375, Learning Rate: 0.0025\n",
      "Epoch [6281/20000], Loss: 928.138916015625, Entropy 397.28662109375, Learning Rate: 0.0025\n",
      "Epoch [6282/20000], Loss: 878.78466796875, Entropy 401.2108154296875, Learning Rate: 0.0025\n",
      "Epoch [6283/20000], Loss: 906.0767822265625, Entropy 384.3283386230469, Learning Rate: 0.0025\n",
      "Epoch [6284/20000], Loss: 920.3494873046875, Entropy 385.6811218261719, Learning Rate: 0.0025\n",
      "Epoch [6285/20000], Loss: 901.6791381835938, Entropy 395.64349365234375, Learning Rate: 0.0025\n",
      "Epoch [6286/20000], Loss: 887.6990356445312, Entropy 387.01409912109375, Learning Rate: 0.0025\n",
      "Epoch [6287/20000], Loss: 905.2387084960938, Entropy 405.90472412109375, Learning Rate: 0.0025\n",
      "Epoch [6288/20000], Loss: 915.2445678710938, Entropy 400.94171142578125, Learning Rate: 0.0025\n",
      "Epoch [6289/20000], Loss: 886.4224853515625, Entropy 392.91259765625, Learning Rate: 0.0025\n",
      "Epoch [6290/20000], Loss: 1020.260986328125, Entropy 388.7300720214844, Learning Rate: 0.0025\n",
      "Epoch [6291/20000], Loss: 985.1904907226562, Entropy 395.97015380859375, Learning Rate: 0.0025\n",
      "Epoch [6292/20000], Loss: 939.1749267578125, Entropy 397.5505065917969, Learning Rate: 0.0025\n",
      "Epoch [6293/20000], Loss: 930.7403564453125, Entropy 382.0077209472656, Learning Rate: 0.0025\n",
      "Epoch [6294/20000], Loss: 973.0809936523438, Entropy 392.21112060546875, Learning Rate: 0.0025\n",
      "Epoch [6295/20000], Loss: 894.9669799804688, Entropy 377.73687744140625, Learning Rate: 0.0025\n",
      "Epoch [6296/20000], Loss: 1020.994140625, Entropy 385.0145263671875, Learning Rate: 0.0025\n",
      "Epoch [6297/20000], Loss: 983.8517456054688, Entropy 393.73333740234375, Learning Rate: 0.0025\n",
      "Epoch [6298/20000], Loss: 976.809814453125, Entropy 396.1388854980469, Learning Rate: 0.0025\n",
      "Epoch [6299/20000], Loss: 898.4876708984375, Entropy 397.6993408203125, Learning Rate: 0.00125\n",
      "Epoch [6300/20000], Loss: 974.7393798828125, Entropy 385.2613525390625, Learning Rate: 0.00125\n",
      "Epoch [6301/20000], Loss: 961.77587890625, Entropy 382.6015930175781, Learning Rate: 0.00125\n",
      "Epoch [6302/20000], Loss: 917.341796875, Entropy 388.9617919921875, Learning Rate: 0.00125\n",
      "Epoch [6303/20000], Loss: 914.8301391601562, Entropy 405.28814697265625, Learning Rate: 0.00125\n",
      "Epoch [6304/20000], Loss: 920.6036987304688, Entropy 397.96319580078125, Learning Rate: 0.00125\n",
      "Epoch [6305/20000], Loss: 889.720947265625, Entropy 384.6258850097656, Learning Rate: 0.00125\n",
      "Epoch [6306/20000], Loss: 911.07470703125, Entropy 396.41357421875, Learning Rate: 0.00125\n",
      "Epoch [6307/20000], Loss: 895.182861328125, Entropy 380.4259948730469, Learning Rate: 0.00125\n",
      "Epoch [6308/20000], Loss: 892.704345703125, Entropy 389.9203796386719, Learning Rate: 0.00125\n",
      "Epoch [6309/20000], Loss: 892.474853515625, Entropy 388.3738098144531, Learning Rate: 0.00125\n",
      "Epoch [6310/20000], Loss: 892.9906005859375, Entropy 404.8533630371094, Learning Rate: 0.00125\n",
      "Epoch [6311/20000], Loss: 903.6264038085938, Entropy 373.29046630859375, Learning Rate: 0.00125\n",
      "Epoch [6312/20000], Loss: 903.5128173828125, Entropy 382.4485778808594, Learning Rate: 0.00125\n",
      "Epoch [6313/20000], Loss: 905.3471069335938, Entropy 392.10406494140625, Learning Rate: 0.00125\n",
      "Epoch [6314/20000], Loss: 881.7696533203125, Entropy 388.1932678222656, Learning Rate: 0.00125\n",
      "Epoch [6315/20000], Loss: 917.70703125, Entropy 385.0096740722656, Learning Rate: 0.00125\n",
      "Epoch [6316/20000], Loss: 917.770263671875, Entropy 394.7484436035156, Learning Rate: 0.00125\n",
      "Epoch [6317/20000], Loss: 900.15673828125, Entropy 400.70458984375, Learning Rate: 0.00125\n",
      "Epoch [6318/20000], Loss: 896.35107421875, Entropy 371.7113952636719, Learning Rate: 0.00125\n",
      "Epoch [6319/20000], Loss: 939.6451416015625, Entropy 381.6729736328125, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6320/20000], Loss: 899.6749267578125, Entropy 391.1522521972656, Learning Rate: 0.00125\n",
      "Epoch [6321/20000], Loss: 930.681884765625, Entropy 394.6280517578125, Learning Rate: 0.00125\n",
      "Epoch [6322/20000], Loss: 882.009033203125, Entropy 398.4945983886719, Learning Rate: 0.00125\n",
      "Epoch [6323/20000], Loss: 895.5719604492188, Entropy 391.30609130859375, Learning Rate: 0.00125\n",
      "Epoch [6324/20000], Loss: 868.5269775390625, Entropy 386.732177734375, Learning Rate: 0.00125\n",
      "Epoch [6325/20000], Loss: 883.859375, Entropy 384.2673645019531, Learning Rate: 0.00125\n",
      "Epoch [6326/20000], Loss: 894.9379272460938, Entropy 396.19818115234375, Learning Rate: 0.00125\n",
      "Epoch [6327/20000], Loss: 894.580078125, Entropy 387.2800598144531, Learning Rate: 0.00125\n",
      "Epoch [6328/20000], Loss: 902.6863403320312, Entropy 391.38092041015625, Learning Rate: 0.00125\n",
      "Epoch [6329/20000], Loss: 928.3927001953125, Entropy 387.0185546875, Learning Rate: 0.00125\n",
      "Epoch [6330/20000], Loss: 921.9661865234375, Entropy 382.5420227050781, Learning Rate: 0.00125\n",
      "Epoch [6331/20000], Loss: 891.619384765625, Entropy 401.2188720703125, Learning Rate: 0.00125\n",
      "Epoch [6332/20000], Loss: 887.6549682617188, Entropy 398.44573974609375, Learning Rate: 0.00125\n",
      "Epoch [6333/20000], Loss: 899.0880126953125, Entropy 386.1345520019531, Learning Rate: 0.00125\n",
      "Epoch [6334/20000], Loss: 862.338134765625, Entropy 395.9790954589844, Learning Rate: 0.00125\n",
      "Epoch [6335/20000], Loss: 919.4332275390625, Entropy 396.3828430175781, Learning Rate: 0.00125\n",
      "Epoch [6336/20000], Loss: 927.3701171875, Entropy 391.1742248535156, Learning Rate: 0.00125\n",
      "Epoch [6337/20000], Loss: 901.554443359375, Entropy 392.7126770019531, Learning Rate: 0.00125\n",
      "Epoch [6338/20000], Loss: 865.5643920898438, Entropy 397.57818603515625, Learning Rate: 0.00125\n",
      "Epoch [6339/20000], Loss: 899.5697021484375, Entropy 381.6095886230469, Learning Rate: 0.00125\n",
      "Epoch [6340/20000], Loss: 907.831298828125, Entropy 382.41943359375, Learning Rate: 0.00125\n",
      "Epoch [6341/20000], Loss: 915.3495483398438, Entropy 401.47161865234375, Learning Rate: 0.00125\n",
      "Epoch [6342/20000], Loss: 855.3812255859375, Entropy 387.1313171386719, Learning Rate: 0.00125\n",
      "Epoch [6343/20000], Loss: 891.4662475585938, Entropy 397.70562744140625, Learning Rate: 0.00125\n",
      "Epoch [6344/20000], Loss: 855.076904296875, Entropy 397.4344787597656, Learning Rate: 0.00125\n",
      "Epoch [6345/20000], Loss: 922.021728515625, Entropy 386.7735595703125, Learning Rate: 0.00125\n",
      "Epoch [6346/20000], Loss: 901.406982421875, Entropy 380.7017822265625, Learning Rate: 0.00125\n",
      "Epoch [6347/20000], Loss: 864.7822265625, Entropy 387.6214294433594, Learning Rate: 0.00125\n",
      "Epoch [6348/20000], Loss: 913.720703125, Entropy 392.2014465332031, Learning Rate: 0.00125\n",
      "Epoch [6349/20000], Loss: 889.185791015625, Entropy 385.484375, Learning Rate: 0.00125\n",
      "Epoch [6350/20000], Loss: 904.559814453125, Entropy 401.3776550292969, Learning Rate: 0.00125\n",
      "Epoch [6351/20000], Loss: 879.24755859375, Entropy 389.1097717285156, Learning Rate: 0.00125\n",
      "Epoch [6352/20000], Loss: 885.298095703125, Entropy 390.4987487792969, Learning Rate: 0.00125\n",
      "Epoch [6353/20000], Loss: 914.4927978515625, Entropy 386.5728759765625, Learning Rate: 0.00125\n",
      "Epoch [6354/20000], Loss: 877.174072265625, Entropy 391.8864440917969, Learning Rate: 0.00125\n",
      "Epoch [6355/20000], Loss: 920.402587890625, Entropy 395.8031921386719, Learning Rate: 0.00125\n",
      "Epoch [6356/20000], Loss: 884.408447265625, Entropy 398.48583984375, Learning Rate: 0.00125\n",
      "Epoch [6357/20000], Loss: 888.3450927734375, Entropy 380.7220764160156, Learning Rate: 0.00125\n",
      "Epoch [6358/20000], Loss: 924.2366943359375, Entropy 389.06884765625, Learning Rate: 0.00125\n",
      "Epoch [6359/20000], Loss: 909.3463134765625, Entropy 388.3971862792969, Learning Rate: 0.00125\n",
      "Epoch [6360/20000], Loss: 878.3734130859375, Entropy 382.7781066894531, Learning Rate: 0.00125\n",
      "Epoch [6361/20000], Loss: 871.429443359375, Entropy 392.173828125, Learning Rate: 0.00125\n",
      "Epoch [6362/20000], Loss: 879.304931640625, Entropy 393.0201416015625, Learning Rate: 0.00125\n",
      "Epoch [6363/20000], Loss: 896.0465087890625, Entropy 399.823974609375, Learning Rate: 0.00125\n",
      "Epoch [6364/20000], Loss: 903.9683227539062, Entropy 388.50982666015625, Learning Rate: 0.00125\n",
      "Epoch [6365/20000], Loss: 884.7320556640625, Entropy 395.3130798339844, Learning Rate: 0.00125\n",
      "Epoch [6366/20000], Loss: 927.4017333984375, Entropy 388.7654113769531, Learning Rate: 0.00125\n",
      "Epoch [6367/20000], Loss: 924.97314453125, Entropy 390.8189697265625, Learning Rate: 0.00125\n",
      "Epoch [6368/20000], Loss: 900.0199584960938, Entropy 385.51788330078125, Learning Rate: 0.00125\n",
      "Epoch [6369/20000], Loss: 853.2286987304688, Entropy 401.50933837890625, Learning Rate: 0.00125\n",
      "Epoch [6370/20000], Loss: 861.1632080078125, Entropy 411.1064758300781, Learning Rate: 0.00125\n",
      "Epoch [6371/20000], Loss: 888.5042724609375, Entropy 394.0785827636719, Learning Rate: 0.00125\n",
      "Epoch [6372/20000], Loss: 915.75927734375, Entropy 395.6560974121094, Learning Rate: 0.00125\n",
      "Epoch [6373/20000], Loss: 920.3222045898438, Entropy 386.33978271484375, Learning Rate: 0.00125\n",
      "Epoch [6374/20000], Loss: 927.7787475585938, Entropy 379.10052490234375, Learning Rate: 0.00125\n",
      "Epoch [6375/20000], Loss: 928.786865234375, Entropy 391.505615234375, Learning Rate: 0.00125\n",
      "Epoch [6376/20000], Loss: 883.6739501953125, Entropy 398.8316955566406, Learning Rate: 0.00125\n",
      "Epoch [6377/20000], Loss: 866.2005615234375, Entropy 395.2306823730469, Learning Rate: 0.00125\n",
      "Epoch [6378/20000], Loss: 883.903564453125, Entropy 391.48291015625, Learning Rate: 0.00125\n",
      "Epoch [6379/20000], Loss: 877.6192626953125, Entropy 388.5270080566406, Learning Rate: 0.00125\n",
      "Epoch [6380/20000], Loss: 866.9486083984375, Entropy 408.8563232421875, Learning Rate: 0.00125\n",
      "Epoch [6381/20000], Loss: 882.5079956054688, Entropy 396.69061279296875, Learning Rate: 0.00125\n",
      "Epoch [6382/20000], Loss: 909.6940307617188, Entropy 387.98077392578125, Learning Rate: 0.00125\n",
      "Epoch [6383/20000], Loss: 919.0052490234375, Entropy 378.7802734375, Learning Rate: 0.00125\n",
      "Epoch [6384/20000], Loss: 879.9537963867188, Entropy 387.52069091796875, Learning Rate: 0.00125\n",
      "Epoch [6385/20000], Loss: 885.181884765625, Entropy 397.2426452636719, Learning Rate: 0.00125\n",
      "Epoch [6386/20000], Loss: 880.985107421875, Entropy 388.7347717285156, Learning Rate: 0.00125\n",
      "Epoch [6387/20000], Loss: 920.788330078125, Entropy 386.6410217285156, Learning Rate: 0.00125\n",
      "Epoch [6388/20000], Loss: 875.0719604492188, Entropy 387.70758056640625, Learning Rate: 0.00125\n",
      "Epoch [6389/20000], Loss: 890.2825927734375, Entropy 385.3915100097656, Learning Rate: 0.00125\n",
      "Epoch [6390/20000], Loss: 869.9413452148438, Entropy 389.55474853515625, Learning Rate: 0.00125\n",
      "Epoch [6391/20000], Loss: 895.579345703125, Entropy 394.4658508300781, Learning Rate: 0.00125\n",
      "Epoch [6392/20000], Loss: 871.0731201171875, Entropy 397.5130920410156, Learning Rate: 0.00125\n",
      "Epoch [6393/20000], Loss: 881.7555541992188, Entropy 390.21099853515625, Learning Rate: 0.00125\n",
      "Epoch [6394/20000], Loss: 877.1602783203125, Entropy 402.4524841308594, Learning Rate: 0.00125\n",
      "Epoch [6395/20000], Loss: 878.119873046875, Entropy 395.4713439941406, Learning Rate: 0.00125\n",
      "Epoch [6396/20000], Loss: 900.194580078125, Entropy 389.34228515625, Learning Rate: 0.00125\n",
      "Epoch [6397/20000], Loss: 946.8596801757812, Entropy 403.20159912109375, Learning Rate: 0.00125\n",
      "Epoch [6398/20000], Loss: 853.4410400390625, Entropy 397.626708984375, Learning Rate: 0.00125\n",
      "Epoch [6399/20000], Loss: 866.2493896484375, Entropy 396.2707824707031, Learning Rate: 0.00125\n",
      "Epoch [6400/20000], Loss: 892.524169921875, Entropy 384.7265625, Learning Rate: 0.00125\n",
      "Epoch [6401/20000], Loss: 905.0291748046875, Entropy 397.011474609375, Learning Rate: 0.00125\n",
      "Epoch [6402/20000], Loss: 903.65625, Entropy 396.4594421386719, Learning Rate: 0.00125\n",
      "Epoch [6403/20000], Loss: 865.576171875, Entropy 393.8564758300781, Learning Rate: 0.00125\n",
      "Epoch [6404/20000], Loss: 853.168701171875, Entropy 394.2657775878906, Learning Rate: 0.00125\n",
      "Epoch [6405/20000], Loss: 880.7932739257812, Entropy 397.07611083984375, Learning Rate: 0.00125\n",
      "Epoch [6406/20000], Loss: 914.5894775390625, Entropy 400.9026794433594, Learning Rate: 0.00125\n",
      "Epoch [6407/20000], Loss: 847.6185302734375, Entropy 405.7328186035156, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6408/20000], Loss: 874.847412109375, Entropy 393.1272277832031, Learning Rate: 0.00125\n",
      "Epoch [6409/20000], Loss: 862.12353515625, Entropy 409.4875183105469, Learning Rate: 0.00125\n",
      "Epoch [6410/20000], Loss: 896.9541015625, Entropy 387.0216369628906, Learning Rate: 0.00125\n",
      "Epoch [6411/20000], Loss: 867.8637084960938, Entropy 395.91912841796875, Learning Rate: 0.00125\n",
      "Epoch [6412/20000], Loss: 897.6119384765625, Entropy 394.5414733886719, Learning Rate: 0.00125\n",
      "Epoch [6413/20000], Loss: 875.2275390625, Entropy 395.5982971191406, Learning Rate: 0.00125\n",
      "Epoch [6414/20000], Loss: 877.0123901367188, Entropy 387.88311767578125, Learning Rate: 0.00125\n",
      "Epoch [6415/20000], Loss: 874.1016845703125, Entropy 393.1495361328125, Learning Rate: 0.00125\n",
      "Epoch [6416/20000], Loss: 919.246337890625, Entropy 392.9508056640625, Learning Rate: 0.00125\n",
      "Epoch [6417/20000], Loss: 895.9461669921875, Entropy 400.1285705566406, Learning Rate: 0.00125\n",
      "Epoch [6418/20000], Loss: 906.6791381835938, Entropy 391.30560302734375, Learning Rate: 0.00125\n",
      "Epoch [6419/20000], Loss: 888.058349609375, Entropy 395.3722229003906, Learning Rate: 0.00125\n",
      "Epoch [6420/20000], Loss: 900.9317626953125, Entropy 385.6833190917969, Learning Rate: 0.00125\n",
      "Epoch [6421/20000], Loss: 874.7432861328125, Entropy 397.1695251464844, Learning Rate: 0.00125\n",
      "Epoch [6422/20000], Loss: 934.66455078125, Entropy 400.0832824707031, Learning Rate: 0.00125\n",
      "Epoch [6423/20000], Loss: 855.101806640625, Entropy 406.5577392578125, Learning Rate: 0.00125\n",
      "Epoch [6424/20000], Loss: 858.4306640625, Entropy 400.8879699707031, Learning Rate: 0.00125\n",
      "Epoch [6425/20000], Loss: 866.0869140625, Entropy 408.942138671875, Learning Rate: 0.00125\n",
      "Epoch [6426/20000], Loss: 900.1612548828125, Entropy 406.1477355957031, Learning Rate: 0.00125\n",
      "Epoch [6427/20000], Loss: 846.757080078125, Entropy 414.838623046875, Learning Rate: 0.00125\n",
      "Epoch [6428/20000], Loss: 880.2391357421875, Entropy 405.2214050292969, Learning Rate: 0.00125\n",
      "Epoch [6429/20000], Loss: 877.069091796875, Entropy 396.5819396972656, Learning Rate: 0.00125\n",
      "Epoch [6430/20000], Loss: 904.5142822265625, Entropy 401.7742004394531, Learning Rate: 0.00125\n",
      "Epoch [6431/20000], Loss: 864.620849609375, Entropy 397.3945617675781, Learning Rate: 0.00125\n",
      "Epoch [6432/20000], Loss: 889.799072265625, Entropy 399.3970947265625, Learning Rate: 0.00125\n",
      "Epoch [6433/20000], Loss: 865.459228515625, Entropy 387.7191467285156, Learning Rate: 0.00125\n",
      "Epoch [6434/20000], Loss: 876.6583251953125, Entropy 403.0884704589844, Learning Rate: 0.00125\n",
      "Epoch [6435/20000], Loss: 881.826171875, Entropy 401.3324890136719, Learning Rate: 0.00125\n",
      "Epoch [6436/20000], Loss: 910.7127685546875, Entropy 389.5447998046875, Learning Rate: 0.00125\n",
      "Epoch [6437/20000], Loss: 897.3402099609375, Entropy 386.2817077636719, Learning Rate: 0.00125\n",
      "Epoch [6438/20000], Loss: 890.5980834960938, Entropy 399.21124267578125, Learning Rate: 0.00125\n",
      "Epoch [6439/20000], Loss: 947.2713623046875, Entropy 390.3067932128906, Learning Rate: 0.00125\n",
      "Epoch [6440/20000], Loss: 837.6226806640625, Entropy 385.2144775390625, Learning Rate: 0.00125\n",
      "Epoch [6441/20000], Loss: 844.185302734375, Entropy 412.3933410644531, Learning Rate: 0.00125\n",
      "Epoch [6442/20000], Loss: 899.9822998046875, Entropy 405.2043762207031, Learning Rate: 0.00125\n",
      "Epoch [6443/20000], Loss: 868.947021484375, Entropy 407.1624450683594, Learning Rate: 0.00125\n",
      "Epoch [6444/20000], Loss: 867.6649780273438, Entropy 404.85113525390625, Learning Rate: 0.00125\n",
      "Epoch [6445/20000], Loss: 827.7889404296875, Entropy 396.9386901855469, Learning Rate: 0.00125\n",
      "Epoch [6446/20000], Loss: 915.9222412109375, Entropy 378.568115234375, Learning Rate: 0.00125\n",
      "Epoch [6447/20000], Loss: 869.495361328125, Entropy 398.9474182128906, Learning Rate: 0.00125\n",
      "Epoch [6448/20000], Loss: 891.40771484375, Entropy 398.0804748535156, Learning Rate: 0.00125\n",
      "Epoch [6449/20000], Loss: 870.38623046875, Entropy 400.58984375, Learning Rate: 0.00125\n",
      "Epoch [6450/20000], Loss: 923.501220703125, Entropy 388.7167053222656, Learning Rate: 0.00125\n",
      "Epoch [6451/20000], Loss: 884.6388549804688, Entropy 396.24114990234375, Learning Rate: 0.00125\n",
      "Epoch [6452/20000], Loss: 905.7838134765625, Entropy 383.2406921386719, Learning Rate: 0.00125\n",
      "Epoch [6453/20000], Loss: 868.7596435546875, Entropy 404.5318603515625, Learning Rate: 0.00125\n",
      "Epoch [6454/20000], Loss: 877.5635986328125, Entropy 393.3332214355469, Learning Rate: 0.00125\n",
      "Epoch [6455/20000], Loss: 873.55615234375, Entropy 401.6307678222656, Learning Rate: 0.00125\n",
      "Epoch [6456/20000], Loss: 845.7540283203125, Entropy 401.1561584472656, Learning Rate: 0.00125\n",
      "Epoch [6457/20000], Loss: 875.6820068359375, Entropy 393.3515930175781, Learning Rate: 0.00125\n",
      "Epoch [6458/20000], Loss: 917.5689086914062, Entropy 399.44622802734375, Learning Rate: 0.00125\n",
      "Epoch [6459/20000], Loss: 905.933837890625, Entropy 399.0188903808594, Learning Rate: 0.00125\n",
      "Epoch [6460/20000], Loss: 867.2823486328125, Entropy 389.3850402832031, Learning Rate: 0.00125\n",
      "Epoch [6461/20000], Loss: 880.5352783203125, Entropy 414.5799560546875, Learning Rate: 0.00125\n",
      "Epoch [6462/20000], Loss: 909.22705078125, Entropy 397.1513977050781, Learning Rate: 0.00125\n",
      "Epoch [6463/20000], Loss: 874.881103515625, Entropy 402.2444763183594, Learning Rate: 0.00125\n",
      "Epoch [6464/20000], Loss: 895.2378540039062, Entropy 401.10882568359375, Learning Rate: 0.00125\n",
      "Epoch [6465/20000], Loss: 872.46044921875, Entropy 398.0133056640625, Learning Rate: 0.00125\n",
      "Epoch [6466/20000], Loss: 866.5736083984375, Entropy 386.8111572265625, Learning Rate: 0.00125\n",
      "Epoch [6467/20000], Loss: 887.5630493164062, Entropy 405.66461181640625, Learning Rate: 0.00125\n",
      "Epoch [6468/20000], Loss: 867.73876953125, Entropy 407.0026550292969, Learning Rate: 0.00125\n",
      "Epoch [6469/20000], Loss: 883.373046875, Entropy 401.552490234375, Learning Rate: 0.00125\n",
      "Epoch [6470/20000], Loss: 903.434814453125, Entropy 402.1746826171875, Learning Rate: 0.00125\n",
      "Epoch [6471/20000], Loss: 884.4678955078125, Entropy 400.005615234375, Learning Rate: 0.00125\n",
      "Epoch [6472/20000], Loss: 862.5352783203125, Entropy 409.939208984375, Learning Rate: 0.00125\n",
      "Epoch [6473/20000], Loss: 869.934814453125, Entropy 411.8135070800781, Learning Rate: 0.00125\n",
      "Epoch [6474/20000], Loss: 890.2462158203125, Entropy 408.6717834472656, Learning Rate: 0.00125\n",
      "Epoch [6475/20000], Loss: 892.9915161132812, Entropy 400.43548583984375, Learning Rate: 0.00125\n",
      "Epoch [6476/20000], Loss: 893.6956787109375, Entropy 413.5804443359375, Learning Rate: 0.00125\n",
      "Epoch [6477/20000], Loss: 942.5406494140625, Entropy 387.3702392578125, Learning Rate: 0.00125\n",
      "Epoch [6478/20000], Loss: 891.5050048828125, Entropy 386.0426330566406, Learning Rate: 0.00125\n",
      "Epoch [6479/20000], Loss: 910.9580078125, Entropy 382.5556945800781, Learning Rate: 0.00125\n",
      "Epoch [6480/20000], Loss: 868.118896484375, Entropy 414.5667724609375, Learning Rate: 0.00125\n",
      "Epoch [6481/20000], Loss: 882.8726806640625, Entropy 404.8909606933594, Learning Rate: 0.00125\n",
      "Epoch [6482/20000], Loss: 912.718505859375, Entropy 388.8935852050781, Learning Rate: 0.00125\n",
      "Epoch [6483/20000], Loss: 883.320068359375, Entropy 415.5949401855469, Learning Rate: 0.00125\n",
      "Epoch [6484/20000], Loss: 884.1126708984375, Entropy 403.1417236328125, Learning Rate: 0.00125\n",
      "Epoch [6485/20000], Loss: 867.9923095703125, Entropy 392.7779541015625, Learning Rate: 0.00125\n",
      "Epoch [6486/20000], Loss: 902.0072021484375, Entropy 384.2458190917969, Learning Rate: 0.00125\n",
      "Epoch [6487/20000], Loss: 890.05712890625, Entropy 401.9143981933594, Learning Rate: 0.00125\n",
      "Epoch [6488/20000], Loss: 911.284423828125, Entropy 397.2571105957031, Learning Rate: 0.00125\n",
      "Epoch [6489/20000], Loss: 884.3800659179688, Entropy 394.37225341796875, Learning Rate: 0.00125\n",
      "Epoch [6490/20000], Loss: 905.8260498046875, Entropy 394.1449279785156, Learning Rate: 0.00125\n",
      "Epoch [6491/20000], Loss: 897.9492797851562, Entropy 383.97027587890625, Learning Rate: 0.00125\n",
      "Epoch [6492/20000], Loss: 915.79150390625, Entropy 392.0596923828125, Learning Rate: 0.00125\n",
      "Epoch [6493/20000], Loss: 896.9949951171875, Entropy 393.6805419921875, Learning Rate: 0.00125\n",
      "Epoch [6494/20000], Loss: 892.34326171875, Entropy 402.4051513671875, Learning Rate: 0.00125\n",
      "Epoch [6495/20000], Loss: 909.79052734375, Entropy 398.7022705078125, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6496/20000], Loss: 880.558837890625, Entropy 395.4100646972656, Learning Rate: 0.00125\n",
      "Epoch [6497/20000], Loss: 876.1099853515625, Entropy 397.779296875, Learning Rate: 0.00125\n",
      "Epoch [6498/20000], Loss: 900.0654907226562, Entropy 408.41656494140625, Learning Rate: 0.00125\n",
      "Epoch [6499/20000], Loss: 894.34130859375, Entropy 399.9909362792969, Learning Rate: 0.00125\n",
      "Epoch [6500/20000], Loss: 846.0796508789062, Entropy 415.10662841796875, Learning Rate: 0.00125\n",
      "Epoch [6501/20000], Loss: 891.2366943359375, Entropy 411.8470153808594, Learning Rate: 0.00125\n",
      "Epoch [6502/20000], Loss: 874.8886108398438, Entropy 394.44781494140625, Learning Rate: 0.00125\n",
      "Epoch [6503/20000], Loss: 869.5015869140625, Entropy 405.1792907714844, Learning Rate: 0.00125\n",
      "Epoch [6504/20000], Loss: 896.1820678710938, Entropy 382.09771728515625, Learning Rate: 0.00125\n",
      "Epoch [6505/20000], Loss: 863.74853515625, Entropy 398.3697204589844, Learning Rate: 0.00125\n",
      "Epoch [6506/20000], Loss: 880.340087890625, Entropy 406.6332702636719, Learning Rate: 0.00125\n",
      "Epoch [6507/20000], Loss: 885.3994750976562, Entropy 390.75445556640625, Learning Rate: 0.00125\n",
      "Epoch [6508/20000], Loss: 879.386474609375, Entropy 396.0740661621094, Learning Rate: 0.00125\n",
      "Epoch [6509/20000], Loss: 907.04345703125, Entropy 407.5290222167969, Learning Rate: 0.00125\n",
      "Epoch [6510/20000], Loss: 852.9532470703125, Entropy 408.2812805175781, Learning Rate: 0.00125\n",
      "Epoch [6511/20000], Loss: 910.3801879882812, Entropy 400.06146240234375, Learning Rate: 0.00125\n",
      "Epoch [6512/20000], Loss: 894.2181396484375, Entropy 396.0245361328125, Learning Rate: 0.00125\n",
      "Epoch [6513/20000], Loss: 889.19677734375, Entropy 396.4097900390625, Learning Rate: 0.00125\n",
      "Epoch [6514/20000], Loss: 913.4544067382812, Entropy 385.70245361328125, Learning Rate: 0.00125\n",
      "Epoch [6515/20000], Loss: 853.8465576171875, Entropy 415.92333984375, Learning Rate: 0.00125\n",
      "Epoch [6516/20000], Loss: 893.7562866210938, Entropy 395.20989990234375, Learning Rate: 0.00125\n",
      "Epoch [6517/20000], Loss: 842.486572265625, Entropy 411.76513671875, Learning Rate: 0.00125\n",
      "Epoch [6518/20000], Loss: 904.981689453125, Entropy 413.9792785644531, Learning Rate: 0.00125\n",
      "Epoch [6519/20000], Loss: 903.0679321289062, Entropy 407.80999755859375, Learning Rate: 0.00125\n",
      "Epoch [6520/20000], Loss: 871.7080078125, Entropy 414.0417785644531, Learning Rate: 0.00125\n",
      "Epoch [6521/20000], Loss: 922.3807373046875, Entropy 403.0806884765625, Learning Rate: 0.00125\n",
      "Epoch [6522/20000], Loss: 860.3028564453125, Entropy 407.8921813964844, Learning Rate: 0.00125\n",
      "Epoch [6523/20000], Loss: 886.3560791015625, Entropy 416.6017150878906, Learning Rate: 0.00125\n",
      "Epoch [6524/20000], Loss: 860.5010986328125, Entropy 408.0353698730469, Learning Rate: 0.00125\n",
      "Epoch [6525/20000], Loss: 859.106201171875, Entropy 413.08349609375, Learning Rate: 0.00125\n",
      "Epoch [6526/20000], Loss: 899.8953857421875, Entropy 399.3600769042969, Learning Rate: 0.00125\n",
      "Epoch [6527/20000], Loss: 872.4107055664062, Entropy 404.33111572265625, Learning Rate: 0.00125\n",
      "Epoch [6528/20000], Loss: 885.4453125, Entropy 406.2454528808594, Learning Rate: 0.00125\n",
      "Epoch [6529/20000], Loss: 864.4722900390625, Entropy 405.5089416503906, Learning Rate: 0.00125\n",
      "Epoch [6530/20000], Loss: 911.84375, Entropy 395.2727355957031, Learning Rate: 0.00125\n",
      "Epoch [6531/20000], Loss: 885.8992919921875, Entropy 411.1101379394531, Learning Rate: 0.00125\n",
      "Epoch [6532/20000], Loss: 860.8526611328125, Entropy 396.8543395996094, Learning Rate: 0.00125\n",
      "Epoch [6533/20000], Loss: 913.7576904296875, Entropy 384.103515625, Learning Rate: 0.00125\n",
      "Epoch [6534/20000], Loss: 908.8191528320312, Entropy 398.23236083984375, Learning Rate: 0.00125\n",
      "Epoch [6535/20000], Loss: 876.9178466796875, Entropy 386.2245178222656, Learning Rate: 0.00125\n",
      "Epoch [6536/20000], Loss: 900.5369873046875, Entropy 405.2430419921875, Learning Rate: 0.00125\n",
      "Epoch [6537/20000], Loss: 892.2854614257812, Entropy 392.21319580078125, Learning Rate: 0.00125\n",
      "Epoch [6538/20000], Loss: 920.32861328125, Entropy 401.4769592285156, Learning Rate: 0.00125\n",
      "Epoch [6539/20000], Loss: 946.508544921875, Entropy 390.30419921875, Learning Rate: 0.00125\n",
      "Epoch [6540/20000], Loss: 855.7986450195312, Entropy 402.87799072265625, Learning Rate: 0.00125\n",
      "Epoch [6541/20000], Loss: 896.787109375, Entropy 401.482421875, Learning Rate: 0.00125\n",
      "Epoch [6542/20000], Loss: 882.6830444335938, Entropy 403.69952392578125, Learning Rate: 0.00125\n",
      "Epoch [6543/20000], Loss: 885.0894775390625, Entropy 408.4495544433594, Learning Rate: 0.00125\n",
      "Epoch [6544/20000], Loss: 897.43896484375, Entropy 407.2552795410156, Learning Rate: 0.00125\n",
      "Epoch [6545/20000], Loss: 836.8357543945312, Entropy 408.46685791015625, Learning Rate: 0.00125\n",
      "Epoch [6546/20000], Loss: 865.419189453125, Entropy 411.5263671875, Learning Rate: 0.00125\n",
      "Epoch [6547/20000], Loss: 848.4783935546875, Entropy 415.0461730957031, Learning Rate: 0.00125\n",
      "Epoch [6548/20000], Loss: 878.0272216796875, Entropy 402.7277526855469, Learning Rate: 0.00125\n",
      "Epoch [6549/20000], Loss: 890.05419921875, Entropy 391.884521484375, Learning Rate: 0.00125\n",
      "Epoch [6550/20000], Loss: 866.2359008789062, Entropy 411.01361083984375, Learning Rate: 0.00125\n",
      "Epoch [6551/20000], Loss: 860.5421142578125, Entropy 401.84228515625, Learning Rate: 0.00125\n",
      "Epoch [6552/20000], Loss: 866.8764038085938, Entropy 405.19781494140625, Learning Rate: 0.00125\n",
      "Epoch [6553/20000], Loss: 869.9409790039062, Entropy 394.89385986328125, Learning Rate: 0.00125\n",
      "Epoch [6554/20000], Loss: 894.6956787109375, Entropy 413.7897644042969, Learning Rate: 0.00125\n",
      "Epoch [6555/20000], Loss: 866.7734375, Entropy 394.8260192871094, Learning Rate: 0.00125\n",
      "Epoch [6556/20000], Loss: 855.304443359375, Entropy 410.71875, Learning Rate: 0.00125\n",
      "Epoch [6557/20000], Loss: 852.91748046875, Entropy 407.6888122558594, Learning Rate: 0.00125\n",
      "Epoch [6558/20000], Loss: 903.32373046875, Entropy 396.2309265136719, Learning Rate: 0.00125\n",
      "Epoch [6559/20000], Loss: 898.6145629882812, Entropy 398.68402099609375, Learning Rate: 0.00125\n",
      "Epoch [6560/20000], Loss: 898.434326171875, Entropy 402.0947265625, Learning Rate: 0.00125\n",
      "Epoch [6561/20000], Loss: 876.9267578125, Entropy 392.4764099121094, Learning Rate: 0.00125\n",
      "Epoch [6562/20000], Loss: 880.8991088867188, Entropy 400.97857666015625, Learning Rate: 0.00125\n",
      "Epoch [6563/20000], Loss: 910.087646484375, Entropy 415.5632629394531, Learning Rate: 0.00125\n",
      "Epoch [6564/20000], Loss: 879.2186279296875, Entropy 392.9353942871094, Learning Rate: 0.00125\n",
      "Epoch [6565/20000], Loss: 936.30615234375, Entropy 404.4948425292969, Learning Rate: 0.00125\n",
      "Epoch [6566/20000], Loss: 902.3734741210938, Entropy 394.21148681640625, Learning Rate: 0.00125\n",
      "Epoch [6567/20000], Loss: 855.580322265625, Entropy 414.541015625, Learning Rate: 0.00125\n",
      "Epoch [6568/20000], Loss: 870.4718017578125, Entropy 406.1994323730469, Learning Rate: 0.00125\n",
      "Epoch [6569/20000], Loss: 917.6326904296875, Entropy 392.8122253417969, Learning Rate: 0.00125\n",
      "Epoch [6570/20000], Loss: 864.0385131835938, Entropy 408.13140869140625, Learning Rate: 0.00125\n",
      "Epoch [6571/20000], Loss: 911.205078125, Entropy 410.6723327636719, Learning Rate: 0.00125\n",
      "Epoch [6572/20000], Loss: 880.5366821289062, Entropy 414.07354736328125, Learning Rate: 0.00125\n",
      "Epoch [6573/20000], Loss: 869.69189453125, Entropy 417.3305358886719, Learning Rate: 0.00125\n",
      "Epoch [6574/20000], Loss: 866.9125366210938, Entropy 411.02935791015625, Learning Rate: 0.00125\n",
      "Epoch [6575/20000], Loss: 920.2777099609375, Entropy 402.369140625, Learning Rate: 0.00125\n",
      "Epoch [6576/20000], Loss: 853.5928955078125, Entropy 411.8381042480469, Learning Rate: 0.00125\n",
      "Epoch [6577/20000], Loss: 879.1453857421875, Entropy 394.5963134765625, Learning Rate: 0.00125\n",
      "Epoch [6578/20000], Loss: 860.7421875, Entropy 408.8643798828125, Learning Rate: 0.00125\n",
      "Epoch [6579/20000], Loss: 833.603515625, Entropy 416.3791198730469, Learning Rate: 0.00125\n",
      "Epoch [6580/20000], Loss: 893.3846435546875, Entropy 399.2537841796875, Learning Rate: 0.00125\n",
      "Epoch [6581/20000], Loss: 893.8154907226562, Entropy 403.24224853515625, Learning Rate: 0.00125\n",
      "Epoch [6582/20000], Loss: 861.1702880859375, Entropy 418.7482604980469, Learning Rate: 0.00125\n",
      "Epoch [6583/20000], Loss: 891.6248779296875, Entropy 402.3387451171875, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6584/20000], Loss: 864.5776977539062, Entropy 404.58148193359375, Learning Rate: 0.00125\n",
      "Epoch [6585/20000], Loss: 879.044921875, Entropy 400.0431823730469, Learning Rate: 0.00125\n",
      "Epoch [6586/20000], Loss: 835.1175537109375, Entropy 418.3813171386719, Learning Rate: 0.00125\n",
      "Epoch [6587/20000], Loss: 870.0802001953125, Entropy 418.0832824707031, Learning Rate: 0.00125\n",
      "Epoch [6588/20000], Loss: 850.9751586914062, Entropy 417.67596435546875, Learning Rate: 0.00125\n",
      "Epoch [6589/20000], Loss: 885.1138916015625, Entropy 408.9909362792969, Learning Rate: 0.00125\n",
      "Epoch [6590/20000], Loss: 877.2943725585938, Entropy 411.37396240234375, Learning Rate: 0.00125\n",
      "Epoch [6591/20000], Loss: 878.9100952148438, Entropy 401.32843017578125, Learning Rate: 0.00125\n",
      "Epoch [6592/20000], Loss: 862.7052001953125, Entropy 404.8468017578125, Learning Rate: 0.00125\n",
      "Epoch [6593/20000], Loss: 859.572265625, Entropy 402.033935546875, Learning Rate: 0.00125\n",
      "Epoch [6594/20000], Loss: 892.7098388671875, Entropy 399.2867736816406, Learning Rate: 0.00125\n",
      "Epoch [6595/20000], Loss: 921.75537109375, Entropy 407.7328796386719, Learning Rate: 0.00125\n",
      "Epoch [6596/20000], Loss: 870.6025390625, Entropy 434.1236877441406, Learning Rate: 0.00125\n",
      "Epoch [6597/20000], Loss: 872.3328247070312, Entropy 401.63092041015625, Learning Rate: 0.00125\n",
      "Epoch [6598/20000], Loss: 862.8668212890625, Entropy 411.1894836425781, Learning Rate: 0.00125\n",
      "Epoch [6599/20000], Loss: 844.1845703125, Entropy 406.29638671875, Learning Rate: 0.00125\n",
      "Epoch [6600/20000], Loss: 917.4337768554688, Entropy 408.29937744140625, Learning Rate: 0.00125\n",
      "Epoch [6601/20000], Loss: 925.932373046875, Entropy 391.41357421875, Learning Rate: 0.00125\n",
      "Epoch [6602/20000], Loss: 868.0147705078125, Entropy 396.9644775390625, Learning Rate: 0.00125\n",
      "Epoch [6603/20000], Loss: 891.683349609375, Entropy 395.6706848144531, Learning Rate: 0.00125\n",
      "Epoch [6604/20000], Loss: 907.033935546875, Entropy 394.0016784667969, Learning Rate: 0.00125\n",
      "Epoch [6605/20000], Loss: 832.9439697265625, Entropy 409.4346923828125, Learning Rate: 0.00125\n",
      "Epoch [6606/20000], Loss: 906.65380859375, Entropy 407.8255310058594, Learning Rate: 0.00125\n",
      "Epoch [6607/20000], Loss: 876.7618408203125, Entropy 407.042724609375, Learning Rate: 0.00125\n",
      "Epoch [6608/20000], Loss: 848.84521484375, Entropy 410.4798278808594, Learning Rate: 0.00125\n",
      "Epoch [6609/20000], Loss: 878.351806640625, Entropy 404.4758605957031, Learning Rate: 0.00125\n",
      "Epoch [6610/20000], Loss: 902.706787109375, Entropy 398.8765563964844, Learning Rate: 0.00125\n",
      "Epoch [6611/20000], Loss: 905.4139404296875, Entropy 408.8177185058594, Learning Rate: 0.00125\n",
      "Epoch [6612/20000], Loss: 870.6153564453125, Entropy 396.7950744628906, Learning Rate: 0.00125\n",
      "Epoch [6613/20000], Loss: 887.5357666015625, Entropy 419.4898681640625, Learning Rate: 0.00125\n",
      "Epoch [6614/20000], Loss: 904.6328125, Entropy 397.28466796875, Learning Rate: 0.00125\n",
      "Epoch [6615/20000], Loss: 907.4254150390625, Entropy 408.7974853515625, Learning Rate: 0.00125\n",
      "Epoch [6616/20000], Loss: 899.85693359375, Entropy 400.1876220703125, Learning Rate: 0.00125\n",
      "Epoch [6617/20000], Loss: 883.91015625, Entropy 419.341796875, Learning Rate: 0.00125\n",
      "Epoch [6618/20000], Loss: 905.5253295898438, Entropy 399.54547119140625, Learning Rate: 0.00125\n",
      "Epoch [6619/20000], Loss: 850.7210083007812, Entropy 407.35003662109375, Learning Rate: 0.00125\n",
      "Epoch [6620/20000], Loss: 906.0292358398438, Entropy 395.13958740234375, Learning Rate: 0.00125\n",
      "Epoch [6621/20000], Loss: 876.3587036132812, Entropy 413.99615478515625, Learning Rate: 0.00125\n",
      "Epoch [6622/20000], Loss: 897.189208984375, Entropy 401.6399230957031, Learning Rate: 0.00125\n",
      "Epoch [6623/20000], Loss: 898.4713134765625, Entropy 392.1964111328125, Learning Rate: 0.00125\n",
      "Epoch [6624/20000], Loss: 855.1839599609375, Entropy 393.4739074707031, Learning Rate: 0.00125\n",
      "Epoch [6625/20000], Loss: 900.35888671875, Entropy 413.4955749511719, Learning Rate: 0.00125\n",
      "Epoch [6626/20000], Loss: 887.6119384765625, Entropy 393.6902160644531, Learning Rate: 0.00125\n",
      "Epoch [6627/20000], Loss: 890.4322509765625, Entropy 410.4705505371094, Learning Rate: 0.00125\n",
      "Epoch [6628/20000], Loss: 863.1992797851562, Entropy 415.04840087890625, Learning Rate: 0.00125\n",
      "Epoch [6629/20000], Loss: 870.47705078125, Entropy 418.2994384765625, Learning Rate: 0.00125\n",
      "Epoch [6630/20000], Loss: 874.5404663085938, Entropy 411.30206298828125, Learning Rate: 0.00125\n",
      "Epoch [6631/20000], Loss: 933.763427734375, Entropy 407.2996826171875, Learning Rate: 0.00125\n",
      "Epoch [6632/20000], Loss: 862.51513671875, Entropy 417.2747497558594, Learning Rate: 0.00125\n",
      "Epoch [6633/20000], Loss: 851.0675048828125, Entropy 409.3048400878906, Learning Rate: 0.00125\n",
      "Epoch [6634/20000], Loss: 874.3349609375, Entropy 423.8626403808594, Learning Rate: 0.00125\n",
      "Epoch [6635/20000], Loss: 866.498046875, Entropy 409.3611145019531, Learning Rate: 0.00125\n",
      "Epoch [6636/20000], Loss: 866.6357421875, Entropy 402.5652160644531, Learning Rate: 0.00125\n",
      "Epoch [6637/20000], Loss: 875.1932373046875, Entropy 392.9477233886719, Learning Rate: 0.00125\n",
      "Epoch [6638/20000], Loss: 871.529296875, Entropy 405.1773986816406, Learning Rate: 0.00125\n",
      "Epoch [6639/20000], Loss: 848.1685791015625, Entropy 418.8249816894531, Learning Rate: 0.00125\n",
      "Epoch [6640/20000], Loss: 884.2802734375, Entropy 404.1551208496094, Learning Rate: 0.00125\n",
      "Epoch [6641/20000], Loss: 887.3197021484375, Entropy 410.4427490234375, Learning Rate: 0.00125\n",
      "Epoch [6642/20000], Loss: 843.954833984375, Entropy 421.6860046386719, Learning Rate: 0.00125\n",
      "Epoch [6643/20000], Loss: 854.1795043945312, Entropy 429.53753662109375, Learning Rate: 0.00125\n",
      "Epoch [6644/20000], Loss: 900.9404296875, Entropy 419.6025390625, Learning Rate: 0.00125\n",
      "Epoch [6645/20000], Loss: 870.0118408203125, Entropy 407.4756164550781, Learning Rate: 0.00125\n",
      "Epoch [6646/20000], Loss: 891.7969360351562, Entropy 408.39703369140625, Learning Rate: 0.00125\n",
      "Epoch [6647/20000], Loss: 821.282958984375, Entropy 420.6508483886719, Learning Rate: 0.00125\n",
      "Epoch [6648/20000], Loss: 887.861572265625, Entropy 406.4752197265625, Learning Rate: 0.00125\n",
      "Epoch [6649/20000], Loss: 882.065185546875, Entropy 408.7245178222656, Learning Rate: 0.00125\n",
      "Epoch [6650/20000], Loss: 879.2929077148438, Entropy 396.25531005859375, Learning Rate: 0.00125\n",
      "Epoch [6651/20000], Loss: 876.6865234375, Entropy 408.8960876464844, Learning Rate: 0.00125\n",
      "Epoch [6652/20000], Loss: 903.0390014648438, Entropy 399.19720458984375, Learning Rate: 0.00125\n",
      "Epoch [6653/20000], Loss: 863.4989013671875, Entropy 412.5660400390625, Learning Rate: 0.00125\n",
      "Epoch [6654/20000], Loss: 887.1233520507812, Entropy 413.17230224609375, Learning Rate: 0.00125\n",
      "Epoch [6655/20000], Loss: 889.0164794921875, Entropy 413.7557678222656, Learning Rate: 0.00125\n",
      "Epoch [6656/20000], Loss: 890.3712768554688, Entropy 406.97515869140625, Learning Rate: 0.00125\n",
      "Epoch [6657/20000], Loss: 887.0286254882812, Entropy 414.83258056640625, Learning Rate: 0.00125\n",
      "Epoch [6658/20000], Loss: 864.9774169921875, Entropy 418.701171875, Learning Rate: 0.00125\n",
      "Epoch [6659/20000], Loss: 921.3710327148438, Entropy 423.53924560546875, Learning Rate: 0.00125\n",
      "Epoch [6660/20000], Loss: 880.8057861328125, Entropy 425.5036315917969, Learning Rate: 0.00125\n",
      "Epoch [6661/20000], Loss: 924.2197875976562, Entropy 397.20709228515625, Learning Rate: 0.00125\n",
      "Epoch [6662/20000], Loss: 879.0289306640625, Entropy 405.4940185546875, Learning Rate: 0.00125\n",
      "Epoch [6663/20000], Loss: 866.0404052734375, Entropy 416.8379211425781, Learning Rate: 0.00125\n",
      "Epoch [6664/20000], Loss: 862.6277465820312, Entropy 426.20843505859375, Learning Rate: 0.00125\n",
      "Epoch [6665/20000], Loss: 858.1395263671875, Entropy 405.6179504394531, Learning Rate: 0.00125\n",
      "Epoch [6666/20000], Loss: 885.803955078125, Entropy 413.1562805175781, Learning Rate: 0.00125\n",
      "Epoch [6667/20000], Loss: 903.9662475585938, Entropy 406.23529052734375, Learning Rate: 0.00125\n",
      "Epoch [6668/20000], Loss: 903.4364013671875, Entropy 417.3958435058594, Learning Rate: 0.00125\n",
      "Epoch [6669/20000], Loss: 878.986328125, Entropy 403.7603454589844, Learning Rate: 0.00125\n",
      "Epoch [6670/20000], Loss: 873.0477294921875, Entropy 412.966796875, Learning Rate: 0.00125\n",
      "Epoch [6671/20000], Loss: 903.5419921875, Entropy 406.175537109375, Learning Rate: 0.00125\n",
      "Epoch [6672/20000], Loss: 886.5399169921875, Entropy 408.1163330078125, Learning Rate: 0.00125\n",
      "Epoch [6673/20000], Loss: 928.0338134765625, Entropy 412.4283752441406, Learning Rate: 0.00125\n",
      "Epoch [6674/20000], Loss: 887.963623046875, Entropy 417.0677185058594, Learning Rate: 0.00125\n",
      "Epoch [6675/20000], Loss: 883.2916259765625, Entropy 409.905029296875, Learning Rate: 0.00125\n",
      "Epoch [6676/20000], Loss: 900.273681640625, Entropy 404.1483154296875, Learning Rate: 0.00125\n",
      "Epoch [6677/20000], Loss: 886.0970458984375, Entropy 415.9471130371094, Learning Rate: 0.00125\n",
      "Epoch [6678/20000], Loss: 869.7756958007812, Entropy 406.02056884765625, Learning Rate: 0.00125\n",
      "Epoch [6679/20000], Loss: 869.0924072265625, Entropy 407.0460205078125, Learning Rate: 0.00125\n",
      "Epoch [6680/20000], Loss: 896.147705078125, Entropy 409.7837829589844, Learning Rate: 0.00125\n",
      "Epoch [6681/20000], Loss: 853.6748046875, Entropy 416.4002380371094, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6682/20000], Loss: 860.3780517578125, Entropy 413.2571105957031, Learning Rate: 0.00125\n",
      "Epoch [6683/20000], Loss: 866.408447265625, Entropy 405.134765625, Learning Rate: 0.00125\n",
      "Epoch [6684/20000], Loss: 851.663330078125, Entropy 404.3976745605469, Learning Rate: 0.00125\n",
      "Epoch [6685/20000], Loss: 878.326416015625, Entropy 414.3834228515625, Learning Rate: 0.00125\n",
      "Epoch [6686/20000], Loss: 852.7037353515625, Entropy 410.418701171875, Learning Rate: 0.00125\n",
      "Epoch [6687/20000], Loss: 836.4197998046875, Entropy 403.7730407714844, Learning Rate: 0.00125\n",
      "Epoch [6688/20000], Loss: 825.29345703125, Entropy 421.7250671386719, Learning Rate: 0.00125\n",
      "Epoch [6689/20000], Loss: 903.9735107421875, Entropy 400.6193542480469, Learning Rate: 0.00125\n",
      "Epoch [6690/20000], Loss: 844.42919921875, Entropy 424.7596435546875, Learning Rate: 0.00125\n",
      "Epoch [6691/20000], Loss: 854.0287475585938, Entropy 415.04913330078125, Learning Rate: 0.00125\n",
      "Epoch [6692/20000], Loss: 860.368408203125, Entropy 415.4676818847656, Learning Rate: 0.00125\n",
      "Epoch [6693/20000], Loss: 870.9609375, Entropy 390.7758483886719, Learning Rate: 0.00125\n",
      "Epoch [6694/20000], Loss: 916.8954467773438, Entropy 411.60980224609375, Learning Rate: 0.00125\n",
      "Epoch [6695/20000], Loss: 910.178466796875, Entropy 412.0152282714844, Learning Rate: 0.00125\n",
      "Epoch [6696/20000], Loss: 844.5631103515625, Entropy 423.465576171875, Learning Rate: 0.00125\n",
      "Epoch [6697/20000], Loss: 853.2528076171875, Entropy 419.7702331542969, Learning Rate: 0.00125\n",
      "Epoch [6698/20000], Loss: 894.718017578125, Entropy 422.1059265136719, Learning Rate: 0.00125\n",
      "Epoch [6699/20000], Loss: 830.7510375976562, Entropy 408.93890380859375, Learning Rate: 0.00125\n",
      "Epoch [6700/20000], Loss: 862.8287353515625, Entropy 415.8583068847656, Learning Rate: 0.00125\n",
      "Epoch [6701/20000], Loss: 887.753662109375, Entropy 427.3721923828125, Learning Rate: 0.00125\n",
      "Epoch [6702/20000], Loss: 894.7427978515625, Entropy 406.4172668457031, Learning Rate: 0.00125\n",
      "Epoch [6703/20000], Loss: 866.4965209960938, Entropy 412.04449462890625, Learning Rate: 0.00125\n",
      "Epoch [6704/20000], Loss: 867.841064453125, Entropy 414.4269714355469, Learning Rate: 0.00125\n",
      "Epoch [6705/20000], Loss: 883.6499633789062, Entropy 403.81671142578125, Learning Rate: 0.00125\n",
      "Epoch [6706/20000], Loss: 907.5798950195312, Entropy 414.60650634765625, Learning Rate: 0.00125\n",
      "Epoch [6707/20000], Loss: 849.8016357421875, Entropy 418.5205078125, Learning Rate: 0.00125\n",
      "Epoch [6708/20000], Loss: 860.6450805664062, Entropy 411.24798583984375, Learning Rate: 0.00125\n",
      "Epoch [6709/20000], Loss: 911.193359375, Entropy 402.9959411621094, Learning Rate: 0.00125\n",
      "Epoch [6710/20000], Loss: 876.01220703125, Entropy 416.1668395996094, Learning Rate: 0.00125\n",
      "Epoch [6711/20000], Loss: 852.9349365234375, Entropy 413.4665222167969, Learning Rate: 0.00125\n",
      "Epoch [6712/20000], Loss: 884.9083251953125, Entropy 412.6366271972656, Learning Rate: 0.00125\n",
      "Epoch [6713/20000], Loss: 882.39892578125, Entropy 417.09716796875, Learning Rate: 0.00125\n",
      "Epoch [6714/20000], Loss: 891.0906982421875, Entropy 396.5626525878906, Learning Rate: 0.00125\n",
      "Epoch [6715/20000], Loss: 880.15185546875, Entropy 411.1756896972656, Learning Rate: 0.00125\n",
      "Epoch [6716/20000], Loss: 882.492919921875, Entropy 418.8302307128906, Learning Rate: 0.00125\n",
      "Epoch [6717/20000], Loss: 872.7042236328125, Entropy 415.8238220214844, Learning Rate: 0.00125\n",
      "Epoch [6718/20000], Loss: 852.093994140625, Entropy 432.2304992675781, Learning Rate: 0.00125\n",
      "Epoch [6719/20000], Loss: 907.415283203125, Entropy 408.4563293457031, Learning Rate: 0.00125\n",
      "Epoch [6720/20000], Loss: 879.9776611328125, Entropy 417.5564880371094, Learning Rate: 0.00125\n",
      "Epoch [6721/20000], Loss: 887.4720458984375, Entropy 409.0226745605469, Learning Rate: 0.00125\n",
      "Epoch [6722/20000], Loss: 913.1528930664062, Entropy 409.92425537109375, Learning Rate: 0.00125\n",
      "Epoch [6723/20000], Loss: 865.678955078125, Entropy 419.5914306640625, Learning Rate: 0.00125\n",
      "Epoch [6724/20000], Loss: 873.3191528320312, Entropy 425.72711181640625, Learning Rate: 0.00125\n",
      "Epoch [6725/20000], Loss: 863.7060546875, Entropy 426.0120544433594, Learning Rate: 0.00125\n",
      "Epoch [6726/20000], Loss: 886.5228271484375, Entropy 399.2830505371094, Learning Rate: 0.00125\n",
      "Epoch [6727/20000], Loss: 855.7574462890625, Entropy 415.7832336425781, Learning Rate: 0.00125\n",
      "Epoch [6728/20000], Loss: 923.4788208007812, Entropy 410.18255615234375, Learning Rate: 0.00125\n",
      "Epoch [6729/20000], Loss: 898.041015625, Entropy 409.8345642089844, Learning Rate: 0.00125\n",
      "Epoch [6730/20000], Loss: 870.9219970703125, Entropy 434.7510070800781, Learning Rate: 0.00125\n",
      "Epoch [6731/20000], Loss: 883.39697265625, Entropy 416.28955078125, Learning Rate: 0.00125\n",
      "Epoch [6732/20000], Loss: 858.2421875, Entropy 406.5240478515625, Learning Rate: 0.00125\n",
      "Epoch [6733/20000], Loss: 893.9403686523438, Entropy 408.41363525390625, Learning Rate: 0.00125\n",
      "Epoch [6734/20000], Loss: 906.2406005859375, Entropy 410.7171325683594, Learning Rate: 0.00125\n",
      "Epoch [6735/20000], Loss: 908.6192626953125, Entropy 407.5516052246094, Learning Rate: 0.00125\n",
      "Epoch [6736/20000], Loss: 840.796630859375, Entropy 418.3292541503906, Learning Rate: 0.00125\n",
      "Epoch [6737/20000], Loss: 915.3260498046875, Entropy 406.9435119628906, Learning Rate: 0.00125\n",
      "Epoch [6738/20000], Loss: 824.9893798828125, Entropy 423.4010314941406, Learning Rate: 0.00125\n",
      "Epoch [6739/20000], Loss: 879.1644287109375, Entropy 413.4212646484375, Learning Rate: 0.00125\n",
      "Epoch [6740/20000], Loss: 878.3651123046875, Entropy 415.44873046875, Learning Rate: 0.00125\n",
      "Epoch [6741/20000], Loss: 898.6229248046875, Entropy 427.9850158691406, Learning Rate: 0.00125\n",
      "Epoch [6742/20000], Loss: 876.637939453125, Entropy 413.5844421386719, Learning Rate: 0.00125\n",
      "Epoch [6743/20000], Loss: 854.29638671875, Entropy 428.0621032714844, Learning Rate: 0.00125\n",
      "Epoch [6744/20000], Loss: 865.3726196289062, Entropy 413.60504150390625, Learning Rate: 0.00125\n",
      "Epoch [6745/20000], Loss: 867.6539306640625, Entropy 419.310302734375, Learning Rate: 0.00125\n",
      "Epoch [6746/20000], Loss: 842.25732421875, Entropy 419.2434997558594, Learning Rate: 0.00125\n",
      "Epoch [6747/20000], Loss: 848.0372924804688, Entropy 418.82733154296875, Learning Rate: 0.00125\n",
      "Epoch [6748/20000], Loss: 893.5355224609375, Entropy 408.2056884765625, Learning Rate: 0.00125\n",
      "Epoch [6749/20000], Loss: 925.6862182617188, Entropy 406.95233154296875, Learning Rate: 0.00125\n",
      "Epoch [6750/20000], Loss: 890.254150390625, Entropy 417.9217834472656, Learning Rate: 0.00125\n",
      "Epoch [6751/20000], Loss: 876.0604248046875, Entropy 421.1314392089844, Learning Rate: 0.00125\n",
      "Epoch [6752/20000], Loss: 884.9764404296875, Entropy 410.1101989746094, Learning Rate: 0.00125\n",
      "Epoch [6753/20000], Loss: 903.4296875, Entropy 411.1015625, Learning Rate: 0.00125\n",
      "Epoch [6754/20000], Loss: 836.7646484375, Entropy 413.4006042480469, Learning Rate: 0.00125\n",
      "Epoch [6755/20000], Loss: 912.4625244140625, Entropy 419.062255859375, Learning Rate: 0.00125\n",
      "Epoch [6756/20000], Loss: 902.8787841796875, Entropy 417.288818359375, Learning Rate: 0.00125\n",
      "Epoch [6757/20000], Loss: 873.632568359375, Entropy 420.1376953125, Learning Rate: 0.00125\n",
      "Epoch [6758/20000], Loss: 883.2001953125, Entropy 427.4615478515625, Learning Rate: 0.00125\n",
      "Epoch [6759/20000], Loss: 905.9291381835938, Entropy 413.00909423828125, Learning Rate: 0.00125\n",
      "Epoch [6760/20000], Loss: 918.8314208984375, Entropy 407.6954650878906, Learning Rate: 0.00125\n",
      "Epoch [6761/20000], Loss: 858.889404296875, Entropy 414.8190002441406, Learning Rate: 0.00125\n",
      "Epoch [6762/20000], Loss: 844.1589965820312, Entropy 427.59234619140625, Learning Rate: 0.00125\n",
      "Epoch [6763/20000], Loss: 915.7620849609375, Entropy 401.4517822265625, Learning Rate: 0.00125\n",
      "Epoch [6764/20000], Loss: 930.031005859375, Entropy 418.2791442871094, Learning Rate: 0.00125\n",
      "Epoch [6765/20000], Loss: 920.0623779296875, Entropy 413.6873474121094, Learning Rate: 0.00125\n",
      "Epoch [6766/20000], Loss: 876.5740356445312, Entropy 412.02044677734375, Learning Rate: 0.00125\n",
      "Epoch [6767/20000], Loss: 847.1556396484375, Entropy 424.6135559082031, Learning Rate: 0.00125\n",
      "Epoch [6768/20000], Loss: 868.4268188476562, Entropy 399.62811279296875, Learning Rate: 0.00125\n",
      "Epoch [6769/20000], Loss: 876.868896484375, Entropy 401.0244140625, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6770/20000], Loss: 903.1524658203125, Entropy 401.0308532714844, Learning Rate: 0.00125\n",
      "Epoch [6771/20000], Loss: 840.1555786132812, Entropy 421.32855224609375, Learning Rate: 0.00125\n",
      "Epoch [6772/20000], Loss: 850.253662109375, Entropy 422.2771911621094, Learning Rate: 0.00125\n",
      "Epoch [6773/20000], Loss: 864.0115966796875, Entropy 410.8800354003906, Learning Rate: 0.00125\n",
      "Epoch [6774/20000], Loss: 908.29931640625, Entropy 416.4029846191406, Learning Rate: 0.00125\n",
      "Epoch [6775/20000], Loss: 896.4392700195312, Entropy 409.15191650390625, Learning Rate: 0.00125\n",
      "Epoch [6776/20000], Loss: 900.6951904296875, Entropy 437.8817138671875, Learning Rate: 0.00125\n",
      "Epoch [6777/20000], Loss: 871.9024047851562, Entropy 420.04107666015625, Learning Rate: 0.00125\n",
      "Epoch [6778/20000], Loss: 864.5880126953125, Entropy 425.4920349121094, Learning Rate: 0.00125\n",
      "Epoch [6779/20000], Loss: 882.9466552734375, Entropy 414.1570739746094, Learning Rate: 0.00125\n",
      "Epoch [6780/20000], Loss: 886.2286376953125, Entropy 418.0012512207031, Learning Rate: 0.00125\n",
      "Epoch [6781/20000], Loss: 936.0076904296875, Entropy 419.9434814453125, Learning Rate: 0.00125\n",
      "Epoch [6782/20000], Loss: 865.7406616210938, Entropy 422.39007568359375, Learning Rate: 0.00125\n",
      "Epoch [6783/20000], Loss: 905.70556640625, Entropy 410.9831237792969, Learning Rate: 0.00125\n",
      "Epoch [6784/20000], Loss: 899.9597778320312, Entropy 409.89935302734375, Learning Rate: 0.00125\n",
      "Epoch [6785/20000], Loss: 887.8656005859375, Entropy 409.3515930175781, Learning Rate: 0.00125\n",
      "Epoch [6786/20000], Loss: 931.57373046875, Entropy 399.2840576171875, Learning Rate: 0.00125\n",
      "Epoch [6787/20000], Loss: 889.5972900390625, Entropy 427.8577880859375, Learning Rate: 0.00125\n",
      "Epoch [6788/20000], Loss: 887.7452392578125, Entropy 399.9085998535156, Learning Rate: 0.00125\n",
      "Epoch [6789/20000], Loss: 885.12841796875, Entropy 415.7462463378906, Learning Rate: 0.00125\n",
      "Epoch [6790/20000], Loss: 891.513671875, Entropy 403.2003173828125, Learning Rate: 0.00125\n",
      "Epoch [6791/20000], Loss: 914.8543701171875, Entropy 399.3699645996094, Learning Rate: 0.00125\n",
      "Epoch [6792/20000], Loss: 859.2943115234375, Entropy 425.697021484375, Learning Rate: 0.00125\n",
      "Epoch [6793/20000], Loss: 905.3138427734375, Entropy 405.5438537597656, Learning Rate: 0.00125\n",
      "Epoch [6794/20000], Loss: 893.914794921875, Entropy 422.8080749511719, Learning Rate: 0.00125\n",
      "Epoch [6795/20000], Loss: 867.5253295898438, Entropy 423.17303466796875, Learning Rate: 0.00125\n",
      "Epoch [6796/20000], Loss: 867.10595703125, Entropy 420.0720520019531, Learning Rate: 0.00125\n",
      "Epoch [6797/20000], Loss: 921.2943115234375, Entropy 412.9696350097656, Learning Rate: 0.00125\n",
      "Epoch [6798/20000], Loss: 862.6461181640625, Entropy 415.8233642578125, Learning Rate: 0.00125\n",
      "Epoch [6799/20000], Loss: 847.5010986328125, Entropy 421.0863952636719, Learning Rate: 0.00125\n",
      "Epoch [6800/20000], Loss: 913.0383911132812, Entropy 434.98077392578125, Learning Rate: 0.00125\n",
      "Epoch [6801/20000], Loss: 911.5948486328125, Entropy 402.642578125, Learning Rate: 0.00125\n",
      "Epoch [6802/20000], Loss: 904.8766479492188, Entropy 408.25140380859375, Learning Rate: 0.00125\n",
      "Epoch [6803/20000], Loss: 959.9630126953125, Entropy 403.7252197265625, Learning Rate: 0.00125\n",
      "Epoch [6804/20000], Loss: 867.2626342773438, Entropy 424.45794677734375, Learning Rate: 0.00125\n",
      "Epoch [6805/20000], Loss: 904.9117431640625, Entropy 424.5735168457031, Learning Rate: 0.00125\n",
      "Epoch [6806/20000], Loss: 887.46142578125, Entropy 405.550537109375, Learning Rate: 0.00125\n",
      "Epoch [6807/20000], Loss: 861.9948120117188, Entropy 422.00030517578125, Learning Rate: 0.00125\n",
      "Epoch [6808/20000], Loss: 852.446533203125, Entropy 420.1882019042969, Learning Rate: 0.00125\n",
      "Epoch [6809/20000], Loss: 897.434814453125, Entropy 423.6317138671875, Learning Rate: 0.00125\n",
      "Epoch [6810/20000], Loss: 891.76025390625, Entropy 419.9597473144531, Learning Rate: 0.00125\n",
      "Epoch [6811/20000], Loss: 908.39697265625, Entropy 417.78271484375, Learning Rate: 0.00125\n",
      "Epoch [6812/20000], Loss: 862.8911743164062, Entropy 417.19476318359375, Learning Rate: 0.00125\n",
      "Epoch [6813/20000], Loss: 880.511962890625, Entropy 414.7181091308594, Learning Rate: 0.00125\n",
      "Epoch [6814/20000], Loss: 907.5828247070312, Entropy 412.29913330078125, Learning Rate: 0.00125\n",
      "Epoch [6815/20000], Loss: 891.6689453125, Entropy 405.7760925292969, Learning Rate: 0.00125\n",
      "Epoch [6816/20000], Loss: 893.5772705078125, Entropy 417.9417724609375, Learning Rate: 0.00125\n",
      "Epoch [6817/20000], Loss: 871.514404296875, Entropy 412.646484375, Learning Rate: 0.00125\n",
      "Epoch [6818/20000], Loss: 897.8165283203125, Entropy 399.5132751464844, Learning Rate: 0.00125\n",
      "Epoch [6819/20000], Loss: 850.519287109375, Entropy 411.5703125, Learning Rate: 0.00125\n",
      "Epoch [6820/20000], Loss: 910.9620361328125, Entropy 407.5848693847656, Learning Rate: 0.00125\n",
      "Epoch [6821/20000], Loss: 848.7489013671875, Entropy 410.7337341308594, Learning Rate: 0.00125\n",
      "Epoch [6822/20000], Loss: 875.631103515625, Entropy 416.1575622558594, Learning Rate: 0.00125\n",
      "Epoch [6823/20000], Loss: 835.46533203125, Entropy 431.5301208496094, Learning Rate: 0.00125\n",
      "Epoch [6824/20000], Loss: 872.9970703125, Entropy 417.8371887207031, Learning Rate: 0.00125\n",
      "Epoch [6825/20000], Loss: 910.3177490234375, Entropy 408.6248474121094, Learning Rate: 0.00125\n",
      "Epoch [6826/20000], Loss: 869.0458984375, Entropy 413.8258972167969, Learning Rate: 0.00125\n",
      "Epoch [6827/20000], Loss: 861.4072265625, Entropy 425.1501770019531, Learning Rate: 0.00125\n",
      "Epoch [6828/20000], Loss: 896.005126953125, Entropy 413.3182373046875, Learning Rate: 0.00125\n",
      "Epoch [6829/20000], Loss: 898.6511840820312, Entropy 432.28131103515625, Learning Rate: 0.00125\n",
      "Epoch [6830/20000], Loss: 887.53759765625, Entropy 407.0827331542969, Learning Rate: 0.00125\n",
      "Epoch [6831/20000], Loss: 871.0455322265625, Entropy 420.1681213378906, Learning Rate: 0.00125\n",
      "Epoch [6832/20000], Loss: 893.3935546875, Entropy 407.11376953125, Learning Rate: 0.00125\n",
      "Epoch [6833/20000], Loss: 946.0761108398438, Entropy 421.51605224609375, Learning Rate: 0.00125\n",
      "Epoch [6834/20000], Loss: 891.6900634765625, Entropy 420.7783508300781, Learning Rate: 0.00125\n",
      "Epoch [6835/20000], Loss: 879.7701416015625, Entropy 420.6176452636719, Learning Rate: 0.00125\n",
      "Epoch [6836/20000], Loss: 871.14892578125, Entropy 419.0099182128906, Learning Rate: 0.00125\n",
      "Epoch [6837/20000], Loss: 881.7033081054688, Entropy 418.75311279296875, Learning Rate: 0.00125\n",
      "Epoch [6838/20000], Loss: 854.67626953125, Entropy 417.0855407714844, Learning Rate: 0.00125\n",
      "Epoch [6839/20000], Loss: 857.6502075195312, Entropy 415.73883056640625, Learning Rate: 0.00125\n",
      "Epoch [6840/20000], Loss: 929.1451416015625, Entropy 424.8857421875, Learning Rate: 0.00125\n",
      "Epoch [6841/20000], Loss: 895.144775390625, Entropy 416.4195251464844, Learning Rate: 0.00125\n",
      "Epoch [6842/20000], Loss: 892.37060546875, Entropy 420.6172180175781, Learning Rate: 0.00125\n",
      "Epoch [6843/20000], Loss: 853.5543212890625, Entropy 396.5807189941406, Learning Rate: 0.00125\n",
      "Epoch [6844/20000], Loss: 873.8699951171875, Entropy 412.6763916015625, Learning Rate: 0.00125\n",
      "Epoch [6845/20000], Loss: 846.869873046875, Entropy 421.5577697753906, Learning Rate: 0.00125\n",
      "Epoch [6846/20000], Loss: 892.9371337890625, Entropy 413.4011535644531, Learning Rate: 0.00125\n",
      "Epoch [6847/20000], Loss: 880.1878051757812, Entropy 429.17999267578125, Learning Rate: 0.00125\n",
      "Epoch [6848/20000], Loss: 888.9224243164062, Entropy 413.49517822265625, Learning Rate: 0.00125\n",
      "Epoch [6849/20000], Loss: 911.291015625, Entropy 409.0530090332031, Learning Rate: 0.00125\n",
      "Epoch [6850/20000], Loss: 861.7681274414062, Entropy 424.54876708984375, Learning Rate: 0.00125\n",
      "Epoch [6851/20000], Loss: 908.418701171875, Entropy 419.1650695800781, Learning Rate: 0.00125\n",
      "Epoch [6852/20000], Loss: 860.9735107421875, Entropy 418.7230224609375, Learning Rate: 0.00125\n",
      "Epoch [6853/20000], Loss: 881.4400024414062, Entropy 404.61444091796875, Learning Rate: 0.00125\n",
      "Epoch [6854/20000], Loss: 893.390625, Entropy 414.4609680175781, Learning Rate: 0.00125\n",
      "Epoch [6855/20000], Loss: 855.3394775390625, Entropy 416.1874084472656, Learning Rate: 0.00125\n",
      "Epoch [6856/20000], Loss: 884.884033203125, Entropy 413.2205505371094, Learning Rate: 0.00125\n",
      "Epoch [6857/20000], Loss: 894.7313232421875, Entropy 414.3561706542969, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6858/20000], Loss: 868.1636962890625, Entropy 418.8871765136719, Learning Rate: 0.00125\n",
      "Epoch [6859/20000], Loss: 892.633544921875, Entropy 430.7994384765625, Learning Rate: 0.00125\n",
      "Epoch [6860/20000], Loss: 886.1016235351562, Entropy 408.69769287109375, Learning Rate: 0.00125\n",
      "Epoch [6861/20000], Loss: 854.8431396484375, Entropy 424.8782653808594, Learning Rate: 0.00125\n",
      "Epoch [6862/20000], Loss: 934.369384765625, Entropy 406.38427734375, Learning Rate: 0.00125\n",
      "Epoch [6863/20000], Loss: 854.8350219726562, Entropy 421.60833740234375, Learning Rate: 0.00125\n",
      "Epoch [6864/20000], Loss: 825.188720703125, Entropy 428.1443786621094, Learning Rate: 0.00125\n",
      "Epoch [6865/20000], Loss: 911.9805908203125, Entropy 404.8699951171875, Learning Rate: 0.00125\n",
      "Epoch [6866/20000], Loss: 897.9268798828125, Entropy 409.2994384765625, Learning Rate: 0.00125\n",
      "Epoch [6867/20000], Loss: 905.09814453125, Entropy 414.536865234375, Learning Rate: 0.00125\n",
      "Epoch [6868/20000], Loss: 894.777587890625, Entropy 417.1277160644531, Learning Rate: 0.00125\n",
      "Epoch [6869/20000], Loss: 870.7808837890625, Entropy 408.681396484375, Learning Rate: 0.00125\n",
      "Epoch [6870/20000], Loss: 872.474853515625, Entropy 424.3606872558594, Learning Rate: 0.00125\n",
      "Epoch [6871/20000], Loss: 871.822509765625, Entropy 421.5747985839844, Learning Rate: 0.00125\n",
      "Epoch [6872/20000], Loss: 872.5654296875, Entropy 405.2181701660156, Learning Rate: 0.00125\n",
      "Epoch [6873/20000], Loss: 887.052734375, Entropy 417.5836181640625, Learning Rate: 0.00125\n",
      "Epoch [6874/20000], Loss: 879.9791259765625, Entropy 419.3994140625, Learning Rate: 0.00125\n",
      "Epoch [6875/20000], Loss: 919.5189819335938, Entropy 415.47406005859375, Learning Rate: 0.00125\n",
      "Epoch [6876/20000], Loss: 901.560302734375, Entropy 422.2102966308594, Learning Rate: 0.00125\n",
      "Epoch [6877/20000], Loss: 891.287109375, Entropy 420.9503173828125, Learning Rate: 0.00125\n",
      "Epoch [6878/20000], Loss: 914.766845703125, Entropy 407.4460754394531, Learning Rate: 0.00125\n",
      "Epoch [6879/20000], Loss: 841.8258666992188, Entropy 430.11859130859375, Learning Rate: 0.00125\n",
      "Epoch [6880/20000], Loss: 897.489501953125, Entropy 424.4698486328125, Learning Rate: 0.00125\n",
      "Epoch [6881/20000], Loss: 904.9861450195312, Entropy 409.35882568359375, Learning Rate: 0.00125\n",
      "Epoch [6882/20000], Loss: 846.3681640625, Entropy 440.0236511230469, Learning Rate: 0.00125\n",
      "Epoch [6883/20000], Loss: 873.2510375976562, Entropy 414.95147705078125, Learning Rate: 0.00125\n",
      "Epoch [6884/20000], Loss: 910.810302734375, Entropy 412.9390563964844, Learning Rate: 0.00125\n",
      "Epoch [6885/20000], Loss: 856.9474487304688, Entropy 425.67498779296875, Learning Rate: 0.00125\n",
      "Epoch [6886/20000], Loss: 879.469482421875, Entropy 422.1355285644531, Learning Rate: 0.00125\n",
      "Epoch [6887/20000], Loss: 902.8742065429688, Entropy 427.89996337890625, Learning Rate: 0.00125\n",
      "Epoch [6888/20000], Loss: 875.4218139648438, Entropy 428.27435302734375, Learning Rate: 0.00125\n",
      "Epoch [6889/20000], Loss: 851.6056518554688, Entropy 427.94097900390625, Learning Rate: 0.00125\n",
      "Epoch [6890/20000], Loss: 909.0394287109375, Entropy 417.112060546875, Learning Rate: 0.00125\n",
      "Epoch [6891/20000], Loss: 841.7929077148438, Entropy 406.93475341796875, Learning Rate: 0.00125\n",
      "Epoch [6892/20000], Loss: 889.616943359375, Entropy 417.4299011230469, Learning Rate: 0.00125\n",
      "Epoch [6893/20000], Loss: 875.7505493164062, Entropy 416.20562744140625, Learning Rate: 0.00125\n",
      "Epoch [6894/20000], Loss: 854.4042358398438, Entropy 426.88226318359375, Learning Rate: 0.00125\n",
      "Epoch [6895/20000], Loss: 852.7266845703125, Entropy 421.5297546386719, Learning Rate: 0.00125\n",
      "Epoch [6896/20000], Loss: 856.4632568359375, Entropy 434.11474609375, Learning Rate: 0.00125\n",
      "Epoch [6897/20000], Loss: 883.5094604492188, Entropy 434.20147705078125, Learning Rate: 0.00125\n",
      "Epoch [6898/20000], Loss: 863.7984619140625, Entropy 442.3828125, Learning Rate: 0.00125\n",
      "Epoch [6899/20000], Loss: 902.0382080078125, Entropy 429.5295104980469, Learning Rate: 0.00125\n",
      "Epoch [6900/20000], Loss: 882.2857055664062, Entropy 410.77960205078125, Learning Rate: 0.00125\n",
      "Epoch [6901/20000], Loss: 895.6007690429688, Entropy 410.57061767578125, Learning Rate: 0.00125\n",
      "Epoch [6902/20000], Loss: 894.298583984375, Entropy 405.3216857910156, Learning Rate: 0.00125\n",
      "Epoch [6903/20000], Loss: 914.6953125, Entropy 416.8746032714844, Learning Rate: 0.00125\n",
      "Epoch [6904/20000], Loss: 849.8592529296875, Entropy 426.4123229980469, Learning Rate: 0.00125\n",
      "Epoch [6905/20000], Loss: 830.9718017578125, Entropy 419.9410705566406, Learning Rate: 0.00125\n",
      "Epoch [6906/20000], Loss: 881.123291015625, Entropy 414.0531921386719, Learning Rate: 0.00125\n",
      "Epoch [6907/20000], Loss: 856.1240234375, Entropy 425.4159240722656, Learning Rate: 0.00125\n",
      "Epoch [6908/20000], Loss: 860.986328125, Entropy 429.5867919921875, Learning Rate: 0.00125\n",
      "Epoch [6909/20000], Loss: 880.9873046875, Entropy 410.5509033203125, Learning Rate: 0.00125\n",
      "Epoch [6910/20000], Loss: 926.350341796875, Entropy 417.4241638183594, Learning Rate: 0.00125\n",
      "Epoch [6911/20000], Loss: 885.701171875, Entropy 414.5510559082031, Learning Rate: 0.00125\n",
      "Epoch [6912/20000], Loss: 863.2029418945312, Entropy 413.79010009765625, Learning Rate: 0.00125\n",
      "Epoch [6913/20000], Loss: 885.3595581054688, Entropy 429.75787353515625, Learning Rate: 0.00125\n",
      "Epoch [6914/20000], Loss: 927.3137817382812, Entropy 410.17803955078125, Learning Rate: 0.00125\n",
      "Epoch [6915/20000], Loss: 863.6669921875, Entropy 428.9602966308594, Learning Rate: 0.00125\n",
      "Epoch [6916/20000], Loss: 884.156005859375, Entropy 416.7236328125, Learning Rate: 0.00125\n",
      "Epoch [6917/20000], Loss: 844.021728515625, Entropy 426.6906433105469, Learning Rate: 0.00125\n",
      "Epoch [6918/20000], Loss: 859.79345703125, Entropy 431.86474609375, Learning Rate: 0.00125\n",
      "Epoch [6919/20000], Loss: 912.4271240234375, Entropy 430.311279296875, Learning Rate: 0.00125\n",
      "Epoch [6920/20000], Loss: 865.3914184570312, Entropy 433.48236083984375, Learning Rate: 0.00125\n",
      "Epoch [6921/20000], Loss: 874.4886474609375, Entropy 426.4664001464844, Learning Rate: 0.00125\n",
      "Epoch [6922/20000], Loss: 889.7891845703125, Entropy 410.3966369628906, Learning Rate: 0.00125\n",
      "Epoch [6923/20000], Loss: 842.2457275390625, Entropy 410.8670349121094, Learning Rate: 0.00125\n",
      "Epoch [6924/20000], Loss: 840.763916015625, Entropy 411.4671325683594, Learning Rate: 0.00125\n",
      "Epoch [6925/20000], Loss: 860.1123046875, Entropy 422.6580505371094, Learning Rate: 0.00125\n",
      "Epoch [6926/20000], Loss: 882.5950927734375, Entropy 421.5029602050781, Learning Rate: 0.00125\n",
      "Epoch [6927/20000], Loss: 864.698974609375, Entropy 422.759521484375, Learning Rate: 0.00125\n",
      "Epoch [6928/20000], Loss: 868.0501708984375, Entropy 421.3333435058594, Learning Rate: 0.00125\n",
      "Epoch [6929/20000], Loss: 873.03173828125, Entropy 413.9068603515625, Learning Rate: 0.00125\n",
      "Epoch [6930/20000], Loss: 884.2464599609375, Entropy 423.7005615234375, Learning Rate: 0.00125\n",
      "Epoch [6931/20000], Loss: 876.8714599609375, Entropy 426.479248046875, Learning Rate: 0.00125\n",
      "Epoch [6932/20000], Loss: 884.5966796875, Entropy 423.6965637207031, Learning Rate: 0.00125\n",
      "Epoch [6933/20000], Loss: 867.07177734375, Entropy 425.3056640625, Learning Rate: 0.00125\n",
      "Epoch [6934/20000], Loss: 883.24365234375, Entropy 419.349609375, Learning Rate: 0.00125\n",
      "Epoch [6935/20000], Loss: 867.7736206054688, Entropy 427.96478271484375, Learning Rate: 0.00125\n",
      "Epoch [6936/20000], Loss: 884.1370849609375, Entropy 414.8776550292969, Learning Rate: 0.00125\n",
      "Epoch [6937/20000], Loss: 909.652587890625, Entropy 413.3814697265625, Learning Rate: 0.00125\n",
      "Epoch [6938/20000], Loss: 895.1546630859375, Entropy 429.2953796386719, Learning Rate: 0.00125\n",
      "Epoch [6939/20000], Loss: 865.2161254882812, Entropy 429.91217041015625, Learning Rate: 0.00125\n",
      "Epoch [6940/20000], Loss: 864.3784790039062, Entropy 427.99932861328125, Learning Rate: 0.00125\n",
      "Epoch [6941/20000], Loss: 902.7045288085938, Entropy 421.54998779296875, Learning Rate: 0.00125\n",
      "Epoch [6942/20000], Loss: 898.21435546875, Entropy 420.2900695800781, Learning Rate: 0.00125\n",
      "Epoch [6943/20000], Loss: 841.4356689453125, Entropy 410.951171875, Learning Rate: 0.00125\n",
      "Epoch [6944/20000], Loss: 886.9727783203125, Entropy 432.5128479003906, Learning Rate: 0.00125\n",
      "Epoch [6945/20000], Loss: 882.8707885742188, Entropy 419.61663818359375, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6946/20000], Loss: 931.0487670898438, Entropy 432.94573974609375, Learning Rate: 0.00125\n",
      "Epoch [6947/20000], Loss: 861.2040405273438, Entropy 412.56488037109375, Learning Rate: 0.00125\n",
      "Epoch [6948/20000], Loss: 955.7294921875, Entropy 411.3970947265625, Learning Rate: 0.00125\n",
      "Epoch [6949/20000], Loss: 860.5009765625, Entropy 432.03564453125, Learning Rate: 0.00125\n",
      "Epoch [6950/20000], Loss: 845.7037353515625, Entropy 433.57373046875, Learning Rate: 0.00125\n",
      "Epoch [6951/20000], Loss: 894.0478515625, Entropy 433.0958251953125, Learning Rate: 0.00125\n",
      "Epoch [6952/20000], Loss: 884.7886962890625, Entropy 418.0171813964844, Learning Rate: 0.00125\n",
      "Epoch [6953/20000], Loss: 976.94140625, Entropy 429.9129333496094, Learning Rate: 0.00125\n",
      "Epoch [6954/20000], Loss: 930.161865234375, Entropy 413.1977233886719, Learning Rate: 0.00125\n",
      "Epoch [6955/20000], Loss: 927.1807250976562, Entropy 415.81207275390625, Learning Rate: 0.00125\n",
      "Epoch [6956/20000], Loss: 922.4978637695312, Entropy 409.47259521484375, Learning Rate: 0.00125\n",
      "Epoch [6957/20000], Loss: 911.730224609375, Entropy 426.578857421875, Learning Rate: 0.00125\n",
      "Epoch [6958/20000], Loss: 877.1051025390625, Entropy 417.2760009765625, Learning Rate: 0.00125\n",
      "Epoch [6959/20000], Loss: 910.8768310546875, Entropy 416.0562438964844, Learning Rate: 0.00125\n",
      "Epoch [6960/20000], Loss: 915.1511840820312, Entropy 421.12396240234375, Learning Rate: 0.00125\n",
      "Epoch [6961/20000], Loss: 912.4844970703125, Entropy 423.7706298828125, Learning Rate: 0.00125\n",
      "Epoch [6962/20000], Loss: 912.799560546875, Entropy 439.4853820800781, Learning Rate: 0.00125\n",
      "Epoch [6963/20000], Loss: 896.2923583984375, Entropy 428.1469421386719, Learning Rate: 0.00125\n",
      "Epoch [6964/20000], Loss: 916.603271484375, Entropy 427.19970703125, Learning Rate: 0.00125\n",
      "Epoch [6965/20000], Loss: 918.849365234375, Entropy 422.1756896972656, Learning Rate: 0.00125\n",
      "Epoch [6966/20000], Loss: 850.7008056640625, Entropy 427.0364685058594, Learning Rate: 0.00125\n",
      "Epoch [6967/20000], Loss: 890.9237060546875, Entropy 413.0352783203125, Learning Rate: 0.00125\n",
      "Epoch [6968/20000], Loss: 883.96044921875, Entropy 420.1478271484375, Learning Rate: 0.00125\n",
      "Epoch [6969/20000], Loss: 899.3123779296875, Entropy 429.6197509765625, Learning Rate: 0.00125\n",
      "Epoch [6970/20000], Loss: 920.5455322265625, Entropy 422.389404296875, Learning Rate: 0.00125\n",
      "Epoch [6971/20000], Loss: 939.0636596679688, Entropy 417.86383056640625, Learning Rate: 0.00125\n",
      "Epoch [6972/20000], Loss: 867.9178466796875, Entropy 418.8252258300781, Learning Rate: 0.00125\n",
      "Epoch [6973/20000], Loss: 885.38232421875, Entropy 425.8966369628906, Learning Rate: 0.00125\n",
      "Epoch [6974/20000], Loss: 857.2992553710938, Entropy 418.93170166015625, Learning Rate: 0.00125\n",
      "Epoch [6975/20000], Loss: 898.138427734375, Entropy 421.68603515625, Learning Rate: 0.00125\n",
      "Epoch [6976/20000], Loss: 862.7281494140625, Entropy 436.5852355957031, Learning Rate: 0.00125\n",
      "Epoch [6977/20000], Loss: 889.7813110351562, Entropy 419.87689208984375, Learning Rate: 0.00125\n",
      "Epoch [6978/20000], Loss: 891.763671875, Entropy 422.3425598144531, Learning Rate: 0.00125\n",
      "Epoch [6979/20000], Loss: 911.7887573242188, Entropy 425.51031494140625, Learning Rate: 0.00125\n",
      "Epoch [6980/20000], Loss: 930.2589111328125, Entropy 405.8697509765625, Learning Rate: 0.00125\n",
      "Epoch [6981/20000], Loss: 877.301513671875, Entropy 428.4467468261719, Learning Rate: 0.00125\n",
      "Epoch [6982/20000], Loss: 909.8934326171875, Entropy 421.0328674316406, Learning Rate: 0.00125\n",
      "Epoch [6983/20000], Loss: 874.515869140625, Entropy 412.1594543457031, Learning Rate: 0.00125\n",
      "Epoch [6984/20000], Loss: 882.9415283203125, Entropy 429.4797058105469, Learning Rate: 0.00125\n",
      "Epoch [6985/20000], Loss: 918.7725219726562, Entropy 412.89764404296875, Learning Rate: 0.00125\n",
      "Epoch [6986/20000], Loss: 886.8569946289062, Entropy 427.52984619140625, Learning Rate: 0.00125\n",
      "Epoch [6987/20000], Loss: 840.8580322265625, Entropy 433.2381286621094, Learning Rate: 0.00125\n",
      "Epoch [6988/20000], Loss: 915.836669921875, Entropy 411.8582763671875, Learning Rate: 0.00125\n",
      "Epoch [6989/20000], Loss: 870.6104736328125, Entropy 423.7813720703125, Learning Rate: 0.00125\n",
      "Epoch [6990/20000], Loss: 894.5611572265625, Entropy 421.9657287597656, Learning Rate: 0.00125\n",
      "Epoch [6991/20000], Loss: 892.6347045898438, Entropy 418.28216552734375, Learning Rate: 0.00125\n",
      "Epoch [6992/20000], Loss: 859.5675048828125, Entropy 413.47265625, Learning Rate: 0.00125\n",
      "Epoch [6993/20000], Loss: 876.234130859375, Entropy 421.6346130371094, Learning Rate: 0.00125\n",
      "Epoch [6994/20000], Loss: 877.1530151367188, Entropy 420.69915771484375, Learning Rate: 0.00125\n",
      "Epoch [6995/20000], Loss: 931.8394775390625, Entropy 409.4129333496094, Learning Rate: 0.00125\n",
      "Epoch [6996/20000], Loss: 853.9768676757812, Entropy 414.00885009765625, Learning Rate: 0.00125\n",
      "Epoch [6997/20000], Loss: 907.6396484375, Entropy 423.773193359375, Learning Rate: 0.00125\n",
      "Epoch [6998/20000], Loss: 926.707763671875, Entropy 414.83349609375, Learning Rate: 0.00125\n",
      "Epoch [6999/20000], Loss: 911.5655517578125, Entropy 427.5777893066406, Learning Rate: 0.00125\n",
      "Epoch [7000/20000], Loss: 907.7763671875, Entropy 422.0847473144531, Learning Rate: 0.00125\n",
      "Epoch [7001/20000], Loss: 910.73486328125, Entropy 427.56982421875, Learning Rate: 0.00125\n",
      "Epoch [7002/20000], Loss: 871.126708984375, Entropy 422.7917785644531, Learning Rate: 0.00125\n",
      "Epoch [7003/20000], Loss: 910.44873046875, Entropy 437.7500305175781, Learning Rate: 0.00125\n",
      "Epoch [7004/20000], Loss: 878.9744873046875, Entropy 427.6038818359375, Learning Rate: 0.00125\n",
      "Epoch [7005/20000], Loss: 909.2119750976562, Entropy 416.51458740234375, Learning Rate: 0.00125\n",
      "Epoch [7006/20000], Loss: 887.5238037109375, Entropy 419.9203796386719, Learning Rate: 0.00125\n",
      "Epoch [7007/20000], Loss: 903.0328369140625, Entropy 420.7318115234375, Learning Rate: 0.00125\n",
      "Epoch [7008/20000], Loss: 900.12158203125, Entropy 417.1167907714844, Learning Rate: 0.00125\n",
      "Epoch [7009/20000], Loss: 882.005615234375, Entropy 417.4002990722656, Learning Rate: 0.00125\n",
      "Epoch [7010/20000], Loss: 887.9000244140625, Entropy 425.1669006347656, Learning Rate: 0.00125\n",
      "Epoch [7011/20000], Loss: 884.35009765625, Entropy 418.3897705078125, Learning Rate: 0.00125\n",
      "Epoch [7012/20000], Loss: 927.102783203125, Entropy 426.592529296875, Learning Rate: 0.00125\n",
      "Epoch [7013/20000], Loss: 909.48291015625, Entropy 402.583984375, Learning Rate: 0.00125\n",
      "Epoch [7014/20000], Loss: 921.347412109375, Entropy 418.2007751464844, Learning Rate: 0.00125\n",
      "Epoch [7015/20000], Loss: 926.6536865234375, Entropy 410.9969787597656, Learning Rate: 0.00125\n",
      "Epoch [7016/20000], Loss: 873.9793701171875, Entropy 419.2184753417969, Learning Rate: 0.00125\n",
      "Epoch [7017/20000], Loss: 859.2589721679688, Entropy 436.03558349609375, Learning Rate: 0.00125\n",
      "Epoch [7018/20000], Loss: 879.6591796875, Entropy 434.1814270019531, Learning Rate: 0.00125\n",
      "Epoch [7019/20000], Loss: 881.7381591796875, Entropy 419.6268005371094, Learning Rate: 0.00125\n",
      "Epoch [7020/20000], Loss: 891.7374267578125, Entropy 408.1158447265625, Learning Rate: 0.00125\n",
      "Epoch [7021/20000], Loss: 914.6837158203125, Entropy 421.63232421875, Learning Rate: 0.00125\n",
      "Epoch [7022/20000], Loss: 885.2755737304688, Entropy 427.71099853515625, Learning Rate: 0.00125\n",
      "Epoch [7023/20000], Loss: 942.214599609375, Entropy 422.0476379394531, Learning Rate: 0.00125\n",
      "Epoch [7024/20000], Loss: 874.05615234375, Entropy 433.5876770019531, Learning Rate: 0.00125\n",
      "Epoch [7025/20000], Loss: 916.8065185546875, Entropy 418.0474853515625, Learning Rate: 0.00125\n",
      "Epoch [7026/20000], Loss: 863.2933959960938, Entropy 433.36517333984375, Learning Rate: 0.00125\n",
      "Epoch [7027/20000], Loss: 900.492431640625, Entropy 421.06005859375, Learning Rate: 0.00125\n",
      "Epoch [7028/20000], Loss: 917.0368041992188, Entropy 425.40570068359375, Learning Rate: 0.00125\n",
      "Epoch [7029/20000], Loss: 889.72802734375, Entropy 412.5777282714844, Learning Rate: 0.00125\n",
      "Epoch [7030/20000], Loss: 858.0367431640625, Entropy 424.075927734375, Learning Rate: 0.00125\n",
      "Epoch [7031/20000], Loss: 882.9905395507812, Entropy 419.55023193359375, Learning Rate: 0.00125\n",
      "Epoch [7032/20000], Loss: 896.0931396484375, Entropy 409.8231201171875, Learning Rate: 0.00125\n",
      "Epoch [7033/20000], Loss: 862.39892578125, Entropy 434.6376037597656, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7034/20000], Loss: 872.2332763671875, Entropy 419.0301513671875, Learning Rate: 0.00125\n",
      "Epoch [7035/20000], Loss: 897.6807861328125, Entropy 414.6764221191406, Learning Rate: 0.00125\n",
      "Epoch [7036/20000], Loss: 867.4910888671875, Entropy 422.6367492675781, Learning Rate: 0.00125\n",
      "Epoch [7037/20000], Loss: 887.2111206054688, Entropy 407.21929931640625, Learning Rate: 0.00125\n",
      "Epoch [7038/20000], Loss: 927.01904296875, Entropy 432.2110900878906, Learning Rate: 0.00125\n",
      "Epoch [7039/20000], Loss: 882.424072265625, Entropy 415.8517150878906, Learning Rate: 0.00125\n",
      "Epoch [7040/20000], Loss: 887.7664794921875, Entropy 422.192138671875, Learning Rate: 0.00125\n",
      "Epoch [7041/20000], Loss: 848.3714599609375, Entropy 432.9305725097656, Learning Rate: 0.00125\n",
      "Epoch [7042/20000], Loss: 893.3185424804688, Entropy 425.34881591796875, Learning Rate: 0.00125\n",
      "Epoch [7043/20000], Loss: 937.2850341796875, Entropy 416.2318115234375, Learning Rate: 0.00125\n",
      "Epoch [7044/20000], Loss: 865.9940185546875, Entropy 434.1954650878906, Learning Rate: 0.00125\n",
      "Epoch [7045/20000], Loss: 853.2551879882812, Entropy 415.48724365234375, Learning Rate: 0.00125\n",
      "Epoch [7046/20000], Loss: 872.7935791015625, Entropy 415.9433898925781, Learning Rate: 0.00125\n",
      "Epoch [7047/20000], Loss: 878.202880859375, Entropy 417.6784362792969, Learning Rate: 0.00125\n",
      "Epoch [7048/20000], Loss: 863.071533203125, Entropy 416.3883972167969, Learning Rate: 0.00125\n",
      "Epoch [7049/20000], Loss: 874.9080810546875, Entropy 420.5345153808594, Learning Rate: 0.00125\n",
      "Epoch [7050/20000], Loss: 885.8215942382812, Entropy 422.67279052734375, Learning Rate: 0.00125\n",
      "Epoch [7051/20000], Loss: 847.001953125, Entropy 430.2771301269531, Learning Rate: 0.00125\n",
      "Epoch [7052/20000], Loss: 869.5288696289062, Entropy 431.97564697265625, Learning Rate: 0.00125\n",
      "Epoch [7053/20000], Loss: 863.0970458984375, Entropy 420.7912292480469, Learning Rate: 0.00125\n",
      "Epoch [7054/20000], Loss: 898.5819091796875, Entropy 426.5555114746094, Learning Rate: 0.00125\n",
      "Epoch [7055/20000], Loss: 810.8914794921875, Entropy 436.6287536621094, Learning Rate: 0.00125\n",
      "Epoch [7056/20000], Loss: 919.6425170898438, Entropy 418.38226318359375, Learning Rate: 0.00125\n",
      "Epoch [7057/20000], Loss: 880.060791015625, Entropy 418.3019104003906, Learning Rate: 0.00125\n",
      "Epoch [7058/20000], Loss: 897.4270629882812, Entropy 423.82171630859375, Learning Rate: 0.00125\n",
      "Epoch [7059/20000], Loss: 860.2740478515625, Entropy 415.5467224121094, Learning Rate: 0.00125\n",
      "Epoch [7060/20000], Loss: 866.616455078125, Entropy 423.5482177734375, Learning Rate: 0.00125\n",
      "Epoch [7061/20000], Loss: 943.6177978515625, Entropy 424.5837707519531, Learning Rate: 0.00125\n",
      "Epoch [7062/20000], Loss: 902.3623046875, Entropy 415.3045654296875, Learning Rate: 0.00125\n",
      "Epoch [7063/20000], Loss: 900.0401000976562, Entropy 419.85491943359375, Learning Rate: 0.00125\n",
      "Epoch [7064/20000], Loss: 879.3388671875, Entropy 411.77880859375, Learning Rate: 0.00125\n",
      "Epoch [7065/20000], Loss: 884.0968017578125, Entropy 415.8634338378906, Learning Rate: 0.00125\n",
      "Epoch [7066/20000], Loss: 895.44580078125, Entropy 418.8088073730469, Learning Rate: 0.00125\n",
      "Epoch [7067/20000], Loss: 882.0953979492188, Entropy 415.32366943359375, Learning Rate: 0.00125\n",
      "Epoch [7068/20000], Loss: 875.7471923828125, Entropy 421.9461669921875, Learning Rate: 0.00125\n",
      "Epoch [7069/20000], Loss: 889.54248046875, Entropy 405.0769348144531, Learning Rate: 0.00125\n",
      "Epoch [7070/20000], Loss: 906.3472900390625, Entropy 407.4490661621094, Learning Rate: 0.00125\n",
      "Epoch [7071/20000], Loss: 853.3505249023438, Entropy 417.01190185546875, Learning Rate: 0.00125\n",
      "Epoch [7072/20000], Loss: 895.1923828125, Entropy 420.2056884765625, Learning Rate: 0.00125\n",
      "Epoch [7073/20000], Loss: 838.4010009765625, Entropy 420.5793151855469, Learning Rate: 0.00125\n",
      "Epoch [7074/20000], Loss: 852.5830688476562, Entropy 439.43780517578125, Learning Rate: 0.00125\n",
      "Epoch [7075/20000], Loss: 876.2256469726562, Entropy 425.13482666015625, Learning Rate: 0.00125\n",
      "Epoch [7076/20000], Loss: 908.8414306640625, Entropy 413.3170471191406, Learning Rate: 0.00125\n",
      "Epoch [7077/20000], Loss: 841.8031005859375, Entropy 427.3983154296875, Learning Rate: 0.00125\n",
      "Epoch [7078/20000], Loss: 901.5428466796875, Entropy 426.9424133300781, Learning Rate: 0.00125\n",
      "Epoch [7079/20000], Loss: 900.8358154296875, Entropy 415.2965393066406, Learning Rate: 0.00125\n",
      "Epoch [7080/20000], Loss: 923.154296875, Entropy 410.6402587890625, Learning Rate: 0.00125\n",
      "Epoch [7081/20000], Loss: 866.623046875, Entropy 424.48486328125, Learning Rate: 0.00125\n",
      "Epoch [7082/20000], Loss: 867.58740234375, Entropy 432.4742736816406, Learning Rate: 0.00125\n",
      "Epoch [7083/20000], Loss: 838.8150634765625, Entropy 441.5422058105469, Learning Rate: 0.00125\n",
      "Epoch [7084/20000], Loss: 927.38037109375, Entropy 413.9568176269531, Learning Rate: 0.00125\n",
      "Epoch [7085/20000], Loss: 932.6221923828125, Entropy 399.6805419921875, Learning Rate: 0.00125\n",
      "Epoch [7086/20000], Loss: 910.68017578125, Entropy 422.2760009765625, Learning Rate: 0.00125\n",
      "Epoch [7087/20000], Loss: 896.163330078125, Entropy 430.388671875, Learning Rate: 0.00125\n",
      "Epoch [7088/20000], Loss: 906.3216552734375, Entropy 430.9049072265625, Learning Rate: 0.00125\n",
      "Epoch [7089/20000], Loss: 878.8168334960938, Entropy 437.40350341796875, Learning Rate: 0.00125\n",
      "Epoch [7090/20000], Loss: 925.6502075195312, Entropy 431.01104736328125, Learning Rate: 0.00125\n",
      "Epoch [7091/20000], Loss: 885.0824584960938, Entropy 429.75921630859375, Learning Rate: 0.00125\n",
      "Epoch [7092/20000], Loss: 882.6672973632812, Entropy 441.04498291015625, Learning Rate: 0.00125\n",
      "Epoch [7093/20000], Loss: 900.2254638671875, Entropy 424.629638671875, Learning Rate: 0.00125\n",
      "Epoch [7094/20000], Loss: 925.450439453125, Entropy 428.3363952636719, Learning Rate: 0.00125\n",
      "Epoch [7095/20000], Loss: 868.3606567382812, Entropy 440.14361572265625, Learning Rate: 0.00125\n",
      "Epoch [7096/20000], Loss: 870.0615234375, Entropy 404.7352294921875, Learning Rate: 0.00125\n",
      "Epoch [7097/20000], Loss: 900.7877197265625, Entropy 425.6539001464844, Learning Rate: 0.00125\n",
      "Epoch [7098/20000], Loss: 885.291015625, Entropy 425.8363952636719, Learning Rate: 0.00125\n",
      "Epoch [7099/20000], Loss: 915.09326171875, Entropy 422.1148376464844, Learning Rate: 0.00125\n",
      "Epoch [7100/20000], Loss: 829.4869384765625, Entropy 419.0860900878906, Learning Rate: 0.00125\n",
      "Epoch [7101/20000], Loss: 851.228515625, Entropy 429.596435546875, Learning Rate: 0.00125\n",
      "Epoch [7102/20000], Loss: 929.994140625, Entropy 412.576171875, Learning Rate: 0.00125\n",
      "Epoch [7103/20000], Loss: 884.7535400390625, Entropy 397.2130126953125, Learning Rate: 0.00125\n",
      "Epoch [7104/20000], Loss: 890.4173583984375, Entropy 423.3277893066406, Learning Rate: 0.00125\n",
      "Epoch [7105/20000], Loss: 922.7510986328125, Entropy 413.4421691894531, Learning Rate: 0.00125\n",
      "Epoch [7106/20000], Loss: 864.77783203125, Entropy 423.9698486328125, Learning Rate: 0.00125\n",
      "Epoch [7107/20000], Loss: 870.978759765625, Entropy 442.9453125, Learning Rate: 0.00125\n",
      "Epoch [7108/20000], Loss: 865.8657836914062, Entropy 417.94049072265625, Learning Rate: 0.00125\n",
      "Epoch [7109/20000], Loss: 908.4502563476562, Entropy 428.70819091796875, Learning Rate: 0.00125\n",
      "Epoch [7110/20000], Loss: 896.4722900390625, Entropy 417.3793640136719, Learning Rate: 0.00125\n",
      "Epoch [7111/20000], Loss: 909.8500366210938, Entropy 416.18695068359375, Learning Rate: 0.00125\n",
      "Epoch [7112/20000], Loss: 899.989013671875, Entropy 438.3710021972656, Learning Rate: 0.00125\n",
      "Epoch [7113/20000], Loss: 928.681884765625, Entropy 420.4649658203125, Learning Rate: 0.00125\n",
      "Epoch [7114/20000], Loss: 878.9556884765625, Entropy 444.2486267089844, Learning Rate: 0.00125\n",
      "Epoch [7115/20000], Loss: 854.0637817382812, Entropy 429.98394775390625, Learning Rate: 0.00125\n",
      "Epoch [7116/20000], Loss: 926.9669189453125, Entropy 426.9522705078125, Learning Rate: 0.00125\n",
      "Epoch [7117/20000], Loss: 886.682373046875, Entropy 416.6104736328125, Learning Rate: 0.00125\n",
      "Epoch [7118/20000], Loss: 877.9996337890625, Entropy 419.259521484375, Learning Rate: 0.00125\n",
      "Epoch [7119/20000], Loss: 882.3829345703125, Entropy 429.783935546875, Learning Rate: 0.00125\n",
      "Epoch [7120/20000], Loss: 863.9071044921875, Entropy 421.9847412109375, Learning Rate: 0.00125\n",
      "Epoch [7121/20000], Loss: 893.2911376953125, Entropy 431.4694519042969, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7122/20000], Loss: 880.4403686523438, Entropy 430.97784423828125, Learning Rate: 0.00125\n",
      "Epoch [7123/20000], Loss: 847.8429565429688, Entropy 439.58148193359375, Learning Rate: 0.00125\n",
      "Epoch [7124/20000], Loss: 881.369873046875, Entropy 413.9146728515625, Learning Rate: 0.00125\n",
      "Epoch [7125/20000], Loss: 878.0748291015625, Entropy 432.3296813964844, Learning Rate: 0.00125\n",
      "Epoch [7126/20000], Loss: 868.1941528320312, Entropy 429.71905517578125, Learning Rate: 0.00125\n",
      "Epoch [7127/20000], Loss: 890.0936279296875, Entropy 412.4134521484375, Learning Rate: 0.00125\n",
      "Epoch [7128/20000], Loss: 864.6531982421875, Entropy 434.5013122558594, Learning Rate: 0.00125\n",
      "Epoch [7129/20000], Loss: 870.2755126953125, Entropy 418.6620178222656, Learning Rate: 0.00125\n",
      "Epoch [7130/20000], Loss: 866.94482421875, Entropy 433.4220886230469, Learning Rate: 0.00125\n",
      "Epoch [7131/20000], Loss: 870.438720703125, Entropy 418.35791015625, Learning Rate: 0.00125\n",
      "Epoch [7132/20000], Loss: 851.2757568359375, Entropy 417.3069763183594, Learning Rate: 0.00125\n",
      "Epoch [7133/20000], Loss: 902.5650634765625, Entropy 428.648193359375, Learning Rate: 0.00125\n",
      "Epoch [7134/20000], Loss: 863.9727172851562, Entropy 426.06597900390625, Learning Rate: 0.00125\n",
      "Epoch [7135/20000], Loss: 943.837646484375, Entropy 417.4034423828125, Learning Rate: 0.00125\n",
      "Epoch [7136/20000], Loss: 878.398681640625, Entropy 412.8568115234375, Learning Rate: 0.00125\n",
      "Epoch [7137/20000], Loss: 855.32568359375, Entropy 417.4893798828125, Learning Rate: 0.00125\n",
      "Epoch [7138/20000], Loss: 904.089111328125, Entropy 425.70849609375, Learning Rate: 0.00125\n",
      "Epoch [7139/20000], Loss: 953.6588134765625, Entropy 414.1202392578125, Learning Rate: 0.00125\n",
      "Epoch [7140/20000], Loss: 890.6050415039062, Entropy 433.08489990234375, Learning Rate: 0.00125\n",
      "Epoch [7141/20000], Loss: 882.2940063476562, Entropy 405.04095458984375, Learning Rate: 0.00125\n",
      "Epoch [7142/20000], Loss: 886.7352294921875, Entropy 427.94140625, Learning Rate: 0.00125\n",
      "Epoch [7143/20000], Loss: 929.0825805664062, Entropy 421.38201904296875, Learning Rate: 0.00125\n",
      "Epoch [7144/20000], Loss: 862.930419921875, Entropy 425.9700012207031, Learning Rate: 0.00125\n",
      "Epoch [7145/20000], Loss: 908.600830078125, Entropy 417.7264709472656, Learning Rate: 0.00125\n",
      "Epoch [7146/20000], Loss: 896.4268798828125, Entropy 418.2507629394531, Learning Rate: 0.00125\n",
      "Epoch [7147/20000], Loss: 823.7115478515625, Entropy 434.7727966308594, Learning Rate: 0.00125\n",
      "Epoch [7148/20000], Loss: 893.5551147460938, Entropy 426.78924560546875, Learning Rate: 0.00125\n",
      "Epoch [7149/20000], Loss: 902.3233642578125, Entropy 418.3916320800781, Learning Rate: 0.00125\n",
      "Epoch [7150/20000], Loss: 877.404541015625, Entropy 427.2552185058594, Learning Rate: 0.00125\n",
      "Epoch [7151/20000], Loss: 905.5588989257812, Entropy 433.10858154296875, Learning Rate: 0.00125\n",
      "Epoch [7152/20000], Loss: 885.0609130859375, Entropy 418.2721862792969, Learning Rate: 0.00125\n",
      "Epoch [7153/20000], Loss: 879.34423828125, Entropy 420.8825988769531, Learning Rate: 0.00125\n",
      "Epoch [7154/20000], Loss: 904.9387817382812, Entropy 422.59820556640625, Learning Rate: 0.00125\n",
      "Epoch [7155/20000], Loss: 900.274658203125, Entropy 423.3453674316406, Learning Rate: 0.00125\n",
      "Epoch [7156/20000], Loss: 878.348876953125, Entropy 434.1867370605469, Learning Rate: 0.00125\n",
      "Epoch [7157/20000], Loss: 862.1683349609375, Entropy 421.4237365722656, Learning Rate: 0.00125\n",
      "Epoch [7158/20000], Loss: 884.4415893554688, Entropy 414.40191650390625, Learning Rate: 0.00125\n",
      "Epoch [7159/20000], Loss: 859.5282592773438, Entropy 423.62750244140625, Learning Rate: 0.00125\n",
      "Epoch [7160/20000], Loss: 896.0045166015625, Entropy 420.4529724121094, Learning Rate: 0.00125\n",
      "Epoch [7161/20000], Loss: 851.984375, Entropy 427.6360778808594, Learning Rate: 0.00125\n",
      "Epoch [7162/20000], Loss: 866.7645263671875, Entropy 413.9929504394531, Learning Rate: 0.00125\n",
      "Epoch [7163/20000], Loss: 853.4322509765625, Entropy 427.8045349121094, Learning Rate: 0.00125\n",
      "Epoch [7164/20000], Loss: 890.7047119140625, Entropy 427.8874206542969, Learning Rate: 0.00125\n",
      "Epoch [7165/20000], Loss: 876.0374755859375, Entropy 418.2555236816406, Learning Rate: 0.00125\n",
      "Epoch [7166/20000], Loss: 867.52978515625, Entropy 428.2681579589844, Learning Rate: 0.00125\n",
      "Epoch [7167/20000], Loss: 862.355712890625, Entropy 425.0790100097656, Learning Rate: 0.00125\n",
      "Epoch [7168/20000], Loss: 911.010009765625, Entropy 406.7121887207031, Learning Rate: 0.00125\n",
      "Epoch [7169/20000], Loss: 902.9845581054688, Entropy 425.97076416015625, Learning Rate: 0.00125\n",
      "Epoch [7170/20000], Loss: 847.58935546875, Entropy 445.3185119628906, Learning Rate: 0.00125\n",
      "Epoch [7171/20000], Loss: 872.7994384765625, Entropy 434.0332336425781, Learning Rate: 0.00125\n",
      "Epoch [7172/20000], Loss: 904.16943359375, Entropy 416.9796447753906, Learning Rate: 0.00125\n",
      "Epoch [7173/20000], Loss: 860.5514526367188, Entropy 431.08551025390625, Learning Rate: 0.00125\n",
      "Epoch [7174/20000], Loss: 885.206298828125, Entropy 430.0082702636719, Learning Rate: 0.00125\n",
      "Epoch [7175/20000], Loss: 885.6502685546875, Entropy 413.6939697265625, Learning Rate: 0.00125\n",
      "Epoch [7176/20000], Loss: 846.1142578125, Entropy 428.9906005859375, Learning Rate: 0.00125\n",
      "Epoch [7177/20000], Loss: 860.7195434570312, Entropy 424.41265869140625, Learning Rate: 0.00125\n",
      "Epoch [7178/20000], Loss: 882.8258056640625, Entropy 428.6141357421875, Learning Rate: 0.00125\n",
      "Epoch [7179/20000], Loss: 863.5650024414062, Entropy 435.34429931640625, Learning Rate: 0.00125\n",
      "Epoch [7180/20000], Loss: 871.4512939453125, Entropy 431.0456237792969, Learning Rate: 0.00125\n",
      "Epoch [7181/20000], Loss: 919.7691040039062, Entropy 426.46307373046875, Learning Rate: 0.00125\n",
      "Epoch [7182/20000], Loss: 854.1964721679688, Entropy 419.30621337890625, Learning Rate: 0.00125\n",
      "Epoch [7183/20000], Loss: 883.8768310546875, Entropy 426.3982849121094, Learning Rate: 0.00125\n",
      "Epoch [7184/20000], Loss: 893.5237426757812, Entropy 411.69195556640625, Learning Rate: 0.00125\n",
      "Epoch [7185/20000], Loss: 873.2208862304688, Entropy 427.26507568359375, Learning Rate: 0.00125\n",
      "Epoch [7186/20000], Loss: 917.6709594726562, Entropy 428.16241455078125, Learning Rate: 0.00125\n",
      "Epoch [7187/20000], Loss: 854.5426635742188, Entropy 434.63922119140625, Learning Rate: 0.00125\n",
      "Epoch [7188/20000], Loss: 848.8133544921875, Entropy 419.9655456542969, Learning Rate: 0.00125\n",
      "Epoch [7189/20000], Loss: 832.1152954101562, Entropy 430.72845458984375, Learning Rate: 0.00125\n",
      "Epoch [7190/20000], Loss: 832.6846313476562, Entropy 426.51263427734375, Learning Rate: 0.00125\n",
      "Epoch [7191/20000], Loss: 855.1370849609375, Entropy 430.06298828125, Learning Rate: 0.00125\n",
      "Epoch [7192/20000], Loss: 892.8780517578125, Entropy 421.24609375, Learning Rate: 0.00125\n",
      "Epoch [7193/20000], Loss: 872.3973999023438, Entropy 443.48382568359375, Learning Rate: 0.00125\n",
      "Epoch [7194/20000], Loss: 893.8011474609375, Entropy 426.1318359375, Learning Rate: 0.00125\n",
      "Epoch [7195/20000], Loss: 885.4130249023438, Entropy 430.52105712890625, Learning Rate: 0.00125\n",
      "Epoch [7196/20000], Loss: 874.7677001953125, Entropy 415.0534362792969, Learning Rate: 0.00125\n",
      "Epoch [7197/20000], Loss: 844.3090209960938, Entropy 429.91046142578125, Learning Rate: 0.00125\n",
      "Epoch [7198/20000], Loss: 871.1351928710938, Entropy 433.52337646484375, Learning Rate: 0.00125\n",
      "Epoch [7199/20000], Loss: 856.5474853515625, Entropy 415.3148193359375, Learning Rate: 0.00125\n",
      "Epoch [7200/20000], Loss: 881.36083984375, Entropy 417.4295349121094, Learning Rate: 0.00125\n",
      "Epoch [7201/20000], Loss: 831.6376342773438, Entropy 433.39056396484375, Learning Rate: 0.00125\n",
      "Epoch [7202/20000], Loss: 889.8218994140625, Entropy 415.4281005859375, Learning Rate: 0.00125\n",
      "Epoch [7203/20000], Loss: 897.891357421875, Entropy 426.76123046875, Learning Rate: 0.00125\n",
      "Epoch [7204/20000], Loss: 859.0498046875, Entropy 424.9460754394531, Learning Rate: 0.00125\n",
      "Epoch [7205/20000], Loss: 891.5148315429688, Entropy 419.51312255859375, Learning Rate: 0.00125\n",
      "Epoch [7206/20000], Loss: 916.6412353515625, Entropy 425.3396911621094, Learning Rate: 0.00125\n",
      "Epoch [7207/20000], Loss: 907.3016357421875, Entropy 430.3092956542969, Learning Rate: 0.00125\n",
      "Epoch [7208/20000], Loss: 871.38916015625, Entropy 412.5160827636719, Learning Rate: 0.00125\n",
      "Epoch [7209/20000], Loss: 902.4341430664062, Entropy 430.38494873046875, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7210/20000], Loss: 891.1851806640625, Entropy 427.5481872558594, Learning Rate: 0.00125\n",
      "Epoch [7211/20000], Loss: 889.009521484375, Entropy 415.4836730957031, Learning Rate: 0.00125\n",
      "Epoch [7212/20000], Loss: 919.4989013671875, Entropy 424.4832763671875, Learning Rate: 0.00125\n",
      "Epoch [7213/20000], Loss: 855.683349609375, Entropy 412.5080871582031, Learning Rate: 0.00125\n",
      "Epoch [7214/20000], Loss: 912.4132080078125, Entropy 414.0859680175781, Learning Rate: 0.00125\n",
      "Epoch [7215/20000], Loss: 861.4990234375, Entropy 427.8740234375, Learning Rate: 0.00125\n",
      "Epoch [7216/20000], Loss: 883.6485595703125, Entropy 423.63818359375, Learning Rate: 0.00125\n",
      "Epoch [7217/20000], Loss: 908.7921142578125, Entropy 417.5059814453125, Learning Rate: 0.00125\n",
      "Epoch [7218/20000], Loss: 879.6575927734375, Entropy 426.3297119140625, Learning Rate: 0.00125\n",
      "Epoch [7219/20000], Loss: 902.0367431640625, Entropy 425.7269287109375, Learning Rate: 0.00125\n",
      "Epoch [7220/20000], Loss: 828.837646484375, Entropy 446.7198486328125, Learning Rate: 0.00125\n",
      "Epoch [7221/20000], Loss: 873.0936889648438, Entropy 429.78717041015625, Learning Rate: 0.00125\n",
      "Epoch [7222/20000], Loss: 927.0986938476562, Entropy 413.50030517578125, Learning Rate: 0.00125\n",
      "Epoch [7223/20000], Loss: 890.2974853515625, Entropy 427.2159423828125, Learning Rate: 0.00125\n",
      "Epoch [7224/20000], Loss: 864.2957153320312, Entropy 417.37835693359375, Learning Rate: 0.00125\n",
      "Epoch [7225/20000], Loss: 907.4876708984375, Entropy 422.5111083984375, Learning Rate: 0.00125\n",
      "Epoch [7226/20000], Loss: 915.659912109375, Entropy 424.4906921386719, Learning Rate: 0.00125\n",
      "Epoch [7227/20000], Loss: 867.964599609375, Entropy 437.1056823730469, Learning Rate: 0.00125\n",
      "Epoch [7228/20000], Loss: 898.1368408203125, Entropy 420.9940490722656, Learning Rate: 0.00125\n",
      "Epoch [7229/20000], Loss: 865.0601806640625, Entropy 421.6121826171875, Learning Rate: 0.00125\n",
      "Epoch [7230/20000], Loss: 904.0726318359375, Entropy 421.6488952636719, Learning Rate: 0.00125\n",
      "Epoch [7231/20000], Loss: 899.76318359375, Entropy 422.3572692871094, Learning Rate: 0.00125\n",
      "Epoch [7232/20000], Loss: 874.0936889648438, Entropy 434.61248779296875, Learning Rate: 0.00125\n",
      "Epoch [7233/20000], Loss: 895.248779296875, Entropy 431.3291320800781, Learning Rate: 0.00125\n",
      "Epoch [7234/20000], Loss: 881.4699096679688, Entropy 425.60894775390625, Learning Rate: 0.00125\n",
      "Epoch [7235/20000], Loss: 893.7138671875, Entropy 421.1748352050781, Learning Rate: 0.00125\n",
      "Epoch [7236/20000], Loss: 895.170654296875, Entropy 424.3601989746094, Learning Rate: 0.00125\n",
      "Epoch [7237/20000], Loss: 899.346923828125, Entropy 417.2414855957031, Learning Rate: 0.00125\n",
      "Epoch [7238/20000], Loss: 841.910888671875, Entropy 435.6279296875, Learning Rate: 0.00125\n",
      "Epoch [7239/20000], Loss: 865.2542114257812, Entropy 426.24468994140625, Learning Rate: 0.00125\n",
      "Epoch [7240/20000], Loss: 900.0722045898438, Entropy 443.25433349609375, Learning Rate: 0.00125\n",
      "Epoch [7241/20000], Loss: 876.7364501953125, Entropy 418.4515075683594, Learning Rate: 0.00125\n",
      "Epoch [7242/20000], Loss: 886.9713134765625, Entropy 425.6840515136719, Learning Rate: 0.00125\n",
      "Epoch [7243/20000], Loss: 922.9794311523438, Entropy 418.47808837890625, Learning Rate: 0.00125\n",
      "Epoch [7244/20000], Loss: 887.5230712890625, Entropy 413.1331787109375, Learning Rate: 0.00125\n",
      "Epoch [7245/20000], Loss: 878.7144165039062, Entropy 418.71099853515625, Learning Rate: 0.00125\n",
      "Epoch [7246/20000], Loss: 871.2966918945312, Entropy 419.72015380859375, Learning Rate: 0.00125\n",
      "Epoch [7247/20000], Loss: 883.9215698242188, Entropy 436.96014404296875, Learning Rate: 0.00125\n",
      "Epoch [7248/20000], Loss: 878.4144287109375, Entropy 422.3150939941406, Learning Rate: 0.00125\n",
      "Epoch [7249/20000], Loss: 862.9080810546875, Entropy 418.9140930175781, Learning Rate: 0.00125\n",
      "Epoch [7250/20000], Loss: 874.074951171875, Entropy 437.6617431640625, Learning Rate: 0.00125\n",
      "Epoch [7251/20000], Loss: 836.1943359375, Entropy 438.784912109375, Learning Rate: 0.00125\n",
      "Epoch [7252/20000], Loss: 903.38427734375, Entropy 423.8038330078125, Learning Rate: 0.00125\n",
      "Epoch [7253/20000], Loss: 908.0809326171875, Entropy 437.9162292480469, Learning Rate: 0.00125\n",
      "Epoch [7254/20000], Loss: 861.7047729492188, Entropy 429.11358642578125, Learning Rate: 0.00125\n",
      "Epoch [7255/20000], Loss: 899.133056640625, Entropy 418.9273376464844, Learning Rate: 0.00125\n",
      "Epoch [7256/20000], Loss: 884.6954956054688, Entropy 437.04693603515625, Learning Rate: 0.00125\n",
      "Epoch [7257/20000], Loss: 887.4415283203125, Entropy 425.0651550292969, Learning Rate: 0.00125\n",
      "Epoch [7258/20000], Loss: 869.289794921875, Entropy 433.8686218261719, Learning Rate: 0.00125\n",
      "Epoch [7259/20000], Loss: 854.38134765625, Entropy 434.76318359375, Learning Rate: 0.00125\n",
      "Epoch [7260/20000], Loss: 868.9712524414062, Entropy 432.77008056640625, Learning Rate: 0.00125\n",
      "Epoch [7261/20000], Loss: 844.9744873046875, Entropy 431.8189392089844, Learning Rate: 0.00125\n",
      "Epoch [7262/20000], Loss: 874.3412475585938, Entropy 431.35382080078125, Learning Rate: 0.00125\n",
      "Epoch [7263/20000], Loss: 875.6981201171875, Entropy 424.1746826171875, Learning Rate: 0.00125\n",
      "Epoch [7264/20000], Loss: 910.6953125, Entropy 418.2665100097656, Learning Rate: 0.00125\n",
      "Epoch [7265/20000], Loss: 912.048095703125, Entropy 413.0569152832031, Learning Rate: 0.00125\n",
      "Epoch [7266/20000], Loss: 868.3211669921875, Entropy 417.7098083496094, Learning Rate: 0.00125\n",
      "Epoch [7267/20000], Loss: 871.908447265625, Entropy 414.2510986328125, Learning Rate: 0.00125\n",
      "Epoch [7268/20000], Loss: 855.4635009765625, Entropy 423.8749084472656, Learning Rate: 0.00125\n",
      "Epoch [7269/20000], Loss: 889.716064453125, Entropy 421.3008117675781, Learning Rate: 0.00125\n",
      "Epoch [7270/20000], Loss: 833.8017578125, Entropy 432.8681945800781, Learning Rate: 0.00125\n",
      "Epoch [7271/20000], Loss: 924.6876831054688, Entropy 412.06756591796875, Learning Rate: 0.00125\n",
      "Epoch [7272/20000], Loss: 898.9326171875, Entropy 411.191162109375, Learning Rate: 0.00125\n",
      "Epoch [7273/20000], Loss: 883.4556884765625, Entropy 411.1076354980469, Learning Rate: 0.00125\n",
      "Epoch [7274/20000], Loss: 948.4844970703125, Entropy 418.943115234375, Learning Rate: 0.00125\n",
      "Epoch [7275/20000], Loss: 868.1710205078125, Entropy 420.8202209472656, Learning Rate: 0.00125\n",
      "Epoch [7276/20000], Loss: 857.672119140625, Entropy 443.1653747558594, Learning Rate: 0.00125\n",
      "Epoch [7277/20000], Loss: 851.5125732421875, Entropy 425.1428527832031, Learning Rate: 0.00125\n",
      "Epoch [7278/20000], Loss: 878.044677734375, Entropy 425.0256042480469, Learning Rate: 0.00125\n",
      "Epoch [7279/20000], Loss: 893.186767578125, Entropy 420.020263671875, Learning Rate: 0.00125\n",
      "Epoch [7280/20000], Loss: 869.9053955078125, Entropy 443.2698669433594, Learning Rate: 0.00125\n",
      "Epoch [7281/20000], Loss: 832.1141357421875, Entropy 435.2515869140625, Learning Rate: 0.00125\n",
      "Epoch [7282/20000], Loss: 872.9899291992188, Entropy 428.86322021484375, Learning Rate: 0.00125\n",
      "Epoch [7283/20000], Loss: 894.8651123046875, Entropy 422.2423400878906, Learning Rate: 0.00125\n",
      "Epoch [7284/20000], Loss: 833.7381591796875, Entropy 421.9432678222656, Learning Rate: 0.00125\n",
      "Epoch [7285/20000], Loss: 897.7392578125, Entropy 433.0037536621094, Learning Rate: 0.00125\n",
      "Epoch [7286/20000], Loss: 860.9395751953125, Entropy 432.51318359375, Learning Rate: 0.00125\n",
      "Epoch [7287/20000], Loss: 844.252197265625, Entropy 439.9817810058594, Learning Rate: 0.00125\n",
      "Epoch [7288/20000], Loss: 849.8550415039062, Entropy 419.41339111328125, Learning Rate: 0.00125\n",
      "Epoch [7289/20000], Loss: 877.7550048828125, Entropy 425.322265625, Learning Rate: 0.00125\n",
      "Epoch [7290/20000], Loss: 872.2159423828125, Entropy 432.2381591796875, Learning Rate: 0.00125\n",
      "Epoch [7291/20000], Loss: 872.8132934570312, Entropy 432.15093994140625, Learning Rate: 0.00125\n",
      "Epoch [7292/20000], Loss: 880.1650390625, Entropy 422.2283630371094, Learning Rate: 0.00125\n",
      "Epoch [7293/20000], Loss: 891.8349609375, Entropy 422.8878173828125, Learning Rate: 0.00125\n",
      "Epoch [7294/20000], Loss: 924.4537353515625, Entropy 416.1849060058594, Learning Rate: 0.00125\n",
      "Epoch [7295/20000], Loss: 923.8822021484375, Entropy 428.675537109375, Learning Rate: 0.00125\n",
      "Epoch [7296/20000], Loss: 919.1361083984375, Entropy 416.1272888183594, Learning Rate: 0.00125\n",
      "Epoch [7297/20000], Loss: 901.51953125, Entropy 424.9197692871094, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7298/20000], Loss: 890.9686279296875, Entropy 419.3228454589844, Learning Rate: 0.00125\n",
      "Epoch [7299/20000], Loss: 899.1793212890625, Entropy 431.9187927246094, Learning Rate: 0.00125\n",
      "Epoch [7300/20000], Loss: 922.4259643554688, Entropy 436.96771240234375, Learning Rate: 0.00125\n",
      "Epoch [7301/20000], Loss: 946.4129028320312, Entropy 423.72467041015625, Learning Rate: 0.00125\n",
      "Epoch [7302/20000], Loss: 875.35107421875, Entropy 432.1360778808594, Learning Rate: 0.00125\n",
      "Epoch [7303/20000], Loss: 905.6670532226562, Entropy 427.33599853515625, Learning Rate: 0.00125\n",
      "Epoch [7304/20000], Loss: 888.18798828125, Entropy 426.7413330078125, Learning Rate: 0.00125\n",
      "Epoch [7305/20000], Loss: 874.0963134765625, Entropy 442.7319030761719, Learning Rate: 0.00125\n",
      "Epoch [7306/20000], Loss: 896.999755859375, Entropy 423.4009704589844, Learning Rate: 0.00125\n",
      "Epoch [7307/20000], Loss: 850.259521484375, Entropy 450.5721740722656, Learning Rate: 0.00125\n",
      "Epoch [7308/20000], Loss: 939.0845336914062, Entropy 429.94049072265625, Learning Rate: 0.00125\n",
      "Epoch [7309/20000], Loss: 911.4119873046875, Entropy 419.5167236328125, Learning Rate: 0.00125\n",
      "Epoch [7310/20000], Loss: 903.1353149414062, Entropy 437.12054443359375, Learning Rate: 0.00125\n",
      "Epoch [7311/20000], Loss: 896.35595703125, Entropy 421.8205261230469, Learning Rate: 0.00125\n",
      "Epoch [7312/20000], Loss: 887.6643676757812, Entropy 421.93792724609375, Learning Rate: 0.00125\n",
      "Epoch [7313/20000], Loss: 935.3880615234375, Entropy 422.2775573730469, Learning Rate: 0.00125\n",
      "Epoch [7314/20000], Loss: 874.4283447265625, Entropy 423.3094787597656, Learning Rate: 0.00125\n",
      "Epoch [7315/20000], Loss: 926.08544921875, Entropy 431.5113525390625, Learning Rate: 0.00125\n",
      "Epoch [7316/20000], Loss: 895.2454223632812, Entropy 430.85174560546875, Learning Rate: 0.00125\n",
      "Epoch [7317/20000], Loss: 852.866455078125, Entropy 438.4342956542969, Learning Rate: 0.00125\n",
      "Epoch [7318/20000], Loss: 879.4700927734375, Entropy 422.085693359375, Learning Rate: 0.00125\n",
      "Epoch [7319/20000], Loss: 899.697021484375, Entropy 426.6988830566406, Learning Rate: 0.00125\n",
      "Epoch [7320/20000], Loss: 940.6201782226562, Entropy 419.59381103515625, Learning Rate: 0.00125\n",
      "Epoch [7321/20000], Loss: 898.05908203125, Entropy 427.3376770019531, Learning Rate: 0.00125\n",
      "Epoch [7322/20000], Loss: 941.65966796875, Entropy 419.4111633300781, Learning Rate: 0.00125\n",
      "Epoch [7323/20000], Loss: 917.4842529296875, Entropy 420.7558898925781, Learning Rate: 0.00125\n",
      "Epoch [7324/20000], Loss: 858.289794921875, Entropy 436.0320129394531, Learning Rate: 0.00125\n",
      "Epoch [7325/20000], Loss: 926.56494140625, Entropy 419.8001708984375, Learning Rate: 0.00125\n",
      "Epoch [7326/20000], Loss: 893.303955078125, Entropy 438.4117736816406, Learning Rate: 0.00125\n",
      "Epoch [7327/20000], Loss: 904.809814453125, Entropy 439.6467590332031, Learning Rate: 0.00125\n",
      "Epoch [7328/20000], Loss: 909.0824584960938, Entropy 413.79193115234375, Learning Rate: 0.00125\n",
      "Epoch [7329/20000], Loss: 886.0868530273438, Entropy 417.37139892578125, Learning Rate: 0.00125\n",
      "Epoch [7330/20000], Loss: 897.3872680664062, Entropy 427.56268310546875, Learning Rate: 0.00125\n",
      "Epoch [7331/20000], Loss: 968.59375, Entropy 414.5260925292969, Learning Rate: 0.00125\n",
      "Epoch [7332/20000], Loss: 937.3896484375, Entropy 427.5587463378906, Learning Rate: 0.00125\n",
      "Epoch [7333/20000], Loss: 949.808349609375, Entropy 438.3194580078125, Learning Rate: 0.00125\n",
      "Epoch [7334/20000], Loss: 903.9627685546875, Entropy 431.9211730957031, Learning Rate: 0.00125\n",
      "Epoch [7335/20000], Loss: 964.0283813476562, Entropy 432.54217529296875, Learning Rate: 0.00125\n",
      "Epoch [7336/20000], Loss: 886.0433349609375, Entropy 417.1739807128906, Learning Rate: 0.00125\n",
      "Epoch [7337/20000], Loss: 873.6065673828125, Entropy 431.2621765136719, Learning Rate: 0.00125\n",
      "Epoch [7338/20000], Loss: 895.9388427734375, Entropy 430.8966979980469, Learning Rate: 0.00125\n",
      "Epoch [7339/20000], Loss: 932.30810546875, Entropy 429.7026062011719, Learning Rate: 0.00125\n",
      "Epoch [7340/20000], Loss: 895.1924438476562, Entropy 428.58258056640625, Learning Rate: 0.00125\n",
      "Epoch [7341/20000], Loss: 906.1607666015625, Entropy 426.3336181640625, Learning Rate: 0.00125\n",
      "Epoch [7342/20000], Loss: 874.4494018554688, Entropy 439.58062744140625, Learning Rate: 0.00125\n",
      "Epoch [7343/20000], Loss: 914.76708984375, Entropy 423.4951477050781, Learning Rate: 0.00125\n",
      "Epoch [7344/20000], Loss: 886.3515625, Entropy 424.3188171386719, Learning Rate: 0.00125\n",
      "Epoch [7345/20000], Loss: 923.3652954101562, Entropy 436.21502685546875, Learning Rate: 0.00125\n",
      "Epoch [7346/20000], Loss: 922.1824951171875, Entropy 428.3902893066406, Learning Rate: 0.00125\n",
      "Epoch [7347/20000], Loss: 920.1395263671875, Entropy 417.3272705078125, Learning Rate: 0.00125\n",
      "Epoch [7348/20000], Loss: 913.4147338867188, Entropy 427.74810791015625, Learning Rate: 0.00125\n",
      "Epoch [7349/20000], Loss: 934.1822509765625, Entropy 420.156005859375, Learning Rate: 0.00125\n",
      "Epoch [7350/20000], Loss: 884.6754150390625, Entropy 429.1702880859375, Learning Rate: 0.00125\n",
      "Epoch [7351/20000], Loss: 839.7568359375, Entropy 429.5869445800781, Learning Rate: 0.00125\n",
      "Epoch [7352/20000], Loss: 930.91796875, Entropy 431.5359802246094, Learning Rate: 0.00125\n",
      "Epoch [7353/20000], Loss: 885.294921875, Entropy 440.6793212890625, Learning Rate: 0.00125\n",
      "Epoch [7354/20000], Loss: 890.6112060546875, Entropy 443.1572570800781, Learning Rate: 0.00125\n",
      "Epoch [7355/20000], Loss: 893.7720947265625, Entropy 441.36083984375, Learning Rate: 0.00125\n",
      "Epoch [7356/20000], Loss: 898.3797607421875, Entropy 414.7964782714844, Learning Rate: 0.00125\n",
      "Epoch [7357/20000], Loss: 850.55419921875, Entropy 438.8551330566406, Learning Rate: 0.00125\n",
      "Epoch [7358/20000], Loss: 909.6387939453125, Entropy 428.4490661621094, Learning Rate: 0.00125\n",
      "Epoch [7359/20000], Loss: 866.3421020507812, Entropy 422.27874755859375, Learning Rate: 0.00125\n",
      "Epoch [7360/20000], Loss: 868.172119140625, Entropy 430.3473205566406, Learning Rate: 0.00125\n",
      "Epoch [7361/20000], Loss: 879.2320556640625, Entropy 423.3278503417969, Learning Rate: 0.00125\n",
      "Epoch [7362/20000], Loss: 926.8876953125, Entropy 427.0994567871094, Learning Rate: 0.00125\n",
      "Epoch [7363/20000], Loss: 887.5487060546875, Entropy 418.0802307128906, Learning Rate: 0.00125\n",
      "Epoch [7364/20000], Loss: 857.1028442382812, Entropy 425.53851318359375, Learning Rate: 0.00125\n",
      "Epoch [7365/20000], Loss: 889.6441040039062, Entropy 427.39117431640625, Learning Rate: 0.00125\n",
      "Epoch [7366/20000], Loss: 890.658203125, Entropy 435.9977111816406, Learning Rate: 0.00125\n",
      "Epoch [7367/20000], Loss: 861.6600341796875, Entropy 435.7931213378906, Learning Rate: 0.00125\n",
      "Epoch [7368/20000], Loss: 870.1473388671875, Entropy 417.0588073730469, Learning Rate: 0.00125\n",
      "Epoch [7369/20000], Loss: 894.3148803710938, Entropy 415.03741455078125, Learning Rate: 0.00125\n",
      "Epoch [7370/20000], Loss: 884.97607421875, Entropy 442.3961486816406, Learning Rate: 0.00125\n",
      "Epoch [7371/20000], Loss: 863.8946533203125, Entropy 430.7529602050781, Learning Rate: 0.00125\n",
      "Epoch [7372/20000], Loss: 882.06005859375, Entropy 427.6197814941406, Learning Rate: 0.00125\n",
      "Epoch [7373/20000], Loss: 885.46826171875, Entropy 427.6083068847656, Learning Rate: 0.00125\n",
      "Epoch [7374/20000], Loss: 868.0670166015625, Entropy 418.2624816894531, Learning Rate: 0.00125\n",
      "Epoch [7375/20000], Loss: 861.28515625, Entropy 433.2655334472656, Learning Rate: 0.00125\n",
      "Epoch [7376/20000], Loss: 861.3104858398438, Entropy 440.34100341796875, Learning Rate: 0.00125\n",
      "Epoch [7377/20000], Loss: 888.8935546875, Entropy 433.7451477050781, Learning Rate: 0.00125\n",
      "Epoch [7378/20000], Loss: 880.172607421875, Entropy 425.8808898925781, Learning Rate: 0.00125\n",
      "Epoch [7379/20000], Loss: 880.7820434570312, Entropy 426.11834716796875, Learning Rate: 0.00125\n",
      "Epoch [7380/20000], Loss: 852.405029296875, Entropy 419.6994934082031, Learning Rate: 0.00125\n",
      "Epoch [7381/20000], Loss: 888.0240478515625, Entropy 429.0475769042969, Learning Rate: 0.00125\n",
      "Epoch [7382/20000], Loss: 858.1817626953125, Entropy 432.4881896972656, Learning Rate: 0.00125\n",
      "Epoch [7383/20000], Loss: 936.5887451171875, Entropy 434.2671813964844, Learning Rate: 0.00125\n",
      "Epoch [7384/20000], Loss: 850.7630615234375, Entropy 422.4328308105469, Learning Rate: 0.00125\n",
      "Epoch [7385/20000], Loss: 902.8414306640625, Entropy 431.6976318359375, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7386/20000], Loss: 874.6964111328125, Entropy 440.4471740722656, Learning Rate: 0.00125\n",
      "Epoch [7387/20000], Loss: 887.2362670898438, Entropy 434.25994873046875, Learning Rate: 0.00125\n",
      "Epoch [7388/20000], Loss: 881.3662109375, Entropy 419.10693359375, Learning Rate: 0.00125\n",
      "Epoch [7389/20000], Loss: 912.8818969726562, Entropy 425.15936279296875, Learning Rate: 0.00125\n",
      "Epoch [7390/20000], Loss: 875.8314208984375, Entropy 425.2161560058594, Learning Rate: 0.00125\n",
      "Epoch [7391/20000], Loss: 882.4672241210938, Entropy 434.52398681640625, Learning Rate: 0.00125\n",
      "Epoch [7392/20000], Loss: 857.0838012695312, Entropy 420.05804443359375, Learning Rate: 0.00125\n",
      "Epoch [7393/20000], Loss: 813.392333984375, Entropy 429.7296447753906, Learning Rate: 0.00125\n",
      "Epoch [7394/20000], Loss: 909.4144287109375, Entropy 419.8146057128906, Learning Rate: 0.00125\n",
      "Epoch [7395/20000], Loss: 861.9561157226562, Entropy 428.27874755859375, Learning Rate: 0.00125\n",
      "Epoch [7396/20000], Loss: 882.444091796875, Entropy 413.4824523925781, Learning Rate: 0.00125\n",
      "Epoch [7397/20000], Loss: 878.5750732421875, Entropy 422.43603515625, Learning Rate: 0.00125\n",
      "Epoch [7398/20000], Loss: 831.0592041015625, Entropy 414.8063049316406, Learning Rate: 0.00125\n",
      "Epoch [7399/20000], Loss: 883.665771484375, Entropy 425.4241943359375, Learning Rate: 0.00125\n",
      "Epoch [7400/20000], Loss: 865.283447265625, Entropy 426.66259765625, Learning Rate: 0.00125\n",
      "Epoch [7401/20000], Loss: 917.5090942382812, Entropy 426.44085693359375, Learning Rate: 0.00125\n",
      "Epoch [7402/20000], Loss: 916.2269287109375, Entropy 420.9842224121094, Learning Rate: 0.00125\n",
      "Epoch [7403/20000], Loss: 850.1612548828125, Entropy 440.9354248046875, Learning Rate: 0.00125\n",
      "Epoch [7404/20000], Loss: 867.1570434570312, Entropy 417.90631103515625, Learning Rate: 0.00125\n",
      "Epoch [7405/20000], Loss: 888.7075805664062, Entropy 430.39373779296875, Learning Rate: 0.00125\n",
      "Epoch [7406/20000], Loss: 840.4189453125, Entropy 429.4365234375, Learning Rate: 0.00125\n",
      "Epoch [7407/20000], Loss: 903.7718505859375, Entropy 421.5099792480469, Learning Rate: 0.00125\n",
      "Epoch [7408/20000], Loss: 869.7061767578125, Entropy 434.6590881347656, Learning Rate: 0.00125\n",
      "Epoch [7409/20000], Loss: 882.0648803710938, Entropy 436.28411865234375, Learning Rate: 0.00125\n",
      "Epoch [7410/20000], Loss: 918.0389404296875, Entropy 431.71826171875, Learning Rate: 0.00125\n",
      "Epoch [7411/20000], Loss: 891.1075439453125, Entropy 439.5375671386719, Learning Rate: 0.00125\n",
      "Epoch [7412/20000], Loss: 844.9202880859375, Entropy 424.0914001464844, Learning Rate: 0.00125\n",
      "Epoch [7413/20000], Loss: 865.0162353515625, Entropy 430.2522277832031, Learning Rate: 0.00125\n",
      "Epoch [7414/20000], Loss: 866.7666015625, Entropy 419.9378662109375, Learning Rate: 0.00125\n",
      "Epoch [7415/20000], Loss: 884.7855224609375, Entropy 424.1913146972656, Learning Rate: 0.00125\n",
      "Epoch [7416/20000], Loss: 866.333740234375, Entropy 425.0911865234375, Learning Rate: 0.00125\n",
      "Epoch [7417/20000], Loss: 831.5354614257812, Entropy 432.79595947265625, Learning Rate: 0.00125\n",
      "Epoch [7418/20000], Loss: 844.6705322265625, Entropy 430.9406433105469, Learning Rate: 0.00125\n",
      "Epoch [7419/20000], Loss: 892.8900146484375, Entropy 427.4934387207031, Learning Rate: 0.00125\n",
      "Epoch [7420/20000], Loss: 848.6864013671875, Entropy 438.0954284667969, Learning Rate: 0.00125\n",
      "Epoch [7421/20000], Loss: 861.6741943359375, Entropy 420.0545349121094, Learning Rate: 0.00125\n",
      "Epoch [7422/20000], Loss: 861.509521484375, Entropy 438.6977233886719, Learning Rate: 0.00125\n",
      "Epoch [7423/20000], Loss: 863.9393310546875, Entropy 431.254638671875, Learning Rate: 0.00125\n",
      "Epoch [7424/20000], Loss: 871.33203125, Entropy 427.301513671875, Learning Rate: 0.00125\n",
      "Epoch [7425/20000], Loss: 863.499755859375, Entropy 434.5050048828125, Learning Rate: 0.00125\n",
      "Epoch [7426/20000], Loss: 877.7586059570312, Entropy 428.98187255859375, Learning Rate: 0.00125\n",
      "Epoch [7427/20000], Loss: 881.7142944335938, Entropy 433.53814697265625, Learning Rate: 0.00125\n",
      "Epoch [7428/20000], Loss: 861.253173828125, Entropy 440.0558166503906, Learning Rate: 0.00125\n",
      "Epoch [7429/20000], Loss: 888.1483154296875, Entropy 427.6580810546875, Learning Rate: 0.00125\n",
      "Epoch [7430/20000], Loss: 924.720703125, Entropy 430.0710144042969, Learning Rate: 0.00125\n",
      "Epoch [7431/20000], Loss: 862.0477294921875, Entropy 437.9607849121094, Learning Rate: 0.00125\n",
      "Epoch [7432/20000], Loss: 899.0748291015625, Entropy 422.7973327636719, Learning Rate: 0.00125\n",
      "Epoch [7433/20000], Loss: 865.856201171875, Entropy 419.4337463378906, Learning Rate: 0.00125\n",
      "Epoch [7434/20000], Loss: 902.505859375, Entropy 421.7137145996094, Learning Rate: 0.00125\n",
      "Epoch [7435/20000], Loss: 911.8194580078125, Entropy 428.5115661621094, Learning Rate: 0.00125\n",
      "Epoch [7436/20000], Loss: 890.8497924804688, Entropy 432.26458740234375, Learning Rate: 0.00125\n",
      "Epoch [7437/20000], Loss: 891.8719482421875, Entropy 433.1824951171875, Learning Rate: 0.00125\n",
      "Epoch [7438/20000], Loss: 954.342041015625, Entropy 429.4353942871094, Learning Rate: 0.00125\n",
      "Epoch [7439/20000], Loss: 882.0858154296875, Entropy 425.2016296386719, Learning Rate: 0.00125\n",
      "Epoch [7440/20000], Loss: 872.3870849609375, Entropy 416.9943542480469, Learning Rate: 0.00125\n",
      "Epoch [7441/20000], Loss: 873.2227783203125, Entropy 424.4889831542969, Learning Rate: 0.00125\n",
      "Epoch [7442/20000], Loss: 899.5235595703125, Entropy 424.5747985839844, Learning Rate: 0.00125\n",
      "Epoch [7443/20000], Loss: 927.7582397460938, Entropy 415.09124755859375, Learning Rate: 0.00125\n",
      "Epoch [7444/20000], Loss: 883.4957275390625, Entropy 420.1663818359375, Learning Rate: 0.00125\n",
      "Epoch [7445/20000], Loss: 876.258544921875, Entropy 428.2902526855469, Learning Rate: 0.00125\n",
      "Epoch [7446/20000], Loss: 952.1488037109375, Entropy 424.7255859375, Learning Rate: 0.00125\n",
      "Epoch [7447/20000], Loss: 878.5836181640625, Entropy 424.8532409667969, Learning Rate: 0.00125\n",
      "Epoch [7448/20000], Loss: 884.20166015625, Entropy 413.07080078125, Learning Rate: 0.00125\n",
      "Epoch [7449/20000], Loss: 856.54541015625, Entropy 420.62548828125, Learning Rate: 0.00125\n",
      "Epoch [7450/20000], Loss: 927.4586181640625, Entropy 430.4492492675781, Learning Rate: 0.00125\n",
      "Epoch [7451/20000], Loss: 878.5108642578125, Entropy 416.8556823730469, Learning Rate: 0.00125\n",
      "Epoch [7452/20000], Loss: 898.9857177734375, Entropy 433.2677307128906, Learning Rate: 0.00125\n",
      "Epoch [7453/20000], Loss: 876.611083984375, Entropy 435.0916748046875, Learning Rate: 0.00125\n",
      "Epoch [7454/20000], Loss: 910.4244384765625, Entropy 432.0164794921875, Learning Rate: 0.00125\n",
      "Epoch [7455/20000], Loss: 868.2694091796875, Entropy 438.3896789550781, Learning Rate: 0.00125\n",
      "Epoch [7456/20000], Loss: 916.82666015625, Entropy 438.7721252441406, Learning Rate: 0.00125\n",
      "Epoch [7457/20000], Loss: 879.0322875976562, Entropy 437.51519775390625, Learning Rate: 0.00125\n",
      "Epoch [7458/20000], Loss: 905.9507446289062, Entropy 435.00152587890625, Learning Rate: 0.00125\n",
      "Epoch [7459/20000], Loss: 926.4716186523438, Entropy 435.00836181640625, Learning Rate: 0.00125\n",
      "Epoch [7460/20000], Loss: 883.00732421875, Entropy 428.3587341308594, Learning Rate: 0.00125\n",
      "Epoch [7461/20000], Loss: 847.330078125, Entropy 436.3926086425781, Learning Rate: 0.00125\n",
      "Epoch [7462/20000], Loss: 930.4005737304688, Entropy 423.27069091796875, Learning Rate: 0.00125\n",
      "Epoch [7463/20000], Loss: 883.173095703125, Entropy 430.0404968261719, Learning Rate: 0.00125\n",
      "Epoch [7464/20000], Loss: 853.3604736328125, Entropy 435.8457336425781, Learning Rate: 0.00125\n",
      "Epoch [7465/20000], Loss: 894.9066772460938, Entropy 429.84576416015625, Learning Rate: 0.00125\n",
      "Epoch [7466/20000], Loss: 900.0274658203125, Entropy 424.5129699707031, Learning Rate: 0.00125\n",
      "Epoch [7467/20000], Loss: 874.0748291015625, Entropy 430.3098449707031, Learning Rate: 0.00125\n",
      "Epoch [7468/20000], Loss: 844.921630859375, Entropy 432.7067565917969, Learning Rate: 0.00125\n",
      "Epoch [7469/20000], Loss: 871.09765625, Entropy 418.1492004394531, Learning Rate: 0.00125\n",
      "Epoch [7470/20000], Loss: 848.380126953125, Entropy 433.9827880859375, Learning Rate: 0.00125\n",
      "Epoch [7471/20000], Loss: 887.0357666015625, Entropy 422.2593994140625, Learning Rate: 0.00125\n",
      "Epoch [7472/20000], Loss: 874.5115966796875, Entropy 449.327880859375, Learning Rate: 0.00125\n",
      "Epoch [7473/20000], Loss: 841.1864624023438, Entropy 435.19854736328125, Learning Rate: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7474/20000], Loss: 908.0211791992188, Entropy 428.70062255859375, Learning Rate: 0.00125\n",
      "Epoch [7475/20000], Loss: 859.5230712890625, Entropy 425.3796691894531, Learning Rate: 0.00125\n",
      "Epoch [7476/20000], Loss: 830.8709716796875, Entropy 422.1676330566406, Learning Rate: 0.00125\n",
      "Epoch [7477/20000], Loss: 885.3414306640625, Entropy 422.6541748046875, Learning Rate: 0.00125\n",
      "Epoch [7478/20000], Loss: 855.7872314453125, Entropy 428.1121826171875, Learning Rate: 0.00125\n",
      "Epoch [7479/20000], Loss: 897.601806640625, Entropy 427.0400695800781, Learning Rate: 0.00125\n",
      "Epoch [7480/20000], Loss: 870.7671508789062, Entropy 431.22308349609375, Learning Rate: 0.00125\n",
      "Epoch [7481/20000], Loss: 860.860107421875, Entropy 430.4094543457031, Learning Rate: 0.00125\n",
      "Epoch [7482/20000], Loss: 907.6556396484375, Entropy 424.263671875, Learning Rate: 0.00125\n",
      "Epoch [7483/20000], Loss: 855.013427734375, Entropy 426.3898010253906, Learning Rate: 0.00125\n",
      "Epoch [7484/20000], Loss: 834.1829223632812, Entropy 431.14361572265625, Learning Rate: 0.00125\n",
      "Epoch [7485/20000], Loss: 840.60986328125, Entropy 430.0837097167969, Learning Rate: 0.00125\n",
      "Epoch [7486/20000], Loss: 850.26806640625, Entropy 426.0771789550781, Learning Rate: 0.00125\n",
      "Epoch [7487/20000], Loss: 891.01513671875, Entropy 425.1826477050781, Learning Rate: 0.00125\n",
      "Epoch [7488/20000], Loss: 843.9489135742188, Entropy 449.77850341796875, Learning Rate: 0.00125\n",
      "Epoch [7489/20000], Loss: 852.30078125, Entropy 424.6501159667969, Learning Rate: 0.00125\n",
      "Epoch [7490/20000], Loss: 884.46044921875, Entropy 423.57275390625, Learning Rate: 0.00125\n",
      "Epoch [7491/20000], Loss: 883.5560302734375, Entropy 426.7369689941406, Learning Rate: 0.00125\n",
      "Epoch [7492/20000], Loss: 870.7720336914062, Entropy 426.73577880859375, Learning Rate: 0.00125\n",
      "Epoch [7493/20000], Loss: 925.2308349609375, Entropy 417.1876525878906, Learning Rate: 0.00125\n",
      "Epoch [7494/20000], Loss: 860.320068359375, Entropy 428.0549011230469, Learning Rate: 0.00125\n",
      "Epoch [7495/20000], Loss: 906.3494873046875, Entropy 438.0594482421875, Learning Rate: 0.00125\n",
      "Epoch [7496/20000], Loss: 905.4773559570312, Entropy 436.37921142578125, Learning Rate: 0.00125\n",
      "Epoch [7497/20000], Loss: 907.4964599609375, Entropy 437.1429443359375, Learning Rate: 0.00125\n",
      "Epoch [7498/20000], Loss: 920.8410034179688, Entropy 421.88140869140625, Learning Rate: 0.00125\n",
      "Epoch [7499/20000], Loss: 1012.4190673828125, Entropy 426.1871032714844, Learning Rate: 0.00125\n",
      "Epoch [7500/20000], Loss: 885.641357421875, Entropy 437.0576477050781, Learning Rate: 0.00125\n",
      "Epoch [7501/20000], Loss: 964.5164794921875, Entropy 432.9244384765625, Learning Rate: 0.00125\n",
      "Epoch [7502/20000], Loss: 915.0333251953125, Entropy 427.6213073730469, Learning Rate: 0.00125\n",
      "Epoch [7503/20000], Loss: 938.2921142578125, Entropy 425.3235168457031, Learning Rate: 0.00125\n",
      "Epoch [7504/20000], Loss: 869.1710205078125, Entropy 436.9372863769531, Learning Rate: 0.00125\n",
      "Epoch [7505/20000], Loss: 880.7703857421875, Entropy 443.5225830078125, Learning Rate: 0.00125\n",
      "Epoch [7506/20000], Loss: 910.840087890625, Entropy 435.5149230957031, Learning Rate: 0.00125\n",
      "Epoch [7507/20000], Loss: 927.2764282226562, Entropy 426.90325927734375, Learning Rate: 0.00125\n",
      "Epoch [7508/20000], Loss: 1024.23291015625, Entropy 434.0550537109375, Learning Rate: 0.00125\n",
      "Epoch [7509/20000], Loss: 1024.97607421875, Entropy 437.75299072265625, Learning Rate: 0.00125\n",
      "Epoch [7510/20000], Loss: 941.81298828125, Entropy 434.5865478515625, Learning Rate: 0.00125\n",
      "Epoch [7511/20000], Loss: 939.411376953125, Entropy 407.8670654296875, Learning Rate: 0.00125\n",
      "Epoch [7512/20000], Loss: 922.951416015625, Entropy 437.5754699707031, Learning Rate: 0.00125\n",
      "Epoch [7513/20000], Loss: 946.2559814453125, Entropy 440.7193298339844, Learning Rate: 0.00125\n",
      "Epoch [7514/20000], Loss: 1081.3446044921875, Entropy 413.7960205078125, Learning Rate: 0.00125\n",
      "Epoch [7515/20000], Loss: 924.0855712890625, Entropy 420.3922119140625, Learning Rate: 0.00125\n",
      "Epoch [7516/20000], Loss: 1064.215087890625, Entropy 438.02655029296875, Learning Rate: 0.00125\n",
      "Epoch [7517/20000], Loss: 973.6285400390625, Entropy 419.6783447265625, Learning Rate: 0.00125\n",
      "Epoch [7518/20000], Loss: 1245.517333984375, Entropy 421.9840393066406, Learning Rate: 0.00125\n",
      "Epoch [7519/20000], Loss: 1032.41943359375, Entropy 436.2439880371094, Learning Rate: 0.00125\n",
      "Epoch [7520/20000], Loss: 1089.787109375, Entropy 423.2335205078125, Learning Rate: 0.00125\n",
      "Epoch [7521/20000], Loss: 972.2333984375, Entropy 428.2306213378906, Learning Rate: 0.00125\n",
      "Epoch [7522/20000], Loss: 933.496826171875, Entropy 434.3278503417969, Learning Rate: 0.00125\n",
      "Epoch [7523/20000], Loss: 1096.9326171875, Entropy 437.9482727050781, Learning Rate: 0.00125\n",
      "Epoch [7524/20000], Loss: 1045.4766845703125, Entropy 433.3117980957031, Learning Rate: 0.00125\n",
      "Epoch [7525/20000], Loss: 1025.6300048828125, Entropy 429.6414794921875, Learning Rate: 0.00125\n",
      "Epoch [7526/20000], Loss: 938.6437377929688, Entropy 424.13531494140625, Learning Rate: 0.00125\n",
      "Epoch [7527/20000], Loss: 1021.7833251953125, Entropy 431.8138122558594, Learning Rate: 0.00125\n",
      "Epoch [7528/20000], Loss: 999.1697998046875, Entropy 417.2310485839844, Learning Rate: 0.00125\n",
      "Epoch [7529/20000], Loss: 1063.216064453125, Entropy 421.0433349609375, Learning Rate: 0.00125\n",
      "Epoch [7530/20000], Loss: 932.0880737304688, Entropy 427.41522216796875, Learning Rate: 0.00125\n",
      "Epoch [7531/20000], Loss: 935.8189697265625, Entropy 427.7507629394531, Learning Rate: 0.00125\n",
      "Epoch [7532/20000], Loss: 1117.3336181640625, Entropy 427.4486999511719, Learning Rate: 0.00125\n",
      "Epoch [7533/20000], Loss: 947.79052734375, Entropy 432.7085876464844, Learning Rate: 0.00125\n",
      "Epoch [7534/20000], Loss: 1031.521728515625, Entropy 443.812255859375, Learning Rate: 0.00125\n",
      "Epoch [7535/20000], Loss: 885.79052734375, Entropy 440.335693359375, Learning Rate: 0.00125\n",
      "Epoch [7536/20000], Loss: 1041.6143798828125, Entropy 416.9212341308594, Learning Rate: 0.00125\n",
      "Epoch [7537/20000], Loss: 892.4608154296875, Entropy 421.1937255859375, Learning Rate: 0.00125\n",
      "Epoch [7538/20000], Loss: 1003.4318237304688, Entropy 429.06085205078125, Learning Rate: 0.00125\n",
      "Epoch [7539/20000], Loss: 940.0057373046875, Entropy 410.2091979980469, Learning Rate: 0.00125\n",
      "Epoch [7540/20000], Loss: 1016.2592163085938, Entropy 424.99261474609375, Learning Rate: 0.00125\n",
      "Epoch [7541/20000], Loss: 973.296630859375, Entropy 422.52587890625, Learning Rate: 0.00125\n",
      "Epoch [7542/20000], Loss: 948.3692626953125, Entropy 428.7062683105469, Learning Rate: 0.00125\n",
      "Epoch [7543/20000], Loss: 926.8779907226562, Entropy 416.22161865234375, Learning Rate: 0.00125\n",
      "Epoch [7544/20000], Loss: 889.839111328125, Entropy 430.3868408203125, Learning Rate: 0.00125\n",
      "Epoch [7545/20000], Loss: 1009.9520263671875, Entropy 412.9188537597656, Learning Rate: 0.00125\n",
      "Epoch [7546/20000], Loss: 908.353759765625, Entropy 427.513671875, Learning Rate: 0.00125\n",
      "Epoch [7547/20000], Loss: 955.7156982421875, Entropy 425.6119079589844, Learning Rate: 0.00125\n",
      "Epoch [7548/20000], Loss: 901.5518798828125, Entropy 405.9066467285156, Learning Rate: 0.00125\n",
      "Epoch [7549/20000], Loss: 966.4886474609375, Entropy 416.6251220703125, Learning Rate: 0.00125\n",
      "Epoch [7550/20000], Loss: 930.411865234375, Entropy 425.7732849121094, Learning Rate: 0.00125\n",
      "Epoch [7551/20000], Loss: 911.34765625, Entropy 418.5826721191406, Learning Rate: 0.00125\n",
      "Epoch [7552/20000], Loss: 968.3585815429688, Entropy 405.79742431640625, Learning Rate: 0.00125\n",
      "Epoch [7553/20000], Loss: 929.33837890625, Entropy 416.5706787109375, Learning Rate: 0.00125\n",
      "Epoch [7554/20000], Loss: 950.9745483398438, Entropy 410.51068115234375, Learning Rate: 0.00125\n",
      "Epoch [7555/20000], Loss: 876.6954345703125, Entropy 418.9073486328125, Learning Rate: 0.00125\n",
      "Epoch [7556/20000], Loss: 874.6907958984375, Entropy 425.1536865234375, Learning Rate: 0.00125\n",
      "Epoch [7557/20000], Loss: 913.7952880859375, Entropy 421.0646057128906, Learning Rate: 0.000625\n",
      "Epoch [7558/20000], Loss: 852.269775390625, Entropy 431.3949890136719, Learning Rate: 0.000625\n",
      "Epoch [7559/20000], Loss: 885.7002563476562, Entropy 408.73443603515625, Learning Rate: 0.000625\n",
      "Epoch [7560/20000], Loss: 890.32470703125, Entropy 417.0896911621094, Learning Rate: 0.000625\n",
      "Epoch [7561/20000], Loss: 892.64013671875, Entropy 420.8951721191406, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7562/20000], Loss: 861.0679321289062, Entropy 418.64703369140625, Learning Rate: 0.000625\n",
      "Epoch [7563/20000], Loss: 869.658935546875, Entropy 429.26904296875, Learning Rate: 0.000625\n",
      "Epoch [7564/20000], Loss: 869.7749633789062, Entropy 411.88714599609375, Learning Rate: 0.000625\n",
      "Epoch [7565/20000], Loss: 823.493408203125, Entropy 432.6607666015625, Learning Rate: 0.000625\n",
      "Epoch [7566/20000], Loss: 878.667724609375, Entropy 418.1391296386719, Learning Rate: 0.000625\n",
      "Epoch [7567/20000], Loss: 863.99658203125, Entropy 427.8674011230469, Learning Rate: 0.000625\n",
      "Epoch [7568/20000], Loss: 891.4679565429688, Entropy 410.86468505859375, Learning Rate: 0.000625\n",
      "Epoch [7569/20000], Loss: 934.5885620117188, Entropy 403.35394287109375, Learning Rate: 0.000625\n",
      "Epoch [7570/20000], Loss: 889.9708251953125, Entropy 407.0545959472656, Learning Rate: 0.000625\n",
      "Epoch [7571/20000], Loss: 880.1618041992188, Entropy 421.07867431640625, Learning Rate: 0.000625\n",
      "Epoch [7572/20000], Loss: 908.32373046875, Entropy 415.2580871582031, Learning Rate: 0.000625\n",
      "Epoch [7573/20000], Loss: 842.935546875, Entropy 427.7020263671875, Learning Rate: 0.000625\n",
      "Epoch [7574/20000], Loss: 900.066650390625, Entropy 403.5154113769531, Learning Rate: 0.000625\n",
      "Epoch [7575/20000], Loss: 879.9307250976562, Entropy 412.37982177734375, Learning Rate: 0.000625\n",
      "Epoch [7576/20000], Loss: 869.480224609375, Entropy 425.5085754394531, Learning Rate: 0.000625\n",
      "Epoch [7577/20000], Loss: 895.7068481445312, Entropy 417.99749755859375, Learning Rate: 0.000625\n",
      "Epoch [7578/20000], Loss: 930.4822998046875, Entropy 402.5609436035156, Learning Rate: 0.000625\n",
      "Epoch [7579/20000], Loss: 839.47119140625, Entropy 416.8475036621094, Learning Rate: 0.000625\n",
      "Epoch [7580/20000], Loss: 880.5486450195312, Entropy 418.88958740234375, Learning Rate: 0.000625\n",
      "Epoch [7581/20000], Loss: 933.217041015625, Entropy 422.5672607421875, Learning Rate: 0.000625\n",
      "Epoch [7582/20000], Loss: 880.6210327148438, Entropy 415.92913818359375, Learning Rate: 0.000625\n",
      "Epoch [7583/20000], Loss: 904.0791015625, Entropy 419.4025573730469, Learning Rate: 0.000625\n",
      "Epoch [7584/20000], Loss: 872.4036865234375, Entropy 410.5061340332031, Learning Rate: 0.000625\n",
      "Epoch [7585/20000], Loss: 874.6685791015625, Entropy 424.4574890136719, Learning Rate: 0.000625\n",
      "Epoch [7586/20000], Loss: 836.384765625, Entropy 420.8440856933594, Learning Rate: 0.000625\n",
      "Epoch [7587/20000], Loss: 835.355712890625, Entropy 419.0701599121094, Learning Rate: 0.000625\n",
      "Epoch [7588/20000], Loss: 917.15185546875, Entropy 413.6695251464844, Learning Rate: 0.000625\n",
      "Epoch [7589/20000], Loss: 853.496826171875, Entropy 417.2669372558594, Learning Rate: 0.000625\n",
      "Epoch [7590/20000], Loss: 888.4012451171875, Entropy 417.4616394042969, Learning Rate: 0.000625\n",
      "Epoch [7591/20000], Loss: 862.8021850585938, Entropy 428.41119384765625, Learning Rate: 0.000625\n",
      "Epoch [7592/20000], Loss: 838.700927734375, Entropy 420.2514343261719, Learning Rate: 0.000625\n",
      "Epoch [7593/20000], Loss: 880.8726806640625, Entropy 415.0123291015625, Learning Rate: 0.000625\n",
      "Epoch [7594/20000], Loss: 881.3196411132812, Entropy 429.63311767578125, Learning Rate: 0.000625\n",
      "Epoch [7595/20000], Loss: 853.7686767578125, Entropy 416.3318176269531, Learning Rate: 0.000625\n",
      "Epoch [7596/20000], Loss: 842.646240234375, Entropy 424.2745361328125, Learning Rate: 0.000625\n",
      "Epoch [7597/20000], Loss: 878.6074829101562, Entropy 429.34918212890625, Learning Rate: 0.000625\n",
      "Epoch [7598/20000], Loss: 874.554931640625, Entropy 417.8012390136719, Learning Rate: 0.000625\n",
      "Epoch [7599/20000], Loss: 862.7796630859375, Entropy 417.0441589355469, Learning Rate: 0.000625\n",
      "Epoch [7600/20000], Loss: 892.2574462890625, Entropy 412.88916015625, Learning Rate: 0.000625\n",
      "Epoch [7601/20000], Loss: 854.1755981445312, Entropy 414.61224365234375, Learning Rate: 0.000625\n",
      "Epoch [7602/20000], Loss: 885.3779907226562, Entropy 408.07635498046875, Learning Rate: 0.000625\n",
      "Epoch [7603/20000], Loss: 836.3314208984375, Entropy 425.861083984375, Learning Rate: 0.000625\n",
      "Epoch [7604/20000], Loss: 863.0408935546875, Entropy 429.7638854980469, Learning Rate: 0.000625\n",
      "Epoch [7605/20000], Loss: 854.3250122070312, Entropy 418.79449462890625, Learning Rate: 0.000625\n",
      "Epoch [7606/20000], Loss: 878.625244140625, Entropy 416.503662109375, Learning Rate: 0.000625\n",
      "Epoch [7607/20000], Loss: 837.371826171875, Entropy 417.5838317871094, Learning Rate: 0.000625\n",
      "Epoch [7608/20000], Loss: 888.7208251953125, Entropy 423.2306823730469, Learning Rate: 0.000625\n",
      "Epoch [7609/20000], Loss: 851.3126220703125, Entropy 421.1153869628906, Learning Rate: 0.000625\n",
      "Epoch [7610/20000], Loss: 865.9849853515625, Entropy 433.2223205566406, Learning Rate: 0.000625\n",
      "Epoch [7611/20000], Loss: 880.2198486328125, Entropy 408.6302185058594, Learning Rate: 0.000625\n",
      "Epoch [7612/20000], Loss: 857.2014770507812, Entropy 433.13177490234375, Learning Rate: 0.000625\n",
      "Epoch [7613/20000], Loss: 882.129150390625, Entropy 421.1316223144531, Learning Rate: 0.000625\n",
      "Epoch [7614/20000], Loss: 890.3746948242188, Entropy 419.03460693359375, Learning Rate: 0.000625\n",
      "Epoch [7615/20000], Loss: 885.7647705078125, Entropy 408.0197448730469, Learning Rate: 0.000625\n",
      "Epoch [7616/20000], Loss: 848.2144165039062, Entropy 432.64886474609375, Learning Rate: 0.000625\n",
      "Epoch [7617/20000], Loss: 894.14306640625, Entropy 407.7667541503906, Learning Rate: 0.000625\n",
      "Epoch [7618/20000], Loss: 850.0032958984375, Entropy 425.3814697265625, Learning Rate: 0.000625\n",
      "Epoch [7619/20000], Loss: 909.7420654296875, Entropy 408.1537780761719, Learning Rate: 0.000625\n",
      "Epoch [7620/20000], Loss: 855.094970703125, Entropy 415.0194091796875, Learning Rate: 0.000625\n",
      "Epoch [7621/20000], Loss: 856.2574462890625, Entropy 417.2991943359375, Learning Rate: 0.000625\n",
      "Epoch [7622/20000], Loss: 824.0328369140625, Entropy 428.5549621582031, Learning Rate: 0.000625\n",
      "Epoch [7623/20000], Loss: 884.0035400390625, Entropy 415.32373046875, Learning Rate: 0.000625\n",
      "Epoch [7624/20000], Loss: 840.9541015625, Entropy 431.466796875, Learning Rate: 0.000625\n",
      "Epoch [7625/20000], Loss: 903.335693359375, Entropy 405.9062805175781, Learning Rate: 0.000625\n",
      "Epoch [7626/20000], Loss: 900.0064697265625, Entropy 415.5992736816406, Learning Rate: 0.000625\n",
      "Epoch [7627/20000], Loss: 848.7354736328125, Entropy 424.7603759765625, Learning Rate: 0.000625\n",
      "Epoch [7628/20000], Loss: 877.512451171875, Entropy 420.0735168457031, Learning Rate: 0.000625\n",
      "Epoch [7629/20000], Loss: 859.108154296875, Entropy 423.046875, Learning Rate: 0.000625\n",
      "Epoch [7630/20000], Loss: 872.4071655273438, Entropy 413.53424072265625, Learning Rate: 0.000625\n",
      "Epoch [7631/20000], Loss: 882.328369140625, Entropy 414.2934265136719, Learning Rate: 0.000625\n",
      "Epoch [7632/20000], Loss: 900.6864624023438, Entropy 415.59100341796875, Learning Rate: 0.000625\n",
      "Epoch [7633/20000], Loss: 869.1483764648438, Entropy 412.52935791015625, Learning Rate: 0.000625\n",
      "Epoch [7634/20000], Loss: 883.6024780273438, Entropy 410.27301025390625, Learning Rate: 0.000625\n",
      "Epoch [7635/20000], Loss: 909.62939453125, Entropy 412.5359191894531, Learning Rate: 0.000625\n",
      "Epoch [7636/20000], Loss: 860.0732421875, Entropy 428.640380859375, Learning Rate: 0.000625\n",
      "Epoch [7637/20000], Loss: 881.918212890625, Entropy 414.6701354980469, Learning Rate: 0.000625\n",
      "Epoch [7638/20000], Loss: 844.74755859375, Entropy 424.6025390625, Learning Rate: 0.000625\n",
      "Epoch [7639/20000], Loss: 854.54638671875, Entropy 420.5252685546875, Learning Rate: 0.000625\n",
      "Epoch [7640/20000], Loss: 886.0217895507812, Entropy 430.76995849609375, Learning Rate: 0.000625\n",
      "Epoch [7641/20000], Loss: 904.9807739257812, Entropy 415.04705810546875, Learning Rate: 0.000625\n",
      "Epoch [7642/20000], Loss: 847.7544555664062, Entropy 420.71722412109375, Learning Rate: 0.000625\n",
      "Epoch [7643/20000], Loss: 853.6656494140625, Entropy 419.277099609375, Learning Rate: 0.000625\n",
      "Epoch [7644/20000], Loss: 879.4016723632812, Entropy 413.46099853515625, Learning Rate: 0.000625\n",
      "Epoch [7645/20000], Loss: 865.3363037109375, Entropy 415.8662414550781, Learning Rate: 0.000625\n",
      "Epoch [7646/20000], Loss: 861.7393798828125, Entropy 422.5318603515625, Learning Rate: 0.000625\n",
      "Epoch [7647/20000], Loss: 863.986083984375, Entropy 418.2975769042969, Learning Rate: 0.000625\n",
      "Epoch [7648/20000], Loss: 885.639404296875, Entropy 417.503662109375, Learning Rate: 0.000625\n",
      "Epoch [7649/20000], Loss: 867.7430419921875, Entropy 426.4201354980469, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7650/20000], Loss: 867.72021484375, Entropy 440.7066345214844, Learning Rate: 0.000625\n",
      "Epoch [7651/20000], Loss: 852.414794921875, Entropy 420.1119384765625, Learning Rate: 0.000625\n",
      "Epoch [7652/20000], Loss: 839.7791748046875, Entropy 432.52490234375, Learning Rate: 0.000625\n",
      "Epoch [7653/20000], Loss: 872.3463134765625, Entropy 423.0858154296875, Learning Rate: 0.000625\n",
      "Epoch [7654/20000], Loss: 868.6162109375, Entropy 420.7447814941406, Learning Rate: 0.000625\n",
      "Epoch [7655/20000], Loss: 834.4638671875, Entropy 420.2041320800781, Learning Rate: 0.000625\n",
      "Epoch [7656/20000], Loss: 854.3115234375, Entropy 430.9595947265625, Learning Rate: 0.000625\n",
      "Epoch [7657/20000], Loss: 859.944091796875, Entropy 426.95458984375, Learning Rate: 0.000625\n",
      "Epoch [7658/20000], Loss: 842.7943115234375, Entropy 430.5115661621094, Learning Rate: 0.000625\n",
      "Epoch [7659/20000], Loss: 908.4191284179688, Entropy 415.43658447265625, Learning Rate: 0.000625\n",
      "Epoch [7660/20000], Loss: 890.9600830078125, Entropy 418.5029602050781, Learning Rate: 0.000625\n",
      "Epoch [7661/20000], Loss: 874.0662841796875, Entropy 418.7306823730469, Learning Rate: 0.000625\n",
      "Epoch [7662/20000], Loss: 876.5631103515625, Entropy 423.5152587890625, Learning Rate: 0.000625\n",
      "Epoch [7663/20000], Loss: 866.5521240234375, Entropy 418.1213073730469, Learning Rate: 0.000625\n",
      "Epoch [7664/20000], Loss: 867.6426391601562, Entropy 417.17193603515625, Learning Rate: 0.000625\n",
      "Epoch [7665/20000], Loss: 862.9846801757812, Entropy 436.47601318359375, Learning Rate: 0.000625\n",
      "Epoch [7666/20000], Loss: 877.7404174804688, Entropy 422.96380615234375, Learning Rate: 0.000625\n",
      "Epoch [7667/20000], Loss: 887.1942138671875, Entropy 413.0525817871094, Learning Rate: 0.000625\n",
      "Epoch [7668/20000], Loss: 875.2438354492188, Entropy 411.12261962890625, Learning Rate: 0.000625\n",
      "Epoch [7669/20000], Loss: 884.43603515625, Entropy 426.5142517089844, Learning Rate: 0.000625\n",
      "Epoch [7670/20000], Loss: 931.1566162109375, Entropy 409.5964660644531, Learning Rate: 0.000625\n",
      "Epoch [7671/20000], Loss: 846.64306640625, Entropy 437.1634216308594, Learning Rate: 0.000625\n",
      "Epoch [7672/20000], Loss: 845.071533203125, Entropy 415.3912353515625, Learning Rate: 0.000625\n",
      "Epoch [7673/20000], Loss: 850.6837158203125, Entropy 437.6942443847656, Learning Rate: 0.000625\n",
      "Epoch [7674/20000], Loss: 879.5015869140625, Entropy 424.03271484375, Learning Rate: 0.000625\n",
      "Epoch [7675/20000], Loss: 860.5400390625, Entropy 429.8475646972656, Learning Rate: 0.000625\n",
      "Epoch [7676/20000], Loss: 851.3653564453125, Entropy 419.46240234375, Learning Rate: 0.000625\n",
      "Epoch [7677/20000], Loss: 883.0592041015625, Entropy 417.664794921875, Learning Rate: 0.000625\n",
      "Epoch [7678/20000], Loss: 882.4638671875, Entropy 417.7135925292969, Learning Rate: 0.000625\n",
      "Epoch [7679/20000], Loss: 921.1151123046875, Entropy 420.8420104980469, Learning Rate: 0.000625\n",
      "Epoch [7680/20000], Loss: 908.948486328125, Entropy 404.4573669433594, Learning Rate: 0.000625\n",
      "Epoch [7681/20000], Loss: 843.5806884765625, Entropy 423.84912109375, Learning Rate: 0.000625\n",
      "Epoch [7682/20000], Loss: 887.7049560546875, Entropy 427.2772216796875, Learning Rate: 0.000625\n",
      "Epoch [7683/20000], Loss: 829.6610717773438, Entropy 429.73272705078125, Learning Rate: 0.000625\n",
      "Epoch [7684/20000], Loss: 854.319091796875, Entropy 427.4367370605469, Learning Rate: 0.000625\n",
      "Epoch [7685/20000], Loss: 867.5491943359375, Entropy 431.7428894042969, Learning Rate: 0.000625\n",
      "Epoch [7686/20000], Loss: 866.7535400390625, Entropy 430.8902893066406, Learning Rate: 0.000625\n",
      "Epoch [7687/20000], Loss: 892.757080078125, Entropy 421.6947937011719, Learning Rate: 0.000625\n",
      "Epoch [7688/20000], Loss: 881.1846923828125, Entropy 427.400390625, Learning Rate: 0.000625\n",
      "Epoch [7689/20000], Loss: 887.6141357421875, Entropy 406.6853942871094, Learning Rate: 0.000625\n",
      "Epoch [7690/20000], Loss: 882.7186279296875, Entropy 428.8020324707031, Learning Rate: 0.000625\n",
      "Epoch [7691/20000], Loss: 871.7171630859375, Entropy 427.2249755859375, Learning Rate: 0.000625\n",
      "Epoch [7692/20000], Loss: 847.9121704101562, Entropy 424.82635498046875, Learning Rate: 0.000625\n",
      "Epoch [7693/20000], Loss: 854.5826416015625, Entropy 425.6550598144531, Learning Rate: 0.000625\n",
      "Epoch [7694/20000], Loss: 838.605224609375, Entropy 411.7960205078125, Learning Rate: 0.000625\n",
      "Epoch [7695/20000], Loss: 864.4622802734375, Entropy 417.2815246582031, Learning Rate: 0.000625\n",
      "Epoch [7696/20000], Loss: 889.669677734375, Entropy 428.5760803222656, Learning Rate: 0.000625\n",
      "Epoch [7697/20000], Loss: 814.9810791015625, Entropy 432.537109375, Learning Rate: 0.000625\n",
      "Epoch [7698/20000], Loss: 919.7578125, Entropy 415.0686340332031, Learning Rate: 0.000625\n",
      "Epoch [7699/20000], Loss: 907.3173217773438, Entropy 421.78375244140625, Learning Rate: 0.000625\n",
      "Epoch [7700/20000], Loss: 860.3795166015625, Entropy 424.3365783691406, Learning Rate: 0.000625\n",
      "Epoch [7701/20000], Loss: 861.4573974609375, Entropy 423.7708435058594, Learning Rate: 0.000625\n",
      "Epoch [7702/20000], Loss: 882.0045166015625, Entropy 431.8609924316406, Learning Rate: 0.000625\n",
      "Epoch [7703/20000], Loss: 893.9259033203125, Entropy 427.5252685546875, Learning Rate: 0.000625\n",
      "Epoch [7704/20000], Loss: 868.0123901367188, Entropy 418.52764892578125, Learning Rate: 0.000625\n",
      "Epoch [7705/20000], Loss: 856.6402587890625, Entropy 436.07080078125, Learning Rate: 0.000625\n",
      "Epoch [7706/20000], Loss: 843.0073852539062, Entropy 422.29644775390625, Learning Rate: 0.000625\n",
      "Epoch [7707/20000], Loss: 848.6979370117188, Entropy 423.13763427734375, Learning Rate: 0.000625\n",
      "Epoch [7708/20000], Loss: 865.45849609375, Entropy 418.8670654296875, Learning Rate: 0.000625\n",
      "Epoch [7709/20000], Loss: 842.1013793945312, Entropy 431.32550048828125, Learning Rate: 0.000625\n",
      "Epoch [7710/20000], Loss: 830.4022216796875, Entropy 437.8709411621094, Learning Rate: 0.000625\n",
      "Epoch [7711/20000], Loss: 874.9293212890625, Entropy 431.4050598144531, Learning Rate: 0.000625\n",
      "Epoch [7712/20000], Loss: 882.903564453125, Entropy 423.2933349609375, Learning Rate: 0.000625\n",
      "Epoch [7713/20000], Loss: 880.093017578125, Entropy 422.2319030761719, Learning Rate: 0.000625\n",
      "Epoch [7714/20000], Loss: 837.69384765625, Entropy 432.4488220214844, Learning Rate: 0.000625\n",
      "Epoch [7715/20000], Loss: 892.1641845703125, Entropy 425.2411193847656, Learning Rate: 0.000625\n",
      "Epoch [7716/20000], Loss: 918.2498168945312, Entropy 418.24127197265625, Learning Rate: 0.000625\n",
      "Epoch [7717/20000], Loss: 875.853515625, Entropy 433.0875549316406, Learning Rate: 0.000625\n",
      "Epoch [7718/20000], Loss: 897.9339599609375, Entropy 431.7288818359375, Learning Rate: 0.000625\n",
      "Epoch [7719/20000], Loss: 845.1620483398438, Entropy 430.93377685546875, Learning Rate: 0.000625\n",
      "Epoch [7720/20000], Loss: 923.5076904296875, Entropy 412.1883850097656, Learning Rate: 0.000625\n",
      "Epoch [7721/20000], Loss: 859.3182983398438, Entropy 423.73248291015625, Learning Rate: 0.000625\n",
      "Epoch [7722/20000], Loss: 915.8516845703125, Entropy 437.9827880859375, Learning Rate: 0.000625\n",
      "Epoch [7723/20000], Loss: 862.4353637695312, Entropy 425.59918212890625, Learning Rate: 0.000625\n",
      "Epoch [7724/20000], Loss: 903.6343994140625, Entropy 410.5124816894531, Learning Rate: 0.000625\n",
      "Epoch [7725/20000], Loss: 907.7156372070312, Entropy 434.27740478515625, Learning Rate: 0.000625\n",
      "Epoch [7726/20000], Loss: 898.7034912109375, Entropy 422.4735107421875, Learning Rate: 0.000625\n",
      "Epoch [7727/20000], Loss: 862.30078125, Entropy 426.4418640136719, Learning Rate: 0.000625\n",
      "Epoch [7728/20000], Loss: 872.2498779296875, Entropy 425.4168701171875, Learning Rate: 0.000625\n",
      "Epoch [7729/20000], Loss: 832.458251953125, Entropy 431.39501953125, Learning Rate: 0.000625\n",
      "Epoch [7730/20000], Loss: 821.4466552734375, Entropy 426.224365234375, Learning Rate: 0.000625\n",
      "Epoch [7731/20000], Loss: 857.0496826171875, Entropy 425.3483581542969, Learning Rate: 0.000625\n",
      "Epoch [7732/20000], Loss: 840.973388671875, Entropy 425.8208923339844, Learning Rate: 0.000625\n",
      "Epoch [7733/20000], Loss: 873.4014282226562, Entropy 415.99664306640625, Learning Rate: 0.000625\n",
      "Epoch [7734/20000], Loss: 858.7823486328125, Entropy 413.1497497558594, Learning Rate: 0.000625\n",
      "Epoch [7735/20000], Loss: 867.14111328125, Entropy 422.1461486816406, Learning Rate: 0.000625\n",
      "Epoch [7736/20000], Loss: 873.6510009765625, Entropy 437.8752136230469, Learning Rate: 0.000625\n",
      "Epoch [7737/20000], Loss: 879.60009765625, Entropy 428.5347595214844, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7738/20000], Loss: 850.064453125, Entropy 429.3585510253906, Learning Rate: 0.000625\n",
      "Epoch [7739/20000], Loss: 848.4888916015625, Entropy 441.6724853515625, Learning Rate: 0.000625\n",
      "Epoch [7740/20000], Loss: 843.6260986328125, Entropy 438.3476867675781, Learning Rate: 0.000625\n",
      "Epoch [7741/20000], Loss: 926.662353515625, Entropy 421.9479064941406, Learning Rate: 0.000625\n",
      "Epoch [7742/20000], Loss: 865.800048828125, Entropy 427.32373046875, Learning Rate: 0.000625\n",
      "Epoch [7743/20000], Loss: 871.0377197265625, Entropy 412.8046875, Learning Rate: 0.000625\n",
      "Epoch [7744/20000], Loss: 856.2236328125, Entropy 423.6958923339844, Learning Rate: 0.000625\n",
      "Epoch [7745/20000], Loss: 869.0672607421875, Entropy 425.9297180175781, Learning Rate: 0.000625\n",
      "Epoch [7746/20000], Loss: 819.119873046875, Entropy 433.67724609375, Learning Rate: 0.000625\n",
      "Epoch [7747/20000], Loss: 881.8739013671875, Entropy 428.6170654296875, Learning Rate: 0.000625\n",
      "Epoch [7748/20000], Loss: 860.640380859375, Entropy 437.79052734375, Learning Rate: 0.000625\n",
      "Epoch [7749/20000], Loss: 907.0009765625, Entropy 426.7949523925781, Learning Rate: 0.000625\n",
      "Epoch [7750/20000], Loss: 841.5609741210938, Entropy 425.76397705078125, Learning Rate: 0.000625\n",
      "Epoch [7751/20000], Loss: 887.42724609375, Entropy 420.2830505371094, Learning Rate: 0.000625\n",
      "Epoch [7752/20000], Loss: 837.7969360351562, Entropy 424.62335205078125, Learning Rate: 0.000625\n",
      "Epoch [7753/20000], Loss: 843.3021240234375, Entropy 425.2327880859375, Learning Rate: 0.000625\n",
      "Epoch [7754/20000], Loss: 868.6602783203125, Entropy 433.2056579589844, Learning Rate: 0.000625\n",
      "Epoch [7755/20000], Loss: 898.2289428710938, Entropy 421.20318603515625, Learning Rate: 0.000625\n",
      "Epoch [7756/20000], Loss: 897.80517578125, Entropy 432.6690673828125, Learning Rate: 0.000625\n",
      "Epoch [7757/20000], Loss: 864.482177734375, Entropy 424.2900390625, Learning Rate: 0.000625\n",
      "Epoch [7758/20000], Loss: 865.8759155273438, Entropy 428.53851318359375, Learning Rate: 0.000625\n",
      "Epoch [7759/20000], Loss: 878.1798095703125, Entropy 413.1524963378906, Learning Rate: 0.000625\n",
      "Epoch [7760/20000], Loss: 856.4952392578125, Entropy 432.5173034667969, Learning Rate: 0.000625\n",
      "Epoch [7761/20000], Loss: 863.7547607421875, Entropy 433.5344543457031, Learning Rate: 0.000625\n",
      "Epoch [7762/20000], Loss: 916.034912109375, Entropy 417.4759521484375, Learning Rate: 0.000625\n",
      "Epoch [7763/20000], Loss: 857.6912231445312, Entropy 425.65362548828125, Learning Rate: 0.000625\n",
      "Epoch [7764/20000], Loss: 864.0663452148438, Entropy 452.34234619140625, Learning Rate: 0.000625\n",
      "Epoch [7765/20000], Loss: 859.78857421875, Entropy 430.7794189453125, Learning Rate: 0.000625\n",
      "Epoch [7766/20000], Loss: 811.1610717773438, Entropy 434.24639892578125, Learning Rate: 0.000625\n",
      "Epoch [7767/20000], Loss: 872.9163818359375, Entropy 420.7515869140625, Learning Rate: 0.000625\n",
      "Epoch [7768/20000], Loss: 905.6046142578125, Entropy 417.1313171386719, Learning Rate: 0.000625\n",
      "Epoch [7769/20000], Loss: 858.492919921875, Entropy 417.0355224609375, Learning Rate: 0.000625\n",
      "Epoch [7770/20000], Loss: 893.7769165039062, Entropy 434.81085205078125, Learning Rate: 0.000625\n",
      "Epoch [7771/20000], Loss: 877.6630859375, Entropy 437.5431213378906, Learning Rate: 0.000625\n",
      "Epoch [7772/20000], Loss: 871.6166381835938, Entropy 429.79742431640625, Learning Rate: 0.000625\n",
      "Epoch [7773/20000], Loss: 829.3800048828125, Entropy 424.10888671875, Learning Rate: 0.000625\n",
      "Epoch [7774/20000], Loss: 866.9761962890625, Entropy 424.0108642578125, Learning Rate: 0.000625\n",
      "Epoch [7775/20000], Loss: 892.2887573242188, Entropy 424.68804931640625, Learning Rate: 0.000625\n",
      "Epoch [7776/20000], Loss: 865.637451171875, Entropy 435.517578125, Learning Rate: 0.000625\n",
      "Epoch [7777/20000], Loss: 831.8197631835938, Entropy 439.92706298828125, Learning Rate: 0.000625\n",
      "Epoch [7778/20000], Loss: 920.8535766601562, Entropy 426.01947021484375, Learning Rate: 0.000625\n",
      "Epoch [7779/20000], Loss: 872.8419799804688, Entropy 422.58343505859375, Learning Rate: 0.000625\n",
      "Epoch [7780/20000], Loss: 849.0149536132812, Entropy 426.41143798828125, Learning Rate: 0.000625\n",
      "Epoch [7781/20000], Loss: 885.845703125, Entropy 439.798583984375, Learning Rate: 0.000625\n",
      "Epoch [7782/20000], Loss: 849.4307861328125, Entropy 430.552734375, Learning Rate: 0.000625\n",
      "Epoch [7783/20000], Loss: 851.239501953125, Entropy 417.8992004394531, Learning Rate: 0.000625\n",
      "Epoch [7784/20000], Loss: 861.9481201171875, Entropy 422.2996520996094, Learning Rate: 0.000625\n",
      "Epoch [7785/20000], Loss: 830.4554443359375, Entropy 432.2169494628906, Learning Rate: 0.000625\n",
      "Epoch [7786/20000], Loss: 874.7921142578125, Entropy 428.2646789550781, Learning Rate: 0.000625\n",
      "Epoch [7787/20000], Loss: 848.456787109375, Entropy 431.1236877441406, Learning Rate: 0.000625\n",
      "Epoch [7788/20000], Loss: 900.2984619140625, Entropy 425.4657287597656, Learning Rate: 0.000625\n",
      "Epoch [7789/20000], Loss: 855.5928955078125, Entropy 434.9573669433594, Learning Rate: 0.000625\n",
      "Epoch [7790/20000], Loss: 834.4766845703125, Entropy 428.9237365722656, Learning Rate: 0.000625\n",
      "Epoch [7791/20000], Loss: 840.793701171875, Entropy 419.0455322265625, Learning Rate: 0.000625\n",
      "Epoch [7792/20000], Loss: 863.2346801757812, Entropy 423.83782958984375, Learning Rate: 0.000625\n",
      "Epoch [7793/20000], Loss: 847.209228515625, Entropy 424.7278137207031, Learning Rate: 0.000625\n",
      "Epoch [7794/20000], Loss: 877.29931640625, Entropy 438.916015625, Learning Rate: 0.000625\n",
      "Epoch [7795/20000], Loss: 893.9198608398438, Entropy 422.30889892578125, Learning Rate: 0.000625\n",
      "Epoch [7796/20000], Loss: 886.3602294921875, Entropy 429.5728759765625, Learning Rate: 0.000625\n",
      "Epoch [7797/20000], Loss: 863.0565185546875, Entropy 418.2796325683594, Learning Rate: 0.000625\n",
      "Epoch [7798/20000], Loss: 888.8758544921875, Entropy 421.3468017578125, Learning Rate: 0.000625\n",
      "Epoch [7799/20000], Loss: 818.489501953125, Entropy 434.01513671875, Learning Rate: 0.000625\n",
      "Epoch [7800/20000], Loss: 863.6630859375, Entropy 424.2732849121094, Learning Rate: 0.000625\n",
      "Epoch [7801/20000], Loss: 860.722412109375, Entropy 418.05517578125, Learning Rate: 0.000625\n",
      "Epoch [7802/20000], Loss: 830.9608154296875, Entropy 429.1689758300781, Learning Rate: 0.000625\n",
      "Epoch [7803/20000], Loss: 859.557373046875, Entropy 441.4476318359375, Learning Rate: 0.000625\n",
      "Epoch [7804/20000], Loss: 878.471923828125, Entropy 435.7264709472656, Learning Rate: 0.000625\n",
      "Epoch [7805/20000], Loss: 889.000244140625, Entropy 429.1710205078125, Learning Rate: 0.000625\n",
      "Epoch [7806/20000], Loss: 888.4462890625, Entropy 421.2860107421875, Learning Rate: 0.000625\n",
      "Epoch [7807/20000], Loss: 836.641357421875, Entropy 444.0478515625, Learning Rate: 0.000625\n",
      "Epoch [7808/20000], Loss: 848.0274658203125, Entropy 422.5110168457031, Learning Rate: 0.000625\n",
      "Epoch [7809/20000], Loss: 898.723876953125, Entropy 427.8034362792969, Learning Rate: 0.000625\n",
      "Epoch [7810/20000], Loss: 932.6858520507812, Entropy 432.70220947265625, Learning Rate: 0.000625\n",
      "Epoch [7811/20000], Loss: 877.7713623046875, Entropy 433.20263671875, Learning Rate: 0.000625\n",
      "Epoch [7812/20000], Loss: 828.70263671875, Entropy 431.4329833984375, Learning Rate: 0.000625\n",
      "Epoch [7813/20000], Loss: 862.0390625, Entropy 420.1194763183594, Learning Rate: 0.000625\n",
      "Epoch [7814/20000], Loss: 908.3902587890625, Entropy 427.8948669433594, Learning Rate: 0.000625\n",
      "Epoch [7815/20000], Loss: 827.9177856445312, Entropy 421.23590087890625, Learning Rate: 0.000625\n",
      "Epoch [7816/20000], Loss: 870.736083984375, Entropy 420.6875305175781, Learning Rate: 0.000625\n",
      "Epoch [7817/20000], Loss: 872.289794921875, Entropy 425.8399658203125, Learning Rate: 0.000625\n",
      "Epoch [7818/20000], Loss: 867.1068725585938, Entropy 440.20343017578125, Learning Rate: 0.000625\n",
      "Epoch [7819/20000], Loss: 853.3516845703125, Entropy 432.4786376953125, Learning Rate: 0.000625\n",
      "Epoch [7820/20000], Loss: 833.4290771484375, Entropy 420.6876525878906, Learning Rate: 0.000625\n",
      "Epoch [7821/20000], Loss: 844.811767578125, Entropy 425.49267578125, Learning Rate: 0.000625\n",
      "Epoch [7822/20000], Loss: 908.7117309570312, Entropy 420.86920166015625, Learning Rate: 0.000625\n",
      "Epoch [7823/20000], Loss: 918.410888671875, Entropy 443.9869689941406, Learning Rate: 0.000625\n",
      "Epoch [7824/20000], Loss: 904.033935546875, Entropy 420.8974609375, Learning Rate: 0.000625\n",
      "Epoch [7825/20000], Loss: 880.8800048828125, Entropy 426.0464782714844, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7826/20000], Loss: 858.849365234375, Entropy 423.2390441894531, Learning Rate: 0.000625\n",
      "Epoch [7827/20000], Loss: 853.0481567382812, Entropy 436.64007568359375, Learning Rate: 0.000625\n",
      "Epoch [7828/20000], Loss: 885.405517578125, Entropy 425.514404296875, Learning Rate: 0.000625\n",
      "Epoch [7829/20000], Loss: 817.998291015625, Entropy 437.8556823730469, Learning Rate: 0.000625\n",
      "Epoch [7830/20000], Loss: 882.6741943359375, Entropy 418.6952209472656, Learning Rate: 0.000625\n",
      "Epoch [7831/20000], Loss: 849.1357421875, Entropy 424.0947570800781, Learning Rate: 0.000625\n",
      "Epoch [7832/20000], Loss: 852.97412109375, Entropy 430.0710754394531, Learning Rate: 0.000625\n",
      "Epoch [7833/20000], Loss: 869.913818359375, Entropy 430.5841369628906, Learning Rate: 0.000625\n",
      "Epoch [7834/20000], Loss: 873.8187255859375, Entropy 430.4610900878906, Learning Rate: 0.000625\n",
      "Epoch [7835/20000], Loss: 866.64990234375, Entropy 425.8141784667969, Learning Rate: 0.000625\n",
      "Epoch [7836/20000], Loss: 857.908203125, Entropy 426.0519714355469, Learning Rate: 0.000625\n",
      "Epoch [7837/20000], Loss: 893.5843505859375, Entropy 417.5792236328125, Learning Rate: 0.000625\n",
      "Epoch [7838/20000], Loss: 879.1656494140625, Entropy 437.3284606933594, Learning Rate: 0.000625\n",
      "Epoch [7839/20000], Loss: 879.2828979492188, Entropy 415.76202392578125, Learning Rate: 0.000625\n",
      "Epoch [7840/20000], Loss: 897.359619140625, Entropy 421.7958068847656, Learning Rate: 0.000625\n",
      "Epoch [7841/20000], Loss: 887.9610595703125, Entropy 428.0528564453125, Learning Rate: 0.000625\n",
      "Epoch [7842/20000], Loss: 844.73828125, Entropy 425.640625, Learning Rate: 0.000625\n",
      "Epoch [7843/20000], Loss: 850.7371826171875, Entropy 433.51611328125, Learning Rate: 0.000625\n",
      "Epoch [7844/20000], Loss: 848.367919921875, Entropy 434.9518737792969, Learning Rate: 0.000625\n",
      "Epoch [7845/20000], Loss: 872.277587890625, Entropy 418.2814636230469, Learning Rate: 0.000625\n",
      "Epoch [7846/20000], Loss: 867.206298828125, Entropy 417.5660400390625, Learning Rate: 0.000625\n",
      "Epoch [7847/20000], Loss: 888.4423828125, Entropy 442.9695129394531, Learning Rate: 0.000625\n",
      "Epoch [7848/20000], Loss: 868.27099609375, Entropy 439.1530456542969, Learning Rate: 0.000625\n",
      "Epoch [7849/20000], Loss: 876.661865234375, Entropy 425.9427185058594, Learning Rate: 0.000625\n",
      "Epoch [7850/20000], Loss: 892.001708984375, Entropy 419.138671875, Learning Rate: 0.000625\n",
      "Epoch [7851/20000], Loss: 881.3082885742188, Entropy 427.19256591796875, Learning Rate: 0.000625\n",
      "Epoch [7852/20000], Loss: 919.5386352539062, Entropy 425.15948486328125, Learning Rate: 0.000625\n",
      "Epoch [7853/20000], Loss: 831.187255859375, Entropy 437.1623229980469, Learning Rate: 0.000625\n",
      "Epoch [7854/20000], Loss: 880.298828125, Entropy 433.1866760253906, Learning Rate: 0.000625\n",
      "Epoch [7855/20000], Loss: 878.4232177734375, Entropy 419.5687255859375, Learning Rate: 0.000625\n",
      "Epoch [7856/20000], Loss: 853.538330078125, Entropy 435.3731994628906, Learning Rate: 0.000625\n",
      "Epoch [7857/20000], Loss: 875.0440673828125, Entropy 438.8359680175781, Learning Rate: 0.000625\n",
      "Epoch [7858/20000], Loss: 903.6192626953125, Entropy 422.7469482421875, Learning Rate: 0.000625\n",
      "Epoch [7859/20000], Loss: 887.3001098632812, Entropy 429.49896240234375, Learning Rate: 0.000625\n",
      "Epoch [7860/20000], Loss: 851.7489013671875, Entropy 419.7164306640625, Learning Rate: 0.000625\n",
      "Epoch [7861/20000], Loss: 862.4771118164062, Entropy 413.75811767578125, Learning Rate: 0.000625\n",
      "Epoch [7862/20000], Loss: 864.19677734375, Entropy 421.1584167480469, Learning Rate: 0.000625\n",
      "Epoch [7863/20000], Loss: 873.3563842773438, Entropy 424.71295166015625, Learning Rate: 0.000625\n",
      "Epoch [7864/20000], Loss: 866.8099365234375, Entropy 426.7894287109375, Learning Rate: 0.000625\n",
      "Epoch [7865/20000], Loss: 880.4014892578125, Entropy 440.0789489746094, Learning Rate: 0.000625\n",
      "Epoch [7866/20000], Loss: 845.20556640625, Entropy 428.140625, Learning Rate: 0.000625\n",
      "Epoch [7867/20000], Loss: 869.37841796875, Entropy 435.1759948730469, Learning Rate: 0.000625\n",
      "Epoch [7868/20000], Loss: 884.1354370117188, Entropy 454.28143310546875, Learning Rate: 0.000625\n",
      "Epoch [7869/20000], Loss: 851.8970336914062, Entropy 436.95257568359375, Learning Rate: 0.000625\n",
      "Epoch [7870/20000], Loss: 874.4652709960938, Entropy 434.37005615234375, Learning Rate: 0.000625\n",
      "Epoch [7871/20000], Loss: 868.2283935546875, Entropy 434.4201354980469, Learning Rate: 0.000625\n",
      "Epoch [7872/20000], Loss: 872.1302490234375, Entropy 440.87451171875, Learning Rate: 0.000625\n",
      "Epoch [7873/20000], Loss: 898.9594116210938, Entropy 414.78839111328125, Learning Rate: 0.000625\n",
      "Epoch [7874/20000], Loss: 857.6995849609375, Entropy 426.2936706542969, Learning Rate: 0.000625\n",
      "Epoch [7875/20000], Loss: 831.4112548828125, Entropy 446.3758239746094, Learning Rate: 0.000625\n",
      "Epoch [7876/20000], Loss: 879.1229248046875, Entropy 430.8653564453125, Learning Rate: 0.000625\n",
      "Epoch [7877/20000], Loss: 853.9693603515625, Entropy 440.271240234375, Learning Rate: 0.000625\n",
      "Epoch [7878/20000], Loss: 884.5592041015625, Entropy 422.5038146972656, Learning Rate: 0.000625\n",
      "Epoch [7879/20000], Loss: 874.1946411132812, Entropy 428.01788330078125, Learning Rate: 0.000625\n",
      "Epoch [7880/20000], Loss: 887.0914916992188, Entropy 439.33843994140625, Learning Rate: 0.000625\n",
      "Epoch [7881/20000], Loss: 846.6922607421875, Entropy 425.849609375, Learning Rate: 0.000625\n",
      "Epoch [7882/20000], Loss: 836.8944091796875, Entropy 423.933349609375, Learning Rate: 0.000625\n",
      "Epoch [7883/20000], Loss: 864.697998046875, Entropy 445.986083984375, Learning Rate: 0.000625\n",
      "Epoch [7884/20000], Loss: 816.46142578125, Entropy 429.8291015625, Learning Rate: 0.000625\n",
      "Epoch [7885/20000], Loss: 909.8409423828125, Entropy 430.6755065917969, Learning Rate: 0.000625\n",
      "Epoch [7886/20000], Loss: 834.0687866210938, Entropy 425.91204833984375, Learning Rate: 0.000625\n",
      "Epoch [7887/20000], Loss: 872.5360107421875, Entropy 432.4334716796875, Learning Rate: 0.000625\n",
      "Epoch [7888/20000], Loss: 875.9827270507812, Entropy 420.54937744140625, Learning Rate: 0.000625\n",
      "Epoch [7889/20000], Loss: 881.9910888671875, Entropy 415.0982971191406, Learning Rate: 0.000625\n",
      "Epoch [7890/20000], Loss: 817.613525390625, Entropy 431.5511474609375, Learning Rate: 0.000625\n",
      "Epoch [7891/20000], Loss: 858.368896484375, Entropy 428.0783996582031, Learning Rate: 0.000625\n",
      "Epoch [7892/20000], Loss: 874.7448120117188, Entropy 423.40472412109375, Learning Rate: 0.000625\n",
      "Epoch [7893/20000], Loss: 833.4480590820312, Entropy 421.47357177734375, Learning Rate: 0.000625\n",
      "Epoch [7894/20000], Loss: 870.3079833984375, Entropy 431.9469909667969, Learning Rate: 0.000625\n",
      "Epoch [7895/20000], Loss: 870.9174194335938, Entropy 431.46429443359375, Learning Rate: 0.000625\n",
      "Epoch [7896/20000], Loss: 940.504638671875, Entropy 411.6197509765625, Learning Rate: 0.000625\n",
      "Epoch [7897/20000], Loss: 914.745849609375, Entropy 426.5771484375, Learning Rate: 0.000625\n",
      "Epoch [7898/20000], Loss: 862.964111328125, Entropy 432.9059143066406, Learning Rate: 0.000625\n",
      "Epoch [7899/20000], Loss: 865.567138671875, Entropy 436.0404968261719, Learning Rate: 0.000625\n",
      "Epoch [7900/20000], Loss: 882.4048461914062, Entropy 430.25042724609375, Learning Rate: 0.000625\n",
      "Epoch [7901/20000], Loss: 810.4276123046875, Entropy 456.8114318847656, Learning Rate: 0.000625\n",
      "Epoch [7902/20000], Loss: 905.7520751953125, Entropy 442.70849609375, Learning Rate: 0.000625\n",
      "Epoch [7903/20000], Loss: 869.7540893554688, Entropy 428.71343994140625, Learning Rate: 0.000625\n",
      "Epoch [7904/20000], Loss: 890.2303466796875, Entropy 433.1199951171875, Learning Rate: 0.000625\n",
      "Epoch [7905/20000], Loss: 871.6494140625, Entropy 424.6014709472656, Learning Rate: 0.000625\n",
      "Epoch [7906/20000], Loss: 933.4329833984375, Entropy 418.1753845214844, Learning Rate: 0.000625\n",
      "Epoch [7907/20000], Loss: 870.0032958984375, Entropy 428.20654296875, Learning Rate: 0.000625\n",
      "Epoch [7908/20000], Loss: 887.7316284179688, Entropy 427.23089599609375, Learning Rate: 0.000625\n",
      "Epoch [7909/20000], Loss: 861.9111328125, Entropy 432.036865234375, Learning Rate: 0.000625\n",
      "Epoch [7910/20000], Loss: 857.318359375, Entropy 430.6778869628906, Learning Rate: 0.000625\n",
      "Epoch [7911/20000], Loss: 870.568359375, Entropy 432.9685974121094, Learning Rate: 0.000625\n",
      "Epoch [7912/20000], Loss: 857.9053955078125, Entropy 421.2130432128906, Learning Rate: 0.000625\n",
      "Epoch [7913/20000], Loss: 853.5110473632812, Entropy 435.53814697265625, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7914/20000], Loss: 874.5556640625, Entropy 435.913818359375, Learning Rate: 0.000625\n",
      "Epoch [7915/20000], Loss: 868.2257080078125, Entropy 421.7465515136719, Learning Rate: 0.000625\n",
      "Epoch [7916/20000], Loss: 925.5755004882812, Entropy 433.87823486328125, Learning Rate: 0.000625\n",
      "Epoch [7917/20000], Loss: 879.9456787109375, Entropy 426.3332214355469, Learning Rate: 0.000625\n",
      "Epoch [7918/20000], Loss: 900.5634765625, Entropy 414.933349609375, Learning Rate: 0.000625\n",
      "Epoch [7919/20000], Loss: 883.8709106445312, Entropy 430.78057861328125, Learning Rate: 0.000625\n",
      "Epoch [7920/20000], Loss: 865.997802734375, Entropy 424.5760192871094, Learning Rate: 0.000625\n",
      "Epoch [7921/20000], Loss: 842.640869140625, Entropy 434.7239685058594, Learning Rate: 0.000625\n",
      "Epoch [7922/20000], Loss: 838.5846557617188, Entropy 435.26593017578125, Learning Rate: 0.000625\n",
      "Epoch [7923/20000], Loss: 842.2662353515625, Entropy 445.4962463378906, Learning Rate: 0.000625\n",
      "Epoch [7924/20000], Loss: 893.3550415039062, Entropy 422.32342529296875, Learning Rate: 0.000625\n",
      "Epoch [7925/20000], Loss: 882.457763671875, Entropy 434.41845703125, Learning Rate: 0.000625\n",
      "Epoch [7926/20000], Loss: 842.0699462890625, Entropy 435.1800537109375, Learning Rate: 0.000625\n",
      "Epoch [7927/20000], Loss: 875.7242431640625, Entropy 434.2165222167969, Learning Rate: 0.000625\n",
      "Epoch [7928/20000], Loss: 891.7244262695312, Entropy 424.36334228515625, Learning Rate: 0.000625\n",
      "Epoch [7929/20000], Loss: 840.55810546875, Entropy 447.0880126953125, Learning Rate: 0.000625\n",
      "Epoch [7930/20000], Loss: 842.0242919921875, Entropy 431.6380310058594, Learning Rate: 0.000625\n",
      "Epoch [7931/20000], Loss: 868.27880859375, Entropy 429.1569519042969, Learning Rate: 0.000625\n",
      "Epoch [7932/20000], Loss: 891.9064331054688, Entropy 435.51885986328125, Learning Rate: 0.000625\n",
      "Epoch [7933/20000], Loss: 902.802001953125, Entropy 423.6121826171875, Learning Rate: 0.000625\n",
      "Epoch [7934/20000], Loss: 920.6829833984375, Entropy 428.4023742675781, Learning Rate: 0.000625\n",
      "Epoch [7935/20000], Loss: 861.833984375, Entropy 429.4735107421875, Learning Rate: 0.000625\n",
      "Epoch [7936/20000], Loss: 893.2694702148438, Entropy 428.74114990234375, Learning Rate: 0.000625\n",
      "Epoch [7937/20000], Loss: 875.0333251953125, Entropy 433.2852783203125, Learning Rate: 0.000625\n",
      "Epoch [7938/20000], Loss: 848.32568359375, Entropy 444.4105224609375, Learning Rate: 0.000625\n",
      "Epoch [7939/20000], Loss: 836.8715209960938, Entropy 431.71710205078125, Learning Rate: 0.000625\n",
      "Epoch [7940/20000], Loss: 832.237548828125, Entropy 422.73193359375, Learning Rate: 0.000625\n",
      "Epoch [7941/20000], Loss: 890.4364013671875, Entropy 413.4577331542969, Learning Rate: 0.000625\n",
      "Epoch [7942/20000], Loss: 838.793212890625, Entropy 454.1080322265625, Learning Rate: 0.000625\n",
      "Epoch [7943/20000], Loss: 855.9588623046875, Entropy 427.7286376953125, Learning Rate: 0.000625\n",
      "Epoch [7944/20000], Loss: 900.1471557617188, Entropy 424.11468505859375, Learning Rate: 0.000625\n",
      "Epoch [7945/20000], Loss: 864.7686767578125, Entropy 436.3713073730469, Learning Rate: 0.000625\n",
      "Epoch [7946/20000], Loss: 815.100830078125, Entropy 438.5589294433594, Learning Rate: 0.000625\n",
      "Epoch [7947/20000], Loss: 892.493408203125, Entropy 431.6546630859375, Learning Rate: 0.000625\n",
      "Epoch [7948/20000], Loss: 845.2022705078125, Entropy 430.6689758300781, Learning Rate: 0.000625\n",
      "Epoch [7949/20000], Loss: 886.20654296875, Entropy 413.5090637207031, Learning Rate: 0.000625\n",
      "Epoch [7950/20000], Loss: 871.8384399414062, Entropy 429.36834716796875, Learning Rate: 0.000625\n",
      "Epoch [7951/20000], Loss: 896.6670532226562, Entropy 429.01678466796875, Learning Rate: 0.000625\n",
      "Epoch [7952/20000], Loss: 839.723388671875, Entropy 452.2513427734375, Learning Rate: 0.000625\n",
      "Epoch [7953/20000], Loss: 858.7936401367188, Entropy 434.96710205078125, Learning Rate: 0.000625\n",
      "Epoch [7954/20000], Loss: 823.741943359375, Entropy 434.7628479003906, Learning Rate: 0.000625\n",
      "Epoch [7955/20000], Loss: 874.7398681640625, Entropy 433.4082336425781, Learning Rate: 0.000625\n",
      "Epoch [7956/20000], Loss: 875.4833984375, Entropy 428.7160949707031, Learning Rate: 0.000625\n",
      "Epoch [7957/20000], Loss: 878.7054443359375, Entropy 440.4749450683594, Learning Rate: 0.000625\n",
      "Epoch [7958/20000], Loss: 921.489990234375, Entropy 433.2658386230469, Learning Rate: 0.000625\n",
      "Epoch [7959/20000], Loss: 885.0584716796875, Entropy 425.460693359375, Learning Rate: 0.000625\n",
      "Epoch [7960/20000], Loss: 844.7056884765625, Entropy 429.3470153808594, Learning Rate: 0.000625\n",
      "Epoch [7961/20000], Loss: 839.2266845703125, Entropy 444.5897216796875, Learning Rate: 0.000625\n",
      "Epoch [7962/20000], Loss: 865.06201171875, Entropy 440.4721374511719, Learning Rate: 0.000625\n",
      "Epoch [7963/20000], Loss: 853.179443359375, Entropy 447.4960021972656, Learning Rate: 0.000625\n",
      "Epoch [7964/20000], Loss: 917.7412719726562, Entropy 425.26373291015625, Learning Rate: 0.000625\n",
      "Epoch [7965/20000], Loss: 900.0929565429688, Entropy 421.81097412109375, Learning Rate: 0.000625\n",
      "Epoch [7966/20000], Loss: 854.4583740234375, Entropy 427.2740173339844, Learning Rate: 0.000625\n",
      "Epoch [7967/20000], Loss: 930.5947265625, Entropy 424.9013977050781, Learning Rate: 0.000625\n",
      "Epoch [7968/20000], Loss: 896.2684326171875, Entropy 435.6435852050781, Learning Rate: 0.000625\n",
      "Epoch [7969/20000], Loss: 830.5111083984375, Entropy 432.3855895996094, Learning Rate: 0.000625\n",
      "Epoch [7970/20000], Loss: 860.009765625, Entropy 433.2048645019531, Learning Rate: 0.000625\n",
      "Epoch [7971/20000], Loss: 835.214111328125, Entropy 449.31005859375, Learning Rate: 0.000625\n",
      "Epoch [7972/20000], Loss: 883.6517333984375, Entropy 430.3239440917969, Learning Rate: 0.000625\n",
      "Epoch [7973/20000], Loss: 848.8314208984375, Entropy 427.170654296875, Learning Rate: 0.000625\n",
      "Epoch [7974/20000], Loss: 891.1468505859375, Entropy 436.7535705566406, Learning Rate: 0.000625\n",
      "Epoch [7975/20000], Loss: 873.10546875, Entropy 434.6285705566406, Learning Rate: 0.000625\n",
      "Epoch [7976/20000], Loss: 851.2210083007812, Entropy 438.25054931640625, Learning Rate: 0.000625\n",
      "Epoch [7977/20000], Loss: 858.6585693359375, Entropy 433.1654968261719, Learning Rate: 0.000625\n",
      "Epoch [7978/20000], Loss: 864.4786376953125, Entropy 445.6275329589844, Learning Rate: 0.000625\n",
      "Epoch [7979/20000], Loss: 846.0291748046875, Entropy 436.0483093261719, Learning Rate: 0.000625\n",
      "Epoch [7980/20000], Loss: 893.667236328125, Entropy 429.5760803222656, Learning Rate: 0.000625\n",
      "Epoch [7981/20000], Loss: 876.118896484375, Entropy 444.9068603515625, Learning Rate: 0.000625\n",
      "Epoch [7982/20000], Loss: 905.4583740234375, Entropy 429.0267028808594, Learning Rate: 0.000625\n",
      "Epoch [7983/20000], Loss: 862.3153076171875, Entropy 438.3414611816406, Learning Rate: 0.000625\n",
      "Epoch [7984/20000], Loss: 861.4287109375, Entropy 440.4200439453125, Learning Rate: 0.000625\n",
      "Epoch [7985/20000], Loss: 887.9151611328125, Entropy 420.9705810546875, Learning Rate: 0.000625\n",
      "Epoch [7986/20000], Loss: 846.337646484375, Entropy 446.6776428222656, Learning Rate: 0.000625\n",
      "Epoch [7987/20000], Loss: 868.2647705078125, Entropy 437.3626403808594, Learning Rate: 0.000625\n",
      "Epoch [7988/20000], Loss: 912.932373046875, Entropy 439.1731872558594, Learning Rate: 0.000625\n",
      "Epoch [7989/20000], Loss: 886.460205078125, Entropy 440.3553771972656, Learning Rate: 0.000625\n",
      "Epoch [7990/20000], Loss: 847.6546630859375, Entropy 435.5877380371094, Learning Rate: 0.000625\n",
      "Epoch [7991/20000], Loss: 854.069580078125, Entropy 442.54052734375, Learning Rate: 0.000625\n",
      "Epoch [7992/20000], Loss: 861.9745483398438, Entropy 430.14154052734375, Learning Rate: 0.000625\n",
      "Epoch [7993/20000], Loss: 916.6119384765625, Entropy 435.4010314941406, Learning Rate: 0.000625\n",
      "Epoch [7994/20000], Loss: 873.4791259765625, Entropy 423.378662109375, Learning Rate: 0.000625\n",
      "Epoch [7995/20000], Loss: 859.3560791015625, Entropy 438.7245178222656, Learning Rate: 0.000625\n",
      "Epoch [7996/20000], Loss: 885.04638671875, Entropy 426.1708984375, Learning Rate: 0.000625\n",
      "Epoch [7997/20000], Loss: 884.51904296875, Entropy 435.7105407714844, Learning Rate: 0.000625\n",
      "Epoch [7998/20000], Loss: 870.3258666992188, Entropy 436.58123779296875, Learning Rate: 0.000625\n",
      "Epoch [7999/20000], Loss: 892.20458984375, Entropy 432.6588134765625, Learning Rate: 0.000625\n",
      "Epoch [8000/20000], Loss: 918.7275390625, Entropy 434.3327331542969, Learning Rate: 0.000625\n",
      "Epoch [8001/20000], Loss: 847.4345703125, Entropy 430.1950378417969, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8002/20000], Loss: 905.9325561523438, Entropy 437.39251708984375, Learning Rate: 0.000625\n",
      "Epoch [8003/20000], Loss: 882.0372314453125, Entropy 442.6636657714844, Learning Rate: 0.000625\n",
      "Epoch [8004/20000], Loss: 861.37841796875, Entropy 431.9245910644531, Learning Rate: 0.000625\n",
      "Epoch [8005/20000], Loss: 890.1292114257812, Entropy 423.38922119140625, Learning Rate: 0.000625\n",
      "Epoch [8006/20000], Loss: 846.5907592773438, Entropy 439.75311279296875, Learning Rate: 0.000625\n",
      "Epoch [8007/20000], Loss: 893.7540893554688, Entropy 424.33245849609375, Learning Rate: 0.000625\n",
      "Epoch [8008/20000], Loss: 907.6654052734375, Entropy 436.6164245605469, Learning Rate: 0.000625\n",
      "Epoch [8009/20000], Loss: 860.824462890625, Entropy 440.77392578125, Learning Rate: 0.000625\n",
      "Epoch [8010/20000], Loss: 863.1904296875, Entropy 445.7236328125, Learning Rate: 0.000625\n",
      "Epoch [8011/20000], Loss: 884.4676513671875, Entropy 423.3685302734375, Learning Rate: 0.000625\n",
      "Epoch [8012/20000], Loss: 870.318115234375, Entropy 429.6831970214844, Learning Rate: 0.000625\n",
      "Epoch [8013/20000], Loss: 875.3907470703125, Entropy 437.1222839355469, Learning Rate: 0.000625\n",
      "Epoch [8014/20000], Loss: 834.8489379882812, Entropy 436.02838134765625, Learning Rate: 0.000625\n",
      "Epoch [8015/20000], Loss: 875.3054809570312, Entropy 431.17974853515625, Learning Rate: 0.000625\n",
      "Epoch [8016/20000], Loss: 870.2474365234375, Entropy 430.3221740722656, Learning Rate: 0.000625\n",
      "Epoch [8017/20000], Loss: 880.3242797851562, Entropy 421.94586181640625, Learning Rate: 0.000625\n",
      "Epoch [8018/20000], Loss: 854.6798095703125, Entropy 435.5396728515625, Learning Rate: 0.000625\n",
      "Epoch [8019/20000], Loss: 887.6436767578125, Entropy 432.7062683105469, Learning Rate: 0.000625\n",
      "Epoch [8020/20000], Loss: 823.7734375, Entropy 437.0555114746094, Learning Rate: 0.000625\n",
      "Epoch [8021/20000], Loss: 862.90234375, Entropy 419.3550720214844, Learning Rate: 0.000625\n",
      "Epoch [8022/20000], Loss: 848.2741088867188, Entropy 442.87115478515625, Learning Rate: 0.000625\n",
      "Epoch [8023/20000], Loss: 836.0286865234375, Entropy 426.5317077636719, Learning Rate: 0.000625\n",
      "Epoch [8024/20000], Loss: 872.21728515625, Entropy 445.620849609375, Learning Rate: 0.000625\n",
      "Epoch [8025/20000], Loss: 842.7130126953125, Entropy 431.2301330566406, Learning Rate: 0.000625\n",
      "Epoch [8026/20000], Loss: 847.8082885742188, Entropy 425.68109130859375, Learning Rate: 0.000625\n",
      "Epoch [8027/20000], Loss: 835.83935546875, Entropy 448.8096008300781, Learning Rate: 0.000625\n",
      "Epoch [8028/20000], Loss: 869.1561279296875, Entropy 435.8061218261719, Learning Rate: 0.000625\n",
      "Epoch [8029/20000], Loss: 824.0675659179688, Entropy 431.04254150390625, Learning Rate: 0.000625\n",
      "Epoch [8030/20000], Loss: 875.8670654296875, Entropy 436.5505676269531, Learning Rate: 0.000625\n",
      "Epoch [8031/20000], Loss: 827.6370849609375, Entropy 430.6242980957031, Learning Rate: 0.000625\n",
      "Epoch [8032/20000], Loss: 846.031005859375, Entropy 444.8763122558594, Learning Rate: 0.000625\n",
      "Epoch [8033/20000], Loss: 829.9786376953125, Entropy 438.0936584472656, Learning Rate: 0.000625\n",
      "Epoch [8034/20000], Loss: 898.9276733398438, Entropy 427.97662353515625, Learning Rate: 0.000625\n",
      "Epoch [8035/20000], Loss: 834.3856201171875, Entropy 443.2307434082031, Learning Rate: 0.000625\n",
      "Epoch [8036/20000], Loss: 826.5911254882812, Entropy 424.32171630859375, Learning Rate: 0.000625\n",
      "Epoch [8037/20000], Loss: 843.9334716796875, Entropy 438.4813537597656, Learning Rate: 0.000625\n",
      "Epoch [8038/20000], Loss: 899.458740234375, Entropy 441.2234191894531, Learning Rate: 0.000625\n",
      "Epoch [8039/20000], Loss: 899.8578491210938, Entropy 425.54400634765625, Learning Rate: 0.000625\n",
      "Epoch [8040/20000], Loss: 885.9000244140625, Entropy 439.443115234375, Learning Rate: 0.000625\n",
      "Epoch [8041/20000], Loss: 836.9306030273438, Entropy 435.87701416015625, Learning Rate: 0.000625\n",
      "Epoch [8042/20000], Loss: 853.7417602539062, Entropy 436.26715087890625, Learning Rate: 0.000625\n",
      "Epoch [8043/20000], Loss: 859.5125732421875, Entropy 445.7127990722656, Learning Rate: 0.000625\n",
      "Epoch [8044/20000], Loss: 892.1810913085938, Entropy 440.66326904296875, Learning Rate: 0.000625\n",
      "Epoch [8045/20000], Loss: 877.9893798828125, Entropy 432.0654296875, Learning Rate: 0.000625\n",
      "Epoch [8046/20000], Loss: 834.3690185546875, Entropy 440.4830627441406, Learning Rate: 0.000625\n",
      "Epoch [8047/20000], Loss: 895.52001953125, Entropy 418.0374755859375, Learning Rate: 0.000625\n",
      "Epoch [8048/20000], Loss: 875.1871337890625, Entropy 425.24365234375, Learning Rate: 0.000625\n",
      "Epoch [8049/20000], Loss: 877.8529052734375, Entropy 438.6321105957031, Learning Rate: 0.000625\n",
      "Epoch [8050/20000], Loss: 847.1475830078125, Entropy 432.3521728515625, Learning Rate: 0.000625\n",
      "Epoch [8051/20000], Loss: 898.7261962890625, Entropy 438.5055847167969, Learning Rate: 0.000625\n",
      "Epoch [8052/20000], Loss: 864.189208984375, Entropy 430.490234375, Learning Rate: 0.000625\n",
      "Epoch [8053/20000], Loss: 861.6656494140625, Entropy 441.9125671386719, Learning Rate: 0.000625\n",
      "Epoch [8054/20000], Loss: 856.5902099609375, Entropy 449.8542785644531, Learning Rate: 0.000625\n",
      "Epoch [8055/20000], Loss: 875.7454833984375, Entropy 433.4045104980469, Learning Rate: 0.000625\n",
      "Epoch [8056/20000], Loss: 868.7650146484375, Entropy 435.5896301269531, Learning Rate: 0.000625\n",
      "Epoch [8057/20000], Loss: 931.359375, Entropy 431.1540832519531, Learning Rate: 0.000625\n",
      "Epoch [8058/20000], Loss: 859.3226928710938, Entropy 441.15350341796875, Learning Rate: 0.000625\n",
      "Epoch [8059/20000], Loss: 835.1422119140625, Entropy 440.5921630859375, Learning Rate: 0.000625\n",
      "Epoch [8060/20000], Loss: 825.5419921875, Entropy 436.4154052734375, Learning Rate: 0.000625\n",
      "Epoch [8061/20000], Loss: 856.7920532226562, Entropy 437.79193115234375, Learning Rate: 0.000625\n",
      "Epoch [8062/20000], Loss: 916.002685546875, Entropy 421.7713623046875, Learning Rate: 0.000625\n",
      "Epoch [8063/20000], Loss: 857.3499755859375, Entropy 433.5006103515625, Learning Rate: 0.000625\n",
      "Epoch [8064/20000], Loss: 902.4133911132812, Entropy 440.01202392578125, Learning Rate: 0.000625\n",
      "Epoch [8065/20000], Loss: 898.154296875, Entropy 442.5959167480469, Learning Rate: 0.000625\n",
      "Epoch [8066/20000], Loss: 844.480224609375, Entropy 433.2842102050781, Learning Rate: 0.000625\n",
      "Epoch [8067/20000], Loss: 864.66259765625, Entropy 432.0912780761719, Learning Rate: 0.000625\n",
      "Epoch [8068/20000], Loss: 861.6329345703125, Entropy 426.0791320800781, Learning Rate: 0.000625\n",
      "Epoch [8069/20000], Loss: 847.08544921875, Entropy 441.8199768066406, Learning Rate: 0.000625\n",
      "Epoch [8070/20000], Loss: 860.3659057617188, Entropy 434.56463623046875, Learning Rate: 0.000625\n",
      "Epoch [8071/20000], Loss: 873.7750244140625, Entropy 415.7254943847656, Learning Rate: 0.000625\n",
      "Epoch [8072/20000], Loss: 827.1705322265625, Entropy 436.9796142578125, Learning Rate: 0.000625\n",
      "Epoch [8073/20000], Loss: 863.2723388671875, Entropy 451.1228942871094, Learning Rate: 0.000625\n",
      "Epoch [8074/20000], Loss: 837.609130859375, Entropy 439.4206848144531, Learning Rate: 0.000625\n",
      "Epoch [8075/20000], Loss: 847.5574951171875, Entropy 434.8796691894531, Learning Rate: 0.000625\n",
      "Epoch [8076/20000], Loss: 873.4754638671875, Entropy 444.290771484375, Learning Rate: 0.000625\n",
      "Epoch [8077/20000], Loss: 878.130859375, Entropy 433.9513854980469, Learning Rate: 0.000625\n",
      "Epoch [8078/20000], Loss: 832.0809936523438, Entropy 437.41925048828125, Learning Rate: 0.000625\n",
      "Epoch [8079/20000], Loss: 838.2232666015625, Entropy 450.4460754394531, Learning Rate: 0.000625\n",
      "Epoch [8080/20000], Loss: 902.24951171875, Entropy 435.1807861328125, Learning Rate: 0.000625\n",
      "Epoch [8081/20000], Loss: 860.08984375, Entropy 434.1710205078125, Learning Rate: 0.000625\n",
      "Epoch [8082/20000], Loss: 885.0100708007812, Entropy 431.14898681640625, Learning Rate: 0.000625\n",
      "Epoch [8083/20000], Loss: 859.427734375, Entropy 435.6304626464844, Learning Rate: 0.000625\n",
      "Epoch [8084/20000], Loss: 914.167724609375, Entropy 431.4960021972656, Learning Rate: 0.000625\n",
      "Epoch [8085/20000], Loss: 847.9287109375, Entropy 435.1659240722656, Learning Rate: 0.000625\n",
      "Epoch [8086/20000], Loss: 835.658447265625, Entropy 431.8827209472656, Learning Rate: 0.000625\n",
      "Epoch [8087/20000], Loss: 893.09765625, Entropy 429.4266357421875, Learning Rate: 0.000625\n",
      "Epoch [8088/20000], Loss: 856.1474609375, Entropy 437.239013671875, Learning Rate: 0.000625\n",
      "Epoch [8089/20000], Loss: 893.646240234375, Entropy 435.6539611816406, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8090/20000], Loss: 839.14794921875, Entropy 439.591796875, Learning Rate: 0.000625\n",
      "Epoch [8091/20000], Loss: 854.803955078125, Entropy 437.5280456542969, Learning Rate: 0.000625\n",
      "Epoch [8092/20000], Loss: 873.661865234375, Entropy 437.4302673339844, Learning Rate: 0.000625\n",
      "Epoch [8093/20000], Loss: 890.2567138671875, Entropy 433.6620178222656, Learning Rate: 0.000625\n",
      "Epoch [8094/20000], Loss: 866.6455078125, Entropy 435.7569580078125, Learning Rate: 0.000625\n",
      "Epoch [8095/20000], Loss: 854.5994262695312, Entropy 427.85284423828125, Learning Rate: 0.000625\n",
      "Epoch [8096/20000], Loss: 840.416259765625, Entropy 436.8611145019531, Learning Rate: 0.000625\n",
      "Epoch [8097/20000], Loss: 852.3556518554688, Entropy 431.42889404296875, Learning Rate: 0.000625\n",
      "Epoch [8098/20000], Loss: 901.4419555664062, Entropy 438.80364990234375, Learning Rate: 0.000625\n",
      "Epoch [8099/20000], Loss: 893.189208984375, Entropy 419.4522705078125, Learning Rate: 0.000625\n",
      "Epoch [8100/20000], Loss: 884.6928100585938, Entropy 430.56549072265625, Learning Rate: 0.000625\n",
      "Epoch [8101/20000], Loss: 833.3565063476562, Entropy 442.86639404296875, Learning Rate: 0.000625\n",
      "Epoch [8102/20000], Loss: 829.8059692382812, Entropy 442.23638916015625, Learning Rate: 0.000625\n",
      "Epoch [8103/20000], Loss: 839.0929565429688, Entropy 438.70916748046875, Learning Rate: 0.000625\n",
      "Epoch [8104/20000], Loss: 872.6002197265625, Entropy 442.4974060058594, Learning Rate: 0.000625\n",
      "Epoch [8105/20000], Loss: 855.5489501953125, Entropy 430.7160339355469, Learning Rate: 0.000625\n",
      "Epoch [8106/20000], Loss: 869.9879760742188, Entropy 438.15350341796875, Learning Rate: 0.000625\n",
      "Epoch [8107/20000], Loss: 908.7913818359375, Entropy 432.2796325683594, Learning Rate: 0.000625\n",
      "Epoch [8108/20000], Loss: 850.6143798828125, Entropy 431.8855895996094, Learning Rate: 0.000625\n",
      "Epoch [8109/20000], Loss: 858.318603515625, Entropy 430.9170227050781, Learning Rate: 0.000625\n",
      "Epoch [8110/20000], Loss: 913.18603515625, Entropy 435.0606994628906, Learning Rate: 0.000625\n",
      "Epoch [8111/20000], Loss: 806.932861328125, Entropy 439.3960876464844, Learning Rate: 0.000625\n",
      "Epoch [8112/20000], Loss: 823.0164794921875, Entropy 455.6304931640625, Learning Rate: 0.000625\n",
      "Epoch [8113/20000], Loss: 902.6416625976562, Entropy 434.29522705078125, Learning Rate: 0.000625\n",
      "Epoch [8114/20000], Loss: 833.77197265625, Entropy 434.5657043457031, Learning Rate: 0.000625\n",
      "Epoch [8115/20000], Loss: 863.3338623046875, Entropy 437.43701171875, Learning Rate: 0.000625\n",
      "Epoch [8116/20000], Loss: 859.613037109375, Entropy 438.40234375, Learning Rate: 0.000625\n",
      "Epoch [8117/20000], Loss: 868.3721923828125, Entropy 442.1513977050781, Learning Rate: 0.000625\n",
      "Epoch [8118/20000], Loss: 834.1671752929688, Entropy 452.72357177734375, Learning Rate: 0.000625\n",
      "Epoch [8119/20000], Loss: 866.3126220703125, Entropy 423.9114074707031, Learning Rate: 0.000625\n",
      "Epoch [8120/20000], Loss: 888.498046875, Entropy 444.8899230957031, Learning Rate: 0.000625\n",
      "Epoch [8121/20000], Loss: 875.78662109375, Entropy 441.6549072265625, Learning Rate: 0.000625\n",
      "Epoch [8122/20000], Loss: 848.7424926757812, Entropy 428.82733154296875, Learning Rate: 0.000625\n",
      "Epoch [8123/20000], Loss: 849.9951782226562, Entropy 432.85833740234375, Learning Rate: 0.000625\n",
      "Epoch [8124/20000], Loss: 837.9092407226562, Entropy 439.79827880859375, Learning Rate: 0.000625\n",
      "Epoch [8125/20000], Loss: 840.962646484375, Entropy 444.3665771484375, Learning Rate: 0.000625\n",
      "Epoch [8126/20000], Loss: 877.9486083984375, Entropy 434.1473693847656, Learning Rate: 0.000625\n",
      "Epoch [8127/20000], Loss: 853.7147216796875, Entropy 437.0900573730469, Learning Rate: 0.000625\n",
      "Epoch [8128/20000], Loss: 841.3281860351562, Entropy 439.42205810546875, Learning Rate: 0.000625\n",
      "Epoch [8129/20000], Loss: 908.9737548828125, Entropy 420.6773986816406, Learning Rate: 0.000625\n",
      "Epoch [8130/20000], Loss: 889.48046875, Entropy 441.4904479980469, Learning Rate: 0.000625\n",
      "Epoch [8131/20000], Loss: 856.0210571289062, Entropy 441.79608154296875, Learning Rate: 0.000625\n",
      "Epoch [8132/20000], Loss: 867.1973876953125, Entropy 428.0939636230469, Learning Rate: 0.000625\n",
      "Epoch [8133/20000], Loss: 815.880126953125, Entropy 446.4611511230469, Learning Rate: 0.000625\n",
      "Epoch [8134/20000], Loss: 858.7929077148438, Entropy 441.67974853515625, Learning Rate: 0.000625\n",
      "Epoch [8135/20000], Loss: 867.9591064453125, Entropy 457.7112121582031, Learning Rate: 0.000625\n",
      "Epoch [8136/20000], Loss: 887.653564453125, Entropy 438.9586486816406, Learning Rate: 0.000625\n",
      "Epoch [8137/20000], Loss: 849.4771728515625, Entropy 442.5690612792969, Learning Rate: 0.000625\n",
      "Epoch [8138/20000], Loss: 836.404052734375, Entropy 432.02392578125, Learning Rate: 0.000625\n",
      "Epoch [8139/20000], Loss: 884.3441162109375, Entropy 434.443359375, Learning Rate: 0.000625\n",
      "Epoch [8140/20000], Loss: 887.4421997070312, Entropy 432.06182861328125, Learning Rate: 0.000625\n",
      "Epoch [8141/20000], Loss: 879.025634765625, Entropy 440.0340576171875, Learning Rate: 0.000625\n",
      "Epoch [8142/20000], Loss: 862.7557983398438, Entropy 448.98040771484375, Learning Rate: 0.000625\n",
      "Epoch [8143/20000], Loss: 867.3384399414062, Entropy 434.40240478515625, Learning Rate: 0.000625\n",
      "Epoch [8144/20000], Loss: 832.384765625, Entropy 445.4129638671875, Learning Rate: 0.000625\n",
      "Epoch [8145/20000], Loss: 826.2278442382812, Entropy 441.74212646484375, Learning Rate: 0.000625\n",
      "Epoch [8146/20000], Loss: 871.74169921875, Entropy 438.5442199707031, Learning Rate: 0.000625\n",
      "Epoch [8147/20000], Loss: 833.2457275390625, Entropy 445.0921630859375, Learning Rate: 0.000625\n",
      "Epoch [8148/20000], Loss: 913.6046142578125, Entropy 420.8441162109375, Learning Rate: 0.000625\n",
      "Epoch [8149/20000], Loss: 901.1178588867188, Entropy 427.90570068359375, Learning Rate: 0.000625\n",
      "Epoch [8150/20000], Loss: 863.755126953125, Entropy 435.69970703125, Learning Rate: 0.000625\n",
      "Epoch [8151/20000], Loss: 895.4852294921875, Entropy 436.3059997558594, Learning Rate: 0.000625\n",
      "Epoch [8152/20000], Loss: 855.3126831054688, Entropy 446.20648193359375, Learning Rate: 0.000625\n",
      "Epoch [8153/20000], Loss: 889.877197265625, Entropy 437.4315185546875, Learning Rate: 0.000625\n",
      "Epoch [8154/20000], Loss: 889.949462890625, Entropy 429.4520568847656, Learning Rate: 0.000625\n",
      "Epoch [8155/20000], Loss: 878.5831298828125, Entropy 443.18994140625, Learning Rate: 0.000625\n",
      "Epoch [8156/20000], Loss: 872.7767333984375, Entropy 434.5208435058594, Learning Rate: 0.000625\n",
      "Epoch [8157/20000], Loss: 885.5921630859375, Entropy 433.0040588378906, Learning Rate: 0.000625\n",
      "Epoch [8158/20000], Loss: 895.0165405273438, Entropy 442.04217529296875, Learning Rate: 0.000625\n",
      "Epoch [8159/20000], Loss: 864.8758544921875, Entropy 447.2418212890625, Learning Rate: 0.000625\n",
      "Epoch [8160/20000], Loss: 848.876708984375, Entropy 432.9049987792969, Learning Rate: 0.000625\n",
      "Epoch [8161/20000], Loss: 863.0972900390625, Entropy 450.3814392089844, Learning Rate: 0.000625\n",
      "Epoch [8162/20000], Loss: 831.3672485351562, Entropy 428.67913818359375, Learning Rate: 0.000625\n",
      "Epoch [8163/20000], Loss: 896.3062744140625, Entropy 435.9088439941406, Learning Rate: 0.000625\n",
      "Epoch [8164/20000], Loss: 845.56689453125, Entropy 436.1307678222656, Learning Rate: 0.000625\n",
      "Epoch [8165/20000], Loss: 860.3025512695312, Entropy 437.77569580078125, Learning Rate: 0.000625\n",
      "Epoch [8166/20000], Loss: 846.3704223632812, Entropy 433.04693603515625, Learning Rate: 0.000625\n",
      "Epoch [8167/20000], Loss: 876.5662231445312, Entropy 435.21966552734375, Learning Rate: 0.000625\n",
      "Epoch [8168/20000], Loss: 854.4071044921875, Entropy 446.5585021972656, Learning Rate: 0.000625\n",
      "Epoch [8169/20000], Loss: 859.06640625, Entropy 442.8796081542969, Learning Rate: 0.000625\n",
      "Epoch [8170/20000], Loss: 858.7333374023438, Entropy 431.14288330078125, Learning Rate: 0.000625\n",
      "Epoch [8171/20000], Loss: 880.720703125, Entropy 435.86083984375, Learning Rate: 0.000625\n",
      "Epoch [8172/20000], Loss: 903.3920288085938, Entropy 434.19049072265625, Learning Rate: 0.000625\n",
      "Epoch [8173/20000], Loss: 893.5729370117188, Entropy 434.98358154296875, Learning Rate: 0.000625\n",
      "Epoch [8174/20000], Loss: 852.3002319335938, Entropy 433.33599853515625, Learning Rate: 0.000625\n",
      "Epoch [8175/20000], Loss: 897.2577514648438, Entropy 435.49163818359375, Learning Rate: 0.000625\n",
      "Epoch [8176/20000], Loss: 889.5703735351562, Entropy 431.67596435546875, Learning Rate: 0.000625\n",
      "Epoch [8177/20000], Loss: 861.6060791015625, Entropy 435.7286376953125, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8178/20000], Loss: 864.797119140625, Entropy 445.0837707519531, Learning Rate: 0.000625\n",
      "Epoch [8179/20000], Loss: 854.9147338867188, Entropy 434.64288330078125, Learning Rate: 0.000625\n",
      "Epoch [8180/20000], Loss: 858.1188354492188, Entropy 441.68023681640625, Learning Rate: 0.000625\n",
      "Epoch [8181/20000], Loss: 885.83447265625, Entropy 445.0433349609375, Learning Rate: 0.000625\n",
      "Epoch [8182/20000], Loss: 873.2160034179688, Entropy 444.03411865234375, Learning Rate: 0.000625\n",
      "Epoch [8183/20000], Loss: 888.781494140625, Entropy 437.9775695800781, Learning Rate: 0.000625\n",
      "Epoch [8184/20000], Loss: 847.20458984375, Entropy 428.8101501464844, Learning Rate: 0.000625\n",
      "Epoch [8185/20000], Loss: 861.7318115234375, Entropy 416.6014709472656, Learning Rate: 0.000625\n",
      "Epoch [8186/20000], Loss: 850.19921875, Entropy 445.2324523925781, Learning Rate: 0.000625\n",
      "Epoch [8187/20000], Loss: 869.2344970703125, Entropy 430.2620849609375, Learning Rate: 0.000625\n",
      "Epoch [8188/20000], Loss: 852.5916137695312, Entropy 432.59210205078125, Learning Rate: 0.000625\n",
      "Epoch [8189/20000], Loss: 869.501953125, Entropy 444.1964111328125, Learning Rate: 0.000625\n",
      "Epoch [8190/20000], Loss: 851.487060546875, Entropy 452.4438171386719, Learning Rate: 0.000625\n",
      "Epoch [8191/20000], Loss: 836.443359375, Entropy 428.6964416503906, Learning Rate: 0.000625\n",
      "Epoch [8192/20000], Loss: 871.4051513671875, Entropy 447.947021484375, Learning Rate: 0.000625\n",
      "Epoch [8193/20000], Loss: 882.7655029296875, Entropy 429.7093200683594, Learning Rate: 0.000625\n",
      "Epoch [8194/20000], Loss: 873.945556640625, Entropy 439.1834411621094, Learning Rate: 0.000625\n",
      "Epoch [8195/20000], Loss: 898.3421020507812, Entropy 430.65850830078125, Learning Rate: 0.000625\n",
      "Epoch [8196/20000], Loss: 864.3104858398438, Entropy 447.83355712890625, Learning Rate: 0.000625\n",
      "Epoch [8197/20000], Loss: 842.7388916015625, Entropy 438.5179138183594, Learning Rate: 0.000625\n",
      "Epoch [8198/20000], Loss: 847.2337036132812, Entropy 435.26812744140625, Learning Rate: 0.000625\n",
      "Epoch [8199/20000], Loss: 914.0720825195312, Entropy 436.63897705078125, Learning Rate: 0.000625\n",
      "Epoch [8200/20000], Loss: 852.13720703125, Entropy 443.8033752441406, Learning Rate: 0.000625\n",
      "Epoch [8201/20000], Loss: 838.4173583984375, Entropy 451.5188903808594, Learning Rate: 0.000625\n",
      "Epoch [8202/20000], Loss: 884.9969482421875, Entropy 444.0433349609375, Learning Rate: 0.000625\n",
      "Epoch [8203/20000], Loss: 838.3062744140625, Entropy 451.169921875, Learning Rate: 0.000625\n",
      "Epoch [8204/20000], Loss: 885.3574829101562, Entropy 440.55169677734375, Learning Rate: 0.000625\n",
      "Epoch [8205/20000], Loss: 807.5112915039062, Entropy 460.19036865234375, Learning Rate: 0.000625\n",
      "Epoch [8206/20000], Loss: 880.439697265625, Entropy 430.0153503417969, Learning Rate: 0.000625\n",
      "Epoch [8207/20000], Loss: 888.96337890625, Entropy 430.458740234375, Learning Rate: 0.000625\n",
      "Epoch [8208/20000], Loss: 866.1661987304688, Entropy 435.50823974609375, Learning Rate: 0.000625\n",
      "Epoch [8209/20000], Loss: 844.3588256835938, Entropy 433.15374755859375, Learning Rate: 0.000625\n",
      "Epoch [8210/20000], Loss: 843.046630859375, Entropy 442.5838623046875, Learning Rate: 0.000625\n",
      "Epoch [8211/20000], Loss: 849.0516357421875, Entropy 448.9176330566406, Learning Rate: 0.000625\n",
      "Epoch [8212/20000], Loss: 858.2626953125, Entropy 429.7610168457031, Learning Rate: 0.000625\n",
      "Epoch [8213/20000], Loss: 900.7684326171875, Entropy 433.2283630371094, Learning Rate: 0.000625\n",
      "Epoch [8214/20000], Loss: 837.1141357421875, Entropy 447.7783203125, Learning Rate: 0.000625\n",
      "Epoch [8215/20000], Loss: 886.959716796875, Entropy 449.1720886230469, Learning Rate: 0.000625\n",
      "Epoch [8216/20000], Loss: 914.286865234375, Entropy 446.1749267578125, Learning Rate: 0.000625\n",
      "Epoch [8217/20000], Loss: 858.7315673828125, Entropy 453.6484375, Learning Rate: 0.000625\n",
      "Epoch [8218/20000], Loss: 833.2349243164062, Entropy 440.07366943359375, Learning Rate: 0.000625\n",
      "Epoch [8219/20000], Loss: 855.3731689453125, Entropy 452.1294860839844, Learning Rate: 0.000625\n",
      "Epoch [8220/20000], Loss: 910.4630126953125, Entropy 438.2279052734375, Learning Rate: 0.000625\n",
      "Epoch [8221/20000], Loss: 836.2754516601562, Entropy 444.09979248046875, Learning Rate: 0.000625\n",
      "Epoch [8222/20000], Loss: 878.40380859375, Entropy 421.5252990722656, Learning Rate: 0.000625\n",
      "Epoch [8223/20000], Loss: 856.9824829101562, Entropy 427.00823974609375, Learning Rate: 0.000625\n",
      "Epoch [8224/20000], Loss: 860.7620239257812, Entropy 446.25128173828125, Learning Rate: 0.000625\n",
      "Epoch [8225/20000], Loss: 842.6182861328125, Entropy 435.9849548339844, Learning Rate: 0.000625\n",
      "Epoch [8226/20000], Loss: 859.8688354492188, Entropy 446.39312744140625, Learning Rate: 0.000625\n",
      "Epoch [8227/20000], Loss: 885.0848999023438, Entropy 438.47027587890625, Learning Rate: 0.000625\n",
      "Epoch [8228/20000], Loss: 887.7337646484375, Entropy 444.2758483886719, Learning Rate: 0.000625\n",
      "Epoch [8229/20000], Loss: 869.4622192382812, Entropy 439.74359130859375, Learning Rate: 0.000625\n",
      "Epoch [8230/20000], Loss: 874.5387573242188, Entropy 435.51007080078125, Learning Rate: 0.000625\n",
      "Epoch [8231/20000], Loss: 870.181640625, Entropy 439.9483642578125, Learning Rate: 0.000625\n",
      "Epoch [8232/20000], Loss: 863.001953125, Entropy 428.8214416503906, Learning Rate: 0.000625\n",
      "Epoch [8233/20000], Loss: 826.3399658203125, Entropy 452.8404541015625, Learning Rate: 0.000625\n",
      "Epoch [8234/20000], Loss: 863.3690185546875, Entropy 439.2024230957031, Learning Rate: 0.000625\n",
      "Epoch [8235/20000], Loss: 861.0955200195312, Entropy 440.23480224609375, Learning Rate: 0.000625\n",
      "Epoch [8236/20000], Loss: 871.888671875, Entropy 449.0549621582031, Learning Rate: 0.000625\n",
      "Epoch [8237/20000], Loss: 895.3865966796875, Entropy 421.0749816894531, Learning Rate: 0.000625\n",
      "Epoch [8238/20000], Loss: 857.120361328125, Entropy 439.8631286621094, Learning Rate: 0.000625\n",
      "Epoch [8239/20000], Loss: 833.1578369140625, Entropy 438.7494812011719, Learning Rate: 0.000625\n",
      "Epoch [8240/20000], Loss: 901.152099609375, Entropy 434.4622497558594, Learning Rate: 0.000625\n",
      "Epoch [8241/20000], Loss: 884.6282958984375, Entropy 437.2176513671875, Learning Rate: 0.000625\n",
      "Epoch [8242/20000], Loss: 863.3797607421875, Entropy 447.3380432128906, Learning Rate: 0.000625\n",
      "Epoch [8243/20000], Loss: 863.0468139648438, Entropy 437.58209228515625, Learning Rate: 0.000625\n",
      "Epoch [8244/20000], Loss: 865.16015625, Entropy 462.3663330078125, Learning Rate: 0.000625\n",
      "Epoch [8245/20000], Loss: 863.5516357421875, Entropy 449.4791259765625, Learning Rate: 0.000625\n",
      "Epoch [8246/20000], Loss: 837.0770263671875, Entropy 451.7233581542969, Learning Rate: 0.000625\n",
      "Epoch [8247/20000], Loss: 832.4112548828125, Entropy 442.714599609375, Learning Rate: 0.000625\n",
      "Epoch [8248/20000], Loss: 851.6126708984375, Entropy 449.7173767089844, Learning Rate: 0.000625\n",
      "Epoch [8249/20000], Loss: 874.2770385742188, Entropy 437.73663330078125, Learning Rate: 0.000625\n",
      "Epoch [8250/20000], Loss: 883.8311157226562, Entropy 419.29351806640625, Learning Rate: 0.000625\n",
      "Epoch [8251/20000], Loss: 896.8164672851562, Entropy 439.17132568359375, Learning Rate: 0.000625\n",
      "Epoch [8252/20000], Loss: 851.6363525390625, Entropy 450.1259765625, Learning Rate: 0.000625\n",
      "Epoch [8253/20000], Loss: 879.4708862304688, Entropy 437.60968017578125, Learning Rate: 0.000625\n",
      "Epoch [8254/20000], Loss: 857.388916015625, Entropy 444.0648193359375, Learning Rate: 0.000625\n",
      "Epoch [8255/20000], Loss: 908.789306640625, Entropy 435.27294921875, Learning Rate: 0.000625\n",
      "Epoch [8256/20000], Loss: 843.8851318359375, Entropy 434.537841796875, Learning Rate: 0.000625\n",
      "Epoch [8257/20000], Loss: 879.42041015625, Entropy 441.6342468261719, Learning Rate: 0.000625\n",
      "Epoch [8258/20000], Loss: 901.0963134765625, Entropy 446.8678894042969, Learning Rate: 0.000625\n",
      "Epoch [8259/20000], Loss: 857.6425170898438, Entropy 438.24530029296875, Learning Rate: 0.000625\n",
      "Epoch [8260/20000], Loss: 852.6151123046875, Entropy 442.779052734375, Learning Rate: 0.000625\n",
      "Epoch [8261/20000], Loss: 868.6319580078125, Entropy 429.9712829589844, Learning Rate: 0.000625\n",
      "Epoch [8262/20000], Loss: 862.9058227539062, Entropy 435.17620849609375, Learning Rate: 0.000625\n",
      "Epoch [8263/20000], Loss: 932.5723876953125, Entropy 440.4382019042969, Learning Rate: 0.000625\n",
      "Epoch [8264/20000], Loss: 853.0753784179688, Entropy 438.57806396484375, Learning Rate: 0.000625\n",
      "Epoch [8265/20000], Loss: 871.1009521484375, Entropy 455.2299499511719, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8266/20000], Loss: 922.5828247070312, Entropy 451.13214111328125, Learning Rate: 0.000625\n",
      "Epoch [8267/20000], Loss: 955.1348876953125, Entropy 437.45068359375, Learning Rate: 0.000625\n",
      "Epoch [8268/20000], Loss: 834.1055908203125, Entropy 432.2640380859375, Learning Rate: 0.000625\n",
      "Epoch [8269/20000], Loss: 833.6521606445312, Entropy 447.32769775390625, Learning Rate: 0.000625\n",
      "Epoch [8270/20000], Loss: 879.94287109375, Entropy 421.7238464355469, Learning Rate: 0.000625\n",
      "Epoch [8271/20000], Loss: 868.6396484375, Entropy 438.9284973144531, Learning Rate: 0.000625\n",
      "Epoch [8272/20000], Loss: 839.5916748046875, Entropy 449.7809753417969, Learning Rate: 0.000625\n",
      "Epoch [8273/20000], Loss: 927.1229248046875, Entropy 427.659912109375, Learning Rate: 0.000625\n",
      "Epoch [8274/20000], Loss: 880.2408447265625, Entropy 426.3101501464844, Learning Rate: 0.000625\n",
      "Epoch [8275/20000], Loss: 873.2552490234375, Entropy 435.8319091796875, Learning Rate: 0.000625\n",
      "Epoch [8276/20000], Loss: 866.7800903320312, Entropy 438.00836181640625, Learning Rate: 0.000625\n",
      "Epoch [8277/20000], Loss: 860.0999145507812, Entropy 434.51788330078125, Learning Rate: 0.000625\n",
      "Epoch [8278/20000], Loss: 883.8082275390625, Entropy 438.927734375, Learning Rate: 0.000625\n",
      "Epoch [8279/20000], Loss: 874.1693115234375, Entropy 437.3094482421875, Learning Rate: 0.000625\n",
      "Epoch [8280/20000], Loss: 869.447509765625, Entropy 453.2853088378906, Learning Rate: 0.000625\n",
      "Epoch [8281/20000], Loss: 904.26708984375, Entropy 440.6530456542969, Learning Rate: 0.000625\n",
      "Epoch [8282/20000], Loss: 839.7276000976562, Entropy 439.03533935546875, Learning Rate: 0.000625\n",
      "Epoch [8283/20000], Loss: 837.2249145507812, Entropy 447.15423583984375, Learning Rate: 0.000625\n",
      "Epoch [8284/20000], Loss: 841.361083984375, Entropy 431.8397521972656, Learning Rate: 0.000625\n",
      "Epoch [8285/20000], Loss: 897.1922607421875, Entropy 428.211669921875, Learning Rate: 0.000625\n",
      "Epoch [8286/20000], Loss: 877.5167236328125, Entropy 446.8337097167969, Learning Rate: 0.000625\n",
      "Epoch [8287/20000], Loss: 844.5733032226562, Entropy 439.05523681640625, Learning Rate: 0.000625\n",
      "Epoch [8288/20000], Loss: 863.3225708007812, Entropy 436.69464111328125, Learning Rate: 0.000625\n",
      "Epoch [8289/20000], Loss: 905.1636962890625, Entropy 432.0774841308594, Learning Rate: 0.000625\n",
      "Epoch [8290/20000], Loss: 885.2011108398438, Entropy 437.24920654296875, Learning Rate: 0.000625\n",
      "Epoch [8291/20000], Loss: 899.454345703125, Entropy 440.2027893066406, Learning Rate: 0.000625\n",
      "Epoch [8292/20000], Loss: 873.2467041015625, Entropy 445.0163269042969, Learning Rate: 0.000625\n",
      "Epoch [8293/20000], Loss: 841.96630859375, Entropy 435.1475830078125, Learning Rate: 0.000625\n",
      "Epoch [8294/20000], Loss: 868.3046875, Entropy 443.8219299316406, Learning Rate: 0.000625\n",
      "Epoch [8295/20000], Loss: 843.28173828125, Entropy 442.605224609375, Learning Rate: 0.000625\n",
      "Epoch [8296/20000], Loss: 843.578125, Entropy 428.3130798339844, Learning Rate: 0.000625\n",
      "Epoch [8297/20000], Loss: 857.633544921875, Entropy 443.39208984375, Learning Rate: 0.000625\n",
      "Epoch [8298/20000], Loss: 901.7445068359375, Entropy 437.1058349609375, Learning Rate: 0.000625\n",
      "Epoch [8299/20000], Loss: 893.3812255859375, Entropy 435.8699035644531, Learning Rate: 0.000625\n",
      "Epoch [8300/20000], Loss: 888.8651123046875, Entropy 435.9696350097656, Learning Rate: 0.000625\n",
      "Epoch [8301/20000], Loss: 864.3119506835938, Entropy 445.30303955078125, Learning Rate: 0.000625\n",
      "Epoch [8302/20000], Loss: 888.591064453125, Entropy 447.0938720703125, Learning Rate: 0.000625\n",
      "Epoch [8303/20000], Loss: 873.5546875, Entropy 444.6903076171875, Learning Rate: 0.000625\n",
      "Epoch [8304/20000], Loss: 899.6119384765625, Entropy 437.0269470214844, Learning Rate: 0.000625\n",
      "Epoch [8305/20000], Loss: 875.28125, Entropy 435.9759521484375, Learning Rate: 0.000625\n",
      "Epoch [8306/20000], Loss: 817.182861328125, Entropy 439.020263671875, Learning Rate: 0.000625\n",
      "Epoch [8307/20000], Loss: 930.89111328125, Entropy 428.446044921875, Learning Rate: 0.000625\n",
      "Epoch [8308/20000], Loss: 876.1207275390625, Entropy 441.9322509765625, Learning Rate: 0.000625\n",
      "Epoch [8309/20000], Loss: 882.332275390625, Entropy 438.4676818847656, Learning Rate: 0.000625\n",
      "Epoch [8310/20000], Loss: 892.1226806640625, Entropy 437.5591735839844, Learning Rate: 0.000625\n",
      "Epoch [8311/20000], Loss: 867.3963012695312, Entropy 431.28533935546875, Learning Rate: 0.000625\n",
      "Epoch [8312/20000], Loss: 819.346923828125, Entropy 449.9117736816406, Learning Rate: 0.000625\n",
      "Epoch [8313/20000], Loss: 928.5599365234375, Entropy 430.6467590332031, Learning Rate: 0.000625\n",
      "Epoch [8314/20000], Loss: 827.5518798828125, Entropy 443.1201477050781, Learning Rate: 0.000625\n",
      "Epoch [8315/20000], Loss: 881.9996337890625, Entropy 433.93310546875, Learning Rate: 0.000625\n",
      "Epoch [8316/20000], Loss: 848.91845703125, Entropy 438.3288879394531, Learning Rate: 0.000625\n",
      "Epoch [8317/20000], Loss: 844.625244140625, Entropy 445.8548583984375, Learning Rate: 0.000625\n",
      "Epoch [8318/20000], Loss: 854.9110107421875, Entropy 432.8787536621094, Learning Rate: 0.000625\n",
      "Epoch [8319/20000], Loss: 850.5673828125, Entropy 443.4645080566406, Learning Rate: 0.000625\n",
      "Epoch [8320/20000], Loss: 848.3441162109375, Entropy 443.6102294921875, Learning Rate: 0.000625\n",
      "Epoch [8321/20000], Loss: 865.5191650390625, Entropy 432.318115234375, Learning Rate: 0.000625\n",
      "Epoch [8322/20000], Loss: 865.5684204101562, Entropy 453.02593994140625, Learning Rate: 0.000625\n",
      "Epoch [8323/20000], Loss: 863.7427978515625, Entropy 447.2906188964844, Learning Rate: 0.000625\n",
      "Epoch [8324/20000], Loss: 849.781982421875, Entropy 447.4185485839844, Learning Rate: 0.000625\n",
      "Epoch [8325/20000], Loss: 866.4439697265625, Entropy 427.033203125, Learning Rate: 0.000625\n",
      "Epoch [8326/20000], Loss: 892.373046875, Entropy 437.0738220214844, Learning Rate: 0.000625\n",
      "Epoch [8327/20000], Loss: 855.5948486328125, Entropy 448.8143615722656, Learning Rate: 0.000625\n",
      "Epoch [8328/20000], Loss: 883.297607421875, Entropy 447.5965270996094, Learning Rate: 0.000625\n",
      "Epoch [8329/20000], Loss: 905.28759765625, Entropy 428.0572509765625, Learning Rate: 0.000625\n",
      "Epoch [8330/20000], Loss: 877.3499145507812, Entropy 453.58538818359375, Learning Rate: 0.000625\n",
      "Epoch [8331/20000], Loss: 930.4149169921875, Entropy 443.646484375, Learning Rate: 0.000625\n",
      "Epoch [8332/20000], Loss: 886.7461547851562, Entropy 434.96697998046875, Learning Rate: 0.000625\n",
      "Epoch [8333/20000], Loss: 848.7305908203125, Entropy 441.2783203125, Learning Rate: 0.000625\n",
      "Epoch [8334/20000], Loss: 863.37255859375, Entropy 445.8785095214844, Learning Rate: 0.000625\n",
      "Epoch [8335/20000], Loss: 838.6253662109375, Entropy 431.0933532714844, Learning Rate: 0.000625\n",
      "Epoch [8336/20000], Loss: 882.17626953125, Entropy 457.4598693847656, Learning Rate: 0.000625\n",
      "Epoch [8337/20000], Loss: 848.37451171875, Entropy 447.5423278808594, Learning Rate: 0.000625\n",
      "Epoch [8338/20000], Loss: 829.2084350585938, Entropy 450.66424560546875, Learning Rate: 0.000625\n",
      "Epoch [8339/20000], Loss: 851.0281372070312, Entropy 452.24713134765625, Learning Rate: 0.000625\n",
      "Epoch [8340/20000], Loss: 864.844970703125, Entropy 454.9877624511719, Learning Rate: 0.000625\n",
      "Epoch [8341/20000], Loss: 913.039794921875, Entropy 442.7110900878906, Learning Rate: 0.000625\n",
      "Epoch [8342/20000], Loss: 866.79248046875, Entropy 454.395263671875, Learning Rate: 0.000625\n",
      "Epoch [8343/20000], Loss: 831.6356201171875, Entropy 446.0422058105469, Learning Rate: 0.000625\n",
      "Epoch [8344/20000], Loss: 880.644287109375, Entropy 443.4551086425781, Learning Rate: 0.000625\n",
      "Epoch [8345/20000], Loss: 815.2702026367188, Entropy 452.34783935546875, Learning Rate: 0.000625\n",
      "Epoch [8346/20000], Loss: 856.3458251953125, Entropy 445.9649963378906, Learning Rate: 0.000625\n",
      "Epoch [8347/20000], Loss: 843.5426025390625, Entropy 445.0643615722656, Learning Rate: 0.000625\n",
      "Epoch [8348/20000], Loss: 891.1502685546875, Entropy 446.5011291503906, Learning Rate: 0.000625\n",
      "Epoch [8349/20000], Loss: 859.79443359375, Entropy 452.9205322265625, Learning Rate: 0.000625\n",
      "Epoch [8350/20000], Loss: 846.6435546875, Entropy 446.51123046875, Learning Rate: 0.000625\n",
      "Epoch [8351/20000], Loss: 862.682861328125, Entropy 441.7964782714844, Learning Rate: 0.000625\n",
      "Epoch [8352/20000], Loss: 817.5418701171875, Entropy 458.6193542480469, Learning Rate: 0.000625\n",
      "Epoch [8353/20000], Loss: 877.7481079101562, Entropy 456.60858154296875, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8354/20000], Loss: 903.8607177734375, Entropy 433.4747314453125, Learning Rate: 0.000625\n",
      "Epoch [8355/20000], Loss: 851.0791015625, Entropy 454.8678283691406, Learning Rate: 0.000625\n",
      "Epoch [8356/20000], Loss: 872.76708984375, Entropy 438.2859802246094, Learning Rate: 0.000625\n",
      "Epoch [8357/20000], Loss: 830.5966186523438, Entropy 441.07244873046875, Learning Rate: 0.000625\n",
      "Epoch [8358/20000], Loss: 867.0399169921875, Entropy 441.9592590332031, Learning Rate: 0.000625\n",
      "Epoch [8359/20000], Loss: 839.464111328125, Entropy 454.7174072265625, Learning Rate: 0.000625\n",
      "Epoch [8360/20000], Loss: 877.1201171875, Entropy 439.704833984375, Learning Rate: 0.000625\n",
      "Epoch [8361/20000], Loss: 821.2543334960938, Entropy 434.95941162109375, Learning Rate: 0.000625\n",
      "Epoch [8362/20000], Loss: 827.2514038085938, Entropy 446.38531494140625, Learning Rate: 0.000625\n",
      "Epoch [8363/20000], Loss: 884.159912109375, Entropy 439.7263488769531, Learning Rate: 0.000625\n",
      "Epoch [8364/20000], Loss: 826.39404296875, Entropy 448.3203125, Learning Rate: 0.000625\n",
      "Epoch [8365/20000], Loss: 853.2078857421875, Entropy 439.9354553222656, Learning Rate: 0.000625\n",
      "Epoch [8366/20000], Loss: 874.2660522460938, Entropy 444.05389404296875, Learning Rate: 0.000625\n",
      "Epoch [8367/20000], Loss: 848.9453125, Entropy 438.7746887207031, Learning Rate: 0.000625\n",
      "Epoch [8368/20000], Loss: 828.9267578125, Entropy 449.82763671875, Learning Rate: 0.000625\n",
      "Epoch [8369/20000], Loss: 876.5850830078125, Entropy 443.7541198730469, Learning Rate: 0.000625\n",
      "Epoch [8370/20000], Loss: 874.8343505859375, Entropy 442.8738708496094, Learning Rate: 0.000625\n",
      "Epoch [8371/20000], Loss: 886.4906005859375, Entropy 446.2922058105469, Learning Rate: 0.000625\n",
      "Epoch [8372/20000], Loss: 828.31396484375, Entropy 454.2502136230469, Learning Rate: 0.000625\n",
      "Epoch [8373/20000], Loss: 797.491455078125, Entropy 453.6332702636719, Learning Rate: 0.000625\n",
      "Epoch [8374/20000], Loss: 874.5911865234375, Entropy 440.0044860839844, Learning Rate: 0.000625\n",
      "Epoch [8375/20000], Loss: 863.28759765625, Entropy 447.3230895996094, Learning Rate: 0.000625\n",
      "Epoch [8376/20000], Loss: 903.1241455078125, Entropy 442.5545349121094, Learning Rate: 0.000625\n",
      "Epoch [8377/20000], Loss: 837.0733642578125, Entropy 447.4173583984375, Learning Rate: 0.000625\n",
      "Epoch [8378/20000], Loss: 882.8379516601562, Entropy 440.70355224609375, Learning Rate: 0.000625\n",
      "Epoch [8379/20000], Loss: 851.635498046875, Entropy 440.6165466308594, Learning Rate: 0.000625\n",
      "Epoch [8380/20000], Loss: 876.0895385742188, Entropy 435.47296142578125, Learning Rate: 0.000625\n",
      "Epoch [8381/20000], Loss: 905.7849731445312, Entropy 447.46905517578125, Learning Rate: 0.000625\n",
      "Epoch [8382/20000], Loss: 829.073974609375, Entropy 445.1651611328125, Learning Rate: 0.000625\n",
      "Epoch [8383/20000], Loss: 854.200927734375, Entropy 445.1383361816406, Learning Rate: 0.000625\n",
      "Epoch [8384/20000], Loss: 910.666259765625, Entropy 444.8371887207031, Learning Rate: 0.000625\n",
      "Epoch [8385/20000], Loss: 855.04931640625, Entropy 434.8451843261719, Learning Rate: 0.000625\n",
      "Epoch [8386/20000], Loss: 844.791748046875, Entropy 447.6894836425781, Learning Rate: 0.000625\n",
      "Epoch [8387/20000], Loss: 843.1502075195312, Entropy 450.16595458984375, Learning Rate: 0.000625\n",
      "Epoch [8388/20000], Loss: 817.8668212890625, Entropy 439.5906066894531, Learning Rate: 0.000625\n",
      "Epoch [8389/20000], Loss: 822.6754150390625, Entropy 453.8329162597656, Learning Rate: 0.000625\n",
      "Epoch [8390/20000], Loss: 838.755126953125, Entropy 451.0760803222656, Learning Rate: 0.000625\n",
      "Epoch [8391/20000], Loss: 914.474853515625, Entropy 438.8104553222656, Learning Rate: 0.000625\n",
      "Epoch [8392/20000], Loss: 846.003173828125, Entropy 449.1888122558594, Learning Rate: 0.000625\n",
      "Epoch [8393/20000], Loss: 856.0107421875, Entropy 449.8127136230469, Learning Rate: 0.000625\n",
      "Epoch [8394/20000], Loss: 861.16845703125, Entropy 444.9881896972656, Learning Rate: 0.000625\n",
      "Epoch [8395/20000], Loss: 821.385009765625, Entropy 446.8034973144531, Learning Rate: 0.000625\n",
      "Epoch [8396/20000], Loss: 858.7619018554688, Entropy 436.52789306640625, Learning Rate: 0.000625\n",
      "Epoch [8397/20000], Loss: 860.46142578125, Entropy 439.6163330078125, Learning Rate: 0.000625\n",
      "Epoch [8398/20000], Loss: 866.13916015625, Entropy 444.8101501464844, Learning Rate: 0.000625\n",
      "Epoch [8399/20000], Loss: 849.9682006835938, Entropy 442.01422119140625, Learning Rate: 0.000625\n",
      "Epoch [8400/20000], Loss: 904.01806640625, Entropy 441.3191833496094, Learning Rate: 0.000625\n",
      "Epoch [8401/20000], Loss: 809.9046630859375, Entropy 447.1712341308594, Learning Rate: 0.000625\n",
      "Epoch [8402/20000], Loss: 878.8532104492188, Entropy 446.75238037109375, Learning Rate: 0.000625\n",
      "Epoch [8403/20000], Loss: 901.0362548828125, Entropy 439.8970947265625, Learning Rate: 0.000625\n",
      "Epoch [8404/20000], Loss: 904.2332763671875, Entropy 439.2585144042969, Learning Rate: 0.000625\n",
      "Epoch [8405/20000], Loss: 871.2689208984375, Entropy 445.8853759765625, Learning Rate: 0.000625\n",
      "Epoch [8406/20000], Loss: 902.5389404296875, Entropy 430.6551513671875, Learning Rate: 0.000625\n",
      "Epoch [8407/20000], Loss: 849.2841186523438, Entropy 449.08990478515625, Learning Rate: 0.000625\n",
      "Epoch [8408/20000], Loss: 857.300537109375, Entropy 432.6545104980469, Learning Rate: 0.000625\n",
      "Epoch [8409/20000], Loss: 839.197509765625, Entropy 449.7981262207031, Learning Rate: 0.000625\n",
      "Epoch [8410/20000], Loss: 867.3021240234375, Entropy 423.778076171875, Learning Rate: 0.000625\n",
      "Epoch [8411/20000], Loss: 911.2225952148438, Entropy 450.56488037109375, Learning Rate: 0.000625\n",
      "Epoch [8412/20000], Loss: 837.70263671875, Entropy 452.6163635253906, Learning Rate: 0.000625\n",
      "Epoch [8413/20000], Loss: 901.4494018554688, Entropy 442.30303955078125, Learning Rate: 0.000625\n",
      "Epoch [8414/20000], Loss: 873.7421875, Entropy 445.3517761230469, Learning Rate: 0.000625\n",
      "Epoch [8415/20000], Loss: 845.5465087890625, Entropy 444.579833984375, Learning Rate: 0.000625\n",
      "Epoch [8416/20000], Loss: 842.609619140625, Entropy 449.3090515136719, Learning Rate: 0.000625\n",
      "Epoch [8417/20000], Loss: 831.82958984375, Entropy 446.4225158691406, Learning Rate: 0.000625\n",
      "Epoch [8418/20000], Loss: 851.628662109375, Entropy 443.3069152832031, Learning Rate: 0.000625\n",
      "Epoch [8419/20000], Loss: 891.1119384765625, Entropy 440.8735046386719, Learning Rate: 0.000625\n",
      "Epoch [8420/20000], Loss: 877.9764404296875, Entropy 446.2194519042969, Learning Rate: 0.000625\n",
      "Epoch [8421/20000], Loss: 864.16064453125, Entropy 443.98388671875, Learning Rate: 0.000625\n",
      "Epoch [8422/20000], Loss: 803.0592041015625, Entropy 456.8287353515625, Learning Rate: 0.000625\n",
      "Epoch [8423/20000], Loss: 922.322998046875, Entropy 446.3148193359375, Learning Rate: 0.000625\n",
      "Epoch [8424/20000], Loss: 874.8611450195312, Entropy 462.11444091796875, Learning Rate: 0.000625\n",
      "Epoch [8425/20000], Loss: 884.2307739257812, Entropy 445.59906005859375, Learning Rate: 0.000625\n",
      "Epoch [8426/20000], Loss: 862.0009765625, Entropy 445.3307800292969, Learning Rate: 0.000625\n",
      "Epoch [8427/20000], Loss: 920.45703125, Entropy 447.3796691894531, Learning Rate: 0.000625\n",
      "Epoch [8428/20000], Loss: 844.7220458984375, Entropy 458.576171875, Learning Rate: 0.000625\n",
      "Epoch [8429/20000], Loss: 878.734619140625, Entropy 448.2409362792969, Learning Rate: 0.000625\n",
      "Epoch [8430/20000], Loss: 899.166748046875, Entropy 431.7167053222656, Learning Rate: 0.000625\n",
      "Epoch [8431/20000], Loss: 849.1658325195312, Entropy 459.80511474609375, Learning Rate: 0.000625\n",
      "Epoch [8432/20000], Loss: 870.9506225585938, Entropy 435.14495849609375, Learning Rate: 0.000625\n",
      "Epoch [8433/20000], Loss: 814.9530029296875, Entropy 466.751708984375, Learning Rate: 0.000625\n",
      "Epoch [8434/20000], Loss: 908.9345703125, Entropy 449.1804504394531, Learning Rate: 0.000625\n",
      "Epoch [8435/20000], Loss: 872.1025390625, Entropy 443.154296875, Learning Rate: 0.000625\n",
      "Epoch [8436/20000], Loss: 856.6666259765625, Entropy 451.3416442871094, Learning Rate: 0.000625\n",
      "Epoch [8437/20000], Loss: 828.74609375, Entropy 456.3732604980469, Learning Rate: 0.000625\n",
      "Epoch [8438/20000], Loss: 862.1517333984375, Entropy 446.3001708984375, Learning Rate: 0.000625\n",
      "Epoch [8439/20000], Loss: 908.7650146484375, Entropy 450.0931091308594, Learning Rate: 0.000625\n",
      "Epoch [8440/20000], Loss: 868.36474609375, Entropy 435.0592346191406, Learning Rate: 0.000625\n",
      "Epoch [8441/20000], Loss: 942.4254150390625, Entropy 435.3536682128906, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8442/20000], Loss: 870.199951171875, Entropy 443.5299072265625, Learning Rate: 0.000625\n",
      "Epoch [8443/20000], Loss: 846.1881103515625, Entropy 470.8616943359375, Learning Rate: 0.000625\n",
      "Epoch [8444/20000], Loss: 891.3018798828125, Entropy 437.1858825683594, Learning Rate: 0.000625\n",
      "Epoch [8445/20000], Loss: 865.83935546875, Entropy 449.5775146484375, Learning Rate: 0.000625\n",
      "Epoch [8446/20000], Loss: 839.5963745117188, Entropy 449.20904541015625, Learning Rate: 0.000625\n",
      "Epoch [8447/20000], Loss: 838.5670166015625, Entropy 448.2843017578125, Learning Rate: 0.000625\n",
      "Epoch [8448/20000], Loss: 888.83984375, Entropy 446.9444885253906, Learning Rate: 0.000625\n",
      "Epoch [8449/20000], Loss: 839.9820556640625, Entropy 445.6462707519531, Learning Rate: 0.000625\n",
      "Epoch [8450/20000], Loss: 841.82763671875, Entropy 445.5771789550781, Learning Rate: 0.000625\n",
      "Epoch [8451/20000], Loss: 856.760986328125, Entropy 449.9886474609375, Learning Rate: 0.000625\n",
      "Epoch [8452/20000], Loss: 841.9637451171875, Entropy 447.7713623046875, Learning Rate: 0.000625\n",
      "Epoch [8453/20000], Loss: 893.0889892578125, Entropy 434.1416320800781, Learning Rate: 0.000625\n",
      "Epoch [8454/20000], Loss: 824.4056396484375, Entropy 441.3835144042969, Learning Rate: 0.000625\n",
      "Epoch [8455/20000], Loss: 856.9046020507812, Entropy 462.02447509765625, Learning Rate: 0.000625\n",
      "Epoch [8456/20000], Loss: 858.040283203125, Entropy 437.5701904296875, Learning Rate: 0.000625\n",
      "Epoch [8457/20000], Loss: 842.6861572265625, Entropy 443.3670959472656, Learning Rate: 0.000625\n",
      "Epoch [8458/20000], Loss: 850.322509765625, Entropy 439.8924255371094, Learning Rate: 0.000625\n",
      "Epoch [8459/20000], Loss: 872.5772094726562, Entropy 442.87652587890625, Learning Rate: 0.000625\n",
      "Epoch [8460/20000], Loss: 827.341552734375, Entropy 449.4494323730469, Learning Rate: 0.000625\n",
      "Epoch [8461/20000], Loss: 864.7506103515625, Entropy 433.5412292480469, Learning Rate: 0.000625\n",
      "Epoch [8462/20000], Loss: 901.2670288085938, Entropy 447.93975830078125, Learning Rate: 0.000625\n",
      "Epoch [8463/20000], Loss: 846.0960693359375, Entropy 456.1463317871094, Learning Rate: 0.000625\n",
      "Epoch [8464/20000], Loss: 873.4208374023438, Entropy 447.89691162109375, Learning Rate: 0.000625\n",
      "Epoch [8465/20000], Loss: 851.6610717773438, Entropy 445.20831298828125, Learning Rate: 0.000625\n",
      "Epoch [8466/20000], Loss: 863.461669921875, Entropy 447.9692077636719, Learning Rate: 0.000625\n",
      "Epoch [8467/20000], Loss: 873.2861328125, Entropy 444.8760070800781, Learning Rate: 0.000625\n",
      "Epoch [8468/20000], Loss: 901.8277587890625, Entropy 425.7811279296875, Learning Rate: 0.000625\n",
      "Epoch [8469/20000], Loss: 870.51513671875, Entropy 440.4480285644531, Learning Rate: 0.000625\n",
      "Epoch [8470/20000], Loss: 884.964111328125, Entropy 433.6162414550781, Learning Rate: 0.000625\n",
      "Epoch [8471/20000], Loss: 865.0751953125, Entropy 456.6341247558594, Learning Rate: 0.000625\n",
      "Epoch [8472/20000], Loss: 888.772705078125, Entropy 445.2791442871094, Learning Rate: 0.000625\n",
      "Epoch [8473/20000], Loss: 878.0926513671875, Entropy 430.7715148925781, Learning Rate: 0.000625\n",
      "Epoch [8474/20000], Loss: 843.5740966796875, Entropy 456.3313903808594, Learning Rate: 0.000625\n",
      "Epoch [8475/20000], Loss: 827.3778076171875, Entropy 450.9136657714844, Learning Rate: 0.000625\n",
      "Epoch [8476/20000], Loss: 836.42138671875, Entropy 433.5520324707031, Learning Rate: 0.000625\n",
      "Epoch [8477/20000], Loss: 879.288330078125, Entropy 450.0315856933594, Learning Rate: 0.000625\n",
      "Epoch [8478/20000], Loss: 851.02783203125, Entropy 441.2186584472656, Learning Rate: 0.000625\n",
      "Epoch [8479/20000], Loss: 912.5595703125, Entropy 451.6805419921875, Learning Rate: 0.000625\n",
      "Epoch [8480/20000], Loss: 841.460693359375, Entropy 455.9156188964844, Learning Rate: 0.000625\n",
      "Epoch [8481/20000], Loss: 868.993896484375, Entropy 435.6539611816406, Learning Rate: 0.000625\n",
      "Epoch [8482/20000], Loss: 829.9697265625, Entropy 462.6223449707031, Learning Rate: 0.000625\n",
      "Epoch [8483/20000], Loss: 822.2052001953125, Entropy 453.2213134765625, Learning Rate: 0.000625\n",
      "Epoch [8484/20000], Loss: 832.554931640625, Entropy 457.5427551269531, Learning Rate: 0.000625\n",
      "Epoch [8485/20000], Loss: 878.9722900390625, Entropy 450.2921142578125, Learning Rate: 0.000625\n",
      "Epoch [8486/20000], Loss: 858.8157348632812, Entropy 454.98944091796875, Learning Rate: 0.000625\n",
      "Epoch [8487/20000], Loss: 840.2576904296875, Entropy 450.3949890136719, Learning Rate: 0.000625\n",
      "Epoch [8488/20000], Loss: 868.4830322265625, Entropy 447.0635070800781, Learning Rate: 0.000625\n",
      "Epoch [8489/20000], Loss: 880.2434692382812, Entropy 451.06793212890625, Learning Rate: 0.000625\n",
      "Epoch [8490/20000], Loss: 852.614501953125, Entropy 444.0910339355469, Learning Rate: 0.000625\n",
      "Epoch [8491/20000], Loss: 866.808349609375, Entropy 449.3424987792969, Learning Rate: 0.000625\n",
      "Epoch [8492/20000], Loss: 902.7406005859375, Entropy 449.4661560058594, Learning Rate: 0.000625\n",
      "Epoch [8493/20000], Loss: 823.544189453125, Entropy 447.1036682128906, Learning Rate: 0.000625\n",
      "Epoch [8494/20000], Loss: 859.0538330078125, Entropy 448.8935546875, Learning Rate: 0.000625\n",
      "Epoch [8495/20000], Loss: 865.275146484375, Entropy 453.4219970703125, Learning Rate: 0.000625\n",
      "Epoch [8496/20000], Loss: 865.3433227539062, Entropy 443.03167724609375, Learning Rate: 0.000625\n",
      "Epoch [8497/20000], Loss: 855.6036987304688, Entropy 442.97406005859375, Learning Rate: 0.000625\n",
      "Epoch [8498/20000], Loss: 851.1688232421875, Entropy 445.6407470703125, Learning Rate: 0.000625\n",
      "Epoch [8499/20000], Loss: 864.9443359375, Entropy 447.5307312011719, Learning Rate: 0.000625\n",
      "Epoch [8500/20000], Loss: 868.9061279296875, Entropy 453.4686584472656, Learning Rate: 0.000625\n",
      "Epoch [8501/20000], Loss: 880.0155029296875, Entropy 435.2401123046875, Learning Rate: 0.000625\n",
      "Epoch [8502/20000], Loss: 921.3099365234375, Entropy 439.4064636230469, Learning Rate: 0.000625\n",
      "Epoch [8503/20000], Loss: 846.4075927734375, Entropy 456.6946716308594, Learning Rate: 0.000625\n",
      "Epoch [8504/20000], Loss: 861.339111328125, Entropy 458.1837463378906, Learning Rate: 0.000625\n",
      "Epoch [8505/20000], Loss: 874.2633056640625, Entropy 445.820068359375, Learning Rate: 0.000625\n",
      "Epoch [8506/20000], Loss: 856.0103759765625, Entropy 453.6728820800781, Learning Rate: 0.000625\n",
      "Epoch [8507/20000], Loss: 880.9679565429688, Entropy 450.04388427734375, Learning Rate: 0.000625\n",
      "Epoch [8508/20000], Loss: 877.9447021484375, Entropy 442.2099914550781, Learning Rate: 0.000625\n",
      "Epoch [8509/20000], Loss: 892.744384765625, Entropy 435.1197509765625, Learning Rate: 0.000625\n",
      "Epoch [8510/20000], Loss: 881.9268798828125, Entropy 440.5703125, Learning Rate: 0.000625\n",
      "Epoch [8511/20000], Loss: 808.2555541992188, Entropy 449.38800048828125, Learning Rate: 0.000625\n",
      "Epoch [8512/20000], Loss: 863.2342529296875, Entropy 460.6007080078125, Learning Rate: 0.000625\n",
      "Epoch [8513/20000], Loss: 827.54248046875, Entropy 464.6443786621094, Learning Rate: 0.000625\n",
      "Epoch [8514/20000], Loss: 843.7620849609375, Entropy 438.187255859375, Learning Rate: 0.000625\n",
      "Epoch [8515/20000], Loss: 862.6180419921875, Entropy 451.7213439941406, Learning Rate: 0.000625\n",
      "Epoch [8516/20000], Loss: 881.379638671875, Entropy 438.4078063964844, Learning Rate: 0.000625\n",
      "Epoch [8517/20000], Loss: 842.6610717773438, Entropy 445.68878173828125, Learning Rate: 0.000625\n",
      "Epoch [8518/20000], Loss: 858.3092041015625, Entropy 456.6163635253906, Learning Rate: 0.000625\n",
      "Epoch [8519/20000], Loss: 838.7430419921875, Entropy 457.2340393066406, Learning Rate: 0.000625\n",
      "Epoch [8520/20000], Loss: 846.6605224609375, Entropy 445.1800231933594, Learning Rate: 0.000625\n",
      "Epoch [8521/20000], Loss: 837.2135009765625, Entropy 441.4412841796875, Learning Rate: 0.000625\n",
      "Epoch [8522/20000], Loss: 890.3866577148438, Entropy 445.37164306640625, Learning Rate: 0.000625\n",
      "Epoch [8523/20000], Loss: 872.7597045898438, Entropy 429.66717529296875, Learning Rate: 0.000625\n",
      "Epoch [8524/20000], Loss: 855.3208618164062, Entropy 445.14788818359375, Learning Rate: 0.000625\n",
      "Epoch [8525/20000], Loss: 831.494384765625, Entropy 450.7838134765625, Learning Rate: 0.000625\n",
      "Epoch [8526/20000], Loss: 893.81298828125, Entropy 450.491943359375, Learning Rate: 0.000625\n",
      "Epoch [8527/20000], Loss: 880.1632080078125, Entropy 437.1382751464844, Learning Rate: 0.000625\n",
      "Epoch [8528/20000], Loss: 880.6871337890625, Entropy 444.9391174316406, Learning Rate: 0.000625\n",
      "Epoch [8529/20000], Loss: 855.7239379882812, Entropy 449.53997802734375, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8530/20000], Loss: 862.0836181640625, Entropy 452.3494567871094, Learning Rate: 0.000625\n",
      "Epoch [8531/20000], Loss: 892.8841552734375, Entropy 451.5911865234375, Learning Rate: 0.000625\n",
      "Epoch [8532/20000], Loss: 876.6254272460938, Entropy 449.32281494140625, Learning Rate: 0.000625\n",
      "Epoch [8533/20000], Loss: 879.0099487304688, Entropy 444.56365966796875, Learning Rate: 0.000625\n",
      "Epoch [8534/20000], Loss: 879.9524536132812, Entropy 447.51068115234375, Learning Rate: 0.000625\n",
      "Epoch [8535/20000], Loss: 853.9473266601562, Entropy 455.64300537109375, Learning Rate: 0.000625\n",
      "Epoch [8536/20000], Loss: 867.7332153320312, Entropy 456.08209228515625, Learning Rate: 0.000625\n",
      "Epoch [8537/20000], Loss: 906.8470458984375, Entropy 442.04833984375, Learning Rate: 0.000625\n",
      "Epoch [8538/20000], Loss: 874.1616821289062, Entropy 446.42535400390625, Learning Rate: 0.000625\n",
      "Epoch [8539/20000], Loss: 826.3787841796875, Entropy 444.2744445800781, Learning Rate: 0.000625\n",
      "Epoch [8540/20000], Loss: 793.4465942382812, Entropy 457.22552490234375, Learning Rate: 0.000625\n",
      "Epoch [8541/20000], Loss: 824.9371948242188, Entropy 462.02545166015625, Learning Rate: 0.000625\n",
      "Epoch [8542/20000], Loss: 904.372802734375, Entropy 440.1159973144531, Learning Rate: 0.000625\n",
      "Epoch [8543/20000], Loss: 837.672607421875, Entropy 450.8072204589844, Learning Rate: 0.000625\n",
      "Epoch [8544/20000], Loss: 861.2133178710938, Entropy 451.60357666015625, Learning Rate: 0.000625\n",
      "Epoch [8545/20000], Loss: 824.1279907226562, Entropy 453.64849853515625, Learning Rate: 0.000625\n",
      "Epoch [8546/20000], Loss: 836.1199951171875, Entropy 454.5537414550781, Learning Rate: 0.000625\n",
      "Epoch [8547/20000], Loss: 853.8043212890625, Entropy 448.654296875, Learning Rate: 0.000625\n",
      "Epoch [8548/20000], Loss: 859.037109375, Entropy 452.2525329589844, Learning Rate: 0.000625\n",
      "Epoch [8549/20000], Loss: 897.6513671875, Entropy 444.4045104980469, Learning Rate: 0.000625\n",
      "Epoch [8550/20000], Loss: 810.535400390625, Entropy 458.017333984375, Learning Rate: 0.000625\n",
      "Epoch [8551/20000], Loss: 873.874755859375, Entropy 438.9930419921875, Learning Rate: 0.000625\n",
      "Epoch [8552/20000], Loss: 857.556640625, Entropy 460.9936218261719, Learning Rate: 0.000625\n",
      "Epoch [8553/20000], Loss: 863.3197021484375, Entropy 454.4880065917969, Learning Rate: 0.000625\n",
      "Epoch [8554/20000], Loss: 866.0042724609375, Entropy 471.2041320800781, Learning Rate: 0.000625\n",
      "Epoch [8555/20000], Loss: 850.5471801757812, Entropy 449.09466552734375, Learning Rate: 0.000625\n",
      "Epoch [8556/20000], Loss: 880.2745361328125, Entropy 447.7947082519531, Learning Rate: 0.000625\n",
      "Epoch [8557/20000], Loss: 832.9057006835938, Entropy 443.84796142578125, Learning Rate: 0.000625\n",
      "Epoch [8558/20000], Loss: 871.9923095703125, Entropy 451.9317626953125, Learning Rate: 0.000625\n",
      "Epoch [8559/20000], Loss: 824.5450439453125, Entropy 446.096435546875, Learning Rate: 0.000625\n",
      "Epoch [8560/20000], Loss: 874.6483154296875, Entropy 439.8856201171875, Learning Rate: 0.000625\n",
      "Epoch [8561/20000], Loss: 872.8258056640625, Entropy 441.601318359375, Learning Rate: 0.000625\n",
      "Epoch [8562/20000], Loss: 866.7900390625, Entropy 438.4093933105469, Learning Rate: 0.000625\n",
      "Epoch [8563/20000], Loss: 867.3447875976562, Entropy 451.56890869140625, Learning Rate: 0.000625\n",
      "Epoch [8564/20000], Loss: 841.4952392578125, Entropy 452.642333984375, Learning Rate: 0.000625\n",
      "Epoch [8565/20000], Loss: 860.8685913085938, Entropy 456.67413330078125, Learning Rate: 0.000625\n",
      "Epoch [8566/20000], Loss: 858.37548828125, Entropy 449.1746520996094, Learning Rate: 0.000625\n",
      "Epoch [8567/20000], Loss: 869.6871337890625, Entropy 449.9268798828125, Learning Rate: 0.000625\n",
      "Epoch [8568/20000], Loss: 883.2105102539062, Entropy 441.03607177734375, Learning Rate: 0.000625\n",
      "Epoch [8569/20000], Loss: 887.3564453125, Entropy 447.7848205566406, Learning Rate: 0.000625\n",
      "Epoch [8570/20000], Loss: 883.8889770507812, Entropy 444.34722900390625, Learning Rate: 0.000625\n",
      "Epoch [8571/20000], Loss: 855.161865234375, Entropy 449.7928466796875, Learning Rate: 0.000625\n",
      "Epoch [8572/20000], Loss: 864.09521484375, Entropy 454.5271911621094, Learning Rate: 0.000625\n",
      "Epoch [8573/20000], Loss: 849.345703125, Entropy 444.2041320800781, Learning Rate: 0.000625\n",
      "Epoch [8574/20000], Loss: 894.7915649414062, Entropy 447.24920654296875, Learning Rate: 0.000625\n",
      "Epoch [8575/20000], Loss: 884.53466796875, Entropy 459.372802734375, Learning Rate: 0.000625\n",
      "Epoch [8576/20000], Loss: 842.5167846679688, Entropy 458.15386962890625, Learning Rate: 0.000625\n",
      "Epoch [8577/20000], Loss: 849.6727294921875, Entropy 441.2883605957031, Learning Rate: 0.000625\n",
      "Epoch [8578/20000], Loss: 879.68310546875, Entropy 444.3127746582031, Learning Rate: 0.000625\n",
      "Epoch [8579/20000], Loss: 862.394775390625, Entropy 452.1199035644531, Learning Rate: 0.000625\n",
      "Epoch [8580/20000], Loss: 861.6185913085938, Entropy 452.40289306640625, Learning Rate: 0.000625\n",
      "Epoch [8581/20000], Loss: 843.98095703125, Entropy 455.9539794921875, Learning Rate: 0.000625\n",
      "Epoch [8582/20000], Loss: 869.8922119140625, Entropy 445.0587463378906, Learning Rate: 0.000625\n",
      "Epoch [8583/20000], Loss: 861.9620361328125, Entropy 443.91748046875, Learning Rate: 0.000625\n",
      "Epoch [8584/20000], Loss: 859.7554931640625, Entropy 441.75927734375, Learning Rate: 0.000625\n",
      "Epoch [8585/20000], Loss: 848.7634887695312, Entropy 458.03619384765625, Learning Rate: 0.000625\n",
      "Epoch [8586/20000], Loss: 834.0810546875, Entropy 440.6470947265625, Learning Rate: 0.000625\n",
      "Epoch [8587/20000], Loss: 886.7392578125, Entropy 444.9010009765625, Learning Rate: 0.000625\n",
      "Epoch [8588/20000], Loss: 867.5169677734375, Entropy 439.8244323730469, Learning Rate: 0.000625\n",
      "Epoch [8589/20000], Loss: 920.50732421875, Entropy 463.0635070800781, Learning Rate: 0.000625\n",
      "Epoch [8590/20000], Loss: 867.95361328125, Entropy 435.9222106933594, Learning Rate: 0.000625\n",
      "Epoch [8591/20000], Loss: 877.899169921875, Entropy 437.2627258300781, Learning Rate: 0.000625\n",
      "Epoch [8592/20000], Loss: 890.0728759765625, Entropy 453.128662109375, Learning Rate: 0.000625\n",
      "Epoch [8593/20000], Loss: 848.09130859375, Entropy 444.5627136230469, Learning Rate: 0.000625\n",
      "Epoch [8594/20000], Loss: 895.9044189453125, Entropy 453.74462890625, Learning Rate: 0.000625\n",
      "Epoch [8595/20000], Loss: 883.3455810546875, Entropy 459.9268798828125, Learning Rate: 0.000625\n",
      "Epoch [8596/20000], Loss: 828.6151123046875, Entropy 452.8997802734375, Learning Rate: 0.000625\n",
      "Epoch [8597/20000], Loss: 894.3469848632812, Entropy 456.94683837890625, Learning Rate: 0.000625\n",
      "Epoch [8598/20000], Loss: 868.3890380859375, Entropy 449.5484313964844, Learning Rate: 0.000625\n",
      "Epoch [8599/20000], Loss: 876.4478759765625, Entropy 446.1048278808594, Learning Rate: 0.000625\n",
      "Epoch [8600/20000], Loss: 849.9140625, Entropy 459.7102966308594, Learning Rate: 0.000625\n",
      "Epoch [8601/20000], Loss: 832.9663696289062, Entropy 444.10980224609375, Learning Rate: 0.000625\n",
      "Epoch [8602/20000], Loss: 865.3271484375, Entropy 444.1963195800781, Learning Rate: 0.000625\n",
      "Epoch [8603/20000], Loss: 859.4364013671875, Entropy 450.1790466308594, Learning Rate: 0.000625\n",
      "Epoch [8604/20000], Loss: 888.8052978515625, Entropy 438.5862121582031, Learning Rate: 0.000625\n",
      "Epoch [8605/20000], Loss: 857.2357177734375, Entropy 441.9217834472656, Learning Rate: 0.000625\n",
      "Epoch [8606/20000], Loss: 860.776611328125, Entropy 456.9298400878906, Learning Rate: 0.000625\n",
      "Epoch [8607/20000], Loss: 845.415283203125, Entropy 448.7458190917969, Learning Rate: 0.000625\n",
      "Epoch [8608/20000], Loss: 890.4879150390625, Entropy 455.1802978515625, Learning Rate: 0.000625\n",
      "Epoch [8609/20000], Loss: 855.98388671875, Entropy 440.9357604980469, Learning Rate: 0.000625\n",
      "Epoch [8610/20000], Loss: 875.9370727539062, Entropy 452.96099853515625, Learning Rate: 0.000625\n",
      "Epoch [8611/20000], Loss: 865.5902099609375, Entropy 441.9635925292969, Learning Rate: 0.000625\n",
      "Epoch [8612/20000], Loss: 840.921630859375, Entropy 449.0386962890625, Learning Rate: 0.000625\n",
      "Epoch [8613/20000], Loss: 875.03076171875, Entropy 441.0193786621094, Learning Rate: 0.000625\n",
      "Epoch [8614/20000], Loss: 894.9232177734375, Entropy 448.16796875, Learning Rate: 0.000625\n",
      "Epoch [8615/20000], Loss: 830.328857421875, Entropy 466.1427917480469, Learning Rate: 0.000625\n",
      "Epoch [8616/20000], Loss: 862.2611083984375, Entropy 435.9403381347656, Learning Rate: 0.000625\n",
      "Epoch [8617/20000], Loss: 860.2816772460938, Entropy 448.43292236328125, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8618/20000], Loss: 832.18408203125, Entropy 451.7698669433594, Learning Rate: 0.000625\n",
      "Epoch [8619/20000], Loss: 880.072265625, Entropy 469.1029968261719, Learning Rate: 0.000625\n",
      "Epoch [8620/20000], Loss: 800.116943359375, Entropy 459.4926452636719, Learning Rate: 0.000625\n",
      "Epoch [8621/20000], Loss: 844.697265625, Entropy 447.7744140625, Learning Rate: 0.000625\n",
      "Epoch [8622/20000], Loss: 890.35400390625, Entropy 449.2731628417969, Learning Rate: 0.000625\n",
      "Epoch [8623/20000], Loss: 890.589599609375, Entropy 452.8760070800781, Learning Rate: 0.000625\n",
      "Epoch [8624/20000], Loss: 945.3857421875, Entropy 460.4167785644531, Learning Rate: 0.000625\n",
      "Epoch [8625/20000], Loss: 944.928955078125, Entropy 450.4500732421875, Learning Rate: 0.000625\n",
      "Epoch [8626/20000], Loss: 851.6644287109375, Entropy 457.5450744628906, Learning Rate: 0.000625\n",
      "Epoch [8627/20000], Loss: 833.0198974609375, Entropy 436.5467529296875, Learning Rate: 0.000625\n",
      "Epoch [8628/20000], Loss: 822.7098388671875, Entropy 442.5141296386719, Learning Rate: 0.000625\n",
      "Epoch [8629/20000], Loss: 961.1665649414062, Entropy 452.15338134765625, Learning Rate: 0.000625\n",
      "Epoch [8630/20000], Loss: 869.2865600585938, Entropy 463.27960205078125, Learning Rate: 0.000625\n",
      "Epoch [8631/20000], Loss: 845.134521484375, Entropy 452.9103088378906, Learning Rate: 0.000625\n",
      "Epoch [8632/20000], Loss: 875.434326171875, Entropy 451.2789611816406, Learning Rate: 0.000625\n",
      "Epoch [8633/20000], Loss: 877.994873046875, Entropy 449.0369873046875, Learning Rate: 0.000625\n",
      "Epoch [8634/20000], Loss: 881.8560791015625, Entropy 447.7562255859375, Learning Rate: 0.000625\n",
      "Epoch [8635/20000], Loss: 861.9619140625, Entropy 445.1544189453125, Learning Rate: 0.000625\n",
      "Epoch [8636/20000], Loss: 883.630126953125, Entropy 452.5370178222656, Learning Rate: 0.000625\n",
      "Epoch [8637/20000], Loss: 845.3363647460938, Entropy 452.00238037109375, Learning Rate: 0.000625\n",
      "Epoch [8638/20000], Loss: 890.2845458984375, Entropy 444.4645080566406, Learning Rate: 0.000625\n",
      "Epoch [8639/20000], Loss: 899.0325927734375, Entropy 445.167724609375, Learning Rate: 0.000625\n",
      "Epoch [8640/20000], Loss: 879.38720703125, Entropy 459.6318359375, Learning Rate: 0.000625\n",
      "Epoch [8641/20000], Loss: 898.2225341796875, Entropy 429.5305480957031, Learning Rate: 0.000625\n",
      "Epoch [8642/20000], Loss: 862.0465698242188, Entropy 453.24822998046875, Learning Rate: 0.000625\n",
      "Epoch [8643/20000], Loss: 835.1759643554688, Entropy 455.62701416015625, Learning Rate: 0.000625\n",
      "Epoch [8644/20000], Loss: 841.9119873046875, Entropy 445.3122863769531, Learning Rate: 0.000625\n",
      "Epoch [8645/20000], Loss: 877.6475830078125, Entropy 458.6160888671875, Learning Rate: 0.000625\n",
      "Epoch [8646/20000], Loss: 885.5824584960938, Entropy 453.30194091796875, Learning Rate: 0.000625\n",
      "Epoch [8647/20000], Loss: 849.644287109375, Entropy 436.9836730957031, Learning Rate: 0.000625\n",
      "Epoch [8648/20000], Loss: 829.960693359375, Entropy 466.2196044921875, Learning Rate: 0.000625\n",
      "Epoch [8649/20000], Loss: 859.6806640625, Entropy 456.7868957519531, Learning Rate: 0.000625\n",
      "Epoch [8650/20000], Loss: 851.9454345703125, Entropy 450.6940002441406, Learning Rate: 0.000625\n",
      "Epoch [8651/20000], Loss: 917.1805419921875, Entropy 442.4009704589844, Learning Rate: 0.000625\n",
      "Epoch [8652/20000], Loss: 860.9749755859375, Entropy 463.8065490722656, Learning Rate: 0.000625\n",
      "Epoch [8653/20000], Loss: 858.0496826171875, Entropy 458.4705505371094, Learning Rate: 0.000625\n",
      "Epoch [8654/20000], Loss: 864.2862548828125, Entropy 446.7309265136719, Learning Rate: 0.000625\n",
      "Epoch [8655/20000], Loss: 856.7083740234375, Entropy 450.3272705078125, Learning Rate: 0.000625\n",
      "Epoch [8656/20000], Loss: 890.25146484375, Entropy 445.8707580566406, Learning Rate: 0.000625\n",
      "Epoch [8657/20000], Loss: 861.0903930664062, Entropy 450.67218017578125, Learning Rate: 0.000625\n",
      "Epoch [8658/20000], Loss: 886.885986328125, Entropy 446.2914733886719, Learning Rate: 0.000625\n",
      "Epoch [8659/20000], Loss: 888.7332763671875, Entropy 436.6773376464844, Learning Rate: 0.000625\n",
      "Epoch [8660/20000], Loss: 866.7696533203125, Entropy 433.7897644042969, Learning Rate: 0.000625\n",
      "Epoch [8661/20000], Loss: 899.52880859375, Entropy 450.7169189453125, Learning Rate: 0.000625\n",
      "Epoch [8662/20000], Loss: 846.168212890625, Entropy 470.9189758300781, Learning Rate: 0.000625\n",
      "Epoch [8663/20000], Loss: 825.9907836914062, Entropy 453.80316162109375, Learning Rate: 0.000625\n",
      "Epoch [8664/20000], Loss: 820.4022216796875, Entropy 455.6798095703125, Learning Rate: 0.000625\n",
      "Epoch [8665/20000], Loss: 827.2120361328125, Entropy 454.9750671386719, Learning Rate: 0.000625\n",
      "Epoch [8666/20000], Loss: 897.4588012695312, Entropy 443.91802978515625, Learning Rate: 0.000625\n",
      "Epoch [8667/20000], Loss: 898.8242797851562, Entropy 447.61834716796875, Learning Rate: 0.000625\n",
      "Epoch [8668/20000], Loss: 866.077392578125, Entropy 451.5752258300781, Learning Rate: 0.000625\n",
      "Epoch [8669/20000], Loss: 852.9307250976562, Entropy 453.59234619140625, Learning Rate: 0.000625\n",
      "Epoch [8670/20000], Loss: 881.3287353515625, Entropy 463.5431213378906, Learning Rate: 0.000625\n",
      "Epoch [8671/20000], Loss: 849.377197265625, Entropy 453.89013671875, Learning Rate: 0.000625\n",
      "Epoch [8672/20000], Loss: 863.887451171875, Entropy 446.3805847167969, Learning Rate: 0.000625\n",
      "Epoch [8673/20000], Loss: 847.8643798828125, Entropy 439.4611511230469, Learning Rate: 0.000625\n",
      "Epoch [8674/20000], Loss: 851.297607421875, Entropy 447.931640625, Learning Rate: 0.000625\n",
      "Epoch [8675/20000], Loss: 847.3980102539062, Entropy 456.87213134765625, Learning Rate: 0.000625\n",
      "Epoch [8676/20000], Loss: 855.5548095703125, Entropy 441.2030334472656, Learning Rate: 0.000625\n",
      "Epoch [8677/20000], Loss: 863.9083251953125, Entropy 442.5592346191406, Learning Rate: 0.000625\n",
      "Epoch [8678/20000], Loss: 857.2080078125, Entropy 451.7774963378906, Learning Rate: 0.000625\n",
      "Epoch [8679/20000], Loss: 849.718505859375, Entropy 453.0400695800781, Learning Rate: 0.000625\n",
      "Epoch [8680/20000], Loss: 847.6577758789062, Entropy 445.65472412109375, Learning Rate: 0.000625\n",
      "Epoch [8681/20000], Loss: 884.2911376953125, Entropy 444.280029296875, Learning Rate: 0.000625\n",
      "Epoch [8682/20000], Loss: 877.9925537109375, Entropy 456.4578552246094, Learning Rate: 0.000625\n",
      "Epoch [8683/20000], Loss: 835.4209594726562, Entropy 454.63861083984375, Learning Rate: 0.000625\n",
      "Epoch [8684/20000], Loss: 830.0504150390625, Entropy 463.0985107421875, Learning Rate: 0.000625\n",
      "Epoch [8685/20000], Loss: 880.9478759765625, Entropy 458.0269470214844, Learning Rate: 0.000625\n",
      "Epoch [8686/20000], Loss: 846.228271484375, Entropy 446.951904296875, Learning Rate: 0.000625\n",
      "Epoch [8687/20000], Loss: 836.4558715820312, Entropy 445.58319091796875, Learning Rate: 0.000625\n",
      "Epoch [8688/20000], Loss: 848.0745849609375, Entropy 454.6112365722656, Learning Rate: 0.000625\n",
      "Epoch [8689/20000], Loss: 839.3729858398438, Entropy 438.21429443359375, Learning Rate: 0.000625\n",
      "Epoch [8690/20000], Loss: 850.61669921875, Entropy 443.0328674316406, Learning Rate: 0.000625\n",
      "Epoch [8691/20000], Loss: 833.5802001953125, Entropy 452.4820861816406, Learning Rate: 0.000625\n",
      "Epoch [8692/20000], Loss: 926.3555908203125, Entropy 447.9156799316406, Learning Rate: 0.000625\n",
      "Epoch [8693/20000], Loss: 882.8387451171875, Entropy 433.0709533691406, Learning Rate: 0.000625\n",
      "Epoch [8694/20000], Loss: 815.624755859375, Entropy 452.2705383300781, Learning Rate: 0.000625\n",
      "Epoch [8695/20000], Loss: 855.3443603515625, Entropy 456.5961608886719, Learning Rate: 0.000625\n",
      "Epoch [8696/20000], Loss: 865.3703002929688, Entropy 429.30487060546875, Learning Rate: 0.000625\n",
      "Epoch [8697/20000], Loss: 873.801025390625, Entropy 446.5885925292969, Learning Rate: 0.000625\n",
      "Epoch [8698/20000], Loss: 857.05712890625, Entropy 469.5509948730469, Learning Rate: 0.000625\n",
      "Epoch [8699/20000], Loss: 906.5771484375, Entropy 440.1496887207031, Learning Rate: 0.000625\n",
      "Epoch [8700/20000], Loss: 881.083984375, Entropy 454.656982421875, Learning Rate: 0.000625\n",
      "Epoch [8701/20000], Loss: 818.8131103515625, Entropy 453.582763671875, Learning Rate: 0.000625\n",
      "Epoch [8702/20000], Loss: 861.6290283203125, Entropy 452.5059814453125, Learning Rate: 0.000625\n",
      "Epoch [8703/20000], Loss: 904.7523193359375, Entropy 444.7892150878906, Learning Rate: 0.000625\n",
      "Epoch [8704/20000], Loss: 908.3924560546875, Entropy 443.1019287109375, Learning Rate: 0.000625\n",
      "Epoch [8705/20000], Loss: 873.7987060546875, Entropy 451.9195861816406, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8706/20000], Loss: 878.416015625, Entropy 456.7040100097656, Learning Rate: 0.000625\n",
      "Epoch [8707/20000], Loss: 864.9549560546875, Entropy 461.39404296875, Learning Rate: 0.000625\n",
      "Epoch [8708/20000], Loss: 871.41455078125, Entropy 449.2976379394531, Learning Rate: 0.000625\n",
      "Epoch [8709/20000], Loss: 843.7994384765625, Entropy 443.1329650878906, Learning Rate: 0.000625\n",
      "Epoch [8710/20000], Loss: 864.376220703125, Entropy 441.2208251953125, Learning Rate: 0.000625\n",
      "Epoch [8711/20000], Loss: 830.0867919921875, Entropy 460.7391357421875, Learning Rate: 0.000625\n",
      "Epoch [8712/20000], Loss: 845.93310546875, Entropy 436.2342834472656, Learning Rate: 0.000625\n",
      "Epoch [8713/20000], Loss: 842.6396484375, Entropy 460.9627990722656, Learning Rate: 0.000625\n",
      "Epoch [8714/20000], Loss: 869.866943359375, Entropy 445.1949157714844, Learning Rate: 0.000625\n",
      "Epoch [8715/20000], Loss: 875.2412109375, Entropy 457.9471130371094, Learning Rate: 0.000625\n",
      "Epoch [8716/20000], Loss: 903.653076171875, Entropy 446.90625, Learning Rate: 0.000625\n",
      "Epoch [8717/20000], Loss: 834.732666015625, Entropy 456.724365234375, Learning Rate: 0.000625\n",
      "Epoch [8718/20000], Loss: 834.5922241210938, Entropy 456.41888427734375, Learning Rate: 0.000625\n",
      "Epoch [8719/20000], Loss: 912.7635498046875, Entropy 457.32958984375, Learning Rate: 0.000625\n",
      "Epoch [8720/20000], Loss: 875.6002197265625, Entropy 449.7850646972656, Learning Rate: 0.000625\n",
      "Epoch [8721/20000], Loss: 843.2041015625, Entropy 447.7980041503906, Learning Rate: 0.000625\n",
      "Epoch [8722/20000], Loss: 843.992919921875, Entropy 458.9382629394531, Learning Rate: 0.000625\n",
      "Epoch [8723/20000], Loss: 860.615478515625, Entropy 460.5280456542969, Learning Rate: 0.000625\n",
      "Epoch [8724/20000], Loss: 809.6946411132812, Entropy 460.44451904296875, Learning Rate: 0.000625\n",
      "Epoch [8725/20000], Loss: 876.4478759765625, Entropy 451.3349609375, Learning Rate: 0.000625\n",
      "Epoch [8726/20000], Loss: 856.482177734375, Entropy 452.4064025878906, Learning Rate: 0.000625\n",
      "Epoch [8727/20000], Loss: 873.8333740234375, Entropy 446.8995361328125, Learning Rate: 0.000625\n",
      "Epoch [8728/20000], Loss: 874.3675537109375, Entropy 455.8435363769531, Learning Rate: 0.000625\n",
      "Epoch [8729/20000], Loss: 894.7546997070312, Entropy 452.51397705078125, Learning Rate: 0.000625\n",
      "Epoch [8730/20000], Loss: 833.8101806640625, Entropy 455.9332580566406, Learning Rate: 0.000625\n",
      "Epoch [8731/20000], Loss: 879.8162841796875, Entropy 450.7174377441406, Learning Rate: 0.000625\n",
      "Epoch [8732/20000], Loss: 859.0841064453125, Entropy 454.3343505859375, Learning Rate: 0.000625\n",
      "Epoch [8733/20000], Loss: 852.5988159179688, Entropy 458.04974365234375, Learning Rate: 0.000625\n",
      "Epoch [8734/20000], Loss: 820.432373046875, Entropy 460.2740478515625, Learning Rate: 0.000625\n",
      "Epoch [8735/20000], Loss: 856.9883422851562, Entropy 463.48724365234375, Learning Rate: 0.000625\n",
      "Epoch [8736/20000], Loss: 860.0234375, Entropy 462.7221374511719, Learning Rate: 0.000625\n",
      "Epoch [8737/20000], Loss: 861.1806640625, Entropy 462.2333984375, Learning Rate: 0.000625\n",
      "Epoch [8738/20000], Loss: 884.8419189453125, Entropy 449.6608581542969, Learning Rate: 0.000625\n",
      "Epoch [8739/20000], Loss: 874.8720703125, Entropy 453.4588928222656, Learning Rate: 0.000625\n",
      "Epoch [8740/20000], Loss: 889.0013427734375, Entropy 441.7932434082031, Learning Rate: 0.000625\n",
      "Epoch [8741/20000], Loss: 833.3345336914062, Entropy 450.78533935546875, Learning Rate: 0.000625\n",
      "Epoch [8742/20000], Loss: 806.095458984375, Entropy 448.0291442871094, Learning Rate: 0.000625\n",
      "Epoch [8743/20000], Loss: 861.1375732421875, Entropy 454.9183349609375, Learning Rate: 0.000625\n",
      "Epoch [8744/20000], Loss: 865.64892578125, Entropy 447.6402893066406, Learning Rate: 0.000625\n",
      "Epoch [8745/20000], Loss: 838.350830078125, Entropy 453.4418640136719, Learning Rate: 0.000625\n",
      "Epoch [8746/20000], Loss: 910.3868408203125, Entropy 449.8532409667969, Learning Rate: 0.000625\n",
      "Epoch [8747/20000], Loss: 805.14111328125, Entropy 459.6953125, Learning Rate: 0.000625\n",
      "Epoch [8748/20000], Loss: 843.8873291015625, Entropy 461.45849609375, Learning Rate: 0.000625\n",
      "Epoch [8749/20000], Loss: 834.3277587890625, Entropy 449.92529296875, Learning Rate: 0.000625\n",
      "Epoch [8750/20000], Loss: 856.3001708984375, Entropy 451.0003662109375, Learning Rate: 0.000625\n",
      "Epoch [8751/20000], Loss: 830.6449584960938, Entropy 463.52740478515625, Learning Rate: 0.000625\n",
      "Epoch [8752/20000], Loss: 946.42529296875, Entropy 448.6417236328125, Learning Rate: 0.000625\n",
      "Epoch [8753/20000], Loss: 866.1224975585938, Entropy 450.40533447265625, Learning Rate: 0.000625\n",
      "Epoch [8754/20000], Loss: 837.0103149414062, Entropy 453.31365966796875, Learning Rate: 0.000625\n",
      "Epoch [8755/20000], Loss: 878.5685424804688, Entropy 444.31085205078125, Learning Rate: 0.000625\n",
      "Epoch [8756/20000], Loss: 867.03271484375, Entropy 451.9769287109375, Learning Rate: 0.000625\n",
      "Epoch [8757/20000], Loss: 880.6697998046875, Entropy 453.3406982421875, Learning Rate: 0.000625\n",
      "Epoch [8758/20000], Loss: 874.578857421875, Entropy 462.294921875, Learning Rate: 0.000625\n",
      "Epoch [8759/20000], Loss: 861.7100830078125, Entropy 456.4352111816406, Learning Rate: 0.000625\n",
      "Epoch [8760/20000], Loss: 873.0249633789062, Entropy 452.53375244140625, Learning Rate: 0.000625\n",
      "Epoch [8761/20000], Loss: 847.7772216796875, Entropy 453.6335754394531, Learning Rate: 0.000625\n",
      "Epoch [8762/20000], Loss: 869.6149291992188, Entropy 460.57952880859375, Learning Rate: 0.000625\n",
      "Epoch [8763/20000], Loss: 860.7909545898438, Entropy 452.78326416015625, Learning Rate: 0.000625\n",
      "Epoch [8764/20000], Loss: 794.271484375, Entropy 450.5408935546875, Learning Rate: 0.000625\n",
      "Epoch [8765/20000], Loss: 873.6142578125, Entropy 431.1365966796875, Learning Rate: 0.000625\n",
      "Epoch [8766/20000], Loss: 830.3128662109375, Entropy 458.181640625, Learning Rate: 0.000625\n",
      "Epoch [8767/20000], Loss: 842.3551025390625, Entropy 456.8094787597656, Learning Rate: 0.000625\n",
      "Epoch [8768/20000], Loss: 870.1756591796875, Entropy 445.054443359375, Learning Rate: 0.000625\n",
      "Epoch [8769/20000], Loss: 918.279296875, Entropy 453.1090393066406, Learning Rate: 0.000625\n",
      "Epoch [8770/20000], Loss: 853.9480590820312, Entropy 461.94390869140625, Learning Rate: 0.000625\n",
      "Epoch [8771/20000], Loss: 882.9859619140625, Entropy 443.4554138183594, Learning Rate: 0.000625\n",
      "Epoch [8772/20000], Loss: 866.773681640625, Entropy 459.9926452636719, Learning Rate: 0.000625\n",
      "Epoch [8773/20000], Loss: 895.0319213867188, Entropy 438.78521728515625, Learning Rate: 0.000625\n",
      "Epoch [8774/20000], Loss: 877.1864624023438, Entropy 442.54693603515625, Learning Rate: 0.000625\n",
      "Epoch [8775/20000], Loss: 881.000244140625, Entropy 447.35498046875, Learning Rate: 0.000625\n",
      "Epoch [8776/20000], Loss: 886.4417724609375, Entropy 441.00244140625, Learning Rate: 0.000625\n",
      "Epoch [8777/20000], Loss: 866.3368530273438, Entropy 452.52435302734375, Learning Rate: 0.000625\n",
      "Epoch [8778/20000], Loss: 846.9261474609375, Entropy 454.6751403808594, Learning Rate: 0.000625\n",
      "Epoch [8779/20000], Loss: 862.7487182617188, Entropy 446.61614990234375, Learning Rate: 0.000625\n",
      "Epoch [8780/20000], Loss: 837.4165649414062, Entropy 458.39398193359375, Learning Rate: 0.000625\n",
      "Epoch [8781/20000], Loss: 847.9445190429688, Entropy 454.09014892578125, Learning Rate: 0.000625\n",
      "Epoch [8782/20000], Loss: 863.8612060546875, Entropy 456.7723693847656, Learning Rate: 0.000625\n",
      "Epoch [8783/20000], Loss: 850.0452880859375, Entropy 456.2928771972656, Learning Rate: 0.000625\n",
      "Epoch [8784/20000], Loss: 870.0479736328125, Entropy 452.2873840332031, Learning Rate: 0.000625\n",
      "Epoch [8785/20000], Loss: 874.448486328125, Entropy 459.6664733886719, Learning Rate: 0.000625\n",
      "Epoch [8786/20000], Loss: 849.4930419921875, Entropy 465.0356140136719, Learning Rate: 0.000625\n",
      "Epoch [8787/20000], Loss: 896.3634643554688, Entropy 444.96405029296875, Learning Rate: 0.000625\n",
      "Epoch [8788/20000], Loss: 865.0930786132812, Entropy 453.48065185546875, Learning Rate: 0.000625\n",
      "Epoch [8789/20000], Loss: 850.6067504882812, Entropy 461.03350830078125, Learning Rate: 0.000625\n",
      "Epoch [8790/20000], Loss: 901.6253662109375, Entropy 444.4440612792969, Learning Rate: 0.000625\n",
      "Epoch [8791/20000], Loss: 875.2103271484375, Entropy 443.3305358886719, Learning Rate: 0.000625\n",
      "Epoch [8792/20000], Loss: 907.9172973632812, Entropy 453.26458740234375, Learning Rate: 0.000625\n",
      "Epoch [8793/20000], Loss: 894.9716796875, Entropy 449.6511535644531, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8794/20000], Loss: 870.4650268554688, Entropy 451.82476806640625, Learning Rate: 0.000625\n",
      "Epoch [8795/20000], Loss: 859.366943359375, Entropy 442.7117004394531, Learning Rate: 0.000625\n",
      "Epoch [8796/20000], Loss: 898.5996704101562, Entropy 442.02044677734375, Learning Rate: 0.000625\n",
      "Epoch [8797/20000], Loss: 867.451904296875, Entropy 453.8931884765625, Learning Rate: 0.000625\n",
      "Epoch [8798/20000], Loss: 893.3268432617188, Entropy 448.49822998046875, Learning Rate: 0.000625\n",
      "Epoch [8799/20000], Loss: 901.0946655273438, Entropy 455.79547119140625, Learning Rate: 0.000625\n",
      "Epoch [8800/20000], Loss: 829.552001953125, Entropy 462.7467956542969, Learning Rate: 0.000625\n",
      "Epoch [8801/20000], Loss: 876.2760009765625, Entropy 457.4244079589844, Learning Rate: 0.000625\n",
      "Epoch [8802/20000], Loss: 830.1737060546875, Entropy 452.9901428222656, Learning Rate: 0.000625\n",
      "Epoch [8803/20000], Loss: 889.5797119140625, Entropy 456.7558898925781, Learning Rate: 0.000625\n",
      "Epoch [8804/20000], Loss: 871.5528564453125, Entropy 441.9171142578125, Learning Rate: 0.000625\n",
      "Epoch [8805/20000], Loss: 843.296142578125, Entropy 460.5278015136719, Learning Rate: 0.000625\n",
      "Epoch [8806/20000], Loss: 899.9784545898438, Entropy 455.00396728515625, Learning Rate: 0.000625\n",
      "Epoch [8807/20000], Loss: 861.771484375, Entropy 461.3775634765625, Learning Rate: 0.000625\n",
      "Epoch [8808/20000], Loss: 918.9215087890625, Entropy 431.0290222167969, Learning Rate: 0.000625\n",
      "Epoch [8809/20000], Loss: 826.462158203125, Entropy 466.2685852050781, Learning Rate: 0.000625\n",
      "Epoch [8810/20000], Loss: 861.26904296875, Entropy 456.1274108886719, Learning Rate: 0.000625\n",
      "Epoch [8811/20000], Loss: 953.7142944335938, Entropy 448.70843505859375, Learning Rate: 0.000625\n",
      "Epoch [8812/20000], Loss: 882.4893798828125, Entropy 443.9878845214844, Learning Rate: 0.000625\n",
      "Epoch [8813/20000], Loss: 977.7559814453125, Entropy 455.1006164550781, Learning Rate: 0.000625\n",
      "Epoch [8814/20000], Loss: 897.3131103515625, Entropy 448.2780456542969, Learning Rate: 0.000625\n",
      "Epoch [8815/20000], Loss: 877.3303833007812, Entropy 458.44671630859375, Learning Rate: 0.000625\n",
      "Epoch [8816/20000], Loss: 844.6184692382812, Entropy 443.25628662109375, Learning Rate: 0.000625\n",
      "Epoch [8817/20000], Loss: 900.416015625, Entropy 457.9001770019531, Learning Rate: 0.000625\n",
      "Epoch [8818/20000], Loss: 881.3958129882812, Entropy 452.54290771484375, Learning Rate: 0.000625\n",
      "Epoch [8819/20000], Loss: 835.7053833007812, Entropy 468.93963623046875, Learning Rate: 0.000625\n",
      "Epoch [8820/20000], Loss: 829.5255126953125, Entropy 448.5743408203125, Learning Rate: 0.000625\n",
      "Epoch [8821/20000], Loss: 874.408203125, Entropy 451.1793212890625, Learning Rate: 0.000625\n",
      "Epoch [8822/20000], Loss: 934.8485107421875, Entropy 439.0601806640625, Learning Rate: 0.000625\n",
      "Epoch [8823/20000], Loss: 831.3331298828125, Entropy 470.5668640136719, Learning Rate: 0.000625\n",
      "Epoch [8824/20000], Loss: 918.8148193359375, Entropy 449.2442932128906, Learning Rate: 0.000625\n",
      "Epoch [8825/20000], Loss: 847.6917724609375, Entropy 450.6604309082031, Learning Rate: 0.000625\n",
      "Epoch [8826/20000], Loss: 863.624755859375, Entropy 454.5127258300781, Learning Rate: 0.000625\n",
      "Epoch [8827/20000], Loss: 859.984619140625, Entropy 445.972412109375, Learning Rate: 0.000625\n",
      "Epoch [8828/20000], Loss: 945.974365234375, Entropy 451.5336608886719, Learning Rate: 0.000625\n",
      "Epoch [8829/20000], Loss: 871.0338134765625, Entropy 453.7549133300781, Learning Rate: 0.000625\n",
      "Epoch [8830/20000], Loss: 905.0919189453125, Entropy 446.1647644042969, Learning Rate: 0.000625\n",
      "Epoch [8831/20000], Loss: 833.609619140625, Entropy 460.095458984375, Learning Rate: 0.000625\n",
      "Epoch [8832/20000], Loss: 832.1289672851562, Entropy 460.18695068359375, Learning Rate: 0.000625\n",
      "Epoch [8833/20000], Loss: 861.5694580078125, Entropy 453.2645263671875, Learning Rate: 0.000625\n",
      "Epoch [8834/20000], Loss: 873.9168701171875, Entropy 452.3396911621094, Learning Rate: 0.000625\n",
      "Epoch [8835/20000], Loss: 881.7521362304688, Entropy 457.94842529296875, Learning Rate: 0.000625\n",
      "Epoch [8836/20000], Loss: 846.037353515625, Entropy 445.2432861328125, Learning Rate: 0.000625\n",
      "Epoch [8837/20000], Loss: 834.3514404296875, Entropy 451.7750549316406, Learning Rate: 0.000625\n",
      "Epoch [8838/20000], Loss: 875.3477783203125, Entropy 450.0252990722656, Learning Rate: 0.000625\n",
      "Epoch [8839/20000], Loss: 871.2310791015625, Entropy 464.4794006347656, Learning Rate: 0.000625\n",
      "Epoch [8840/20000], Loss: 843.8848266601562, Entropy 459.62152099609375, Learning Rate: 0.000625\n",
      "Epoch [8841/20000], Loss: 873.0870361328125, Entropy 451.2773742675781, Learning Rate: 0.000625\n",
      "Epoch [8842/20000], Loss: 875.1492919921875, Entropy 447.404296875, Learning Rate: 0.000625\n",
      "Epoch [8843/20000], Loss: 828.56689453125, Entropy 451.8104553222656, Learning Rate: 0.000625\n",
      "Epoch [8844/20000], Loss: 876.463134765625, Entropy 447.7192077636719, Learning Rate: 0.000625\n",
      "Epoch [8845/20000], Loss: 821.2066650390625, Entropy 455.9678955078125, Learning Rate: 0.000625\n",
      "Epoch [8846/20000], Loss: 828.575927734375, Entropy 445.810546875, Learning Rate: 0.000625\n",
      "Epoch [8847/20000], Loss: 848.9468383789062, Entropy 445.75811767578125, Learning Rate: 0.000625\n",
      "Epoch [8848/20000], Loss: 868.081298828125, Entropy 451.3746337890625, Learning Rate: 0.000625\n",
      "Epoch [8849/20000], Loss: 853.871826171875, Entropy 460.2618713378906, Learning Rate: 0.000625\n",
      "Epoch [8850/20000], Loss: 905.1041870117188, Entropy 460.30999755859375, Learning Rate: 0.000625\n",
      "Epoch [8851/20000], Loss: 834.6358032226562, Entropy 453.18255615234375, Learning Rate: 0.000625\n",
      "Epoch [8852/20000], Loss: 923.346435546875, Entropy 448.2892761230469, Learning Rate: 0.000625\n",
      "Epoch [8853/20000], Loss: 848.4217529296875, Entropy 459.8111877441406, Learning Rate: 0.000625\n",
      "Epoch [8854/20000], Loss: 900.9576416015625, Entropy 438.3023681640625, Learning Rate: 0.000625\n",
      "Epoch [8855/20000], Loss: 810.73046875, Entropy 452.0130310058594, Learning Rate: 0.000625\n",
      "Epoch [8856/20000], Loss: 856.039794921875, Entropy 456.4638671875, Learning Rate: 0.000625\n",
      "Epoch [8857/20000], Loss: 834.3413696289062, Entropy 451.20904541015625, Learning Rate: 0.000625\n",
      "Epoch [8858/20000], Loss: 896.1019287109375, Entropy 450.8227233886719, Learning Rate: 0.000625\n",
      "Epoch [8859/20000], Loss: 887.7537841796875, Entropy 447.2846374511719, Learning Rate: 0.000625\n",
      "Epoch [8860/20000], Loss: 857.0269165039062, Entropy 462.05084228515625, Learning Rate: 0.000625\n",
      "Epoch [8861/20000], Loss: 873.505126953125, Entropy 439.454833984375, Learning Rate: 0.000625\n",
      "Epoch [8862/20000], Loss: 832.1567993164062, Entropy 457.16656494140625, Learning Rate: 0.000625\n",
      "Epoch [8863/20000], Loss: 834.4425048828125, Entropy 456.5992126464844, Learning Rate: 0.000625\n",
      "Epoch [8864/20000], Loss: 845.0508422851562, Entropy 454.01361083984375, Learning Rate: 0.000625\n",
      "Epoch [8865/20000], Loss: 887.66064453125, Entropy 460.0575256347656, Learning Rate: 0.000625\n",
      "Epoch [8866/20000], Loss: 886.02978515625, Entropy 444.4786682128906, Learning Rate: 0.000625\n",
      "Epoch [8867/20000], Loss: 832.4312744140625, Entropy 452.8372802734375, Learning Rate: 0.000625\n",
      "Epoch [8868/20000], Loss: 867.7691040039062, Entropy 448.38275146484375, Learning Rate: 0.000625\n",
      "Epoch [8869/20000], Loss: 860.1806640625, Entropy 438.3220520019531, Learning Rate: 0.000625\n",
      "Epoch [8870/20000], Loss: 879.70556640625, Entropy 456.5021667480469, Learning Rate: 0.000625\n",
      "Epoch [8871/20000], Loss: 847.0804443359375, Entropy 463.1077575683594, Learning Rate: 0.000625\n",
      "Epoch [8872/20000], Loss: 851.6195068359375, Entropy 448.8305358886719, Learning Rate: 0.000625\n",
      "Epoch [8873/20000], Loss: 861.23095703125, Entropy 468.2545166015625, Learning Rate: 0.000625\n",
      "Epoch [8874/20000], Loss: 929.6929931640625, Entropy 438.1105041503906, Learning Rate: 0.000625\n",
      "Epoch [8875/20000], Loss: 844.9473876953125, Entropy 450.3963317871094, Learning Rate: 0.000625\n",
      "Epoch [8876/20000], Loss: 881.2640380859375, Entropy 448.1499938964844, Learning Rate: 0.000625\n",
      "Epoch [8877/20000], Loss: 874.3346557617188, Entropy 443.06011962890625, Learning Rate: 0.000625\n",
      "Epoch [8878/20000], Loss: 867.4808959960938, Entropy 440.59100341796875, Learning Rate: 0.000625\n",
      "Epoch [8879/20000], Loss: 859.88916015625, Entropy 448.4134521484375, Learning Rate: 0.000625\n",
      "Epoch [8880/20000], Loss: 865.646484375, Entropy 456.1448059082031, Learning Rate: 0.000625\n",
      "Epoch [8881/20000], Loss: 907.4691162109375, Entropy 440.969482421875, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8882/20000], Loss: 870.6021728515625, Entropy 449.3433532714844, Learning Rate: 0.000625\n",
      "Epoch [8883/20000], Loss: 852.1485595703125, Entropy 458.5816955566406, Learning Rate: 0.000625\n",
      "Epoch [8884/20000], Loss: 915.8936767578125, Entropy 441.2337341308594, Learning Rate: 0.000625\n",
      "Epoch [8885/20000], Loss: 876.00439453125, Entropy 447.6518249511719, Learning Rate: 0.000625\n",
      "Epoch [8886/20000], Loss: 857.769775390625, Entropy 457.4812927246094, Learning Rate: 0.000625\n",
      "Epoch [8887/20000], Loss: 872.4508056640625, Entropy 442.8323974609375, Learning Rate: 0.000625\n",
      "Epoch [8888/20000], Loss: 865.9248046875, Entropy 452.5469055175781, Learning Rate: 0.000625\n",
      "Epoch [8889/20000], Loss: 852.595458984375, Entropy 448.79150390625, Learning Rate: 0.000625\n",
      "Epoch [8890/20000], Loss: 837.419677734375, Entropy 459.7630615234375, Learning Rate: 0.000625\n",
      "Epoch [8891/20000], Loss: 847.6946411132812, Entropy 460.09197998046875, Learning Rate: 0.000625\n",
      "Epoch [8892/20000], Loss: 811.6373291015625, Entropy 467.9479675292969, Learning Rate: 0.000625\n",
      "Epoch [8893/20000], Loss: 851.915771484375, Entropy 456.9354553222656, Learning Rate: 0.000625\n",
      "Epoch [8894/20000], Loss: 859.9505004882812, Entropy 463.75396728515625, Learning Rate: 0.000625\n",
      "Epoch [8895/20000], Loss: 850.3807983398438, Entropy 454.40289306640625, Learning Rate: 0.000625\n",
      "Epoch [8896/20000], Loss: 852.4697265625, Entropy 463.8450012207031, Learning Rate: 0.000625\n",
      "Epoch [8897/20000], Loss: 864.6054077148438, Entropy 454.94329833984375, Learning Rate: 0.000625\n",
      "Epoch [8898/20000], Loss: 864.316650390625, Entropy 449.3189392089844, Learning Rate: 0.000625\n",
      "Epoch [8899/20000], Loss: 847.1541748046875, Entropy 460.9552917480469, Learning Rate: 0.000625\n",
      "Epoch [8900/20000], Loss: 886.473876953125, Entropy 469.58740234375, Learning Rate: 0.000625\n",
      "Epoch [8901/20000], Loss: 902.4915771484375, Entropy 454.6195068359375, Learning Rate: 0.000625\n",
      "Epoch [8902/20000], Loss: 854.5726318359375, Entropy 455.9170227050781, Learning Rate: 0.000625\n",
      "Epoch [8903/20000], Loss: 867.8994750976562, Entropy 452.24615478515625, Learning Rate: 0.000625\n",
      "Epoch [8904/20000], Loss: 838.1761474609375, Entropy 448.6944580078125, Learning Rate: 0.000625\n",
      "Epoch [8905/20000], Loss: 863.7998657226562, Entropy 447.88983154296875, Learning Rate: 0.000625\n",
      "Epoch [8906/20000], Loss: 880.1422119140625, Entropy 445.829833984375, Learning Rate: 0.000625\n",
      "Epoch [8907/20000], Loss: 881.7564697265625, Entropy 452.4901428222656, Learning Rate: 0.000625\n",
      "Epoch [8908/20000], Loss: 849.439208984375, Entropy 445.6271667480469, Learning Rate: 0.000625\n",
      "Epoch [8909/20000], Loss: 867.1974487304688, Entropy 439.84320068359375, Learning Rate: 0.000625\n",
      "Epoch [8910/20000], Loss: 853.2088623046875, Entropy 457.6295166015625, Learning Rate: 0.000625\n",
      "Epoch [8911/20000], Loss: 820.712890625, Entropy 460.1734619140625, Learning Rate: 0.000625\n",
      "Epoch [8912/20000], Loss: 866.1488647460938, Entropy 436.48529052734375, Learning Rate: 0.000625\n",
      "Epoch [8913/20000], Loss: 878.019775390625, Entropy 465.0889587402344, Learning Rate: 0.000625\n",
      "Epoch [8914/20000], Loss: 867.5533447265625, Entropy 460.0110778808594, Learning Rate: 0.000625\n",
      "Epoch [8915/20000], Loss: 904.9722900390625, Entropy 460.2677917480469, Learning Rate: 0.000625\n",
      "Epoch [8916/20000], Loss: 844.27880859375, Entropy 457.2564697265625, Learning Rate: 0.000625\n",
      "Epoch [8917/20000], Loss: 867.964599609375, Entropy 460.775390625, Learning Rate: 0.000625\n",
      "Epoch [8918/20000], Loss: 864.9019775390625, Entropy 458.2349853515625, Learning Rate: 0.000625\n",
      "Epoch [8919/20000], Loss: 881.277099609375, Entropy 447.99462890625, Learning Rate: 0.000625\n",
      "Epoch [8920/20000], Loss: 883.416015625, Entropy 455.3103332519531, Learning Rate: 0.000625\n",
      "Epoch [8921/20000], Loss: 857.865234375, Entropy 440.0774230957031, Learning Rate: 0.000625\n",
      "Epoch [8922/20000], Loss: 883.4431762695312, Entropy 456.20318603515625, Learning Rate: 0.000625\n",
      "Epoch [8923/20000], Loss: 817.8245239257812, Entropy 458.68414306640625, Learning Rate: 0.000625\n",
      "Epoch [8924/20000], Loss: 904.7979736328125, Entropy 439.71875, Learning Rate: 0.000625\n",
      "Epoch [8925/20000], Loss: 872.2061767578125, Entropy 442.7898864746094, Learning Rate: 0.000625\n",
      "Epoch [8926/20000], Loss: 823.6715087890625, Entropy 453.8975830078125, Learning Rate: 0.000625\n",
      "Epoch [8927/20000], Loss: 851.5054931640625, Entropy 453.1250305175781, Learning Rate: 0.000625\n",
      "Epoch [8928/20000], Loss: 837.990478515625, Entropy 464.167724609375, Learning Rate: 0.000625\n",
      "Epoch [8929/20000], Loss: 880.1986694335938, Entropy 450.36944580078125, Learning Rate: 0.000625\n",
      "Epoch [8930/20000], Loss: 860.0645751953125, Entropy 440.9078674316406, Learning Rate: 0.000625\n",
      "Epoch [8931/20000], Loss: 882.3868408203125, Entropy 448.0710754394531, Learning Rate: 0.000625\n",
      "Epoch [8932/20000], Loss: 842.5166015625, Entropy 460.6578063964844, Learning Rate: 0.000625\n",
      "Epoch [8933/20000], Loss: 825.4222412109375, Entropy 461.1854553222656, Learning Rate: 0.000625\n",
      "Epoch [8934/20000], Loss: 819.766357421875, Entropy 459.2639465332031, Learning Rate: 0.000625\n",
      "Epoch [8935/20000], Loss: 866.32421875, Entropy 446.4527282714844, Learning Rate: 0.000625\n",
      "Epoch [8936/20000], Loss: 864.6559448242188, Entropy 465.58624267578125, Learning Rate: 0.000625\n",
      "Epoch [8937/20000], Loss: 839.73046875, Entropy 450.2899169921875, Learning Rate: 0.000625\n",
      "Epoch [8938/20000], Loss: 842.803955078125, Entropy 445.4392395019531, Learning Rate: 0.000625\n",
      "Epoch [8939/20000], Loss: 839.9039306640625, Entropy 455.9831848144531, Learning Rate: 0.000625\n",
      "Epoch [8940/20000], Loss: 871.9865112304688, Entropy 447.20330810546875, Learning Rate: 0.000625\n",
      "Epoch [8941/20000], Loss: 882.866943359375, Entropy 460.8693542480469, Learning Rate: 0.000625\n",
      "Epoch [8942/20000], Loss: 853.78271484375, Entropy 463.3647155761719, Learning Rate: 0.000625\n",
      "Epoch [8943/20000], Loss: 809.4300537109375, Entropy 463.3975830078125, Learning Rate: 0.000625\n",
      "Epoch [8944/20000], Loss: 870.25537109375, Entropy 451.219482421875, Learning Rate: 0.000625\n",
      "Epoch [8945/20000], Loss: 853.256591796875, Entropy 455.6798400878906, Learning Rate: 0.000625\n",
      "Epoch [8946/20000], Loss: 833.42041015625, Entropy 451.6692810058594, Learning Rate: 0.000625\n",
      "Epoch [8947/20000], Loss: 889.6223754882812, Entropy 452.32733154296875, Learning Rate: 0.000625\n",
      "Epoch [8948/20000], Loss: 831.7537231445312, Entropy 463.80950927734375, Learning Rate: 0.000625\n",
      "Epoch [8949/20000], Loss: 870.75439453125, Entropy 454.5286560058594, Learning Rate: 0.000625\n",
      "Epoch [8950/20000], Loss: 872.8358154296875, Entropy 442.2083435058594, Learning Rate: 0.000625\n",
      "Epoch [8951/20000], Loss: 873.627685546875, Entropy 461.2073669433594, Learning Rate: 0.000625\n",
      "Epoch [8952/20000], Loss: 853.7371826171875, Entropy 441.0828552246094, Learning Rate: 0.000625\n",
      "Epoch [8953/20000], Loss: 872.490234375, Entropy 441.9149169921875, Learning Rate: 0.000625\n",
      "Epoch [8954/20000], Loss: 817.05810546875, Entropy 460.6117858886719, Learning Rate: 0.000625\n",
      "Epoch [8955/20000], Loss: 850.0516357421875, Entropy 459.1751403808594, Learning Rate: 0.000625\n",
      "Epoch [8956/20000], Loss: 795.3417358398438, Entropy 465.28350830078125, Learning Rate: 0.000625\n",
      "Epoch [8957/20000], Loss: 885.89501953125, Entropy 454.050537109375, Learning Rate: 0.000625\n",
      "Epoch [8958/20000], Loss: 876.1281127929688, Entropy 444.40191650390625, Learning Rate: 0.000625\n",
      "Epoch [8959/20000], Loss: 887.669189453125, Entropy 443.5354919433594, Learning Rate: 0.000625\n",
      "Epoch [8960/20000], Loss: 873.3224487304688, Entropy 446.28082275390625, Learning Rate: 0.000625\n",
      "Epoch [8961/20000], Loss: 843.563232421875, Entropy 464.2618713378906, Learning Rate: 0.000625\n",
      "Epoch [8962/20000], Loss: 862.7821044921875, Entropy 458.2886657714844, Learning Rate: 0.000625\n",
      "Epoch [8963/20000], Loss: 883.7623901367188, Entropy 453.22100830078125, Learning Rate: 0.000625\n",
      "Epoch [8964/20000], Loss: 844.3795166015625, Entropy 449.1837463378906, Learning Rate: 0.000625\n",
      "Epoch [8965/20000], Loss: 888.7979736328125, Entropy 434.0208435058594, Learning Rate: 0.000625\n",
      "Epoch [8966/20000], Loss: 842.7464599609375, Entropy 455.502685546875, Learning Rate: 0.000625\n",
      "Epoch [8967/20000], Loss: 861.66455078125, Entropy 467.2566833496094, Learning Rate: 0.000625\n",
      "Epoch [8968/20000], Loss: 877.367919921875, Entropy 457.1326904296875, Learning Rate: 0.000625\n",
      "Epoch [8969/20000], Loss: 842.0015869140625, Entropy 455.2130432128906, Learning Rate: 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8970/20000], Loss: 866.2066650390625, Entropy 455.6431579589844, Learning Rate: 0.000625\n",
      "Epoch [8971/20000], Loss: 855.4454345703125, Entropy 459.3671875, Learning Rate: 0.000625\n",
      "Epoch [8972/20000], Loss: 893.0537109375, Entropy 461.5598449707031, Learning Rate: 0.000625\n",
      "Epoch [8973/20000], Loss: 836.5657348632812, Entropy 462.09381103515625, Learning Rate: 0.000625\n",
      "Epoch [8974/20000], Loss: 886.3370361328125, Entropy 451.4966735839844, Learning Rate: 0.000625\n",
      "Epoch [8975/20000], Loss: 891.6444091796875, Entropy 450.7652282714844, Learning Rate: 0.000625\n",
      "Epoch [8976/20000], Loss: 873.2396240234375, Entropy 449.5874938964844, Learning Rate: 0.000625\n",
      "Epoch [8977/20000], Loss: 805.7490844726562, Entropy 461.60089111328125, Learning Rate: 0.000625\n",
      "Epoch [8978/20000], Loss: 834.5626220703125, Entropy 454.9996032714844, Learning Rate: 0.000625\n",
      "Epoch [8979/20000], Loss: 867.3624267578125, Entropy 454.4664001464844, Learning Rate: 0.000625\n",
      "Epoch [8980/20000], Loss: 871.3345336914062, Entropy 460.44476318359375, Learning Rate: 0.000625\n",
      "Epoch [8981/20000], Loss: 855.357666015625, Entropy 447.0167236328125, Learning Rate: 0.000625\n",
      "Epoch [8982/20000], Loss: 881.8545532226562, Entropy 440.46234130859375, Learning Rate: 0.000625\n",
      "Epoch [8983/20000], Loss: 799.7909545898438, Entropy 459.46429443359375, Learning Rate: 0.000625\n",
      "Epoch [8984/20000], Loss: 853.4713134765625, Entropy 461.7630310058594, Learning Rate: 0.000625\n",
      "Epoch [8985/20000], Loss: 827.322021484375, Entropy 462.2765197753906, Learning Rate: 0.000625\n",
      "Epoch [8986/20000], Loss: 871.5157470703125, Entropy 446.7572021484375, Learning Rate: 0.000625\n",
      "Epoch [8987/20000], Loss: 857.072998046875, Entropy 451.62060546875, Learning Rate: 0.000625\n",
      "Epoch [8988/20000], Loss: 858.1595458984375, Entropy 473.8423767089844, Learning Rate: 0.000625\n",
      "Epoch [8989/20000], Loss: 869.7206420898438, Entropy 453.49041748046875, Learning Rate: 0.000625\n",
      "Epoch [8990/20000], Loss: 824.8607177734375, Entropy 473.9872131347656, Learning Rate: 0.000625\n",
      "Epoch [8991/20000], Loss: 836.6204833984375, Entropy 455.4646911621094, Learning Rate: 0.000625\n",
      "Epoch [8992/20000], Loss: 835.0274658203125, Entropy 455.3570251464844, Learning Rate: 0.000625\n",
      "Epoch [8993/20000], Loss: 864.4676513671875, Entropy 457.1305236816406, Learning Rate: 0.000625\n",
      "Epoch [8994/20000], Loss: 876.5153198242188, Entropy 437.90228271484375, Learning Rate: 0.000625\n",
      "Epoch [8995/20000], Loss: 840.4625244140625, Entropy 452.4800720214844, Learning Rate: 0.000625\n",
      "Epoch [8996/20000], Loss: 859.1387939453125, Entropy 454.4673767089844, Learning Rate: 0.000625\n",
      "Epoch [8997/20000], Loss: 850.5941162109375, Entropy 450.573974609375, Learning Rate: 0.000625\n",
      "Epoch [8998/20000], Loss: 827.3704833984375, Entropy 456.534912109375, Learning Rate: 0.000625\n",
      "Epoch [8999/20000], Loss: 877.6734619140625, Entropy 465.65625, Learning Rate: 0.000625\n",
      "Epoch [9000/20000], Loss: 865.2415771484375, Entropy 452.6278076171875, Learning Rate: 0.000625\n",
      "Epoch [9001/20000], Loss: 875.4322509765625, Entropy 449.3802185058594, Learning Rate: 0.000625\n",
      "Epoch [9002/20000], Loss: 855.27587890625, Entropy 459.1731262207031, Learning Rate: 0.000625\n",
      "Epoch [9003/20000], Loss: 842.7299194335938, Entropy 453.54437255859375, Learning Rate: 0.000625\n",
      "Epoch [9004/20000], Loss: 868.5791625976562, Entropy 461.14739990234375, Learning Rate: 0.000625\n",
      "Epoch [9005/20000], Loss: 883.2366943359375, Entropy 466.4111328125, Learning Rate: 0.000625\n",
      "Epoch [9006/20000], Loss: 823.6976928710938, Entropy 456.74737548828125, Learning Rate: 0.000625\n",
      "Epoch [9007/20000], Loss: 892.318603515625, Entropy 459.72412109375, Learning Rate: 0.000625\n",
      "Epoch [9008/20000], Loss: 884.5606689453125, Entropy 443.3692932128906, Learning Rate: 0.000625\n",
      "Epoch [9009/20000], Loss: 869.7771606445312, Entropy 469.68707275390625, Learning Rate: 0.000625\n",
      "Epoch [9010/20000], Loss: 886.0621337890625, Entropy 454.2757568359375, Learning Rate: 0.000625\n",
      "Epoch [9011/20000], Loss: 845.6151733398438, Entropy 462.75640869140625, Learning Rate: 0.000625\n",
      "Epoch [9012/20000], Loss: 870.8414916992188, Entropy 464.61041259765625, Learning Rate: 0.000625\n",
      "Epoch [9013/20000], Loss: 883.5836181640625, Entropy 453.9938659667969, Learning Rate: 0.000625\n",
      "Epoch [9014/20000], Loss: 871.03369140625, Entropy 453.5047607421875, Learning Rate: 0.000625\n",
      "Epoch [9015/20000], Loss: 862.3531494140625, Entropy 462.6021728515625, Learning Rate: 0.000625\n",
      "Epoch [9016/20000], Loss: 867.81787109375, Entropy 455.5451965332031, Learning Rate: 0.000625\n",
      "Epoch [9017/20000], Loss: 839.604736328125, Entropy 461.2597961425781, Learning Rate: 0.000625\n",
      "Epoch [9018/20000], Loss: 833.5009765625, Entropy 457.7250671386719, Learning Rate: 0.000625\n",
      "Epoch [9019/20000], Loss: 853.909912109375, Entropy 468.8977966308594, Learning Rate: 0.000625\n",
      "Epoch [9020/20000], Loss: 871.4259033203125, Entropy 453.9268798828125, Learning Rate: 0.000625\n",
      "Epoch [9021/20000], Loss: 853.901611328125, Entropy 454.9781799316406, Learning Rate: 0.000625\n",
      "Epoch [9022/20000], Loss: 858.8482666015625, Entropy 469.5531005859375, Learning Rate: 0.000625\n",
      "Epoch [9023/20000], Loss: 878.4267578125, Entropy 459.6610412597656, Learning Rate: 0.000625\n",
      "Epoch [9024/20000], Loss: 820.7110595703125, Entropy 456.0863037109375, Learning Rate: 0.000625\n",
      "Epoch [9025/20000], Loss: 873.9013671875, Entropy 456.6920166015625, Learning Rate: 0.000625\n",
      "Epoch [9026/20000], Loss: 874.394287109375, Entropy 459.8206787109375, Learning Rate: 0.000625\n",
      "Epoch [9027/20000], Loss: 829.7645263671875, Entropy 456.3295593261719, Learning Rate: 0.000625\n",
      "Epoch [9028/20000], Loss: 866.36181640625, Entropy 459.4699401855469, Learning Rate: 0.000625\n",
      "Epoch [9029/20000], Loss: 876.0195922851562, Entropy 449.25909423828125, Learning Rate: 0.000625\n",
      "Epoch [9030/20000], Loss: 868.6221923828125, Entropy 444.6363525390625, Learning Rate: 0.000625\n",
      "Epoch [9031/20000], Loss: 839.3384399414062, Entropy 466.04718017578125, Learning Rate: 0.000625\n",
      "Epoch [9032/20000], Loss: 874.777099609375, Entropy 465.0890808105469, Learning Rate: 0.000625\n",
      "Epoch [9033/20000], Loss: 826.1201171875, Entropy 472.6805419921875, Learning Rate: 0.000625\n",
      "Epoch [9034/20000], Loss: 911.5146484375, Entropy 456.4318542480469, Learning Rate: 0.000625\n",
      "Epoch [9035/20000], Loss: 816.5787963867188, Entropy 468.05474853515625, Learning Rate: 0.000625\n",
      "Epoch [9036/20000], Loss: 843.9267578125, Entropy 467.77099609375, Learning Rate: 0.000625\n",
      "Epoch [9037/20000], Loss: 841.8427734375, Entropy 462.1776123046875, Learning Rate: 0.000625\n",
      "Epoch [9038/20000], Loss: 806.1091918945312, Entropy 464.86444091796875, Learning Rate: 0.000625\n",
      "Epoch [9039/20000], Loss: 845.3209228515625, Entropy 465.4168395996094, Learning Rate: 0.000625\n",
      "Epoch [9040/20000], Loss: 887.9530029296875, Entropy 456.1397705078125, Learning Rate: 0.000625\n",
      "Epoch [9041/20000], Loss: 900.6539306640625, Entropy 455.4879455566406, Learning Rate: 0.000625\n",
      "Epoch [9042/20000], Loss: 867.1224365234375, Entropy 459.5032043457031, Learning Rate: 0.0003125\n",
      "Epoch [9043/20000], Loss: 879.410888671875, Entropy 451.2458801269531, Learning Rate: 0.0003125\n",
      "Epoch [9044/20000], Loss: 837.645263671875, Entropy 471.005859375, Learning Rate: 0.0003125\n",
      "Epoch [9045/20000], Loss: 857.9068603515625, Entropy 452.3062438964844, Learning Rate: 0.0003125\n",
      "Epoch [9046/20000], Loss: 837.7371826171875, Entropy 455.6787109375, Learning Rate: 0.0003125\n",
      "Epoch [9047/20000], Loss: 854.5692138671875, Entropy 448.0184326171875, Learning Rate: 0.0003125\n",
      "Epoch [9048/20000], Loss: 844.08544921875, Entropy 461.3205871582031, Learning Rate: 0.0003125\n",
      "Epoch [9049/20000], Loss: 836.3305053710938, Entropy 458.59661865234375, Learning Rate: 0.0003125\n",
      "Epoch [9050/20000], Loss: 852.2354736328125, Entropy 464.015625, Learning Rate: 0.0003125\n",
      "Epoch [9051/20000], Loss: 877.7445068359375, Entropy 458.6126708984375, Learning Rate: 0.0003125\n",
      "Epoch [9052/20000], Loss: 880.8995971679688, Entropy 448.36224365234375, Learning Rate: 0.0003125\n",
      "Epoch [9053/20000], Loss: 828.343505859375, Entropy 449.4996032714844, Learning Rate: 0.0003125\n",
      "Epoch [9054/20000], Loss: 838.71533203125, Entropy 465.7835693359375, Learning Rate: 0.0003125\n",
      "Epoch [9055/20000], Loss: 798.6539916992188, Entropy 475.39642333984375, Learning Rate: 0.0003125\n",
      "Epoch [9056/20000], Loss: 854.0333862304688, Entropy 456.50128173828125, Learning Rate: 0.0003125\n",
      "Epoch [9057/20000], Loss: 879.1917724609375, Entropy 452.5817565917969, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9058/20000], Loss: 846.7568359375, Entropy 450.8773193359375, Learning Rate: 0.0003125\n",
      "Epoch [9059/20000], Loss: 849.4029541015625, Entropy 459.146240234375, Learning Rate: 0.0003125\n",
      "Epoch [9060/20000], Loss: 870.3911743164062, Entropy 446.80413818359375, Learning Rate: 0.0003125\n",
      "Epoch [9061/20000], Loss: 857.54150390625, Entropy 446.0197448730469, Learning Rate: 0.0003125\n",
      "Epoch [9062/20000], Loss: 844.42724609375, Entropy 465.3367614746094, Learning Rate: 0.0003125\n",
      "Epoch [9063/20000], Loss: 833.2401733398438, Entropy 464.27398681640625, Learning Rate: 0.0003125\n",
      "Epoch [9064/20000], Loss: 901.50537109375, Entropy 451.4317932128906, Learning Rate: 0.0003125\n",
      "Epoch [9065/20000], Loss: 807.1907348632812, Entropy 457.51324462890625, Learning Rate: 0.0003125\n",
      "Epoch [9066/20000], Loss: 860.200439453125, Entropy 458.8873291015625, Learning Rate: 0.0003125\n",
      "Epoch [9067/20000], Loss: 835.7266845703125, Entropy 458.0567932128906, Learning Rate: 0.0003125\n",
      "Epoch [9068/20000], Loss: 827.9486083984375, Entropy 456.2701416015625, Learning Rate: 0.0003125\n",
      "Epoch [9069/20000], Loss: 861.3018798828125, Entropy 456.1202392578125, Learning Rate: 0.0003125\n",
      "Epoch [9070/20000], Loss: 846.5389404296875, Entropy 461.1604919433594, Learning Rate: 0.0003125\n",
      "Epoch [9071/20000], Loss: 846.390625, Entropy 451.5461120605469, Learning Rate: 0.0003125\n",
      "Epoch [9072/20000], Loss: 854.8160400390625, Entropy 457.3347473144531, Learning Rate: 0.0003125\n",
      "Epoch [9073/20000], Loss: 844.0836181640625, Entropy 459.1731262207031, Learning Rate: 0.0003125\n",
      "Epoch [9074/20000], Loss: 827.2781372070312, Entropy 460.43853759765625, Learning Rate: 0.0003125\n",
      "Epoch [9075/20000], Loss: 865.3372802734375, Entropy 455.9048767089844, Learning Rate: 0.0003125\n",
      "Epoch [9076/20000], Loss: 865.931884765625, Entropy 457.2760009765625, Learning Rate: 0.0003125\n",
      "Epoch [9077/20000], Loss: 879.572998046875, Entropy 442.3228454589844, Learning Rate: 0.0003125\n",
      "Epoch [9078/20000], Loss: 842.70361328125, Entropy 469.3535461425781, Learning Rate: 0.0003125\n",
      "Epoch [9079/20000], Loss: 844.9033203125, Entropy 469.5222473144531, Learning Rate: 0.0003125\n",
      "Epoch [9080/20000], Loss: 877.4240112304688, Entropy 453.73004150390625, Learning Rate: 0.0003125\n",
      "Epoch [9081/20000], Loss: 835.2015380859375, Entropy 465.24267578125, Learning Rate: 0.0003125\n",
      "Epoch [9082/20000], Loss: 898.6605834960938, Entropy 446.69268798828125, Learning Rate: 0.0003125\n",
      "Epoch [9083/20000], Loss: 777.1580810546875, Entropy 474.71337890625, Learning Rate: 0.0003125\n",
      "Epoch [9084/20000], Loss: 854.8944091796875, Entropy 450.6618347167969, Learning Rate: 0.0003125\n",
      "Epoch [9085/20000], Loss: 878.9345703125, Entropy 454.5400695800781, Learning Rate: 0.0003125\n",
      "Epoch [9086/20000], Loss: 826.0056762695312, Entropy 456.13995361328125, Learning Rate: 0.0003125\n",
      "Epoch [9087/20000], Loss: 862.771728515625, Entropy 453.9622497558594, Learning Rate: 0.0003125\n",
      "Epoch [9088/20000], Loss: 898.5408935546875, Entropy 445.4635314941406, Learning Rate: 0.0003125\n",
      "Epoch [9089/20000], Loss: 872.1022338867188, Entropy 457.43865966796875, Learning Rate: 0.0003125\n",
      "Epoch [9090/20000], Loss: 859.3662109375, Entropy 461.5222473144531, Learning Rate: 0.0003125\n",
      "Epoch [9091/20000], Loss: 864.1544189453125, Entropy 460.912109375, Learning Rate: 0.0003125\n",
      "Epoch [9092/20000], Loss: 832.1368408203125, Entropy 451.5061950683594, Learning Rate: 0.0003125\n",
      "Epoch [9093/20000], Loss: 893.2476806640625, Entropy 451.4571838378906, Learning Rate: 0.0003125\n",
      "Epoch [9094/20000], Loss: 816.748046875, Entropy 461.8835754394531, Learning Rate: 0.0003125\n",
      "Epoch [9095/20000], Loss: 874.3924560546875, Entropy 453.2264099121094, Learning Rate: 0.0003125\n",
      "Epoch [9096/20000], Loss: 839.766845703125, Entropy 452.04833984375, Learning Rate: 0.0003125\n",
      "Epoch [9097/20000], Loss: 855.83203125, Entropy 452.5953674316406, Learning Rate: 0.0003125\n",
      "Epoch [9098/20000], Loss: 867.3756103515625, Entropy 452.0635986328125, Learning Rate: 0.0003125\n",
      "Epoch [9099/20000], Loss: 890.2637939453125, Entropy 464.1831970214844, Learning Rate: 0.0003125\n",
      "Epoch [9100/20000], Loss: 845.2178955078125, Entropy 443.1544189453125, Learning Rate: 0.0003125\n",
      "Epoch [9101/20000], Loss: 787.42919921875, Entropy 473.6586608886719, Learning Rate: 0.0003125\n",
      "Epoch [9102/20000], Loss: 821.619873046875, Entropy 465.392578125, Learning Rate: 0.0003125\n",
      "Epoch [9103/20000], Loss: 913.6025390625, Entropy 458.9239807128906, Learning Rate: 0.0003125\n",
      "Epoch [9104/20000], Loss: 846.9810791015625, Entropy 445.7999572753906, Learning Rate: 0.0003125\n",
      "Epoch [9105/20000], Loss: 844.97412109375, Entropy 465.3948974609375, Learning Rate: 0.0003125\n",
      "Epoch [9106/20000], Loss: 872.4577026367188, Entropy 460.54730224609375, Learning Rate: 0.0003125\n",
      "Epoch [9107/20000], Loss: 866.891845703125, Entropy 461.8106994628906, Learning Rate: 0.0003125\n",
      "Epoch [9108/20000], Loss: 878.9511108398438, Entropy 452.12994384765625, Learning Rate: 0.0003125\n",
      "Epoch [9109/20000], Loss: 876.5880737304688, Entropy 450.69256591796875, Learning Rate: 0.0003125\n",
      "Epoch [9110/20000], Loss: 876.5933837890625, Entropy 456.9608459472656, Learning Rate: 0.0003125\n",
      "Epoch [9111/20000], Loss: 836.636474609375, Entropy 468.7740783691406, Learning Rate: 0.0003125\n",
      "Epoch [9112/20000], Loss: 850.065185546875, Entropy 458.2440490722656, Learning Rate: 0.0003125\n",
      "Epoch [9113/20000], Loss: 799.76513671875, Entropy 459.2630310058594, Learning Rate: 0.0003125\n",
      "Epoch [9114/20000], Loss: 853.2608642578125, Entropy 467.1451110839844, Learning Rate: 0.0003125\n",
      "Epoch [9115/20000], Loss: 855.00732421875, Entropy 457.9849853515625, Learning Rate: 0.0003125\n",
      "Epoch [9116/20000], Loss: 829.76513671875, Entropy 459.3330383300781, Learning Rate: 0.0003125\n",
      "Epoch [9117/20000], Loss: 849.260498046875, Entropy 467.976318359375, Learning Rate: 0.0003125\n",
      "Epoch [9118/20000], Loss: 871.3408203125, Entropy 446.4788513183594, Learning Rate: 0.0003125\n",
      "Epoch [9119/20000], Loss: 876.7876586914062, Entropy 450.17633056640625, Learning Rate: 0.0003125\n",
      "Epoch [9120/20000], Loss: 869.0355834960938, Entropy 455.98638916015625, Learning Rate: 0.0003125\n",
      "Epoch [9121/20000], Loss: 899.7989501953125, Entropy 455.4594421386719, Learning Rate: 0.0003125\n",
      "Epoch [9122/20000], Loss: 874.6680908203125, Entropy 456.5328674316406, Learning Rate: 0.0003125\n",
      "Epoch [9123/20000], Loss: 848.7698974609375, Entropy 453.2003173828125, Learning Rate: 0.0003125\n",
      "Epoch [9124/20000], Loss: 843.8919067382812, Entropy 464.43463134765625, Learning Rate: 0.0003125\n",
      "Epoch [9125/20000], Loss: 830.4226684570312, Entropy 449.91998291015625, Learning Rate: 0.0003125\n",
      "Epoch [9126/20000], Loss: 868.8782958984375, Entropy 460.9866638183594, Learning Rate: 0.0003125\n",
      "Epoch [9127/20000], Loss: 839.921630859375, Entropy 457.5546875, Learning Rate: 0.0003125\n",
      "Epoch [9128/20000], Loss: 857.6893920898438, Entropy 444.03338623046875, Learning Rate: 0.0003125\n",
      "Epoch [9129/20000], Loss: 840.4178466796875, Entropy 461.6373291015625, Learning Rate: 0.0003125\n",
      "Epoch [9130/20000], Loss: 882.861572265625, Entropy 462.94091796875, Learning Rate: 0.0003125\n",
      "Epoch [9131/20000], Loss: 863.9483642578125, Entropy 465.298828125, Learning Rate: 0.0003125\n",
      "Epoch [9132/20000], Loss: 859.4155883789062, Entropy 448.76226806640625, Learning Rate: 0.0003125\n",
      "Epoch [9133/20000], Loss: 893.0040893554688, Entropy 440.11712646484375, Learning Rate: 0.0003125\n",
      "Epoch [9134/20000], Loss: 857.4354858398438, Entropy 458.88983154296875, Learning Rate: 0.0003125\n",
      "Epoch [9135/20000], Loss: 831.979736328125, Entropy 462.1480407714844, Learning Rate: 0.0003125\n",
      "Epoch [9136/20000], Loss: 860.384765625, Entropy 461.0398254394531, Learning Rate: 0.0003125\n",
      "Epoch [9137/20000], Loss: 859.6984252929688, Entropy 459.49859619140625, Learning Rate: 0.0003125\n",
      "Epoch [9138/20000], Loss: 875.4998168945312, Entropy 454.46234130859375, Learning Rate: 0.0003125\n",
      "Epoch [9139/20000], Loss: 863.4632568359375, Entropy 446.0105285644531, Learning Rate: 0.0003125\n",
      "Epoch [9140/20000], Loss: 835.324951171875, Entropy 461.8686218261719, Learning Rate: 0.0003125\n",
      "Epoch [9141/20000], Loss: 843.5742797851562, Entropy 451.47491455078125, Learning Rate: 0.0003125\n",
      "Epoch [9142/20000], Loss: 833.5050048828125, Entropy 446.02392578125, Learning Rate: 0.0003125\n",
      "Epoch [9143/20000], Loss: 879.5968017578125, Entropy 464.0167236328125, Learning Rate: 0.0003125\n",
      "Epoch [9144/20000], Loss: 860.841796875, Entropy 466.9859924316406, Learning Rate: 0.0003125\n",
      "Epoch [9145/20000], Loss: 863.9754028320312, Entropy 459.11712646484375, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9146/20000], Loss: 905.0535888671875, Entropy 446.1195068359375, Learning Rate: 0.0003125\n",
      "Epoch [9147/20000], Loss: 880.4121704101562, Entropy 461.56781005859375, Learning Rate: 0.0003125\n",
      "Epoch [9148/20000], Loss: 859.475830078125, Entropy 458.4421081542969, Learning Rate: 0.0003125\n",
      "Epoch [9149/20000], Loss: 868.2890625, Entropy 453.2283630371094, Learning Rate: 0.0003125\n",
      "Epoch [9150/20000], Loss: 814.7959594726562, Entropy 474.06304931640625, Learning Rate: 0.0003125\n",
      "Epoch [9151/20000], Loss: 852.39013671875, Entropy 456.064208984375, Learning Rate: 0.0003125\n",
      "Epoch [9152/20000], Loss: 873.62060546875, Entropy 456.5172119140625, Learning Rate: 0.0003125\n",
      "Epoch [9153/20000], Loss: 817.5518798828125, Entropy 459.2600402832031, Learning Rate: 0.0003125\n",
      "Epoch [9154/20000], Loss: 872.9324951171875, Entropy 456.4296875, Learning Rate: 0.0003125\n",
      "Epoch [9155/20000], Loss: 883.3941650390625, Entropy 456.6351318359375, Learning Rate: 0.0003125\n",
      "Epoch [9156/20000], Loss: 912.0151977539062, Entropy 445.59600830078125, Learning Rate: 0.0003125\n",
      "Epoch [9157/20000], Loss: 862.6089477539062, Entropy 456.41070556640625, Learning Rate: 0.0003125\n",
      "Epoch [9158/20000], Loss: 875.0218505859375, Entropy 459.8840637207031, Learning Rate: 0.0003125\n",
      "Epoch [9159/20000], Loss: 891.100341796875, Entropy 469.62060546875, Learning Rate: 0.0003125\n",
      "Epoch [9160/20000], Loss: 859.1873168945312, Entropy 459.60736083984375, Learning Rate: 0.0003125\n",
      "Epoch [9161/20000], Loss: 909.307373046875, Entropy 461.753662109375, Learning Rate: 0.0003125\n",
      "Epoch [9162/20000], Loss: 847.228271484375, Entropy 458.6373291015625, Learning Rate: 0.0003125\n",
      "Epoch [9163/20000], Loss: 847.05078125, Entropy 464.4203796386719, Learning Rate: 0.0003125\n",
      "Epoch [9164/20000], Loss: 877.3935546875, Entropy 467.3321838378906, Learning Rate: 0.0003125\n",
      "Epoch [9165/20000], Loss: 808.7644653320312, Entropy 469.48431396484375, Learning Rate: 0.0003125\n",
      "Epoch [9166/20000], Loss: 844.7288818359375, Entropy 467.6702880859375, Learning Rate: 0.0003125\n",
      "Epoch [9167/20000], Loss: 838.1757202148438, Entropy 473.31988525390625, Learning Rate: 0.0003125\n",
      "Epoch [9168/20000], Loss: 843.3131103515625, Entropy 450.5423278808594, Learning Rate: 0.0003125\n",
      "Epoch [9169/20000], Loss: 858.0400390625, Entropy 464.2097473144531, Learning Rate: 0.0003125\n",
      "Epoch [9170/20000], Loss: 891.9871215820312, Entropy 471.55389404296875, Learning Rate: 0.0003125\n",
      "Epoch [9171/20000], Loss: 837.9215087890625, Entropy 457.4762878417969, Learning Rate: 0.0003125\n",
      "Epoch [9172/20000], Loss: 866.9508056640625, Entropy 461.8171691894531, Learning Rate: 0.0003125\n",
      "Epoch [9173/20000], Loss: 854.8807373046875, Entropy 465.2688903808594, Learning Rate: 0.0003125\n",
      "Epoch [9174/20000], Loss: 876.520751953125, Entropy 458.0526428222656, Learning Rate: 0.0003125\n",
      "Epoch [9175/20000], Loss: 818.0099487304688, Entropy 467.49835205078125, Learning Rate: 0.0003125\n",
      "Epoch [9176/20000], Loss: 864.5132446289062, Entropy 460.89276123046875, Learning Rate: 0.0003125\n",
      "Epoch [9177/20000], Loss: 864.10888671875, Entropy 469.5657043457031, Learning Rate: 0.0003125\n",
      "Epoch [9178/20000], Loss: 849.609619140625, Entropy 454.9129638671875, Learning Rate: 0.0003125\n",
      "Epoch [9179/20000], Loss: 885.0516967773438, Entropy 466.82330322265625, Learning Rate: 0.0003125\n",
      "Epoch [9180/20000], Loss: 845.3179931640625, Entropy 449.0472412109375, Learning Rate: 0.0003125\n",
      "Epoch [9181/20000], Loss: 830.3987426757812, Entropy 470.65460205078125, Learning Rate: 0.0003125\n",
      "Epoch [9182/20000], Loss: 827.9915161132812, Entropy 463.41558837890625, Learning Rate: 0.0003125\n",
      "Epoch [9183/20000], Loss: 830.6554565429688, Entropy 458.04888916015625, Learning Rate: 0.0003125\n",
      "Epoch [9184/20000], Loss: 858.171875, Entropy 445.8953857421875, Learning Rate: 0.0003125\n",
      "Epoch [9185/20000], Loss: 845.3232421875, Entropy 456.3103942871094, Learning Rate: 0.0003125\n",
      "Epoch [9186/20000], Loss: 815.008544921875, Entropy 459.7297668457031, Learning Rate: 0.0003125\n",
      "Epoch [9187/20000], Loss: 825.1285400390625, Entropy 459.349365234375, Learning Rate: 0.0003125\n",
      "Epoch [9188/20000], Loss: 831.4644775390625, Entropy 456.9886474609375, Learning Rate: 0.0003125\n",
      "Epoch [9189/20000], Loss: 857.7462768554688, Entropy 464.00054931640625, Learning Rate: 0.0003125\n",
      "Epoch [9190/20000], Loss: 867.616455078125, Entropy 468.8601989746094, Learning Rate: 0.0003125\n",
      "Epoch [9191/20000], Loss: 874.420654296875, Entropy 442.9940185546875, Learning Rate: 0.0003125\n",
      "Epoch [9192/20000], Loss: 852.4186401367188, Entropy 467.18560791015625, Learning Rate: 0.0003125\n",
      "Epoch [9193/20000], Loss: 816.7911376953125, Entropy 457.8348083496094, Learning Rate: 0.0003125\n",
      "Epoch [9194/20000], Loss: 878.947265625, Entropy 458.0111083984375, Learning Rate: 0.0003125\n",
      "Epoch [9195/20000], Loss: 837.9940185546875, Entropy 466.0198974609375, Learning Rate: 0.0003125\n",
      "Epoch [9196/20000], Loss: 819.9459838867188, Entropy 471.77972412109375, Learning Rate: 0.0003125\n",
      "Epoch [9197/20000], Loss: 880.75146484375, Entropy 450.3824157714844, Learning Rate: 0.0003125\n",
      "Epoch [9198/20000], Loss: 881.9480590820312, Entropy 461.61749267578125, Learning Rate: 0.0003125\n",
      "Epoch [9199/20000], Loss: 843.058349609375, Entropy 465.2198791503906, Learning Rate: 0.0003125\n",
      "Epoch [9200/20000], Loss: 820.205322265625, Entropy 467.1373291015625, Learning Rate: 0.0003125\n",
      "Epoch [9201/20000], Loss: 853.532958984375, Entropy 446.193115234375, Learning Rate: 0.0003125\n",
      "Epoch [9202/20000], Loss: 855.711669921875, Entropy 457.6170349121094, Learning Rate: 0.0003125\n",
      "Epoch [9203/20000], Loss: 835.8215942382812, Entropy 455.92694091796875, Learning Rate: 0.0003125\n",
      "Epoch [9204/20000], Loss: 834.7059936523438, Entropy 470.51409912109375, Learning Rate: 0.0003125\n",
      "Epoch [9205/20000], Loss: 847.7579345703125, Entropy 461.1853942871094, Learning Rate: 0.0003125\n",
      "Epoch [9206/20000], Loss: 852.8626708984375, Entropy 471.734375, Learning Rate: 0.0003125\n",
      "Epoch [9207/20000], Loss: 872.33203125, Entropy 452.0554504394531, Learning Rate: 0.0003125\n",
      "Epoch [9208/20000], Loss: 863.4059448242188, Entropy 461.54058837890625, Learning Rate: 0.0003125\n",
      "Epoch [9209/20000], Loss: 862.3553466796875, Entropy 463.3932189941406, Learning Rate: 0.0003125\n",
      "Epoch [9210/20000], Loss: 859.3692016601562, Entropy 464.16949462890625, Learning Rate: 0.0003125\n",
      "Epoch [9211/20000], Loss: 868.7593383789062, Entropy 455.05999755859375, Learning Rate: 0.0003125\n",
      "Epoch [9212/20000], Loss: 835.935546875, Entropy 460.4342041015625, Learning Rate: 0.0003125\n",
      "Epoch [9213/20000], Loss: 839.202880859375, Entropy 466.5768737792969, Learning Rate: 0.0003125\n",
      "Epoch [9214/20000], Loss: 859.4296875, Entropy 456.7070617675781, Learning Rate: 0.0003125\n",
      "Epoch [9215/20000], Loss: 859.146484375, Entropy 446.0032653808594, Learning Rate: 0.0003125\n",
      "Epoch [9216/20000], Loss: 852.4036254882812, Entropy 460.73333740234375, Learning Rate: 0.0003125\n",
      "Epoch [9217/20000], Loss: 881.2022705078125, Entropy 445.0496826171875, Learning Rate: 0.0003125\n",
      "Epoch [9218/20000], Loss: 857.5618286132812, Entropy 459.48187255859375, Learning Rate: 0.0003125\n",
      "Epoch [9219/20000], Loss: 873.41552734375, Entropy 454.1053771972656, Learning Rate: 0.0003125\n",
      "Epoch [9220/20000], Loss: 937.01806640625, Entropy 464.9495849609375, Learning Rate: 0.0003125\n",
      "Epoch [9221/20000], Loss: 820.4677734375, Entropy 451.630615234375, Learning Rate: 0.0003125\n",
      "Epoch [9222/20000], Loss: 850.508056640625, Entropy 455.9161682128906, Learning Rate: 0.0003125\n",
      "Epoch [9223/20000], Loss: 838.470703125, Entropy 470.5244140625, Learning Rate: 0.0003125\n",
      "Epoch [9224/20000], Loss: 845.7808837890625, Entropy 461.314453125, Learning Rate: 0.0003125\n",
      "Epoch [9225/20000], Loss: 836.7989501953125, Entropy 461.0743408203125, Learning Rate: 0.0003125\n",
      "Epoch [9226/20000], Loss: 914.7450561523438, Entropy 455.17291259765625, Learning Rate: 0.0003125\n",
      "Epoch [9227/20000], Loss: 806.975830078125, Entropy 454.1056823730469, Learning Rate: 0.0003125\n",
      "Epoch [9228/20000], Loss: 862.6094970703125, Entropy 464.4529724121094, Learning Rate: 0.0003125\n",
      "Epoch [9229/20000], Loss: 857.008544921875, Entropy 445.3888854980469, Learning Rate: 0.0003125\n",
      "Epoch [9230/20000], Loss: 887.36865234375, Entropy 460.4847106933594, Learning Rate: 0.0003125\n",
      "Epoch [9231/20000], Loss: 828.2974243164062, Entropy 462.31951904296875, Learning Rate: 0.0003125\n",
      "Epoch [9232/20000], Loss: 871.7418823242188, Entropy 448.89361572265625, Learning Rate: 0.0003125\n",
      "Epoch [9233/20000], Loss: 888.285888671875, Entropy 439.5480651855469, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9234/20000], Loss: 888.0899047851562, Entropy 448.90679931640625, Learning Rate: 0.0003125\n",
      "Epoch [9235/20000], Loss: 829.5267333984375, Entropy 471.214599609375, Learning Rate: 0.0003125\n",
      "Epoch [9236/20000], Loss: 859.5125732421875, Entropy 459.3726501464844, Learning Rate: 0.0003125\n",
      "Epoch [9237/20000], Loss: 890.5517578125, Entropy 460.5498352050781, Learning Rate: 0.0003125\n",
      "Epoch [9238/20000], Loss: 816.2515869140625, Entropy 460.94873046875, Learning Rate: 0.0003125\n",
      "Epoch [9239/20000], Loss: 826.8912353515625, Entropy 460.8974609375, Learning Rate: 0.0003125\n",
      "Epoch [9240/20000], Loss: 822.833984375, Entropy 475.7217102050781, Learning Rate: 0.0003125\n",
      "Epoch [9241/20000], Loss: 852.4990234375, Entropy 449.9809265136719, Learning Rate: 0.0003125\n",
      "Epoch [9242/20000], Loss: 863.6456909179688, Entropy 441.60577392578125, Learning Rate: 0.0003125\n",
      "Epoch [9243/20000], Loss: 844.5567016601562, Entropy 460.78668212890625, Learning Rate: 0.0003125\n",
      "Epoch [9244/20000], Loss: 814.7388305664062, Entropy 473.17083740234375, Learning Rate: 0.0003125\n",
      "Epoch [9245/20000], Loss: 826.554443359375, Entropy 468.7840881347656, Learning Rate: 0.0003125\n",
      "Epoch [9246/20000], Loss: 854.960693359375, Entropy 464.2989196777344, Learning Rate: 0.0003125\n",
      "Epoch [9247/20000], Loss: 863.9937744140625, Entropy 451.0535583496094, Learning Rate: 0.0003125\n",
      "Epoch [9248/20000], Loss: 863.1898193359375, Entropy 466.7701721191406, Learning Rate: 0.0003125\n",
      "Epoch [9249/20000], Loss: 884.4210205078125, Entropy 454.4420471191406, Learning Rate: 0.0003125\n",
      "Epoch [9250/20000], Loss: 835.0841064453125, Entropy 459.6960144042969, Learning Rate: 0.0003125\n",
      "Epoch [9251/20000], Loss: 831.8760986328125, Entropy 466.3830261230469, Learning Rate: 0.0003125\n",
      "Epoch [9252/20000], Loss: 837.1458740234375, Entropy 477.287109375, Learning Rate: 0.0003125\n",
      "Epoch [9253/20000], Loss: 850.91259765625, Entropy 470.4604187011719, Learning Rate: 0.0003125\n",
      "Epoch [9254/20000], Loss: 886.452880859375, Entropy 455.6943664550781, Learning Rate: 0.0003125\n",
      "Epoch [9255/20000], Loss: 896.281982421875, Entropy 459.2035827636719, Learning Rate: 0.0003125\n",
      "Epoch [9256/20000], Loss: 895.8919677734375, Entropy 451.6390075683594, Learning Rate: 0.0003125\n",
      "Epoch [9257/20000], Loss: 900.7943115234375, Entropy 456.0700378417969, Learning Rate: 0.0003125\n",
      "Epoch [9258/20000], Loss: 868.2050170898438, Entropy 468.44390869140625, Learning Rate: 0.0003125\n",
      "Epoch [9259/20000], Loss: 849.5538940429688, Entropy 461.16607666015625, Learning Rate: 0.0003125\n",
      "Epoch [9260/20000], Loss: 845.750732421875, Entropy 456.8828125, Learning Rate: 0.0003125\n",
      "Epoch [9261/20000], Loss: 867.4434814453125, Entropy 455.7257080078125, Learning Rate: 0.0003125\n",
      "Epoch [9262/20000], Loss: 881.814453125, Entropy 460.1296691894531, Learning Rate: 0.0003125\n",
      "Epoch [9263/20000], Loss: 819.6434326171875, Entropy 471.2602233886719, Learning Rate: 0.0003125\n",
      "Epoch [9264/20000], Loss: 860.557373046875, Entropy 454.9042053222656, Learning Rate: 0.0003125\n",
      "Epoch [9265/20000], Loss: 834.6676025390625, Entropy 468.04833984375, Learning Rate: 0.0003125\n",
      "Epoch [9266/20000], Loss: 814.179443359375, Entropy 461.9493713378906, Learning Rate: 0.0003125\n",
      "Epoch [9267/20000], Loss: 852.2142333984375, Entropy 465.8899841308594, Learning Rate: 0.0003125\n",
      "Epoch [9268/20000], Loss: 924.9603271484375, Entropy 441.0862121582031, Learning Rate: 0.0003125\n",
      "Epoch [9269/20000], Loss: 876.7205810546875, Entropy 456.408935546875, Learning Rate: 0.0003125\n",
      "Epoch [9270/20000], Loss: 872.66552734375, Entropy 457.4220275878906, Learning Rate: 0.0003125\n",
      "Epoch [9271/20000], Loss: 857.151611328125, Entropy 458.5682067871094, Learning Rate: 0.0003125\n",
      "Epoch [9272/20000], Loss: 915.51171875, Entropy 454.6922912597656, Learning Rate: 0.0003125\n",
      "Epoch [9273/20000], Loss: 871.88134765625, Entropy 467.453125, Learning Rate: 0.0003125\n",
      "Epoch [9274/20000], Loss: 837.810302734375, Entropy 464.5439453125, Learning Rate: 0.0003125\n",
      "Epoch [9275/20000], Loss: 831.5616455078125, Entropy 454.4546813964844, Learning Rate: 0.0003125\n",
      "Epoch [9276/20000], Loss: 897.915283203125, Entropy 465.4566345214844, Learning Rate: 0.0003125\n",
      "Epoch [9277/20000], Loss: 833.3504028320312, Entropy 465.50982666015625, Learning Rate: 0.0003125\n",
      "Epoch [9278/20000], Loss: 870.211181640625, Entropy 459.5054626464844, Learning Rate: 0.0003125\n",
      "Epoch [9279/20000], Loss: 934.1424560546875, Entropy 449.8643798828125, Learning Rate: 0.0003125\n",
      "Epoch [9280/20000], Loss: 870.7470092773438, Entropy 453.87750244140625, Learning Rate: 0.0003125\n",
      "Epoch [9281/20000], Loss: 881.6102294921875, Entropy 465.3635559082031, Learning Rate: 0.0003125\n",
      "Epoch [9282/20000], Loss: 839.68798828125, Entropy 455.2906799316406, Learning Rate: 0.0003125\n",
      "Epoch [9283/20000], Loss: 873.6964111328125, Entropy 454.8180236816406, Learning Rate: 0.0003125\n",
      "Epoch [9284/20000], Loss: 850.7625732421875, Entropy 458.50537109375, Learning Rate: 0.0003125\n",
      "Epoch [9285/20000], Loss: 873.8276977539062, Entropy 455.10699462890625, Learning Rate: 0.0003125\n",
      "Epoch [9286/20000], Loss: 868.5137939453125, Entropy 445.3249206542969, Learning Rate: 0.0003125\n",
      "Epoch [9287/20000], Loss: 830.770263671875, Entropy 464.9967346191406, Learning Rate: 0.0003125\n",
      "Epoch [9288/20000], Loss: 851.23876953125, Entropy 458.99072265625, Learning Rate: 0.0003125\n",
      "Epoch [9289/20000], Loss: 819.1923828125, Entropy 456.5869445800781, Learning Rate: 0.0003125\n",
      "Epoch [9290/20000], Loss: 826.9918823242188, Entropy 457.29022216796875, Learning Rate: 0.0003125\n",
      "Epoch [9291/20000], Loss: 832.5730590820312, Entropy 462.25775146484375, Learning Rate: 0.0003125\n",
      "Epoch [9292/20000], Loss: 885.5438232421875, Entropy 446.4402160644531, Learning Rate: 0.0003125\n",
      "Epoch [9293/20000], Loss: 846.71728515625, Entropy 460.8327331542969, Learning Rate: 0.0003125\n",
      "Epoch [9294/20000], Loss: 860.9256591796875, Entropy 464.5080871582031, Learning Rate: 0.0003125\n",
      "Epoch [9295/20000], Loss: 867.0399169921875, Entropy 451.2627258300781, Learning Rate: 0.0003125\n",
      "Epoch [9296/20000], Loss: 851.060302734375, Entropy 456.0018005371094, Learning Rate: 0.0003125\n",
      "Epoch [9297/20000], Loss: 874.2472534179688, Entropy 460.32037353515625, Learning Rate: 0.0003125\n",
      "Epoch [9298/20000], Loss: 853.080322265625, Entropy 447.5552978515625, Learning Rate: 0.0003125\n",
      "Epoch [9299/20000], Loss: 853.65869140625, Entropy 461.4530334472656, Learning Rate: 0.0003125\n",
      "Epoch [9300/20000], Loss: 852.4820556640625, Entropy 460.7874755859375, Learning Rate: 0.0003125\n",
      "Epoch [9301/20000], Loss: 840.03271484375, Entropy 451.3249206542969, Learning Rate: 0.0003125\n",
      "Epoch [9302/20000], Loss: 854.0350341796875, Entropy 457.65087890625, Learning Rate: 0.0003125\n",
      "Epoch [9303/20000], Loss: 845.1365966796875, Entropy 460.9211730957031, Learning Rate: 0.0003125\n",
      "Epoch [9304/20000], Loss: 913.2132568359375, Entropy 454.4470520019531, Learning Rate: 0.0003125\n",
      "Epoch [9305/20000], Loss: 842.2508544921875, Entropy 467.6433410644531, Learning Rate: 0.0003125\n",
      "Epoch [9306/20000], Loss: 900.1293334960938, Entropy 453.17694091796875, Learning Rate: 0.0003125\n",
      "Epoch [9307/20000], Loss: 876.330810546875, Entropy 451.0464782714844, Learning Rate: 0.0003125\n",
      "Epoch [9308/20000], Loss: 841.2342529296875, Entropy 471.6542053222656, Learning Rate: 0.0003125\n",
      "Epoch [9309/20000], Loss: 865.8193359375, Entropy 458.1824951171875, Learning Rate: 0.0003125\n",
      "Epoch [9310/20000], Loss: 907.6972045898438, Entropy 446.35687255859375, Learning Rate: 0.0003125\n",
      "Epoch [9311/20000], Loss: 849.9383544921875, Entropy 470.8870849609375, Learning Rate: 0.0003125\n",
      "Epoch [9312/20000], Loss: 867.2821044921875, Entropy 453.3919677734375, Learning Rate: 0.0003125\n",
      "Epoch [9313/20000], Loss: 862.63916015625, Entropy 459.279052734375, Learning Rate: 0.0003125\n",
      "Epoch [9314/20000], Loss: 850.2022705078125, Entropy 456.1949157714844, Learning Rate: 0.0003125\n",
      "Epoch [9315/20000], Loss: 867.7207641601562, Entropy 462.69293212890625, Learning Rate: 0.0003125\n",
      "Epoch [9316/20000], Loss: 884.098876953125, Entropy 448.8701171875, Learning Rate: 0.0003125\n",
      "Epoch [9317/20000], Loss: 852.3114013671875, Entropy 470.7322998046875, Learning Rate: 0.0003125\n",
      "Epoch [9318/20000], Loss: 897.4873657226562, Entropy 455.49468994140625, Learning Rate: 0.0003125\n",
      "Epoch [9319/20000], Loss: 858.9742431640625, Entropy 468.2313232421875, Learning Rate: 0.0003125\n",
      "Epoch [9320/20000], Loss: 833.6143798828125, Entropy 452.1748352050781, Learning Rate: 0.0003125\n",
      "Epoch [9321/20000], Loss: 846.9383544921875, Entropy 478.1258544921875, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9322/20000], Loss: 908.3494873046875, Entropy 449.16943359375, Learning Rate: 0.0003125\n",
      "Epoch [9323/20000], Loss: 868.4815063476562, Entropy 466.09210205078125, Learning Rate: 0.0003125\n",
      "Epoch [9324/20000], Loss: 875.0028076171875, Entropy 453.5871887207031, Learning Rate: 0.0003125\n",
      "Epoch [9325/20000], Loss: 922.9820556640625, Entropy 454.4975280761719, Learning Rate: 0.0003125\n",
      "Epoch [9326/20000], Loss: 849.5359497070312, Entropy 456.09307861328125, Learning Rate: 0.0003125\n",
      "Epoch [9327/20000], Loss: 828.588623046875, Entropy 468.0152282714844, Learning Rate: 0.0003125\n",
      "Epoch [9328/20000], Loss: 878.9049072265625, Entropy 464.1839294433594, Learning Rate: 0.0003125\n",
      "Epoch [9329/20000], Loss: 867.0894775390625, Entropy 456.0349426269531, Learning Rate: 0.0003125\n",
      "Epoch [9330/20000], Loss: 866.0980224609375, Entropy 463.5472412109375, Learning Rate: 0.0003125\n",
      "Epoch [9331/20000], Loss: 879.1470947265625, Entropy 463.7847595214844, Learning Rate: 0.0003125\n",
      "Epoch [9332/20000], Loss: 824.126220703125, Entropy 456.6203308105469, Learning Rate: 0.0003125\n",
      "Epoch [9333/20000], Loss: 839.6243896484375, Entropy 457.48779296875, Learning Rate: 0.0003125\n",
      "Epoch [9334/20000], Loss: 891.8363647460938, Entropy 458.60015869140625, Learning Rate: 0.0003125\n",
      "Epoch [9335/20000], Loss: 880.5715942382812, Entropy 448.04046630859375, Learning Rate: 0.0003125\n",
      "Epoch [9336/20000], Loss: 884.0547485351562, Entropy 450.60443115234375, Learning Rate: 0.0003125\n",
      "Epoch [9337/20000], Loss: 830.4839477539062, Entropy 447.29705810546875, Learning Rate: 0.0003125\n",
      "Epoch [9338/20000], Loss: 860.8819580078125, Entropy 447.1650390625, Learning Rate: 0.0003125\n",
      "Epoch [9339/20000], Loss: 859.3115234375, Entropy 464.8146667480469, Learning Rate: 0.0003125\n",
      "Epoch [9340/20000], Loss: 846.9136962890625, Entropy 457.9874572753906, Learning Rate: 0.0003125\n",
      "Epoch [9341/20000], Loss: 843.7557373046875, Entropy 463.8295593261719, Learning Rate: 0.0003125\n",
      "Epoch [9342/20000], Loss: 820.289306640625, Entropy 464.1317138671875, Learning Rate: 0.0003125\n",
      "Epoch [9343/20000], Loss: 839.909423828125, Entropy 472.1873474121094, Learning Rate: 0.0003125\n",
      "Epoch [9344/20000], Loss: 837.8618774414062, Entropy 466.39459228515625, Learning Rate: 0.0003125\n",
      "Epoch [9345/20000], Loss: 807.2537841796875, Entropy 465.5711975097656, Learning Rate: 0.0003125\n",
      "Epoch [9346/20000], Loss: 863.9397583007812, Entropy 460.84234619140625, Learning Rate: 0.0003125\n",
      "Epoch [9347/20000], Loss: 865.197509765625, Entropy 459.3026123046875, Learning Rate: 0.0003125\n",
      "Epoch [9348/20000], Loss: 885.2642822265625, Entropy 455.2180480957031, Learning Rate: 0.0003125\n",
      "Epoch [9349/20000], Loss: 890.0098876953125, Entropy 460.78076171875, Learning Rate: 0.0003125\n",
      "Epoch [9350/20000], Loss: 852.783935546875, Entropy 464.3746643066406, Learning Rate: 0.0003125\n",
      "Epoch [9351/20000], Loss: 858.1741943359375, Entropy 455.0117492675781, Learning Rate: 0.0003125\n",
      "Epoch [9352/20000], Loss: 834.44677734375, Entropy 451.8059387207031, Learning Rate: 0.0003125\n",
      "Epoch [9353/20000], Loss: 862.2257690429688, Entropy 458.34857177734375, Learning Rate: 0.0003125\n",
      "Epoch [9354/20000], Loss: 851.433349609375, Entropy 471.2315368652344, Learning Rate: 0.0003125\n",
      "Epoch [9355/20000], Loss: 878.1341552734375, Entropy 457.1617126464844, Learning Rate: 0.0003125\n",
      "Epoch [9356/20000], Loss: 904.4395751953125, Entropy 442.86962890625, Learning Rate: 0.0003125\n",
      "Epoch [9357/20000], Loss: 859.137451171875, Entropy 452.1552734375, Learning Rate: 0.0003125\n",
      "Epoch [9358/20000], Loss: 832.230224609375, Entropy 468.4051208496094, Learning Rate: 0.0003125\n",
      "Epoch [9359/20000], Loss: 857.32421875, Entropy 470.4147644042969, Learning Rate: 0.0003125\n",
      "Epoch [9360/20000], Loss: 857.88525390625, Entropy 463.4563903808594, Learning Rate: 0.0003125\n",
      "Epoch [9361/20000], Loss: 807.3720703125, Entropy 464.9335021972656, Learning Rate: 0.0003125\n",
      "Epoch [9362/20000], Loss: 895.9337158203125, Entropy 459.5021667480469, Learning Rate: 0.0003125\n",
      "Epoch [9363/20000], Loss: 830.400390625, Entropy 460.2093200683594, Learning Rate: 0.0003125\n",
      "Epoch [9364/20000], Loss: 879.173095703125, Entropy 458.1617431640625, Learning Rate: 0.0003125\n",
      "Epoch [9365/20000], Loss: 828.0786743164062, Entropy 464.03656005859375, Learning Rate: 0.0003125\n",
      "Epoch [9366/20000], Loss: 881.6151733398438, Entropy 465.16717529296875, Learning Rate: 0.0003125\n",
      "Epoch [9367/20000], Loss: 867.6416625976562, Entropy 447.94647216796875, Learning Rate: 0.0003125\n",
      "Epoch [9368/20000], Loss: 871.8490600585938, Entropy 464.75811767578125, Learning Rate: 0.0003125\n",
      "Epoch [9369/20000], Loss: 861.7294311523438, Entropy 444.24822998046875, Learning Rate: 0.0003125\n",
      "Epoch [9370/20000], Loss: 844.2666015625, Entropy 462.6832275390625, Learning Rate: 0.0003125\n",
      "Epoch [9371/20000], Loss: 852.830810546875, Entropy 462.8417053222656, Learning Rate: 0.0003125\n",
      "Epoch [9372/20000], Loss: 805.6486206054688, Entropy 466.42584228515625, Learning Rate: 0.0003125\n",
      "Epoch [9373/20000], Loss: 845.2511596679688, Entropy 473.94036865234375, Learning Rate: 0.0003125\n",
      "Epoch [9374/20000], Loss: 842.3079833984375, Entropy 465.5742492675781, Learning Rate: 0.0003125\n",
      "Epoch [9375/20000], Loss: 854.7839965820312, Entropy 451.63311767578125, Learning Rate: 0.0003125\n",
      "Epoch [9376/20000], Loss: 875.8222045898438, Entropy 477.27239990234375, Learning Rate: 0.0003125\n",
      "Epoch [9377/20000], Loss: 847.765380859375, Entropy 463.2599182128906, Learning Rate: 0.0003125\n",
      "Epoch [9378/20000], Loss: 823.3540649414062, Entropy 464.68890380859375, Learning Rate: 0.0003125\n",
      "Epoch [9379/20000], Loss: 865.2822875976562, Entropy 462.36077880859375, Learning Rate: 0.0003125\n",
      "Epoch [9380/20000], Loss: 852.6599731445312, Entropy 447.43548583984375, Learning Rate: 0.0003125\n",
      "Epoch [9381/20000], Loss: 836.548583984375, Entropy 454.1639099121094, Learning Rate: 0.0003125\n",
      "Epoch [9382/20000], Loss: 806.34228515625, Entropy 467.4952087402344, Learning Rate: 0.0003125\n",
      "Epoch [9383/20000], Loss: 841.7501831054688, Entropy 459.52459716796875, Learning Rate: 0.0003125\n",
      "Epoch [9384/20000], Loss: 843.0418701171875, Entropy 459.2674255371094, Learning Rate: 0.0003125\n",
      "Epoch [9385/20000], Loss: 877.642822265625, Entropy 464.7552185058594, Learning Rate: 0.0003125\n",
      "Epoch [9386/20000], Loss: 868.3944091796875, Entropy 449.4233093261719, Learning Rate: 0.0003125\n",
      "Epoch [9387/20000], Loss: 833.61669921875, Entropy 466.2718505859375, Learning Rate: 0.0003125\n",
      "Epoch [9388/20000], Loss: 839.2608642578125, Entropy 455.2834167480469, Learning Rate: 0.0003125\n",
      "Epoch [9389/20000], Loss: 888.7451782226562, Entropy 447.90228271484375, Learning Rate: 0.0003125\n",
      "Epoch [9390/20000], Loss: 876.86376953125, Entropy 454.6167907714844, Learning Rate: 0.0003125\n",
      "Epoch [9391/20000], Loss: 876.9926147460938, Entropy 439.76702880859375, Learning Rate: 0.0003125\n",
      "Epoch [9392/20000], Loss: 821.3416748046875, Entropy 470.4521484375, Learning Rate: 0.0003125\n",
      "Epoch [9393/20000], Loss: 838.577392578125, Entropy 458.3103942871094, Learning Rate: 0.0003125\n",
      "Epoch [9394/20000], Loss: 873.1868896484375, Entropy 452.9347229003906, Learning Rate: 0.0003125\n",
      "Epoch [9395/20000], Loss: 806.69580078125, Entropy 466.0967102050781, Learning Rate: 0.0003125\n",
      "Epoch [9396/20000], Loss: 849.262939453125, Entropy 471.2002258300781, Learning Rate: 0.0003125\n",
      "Epoch [9397/20000], Loss: 868.5237426757812, Entropy 442.13421630859375, Learning Rate: 0.0003125\n",
      "Epoch [9398/20000], Loss: 886.4573974609375, Entropy 446.0374755859375, Learning Rate: 0.0003125\n",
      "Epoch [9399/20000], Loss: 863.891845703125, Entropy 453.7568664550781, Learning Rate: 0.0003125\n",
      "Epoch [9400/20000], Loss: 845.8778076171875, Entropy 466.7035827636719, Learning Rate: 0.0003125\n",
      "Epoch [9401/20000], Loss: 844.8111572265625, Entropy 462.4334716796875, Learning Rate: 0.0003125\n",
      "Epoch [9402/20000], Loss: 833.1083984375, Entropy 454.92724609375, Learning Rate: 0.0003125\n",
      "Epoch [9403/20000], Loss: 882.681640625, Entropy 465.576904296875, Learning Rate: 0.0003125\n",
      "Epoch [9404/20000], Loss: 882.627685546875, Entropy 449.7010192871094, Learning Rate: 0.0003125\n",
      "Epoch [9405/20000], Loss: 797.273681640625, Entropy 464.4463195800781, Learning Rate: 0.0003125\n",
      "Epoch [9406/20000], Loss: 821.808349609375, Entropy 478.0286560058594, Learning Rate: 0.0003125\n",
      "Epoch [9407/20000], Loss: 810.8614501953125, Entropy 471.1818542480469, Learning Rate: 0.0003125\n",
      "Epoch [9408/20000], Loss: 848.581298828125, Entropy 462.4452209472656, Learning Rate: 0.0003125\n",
      "Epoch [9409/20000], Loss: 851.6580200195312, Entropy 452.56695556640625, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9410/20000], Loss: 853.6492309570312, Entropy 459.31634521484375, Learning Rate: 0.0003125\n",
      "Epoch [9411/20000], Loss: 830.8489990234375, Entropy 476.0975036621094, Learning Rate: 0.0003125\n",
      "Epoch [9412/20000], Loss: 859.0903930664062, Entropy 443.68255615234375, Learning Rate: 0.0003125\n",
      "Epoch [9413/20000], Loss: 841.4165649414062, Entropy 462.83843994140625, Learning Rate: 0.0003125\n",
      "Epoch [9414/20000], Loss: 843.927978515625, Entropy 456.7990417480469, Learning Rate: 0.0003125\n",
      "Epoch [9415/20000], Loss: 832.3809814453125, Entropy 464.1260070800781, Learning Rate: 0.0003125\n",
      "Epoch [9416/20000], Loss: 849.8809814453125, Entropy 467.77099609375, Learning Rate: 0.0003125\n",
      "Epoch [9417/20000], Loss: 846.1585693359375, Entropy 470.6433410644531, Learning Rate: 0.0003125\n",
      "Epoch [9418/20000], Loss: 886.1366577148438, Entropy 455.61138916015625, Learning Rate: 0.0003125\n",
      "Epoch [9419/20000], Loss: 898.69970703125, Entropy 453.4752197265625, Learning Rate: 0.0003125\n",
      "Epoch [9420/20000], Loss: 856.6144409179688, Entropy 470.23883056640625, Learning Rate: 0.0003125\n",
      "Epoch [9421/20000], Loss: 880.6937255859375, Entropy 462.7203674316406, Learning Rate: 0.0003125\n",
      "Epoch [9422/20000], Loss: 872.886962890625, Entropy 464.4613952636719, Learning Rate: 0.0003125\n",
      "Epoch [9423/20000], Loss: 839.3250732421875, Entropy 465.1835021972656, Learning Rate: 0.0003125\n",
      "Epoch [9424/20000], Loss: 846.3199462890625, Entropy 467.8517150878906, Learning Rate: 0.0003125\n",
      "Epoch [9425/20000], Loss: 865.0689697265625, Entropy 460.9959411621094, Learning Rate: 0.0003125\n",
      "Epoch [9426/20000], Loss: 866.3740234375, Entropy 481.13720703125, Learning Rate: 0.0003125\n",
      "Epoch [9427/20000], Loss: 876.1223754882812, Entropy 455.97967529296875, Learning Rate: 0.0003125\n",
      "Epoch [9428/20000], Loss: 854.7705078125, Entropy 474.3969421386719, Learning Rate: 0.0003125\n",
      "Epoch [9429/20000], Loss: 862.321044921875, Entropy 465.8992919921875, Learning Rate: 0.0003125\n",
      "Epoch [9430/20000], Loss: 880.587158203125, Entropy 456.651123046875, Learning Rate: 0.0003125\n",
      "Epoch [9431/20000], Loss: 901.30322265625, Entropy 453.1417541503906, Learning Rate: 0.0003125\n",
      "Epoch [9432/20000], Loss: 816.838623046875, Entropy 460.7290954589844, Learning Rate: 0.0003125\n",
      "Epoch [9433/20000], Loss: 893.1679077148438, Entropy 452.92083740234375, Learning Rate: 0.0003125\n",
      "Epoch [9434/20000], Loss: 844.2386474609375, Entropy 464.6170349121094, Learning Rate: 0.0003125\n",
      "Epoch [9435/20000], Loss: 860.91748046875, Entropy 462.1496887207031, Learning Rate: 0.0003125\n",
      "Epoch [9436/20000], Loss: 820.8858032226562, Entropy 466.79632568359375, Learning Rate: 0.0003125\n",
      "Epoch [9437/20000], Loss: 852.5421142578125, Entropy 461.1505432128906, Learning Rate: 0.0003125\n",
      "Epoch [9438/20000], Loss: 833.13720703125, Entropy 467.20947265625, Learning Rate: 0.0003125\n",
      "Epoch [9439/20000], Loss: 827.7772216796875, Entropy 460.6803283691406, Learning Rate: 0.0003125\n",
      "Epoch [9440/20000], Loss: 828.099853515625, Entropy 450.6941833496094, Learning Rate: 0.0003125\n",
      "Epoch [9441/20000], Loss: 875.2930297851562, Entropy 453.95721435546875, Learning Rate: 0.0003125\n",
      "Epoch [9442/20000], Loss: 826.4954833984375, Entropy 450.2447204589844, Learning Rate: 0.0003125\n",
      "Epoch [9443/20000], Loss: 838.7117919921875, Entropy 459.64208984375, Learning Rate: 0.0003125\n",
      "Epoch [9444/20000], Loss: 859.5457763671875, Entropy 456.1966247558594, Learning Rate: 0.0003125\n",
      "Epoch [9445/20000], Loss: 809.41455078125, Entropy 472.1469421386719, Learning Rate: 0.0003125\n",
      "Epoch [9446/20000], Loss: 865.1932373046875, Entropy 468.3515625, Learning Rate: 0.0003125\n",
      "Epoch [9447/20000], Loss: 862.417724609375, Entropy 450.7804870605469, Learning Rate: 0.0003125\n",
      "Epoch [9448/20000], Loss: 898.038818359375, Entropy 457.4568176269531, Learning Rate: 0.0003125\n",
      "Epoch [9449/20000], Loss: 870.4896240234375, Entropy 465.296875, Learning Rate: 0.0003125\n",
      "Epoch [9450/20000], Loss: 862.0989990234375, Entropy 452.0328063964844, Learning Rate: 0.0003125\n",
      "Epoch [9451/20000], Loss: 833.6358642578125, Entropy 461.02783203125, Learning Rate: 0.0003125\n",
      "Epoch [9452/20000], Loss: 846.3314208984375, Entropy 478.65771484375, Learning Rate: 0.0003125\n",
      "Epoch [9453/20000], Loss: 848.24755859375, Entropy 458.8556213378906, Learning Rate: 0.0003125\n",
      "Epoch [9454/20000], Loss: 872.802490234375, Entropy 455.0074768066406, Learning Rate: 0.0003125\n",
      "Epoch [9455/20000], Loss: 829.500244140625, Entropy 461.8988952636719, Learning Rate: 0.0003125\n",
      "Epoch [9456/20000], Loss: 841.4880981445312, Entropy 457.58343505859375, Learning Rate: 0.0003125\n",
      "Epoch [9457/20000], Loss: 865.936767578125, Entropy 458.1944580078125, Learning Rate: 0.0003125\n",
      "Epoch [9458/20000], Loss: 874.625244140625, Entropy 455.5154724121094, Learning Rate: 0.0003125\n",
      "Epoch [9459/20000], Loss: 825.178466796875, Entropy 460.1549987792969, Learning Rate: 0.0003125\n",
      "Epoch [9460/20000], Loss: 844.006103515625, Entropy 466.1983337402344, Learning Rate: 0.0003125\n",
      "Epoch [9461/20000], Loss: 903.7407836914062, Entropy 464.95111083984375, Learning Rate: 0.0003125\n",
      "Epoch [9462/20000], Loss: 851.19775390625, Entropy 469.2008972167969, Learning Rate: 0.0003125\n",
      "Epoch [9463/20000], Loss: 836.4815063476562, Entropy 460.37725830078125, Learning Rate: 0.0003125\n",
      "Epoch [9464/20000], Loss: 815.0887451171875, Entropy 464.4318542480469, Learning Rate: 0.0003125\n",
      "Epoch [9465/20000], Loss: 841.7666015625, Entropy 465.3650207519531, Learning Rate: 0.0003125\n",
      "Epoch [9466/20000], Loss: 893.2020263671875, Entropy 444.7897644042969, Learning Rate: 0.0003125\n",
      "Epoch [9467/20000], Loss: 851.0338134765625, Entropy 467.6028747558594, Learning Rate: 0.0003125\n",
      "Epoch [9468/20000], Loss: 855.8829345703125, Entropy 444.0701599121094, Learning Rate: 0.0003125\n",
      "Epoch [9469/20000], Loss: 847.5670166015625, Entropy 464.7582702636719, Learning Rate: 0.0003125\n",
      "Epoch [9470/20000], Loss: 800.5631103515625, Entropy 476.0587463378906, Learning Rate: 0.0003125\n",
      "Epoch [9471/20000], Loss: 826.2313232421875, Entropy 466.5535888671875, Learning Rate: 0.0003125\n",
      "Epoch [9472/20000], Loss: 814.38623046875, Entropy 472.5647277832031, Learning Rate: 0.0003125\n",
      "Epoch [9473/20000], Loss: 802.3916015625, Entropy 469.2593994140625, Learning Rate: 0.0003125\n",
      "Epoch [9474/20000], Loss: 859.9166259765625, Entropy 457.0345153808594, Learning Rate: 0.0003125\n",
      "Epoch [9475/20000], Loss: 837.687255859375, Entropy 480.1935119628906, Learning Rate: 0.0003125\n",
      "Epoch [9476/20000], Loss: 849.4198608398438, Entropy 461.66497802734375, Learning Rate: 0.0003125\n",
      "Epoch [9477/20000], Loss: 834.4246215820312, Entropy 465.42095947265625, Learning Rate: 0.0003125\n",
      "Epoch [9478/20000], Loss: 797.63720703125, Entropy 470.1792907714844, Learning Rate: 0.0003125\n",
      "Epoch [9479/20000], Loss: 838.96240234375, Entropy 476.826171875, Learning Rate: 0.0003125\n",
      "Epoch [9480/20000], Loss: 904.7535400390625, Entropy 466.1254577636719, Learning Rate: 0.0003125\n",
      "Epoch [9481/20000], Loss: 857.693115234375, Entropy 473.4482421875, Learning Rate: 0.0003125\n",
      "Epoch [9482/20000], Loss: 888.2667236328125, Entropy 461.3254699707031, Learning Rate: 0.0003125\n",
      "Epoch [9483/20000], Loss: 869.084228515625, Entropy 460.6174011230469, Learning Rate: 0.0003125\n",
      "Epoch [9484/20000], Loss: 805.163818359375, Entropy 470.53857421875, Learning Rate: 0.0003125\n",
      "Epoch [9485/20000], Loss: 851.9979248046875, Entropy 464.33984375, Learning Rate: 0.0003125\n",
      "Epoch [9486/20000], Loss: 861.425048828125, Entropy 459.1873474121094, Learning Rate: 0.0003125\n",
      "Epoch [9487/20000], Loss: 857.4356079101562, Entropy 461.80377197265625, Learning Rate: 0.0003125\n",
      "Epoch [9488/20000], Loss: 808.47705078125, Entropy 468.3302917480469, Learning Rate: 0.0003125\n",
      "Epoch [9489/20000], Loss: 846.890869140625, Entropy 446.0345153808594, Learning Rate: 0.0003125\n",
      "Epoch [9490/20000], Loss: 837.0616455078125, Entropy 465.4383850097656, Learning Rate: 0.0003125\n",
      "Epoch [9491/20000], Loss: 860.7823486328125, Entropy 457.3573303222656, Learning Rate: 0.0003125\n",
      "Epoch [9492/20000], Loss: 809.572998046875, Entropy 466.8992614746094, Learning Rate: 0.0003125\n",
      "Epoch [9493/20000], Loss: 854.3406982421875, Entropy 456.7999267578125, Learning Rate: 0.0003125\n",
      "Epoch [9494/20000], Loss: 900.62841796875, Entropy 445.51953125, Learning Rate: 0.0003125\n",
      "Epoch [9495/20000], Loss: 850.0908203125, Entropy 459.2735900878906, Learning Rate: 0.0003125\n",
      "Epoch [9496/20000], Loss: 848.4618530273438, Entropy 452.59014892578125, Learning Rate: 0.0003125\n",
      "Epoch [9497/20000], Loss: 834.7611083984375, Entropy 463.7237548828125, Learning Rate: 0.0003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9498/20000], Loss: 874.5035400390625, Entropy 467.8636474609375, Learning Rate: 0.0003125\n",
      "Epoch [9499/20000], Loss: 884.576416015625, Entropy 455.400146484375, Learning Rate: 0.0003125\n",
      "Epoch [9500/20000], Loss: 864.3809814453125, Entropy 472.4224548339844, Learning Rate: 0.0003125\n",
      "Epoch [9501/20000], Loss: 853.3206176757812, Entropy 464.74249267578125, Learning Rate: 0.0003125\n",
      "Epoch [9502/20000], Loss: 865.3201904296875, Entropy 466.2038879394531, Learning Rate: 0.0003125\n",
      "Epoch [9503/20000], Loss: 859.4290771484375, Entropy 454.9283752441406, Learning Rate: 0.0003125\n",
      "Epoch [9504/20000], Loss: 832.1776733398438, Entropy 463.26593017578125, Learning Rate: 0.0003125\n",
      "Epoch [9505/20000], Loss: 847.6304321289062, Entropy 462.92999267578125, Learning Rate: 0.0003125\n",
      "Epoch [9506/20000], Loss: 877.6734619140625, Entropy 448.0105895996094, Learning Rate: 0.0003125\n",
      "Epoch [9507/20000], Loss: 823.0859375, Entropy 461.5201110839844, Learning Rate: 0.0003125\n",
      "Epoch [9508/20000], Loss: 844.5091552734375, Entropy 465.3352966308594, Learning Rate: 0.0003125\n",
      "Epoch [9509/20000], Loss: 853.0582275390625, Entropy 466.1579895019531, Learning Rate: 0.0003125\n",
      "Epoch [9510/20000], Loss: 910.8857421875, Entropy 459.54833984375, Learning Rate: 0.0003125\n",
      "Epoch [9511/20000], Loss: 876.3383178710938, Entropy 460.36224365234375, Learning Rate: 0.0003125\n",
      "Epoch [9512/20000], Loss: 829.5914306640625, Entropy 470.6822509765625, Learning Rate: 0.0003125\n",
      "Epoch [9513/20000], Loss: 866.38232421875, Entropy 478.0224914550781, Learning Rate: 0.0003125\n",
      "Epoch [9514/20000], Loss: 866.9248046875, Entropy 456.8404541015625, Learning Rate: 0.0003125\n",
      "Epoch [9515/20000], Loss: 859.4405517578125, Entropy 470.8412780761719, Learning Rate: 0.0003125\n",
      "Epoch [9516/20000], Loss: 875.6390991210938, Entropy 465.97711181640625, Learning Rate: 0.0003125\n",
      "Epoch [9517/20000], Loss: 855.037841796875, Entropy 461.8572692871094, Learning Rate: 0.0003125\n",
      "Epoch [9518/20000], Loss: 843.29541015625, Entropy 456.1662902832031, Learning Rate: 0.0003125\n",
      "Epoch [9519/20000], Loss: 837.85888671875, Entropy 472.5911560058594, Learning Rate: 0.0003125\n",
      "Epoch [9520/20000], Loss: 850.045654296875, Entropy 469.7952880859375, Learning Rate: 0.0003125\n",
      "Epoch [9521/20000], Loss: 855.2412109375, Entropy 471.2922668457031, Learning Rate: 0.0003125\n",
      "Epoch [9522/20000], Loss: 824.643798828125, Entropy 473.3634338378906, Learning Rate: 0.0003125\n",
      "Epoch [9523/20000], Loss: 898.212646484375, Entropy 458.7510986328125, Learning Rate: 0.0003125\n",
      "Epoch [9524/20000], Loss: 852.236572265625, Entropy 460.22802734375, Learning Rate: 0.0003125\n",
      "Epoch [9525/20000], Loss: 870.2096557617188, Entropy 455.80999755859375, Learning Rate: 0.0003125\n",
      "Epoch [9526/20000], Loss: 880.7322387695312, Entropy 456.48944091796875, Learning Rate: 0.0003125\n",
      "Epoch [9527/20000], Loss: 843.1185302734375, Entropy 473.4359130859375, Learning Rate: 0.0003125\n",
      "Epoch [9528/20000], Loss: 870.3193359375, Entropy 458.9659729003906, Learning Rate: 0.0003125\n",
      "Epoch [9529/20000], Loss: 844.8070068359375, Entropy 454.7844543457031, Learning Rate: 0.0003125\n",
      "Epoch [9530/20000], Loss: 844.249267578125, Entropy 474.2322692871094, Learning Rate: 0.0003125\n",
      "Epoch [9531/20000], Loss: 888.845947265625, Entropy 461.27734375, Learning Rate: 0.0003125\n",
      "Epoch [9532/20000], Loss: 859.416015625, Entropy 459.4322814941406, Learning Rate: 0.0003125\n",
      "Epoch [9533/20000], Loss: 905.4013671875, Entropy 462.9095153808594, Learning Rate: 0.0003125\n",
      "Epoch [9534/20000], Loss: 891.0233764648438, Entropy 457.82037353515625, Learning Rate: 0.0003125\n",
      "Epoch [9535/20000], Loss: 890.930908203125, Entropy 462.0328674316406, Learning Rate: 0.0003125\n",
      "Epoch [9536/20000], Loss: 829.148193359375, Entropy 466.2220153808594, Learning Rate: 0.0003125\n",
      "Epoch [9537/20000], Loss: 838.2348022460938, Entropy 468.19622802734375, Learning Rate: 0.0003125\n",
      "Epoch [9538/20000], Loss: 810.179931640625, Entropy 470.9359130859375, Learning Rate: 0.0003125\n",
      "Epoch [9539/20000], Loss: 850.0994262695312, Entropy 468.16339111328125, Learning Rate: 0.0003125\n",
      "Epoch [9540/20000], Loss: 857.9711303710938, Entropy 472.90228271484375, Learning Rate: 0.0003125\n",
      "Epoch [9541/20000], Loss: 860.76318359375, Entropy 465.6545715332031, Learning Rate: 0.0003125\n",
      "Epoch [9542/20000], Loss: 847.666259765625, Entropy 473.318359375, Learning Rate: 0.0003125\n",
      "Epoch [9543/20000], Loss: 856.989501953125, Entropy 455.1763610839844, Learning Rate: 0.0003125\n",
      "Epoch [9544/20000], Loss: 830.3125, Entropy 466.6770324707031, Learning Rate: 0.0003125\n",
      "Epoch [9545/20000], Loss: 828.7217407226562, Entropy 474.05279541015625, Learning Rate: 0.0003125\n",
      "Epoch [9546/20000], Loss: 832.7977294921875, Entropy 471.10302734375, Learning Rate: 0.0003125\n",
      "Epoch [9547/20000], Loss: 893.2918701171875, Entropy 458.7815246582031, Learning Rate: 0.0003125\n",
      "Epoch [9548/20000], Loss: 862.9681396484375, Entropy 455.0184326171875, Learning Rate: 0.0003125\n",
      "Epoch [9549/20000], Loss: 850.885986328125, Entropy 460.1374206542969, Learning Rate: 0.0003125\n",
      "Epoch [9550/20000], Loss: 882.2783203125, Entropy 448.556396484375, Learning Rate: 0.0003125\n",
      "Epoch [9551/20000], Loss: 860.655029296875, Entropy 473.224365234375, Learning Rate: 0.0003125\n",
      "Epoch [9552/20000], Loss: 832.0628662109375, Entropy 459.3088073730469, Learning Rate: 0.0003125\n",
      "Epoch [9553/20000], Loss: 892.7962646484375, Entropy 446.9621887207031, Learning Rate: 0.0003125\n",
      "Epoch [9554/20000], Loss: 876.0184326171875, Entropy 457.7261657714844, Learning Rate: 0.0003125\n",
      "Epoch [9555/20000], Loss: 891.8856201171875, Entropy 451.1763916015625, Learning Rate: 0.0003125\n",
      "Epoch [9556/20000], Loss: 869.784423828125, Entropy 462.8388671875, Learning Rate: 0.0003125\n",
      "Epoch [9557/20000], Loss: 835.9154052734375, Entropy 467.1138610839844, Learning Rate: 0.0003125\n",
      "Epoch [9558/20000], Loss: 829.1510009765625, Entropy 460.6631164550781, Learning Rate: 0.0003125\n",
      "Epoch [9559/20000], Loss: 848.2408447265625, Entropy 457.1335144042969, Learning Rate: 0.0003125\n",
      "Epoch [9560/20000], Loss: 866.2303466796875, Entropy 459.974365234375, Learning Rate: 0.0003125\n",
      "Epoch [9561/20000], Loss: 857.4930419921875, Entropy 471.4232177734375, Learning Rate: 0.0003125\n",
      "Epoch [9562/20000], Loss: 864.4591064453125, Entropy 462.0643310546875, Learning Rate: 0.0003125\n",
      "Epoch [9563/20000], Loss: 870.6640625, Entropy 458.4558410644531, Learning Rate: 0.0003125\n",
      "Epoch [9564/20000], Loss: 894.9912719726562, Entropy 472.13372802734375, Learning Rate: 0.0003125\n",
      "Epoch [9565/20000], Loss: 826.724365234375, Entropy 476.1182556152344, Learning Rate: 0.0003125\n",
      "Epoch [9566/20000], Loss: 837.1190185546875, Entropy 457.6218566894531, Learning Rate: 0.0003125\n",
      "Epoch [9567/20000], Loss: 821.66650390625, Entropy 469.91748046875, Learning Rate: 0.0003125\n",
      "Epoch [9568/20000], Loss: 865.8377685546875, Entropy 467.2149963378906, Learning Rate: 0.0003125\n",
      "Epoch [9569/20000], Loss: 862.4420166015625, Entropy 466.6217041015625, Learning Rate: 0.0003125\n",
      "Epoch [9570/20000], Loss: 830.9544677734375, Entropy 469.3265380859375, Learning Rate: 0.0003125\n",
      "Epoch [9571/20000], Loss: 882.0472412109375, Entropy 460.5012512207031, Learning Rate: 0.0003125\n",
      "Epoch [9572/20000], Loss: 865.8825073242188, Entropy 459.69964599609375, Learning Rate: 0.0003125\n",
      "Epoch [9573/20000], Loss: 857.76171875, Entropy 473.796630859375, Learning Rate: 0.0003125\n",
      "Epoch [9574/20000], Loss: 843.3096923828125, Entropy 469.7366027832031, Learning Rate: 0.0003125\n",
      "Epoch [9575/20000], Loss: 818.3306884765625, Entropy 475.7420654296875, Learning Rate: 0.0003125\n",
      "Epoch [9576/20000], Loss: 848.067626953125, Entropy 473.711669921875, Learning Rate: 0.0003125\n",
      "Epoch [9577/20000], Loss: 826.592041015625, Entropy 473.443359375, Learning Rate: 0.0003125\n",
      "Epoch [9578/20000], Loss: 825.0833740234375, Entropy 461.57177734375, Learning Rate: 0.0003125\n",
      "Epoch [9579/20000], Loss: 841.686767578125, Entropy 461.8341979980469, Learning Rate: 0.0003125\n",
      "Epoch [9580/20000], Loss: 881.953369140625, Entropy 466.398193359375, Learning Rate: 0.0003125\n",
      "Epoch [9581/20000], Loss: 894.1890258789062, Entropy 456.80889892578125, Learning Rate: 0.0003125\n",
      "Epoch [9582/20000], Loss: 842.822998046875, Entropy 459.4009704589844, Learning Rate: 0.0003125\n",
      "Epoch [9583/20000], Loss: 848.6465454101562, Entropy 457.16046142578125, Learning Rate: 0.0003125\n",
      "Epoch [9584/20000], Loss: 863.8253784179688, Entropy 457.01300048828125, Learning Rate: 0.0003125\n",
      "Epoch [9585/20000], Loss: 864.36865234375, Entropy 461.6476135253906, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9586/20000], Loss: 825.9591064453125, Entropy 458.861328125, Learning Rate: 0.00015625\n",
      "Epoch [9587/20000], Loss: 828.662353515625, Entropy 458.1903076171875, Learning Rate: 0.00015625\n",
      "Epoch [9588/20000], Loss: 861.3833618164062, Entropy 470.18780517578125, Learning Rate: 0.00015625\n",
      "Epoch [9589/20000], Loss: 813.2543334960938, Entropy 478.39959716796875, Learning Rate: 0.00015625\n",
      "Epoch [9590/20000], Loss: 866.8821411132812, Entropy 459.60284423828125, Learning Rate: 0.00015625\n",
      "Epoch [9591/20000], Loss: 819.0732421875, Entropy 477.3855285644531, Learning Rate: 0.00015625\n",
      "Epoch [9592/20000], Loss: 879.1124267578125, Entropy 467.7279968261719, Learning Rate: 0.00015625\n",
      "Epoch [9593/20000], Loss: 826.08203125, Entropy 474.2117004394531, Learning Rate: 0.00015625\n",
      "Epoch [9594/20000], Loss: 831.4427490234375, Entropy 444.8228759765625, Learning Rate: 0.00015625\n",
      "Epoch [9595/20000], Loss: 867.809326171875, Entropy 470.5985412597656, Learning Rate: 0.00015625\n",
      "Epoch [9596/20000], Loss: 866.662841796875, Entropy 444.0464782714844, Learning Rate: 0.00015625\n",
      "Epoch [9597/20000], Loss: 860.1317138671875, Entropy 467.6067199707031, Learning Rate: 0.00015625\n",
      "Epoch [9598/20000], Loss: 836.0262451171875, Entropy 456.8778381347656, Learning Rate: 0.00015625\n",
      "Epoch [9599/20000], Loss: 857.9995727539062, Entropy 458.44879150390625, Learning Rate: 0.00015625\n",
      "Epoch [9600/20000], Loss: 806.8577880859375, Entropy 470.9587097167969, Learning Rate: 0.00015625\n",
      "Epoch [9601/20000], Loss: 820.0399169921875, Entropy 470.6644287109375, Learning Rate: 0.00015625\n",
      "Epoch [9602/20000], Loss: 841.0809326171875, Entropy 458.4948425292969, Learning Rate: 0.00015625\n",
      "Epoch [9603/20000], Loss: 839.5376586914062, Entropy 461.60772705078125, Learning Rate: 0.00015625\n",
      "Epoch [9604/20000], Loss: 817.87158203125, Entropy 474.087890625, Learning Rate: 0.00015625\n",
      "Epoch [9605/20000], Loss: 861.36865234375, Entropy 461.2920227050781, Learning Rate: 0.00015625\n",
      "Epoch [9606/20000], Loss: 881.139404296875, Entropy 468.0945129394531, Learning Rate: 0.00015625\n",
      "Epoch [9607/20000], Loss: 861.6453247070312, Entropy 467.36187744140625, Learning Rate: 0.00015625\n",
      "Epoch [9608/20000], Loss: 863.5748291015625, Entropy 463.4792785644531, Learning Rate: 0.00015625\n",
      "Epoch [9609/20000], Loss: 833.2979736328125, Entropy 469.0210876464844, Learning Rate: 0.00015625\n",
      "Epoch [9610/20000], Loss: 870.2017211914062, Entropy 461.11859130859375, Learning Rate: 0.00015625\n",
      "Epoch [9611/20000], Loss: 914.6163330078125, Entropy 444.904296875, Learning Rate: 0.00015625\n",
      "Epoch [9612/20000], Loss: 823.6683349609375, Entropy 473.6767883300781, Learning Rate: 0.00015625\n",
      "Epoch [9613/20000], Loss: 871.8626708984375, Entropy 453.72265625, Learning Rate: 0.00015625\n",
      "Epoch [9614/20000], Loss: 819.5601806640625, Entropy 460.4932861328125, Learning Rate: 0.00015625\n",
      "Epoch [9615/20000], Loss: 849.72021484375, Entropy 469.8553161621094, Learning Rate: 0.00015625\n",
      "Epoch [9616/20000], Loss: 856.8436279296875, Entropy 470.2581787109375, Learning Rate: 0.00015625\n",
      "Epoch [9617/20000], Loss: 829.7108154296875, Entropy 469.6477966308594, Learning Rate: 0.00015625\n",
      "Epoch [9618/20000], Loss: 837.2836303710938, Entropy 477.54290771484375, Learning Rate: 0.00015625\n",
      "Epoch [9619/20000], Loss: 865.73486328125, Entropy 458.8302917480469, Learning Rate: 0.00015625\n",
      "Epoch [9620/20000], Loss: 888.057373046875, Entropy 462.5399169921875, Learning Rate: 0.00015625\n",
      "Epoch [9621/20000], Loss: 864.0643310546875, Entropy 467.8699645996094, Learning Rate: 0.00015625\n",
      "Epoch [9622/20000], Loss: 837.539306640625, Entropy 478.5706787109375, Learning Rate: 0.00015625\n",
      "Epoch [9623/20000], Loss: 855.6317138671875, Entropy 469.5096130371094, Learning Rate: 0.00015625\n",
      "Epoch [9624/20000], Loss: 846.9102783203125, Entropy 469.3484191894531, Learning Rate: 0.00015625\n",
      "Epoch [9625/20000], Loss: 877.5275268554688, Entropy 459.42474365234375, Learning Rate: 0.00015625\n",
      "Epoch [9626/20000], Loss: 891.1005859375, Entropy 466.5663146972656, Learning Rate: 0.00015625\n",
      "Epoch [9627/20000], Loss: 809.7747802734375, Entropy 470.5776062011719, Learning Rate: 0.00015625\n",
      "Epoch [9628/20000], Loss: 882.59326171875, Entropy 467.7889709472656, Learning Rate: 0.00015625\n",
      "Epoch [9629/20000], Loss: 877.312255859375, Entropy 465.3830871582031, Learning Rate: 0.00015625\n",
      "Epoch [9630/20000], Loss: 841.326171875, Entropy 452.398193359375, Learning Rate: 0.00015625\n",
      "Epoch [9631/20000], Loss: 859.27587890625, Entropy 471.2112121582031, Learning Rate: 0.00015625\n",
      "Epoch [9632/20000], Loss: 876.1068115234375, Entropy 466.9188232421875, Learning Rate: 0.00015625\n",
      "Epoch [9633/20000], Loss: 804.240966796875, Entropy 466.7776794433594, Learning Rate: 0.00015625\n",
      "Epoch [9634/20000], Loss: 871.2850341796875, Entropy 471.7213134765625, Learning Rate: 0.00015625\n",
      "Epoch [9635/20000], Loss: 834.14013671875, Entropy 452.8878479003906, Learning Rate: 0.00015625\n",
      "Epoch [9636/20000], Loss: 885.6333618164062, Entropy 442.99334716796875, Learning Rate: 0.00015625\n",
      "Epoch [9637/20000], Loss: 886.0662231445312, Entropy 470.47222900390625, Learning Rate: 0.00015625\n",
      "Epoch [9638/20000], Loss: 877.3251953125, Entropy 462.8205261230469, Learning Rate: 0.00015625\n",
      "Epoch [9639/20000], Loss: 804.2982177734375, Entropy 472.4358215332031, Learning Rate: 0.00015625\n",
      "Epoch [9640/20000], Loss: 843.9298095703125, Entropy 471.5982360839844, Learning Rate: 0.00015625\n",
      "Epoch [9641/20000], Loss: 873.9518432617188, Entropy 469.11224365234375, Learning Rate: 0.00015625\n",
      "Epoch [9642/20000], Loss: 841.2968139648438, Entropy 456.08148193359375, Learning Rate: 0.00015625\n",
      "Epoch [9643/20000], Loss: 897.5477294921875, Entropy 466.2722473144531, Learning Rate: 0.00015625\n",
      "Epoch [9644/20000], Loss: 832.37548828125, Entropy 473.902099609375, Learning Rate: 0.00015625\n",
      "Epoch [9645/20000], Loss: 832.4791259765625, Entropy 464.08349609375, Learning Rate: 0.00015625\n",
      "Epoch [9646/20000], Loss: 874.6156005859375, Entropy 450.2613830566406, Learning Rate: 0.00015625\n",
      "Epoch [9647/20000], Loss: 872.5765380859375, Entropy 481.5312805175781, Learning Rate: 0.00015625\n",
      "Epoch [9648/20000], Loss: 817.4166870117188, Entropy 465.94000244140625, Learning Rate: 0.00015625\n",
      "Epoch [9649/20000], Loss: 855.9493408203125, Entropy 470.4669494628906, Learning Rate: 0.00015625\n",
      "Epoch [9650/20000], Loss: 876.411865234375, Entropy 469.1053771972656, Learning Rate: 0.00015625\n",
      "Epoch [9651/20000], Loss: 869.0718994140625, Entropy 466.8160705566406, Learning Rate: 0.00015625\n",
      "Epoch [9652/20000], Loss: 825.8038330078125, Entropy 472.6317138671875, Learning Rate: 0.00015625\n",
      "Epoch [9653/20000], Loss: 811.551025390625, Entropy 463.7789001464844, Learning Rate: 0.00015625\n",
      "Epoch [9654/20000], Loss: 847.431884765625, Entropy 451.025146484375, Learning Rate: 0.00015625\n",
      "Epoch [9655/20000], Loss: 850.8360595703125, Entropy 461.3170166015625, Learning Rate: 0.00015625\n",
      "Epoch [9656/20000], Loss: 808.4236450195312, Entropy 474.70123291015625, Learning Rate: 0.00015625\n",
      "Epoch [9657/20000], Loss: 870.2285766601562, Entropy 465.09112548828125, Learning Rate: 0.00015625\n",
      "Epoch [9658/20000], Loss: 862.622314453125, Entropy 454.8551025390625, Learning Rate: 0.00015625\n",
      "Epoch [9659/20000], Loss: 843.2623901367188, Entropy 454.22088623046875, Learning Rate: 0.00015625\n",
      "Epoch [9660/20000], Loss: 841.2977294921875, Entropy 463.1111145019531, Learning Rate: 0.00015625\n",
      "Epoch [9661/20000], Loss: 827.8836059570312, Entropy 474.53936767578125, Learning Rate: 0.00015625\n",
      "Epoch [9662/20000], Loss: 839.6680908203125, Entropy 461.8977355957031, Learning Rate: 0.00015625\n",
      "Epoch [9663/20000], Loss: 834.0789794921875, Entropy 461.9862060546875, Learning Rate: 0.00015625\n",
      "Epoch [9664/20000], Loss: 841.3038330078125, Entropy 461.68994140625, Learning Rate: 0.00015625\n",
      "Epoch [9665/20000], Loss: 842.1107177734375, Entropy 458.0238952636719, Learning Rate: 0.00015625\n",
      "Epoch [9666/20000], Loss: 866.1097412109375, Entropy 457.1150817871094, Learning Rate: 0.00015625\n",
      "Epoch [9667/20000], Loss: 890.7503662109375, Entropy 461.4039611816406, Learning Rate: 0.00015625\n",
      "Epoch [9668/20000], Loss: 878.3098754882812, Entropy 453.07733154296875, Learning Rate: 0.00015625\n",
      "Epoch [9669/20000], Loss: 838.163330078125, Entropy 467.6976318359375, Learning Rate: 0.00015625\n",
      "Epoch [9670/20000], Loss: 851.9032592773438, Entropy 472.48480224609375, Learning Rate: 0.00015625\n",
      "Epoch [9671/20000], Loss: 869.9801635742188, Entropy 456.45135498046875, Learning Rate: 0.00015625\n",
      "Epoch [9672/20000], Loss: 827.7593383789062, Entropy 480.58050537109375, Learning Rate: 0.00015625\n",
      "Epoch [9673/20000], Loss: 833.785400390625, Entropy 455.3202209472656, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9674/20000], Loss: 892.4110107421875, Entropy 451.755859375, Learning Rate: 0.00015625\n",
      "Epoch [9675/20000], Loss: 855.2891845703125, Entropy 464.7292175292969, Learning Rate: 0.00015625\n",
      "Epoch [9676/20000], Loss: 817.43408203125, Entropy 474.3890380859375, Learning Rate: 0.00015625\n",
      "Epoch [9677/20000], Loss: 849.848876953125, Entropy 466.3495178222656, Learning Rate: 0.00015625\n",
      "Epoch [9678/20000], Loss: 857.0299072265625, Entropy 470.5119323730469, Learning Rate: 0.00015625\n",
      "Epoch [9679/20000], Loss: 835.046630859375, Entropy 457.5574645996094, Learning Rate: 0.00015625\n",
      "Epoch [9680/20000], Loss: 847.1861572265625, Entropy 462.2761535644531, Learning Rate: 0.00015625\n",
      "Epoch [9681/20000], Loss: 866.7655029296875, Entropy 466.5647888183594, Learning Rate: 0.00015625\n",
      "Epoch [9682/20000], Loss: 840.0089111328125, Entropy 465.0208435058594, Learning Rate: 0.00015625\n",
      "Epoch [9683/20000], Loss: 848.201171875, Entropy 470.1063232421875, Learning Rate: 0.00015625\n",
      "Epoch [9684/20000], Loss: 855.7245483398438, Entropy 466.71099853515625, Learning Rate: 0.00015625\n",
      "Epoch [9685/20000], Loss: 845.15478515625, Entropy 452.8585510253906, Learning Rate: 0.00015625\n",
      "Epoch [9686/20000], Loss: 830.3390502929688, Entropy 465.44171142578125, Learning Rate: 0.00015625\n",
      "Epoch [9687/20000], Loss: 866.988525390625, Entropy 460.93701171875, Learning Rate: 0.00015625\n",
      "Epoch [9688/20000], Loss: 834.6845703125, Entropy 464.3695983886719, Learning Rate: 0.00015625\n",
      "Epoch [9689/20000], Loss: 884.5514526367188, Entropy 459.79412841796875, Learning Rate: 0.00015625\n",
      "Epoch [9690/20000], Loss: 853.2106323242188, Entropy 470.03338623046875, Learning Rate: 0.00015625\n",
      "Epoch [9691/20000], Loss: 858.4906005859375, Entropy 454.9156188964844, Learning Rate: 0.00015625\n",
      "Epoch [9692/20000], Loss: 854.1915283203125, Entropy 470.996826171875, Learning Rate: 0.00015625\n",
      "Epoch [9693/20000], Loss: 844.8475341796875, Entropy 466.7250671386719, Learning Rate: 0.00015625\n",
      "Epoch [9694/20000], Loss: 844.815673828125, Entropy 462.5097961425781, Learning Rate: 0.00015625\n",
      "Epoch [9695/20000], Loss: 866.423583984375, Entropy 468.4375, Learning Rate: 0.00015625\n",
      "Epoch [9696/20000], Loss: 843.1739501953125, Entropy 468.7882385253906, Learning Rate: 0.00015625\n",
      "Epoch [9697/20000], Loss: 857.340576171875, Entropy 471.8797607421875, Learning Rate: 0.00015625\n",
      "Epoch [9698/20000], Loss: 861.57568359375, Entropy 465.4784240722656, Learning Rate: 0.00015625\n",
      "Epoch [9699/20000], Loss: 872.9991455078125, Entropy 456.3777160644531, Learning Rate: 0.00015625\n",
      "Epoch [9700/20000], Loss: 862.565673828125, Entropy 450.6095886230469, Learning Rate: 0.00015625\n",
      "Epoch [9701/20000], Loss: 834.531005859375, Entropy 455.4229736328125, Learning Rate: 0.00015625\n",
      "Epoch [9702/20000], Loss: 876.5965576171875, Entropy 463.884521484375, Learning Rate: 0.00015625\n",
      "Epoch [9703/20000], Loss: 852.7785034179688, Entropy 449.88275146484375, Learning Rate: 0.00015625\n",
      "Epoch [9704/20000], Loss: 855.8245849609375, Entropy 461.9501037597656, Learning Rate: 0.00015625\n",
      "Epoch [9705/20000], Loss: 875.9541015625, Entropy 466.4978942871094, Learning Rate: 0.00015625\n",
      "Epoch [9706/20000], Loss: 881.067626953125, Entropy 454.0177917480469, Learning Rate: 0.00015625\n",
      "Epoch [9707/20000], Loss: 812.7327880859375, Entropy 469.423583984375, Learning Rate: 0.00015625\n",
      "Epoch [9708/20000], Loss: 841.2913208007812, Entropy 466.60589599609375, Learning Rate: 0.00015625\n",
      "Epoch [9709/20000], Loss: 878.0111694335938, Entropy 472.23944091796875, Learning Rate: 0.00015625\n",
      "Epoch [9710/20000], Loss: 865.7742919921875, Entropy 451.828857421875, Learning Rate: 0.00015625\n",
      "Epoch [9711/20000], Loss: 912.9270629882812, Entropy 454.90655517578125, Learning Rate: 0.00015625\n",
      "Epoch [9712/20000], Loss: 859.2550659179688, Entropy 464.84490966796875, Learning Rate: 0.00015625\n",
      "Epoch [9713/20000], Loss: 814.8946533203125, Entropy 467.1331481933594, Learning Rate: 0.00015625\n",
      "Epoch [9714/20000], Loss: 860.076904296875, Entropy 473.2289733886719, Learning Rate: 0.00015625\n",
      "Epoch [9715/20000], Loss: 848.8186645507812, Entropy 466.75286865234375, Learning Rate: 0.00015625\n",
      "Epoch [9716/20000], Loss: 871.9249267578125, Entropy 464.70458984375, Learning Rate: 0.00015625\n",
      "Epoch [9717/20000], Loss: 819.812255859375, Entropy 470.159912109375, Learning Rate: 0.00015625\n",
      "Epoch [9718/20000], Loss: 875.2401123046875, Entropy 466.6568603515625, Learning Rate: 0.00015625\n",
      "Epoch [9719/20000], Loss: 813.045166015625, Entropy 466.4767761230469, Learning Rate: 0.00015625\n",
      "Epoch [9720/20000], Loss: 849.939208984375, Entropy 463.0011291503906, Learning Rate: 0.00015625\n",
      "Epoch [9721/20000], Loss: 867.6712646484375, Entropy 451.7590637207031, Learning Rate: 0.00015625\n",
      "Epoch [9722/20000], Loss: 870.293701171875, Entropy 469.1634521484375, Learning Rate: 0.00015625\n",
      "Epoch [9723/20000], Loss: 878.0394897460938, Entropy 449.58111572265625, Learning Rate: 0.00015625\n",
      "Epoch [9724/20000], Loss: 842.7559814453125, Entropy 469.1324462890625, Learning Rate: 0.00015625\n",
      "Epoch [9725/20000], Loss: 869.3419189453125, Entropy 453.7200927734375, Learning Rate: 0.00015625\n",
      "Epoch [9726/20000], Loss: 863.6139526367188, Entropy 474.36810302734375, Learning Rate: 0.00015625\n",
      "Epoch [9727/20000], Loss: 823.2843017578125, Entropy 455.0767822265625, Learning Rate: 0.00015625\n",
      "Epoch [9728/20000], Loss: 793.48828125, Entropy 468.0652770996094, Learning Rate: 0.00015625\n",
      "Epoch [9729/20000], Loss: 862.92431640625, Entropy 460.8797607421875, Learning Rate: 0.00015625\n",
      "Epoch [9730/20000], Loss: 882.9234619140625, Entropy 463.6864013671875, Learning Rate: 0.00015625\n",
      "Epoch [9731/20000], Loss: 875.172607421875, Entropy 466.4938049316406, Learning Rate: 0.00015625\n",
      "Epoch [9732/20000], Loss: 816.72265625, Entropy 458.19580078125, Learning Rate: 0.00015625\n",
      "Epoch [9733/20000], Loss: 844.544921875, Entropy 457.3392333984375, Learning Rate: 0.00015625\n",
      "Epoch [9734/20000], Loss: 893.003662109375, Entropy 459.3635559082031, Learning Rate: 0.00015625\n",
      "Epoch [9735/20000], Loss: 870.2633056640625, Entropy 468.4682312011719, Learning Rate: 0.00015625\n",
      "Epoch [9736/20000], Loss: 802.576171875, Entropy 463.849609375, Learning Rate: 0.00015625\n",
      "Epoch [9737/20000], Loss: 884.5061645507812, Entropy 472.68475341796875, Learning Rate: 0.00015625\n",
      "Epoch [9738/20000], Loss: 843.337158203125, Entropy 456.8649597167969, Learning Rate: 0.00015625\n",
      "Epoch [9739/20000], Loss: 902.217529296875, Entropy 456.9583435058594, Learning Rate: 0.00015625\n",
      "Epoch [9740/20000], Loss: 856.9553833007812, Entropy 449.89288330078125, Learning Rate: 0.00015625\n",
      "Epoch [9741/20000], Loss: 854.863525390625, Entropy 468.173583984375, Learning Rate: 0.00015625\n",
      "Epoch [9742/20000], Loss: 831.9290771484375, Entropy 463.2183532714844, Learning Rate: 0.00015625\n",
      "Epoch [9743/20000], Loss: 864.0526123046875, Entropy 461.77783203125, Learning Rate: 0.00015625\n",
      "Epoch [9744/20000], Loss: 832.1173095703125, Entropy 468.4446105957031, Learning Rate: 0.00015625\n",
      "Epoch [9745/20000], Loss: 840.2802734375, Entropy 466.3308410644531, Learning Rate: 0.00015625\n",
      "Epoch [9746/20000], Loss: 839.7467651367188, Entropy 448.22796630859375, Learning Rate: 0.00015625\n",
      "Epoch [9747/20000], Loss: 843.1017456054688, Entropy 468.47515869140625, Learning Rate: 0.00015625\n",
      "Epoch [9748/20000], Loss: 825.8452758789062, Entropy 465.94097900390625, Learning Rate: 0.00015625\n",
      "Epoch [9749/20000], Loss: 864.552978515625, Entropy 455.0788879394531, Learning Rate: 0.00015625\n",
      "Epoch [9750/20000], Loss: 859.365966796875, Entropy 457.0724182128906, Learning Rate: 0.00015625\n",
      "Epoch [9751/20000], Loss: 876.7921142578125, Entropy 456.9247131347656, Learning Rate: 0.00015625\n",
      "Epoch [9752/20000], Loss: 806.6847534179688, Entropy 466.49053955078125, Learning Rate: 0.00015625\n",
      "Epoch [9753/20000], Loss: 831.5482788085938, Entropy 472.69561767578125, Learning Rate: 0.00015625\n",
      "Epoch [9754/20000], Loss: 878.4959716796875, Entropy 462.7364501953125, Learning Rate: 0.00015625\n",
      "Epoch [9755/20000], Loss: 880.2373046875, Entropy 466.4830322265625, Learning Rate: 0.00015625\n",
      "Epoch [9756/20000], Loss: 838.996337890625, Entropy 451.177734375, Learning Rate: 0.00015625\n",
      "Epoch [9757/20000], Loss: 849.3704833984375, Entropy 457.3038330078125, Learning Rate: 0.00015625\n",
      "Epoch [9758/20000], Loss: 798.6754150390625, Entropy 469.5015563964844, Learning Rate: 0.00015625\n",
      "Epoch [9759/20000], Loss: 871.2191162109375, Entropy 463.0975646972656, Learning Rate: 0.00015625\n",
      "Epoch [9760/20000], Loss: 841.5474853515625, Entropy 466.9714660644531, Learning Rate: 0.00015625\n",
      "Epoch [9761/20000], Loss: 868.3833618164062, Entropy 454.30474853515625, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9762/20000], Loss: 860.8925170898438, Entropy 461.67242431640625, Learning Rate: 0.00015625\n",
      "Epoch [9763/20000], Loss: 839.0421752929688, Entropy 453.66534423828125, Learning Rate: 0.00015625\n",
      "Epoch [9764/20000], Loss: 842.7847900390625, Entropy 459.3447265625, Learning Rate: 0.00015625\n",
      "Epoch [9765/20000], Loss: 841.7354736328125, Entropy 469.5129089355469, Learning Rate: 0.00015625\n",
      "Epoch [9766/20000], Loss: 879.4592895507812, Entropy 474.19866943359375, Learning Rate: 0.00015625\n",
      "Epoch [9767/20000], Loss: 900.02880859375, Entropy 458.8623352050781, Learning Rate: 0.00015625\n",
      "Epoch [9768/20000], Loss: 817.9207763671875, Entropy 469.5440979003906, Learning Rate: 0.00015625\n",
      "Epoch [9769/20000], Loss: 883.6978149414062, Entropy 465.20623779296875, Learning Rate: 0.00015625\n",
      "Epoch [9770/20000], Loss: 877.2492065429688, Entropy 457.32452392578125, Learning Rate: 0.00015625\n",
      "Epoch [9771/20000], Loss: 868.278076171875, Entropy 449.7438049316406, Learning Rate: 0.00015625\n",
      "Epoch [9772/20000], Loss: 881.1857299804688, Entropy 452.45562744140625, Learning Rate: 0.00015625\n",
      "Epoch [9773/20000], Loss: 875.8402099609375, Entropy 472.7060852050781, Learning Rate: 0.00015625\n",
      "Epoch [9774/20000], Loss: 908.783447265625, Entropy 459.5052185058594, Learning Rate: 0.00015625\n",
      "Epoch [9775/20000], Loss: 846.6858520507812, Entropy 460.66632080078125, Learning Rate: 0.00015625\n",
      "Epoch [9776/20000], Loss: 845.3953857421875, Entropy 459.9568786621094, Learning Rate: 0.00015625\n",
      "Epoch [9777/20000], Loss: 846.65869140625, Entropy 473.562255859375, Learning Rate: 0.00015625\n",
      "Epoch [9778/20000], Loss: 909.2547607421875, Entropy 460.9517822265625, Learning Rate: 0.00015625\n",
      "Epoch [9779/20000], Loss: 836.52783203125, Entropy 457.1585693359375, Learning Rate: 0.00015625\n",
      "Epoch [9780/20000], Loss: 870.7567138671875, Entropy 449.8952941894531, Learning Rate: 0.00015625\n",
      "Epoch [9781/20000], Loss: 812.728271484375, Entropy 463.6065673828125, Learning Rate: 0.00015625\n",
      "Epoch [9782/20000], Loss: 918.0260009765625, Entropy 454.2261657714844, Learning Rate: 0.00015625\n",
      "Epoch [9783/20000], Loss: 868.5643310546875, Entropy 466.5592041015625, Learning Rate: 0.00015625\n",
      "Epoch [9784/20000], Loss: 859.8583374023438, Entropy 469.95440673828125, Learning Rate: 0.00015625\n",
      "Epoch [9785/20000], Loss: 864.030517578125, Entropy 466.98876953125, Learning Rate: 0.00015625\n",
      "Epoch [9786/20000], Loss: 854.554931640625, Entropy 466.0896911621094, Learning Rate: 0.00015625\n",
      "Epoch [9787/20000], Loss: 851.5245361328125, Entropy 460.2664794921875, Learning Rate: 0.00015625\n",
      "Epoch [9788/20000], Loss: 839.8297119140625, Entropy 468.2500305175781, Learning Rate: 0.00015625\n",
      "Epoch [9789/20000], Loss: 855.8043823242188, Entropy 453.77838134765625, Learning Rate: 0.00015625\n",
      "Epoch [9790/20000], Loss: 856.2351684570312, Entropy 478.89788818359375, Learning Rate: 0.00015625\n",
      "Epoch [9791/20000], Loss: 867.7920532226562, Entropy 466.17181396484375, Learning Rate: 0.00015625\n",
      "Epoch [9792/20000], Loss: 841.3138427734375, Entropy 457.183349609375, Learning Rate: 0.00015625\n",
      "Epoch [9793/20000], Loss: 819.6441650390625, Entropy 472.6922607421875, Learning Rate: 0.00015625\n",
      "Epoch [9794/20000], Loss: 826.255615234375, Entropy 459.9360046386719, Learning Rate: 0.00015625\n",
      "Epoch [9795/20000], Loss: 885.8983154296875, Entropy 460.2147521972656, Learning Rate: 0.00015625\n",
      "Epoch [9796/20000], Loss: 858.3248291015625, Entropy 457.9937438964844, Learning Rate: 0.00015625\n",
      "Epoch [9797/20000], Loss: 830.68212890625, Entropy 472.9288635253906, Learning Rate: 0.00015625\n",
      "Epoch [9798/20000], Loss: 922.73388671875, Entropy 449.5235900878906, Learning Rate: 0.00015625\n",
      "Epoch [9799/20000], Loss: 861.4775390625, Entropy 473.5651550292969, Learning Rate: 0.00015625\n",
      "Epoch [9800/20000], Loss: 880.758544921875, Entropy 456.8673095703125, Learning Rate: 0.00015625\n",
      "Epoch [9801/20000], Loss: 840.3802490234375, Entropy 475.0531005859375, Learning Rate: 0.00015625\n",
      "Epoch [9802/20000], Loss: 843.8804931640625, Entropy 463.1271667480469, Learning Rate: 0.00015625\n",
      "Epoch [9803/20000], Loss: 839.4931640625, Entropy 459.3521728515625, Learning Rate: 0.00015625\n",
      "Epoch [9804/20000], Loss: 875.645751953125, Entropy 462.5782775878906, Learning Rate: 0.00015625\n",
      "Epoch [9805/20000], Loss: 865.54345703125, Entropy 453.700927734375, Learning Rate: 0.00015625\n",
      "Epoch [9806/20000], Loss: 836.884521484375, Entropy 458.1250305175781, Learning Rate: 0.00015625\n",
      "Epoch [9807/20000], Loss: 877.8479614257812, Entropy 470.83612060546875, Learning Rate: 0.00015625\n",
      "Epoch [9808/20000], Loss: 853.8935546875, Entropy 474.4617004394531, Learning Rate: 0.00015625\n",
      "Epoch [9809/20000], Loss: 803.2853393554688, Entropy 476.71514892578125, Learning Rate: 0.00015625\n",
      "Epoch [9810/20000], Loss: 859.0126953125, Entropy 465.0237731933594, Learning Rate: 0.00015625\n",
      "Epoch [9811/20000], Loss: 816.3102416992188, Entropy 463.22406005859375, Learning Rate: 0.00015625\n",
      "Epoch [9812/20000], Loss: 881.13671875, Entropy 472.9873352050781, Learning Rate: 0.00015625\n",
      "Epoch [9813/20000], Loss: 834.6015625, Entropy 460.7007751464844, Learning Rate: 0.00015625\n",
      "Epoch [9814/20000], Loss: 918.275390625, Entropy 461.7069396972656, Learning Rate: 0.00015625\n",
      "Epoch [9815/20000], Loss: 830.387451171875, Entropy 461.7913818359375, Learning Rate: 0.00015625\n",
      "Epoch [9816/20000], Loss: 827.0950927734375, Entropy 460.4456787109375, Learning Rate: 0.00015625\n",
      "Epoch [9817/20000], Loss: 880.3228759765625, Entropy 461.577880859375, Learning Rate: 0.00015625\n",
      "Epoch [9818/20000], Loss: 864.7063598632812, Entropy 464.60174560546875, Learning Rate: 0.00015625\n",
      "Epoch [9819/20000], Loss: 881.5196533203125, Entropy 454.7740478515625, Learning Rate: 0.00015625\n",
      "Epoch [9820/20000], Loss: 835.8199462890625, Entropy 473.2931823730469, Learning Rate: 0.00015625\n",
      "Epoch [9821/20000], Loss: 851.7254638671875, Entropy 461.9876403808594, Learning Rate: 0.00015625\n",
      "Epoch [9822/20000], Loss: 839.2891845703125, Entropy 472.4256896972656, Learning Rate: 0.00015625\n",
      "Epoch [9823/20000], Loss: 849.040771484375, Entropy 472.4892883300781, Learning Rate: 0.00015625\n",
      "Epoch [9824/20000], Loss: 843.826416015625, Entropy 464.6637268066406, Learning Rate: 0.00015625\n",
      "Epoch [9825/20000], Loss: 855.86328125, Entropy 453.3336486816406, Learning Rate: 0.00015625\n",
      "Epoch [9826/20000], Loss: 838.231689453125, Entropy 467.4557800292969, Learning Rate: 0.00015625\n",
      "Epoch [9827/20000], Loss: 881.6612548828125, Entropy 468.5965270996094, Learning Rate: 0.00015625\n",
      "Epoch [9828/20000], Loss: 850.2384033203125, Entropy 458.2455749511719, Learning Rate: 0.00015625\n",
      "Epoch [9829/20000], Loss: 777.4436645507812, Entropy 465.74749755859375, Learning Rate: 0.00015625\n",
      "Epoch [9830/20000], Loss: 839.9341430664062, Entropy 471.65362548828125, Learning Rate: 0.00015625\n",
      "Epoch [9831/20000], Loss: 886.298095703125, Entropy 460.8215637207031, Learning Rate: 0.00015625\n",
      "Epoch [9832/20000], Loss: 846.1871337890625, Entropy 460.2740478515625, Learning Rate: 0.00015625\n",
      "Epoch [9833/20000], Loss: 866.6300659179688, Entropy 465.43218994140625, Learning Rate: 0.00015625\n",
      "Epoch [9834/20000], Loss: 913.392578125, Entropy 457.613037109375, Learning Rate: 0.00015625\n",
      "Epoch [9835/20000], Loss: 885.2481689453125, Entropy 453.1614685058594, Learning Rate: 0.00015625\n",
      "Epoch [9836/20000], Loss: 892.206787109375, Entropy 462.3697509765625, Learning Rate: 0.00015625\n",
      "Epoch [9837/20000], Loss: 843.7139892578125, Entropy 460.5693359375, Learning Rate: 0.00015625\n",
      "Epoch [9838/20000], Loss: 879.904541015625, Entropy 456.7597961425781, Learning Rate: 0.00015625\n",
      "Epoch [9839/20000], Loss: 821.1593017578125, Entropy 475.3584899902344, Learning Rate: 0.00015625\n",
      "Epoch [9840/20000], Loss: 822.3746337890625, Entropy 471.0311279296875, Learning Rate: 0.00015625\n",
      "Epoch [9841/20000], Loss: 822.7952880859375, Entropy 473.5291748046875, Learning Rate: 0.00015625\n",
      "Epoch [9842/20000], Loss: 878.1956787109375, Entropy 452.8085021972656, Learning Rate: 0.00015625\n",
      "Epoch [9843/20000], Loss: 899.82666015625, Entropy 474.2197570800781, Learning Rate: 0.00015625\n",
      "Epoch [9844/20000], Loss: 870.464111328125, Entropy 455.822265625, Learning Rate: 0.00015625\n",
      "Epoch [9845/20000], Loss: 870.381591796875, Entropy 462.73583984375, Learning Rate: 0.00015625\n",
      "Epoch [9846/20000], Loss: 844.234375, Entropy 471.5152282714844, Learning Rate: 0.00015625\n",
      "Epoch [9847/20000], Loss: 871.1390991210938, Entropy 472.37396240234375, Learning Rate: 0.00015625\n",
      "Epoch [9848/20000], Loss: 846.9341430664062, Entropy 465.81268310546875, Learning Rate: 0.00015625\n",
      "Epoch [9849/20000], Loss: 853.80322265625, Entropy 469.4474182128906, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9850/20000], Loss: 855.6383056640625, Entropy 461.0667419433594, Learning Rate: 0.00015625\n",
      "Epoch [9851/20000], Loss: 860.9527587890625, Entropy 473.0103759765625, Learning Rate: 0.00015625\n",
      "Epoch [9852/20000], Loss: 832.4228515625, Entropy 468.4954528808594, Learning Rate: 0.00015625\n",
      "Epoch [9853/20000], Loss: 865.7828369140625, Entropy 467.2762145996094, Learning Rate: 0.00015625\n",
      "Epoch [9854/20000], Loss: 813.106201171875, Entropy 472.9166259765625, Learning Rate: 0.00015625\n",
      "Epoch [9855/20000], Loss: 833.9583129882812, Entropy 455.21734619140625, Learning Rate: 0.00015625\n",
      "Epoch [9856/20000], Loss: 845.9110107421875, Entropy 474.2889404296875, Learning Rate: 0.00015625\n",
      "Epoch [9857/20000], Loss: 877.8316650390625, Entropy 455.126708984375, Learning Rate: 0.00015625\n",
      "Epoch [9858/20000], Loss: 821.6270751953125, Entropy 471.3026428222656, Learning Rate: 0.00015625\n",
      "Epoch [9859/20000], Loss: 873.3565063476562, Entropy 457.47967529296875, Learning Rate: 0.00015625\n",
      "Epoch [9860/20000], Loss: 844.69091796875, Entropy 470.9816589355469, Learning Rate: 0.00015625\n",
      "Epoch [9861/20000], Loss: 818.7365112304688, Entropy 459.14801025390625, Learning Rate: 0.00015625\n",
      "Epoch [9862/20000], Loss: 853.1058349609375, Entropy 453.8631286621094, Learning Rate: 0.00015625\n",
      "Epoch [9863/20000], Loss: 841.325927734375, Entropy 458.5735168457031, Learning Rate: 0.00015625\n",
      "Epoch [9864/20000], Loss: 855.9476928710938, Entropy 474.60943603515625, Learning Rate: 0.00015625\n",
      "Epoch [9865/20000], Loss: 844.0830078125, Entropy 469.8723449707031, Learning Rate: 0.00015625\n",
      "Epoch [9866/20000], Loss: 856.6373901367188, Entropy 468.18951416015625, Learning Rate: 0.00015625\n",
      "Epoch [9867/20000], Loss: 876.7935180664062, Entropy 466.18084716796875, Learning Rate: 0.00015625\n",
      "Epoch [9868/20000], Loss: 865.0389404296875, Entropy 468.1637878417969, Learning Rate: 0.00015625\n",
      "Epoch [9869/20000], Loss: 816.6129150390625, Entropy 468.7074890136719, Learning Rate: 0.00015625\n",
      "Epoch [9870/20000], Loss: 847.3148193359375, Entropy 463.9934387207031, Learning Rate: 0.00015625\n",
      "Epoch [9871/20000], Loss: 865.6002197265625, Entropy 467.6991271972656, Learning Rate: 0.00015625\n",
      "Epoch [9872/20000], Loss: 851.9521484375, Entropy 467.9927978515625, Learning Rate: 0.00015625\n",
      "Epoch [9873/20000], Loss: 853.6538696289062, Entropy 464.41265869140625, Learning Rate: 0.00015625\n",
      "Epoch [9874/20000], Loss: 864.3460693359375, Entropy 460.49609375, Learning Rate: 0.00015625\n",
      "Epoch [9875/20000], Loss: 844.7174072265625, Entropy 456.1215515136719, Learning Rate: 0.00015625\n",
      "Epoch [9876/20000], Loss: 863.2752075195312, Entropy 452.10272216796875, Learning Rate: 0.00015625\n",
      "Epoch [9877/20000], Loss: 799.6973876953125, Entropy 468.9718933105469, Learning Rate: 0.00015625\n",
      "Epoch [9878/20000], Loss: 810.11962890625, Entropy 459.1249084472656, Learning Rate: 0.00015625\n",
      "Epoch [9879/20000], Loss: 819.6758422851562, Entropy 464.05902099609375, Learning Rate: 0.00015625\n",
      "Epoch [9880/20000], Loss: 857.6991577148438, Entropy 452.55389404296875, Learning Rate: 0.00015625\n",
      "Epoch [9881/20000], Loss: 846.2733764648438, Entropy 469.64569091796875, Learning Rate: 0.00015625\n",
      "Epoch [9882/20000], Loss: 834.5873413085938, Entropy 469.09173583984375, Learning Rate: 0.00015625\n",
      "Epoch [9883/20000], Loss: 865.1144409179688, Entropy 463.23675537109375, Learning Rate: 0.00015625\n",
      "Epoch [9884/20000], Loss: 885.250732421875, Entropy 453.6398620605469, Learning Rate: 0.00015625\n",
      "Epoch [9885/20000], Loss: 881.8179931640625, Entropy 458.697021484375, Learning Rate: 0.00015625\n",
      "Epoch [9886/20000], Loss: 848.360107421875, Entropy 460.3766174316406, Learning Rate: 0.00015625\n",
      "Epoch [9887/20000], Loss: 838.59326171875, Entropy 462.4291687011719, Learning Rate: 0.00015625\n",
      "Epoch [9888/20000], Loss: 846.8108520507812, Entropy 473.88726806640625, Learning Rate: 0.00015625\n",
      "Epoch [9889/20000], Loss: 842.1112670898438, Entropy 466.26983642578125, Learning Rate: 0.00015625\n",
      "Epoch [9890/20000], Loss: 856.8521728515625, Entropy 453.4241027832031, Learning Rate: 0.00015625\n",
      "Epoch [9891/20000], Loss: 854.040283203125, Entropy 462.3935852050781, Learning Rate: 0.00015625\n",
      "Epoch [9892/20000], Loss: 864.6349487304688, Entropy 462.47503662109375, Learning Rate: 0.00015625\n",
      "Epoch [9893/20000], Loss: 870.6278076171875, Entropy 469.3515625, Learning Rate: 0.00015625\n",
      "Epoch [9894/20000], Loss: 847.15966796875, Entropy 459.2967224121094, Learning Rate: 0.00015625\n",
      "Epoch [9895/20000], Loss: 853.34130859375, Entropy 456.2771911621094, Learning Rate: 0.00015625\n",
      "Epoch [9896/20000], Loss: 894.501953125, Entropy 460.837646484375, Learning Rate: 0.00015625\n",
      "Epoch [9897/20000], Loss: 813.6744384765625, Entropy 463.9519958496094, Learning Rate: 0.00015625\n",
      "Epoch [9898/20000], Loss: 858.545166015625, Entropy 460.7879638671875, Learning Rate: 0.00015625\n",
      "Epoch [9899/20000], Loss: 832.4812622070312, Entropy 458.88568115234375, Learning Rate: 0.00015625\n",
      "Epoch [9900/20000], Loss: 868.8271484375, Entropy 457.53955078125, Learning Rate: 0.00015625\n",
      "Epoch [9901/20000], Loss: 879.0760498046875, Entropy 445.7784729003906, Learning Rate: 0.00015625\n",
      "Epoch [9902/20000], Loss: 829.835693359375, Entropy 472.8383483886719, Learning Rate: 0.00015625\n",
      "Epoch [9903/20000], Loss: 866.7149658203125, Entropy 461.3397521972656, Learning Rate: 0.00015625\n",
      "Epoch [9904/20000], Loss: 839.8321533203125, Entropy 473.2471618652344, Learning Rate: 0.00015625\n",
      "Epoch [9905/20000], Loss: 843.8567504882812, Entropy 473.66607666015625, Learning Rate: 0.00015625\n",
      "Epoch [9906/20000], Loss: 871.427001953125, Entropy 455.5617980957031, Learning Rate: 0.00015625\n",
      "Epoch [9907/20000], Loss: 871.6754760742188, Entropy 456.82257080078125, Learning Rate: 0.00015625\n",
      "Epoch [9908/20000], Loss: 883.496337890625, Entropy 459.8810729980469, Learning Rate: 0.00015625\n",
      "Epoch [9909/20000], Loss: 825.9508056640625, Entropy 451.36669921875, Learning Rate: 0.00015625\n",
      "Epoch [9910/20000], Loss: 846.3255615234375, Entropy 473.6415100097656, Learning Rate: 0.00015625\n",
      "Epoch [9911/20000], Loss: 909.5906982421875, Entropy 452.5298767089844, Learning Rate: 0.00015625\n",
      "Epoch [9912/20000], Loss: 832.0084228515625, Entropy 463.1910705566406, Learning Rate: 0.00015625\n",
      "Epoch [9913/20000], Loss: 820.1500244140625, Entropy 470.2525329589844, Learning Rate: 0.00015625\n",
      "Epoch [9914/20000], Loss: 846.9202880859375, Entropy 466.5177917480469, Learning Rate: 0.00015625\n",
      "Epoch [9915/20000], Loss: 877.5267944335938, Entropy 463.58843994140625, Learning Rate: 0.00015625\n",
      "Epoch [9916/20000], Loss: 903.7692260742188, Entropy 455.13507080078125, Learning Rate: 0.00015625\n",
      "Epoch [9917/20000], Loss: 821.892822265625, Entropy 470.2638854980469, Learning Rate: 0.00015625\n",
      "Epoch [9918/20000], Loss: 873.824462890625, Entropy 467.9993896484375, Learning Rate: 0.00015625\n",
      "Epoch [9919/20000], Loss: 893.845458984375, Entropy 467.7071228027344, Learning Rate: 0.00015625\n",
      "Epoch [9920/20000], Loss: 842.0289916992188, Entropy 462.91741943359375, Learning Rate: 0.00015625\n",
      "Epoch [9921/20000], Loss: 826.4815673828125, Entropy 484.56201171875, Learning Rate: 0.00015625\n",
      "Epoch [9922/20000], Loss: 879.523681640625, Entropy 460.8671875, Learning Rate: 0.00015625\n",
      "Epoch [9923/20000], Loss: 836.9461669921875, Entropy 469.0282287597656, Learning Rate: 0.00015625\n",
      "Epoch [9924/20000], Loss: 881.355712890625, Entropy 453.7118225097656, Learning Rate: 0.00015625\n",
      "Epoch [9925/20000], Loss: 856.854248046875, Entropy 462.6531677246094, Learning Rate: 0.00015625\n",
      "Epoch [9926/20000], Loss: 865.4511108398438, Entropy 460.44622802734375, Learning Rate: 0.00015625\n",
      "Epoch [9927/20000], Loss: 850.7146606445312, Entropy 457.57232666015625, Learning Rate: 0.00015625\n",
      "Epoch [9928/20000], Loss: 829.400390625, Entropy 462.1307067871094, Learning Rate: 0.00015625\n",
      "Epoch [9929/20000], Loss: 845.047119140625, Entropy 464.8418884277344, Learning Rate: 0.00015625\n",
      "Epoch [9930/20000], Loss: 879.1607666015625, Entropy 468.6156921386719, Learning Rate: 0.00015625\n",
      "Epoch [9931/20000], Loss: 825.306396484375, Entropy 474.5515441894531, Learning Rate: 0.00015625\n",
      "Epoch [9932/20000], Loss: 826.0760498046875, Entropy 465.2937927246094, Learning Rate: 0.00015625\n",
      "Epoch [9933/20000], Loss: 892.593017578125, Entropy 455.794921875, Learning Rate: 0.00015625\n",
      "Epoch [9934/20000], Loss: 881.68505859375, Entropy 468.4920959472656, Learning Rate: 0.00015625\n",
      "Epoch [9935/20000], Loss: 886.4251708984375, Entropy 468.8216247558594, Learning Rate: 0.00015625\n",
      "Epoch [9936/20000], Loss: 800.0645751953125, Entropy 466.8229675292969, Learning Rate: 0.00015625\n",
      "Epoch [9937/20000], Loss: 899.66015625, Entropy 459.1060485839844, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9938/20000], Loss: 836.80322265625, Entropy 452.7995910644531, Learning Rate: 0.00015625\n",
      "Epoch [9939/20000], Loss: 809.48779296875, Entropy 464.40576171875, Learning Rate: 0.00015625\n",
      "Epoch [9940/20000], Loss: 824.1834716796875, Entropy 471.66357421875, Learning Rate: 0.00015625\n",
      "Epoch [9941/20000], Loss: 844.5726318359375, Entropy 473.0261535644531, Learning Rate: 0.00015625\n",
      "Epoch [9942/20000], Loss: 867.450927734375, Entropy 459.3369445800781, Learning Rate: 0.00015625\n",
      "Epoch [9943/20000], Loss: 843.9022216796875, Entropy 458.2733459472656, Learning Rate: 0.00015625\n",
      "Epoch [9944/20000], Loss: 804.6009521484375, Entropy 474.5865173339844, Learning Rate: 0.00015625\n",
      "Epoch [9945/20000], Loss: 847.6672973632812, Entropy 469.16107177734375, Learning Rate: 0.00015625\n",
      "Epoch [9946/20000], Loss: 850.59130859375, Entropy 482.6751403808594, Learning Rate: 0.00015625\n",
      "Epoch [9947/20000], Loss: 870.920654296875, Entropy 463.9996032714844, Learning Rate: 0.00015625\n",
      "Epoch [9948/20000], Loss: 847.1959228515625, Entropy 479.9006042480469, Learning Rate: 0.00015625\n",
      "Epoch [9949/20000], Loss: 853.7997436523438, Entropy 462.71209716796875, Learning Rate: 0.00015625\n",
      "Epoch [9950/20000], Loss: 849.5096435546875, Entropy 464.6598815917969, Learning Rate: 0.00015625\n",
      "Epoch [9951/20000], Loss: 847.5438232421875, Entropy 464.2808532714844, Learning Rate: 0.00015625\n",
      "Epoch [9952/20000], Loss: 862.2838134765625, Entropy 467.6446838378906, Learning Rate: 0.00015625\n",
      "Epoch [9953/20000], Loss: 834.26904296875, Entropy 465.368896484375, Learning Rate: 0.00015625\n",
      "Epoch [9954/20000], Loss: 846.3269653320312, Entropy 480.08013916015625, Learning Rate: 0.00015625\n",
      "Epoch [9955/20000], Loss: 833.0646362304688, Entropy 465.98748779296875, Learning Rate: 0.00015625\n",
      "Epoch [9956/20000], Loss: 848.4205322265625, Entropy 466.9638977050781, Learning Rate: 0.00015625\n",
      "Epoch [9957/20000], Loss: 828.5701293945312, Entropy 463.83489990234375, Learning Rate: 0.00015625\n",
      "Epoch [9958/20000], Loss: 883.7657470703125, Entropy 461.0284423828125, Learning Rate: 0.00015625\n",
      "Epoch [9959/20000], Loss: 826.1383666992188, Entropy 469.51690673828125, Learning Rate: 0.00015625\n",
      "Epoch [9960/20000], Loss: 892.8848876953125, Entropy 469.8283386230469, Learning Rate: 0.00015625\n",
      "Epoch [9961/20000], Loss: 863.3192749023438, Entropy 458.17083740234375, Learning Rate: 0.00015625\n",
      "Epoch [9962/20000], Loss: 856.6900634765625, Entropy 452.9923400878906, Learning Rate: 0.00015625\n",
      "Epoch [9963/20000], Loss: 868.92578125, Entropy 460.8882751464844, Learning Rate: 0.00015625\n",
      "Epoch [9964/20000], Loss: 859.4412841796875, Entropy 447.82958984375, Learning Rate: 0.00015625\n",
      "Epoch [9965/20000], Loss: 824.84765625, Entropy 461.5624084472656, Learning Rate: 0.00015625\n",
      "Epoch [9966/20000], Loss: 857.0308227539062, Entropy 466.70941162109375, Learning Rate: 0.00015625\n",
      "Epoch [9967/20000], Loss: 857.42333984375, Entropy 456.0672302246094, Learning Rate: 0.00015625\n",
      "Epoch [9968/20000], Loss: 843.726318359375, Entropy 472.0506286621094, Learning Rate: 0.00015625\n",
      "Epoch [9969/20000], Loss: 846.5640869140625, Entropy 467.2780456542969, Learning Rate: 0.00015625\n",
      "Epoch [9970/20000], Loss: 834.28955078125, Entropy 470.4642333984375, Learning Rate: 0.00015625\n",
      "Epoch [9971/20000], Loss: 840.3529052734375, Entropy 467.27880859375, Learning Rate: 0.00015625\n",
      "Epoch [9972/20000], Loss: 847.590087890625, Entropy 478.1479187011719, Learning Rate: 0.00015625\n",
      "Epoch [9973/20000], Loss: 858.8240966796875, Entropy 459.222412109375, Learning Rate: 0.00015625\n",
      "Epoch [9974/20000], Loss: 873.2498168945312, Entropy 455.15045166015625, Learning Rate: 0.00015625\n",
      "Epoch [9975/20000], Loss: 805.252197265625, Entropy 468.0763244628906, Learning Rate: 0.00015625\n",
      "Epoch [9976/20000], Loss: 863.747314453125, Entropy 463.2454528808594, Learning Rate: 0.00015625\n",
      "Epoch [9977/20000], Loss: 865.5452880859375, Entropy 469.5343933105469, Learning Rate: 0.00015625\n",
      "Epoch [9978/20000], Loss: 864.0087890625, Entropy 457.4060363769531, Learning Rate: 0.00015625\n",
      "Epoch [9979/20000], Loss: 858.7621459960938, Entropy 466.57904052734375, Learning Rate: 0.00015625\n",
      "Epoch [9980/20000], Loss: 845.7733154296875, Entropy 473.9333801269531, Learning Rate: 0.00015625\n",
      "Epoch [9981/20000], Loss: 881.1988525390625, Entropy 458.1345520019531, Learning Rate: 0.00015625\n",
      "Epoch [9982/20000], Loss: 852.86572265625, Entropy 455.3225402832031, Learning Rate: 0.00015625\n",
      "Epoch [9983/20000], Loss: 872.7459716796875, Entropy 471.044677734375, Learning Rate: 0.00015625\n",
      "Epoch [9984/20000], Loss: 885.9992065429688, Entropy 450.82733154296875, Learning Rate: 0.00015625\n",
      "Epoch [9985/20000], Loss: 892.4808349609375, Entropy 451.3273010253906, Learning Rate: 0.00015625\n",
      "Epoch [9986/20000], Loss: 901.3898315429688, Entropy 467.45550537109375, Learning Rate: 0.00015625\n",
      "Epoch [9987/20000], Loss: 889.896728515625, Entropy 457.7064208984375, Learning Rate: 0.00015625\n",
      "Epoch [9988/20000], Loss: 843.0911865234375, Entropy 469.5817565917969, Learning Rate: 0.00015625\n",
      "Epoch [9989/20000], Loss: 896.478271484375, Entropy 463.2956848144531, Learning Rate: 0.00015625\n",
      "Epoch [9990/20000], Loss: 826.421875, Entropy 458.74951171875, Learning Rate: 0.00015625\n",
      "Epoch [9991/20000], Loss: 833.6458740234375, Entropy 469.4534606933594, Learning Rate: 0.00015625\n",
      "Epoch [9992/20000], Loss: 808.200927734375, Entropy 466.4344482421875, Learning Rate: 0.00015625\n",
      "Epoch [9993/20000], Loss: 841.61962890625, Entropy 466.1421813964844, Learning Rate: 0.00015625\n",
      "Epoch [9994/20000], Loss: 849.3316040039062, Entropy 459.98199462890625, Learning Rate: 0.00015625\n",
      "Epoch [9995/20000], Loss: 850.89013671875, Entropy 470.1156005859375, Learning Rate: 0.00015625\n",
      "Epoch [9996/20000], Loss: 835.7817993164062, Entropy 471.46710205078125, Learning Rate: 0.00015625\n",
      "Epoch [9997/20000], Loss: 883.332275390625, Entropy 463.9295959472656, Learning Rate: 0.00015625\n",
      "Epoch [9998/20000], Loss: 869.1507568359375, Entropy 473.4652099609375, Learning Rate: 0.00015625\n",
      "Epoch [9999/20000], Loss: 844.5352783203125, Entropy 466.4332580566406, Learning Rate: 0.00015625\n",
      "Epoch [10000/20000], Loss: 852.302490234375, Entropy 471.5361328125, Learning Rate: 0.00015625\n",
      "Epoch [10001/20000], Loss: 852.0029296875, Entropy 476.1976318359375, Learning Rate: 0.00015625\n",
      "Epoch [10002/20000], Loss: 875.5963134765625, Entropy 456.97021484375, Learning Rate: 0.00015625\n",
      "Epoch [10003/20000], Loss: 893.94189453125, Entropy 455.7508544921875, Learning Rate: 0.00015625\n",
      "Epoch [10004/20000], Loss: 835.8601684570312, Entropy 464.49859619140625, Learning Rate: 0.00015625\n",
      "Epoch [10005/20000], Loss: 849.5540161132812, Entropy 471.45318603515625, Learning Rate: 0.00015625\n",
      "Epoch [10006/20000], Loss: 862.5689697265625, Entropy 464.9708557128906, Learning Rate: 0.00015625\n",
      "Epoch [10007/20000], Loss: 885.8770751953125, Entropy 456.0392150878906, Learning Rate: 0.00015625\n",
      "Epoch [10008/20000], Loss: 870.48681640625, Entropy 461.4595947265625, Learning Rate: 0.00015625\n",
      "Epoch [10009/20000], Loss: 851.58935546875, Entropy 454.0724182128906, Learning Rate: 0.00015625\n",
      "Epoch [10010/20000], Loss: 855.6074829101562, Entropy 470.25433349609375, Learning Rate: 0.00015625\n",
      "Epoch [10011/20000], Loss: 858.8721923828125, Entropy 464.5462646484375, Learning Rate: 0.00015625\n",
      "Epoch [10012/20000], Loss: 899.666015625, Entropy 466.8011169433594, Learning Rate: 0.00015625\n",
      "Epoch [10013/20000], Loss: 819.0330810546875, Entropy 477.2720642089844, Learning Rate: 0.00015625\n",
      "Epoch [10014/20000], Loss: 876.96875, Entropy 463.0987548828125, Learning Rate: 0.00015625\n",
      "Epoch [10015/20000], Loss: 862.641845703125, Entropy 462.4195556640625, Learning Rate: 0.00015625\n",
      "Epoch [10016/20000], Loss: 867.1597900390625, Entropy 451.6170349121094, Learning Rate: 0.00015625\n",
      "Epoch [10017/20000], Loss: 835.924560546875, Entropy 466.710693359375, Learning Rate: 0.00015625\n",
      "Epoch [10018/20000], Loss: 837.8013916015625, Entropy 462.8526611328125, Learning Rate: 0.00015625\n",
      "Epoch [10019/20000], Loss: 885.439453125, Entropy 452.3485107421875, Learning Rate: 0.00015625\n",
      "Epoch [10020/20000], Loss: 866.9676513671875, Entropy 454.7396240234375, Learning Rate: 0.00015625\n",
      "Epoch [10021/20000], Loss: 835.7553100585938, Entropy 462.75872802734375, Learning Rate: 0.00015625\n",
      "Epoch [10022/20000], Loss: 852.8186645507812, Entropy 482.92034912109375, Learning Rate: 0.00015625\n",
      "Epoch [10023/20000], Loss: 836.132568359375, Entropy 467.1089782714844, Learning Rate: 0.00015625\n",
      "Epoch [10024/20000], Loss: 844.5128784179688, Entropy 458.20306396484375, Learning Rate: 0.00015625\n",
      "Epoch [10025/20000], Loss: 857.3140869140625, Entropy 458.9459228515625, Learning Rate: 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10026/20000], Loss: 897.1343994140625, Entropy 473.973388671875, Learning Rate: 0.00015625\n",
      "Epoch [10027/20000], Loss: 836.6065673828125, Entropy 460.458740234375, Learning Rate: 0.00015625\n",
      "Epoch [10028/20000], Loss: 804.75390625, Entropy 478.6556091308594, Learning Rate: 0.00015625\n",
      "Epoch [10029/20000], Loss: 855.783935546875, Entropy 460.1111145019531, Learning Rate: 0.00015625\n",
      "Epoch [10030/20000], Loss: 867.021484375, Entropy 459.2073059082031, Learning Rate: 0.00015625\n",
      "Epoch [10031/20000], Loss: 885.9064331054688, Entropy 469.79974365234375, Learning Rate: 0.00015625\n",
      "Epoch [10032/20000], Loss: 803.766845703125, Entropy 473.2518005371094, Learning Rate: 0.00015625\n",
      "Epoch [10033/20000], Loss: 844.8362426757812, Entropy 466.38189697265625, Learning Rate: 0.00015625\n",
      "Epoch [10034/20000], Loss: 856.436767578125, Entropy 451.5700988769531, Learning Rate: 0.00015625\n",
      "Epoch [10035/20000], Loss: 843.8705444335938, Entropy 472.09112548828125, Learning Rate: 0.00015625\n",
      "Epoch [10036/20000], Loss: 893.3536376953125, Entropy 458.73974609375, Learning Rate: 0.00015625\n",
      "Epoch [10037/20000], Loss: 884.2021484375, Entropy 455.3445129394531, Learning Rate: 0.00015625\n",
      "Epoch [10038/20000], Loss: 845.4999389648438, Entropy 486.52740478515625, Learning Rate: 0.00015625\n",
      "Epoch [10039/20000], Loss: 858.6614990234375, Entropy 476.8326416015625, Learning Rate: 0.00015625\n",
      "Epoch [10040/20000], Loss: 815.0335693359375, Entropy 473.6474914550781, Learning Rate: 0.00015625\n",
      "Epoch [10041/20000], Loss: 867.4735717773438, Entropy 457.25921630859375, Learning Rate: 0.00015625\n",
      "Epoch [10042/20000], Loss: 819.7162475585938, Entropy 471.10882568359375, Learning Rate: 0.00015625\n",
      "Epoch [10043/20000], Loss: 867.1295166015625, Entropy 459.9335021972656, Learning Rate: 0.00015625\n",
      "Epoch [10044/20000], Loss: 829.87841796875, Entropy 463.3541259765625, Learning Rate: 0.00015625\n",
      "Epoch [10045/20000], Loss: 845.169677734375, Entropy 472.4142150878906, Learning Rate: 0.00015625\n",
      "Epoch [10046/20000], Loss: 869.5311889648438, Entropy 463.90545654296875, Learning Rate: 0.00015625\n",
      "Epoch [10047/20000], Loss: 854.9058837890625, Entropy 450.306396484375, Learning Rate: 0.00015625\n",
      "Epoch [10048/20000], Loss: 873.9456787109375, Entropy 465.3201599121094, Learning Rate: 0.00015625\n",
      "Epoch [10049/20000], Loss: 826.05810546875, Entropy 456.9609375, Learning Rate: 0.00015625\n",
      "Epoch [10050/20000], Loss: 831.8193359375, Entropy 459.7674255371094, Learning Rate: 0.00015625\n",
      "Epoch [10051/20000], Loss: 886.6650390625, Entropy 460.6711120605469, Learning Rate: 0.00015625\n",
      "Epoch [10052/20000], Loss: 844.4076538085938, Entropy 471.92608642578125, Learning Rate: 0.00015625\n",
      "Epoch [10053/20000], Loss: 810.2513427734375, Entropy 467.0071716308594, Learning Rate: 0.00015625\n",
      "Epoch [10054/20000], Loss: 819.7032470703125, Entropy 472.0160827636719, Learning Rate: 0.00015625\n",
      "Epoch [10055/20000], Loss: 872.9580688476562, Entropy 461.25982666015625, Learning Rate: 0.00015625\n",
      "Epoch [10056/20000], Loss: 778.4952392578125, Entropy 476.3233337402344, Learning Rate: 0.00015625\n",
      "Epoch [10057/20000], Loss: 884.169677734375, Entropy 466.0101318359375, Learning Rate: 0.00015625\n",
      "Epoch [10058/20000], Loss: 871.7613525390625, Entropy 464.2854919433594, Learning Rate: 0.00015625\n",
      "Epoch [10059/20000], Loss: 852.7455444335938, Entropy 465.98333740234375, Learning Rate: 0.00015625\n",
      "Epoch [10060/20000], Loss: 873.0726318359375, Entropy 473.5575256347656, Learning Rate: 0.00015625\n",
      "Epoch [10061/20000], Loss: 818.214111328125, Entropy 459.5353698730469, Learning Rate: 0.00015625\n",
      "Epoch [10062/20000], Loss: 848.005126953125, Entropy 477.1092529296875, Learning Rate: 0.00015625\n",
      "Epoch [10063/20000], Loss: 852.6282958984375, Entropy 476.7379455566406, Learning Rate: 0.00015625\n",
      "Epoch [10064/20000], Loss: 855.953125, Entropy 464.9315490722656, Learning Rate: 0.00015625\n",
      "Epoch [10065/20000], Loss: 846.4505615234375, Entropy 469.7271728515625, Learning Rate: 0.00015625\n",
      "Epoch [10066/20000], Loss: 850.9544677734375, Entropy 486.6539306640625, Learning Rate: 0.00015625\n",
      "Epoch [10067/20000], Loss: 856.2208251953125, Entropy 459.0115661621094, Learning Rate: 0.00015625\n",
      "Epoch [10068/20000], Loss: 852.508056640625, Entropy 461.25537109375, Learning Rate: 0.00015625\n",
      "Epoch [10069/20000], Loss: 872.765869140625, Entropy 470.1328430175781, Learning Rate: 0.00015625\n",
      "Epoch [10070/20000], Loss: 849.4857788085938, Entropy 458.13568115234375, Learning Rate: 0.00015625\n",
      "Epoch [10071/20000], Loss: 829.4457397460938, Entropy 469.43304443359375, Learning Rate: 0.00015625\n",
      "Epoch [10072/20000], Loss: 858.964599609375, Entropy 480.89990234375, Learning Rate: 0.00015625\n",
      "Epoch [10073/20000], Loss: 831.7791748046875, Entropy 459.6043701171875, Learning Rate: 0.00015625\n",
      "Epoch [10074/20000], Loss: 898.6387329101562, Entropy 455.43060302734375, Learning Rate: 0.00015625\n",
      "Epoch [10075/20000], Loss: 838.8665771484375, Entropy 470.306396484375, Learning Rate: 0.00015625\n",
      "Epoch [10076/20000], Loss: 847.9733276367188, Entropy 472.16302490234375, Learning Rate: 0.00015625\n",
      "Epoch [10077/20000], Loss: 887.1300048828125, Entropy 463.5820617675781, Learning Rate: 0.00015625\n",
      "Epoch [10078/20000], Loss: 790.7086181640625, Entropy 483.9852600097656, Learning Rate: 0.00015625\n",
      "Epoch [10079/20000], Loss: 865.4031982421875, Entropy 472.0037536621094, Learning Rate: 0.00015625\n",
      "Epoch [10080/20000], Loss: 829.954833984375, Entropy 474.6033630371094, Learning Rate: 0.00015625\n",
      "Epoch [10081/20000], Loss: 788.2386474609375, Entropy 459.4105224609375, Learning Rate: 0.00015625\n",
      "Epoch [10082/20000], Loss: 837.6568603515625, Entropy 475.4901428222656, Learning Rate: 0.00015625\n",
      "Epoch [10083/20000], Loss: 827.23486328125, Entropy 469.1725158691406, Learning Rate: 0.00015625\n",
      "Epoch [10084/20000], Loss: 897.2680053710938, Entropy 459.74920654296875, Learning Rate: 0.00015625\n",
      "Epoch [10085/20000], Loss: 863.902099609375, Entropy 466.2607727050781, Learning Rate: 0.00015625\n",
      "Epoch [10086/20000], Loss: 869.4602661132812, Entropy 457.91107177734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10087/20000], Loss: 847.2176513671875, Entropy 484.5735778808594, Learning Rate: 7.8125e-05\n",
      "Epoch [10088/20000], Loss: 846.6982421875, Entropy 470.0502624511719, Learning Rate: 7.8125e-05\n",
      "Epoch [10089/20000], Loss: 814.6821899414062, Entropy 458.95806884765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10090/20000], Loss: 917.163818359375, Entropy 455.0723876953125, Learning Rate: 7.8125e-05\n",
      "Epoch [10091/20000], Loss: 842.73828125, Entropy 461.2278137207031, Learning Rate: 7.8125e-05\n",
      "Epoch [10092/20000], Loss: 852.8046875, Entropy 465.523193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10093/20000], Loss: 840.9786376953125, Entropy 470.7140808105469, Learning Rate: 7.8125e-05\n",
      "Epoch [10094/20000], Loss: 858.77685546875, Entropy 457.3009033203125, Learning Rate: 7.8125e-05\n",
      "Epoch [10095/20000], Loss: 864.5263671875, Entropy 457.8560791015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10096/20000], Loss: 827.95361328125, Entropy 458.025146484375, Learning Rate: 7.8125e-05\n",
      "Epoch [10097/20000], Loss: 851.2589721679688, Entropy 467.94195556640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10098/20000], Loss: 869.8018188476562, Entropy 464.12786865234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10099/20000], Loss: 828.4666137695312, Entropy 463.51971435546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10100/20000], Loss: 905.2637939453125, Entropy 464.7965393066406, Learning Rate: 7.8125e-05\n",
      "Epoch [10101/20000], Loss: 867.9276123046875, Entropy 470.0023193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10102/20000], Loss: 869.435546875, Entropy 468.9034729003906, Learning Rate: 7.8125e-05\n",
      "Epoch [10103/20000], Loss: 836.911865234375, Entropy 465.6191711425781, Learning Rate: 7.8125e-05\n",
      "Epoch [10104/20000], Loss: 867.6376953125, Entropy 467.4897155761719, Learning Rate: 7.8125e-05\n",
      "Epoch [10105/20000], Loss: 833.3206787109375, Entropy 465.7615966796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10106/20000], Loss: 857.14208984375, Entropy 455.8659973144531, Learning Rate: 7.8125e-05\n",
      "Epoch [10107/20000], Loss: 812.6302490234375, Entropy 471.0151062011719, Learning Rate: 7.8125e-05\n",
      "Epoch [10108/20000], Loss: 891.8837890625, Entropy 460.0233459472656, Learning Rate: 7.8125e-05\n",
      "Epoch [10109/20000], Loss: 798.9326171875, Entropy 463.7184143066406, Learning Rate: 7.8125e-05\n",
      "Epoch [10110/20000], Loss: 816.7769165039062, Entropy 475.03326416015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10111/20000], Loss: 845.821533203125, Entropy 464.9547119140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10112/20000], Loss: 869.5118408203125, Entropy 459.8600769042969, Learning Rate: 7.8125e-05\n",
      "Epoch [10113/20000], Loss: 831.2691650390625, Entropy 451.6899108886719, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10114/20000], Loss: 840.4373779296875, Entropy 481.638427734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10115/20000], Loss: 801.0972900390625, Entropy 469.9700012207031, Learning Rate: 7.8125e-05\n",
      "Epoch [10116/20000], Loss: 867.009765625, Entropy 462.9327392578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10117/20000], Loss: 860.3516845703125, Entropy 478.9425354003906, Learning Rate: 7.8125e-05\n",
      "Epoch [10118/20000], Loss: 852.491455078125, Entropy 469.0495300292969, Learning Rate: 7.8125e-05\n",
      "Epoch [10119/20000], Loss: 859.3722534179688, Entropy 461.74334716796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10120/20000], Loss: 836.0819091796875, Entropy 466.9791564941406, Learning Rate: 7.8125e-05\n",
      "Epoch [10121/20000], Loss: 851.732666015625, Entropy 459.3035888671875, Learning Rate: 7.8125e-05\n",
      "Epoch [10122/20000], Loss: 887.835205078125, Entropy 457.8994445800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10123/20000], Loss: 816.8067626953125, Entropy 463.9069519042969, Learning Rate: 7.8125e-05\n",
      "Epoch [10124/20000], Loss: 861.4011840820312, Entropy 464.69171142578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10125/20000], Loss: 889.3092651367188, Entropy 465.98785400390625, Learning Rate: 7.8125e-05\n",
      "Epoch [10126/20000], Loss: 840.2498779296875, Entropy 457.5749816894531, Learning Rate: 7.8125e-05\n",
      "Epoch [10127/20000], Loss: 865.2883911132812, Entropy 469.66021728515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10128/20000], Loss: 818.1917114257812, Entropy 469.81695556640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10129/20000], Loss: 826.8326416015625, Entropy 470.9251403808594, Learning Rate: 7.8125e-05\n",
      "Epoch [10130/20000], Loss: 838.1280517578125, Entropy 464.08984375, Learning Rate: 7.8125e-05\n",
      "Epoch [10131/20000], Loss: 827.9872436523438, Entropy 470.42828369140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10132/20000], Loss: 850.40576171875, Entropy 458.479248046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10133/20000], Loss: 836.7393798828125, Entropy 471.9109191894531, Learning Rate: 7.8125e-05\n",
      "Epoch [10134/20000], Loss: 859.3831787109375, Entropy 465.2414855957031, Learning Rate: 7.8125e-05\n",
      "Epoch [10135/20000], Loss: 839.2650756835938, Entropy 470.35638427734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10136/20000], Loss: 834.9898681640625, Entropy 474.4314270019531, Learning Rate: 7.8125e-05\n",
      "Epoch [10137/20000], Loss: 859.7718505859375, Entropy 483.2727966308594, Learning Rate: 7.8125e-05\n",
      "Epoch [10138/20000], Loss: 818.937255859375, Entropy 468.225341796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10139/20000], Loss: 858.7100219726562, Entropy 446.73297119140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10140/20000], Loss: 835.675537109375, Entropy 464.2961730957031, Learning Rate: 7.8125e-05\n",
      "Epoch [10141/20000], Loss: 847.439453125, Entropy 471.859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10142/20000], Loss: 794.0314331054688, Entropy 470.20526123046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10143/20000], Loss: 886.81201171875, Entropy 463.4447937011719, Learning Rate: 7.8125e-05\n",
      "Epoch [10144/20000], Loss: 869.1214599609375, Entropy 468.5696716308594, Learning Rate: 7.8125e-05\n",
      "Epoch [10145/20000], Loss: 852.8621826171875, Entropy 453.5773620605469, Learning Rate: 7.8125e-05\n",
      "Epoch [10146/20000], Loss: 867.43896484375, Entropy 470.3221435546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10147/20000], Loss: 845.6705322265625, Entropy 450.4990539550781, Learning Rate: 7.8125e-05\n",
      "Epoch [10148/20000], Loss: 859.8380126953125, Entropy 462.322265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10149/20000], Loss: 889.1901245117188, Entropy 456.57171630859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10150/20000], Loss: 904.7139892578125, Entropy 463.8214416503906, Learning Rate: 7.8125e-05\n",
      "Epoch [10151/20000], Loss: 856.4664916992188, Entropy 471.46124267578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10152/20000], Loss: 777.846923828125, Entropy 462.66455078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10153/20000], Loss: 850.2158203125, Entropy 458.4256591796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10154/20000], Loss: 842.893310546875, Entropy 454.7261657714844, Learning Rate: 7.8125e-05\n",
      "Epoch [10155/20000], Loss: 842.2243041992188, Entropy 461.13787841796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10156/20000], Loss: 847.09716796875, Entropy 460.6572570800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10157/20000], Loss: 865.3966064453125, Entropy 461.8796081542969, Learning Rate: 7.8125e-05\n",
      "Epoch [10158/20000], Loss: 814.9345703125, Entropy 457.5002136230469, Learning Rate: 7.8125e-05\n",
      "Epoch [10159/20000], Loss: 850.2869262695312, Entropy 459.02349853515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10160/20000], Loss: 869.6846923828125, Entropy 468.7205505371094, Learning Rate: 7.8125e-05\n",
      "Epoch [10161/20000], Loss: 815.1388549804688, Entropy 480.26873779296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10162/20000], Loss: 885.62646484375, Entropy 469.5292053222656, Learning Rate: 7.8125e-05\n",
      "Epoch [10163/20000], Loss: 893.2169189453125, Entropy 447.9089660644531, Learning Rate: 7.8125e-05\n",
      "Epoch [10164/20000], Loss: 869.3067016601562, Entropy 463.75018310546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10165/20000], Loss: 860.7589721679688, Entropy 456.85833740234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10166/20000], Loss: 835.951171875, Entropy 471.6218566894531, Learning Rate: 7.8125e-05\n",
      "Epoch [10167/20000], Loss: 869.0321044921875, Entropy 462.09814453125, Learning Rate: 7.8125e-05\n",
      "Epoch [10168/20000], Loss: 866.4237060546875, Entropy 474.9256286621094, Learning Rate: 7.8125e-05\n",
      "Epoch [10169/20000], Loss: 884.7255859375, Entropy 471.9191589355469, Learning Rate: 7.8125e-05\n",
      "Epoch [10170/20000], Loss: 833.7894287109375, Entropy 457.6600036621094, Learning Rate: 7.8125e-05\n",
      "Epoch [10171/20000], Loss: 852.0911254882812, Entropy 481.17327880859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10172/20000], Loss: 891.3580932617188, Entropy 455.25311279296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10173/20000], Loss: 857.162353515625, Entropy 453.906005859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10174/20000], Loss: 875.4044189453125, Entropy 463.0699462890625, Learning Rate: 7.8125e-05\n",
      "Epoch [10175/20000], Loss: 892.6813354492188, Entropy 451.16705322265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10176/20000], Loss: 832.222900390625, Entropy 470.8484802246094, Learning Rate: 7.8125e-05\n",
      "Epoch [10177/20000], Loss: 800.3823852539062, Entropy 476.00677490234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10178/20000], Loss: 884.0164794921875, Entropy 455.4733581542969, Learning Rate: 7.8125e-05\n",
      "Epoch [10179/20000], Loss: 849.7003784179688, Entropy 466.35174560546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10180/20000], Loss: 834.9449462890625, Entropy 468.9647521972656, Learning Rate: 7.8125e-05\n",
      "Epoch [10181/20000], Loss: 829.2943725585938, Entropy 469.95147705078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10182/20000], Loss: 844.10693359375, Entropy 467.1268310546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10183/20000], Loss: 895.6946411132812, Entropy 459.41424560546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10184/20000], Loss: 837.7919921875, Entropy 467.5902099609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10185/20000], Loss: 887.60595703125, Entropy 465.6234130859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10186/20000], Loss: 838.0704345703125, Entropy 459.7226867675781, Learning Rate: 7.8125e-05\n",
      "Epoch [10187/20000], Loss: 882.630859375, Entropy 463.2062683105469, Learning Rate: 7.8125e-05\n",
      "Epoch [10188/20000], Loss: 829.8851318359375, Entropy 458.8462829589844, Learning Rate: 7.8125e-05\n",
      "Epoch [10189/20000], Loss: 866.0634155273438, Entropy 459.18072509765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10190/20000], Loss: 884.1138916015625, Entropy 467.71044921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10191/20000], Loss: 854.0466918945312, Entropy 473.24139404296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10192/20000], Loss: 834.062744140625, Entropy 472.5208435058594, Learning Rate: 7.8125e-05\n",
      "Epoch [10193/20000], Loss: 791.3576049804688, Entropy 459.25592041015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10194/20000], Loss: 830.0068359375, Entropy 485.4244384765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10195/20000], Loss: 849.22802734375, Entropy 476.9806823730469, Learning Rate: 7.8125e-05\n",
      "Epoch [10196/20000], Loss: 871.4368286132812, Entropy 459.28070068359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10197/20000], Loss: 838.0408935546875, Entropy 464.3404235839844, Learning Rate: 7.8125e-05\n",
      "Epoch [10198/20000], Loss: 861.042724609375, Entropy 465.4880065917969, Learning Rate: 7.8125e-05\n",
      "Epoch [10199/20000], Loss: 815.370361328125, Entropy 464.6003112792969, Learning Rate: 7.8125e-05\n",
      "Epoch [10200/20000], Loss: 841.2945556640625, Entropy 467.9696044921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10201/20000], Loss: 794.6171875, Entropy 482.1567077636719, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10202/20000], Loss: 864.371337890625, Entropy 458.6383361816406, Learning Rate: 7.8125e-05\n",
      "Epoch [10203/20000], Loss: 883.34521484375, Entropy 460.0791015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10204/20000], Loss: 859.8120727539062, Entropy 471.68951416015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10205/20000], Loss: 817.1904296875, Entropy 476.7052917480469, Learning Rate: 7.8125e-05\n",
      "Epoch [10206/20000], Loss: 845.4072265625, Entropy 462.4460754394531, Learning Rate: 7.8125e-05\n",
      "Epoch [10207/20000], Loss: 854.1228637695312, Entropy 464.73272705078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10208/20000], Loss: 810.392578125, Entropy 478.7491149902344, Learning Rate: 7.8125e-05\n",
      "Epoch [10209/20000], Loss: 854.6092529296875, Entropy 452.4634704589844, Learning Rate: 7.8125e-05\n",
      "Epoch [10210/20000], Loss: 839.5347900390625, Entropy 472.9396667480469, Learning Rate: 7.8125e-05\n",
      "Epoch [10211/20000], Loss: 836.759033203125, Entropy 463.2574157714844, Learning Rate: 7.8125e-05\n",
      "Epoch [10212/20000], Loss: 884.8555297851562, Entropy 464.77630615234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10213/20000], Loss: 833.017333984375, Entropy 459.8428955078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10214/20000], Loss: 906.54248046875, Entropy 473.3443603515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10215/20000], Loss: 874.6611938476562, Entropy 462.61444091796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10216/20000], Loss: 831.1485595703125, Entropy 464.6865539550781, Learning Rate: 7.8125e-05\n",
      "Epoch [10217/20000], Loss: 833.022705078125, Entropy 470.847412109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10218/20000], Loss: 880.929931640625, Entropy 458.9244384765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10219/20000], Loss: 858.2213745117188, Entropy 457.17926025390625, Learning Rate: 7.8125e-05\n",
      "Epoch [10220/20000], Loss: 828.4069213867188, Entropy 466.72174072265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10221/20000], Loss: 860.1023559570312, Entropy 470.82452392578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10222/20000], Loss: 875.1033935546875, Entropy 459.3994445800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10223/20000], Loss: 884.8172607421875, Entropy 472.3346862792969, Learning Rate: 7.8125e-05\n",
      "Epoch [10224/20000], Loss: 839.1255493164062, Entropy 464.62921142578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10225/20000], Loss: 875.878173828125, Entropy 468.1683349609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10226/20000], Loss: 879.368896484375, Entropy 472.5289001464844, Learning Rate: 7.8125e-05\n",
      "Epoch [10227/20000], Loss: 813.8289184570312, Entropy 464.48724365234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10228/20000], Loss: 814.29736328125, Entropy 459.0145263671875, Learning Rate: 7.8125e-05\n",
      "Epoch [10229/20000], Loss: 873.322265625, Entropy 486.3056945800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10230/20000], Loss: 899.5039672851562, Entropy 460.79791259765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10231/20000], Loss: 858.5938720703125, Entropy 479.3885803222656, Learning Rate: 7.8125e-05\n",
      "Epoch [10232/20000], Loss: 821.1051025390625, Entropy 456.9952392578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10233/20000], Loss: 890.93701171875, Entropy 457.6252136230469, Learning Rate: 7.8125e-05\n",
      "Epoch [10234/20000], Loss: 828.072265625, Entropy 462.1727600097656, Learning Rate: 7.8125e-05\n",
      "Epoch [10235/20000], Loss: 828.04833984375, Entropy 466.5281066894531, Learning Rate: 7.8125e-05\n",
      "Epoch [10236/20000], Loss: 857.8641357421875, Entropy 467.3366394042969, Learning Rate: 7.8125e-05\n",
      "Epoch [10237/20000], Loss: 821.8721923828125, Entropy 469.5726318359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10238/20000], Loss: 855.9556274414062, Entropy 465.79388427734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10239/20000], Loss: 843.2474365234375, Entropy 460.6192932128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10240/20000], Loss: 810.9207763671875, Entropy 457.0917053222656, Learning Rate: 7.8125e-05\n",
      "Epoch [10241/20000], Loss: 876.357421875, Entropy 452.6106872558594, Learning Rate: 7.8125e-05\n",
      "Epoch [10242/20000], Loss: 832.892333984375, Entropy 477.5133972167969, Learning Rate: 7.8125e-05\n",
      "Epoch [10243/20000], Loss: 837.7100219726562, Entropy 467.65557861328125, Learning Rate: 7.8125e-05\n",
      "Epoch [10244/20000], Loss: 827.33447265625, Entropy 462.8877258300781, Learning Rate: 7.8125e-05\n",
      "Epoch [10245/20000], Loss: 811.6175537109375, Entropy 470.1367492675781, Learning Rate: 7.8125e-05\n",
      "Epoch [10246/20000], Loss: 869.6669921875, Entropy 465.8614807128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10247/20000], Loss: 856.956298828125, Entropy 464.7867736816406, Learning Rate: 7.8125e-05\n",
      "Epoch [10248/20000], Loss: 833.443359375, Entropy 456.4776916503906, Learning Rate: 7.8125e-05\n",
      "Epoch [10249/20000], Loss: 820.751953125, Entropy 476.589599609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10250/20000], Loss: 814.107666015625, Entropy 481.8262023925781, Learning Rate: 7.8125e-05\n",
      "Epoch [10251/20000], Loss: 846.5122680664062, Entropy 467.85943603515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10252/20000], Loss: 825.1888427734375, Entropy 473.4250793457031, Learning Rate: 7.8125e-05\n",
      "Epoch [10253/20000], Loss: 853.2186279296875, Entropy 461.998046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10254/20000], Loss: 839.1541137695312, Entropy 480.55303955078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10255/20000], Loss: 875.6163330078125, Entropy 464.1912841796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10256/20000], Loss: 828.15673828125, Entropy 455.093505859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10257/20000], Loss: 841.427978515625, Entropy 479.3668518066406, Learning Rate: 7.8125e-05\n",
      "Epoch [10258/20000], Loss: 833.9434814453125, Entropy 468.1934509277344, Learning Rate: 7.8125e-05\n",
      "Epoch [10259/20000], Loss: 871.933349609375, Entropy 456.775390625, Learning Rate: 7.8125e-05\n",
      "Epoch [10260/20000], Loss: 799.5078735351562, Entropy 494.47015380859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10261/20000], Loss: 857.1408081054688, Entropy 456.75823974609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10262/20000], Loss: 864.5127563476562, Entropy 463.48284912109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10263/20000], Loss: 823.46337890625, Entropy 482.1133728027344, Learning Rate: 7.8125e-05\n",
      "Epoch [10264/20000], Loss: 836.112060546875, Entropy 473.9691162109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10265/20000], Loss: 846.8525390625, Entropy 466.2317810058594, Learning Rate: 7.8125e-05\n",
      "Epoch [10266/20000], Loss: 857.9718017578125, Entropy 465.0384216308594, Learning Rate: 7.8125e-05\n",
      "Epoch [10267/20000], Loss: 870.7666015625, Entropy 460.9041442871094, Learning Rate: 7.8125e-05\n",
      "Epoch [10268/20000], Loss: 871.931884765625, Entropy 455.3149108886719, Learning Rate: 7.8125e-05\n",
      "Epoch [10269/20000], Loss: 839.4173583984375, Entropy 466.5691223144531, Learning Rate: 7.8125e-05\n",
      "Epoch [10270/20000], Loss: 863.69091796875, Entropy 467.2209777832031, Learning Rate: 7.8125e-05\n",
      "Epoch [10271/20000], Loss: 852.043212890625, Entropy 469.67822265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10272/20000], Loss: 851.473876953125, Entropy 459.0080261230469, Learning Rate: 7.8125e-05\n",
      "Epoch [10273/20000], Loss: 891.0682373046875, Entropy 462.5782775878906, Learning Rate: 7.8125e-05\n",
      "Epoch [10274/20000], Loss: 826.8722534179688, Entropy 461.61773681640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10275/20000], Loss: 840.5552978515625, Entropy 465.359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10276/20000], Loss: 871.4942626953125, Entropy 483.2104187011719, Learning Rate: 7.8125e-05\n",
      "Epoch [10277/20000], Loss: 865.9566650390625, Entropy 466.5881042480469, Learning Rate: 7.8125e-05\n",
      "Epoch [10278/20000], Loss: 851.4697875976562, Entropy 469.24114990234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10279/20000], Loss: 871.4722900390625, Entropy 454.4171142578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10280/20000], Loss: 834.2567138671875, Entropy 462.5646057128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10281/20000], Loss: 849.2982177734375, Entropy 464.1434326171875, Learning Rate: 7.8125e-05\n",
      "Epoch [10282/20000], Loss: 832.928955078125, Entropy 462.9308776855469, Learning Rate: 7.8125e-05\n",
      "Epoch [10283/20000], Loss: 858.263671875, Entropy 475.044677734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10284/20000], Loss: 853.6085205078125, Entropy 446.4146728515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10285/20000], Loss: 858.6439208984375, Entropy 472.3633117675781, Learning Rate: 7.8125e-05\n",
      "Epoch [10286/20000], Loss: 866.951416015625, Entropy 464.9197998046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10287/20000], Loss: 799.9015502929688, Entropy 478.50445556640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10288/20000], Loss: 859.6015625, Entropy 474.7909240722656, Learning Rate: 7.8125e-05\n",
      "Epoch [10289/20000], Loss: 844.8240356445312, Entropy 465.52557373046875, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10290/20000], Loss: 824.2285766601562, Entropy 470.59515380859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10291/20000], Loss: 862.909423828125, Entropy 473.7642822265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10292/20000], Loss: 859.37939453125, Entropy 458.5911865234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10293/20000], Loss: 890.4921875, Entropy 472.8063659667969, Learning Rate: 7.8125e-05\n",
      "Epoch [10294/20000], Loss: 887.8592529296875, Entropy 462.8025817871094, Learning Rate: 7.8125e-05\n",
      "Epoch [10295/20000], Loss: 842.6792602539062, Entropy 461.60601806640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10296/20000], Loss: 837.20166015625, Entropy 464.3010559082031, Learning Rate: 7.8125e-05\n",
      "Epoch [10297/20000], Loss: 843.9095458984375, Entropy 475.8766784667969, Learning Rate: 7.8125e-05\n",
      "Epoch [10298/20000], Loss: 812.0285034179688, Entropy 466.86224365234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10299/20000], Loss: 778.1763916015625, Entropy 468.2439270019531, Learning Rate: 7.8125e-05\n",
      "Epoch [10300/20000], Loss: 842.2667236328125, Entropy 461.1169738769531, Learning Rate: 7.8125e-05\n",
      "Epoch [10301/20000], Loss: 810.864501953125, Entropy 473.9378662109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10302/20000], Loss: 855.4622192382812, Entropy 472.88665771484375, Learning Rate: 7.8125e-05\n",
      "Epoch [10303/20000], Loss: 880.1629028320312, Entropy 472.91607666015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10304/20000], Loss: 828.1968994140625, Entropy 475.5437927246094, Learning Rate: 7.8125e-05\n",
      "Epoch [10305/20000], Loss: 865.7803955078125, Entropy 464.292724609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10306/20000], Loss: 860.1207275390625, Entropy 455.4688720703125, Learning Rate: 7.8125e-05\n",
      "Epoch [10307/20000], Loss: 843.162353515625, Entropy 456.5767517089844, Learning Rate: 7.8125e-05\n",
      "Epoch [10308/20000], Loss: 888.521484375, Entropy 453.0972595214844, Learning Rate: 7.8125e-05\n",
      "Epoch [10309/20000], Loss: 867.0650634765625, Entropy 455.7550048828125, Learning Rate: 7.8125e-05\n",
      "Epoch [10310/20000], Loss: 869.059326171875, Entropy 470.2059020996094, Learning Rate: 7.8125e-05\n",
      "Epoch [10311/20000], Loss: 846.8552856445312, Entropy 467.17791748046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10312/20000], Loss: 856.3720703125, Entropy 467.4043884277344, Learning Rate: 7.8125e-05\n",
      "Epoch [10313/20000], Loss: 856.76025390625, Entropy 455.53466796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10314/20000], Loss: 847.177978515625, Entropy 467.31982421875, Learning Rate: 7.8125e-05\n",
      "Epoch [10315/20000], Loss: 796.922119140625, Entropy 466.2082824707031, Learning Rate: 7.8125e-05\n",
      "Epoch [10316/20000], Loss: 851.5228271484375, Entropy 453.5370178222656, Learning Rate: 7.8125e-05\n",
      "Epoch [10317/20000], Loss: 874.6466064453125, Entropy 463.0936584472656, Learning Rate: 7.8125e-05\n",
      "Epoch [10318/20000], Loss: 815.072509765625, Entropy 461.2316589355469, Learning Rate: 7.8125e-05\n",
      "Epoch [10319/20000], Loss: 857.2994384765625, Entropy 475.6790466308594, Learning Rate: 7.8125e-05\n",
      "Epoch [10320/20000], Loss: 862.7399291992188, Entropy 466.77374267578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10321/20000], Loss: 836.20458984375, Entropy 468.9211120605469, Learning Rate: 7.8125e-05\n",
      "Epoch [10322/20000], Loss: 805.4825439453125, Entropy 449.3031921386719, Learning Rate: 7.8125e-05\n",
      "Epoch [10323/20000], Loss: 824.8792114257812, Entropy 468.86712646484375, Learning Rate: 7.8125e-05\n",
      "Epoch [10324/20000], Loss: 864.7310180664062, Entropy 459.26483154296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10325/20000], Loss: 843.9051513671875, Entropy 467.8137512207031, Learning Rate: 7.8125e-05\n",
      "Epoch [10326/20000], Loss: 862.3170166015625, Entropy 467.2898254394531, Learning Rate: 7.8125e-05\n",
      "Epoch [10327/20000], Loss: 834.327392578125, Entropy 479.858154296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10328/20000], Loss: 857.2161865234375, Entropy 463.5652160644531, Learning Rate: 7.8125e-05\n",
      "Epoch [10329/20000], Loss: 847.2094116210938, Entropy 469.41461181640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10330/20000], Loss: 844.2589111328125, Entropy 461.5377197265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10331/20000], Loss: 802.9620361328125, Entropy 478.964599609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10332/20000], Loss: 846.8687744140625, Entropy 472.7667541503906, Learning Rate: 7.8125e-05\n",
      "Epoch [10333/20000], Loss: 830.77734375, Entropy 469.4549255371094, Learning Rate: 7.8125e-05\n",
      "Epoch [10334/20000], Loss: 838.2293701171875, Entropy 469.3141784667969, Learning Rate: 7.8125e-05\n",
      "Epoch [10335/20000], Loss: 822.9615478515625, Entropy 477.7953796386719, Learning Rate: 7.8125e-05\n",
      "Epoch [10336/20000], Loss: 847.7880249023438, Entropy 467.84869384765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10337/20000], Loss: 894.1866455078125, Entropy 461.1436767578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10338/20000], Loss: 822.5889892578125, Entropy 475.4645080566406, Learning Rate: 7.8125e-05\n",
      "Epoch [10339/20000], Loss: 896.0264282226562, Entropy 468.55474853515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10340/20000], Loss: 819.1520385742188, Entropy 472.80133056640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10341/20000], Loss: 826.31884765625, Entropy 471.24462890625, Learning Rate: 7.8125e-05\n",
      "Epoch [10342/20000], Loss: 869.2379760742188, Entropy 454.98858642578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10343/20000], Loss: 868.870361328125, Entropy 462.7351989746094, Learning Rate: 7.8125e-05\n",
      "Epoch [10344/20000], Loss: 879.5802001953125, Entropy 454.7369079589844, Learning Rate: 7.8125e-05\n",
      "Epoch [10345/20000], Loss: 812.17529296875, Entropy 465.5649108886719, Learning Rate: 7.8125e-05\n",
      "Epoch [10346/20000], Loss: 870.6500244140625, Entropy 470.6649169921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10347/20000], Loss: 812.0642700195312, Entropy 467.90850830078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10348/20000], Loss: 832.1048583984375, Entropy 467.5198974609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10349/20000], Loss: 814.3523559570312, Entropy 484.26116943359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10350/20000], Loss: 802.2283935546875, Entropy 459.7236633300781, Learning Rate: 7.8125e-05\n",
      "Epoch [10351/20000], Loss: 879.3629150390625, Entropy 468.8045959472656, Learning Rate: 7.8125e-05\n",
      "Epoch [10352/20000], Loss: 832.7156982421875, Entropy 469.45556640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10353/20000], Loss: 820.2391357421875, Entropy 467.6601867675781, Learning Rate: 7.8125e-05\n",
      "Epoch [10354/20000], Loss: 821.2548828125, Entropy 481.070068359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10355/20000], Loss: 826.681396484375, Entropy 474.5953674316406, Learning Rate: 7.8125e-05\n",
      "Epoch [10356/20000], Loss: 841.8734130859375, Entropy 469.1483459472656, Learning Rate: 7.8125e-05\n",
      "Epoch [10357/20000], Loss: 843.3665771484375, Entropy 467.1705017089844, Learning Rate: 7.8125e-05\n",
      "Epoch [10358/20000], Loss: 817.7310791015625, Entropy 466.3692932128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10359/20000], Loss: 868.9229736328125, Entropy 460.8790283203125, Learning Rate: 7.8125e-05\n",
      "Epoch [10360/20000], Loss: 832.625, Entropy 452.7870178222656, Learning Rate: 7.8125e-05\n",
      "Epoch [10361/20000], Loss: 847.07568359375, Entropy 478.01708984375, Learning Rate: 7.8125e-05\n",
      "Epoch [10362/20000], Loss: 891.4996337890625, Entropy 474.9123840332031, Learning Rate: 7.8125e-05\n",
      "Epoch [10363/20000], Loss: 851.2523193359375, Entropy 460.75390625, Learning Rate: 7.8125e-05\n",
      "Epoch [10364/20000], Loss: 841.4551391601562, Entropy 468.07354736328125, Learning Rate: 7.8125e-05\n",
      "Epoch [10365/20000], Loss: 826.1348876953125, Entropy 468.8870849609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10366/20000], Loss: 836.2504272460938, Entropy 453.65875244140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10367/20000], Loss: 875.0336303710938, Entropy 466.51568603515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10368/20000], Loss: 907.8203125, Entropy 468.0553894042969, Learning Rate: 7.8125e-05\n",
      "Epoch [10369/20000], Loss: 833.3111572265625, Entropy 475.3757629394531, Learning Rate: 7.8125e-05\n",
      "Epoch [10370/20000], Loss: 862.3048095703125, Entropy 460.5534973144531, Learning Rate: 7.8125e-05\n",
      "Epoch [10371/20000], Loss: 836.178955078125, Entropy 469.1070251464844, Learning Rate: 7.8125e-05\n",
      "Epoch [10372/20000], Loss: 832.718505859375, Entropy 468.2428894042969, Learning Rate: 7.8125e-05\n",
      "Epoch [10373/20000], Loss: 833.5823974609375, Entropy 467.5110778808594, Learning Rate: 7.8125e-05\n",
      "Epoch [10374/20000], Loss: 849.7835693359375, Entropy 459.7696533203125, Learning Rate: 7.8125e-05\n",
      "Epoch [10375/20000], Loss: 824.9439086914062, Entropy 468.57232666015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10376/20000], Loss: 800.7363891601562, Entropy 468.53228759765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10377/20000], Loss: 883.197509765625, Entropy 484.0230407714844, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10378/20000], Loss: 853.098388671875, Entropy 464.1803283691406, Learning Rate: 7.8125e-05\n",
      "Epoch [10379/20000], Loss: 839.79443359375, Entropy 464.1784973144531, Learning Rate: 7.8125e-05\n",
      "Epoch [10380/20000], Loss: 884.0914306640625, Entropy 458.5325622558594, Learning Rate: 7.8125e-05\n",
      "Epoch [10381/20000], Loss: 839.4150390625, Entropy 473.3535461425781, Learning Rate: 7.8125e-05\n",
      "Epoch [10382/20000], Loss: 874.8430786132812, Entropy 478.85076904296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10383/20000], Loss: 852.4365234375, Entropy 462.3482666015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10384/20000], Loss: 814.8092651367188, Entropy 481.64068603515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10385/20000], Loss: 842.5490112304688, Entropy 480.48358154296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10386/20000], Loss: 828.6536254882812, Entropy 466.73382568359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10387/20000], Loss: 859.6494750976562, Entropy 458.34173583984375, Learning Rate: 7.8125e-05\n",
      "Epoch [10388/20000], Loss: 914.5663452148438, Entropy 459.74053955078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10389/20000], Loss: 814.619140625, Entropy 473.9188232421875, Learning Rate: 7.8125e-05\n",
      "Epoch [10390/20000], Loss: 877.6265869140625, Entropy 458.4153747558594, Learning Rate: 7.8125e-05\n",
      "Epoch [10391/20000], Loss: 834.1573486328125, Entropy 476.529052734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10392/20000], Loss: 836.890380859375, Entropy 461.5721130371094, Learning Rate: 7.8125e-05\n",
      "Epoch [10393/20000], Loss: 814.1962890625, Entropy 471.96435546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10394/20000], Loss: 830.0135498046875, Entropy 466.3295593261719, Learning Rate: 7.8125e-05\n",
      "Epoch [10395/20000], Loss: 870.022216796875, Entropy 463.6896057128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10396/20000], Loss: 826.1915283203125, Entropy 483.1986999511719, Learning Rate: 7.8125e-05\n",
      "Epoch [10397/20000], Loss: 866.1556396484375, Entropy 463.3817138671875, Learning Rate: 7.8125e-05\n",
      "Epoch [10398/20000], Loss: 866.4999389648438, Entropy 459.40911865234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10399/20000], Loss: 864.4110107421875, Entropy 463.9111633300781, Learning Rate: 7.8125e-05\n",
      "Epoch [10400/20000], Loss: 840.9942016601562, Entropy 466.95050048828125, Learning Rate: 7.8125e-05\n",
      "Epoch [10401/20000], Loss: 848.025146484375, Entropy 463.2131042480469, Learning Rate: 7.8125e-05\n",
      "Epoch [10402/20000], Loss: 847.1627197265625, Entropy 468.9020080566406, Learning Rate: 7.8125e-05\n",
      "Epoch [10403/20000], Loss: 839.210205078125, Entropy 468.30419921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10404/20000], Loss: 844.6312866210938, Entropy 469.47161865234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10405/20000], Loss: 871.1697998046875, Entropy 457.0057067871094, Learning Rate: 7.8125e-05\n",
      "Epoch [10406/20000], Loss: 863.6527099609375, Entropy 468.7006530761719, Learning Rate: 7.8125e-05\n",
      "Epoch [10407/20000], Loss: 852.9468383789062, Entropy 466.27655029296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10408/20000], Loss: 875.3900756835938, Entropy 472.27008056640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10409/20000], Loss: 845.3369140625, Entropy 465.462890625, Learning Rate: 7.8125e-05\n",
      "Epoch [10410/20000], Loss: 881.976806640625, Entropy 452.889404296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10411/20000], Loss: 872.3421020507812, Entropy 475.90093994140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10412/20000], Loss: 834.1083374023438, Entropy 468.91363525390625, Learning Rate: 7.8125e-05\n",
      "Epoch [10413/20000], Loss: 853.347412109375, Entropy 458.8022155761719, Learning Rate: 7.8125e-05\n",
      "Epoch [10414/20000], Loss: 840.2571411132812, Entropy 473.09686279296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10415/20000], Loss: 838.33740234375, Entropy 461.8847961425781, Learning Rate: 7.8125e-05\n",
      "Epoch [10416/20000], Loss: 843.2112426757812, Entropy 468.20257568359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10417/20000], Loss: 854.7347412109375, Entropy 462.3625183105469, Learning Rate: 7.8125e-05\n",
      "Epoch [10418/20000], Loss: 823.5762329101562, Entropy 475.86138916015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10419/20000], Loss: 858.2222900390625, Entropy 465.83740234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10420/20000], Loss: 892.4085693359375, Entropy 469.4906005859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10421/20000], Loss: 834.9134521484375, Entropy 463.4567565917969, Learning Rate: 7.8125e-05\n",
      "Epoch [10422/20000], Loss: 894.559326171875, Entropy 467.8365173339844, Learning Rate: 7.8125e-05\n",
      "Epoch [10423/20000], Loss: 803.53857421875, Entropy 473.2693786621094, Learning Rate: 7.8125e-05\n",
      "Epoch [10424/20000], Loss: 865.0596923828125, Entropy 468.6037902832031, Learning Rate: 7.8125e-05\n",
      "Epoch [10425/20000], Loss: 855.0289916992188, Entropy 463.76873779296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10426/20000], Loss: 862.9097900390625, Entropy 466.7160949707031, Learning Rate: 7.8125e-05\n",
      "Epoch [10427/20000], Loss: 838.27587890625, Entropy 454.8492431640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10428/20000], Loss: 861.5325927734375, Entropy 470.2471008300781, Learning Rate: 7.8125e-05\n",
      "Epoch [10429/20000], Loss: 829.52587890625, Entropy 461.1046447753906, Learning Rate: 7.8125e-05\n",
      "Epoch [10430/20000], Loss: 849.2294921875, Entropy 464.5469665527344, Learning Rate: 7.8125e-05\n",
      "Epoch [10431/20000], Loss: 888.2305908203125, Entropy 461.0088195800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10432/20000], Loss: 870.6748046875, Entropy 472.0367736816406, Learning Rate: 7.8125e-05\n",
      "Epoch [10433/20000], Loss: 875.1307983398438, Entropy 462.69085693359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10434/20000], Loss: 886.5526733398438, Entropy 470.32171630859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10435/20000], Loss: 808.4398193359375, Entropy 492.1632995605469, Learning Rate: 7.8125e-05\n",
      "Epoch [10436/20000], Loss: 827.7125854492188, Entropy 469.90093994140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10437/20000], Loss: 825.3824462890625, Entropy 455.2259216308594, Learning Rate: 7.8125e-05\n",
      "Epoch [10438/20000], Loss: 839.6602783203125, Entropy 460.1668701171875, Learning Rate: 7.8125e-05\n",
      "Epoch [10439/20000], Loss: 811.7969360351562, Entropy 471.06158447265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10440/20000], Loss: 813.4760131835938, Entropy 463.65850830078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10441/20000], Loss: 834.4072265625, Entropy 478.4437255859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10442/20000], Loss: 856.216796875, Entropy 453.5060119628906, Learning Rate: 7.8125e-05\n",
      "Epoch [10443/20000], Loss: 850.2513427734375, Entropy 466.232177734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10444/20000], Loss: 844.2093505859375, Entropy 467.4407043457031, Learning Rate: 7.8125e-05\n",
      "Epoch [10445/20000], Loss: 828.0997314453125, Entropy 471.666748046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10446/20000], Loss: 824.25634765625, Entropy 479.67919921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10447/20000], Loss: 833.2127685546875, Entropy 465.4306640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10448/20000], Loss: 885.8602294921875, Entropy 463.2156982421875, Learning Rate: 7.8125e-05\n",
      "Epoch [10449/20000], Loss: 886.6178588867188, Entropy 472.93841552734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10450/20000], Loss: 828.258056640625, Entropy 462.8194580078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10451/20000], Loss: 857.5941162109375, Entropy 473.9861755371094, Learning Rate: 7.8125e-05\n",
      "Epoch [10452/20000], Loss: 815.577880859375, Entropy 470.6625671386719, Learning Rate: 7.8125e-05\n",
      "Epoch [10453/20000], Loss: 873.4376831054688, Entropy 456.57086181640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10454/20000], Loss: 891.84912109375, Entropy 458.9322814941406, Learning Rate: 7.8125e-05\n",
      "Epoch [10455/20000], Loss: 877.8796997070312, Entropy 463.42498779296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10456/20000], Loss: 831.512939453125, Entropy 470.2086486816406, Learning Rate: 7.8125e-05\n",
      "Epoch [10457/20000], Loss: 858.8927001953125, Entropy 475.0912780761719, Learning Rate: 7.8125e-05\n",
      "Epoch [10458/20000], Loss: 841.7301025390625, Entropy 477.8631896972656, Learning Rate: 7.8125e-05\n",
      "Epoch [10459/20000], Loss: 877.8970336914062, Entropy 462.16107177734375, Learning Rate: 7.8125e-05\n",
      "Epoch [10460/20000], Loss: 834.6405029296875, Entropy 468.9247131347656, Learning Rate: 7.8125e-05\n",
      "Epoch [10461/20000], Loss: 876.1351318359375, Entropy 467.4759216308594, Learning Rate: 7.8125e-05\n",
      "Epoch [10462/20000], Loss: 861.743896484375, Entropy 464.9697570800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10463/20000], Loss: 875.4676513671875, Entropy 453.1541442871094, Learning Rate: 7.8125e-05\n",
      "Epoch [10464/20000], Loss: 845.7745971679688, Entropy 458.24664306640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10465/20000], Loss: 895.693603515625, Entropy 455.2791748046875, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10466/20000], Loss: 831.1744384765625, Entropy 456.9674072265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10467/20000], Loss: 809.1079711914062, Entropy 468.99468994140625, Learning Rate: 7.8125e-05\n",
      "Epoch [10468/20000], Loss: 822.6058349609375, Entropy 486.8399963378906, Learning Rate: 7.8125e-05\n",
      "Epoch [10469/20000], Loss: 881.6129150390625, Entropy 457.4987487792969, Learning Rate: 7.8125e-05\n",
      "Epoch [10470/20000], Loss: 853.3287353515625, Entropy 470.54931640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10471/20000], Loss: 820.40087890625, Entropy 467.3870849609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10472/20000], Loss: 850.9743041992188, Entropy 465.03350830078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10473/20000], Loss: 901.830322265625, Entropy 456.1861267089844, Learning Rate: 7.8125e-05\n",
      "Epoch [10474/20000], Loss: 788.7116088867188, Entropy 478.25701904296875, Learning Rate: 7.8125e-05\n",
      "Epoch [10475/20000], Loss: 820.8389892578125, Entropy 479.851318359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10476/20000], Loss: 839.890869140625, Entropy 467.2977294921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10477/20000], Loss: 856.9520874023438, Entropy 456.50189208984375, Learning Rate: 7.8125e-05\n",
      "Epoch [10478/20000], Loss: 855.261474609375, Entropy 473.9538879394531, Learning Rate: 7.8125e-05\n",
      "Epoch [10479/20000], Loss: 839.6827392578125, Entropy 467.7722473144531, Learning Rate: 7.8125e-05\n",
      "Epoch [10480/20000], Loss: 898.4940795898438, Entropy 458.25030517578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10481/20000], Loss: 860.1798706054688, Entropy 450.21490478515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10482/20000], Loss: 898.3547973632812, Entropy 469.79107666015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10483/20000], Loss: 843.5906982421875, Entropy 466.8123474121094, Learning Rate: 7.8125e-05\n",
      "Epoch [10484/20000], Loss: 870.3260498046875, Entropy 464.1473388671875, Learning Rate: 7.8125e-05\n",
      "Epoch [10485/20000], Loss: 841.047607421875, Entropy 463.7889709472656, Learning Rate: 7.8125e-05\n",
      "Epoch [10486/20000], Loss: 874.4073486328125, Entropy 465.98046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10487/20000], Loss: 857.5161743164062, Entropy 468.01409912109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10488/20000], Loss: 874.261474609375, Entropy 470.3246765136719, Learning Rate: 7.8125e-05\n",
      "Epoch [10489/20000], Loss: 817.3395385742188, Entropy 474.87835693359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10490/20000], Loss: 837.2576904296875, Entropy 460.4456787109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10491/20000], Loss: 841.9804077148438, Entropy 461.02960205078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10492/20000], Loss: 824.48681640625, Entropy 463.2208557128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10493/20000], Loss: 831.0736083984375, Entropy 469.4042053222656, Learning Rate: 7.8125e-05\n",
      "Epoch [10494/20000], Loss: 853.9736328125, Entropy 461.1568603515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10495/20000], Loss: 844.6663818359375, Entropy 464.268310546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10496/20000], Loss: 828.8402099609375, Entropy 470.361328125, Learning Rate: 7.8125e-05\n",
      "Epoch [10497/20000], Loss: 849.5902709960938, Entropy 469.69342041015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10498/20000], Loss: 834.5439453125, Entropy 470.4248352050781, Learning Rate: 7.8125e-05\n",
      "Epoch [10499/20000], Loss: 803.48583984375, Entropy 482.9435729980469, Learning Rate: 7.8125e-05\n",
      "Epoch [10500/20000], Loss: 833.556884765625, Entropy 460.0478820800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10501/20000], Loss: 829.722412109375, Entropy 461.5193786621094, Learning Rate: 7.8125e-05\n",
      "Epoch [10502/20000], Loss: 909.3807983398438, Entropy 473.61224365234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10503/20000], Loss: 847.2929077148438, Entropy 469.96600341796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10504/20000], Loss: 845.4739379882812, Entropy 459.17340087890625, Learning Rate: 7.8125e-05\n",
      "Epoch [10505/20000], Loss: 878.004150390625, Entropy 450.4107666015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10506/20000], Loss: 817.9921264648438, Entropy 466.22857666015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10507/20000], Loss: 854.237548828125, Entropy 465.4050598144531, Learning Rate: 7.8125e-05\n",
      "Epoch [10508/20000], Loss: 864.3016357421875, Entropy 470.0645446777344, Learning Rate: 7.8125e-05\n",
      "Epoch [10509/20000], Loss: 867.2352294921875, Entropy 464.027099609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10510/20000], Loss: 817.3849487304688, Entropy 464.43194580078125, Learning Rate: 7.8125e-05\n",
      "Epoch [10511/20000], Loss: 877.6199951171875, Entropy 471.368896484375, Learning Rate: 7.8125e-05\n",
      "Epoch [10512/20000], Loss: 837.220458984375, Entropy 470.6539001464844, Learning Rate: 7.8125e-05\n",
      "Epoch [10513/20000], Loss: 892.4956665039062, Entropy 458.00994873046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10514/20000], Loss: 846.7679443359375, Entropy 472.05419921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10515/20000], Loss: 814.1046142578125, Entropy 470.9290771484375, Learning Rate: 7.8125e-05\n",
      "Epoch [10516/20000], Loss: 838.518798828125, Entropy 460.908935546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10517/20000], Loss: 868.8632202148438, Entropy 464.14984130859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10518/20000], Loss: 888.1393432617188, Entropy 467.58734130859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10519/20000], Loss: 851.9732666015625, Entropy 465.0914306640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10520/20000], Loss: 857.3385009765625, Entropy 462.5791015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10521/20000], Loss: 852.1171264648438, Entropy 481.03314208984375, Learning Rate: 7.8125e-05\n",
      "Epoch [10522/20000], Loss: 858.5852661132812, Entropy 473.87615966796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10523/20000], Loss: 858.7410888671875, Entropy 455.5882568359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10524/20000], Loss: 851.487548828125, Entropy 467.3740539550781, Learning Rate: 7.8125e-05\n",
      "Epoch [10525/20000], Loss: 841.8367919921875, Entropy 466.8287353515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10526/20000], Loss: 893.5791015625, Entropy 464.5661926269531, Learning Rate: 7.8125e-05\n",
      "Epoch [10527/20000], Loss: 861.5908203125, Entropy 470.094482421875, Learning Rate: 7.8125e-05\n",
      "Epoch [10528/20000], Loss: 827.8899536132812, Entropy 468.45648193359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10529/20000], Loss: 872.2505493164062, Entropy 465.49822998046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10530/20000], Loss: 867.8228149414062, Entropy 469.38092041015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10531/20000], Loss: 851.1934814453125, Entropy 469.1086730957031, Learning Rate: 7.8125e-05\n",
      "Epoch [10532/20000], Loss: 831.1214599609375, Entropy 467.4064636230469, Learning Rate: 7.8125e-05\n",
      "Epoch [10533/20000], Loss: 892.09765625, Entropy 464.4587097167969, Learning Rate: 7.8125e-05\n",
      "Epoch [10534/20000], Loss: 878.7899780273438, Entropy 472.36358642578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10535/20000], Loss: 817.9014892578125, Entropy 477.2396240234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10536/20000], Loss: 903.306884765625, Entropy 465.2830810546875, Learning Rate: 7.8125e-05\n",
      "Epoch [10537/20000], Loss: 864.6043090820312, Entropy 476.87835693359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10538/20000], Loss: 880.4588623046875, Entropy 470.2532653808594, Learning Rate: 7.8125e-05\n",
      "Epoch [10539/20000], Loss: 876.1026611328125, Entropy 475.0833435058594, Learning Rate: 7.8125e-05\n",
      "Epoch [10540/20000], Loss: 902.5486450195312, Entropy 459.82476806640625, Learning Rate: 7.8125e-05\n",
      "Epoch [10541/20000], Loss: 852.177001953125, Entropy 466.67822265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10542/20000], Loss: 816.6820678710938, Entropy 465.09112548828125, Learning Rate: 7.8125e-05\n",
      "Epoch [10543/20000], Loss: 856.8701171875, Entropy 462.8905334472656, Learning Rate: 7.8125e-05\n",
      "Epoch [10544/20000], Loss: 859.6453857421875, Entropy 471.6444396972656, Learning Rate: 7.8125e-05\n",
      "Epoch [10545/20000], Loss: 888.9097900390625, Entropy 484.0848083496094, Learning Rate: 7.8125e-05\n",
      "Epoch [10546/20000], Loss: 828.474609375, Entropy 472.3701477050781, Learning Rate: 7.8125e-05\n",
      "Epoch [10547/20000], Loss: 866.1065673828125, Entropy 461.6407470703125, Learning Rate: 7.8125e-05\n",
      "Epoch [10548/20000], Loss: 851.8106689453125, Entropy 467.7501525878906, Learning Rate: 7.8125e-05\n",
      "Epoch [10549/20000], Loss: 820.0299072265625, Entropy 465.448974609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10550/20000], Loss: 826.3291015625, Entropy 465.3061218261719, Learning Rate: 7.8125e-05\n",
      "Epoch [10551/20000], Loss: 870.371337890625, Entropy 478.6974182128906, Learning Rate: 7.8125e-05\n",
      "Epoch [10552/20000], Loss: 892.49853515625, Entropy 471.287109375, Learning Rate: 7.8125e-05\n",
      "Epoch [10553/20000], Loss: 875.8363647460938, Entropy 477.18670654296875, Learning Rate: 7.8125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10554/20000], Loss: 822.9761962890625, Entropy 458.5359802246094, Learning Rate: 7.8125e-05\n",
      "Epoch [10555/20000], Loss: 841.3792114257812, Entropy 470.35296630859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10556/20000], Loss: 811.2728881835938, Entropy 463.18780517578125, Learning Rate: 7.8125e-05\n",
      "Epoch [10557/20000], Loss: 857.519287109375, Entropy 464.1146240234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10558/20000], Loss: 870.1175537109375, Entropy 457.9025573730469, Learning Rate: 7.8125e-05\n",
      "Epoch [10559/20000], Loss: 855.3890380859375, Entropy 459.8125305175781, Learning Rate: 7.8125e-05\n",
      "Epoch [10560/20000], Loss: 846.8056030273438, Entropy 478.62493896484375, Learning Rate: 7.8125e-05\n",
      "Epoch [10561/20000], Loss: 838.207275390625, Entropy 477.6592712402344, Learning Rate: 7.8125e-05\n",
      "Epoch [10562/20000], Loss: 857.3008422851562, Entropy 462.51507568359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10563/20000], Loss: 826.0374145507812, Entropy 458.37249755859375, Learning Rate: 7.8125e-05\n",
      "Epoch [10564/20000], Loss: 845.3599853515625, Entropy 456.8638916015625, Learning Rate: 7.8125e-05\n",
      "Epoch [10565/20000], Loss: 808.2992553710938, Entropy 468.60833740234375, Learning Rate: 7.8125e-05\n",
      "Epoch [10566/20000], Loss: 864.6617431640625, Entropy 453.5720520019531, Learning Rate: 7.8125e-05\n",
      "Epoch [10567/20000], Loss: 845.8717041015625, Entropy 461.6435852050781, Learning Rate: 7.8125e-05\n",
      "Epoch [10568/20000], Loss: 866.1055908203125, Entropy 469.67236328125, Learning Rate: 7.8125e-05\n",
      "Epoch [10569/20000], Loss: 830.1522216796875, Entropy 471.1629638671875, Learning Rate: 7.8125e-05\n",
      "Epoch [10570/20000], Loss: 866.401123046875, Entropy 464.4129638671875, Learning Rate: 7.8125e-05\n",
      "Epoch [10571/20000], Loss: 897.2969970703125, Entropy 472.7510070800781, Learning Rate: 7.8125e-05\n",
      "Epoch [10572/20000], Loss: 840.0228271484375, Entropy 474.2135009765625, Learning Rate: 7.8125e-05\n",
      "Epoch [10573/20000], Loss: 809.6146240234375, Entropy 473.2422180175781, Learning Rate: 7.8125e-05\n",
      "Epoch [10574/20000], Loss: 842.8643798828125, Entropy 476.3921813964844, Learning Rate: 7.8125e-05\n",
      "Epoch [10575/20000], Loss: 827.785888671875, Entropy 470.2138977050781, Learning Rate: 7.8125e-05\n",
      "Epoch [10576/20000], Loss: 867.6792602539062, Entropy 473.24261474609375, Learning Rate: 7.8125e-05\n",
      "Epoch [10577/20000], Loss: 832.787841796875, Entropy 477.6106262207031, Learning Rate: 7.8125e-05\n",
      "Epoch [10578/20000], Loss: 823.7451782226562, Entropy 467.44476318359375, Learning Rate: 7.8125e-05\n",
      "Epoch [10579/20000], Loss: 813.3428344726562, Entropy 478.65740966796875, Learning Rate: 7.8125e-05\n",
      "Epoch [10580/20000], Loss: 834.3738403320312, Entropy 477.64459228515625, Learning Rate: 7.8125e-05\n",
      "Epoch [10581/20000], Loss: 811.4805908203125, Entropy 476.3644104003906, Learning Rate: 7.8125e-05\n",
      "Epoch [10582/20000], Loss: 930.475341796875, Entropy 452.01123046875, Learning Rate: 7.8125e-05\n",
      "Epoch [10583/20000], Loss: 860.9810791015625, Entropy 462.0680236816406, Learning Rate: 7.8125e-05\n",
      "Epoch [10584/20000], Loss: 846.1329345703125, Entropy 468.08544921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10585/20000], Loss: 882.8740234375, Entropy 469.5689697265625, Learning Rate: 7.8125e-05\n",
      "Epoch [10586/20000], Loss: 843.98828125, Entropy 468.149169921875, Learning Rate: 7.8125e-05\n",
      "Epoch [10587/20000], Loss: 833.6017456054688, Entropy 471.67779541015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10588/20000], Loss: 797.686279296875, Entropy 455.2876892089844, Learning Rate: 3.90625e-05\n",
      "Epoch [10589/20000], Loss: 882.393798828125, Entropy 475.560546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10590/20000], Loss: 817.7166748046875, Entropy 471.0707702636719, Learning Rate: 3.90625e-05\n",
      "Epoch [10591/20000], Loss: 869.017822265625, Entropy 477.5960693359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10592/20000], Loss: 818.850341796875, Entropy 477.5074768066406, Learning Rate: 3.90625e-05\n",
      "Epoch [10593/20000], Loss: 858.4835815429688, Entropy 463.00091552734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10594/20000], Loss: 870.18310546875, Entropy 474.4146728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10595/20000], Loss: 877.037353515625, Entropy 466.6681823730469, Learning Rate: 3.90625e-05\n",
      "Epoch [10596/20000], Loss: 836.8671875, Entropy 467.1317138671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10597/20000], Loss: 847.2154541015625, Entropy 470.5307312011719, Learning Rate: 3.90625e-05\n",
      "Epoch [10598/20000], Loss: 829.0494384765625, Entropy 471.7065124511719, Learning Rate: 3.90625e-05\n",
      "Epoch [10599/20000], Loss: 847.8992309570312, Entropy 470.28460693359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10600/20000], Loss: 874.8931274414062, Entropy 455.43902587890625, Learning Rate: 3.90625e-05\n",
      "Epoch [10601/20000], Loss: 865.0510864257812, Entropy 476.50518798828125, Learning Rate: 3.90625e-05\n",
      "Epoch [10602/20000], Loss: 896.0447998046875, Entropy 451.35888671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10603/20000], Loss: 865.130126953125, Entropy 483.704833984375, Learning Rate: 3.90625e-05\n",
      "Epoch [10604/20000], Loss: 866.2261962890625, Entropy 464.5807189941406, Learning Rate: 3.90625e-05\n",
      "Epoch [10605/20000], Loss: 880.1551513671875, Entropy 459.6395263671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10606/20000], Loss: 839.5516357421875, Entropy 454.6700744628906, Learning Rate: 3.90625e-05\n",
      "Epoch [10607/20000], Loss: 879.8118896484375, Entropy 480.5323181152344, Learning Rate: 3.90625e-05\n",
      "Epoch [10608/20000], Loss: 799.153564453125, Entropy 461.4617004394531, Learning Rate: 3.90625e-05\n",
      "Epoch [10609/20000], Loss: 840.319091796875, Entropy 472.7252197265625, Learning Rate: 3.90625e-05\n",
      "Epoch [10610/20000], Loss: 927.9666748046875, Entropy 472.5791320800781, Learning Rate: 3.90625e-05\n",
      "Epoch [10611/20000], Loss: 888.0234985351562, Entropy 470.44586181640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10612/20000], Loss: 813.05859375, Entropy 468.6805725097656, Learning Rate: 3.90625e-05\n",
      "Epoch [10613/20000], Loss: 842.5206298828125, Entropy 486.292724609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10614/20000], Loss: 791.8883666992188, Entropy 476.33538818359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10615/20000], Loss: 825.4191284179688, Entropy 486.82281494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [10616/20000], Loss: 816.6417236328125, Entropy 470.224609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10617/20000], Loss: 838.9716796875, Entropy 477.1963806152344, Learning Rate: 3.90625e-05\n",
      "Epoch [10618/20000], Loss: 867.454345703125, Entropy 465.9156188964844, Learning Rate: 3.90625e-05\n",
      "Epoch [10619/20000], Loss: 824.5205078125, Entropy 477.0416564941406, Learning Rate: 3.90625e-05\n",
      "Epoch [10620/20000], Loss: 854.3552856445312, Entropy 486.18988037109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10621/20000], Loss: 875.2678833007812, Entropy 477.16131591796875, Learning Rate: 3.90625e-05\n",
      "Epoch [10622/20000], Loss: 851.25439453125, Entropy 472.2897644042969, Learning Rate: 3.90625e-05\n",
      "Epoch [10623/20000], Loss: 845.0007934570312, Entropy 479.95953369140625, Learning Rate: 3.90625e-05\n",
      "Epoch [10624/20000], Loss: 818.8616943359375, Entropy 476.7457275390625, Learning Rate: 3.90625e-05\n",
      "Epoch [10625/20000], Loss: 894.93701171875, Entropy 472.4173278808594, Learning Rate: 3.90625e-05\n",
      "Epoch [10626/20000], Loss: 835.2036743164062, Entropy 468.83624267578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10627/20000], Loss: 796.2679443359375, Entropy 483.1150817871094, Learning Rate: 3.90625e-05\n",
      "Epoch [10628/20000], Loss: 821.923095703125, Entropy 475.1514587402344, Learning Rate: 3.90625e-05\n",
      "Epoch [10629/20000], Loss: 881.6427001953125, Entropy 471.5901184082031, Learning Rate: 3.90625e-05\n",
      "Epoch [10630/20000], Loss: 829.53955078125, Entropy 471.3972473144531, Learning Rate: 3.90625e-05\n",
      "Epoch [10631/20000], Loss: 870.6177978515625, Entropy 464.91748046875, Learning Rate: 3.90625e-05\n",
      "Epoch [10632/20000], Loss: 889.266845703125, Entropy 462.6734924316406, Learning Rate: 3.90625e-05\n",
      "Epoch [10633/20000], Loss: 878.41748046875, Entropy 463.91015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10634/20000], Loss: 827.2999267578125, Entropy 465.9836730957031, Learning Rate: 3.90625e-05\n",
      "Epoch [10635/20000], Loss: 861.9093017578125, Entropy 470.0191955566406, Learning Rate: 3.90625e-05\n",
      "Epoch [10636/20000], Loss: 839.423828125, Entropy 477.3363037109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10637/20000], Loss: 844.77978515625, Entropy 466.3435363769531, Learning Rate: 3.90625e-05\n",
      "Epoch [10638/20000], Loss: 845.6229248046875, Entropy 459.4324951171875, Learning Rate: 3.90625e-05\n",
      "Epoch [10639/20000], Loss: 842.1566772460938, Entropy 474.01983642578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10640/20000], Loss: 819.6533203125, Entropy 476.711669921875, Learning Rate: 3.90625e-05\n",
      "Epoch [10641/20000], Loss: 832.056884765625, Entropy 471.8443298339844, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10642/20000], Loss: 835.7102661132812, Entropy 473.79693603515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10643/20000], Loss: 827.958740234375, Entropy 474.0326843261719, Learning Rate: 3.90625e-05\n",
      "Epoch [10644/20000], Loss: 854.309814453125, Entropy 469.3448181152344, Learning Rate: 3.90625e-05\n",
      "Epoch [10645/20000], Loss: 830.9654541015625, Entropy 485.14453125, Learning Rate: 3.90625e-05\n",
      "Epoch [10646/20000], Loss: 842.1918334960938, Entropy 476.70233154296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10647/20000], Loss: 827.9467163085938, Entropy 475.08233642578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10648/20000], Loss: 856.20166015625, Entropy 470.2073669433594, Learning Rate: 3.90625e-05\n",
      "Epoch [10649/20000], Loss: 886.668701171875, Entropy 476.8323974609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10650/20000], Loss: 843.20068359375, Entropy 465.9245910644531, Learning Rate: 3.90625e-05\n",
      "Epoch [10651/20000], Loss: 866.411376953125, Entropy 469.07958984375, Learning Rate: 3.90625e-05\n",
      "Epoch [10652/20000], Loss: 815.8582153320312, Entropy 470.52874755859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10653/20000], Loss: 882.6901245117188, Entropy 462.48052978515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10654/20000], Loss: 826.4471435546875, Entropy 470.6568298339844, Learning Rate: 3.90625e-05\n",
      "Epoch [10655/20000], Loss: 851.31005859375, Entropy 451.85546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10656/20000], Loss: 818.3600463867188, Entropy 465.00823974609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10657/20000], Loss: 848.7347412109375, Entropy 472.4713134765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10658/20000], Loss: 830.7998046875, Entropy 474.0389099121094, Learning Rate: 3.90625e-05\n",
      "Epoch [10659/20000], Loss: 837.9414672851562, Entropy 473.60443115234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10660/20000], Loss: 834.383544921875, Entropy 478.1136474609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10661/20000], Loss: 888.635986328125, Entropy 462.5172424316406, Learning Rate: 3.90625e-05\n",
      "Epoch [10662/20000], Loss: 842.0921630859375, Entropy 477.5340576171875, Learning Rate: 3.90625e-05\n",
      "Epoch [10663/20000], Loss: 887.9932861328125, Entropy 454.6803283691406, Learning Rate: 3.90625e-05\n",
      "Epoch [10664/20000], Loss: 807.83984375, Entropy 479.6844482421875, Learning Rate: 3.90625e-05\n",
      "Epoch [10665/20000], Loss: 830.0631103515625, Entropy 461.15087890625, Learning Rate: 3.90625e-05\n",
      "Epoch [10666/20000], Loss: 880.564208984375, Entropy 464.7098388671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10667/20000], Loss: 876.0582275390625, Entropy 466.1142578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10668/20000], Loss: 816.386962890625, Entropy 469.4329528808594, Learning Rate: 3.90625e-05\n",
      "Epoch [10669/20000], Loss: 830.09521484375, Entropy 456.0671081542969, Learning Rate: 3.90625e-05\n",
      "Epoch [10670/20000], Loss: 873.17236328125, Entropy 467.3389587402344, Learning Rate: 3.90625e-05\n",
      "Epoch [10671/20000], Loss: 799.2232666015625, Entropy 472.8846435546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10672/20000], Loss: 848.724365234375, Entropy 467.6965026855469, Learning Rate: 3.90625e-05\n",
      "Epoch [10673/20000], Loss: 864.5203247070312, Entropy 471.11248779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10674/20000], Loss: 843.027099609375, Entropy 470.9824523925781, Learning Rate: 3.90625e-05\n",
      "Epoch [10675/20000], Loss: 877.0194091796875, Entropy 455.5353088378906, Learning Rate: 3.90625e-05\n",
      "Epoch [10676/20000], Loss: 847.35791015625, Entropy 456.1983642578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10677/20000], Loss: 861.508056640625, Entropy 455.8725280761719, Learning Rate: 3.90625e-05\n",
      "Epoch [10678/20000], Loss: 880.057861328125, Entropy 468.6280212402344, Learning Rate: 3.90625e-05\n",
      "Epoch [10679/20000], Loss: 836.0091552734375, Entropy 475.4118957519531, Learning Rate: 3.90625e-05\n",
      "Epoch [10680/20000], Loss: 894.7388916015625, Entropy 465.6954650878906, Learning Rate: 3.90625e-05\n",
      "Epoch [10681/20000], Loss: 853.0706787109375, Entropy 478.5587463378906, Learning Rate: 3.90625e-05\n",
      "Epoch [10682/20000], Loss: 918.9757080078125, Entropy 459.521484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10683/20000], Loss: 815.59375, Entropy 478.4792175292969, Learning Rate: 3.90625e-05\n",
      "Epoch [10684/20000], Loss: 833.1341552734375, Entropy 470.8267517089844, Learning Rate: 3.90625e-05\n",
      "Epoch [10685/20000], Loss: 823.211669921875, Entropy 487.8382263183594, Learning Rate: 3.90625e-05\n",
      "Epoch [10686/20000], Loss: 893.2197265625, Entropy 460.0534973144531, Learning Rate: 3.90625e-05\n",
      "Epoch [10687/20000], Loss: 864.4669189453125, Entropy 472.4019470214844, Learning Rate: 3.90625e-05\n",
      "Epoch [10688/20000], Loss: 813.93505859375, Entropy 481.8175354003906, Learning Rate: 3.90625e-05\n",
      "Epoch [10689/20000], Loss: 834.6798095703125, Entropy 472.9808349609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10690/20000], Loss: 803.7049560546875, Entropy 465.1690368652344, Learning Rate: 3.90625e-05\n",
      "Epoch [10691/20000], Loss: 845.696533203125, Entropy 459.6369323730469, Learning Rate: 3.90625e-05\n",
      "Epoch [10692/20000], Loss: 832.2273559570312, Entropy 470.34820556640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10693/20000], Loss: 859.9085693359375, Entropy 459.34765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10694/20000], Loss: 831.668701171875, Entropy 463.5533447265625, Learning Rate: 3.90625e-05\n",
      "Epoch [10695/20000], Loss: 871.0958251953125, Entropy 469.36865234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10696/20000], Loss: 845.120849609375, Entropy 474.6285705566406, Learning Rate: 3.90625e-05\n",
      "Epoch [10697/20000], Loss: 862.5567016601562, Entropy 461.10650634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10698/20000], Loss: 849.931884765625, Entropy 465.1924743652344, Learning Rate: 3.90625e-05\n",
      "Epoch [10699/20000], Loss: 839.9592895507812, Entropy 472.13031005859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10700/20000], Loss: 893.1577758789062, Entropy 468.30560302734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10701/20000], Loss: 784.6656494140625, Entropy 479.8224182128906, Learning Rate: 3.90625e-05\n",
      "Epoch [10702/20000], Loss: 850.2083129882812, Entropy 465.87530517578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10703/20000], Loss: 874.91015625, Entropy 477.6399841308594, Learning Rate: 3.90625e-05\n",
      "Epoch [10704/20000], Loss: 912.144287109375, Entropy 454.5784912109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10705/20000], Loss: 819.3998413085938, Entropy 463.04888916015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10706/20000], Loss: 842.8779907226562, Entropy 469.21514892578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10707/20000], Loss: 859.7484130859375, Entropy 476.5422668457031, Learning Rate: 3.90625e-05\n",
      "Epoch [10708/20000], Loss: 843.7344970703125, Entropy 459.9479675292969, Learning Rate: 3.90625e-05\n",
      "Epoch [10709/20000], Loss: 874.3006591796875, Entropy 472.5950012207031, Learning Rate: 3.90625e-05\n",
      "Epoch [10710/20000], Loss: 817.6270751953125, Entropy 481.74853515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10711/20000], Loss: 855.2882080078125, Entropy 461.6253662109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10712/20000], Loss: 863.4737548828125, Entropy 470.0771484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10713/20000], Loss: 848.033935546875, Entropy 454.7412414550781, Learning Rate: 3.90625e-05\n",
      "Epoch [10714/20000], Loss: 872.2801513671875, Entropy 463.0164489746094, Learning Rate: 3.90625e-05\n",
      "Epoch [10715/20000], Loss: 882.532958984375, Entropy 459.8728332519531, Learning Rate: 3.90625e-05\n",
      "Epoch [10716/20000], Loss: 876.054931640625, Entropy 468.7801513671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10717/20000], Loss: 884.28857421875, Entropy 458.9605407714844, Learning Rate: 3.90625e-05\n",
      "Epoch [10718/20000], Loss: 844.12890625, Entropy 473.0007629394531, Learning Rate: 3.90625e-05\n",
      "Epoch [10719/20000], Loss: 827.1082763671875, Entropy 471.4560852050781, Learning Rate: 3.90625e-05\n",
      "Epoch [10720/20000], Loss: 845.7919921875, Entropy 472.193115234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10721/20000], Loss: 859.14501953125, Entropy 472.3697509765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10722/20000], Loss: 852.9386596679688, Entropy 477.70599365234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10723/20000], Loss: 880.346923828125, Entropy 465.02490234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10724/20000], Loss: 820.9151611328125, Entropy 463.9527893066406, Learning Rate: 3.90625e-05\n",
      "Epoch [10725/20000], Loss: 860.956787109375, Entropy 481.0867004394531, Learning Rate: 3.90625e-05\n",
      "Epoch [10726/20000], Loss: 873.0787353515625, Entropy 472.6343688964844, Learning Rate: 3.90625e-05\n",
      "Epoch [10727/20000], Loss: 913.1279296875, Entropy 455.4502258300781, Learning Rate: 3.90625e-05\n",
      "Epoch [10728/20000], Loss: 773.6441650390625, Entropy 487.855224609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10729/20000], Loss: 875.689208984375, Entropy 476.4664001464844, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10730/20000], Loss: 898.98828125, Entropy 461.8257751464844, Learning Rate: 3.90625e-05\n",
      "Epoch [10731/20000], Loss: 825.3570556640625, Entropy 458.8859558105469, Learning Rate: 3.90625e-05\n",
      "Epoch [10732/20000], Loss: 851.9757690429688, Entropy 468.59466552734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10733/20000], Loss: 819.718505859375, Entropy 470.099365234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10734/20000], Loss: 871.428466796875, Entropy 469.8517761230469, Learning Rate: 3.90625e-05\n",
      "Epoch [10735/20000], Loss: 861.7667846679688, Entropy 465.56097412109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10736/20000], Loss: 855.680908203125, Entropy 475.9976501464844, Learning Rate: 3.90625e-05\n",
      "Epoch [10737/20000], Loss: 827.8148193359375, Entropy 476.3094482421875, Learning Rate: 3.90625e-05\n",
      "Epoch [10738/20000], Loss: 836.9576416015625, Entropy 484.9341735839844, Learning Rate: 3.90625e-05\n",
      "Epoch [10739/20000], Loss: 880.24365234375, Entropy 458.8715515136719, Learning Rate: 3.90625e-05\n",
      "Epoch [10740/20000], Loss: 804.0377197265625, Entropy 480.716552734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10741/20000], Loss: 841.9334716796875, Entropy 464.83984375, Learning Rate: 3.90625e-05\n",
      "Epoch [10742/20000], Loss: 835.262939453125, Entropy 468.0968933105469, Learning Rate: 3.90625e-05\n",
      "Epoch [10743/20000], Loss: 828.900390625, Entropy 468.4660949707031, Learning Rate: 3.90625e-05\n",
      "Epoch [10744/20000], Loss: 823.5197143554688, Entropy 487.04388427734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10745/20000], Loss: 870.31201171875, Entropy 479.7094421386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10746/20000], Loss: 819.4791259765625, Entropy 462.4123229980469, Learning Rate: 3.90625e-05\n",
      "Epoch [10747/20000], Loss: 839.34765625, Entropy 468.8221435546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10748/20000], Loss: 806.1871337890625, Entropy 462.5534973144531, Learning Rate: 3.90625e-05\n",
      "Epoch [10749/20000], Loss: 868.229736328125, Entropy 460.1839599609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10750/20000], Loss: 802.2530517578125, Entropy 475.8255615234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10751/20000], Loss: 840.0897216796875, Entropy 466.0449523925781, Learning Rate: 3.90625e-05\n",
      "Epoch [10752/20000], Loss: 847.3426513671875, Entropy 472.4453125, Learning Rate: 3.90625e-05\n",
      "Epoch [10753/20000], Loss: 843.0247802734375, Entropy 471.255859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10754/20000], Loss: 822.8492431640625, Entropy 459.6714782714844, Learning Rate: 3.90625e-05\n",
      "Epoch [10755/20000], Loss: 899.0965576171875, Entropy 460.1756896972656, Learning Rate: 3.90625e-05\n",
      "Epoch [10756/20000], Loss: 889.9434814453125, Entropy 474.2594299316406, Learning Rate: 3.90625e-05\n",
      "Epoch [10757/20000], Loss: 834.3147583007812, Entropy 467.20135498046875, Learning Rate: 3.90625e-05\n",
      "Epoch [10758/20000], Loss: 815.0308837890625, Entropy 477.8376770019531, Learning Rate: 3.90625e-05\n",
      "Epoch [10759/20000], Loss: 793.8748779296875, Entropy 482.3040466308594, Learning Rate: 3.90625e-05\n",
      "Epoch [10760/20000], Loss: 839.80224609375, Entropy 473.7213439941406, Learning Rate: 3.90625e-05\n",
      "Epoch [10761/20000], Loss: 842.4215087890625, Entropy 470.7475280761719, Learning Rate: 3.90625e-05\n",
      "Epoch [10762/20000], Loss: 857.26025390625, Entropy 468.7744445800781, Learning Rate: 3.90625e-05\n",
      "Epoch [10763/20000], Loss: 815.982177734375, Entropy 482.1945495605469, Learning Rate: 3.90625e-05\n",
      "Epoch [10764/20000], Loss: 835.880859375, Entropy 470.4360046386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10765/20000], Loss: 881.4439697265625, Entropy 466.3479919433594, Learning Rate: 3.90625e-05\n",
      "Epoch [10766/20000], Loss: 886.95166015625, Entropy 464.9798278808594, Learning Rate: 3.90625e-05\n",
      "Epoch [10767/20000], Loss: 834.886474609375, Entropy 468.3804626464844, Learning Rate: 3.90625e-05\n",
      "Epoch [10768/20000], Loss: 859.116455078125, Entropy 472.050537109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10769/20000], Loss: 874.5191040039062, Entropy 461.93182373046875, Learning Rate: 3.90625e-05\n",
      "Epoch [10770/20000], Loss: 843.1429443359375, Entropy 463.3138122558594, Learning Rate: 3.90625e-05\n",
      "Epoch [10771/20000], Loss: 875.8707275390625, Entropy 455.8576965332031, Learning Rate: 3.90625e-05\n",
      "Epoch [10772/20000], Loss: 850.377197265625, Entropy 472.0671691894531, Learning Rate: 3.90625e-05\n",
      "Epoch [10773/20000], Loss: 845.7984619140625, Entropy 472.7613525390625, Learning Rate: 3.90625e-05\n",
      "Epoch [10774/20000], Loss: 836.34423828125, Entropy 461.0133361816406, Learning Rate: 3.90625e-05\n",
      "Epoch [10775/20000], Loss: 859.604736328125, Entropy 465.2697448730469, Learning Rate: 3.90625e-05\n",
      "Epoch [10776/20000], Loss: 907.3966064453125, Entropy 457.2892761230469, Learning Rate: 3.90625e-05\n",
      "Epoch [10777/20000], Loss: 890.7508544921875, Entropy 471.6431884765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10778/20000], Loss: 835.5547485351562, Entropy 482.88214111328125, Learning Rate: 3.90625e-05\n",
      "Epoch [10779/20000], Loss: 865.918701171875, Entropy 459.095703125, Learning Rate: 3.90625e-05\n",
      "Epoch [10780/20000], Loss: 817.394287109375, Entropy 475.0131530761719, Learning Rate: 3.90625e-05\n",
      "Epoch [10781/20000], Loss: 838.11279296875, Entropy 481.1037902832031, Learning Rate: 3.90625e-05\n",
      "Epoch [10782/20000], Loss: 844.58447265625, Entropy 467.8332824707031, Learning Rate: 3.90625e-05\n",
      "Epoch [10783/20000], Loss: 832.9981079101562, Entropy 471.22406005859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10784/20000], Loss: 818.9461669921875, Entropy 468.4622497558594, Learning Rate: 3.90625e-05\n",
      "Epoch [10785/20000], Loss: 850.7702026367188, Entropy 455.55462646484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10786/20000], Loss: 851.4417114257812, Entropy 478.28961181640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10787/20000], Loss: 863.1320190429688, Entropy 466.05072021484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10788/20000], Loss: 862.1461181640625, Entropy 455.208740234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10789/20000], Loss: 858.4815063476562, Entropy 467.64068603515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10790/20000], Loss: 897.8656616210938, Entropy 461.92523193359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10791/20000], Loss: 860.8114013671875, Entropy 476.6365661621094, Learning Rate: 3.90625e-05\n",
      "Epoch [10792/20000], Loss: 845.5429077148438, Entropy 475.62982177734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10793/20000], Loss: 854.7637329101562, Entropy 474.49127197265625, Learning Rate: 3.90625e-05\n",
      "Epoch [10794/20000], Loss: 882.4754638671875, Entropy 477.1920166015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10795/20000], Loss: 914.344482421875, Entropy 471.9233093261719, Learning Rate: 3.90625e-05\n",
      "Epoch [10796/20000], Loss: 883.2066650390625, Entropy 458.037109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10797/20000], Loss: 848.8963623046875, Entropy 465.4947204589844, Learning Rate: 3.90625e-05\n",
      "Epoch [10798/20000], Loss: 834.4431762695312, Entropy 478.74957275390625, Learning Rate: 3.90625e-05\n",
      "Epoch [10799/20000], Loss: 865.550048828125, Entropy 455.249755859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10800/20000], Loss: 832.215576171875, Entropy 481.7959289550781, Learning Rate: 3.90625e-05\n",
      "Epoch [10801/20000], Loss: 846.7421875, Entropy 465.9699401855469, Learning Rate: 3.90625e-05\n",
      "Epoch [10802/20000], Loss: 870.2657470703125, Entropy 472.29443359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10803/20000], Loss: 838.01611328125, Entropy 474.9650573730469, Learning Rate: 3.90625e-05\n",
      "Epoch [10804/20000], Loss: 808.2132568359375, Entropy 474.8690490722656, Learning Rate: 3.90625e-05\n",
      "Epoch [10805/20000], Loss: 842.2225341796875, Entropy 472.1116943359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10806/20000], Loss: 860.9613037109375, Entropy 465.9912414550781, Learning Rate: 3.90625e-05\n",
      "Epoch [10807/20000], Loss: 847.1573486328125, Entropy 478.3949890136719, Learning Rate: 3.90625e-05\n",
      "Epoch [10808/20000], Loss: 835.676513671875, Entropy 472.7874755859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10809/20000], Loss: 840.8240966796875, Entropy 484.1358947753906, Learning Rate: 3.90625e-05\n",
      "Epoch [10810/20000], Loss: 854.0805053710938, Entropy 479.45819091796875, Learning Rate: 3.90625e-05\n",
      "Epoch [10811/20000], Loss: 816.5601806640625, Entropy 471.2508544921875, Learning Rate: 3.90625e-05\n",
      "Epoch [10812/20000], Loss: 855.77197265625, Entropy 461.7889709472656, Learning Rate: 3.90625e-05\n",
      "Epoch [10813/20000], Loss: 858.002685546875, Entropy 464.7116394042969, Learning Rate: 3.90625e-05\n",
      "Epoch [10814/20000], Loss: 883.135498046875, Entropy 469.4516296386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10815/20000], Loss: 881.2455444335938, Entropy 463.05914306640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10816/20000], Loss: 872.1585693359375, Entropy 466.6324157714844, Learning Rate: 3.90625e-05\n",
      "Epoch [10817/20000], Loss: 863.3826904296875, Entropy 464.2156066894531, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10818/20000], Loss: 844.631591796875, Entropy 471.2513427734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10819/20000], Loss: 845.402099609375, Entropy 460.7574157714844, Learning Rate: 3.90625e-05\n",
      "Epoch [10820/20000], Loss: 849.6304931640625, Entropy 467.1932678222656, Learning Rate: 3.90625e-05\n",
      "Epoch [10821/20000], Loss: 800.9970703125, Entropy 476.5237121582031, Learning Rate: 3.90625e-05\n",
      "Epoch [10822/20000], Loss: 853.9224853515625, Entropy 457.04248046875, Learning Rate: 3.90625e-05\n",
      "Epoch [10823/20000], Loss: 841.2447509765625, Entropy 467.5604553222656, Learning Rate: 3.90625e-05\n",
      "Epoch [10824/20000], Loss: 861.3577880859375, Entropy 475.2029724121094, Learning Rate: 3.90625e-05\n",
      "Epoch [10825/20000], Loss: 887.9033203125, Entropy 466.8478698730469, Learning Rate: 3.90625e-05\n",
      "Epoch [10826/20000], Loss: 861.2822875976562, Entropy 473.92864990234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10827/20000], Loss: 879.1204833984375, Entropy 467.1556396484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10828/20000], Loss: 873.3048095703125, Entropy 465.3504638671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10829/20000], Loss: 850.6784057617188, Entropy 467.35845947265625, Learning Rate: 3.90625e-05\n",
      "Epoch [10830/20000], Loss: 869.1171875, Entropy 469.2583923339844, Learning Rate: 3.90625e-05\n",
      "Epoch [10831/20000], Loss: 893.8858642578125, Entropy 467.935302734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10832/20000], Loss: 871.7796630859375, Entropy 472.4465637207031, Learning Rate: 3.90625e-05\n",
      "Epoch [10833/20000], Loss: 913.6830444335938, Entropy 458.99835205078125, Learning Rate: 3.90625e-05\n",
      "Epoch [10834/20000], Loss: 844.006103515625, Entropy 460.050537109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10835/20000], Loss: 814.2254638671875, Entropy 482.6609802246094, Learning Rate: 3.90625e-05\n",
      "Epoch [10836/20000], Loss: 848.730224609375, Entropy 474.4979553222656, Learning Rate: 3.90625e-05\n",
      "Epoch [10837/20000], Loss: 870.0557861328125, Entropy 482.9140625, Learning Rate: 3.90625e-05\n",
      "Epoch [10838/20000], Loss: 850.8538818359375, Entropy 469.1966247558594, Learning Rate: 3.90625e-05\n",
      "Epoch [10839/20000], Loss: 851.1846923828125, Entropy 459.9778137207031, Learning Rate: 3.90625e-05\n",
      "Epoch [10840/20000], Loss: 835.8565673828125, Entropy 466.5345153808594, Learning Rate: 3.90625e-05\n",
      "Epoch [10841/20000], Loss: 847.8031005859375, Entropy 464.5414733886719, Learning Rate: 3.90625e-05\n",
      "Epoch [10842/20000], Loss: 876.975830078125, Entropy 462.8813171386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10843/20000], Loss: 893.0250854492188, Entropy 463.34991455078125, Learning Rate: 3.90625e-05\n",
      "Epoch [10844/20000], Loss: 819.982177734375, Entropy 473.5101318359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10845/20000], Loss: 851.880615234375, Entropy 470.3908996582031, Learning Rate: 3.90625e-05\n",
      "Epoch [10846/20000], Loss: 871.173828125, Entropy 468.3453369140625, Learning Rate: 3.90625e-05\n",
      "Epoch [10847/20000], Loss: 856.6790771484375, Entropy 458.3326721191406, Learning Rate: 3.90625e-05\n",
      "Epoch [10848/20000], Loss: 871.5836791992188, Entropy 472.43939208984375, Learning Rate: 3.90625e-05\n",
      "Epoch [10849/20000], Loss: 851.53466796875, Entropy 474.0049133300781, Learning Rate: 3.90625e-05\n",
      "Epoch [10850/20000], Loss: 808.50732421875, Entropy 465.7945861816406, Learning Rate: 3.90625e-05\n",
      "Epoch [10851/20000], Loss: 845.492431640625, Entropy 464.2641296386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10852/20000], Loss: 865.488525390625, Entropy 460.82763671875, Learning Rate: 3.90625e-05\n",
      "Epoch [10853/20000], Loss: 848.952392578125, Entropy 487.9660339355469, Learning Rate: 3.90625e-05\n",
      "Epoch [10854/20000], Loss: 809.403076171875, Entropy 489.3795166015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10855/20000], Loss: 833.5197143554688, Entropy 471.17327880859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10856/20000], Loss: 816.636962890625, Entropy 489.5625305175781, Learning Rate: 3.90625e-05\n",
      "Epoch [10857/20000], Loss: 807.481201171875, Entropy 485.7392578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10858/20000], Loss: 864.4788818359375, Entropy 485.34375, Learning Rate: 3.90625e-05\n",
      "Epoch [10859/20000], Loss: 845.021484375, Entropy 474.1882629394531, Learning Rate: 3.90625e-05\n",
      "Epoch [10860/20000], Loss: 826.447021484375, Entropy 486.9778747558594, Learning Rate: 3.90625e-05\n",
      "Epoch [10861/20000], Loss: 840.4085693359375, Entropy 458.248779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10862/20000], Loss: 878.409912109375, Entropy 453.5325622558594, Learning Rate: 3.90625e-05\n",
      "Epoch [10863/20000], Loss: 856.5291748046875, Entropy 480.5667724609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10864/20000], Loss: 876.4947509765625, Entropy 456.4892883300781, Learning Rate: 3.90625e-05\n",
      "Epoch [10865/20000], Loss: 816.031494140625, Entropy 465.7160339355469, Learning Rate: 3.90625e-05\n",
      "Epoch [10866/20000], Loss: 848.1996459960938, Entropy 476.03521728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10867/20000], Loss: 865.57373046875, Entropy 460.3185119628906, Learning Rate: 3.90625e-05\n",
      "Epoch [10868/20000], Loss: 910.9774169921875, Entropy 467.5632019042969, Learning Rate: 3.90625e-05\n",
      "Epoch [10869/20000], Loss: 883.9430541992188, Entropy 459.27691650390625, Learning Rate: 3.90625e-05\n",
      "Epoch [10870/20000], Loss: 840.23876953125, Entropy 472.3087463378906, Learning Rate: 3.90625e-05\n",
      "Epoch [10871/20000], Loss: 892.6116943359375, Entropy 465.0330505371094, Learning Rate: 3.90625e-05\n",
      "Epoch [10872/20000], Loss: 871.435302734375, Entropy 466.3567810058594, Learning Rate: 3.90625e-05\n",
      "Epoch [10873/20000], Loss: 808.6400146484375, Entropy 464.7160949707031, Learning Rate: 3.90625e-05\n",
      "Epoch [10874/20000], Loss: 849.4847412109375, Entropy 459.0948791503906, Learning Rate: 3.90625e-05\n",
      "Epoch [10875/20000], Loss: 801.192626953125, Entropy 456.0167541503906, Learning Rate: 3.90625e-05\n",
      "Epoch [10876/20000], Loss: 876.0686645507812, Entropy 469.80487060546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10877/20000], Loss: 851.69384765625, Entropy 467.5404968261719, Learning Rate: 3.90625e-05\n",
      "Epoch [10878/20000], Loss: 805.9300537109375, Entropy 480.2220458984375, Learning Rate: 3.90625e-05\n",
      "Epoch [10879/20000], Loss: 854.3801879882812, Entropy 468.43255615234375, Learning Rate: 3.90625e-05\n",
      "Epoch [10880/20000], Loss: 874.1859130859375, Entropy 457.0604553222656, Learning Rate: 3.90625e-05\n",
      "Epoch [10881/20000], Loss: 821.7601318359375, Entropy 467.4346008300781, Learning Rate: 3.90625e-05\n",
      "Epoch [10882/20000], Loss: 851.5228271484375, Entropy 467.6599426269531, Learning Rate: 3.90625e-05\n",
      "Epoch [10883/20000], Loss: 832.3169555664062, Entropy 465.60394287109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10884/20000], Loss: 899.8082885742188, Entropy 454.74542236328125, Learning Rate: 3.90625e-05\n",
      "Epoch [10885/20000], Loss: 818.7377319335938, Entropy 467.57904052734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10886/20000], Loss: 815.5449829101562, Entropy 484.39666748046875, Learning Rate: 3.90625e-05\n",
      "Epoch [10887/20000], Loss: 849.64453125, Entropy 467.8974609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10888/20000], Loss: 834.34228515625, Entropy 481.6795654296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10889/20000], Loss: 888.7069702148438, Entropy 455.78717041015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10890/20000], Loss: 832.4291381835938, Entropy 466.89605712890625, Learning Rate: 3.90625e-05\n",
      "Epoch [10891/20000], Loss: 822.816650390625, Entropy 471.9947204589844, Learning Rate: 3.90625e-05\n",
      "Epoch [10892/20000], Loss: 848.7335205078125, Entropy 447.1009216308594, Learning Rate: 3.90625e-05\n",
      "Epoch [10893/20000], Loss: 863.0511474609375, Entropy 453.1500549316406, Learning Rate: 3.90625e-05\n",
      "Epoch [10894/20000], Loss: 854.4339599609375, Entropy 466.8157653808594, Learning Rate: 3.90625e-05\n",
      "Epoch [10895/20000], Loss: 861.2440185546875, Entropy 456.2572021484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10896/20000], Loss: 863.8359375, Entropy 462.4074401855469, Learning Rate: 3.90625e-05\n",
      "Epoch [10897/20000], Loss: 825.828125, Entropy 478.060546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10898/20000], Loss: 818.9573974609375, Entropy 480.3203125, Learning Rate: 3.90625e-05\n",
      "Epoch [10899/20000], Loss: 825.3272705078125, Entropy 476.1193542480469, Learning Rate: 3.90625e-05\n",
      "Epoch [10900/20000], Loss: 820.7017211914062, Entropy 476.33795166015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10901/20000], Loss: 847.0673828125, Entropy 460.1712646484375, Learning Rate: 3.90625e-05\n",
      "Epoch [10902/20000], Loss: 846.1785278320312, Entropy 464.37896728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10903/20000], Loss: 868.703369140625, Entropy 472.9256286621094, Learning Rate: 3.90625e-05\n",
      "Epoch [10904/20000], Loss: 822.2108764648438, Entropy 475.37359619140625, Learning Rate: 3.90625e-05\n",
      "Epoch [10905/20000], Loss: 876.7335205078125, Entropy 469.4886169433594, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10906/20000], Loss: 876.8046264648438, Entropy 461.17193603515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10907/20000], Loss: 846.755615234375, Entropy 455.3338928222656, Learning Rate: 3.90625e-05\n",
      "Epoch [10908/20000], Loss: 858.240234375, Entropy 467.351318359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10909/20000], Loss: 834.7286376953125, Entropy 477.9059143066406, Learning Rate: 3.90625e-05\n",
      "Epoch [10910/20000], Loss: 834.2550659179688, Entropy 482.88775634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10911/20000], Loss: 840.733642578125, Entropy 472.1469421386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10912/20000], Loss: 856.5697021484375, Entropy 472.2472839355469, Learning Rate: 3.90625e-05\n",
      "Epoch [10913/20000], Loss: 849.3402099609375, Entropy 468.6709899902344, Learning Rate: 3.90625e-05\n",
      "Epoch [10914/20000], Loss: 839.9677734375, Entropy 464.7034912109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10915/20000], Loss: 825.3655395507812, Entropy 482.39495849609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10916/20000], Loss: 915.138671875, Entropy 477.4296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10917/20000], Loss: 857.6592407226562, Entropy 469.12725830078125, Learning Rate: 3.90625e-05\n",
      "Epoch [10918/20000], Loss: 847.0238647460938, Entropy 470.14288330078125, Learning Rate: 3.90625e-05\n",
      "Epoch [10919/20000], Loss: 855.5426025390625, Entropy 469.4732666015625, Learning Rate: 3.90625e-05\n",
      "Epoch [10920/20000], Loss: 814.9083251953125, Entropy 480.5559387207031, Learning Rate: 3.90625e-05\n",
      "Epoch [10921/20000], Loss: 915.736328125, Entropy 463.72119140625, Learning Rate: 3.90625e-05\n",
      "Epoch [10922/20000], Loss: 944.681640625, Entropy 469.8882751464844, Learning Rate: 3.90625e-05\n",
      "Epoch [10923/20000], Loss: 893.982421875, Entropy 452.6608581542969, Learning Rate: 3.90625e-05\n",
      "Epoch [10924/20000], Loss: 841.5574951171875, Entropy 479.3990478515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10925/20000], Loss: 828.9400634765625, Entropy 474.8553466796875, Learning Rate: 3.90625e-05\n",
      "Epoch [10926/20000], Loss: 856.2097778320312, Entropy 451.88690185546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10927/20000], Loss: 859.9270629882812, Entropy 463.88507080078125, Learning Rate: 3.90625e-05\n",
      "Epoch [10928/20000], Loss: 817.031005859375, Entropy 472.8714599609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10929/20000], Loss: 866.0208129882812, Entropy 461.22015380859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10930/20000], Loss: 865.2459716796875, Entropy 471.7509765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10931/20000], Loss: 806.661376953125, Entropy 468.6690979003906, Learning Rate: 3.90625e-05\n",
      "Epoch [10932/20000], Loss: 851.6557006835938, Entropy 472.20733642578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10933/20000], Loss: 857.5733642578125, Entropy 470.0768737792969, Learning Rate: 3.90625e-05\n",
      "Epoch [10934/20000], Loss: 841.695556640625, Entropy 469.562255859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10935/20000], Loss: 912.663330078125, Entropy 470.0710144042969, Learning Rate: 3.90625e-05\n",
      "Epoch [10936/20000], Loss: 863.88818359375, Entropy 468.3377380371094, Learning Rate: 3.90625e-05\n",
      "Epoch [10937/20000], Loss: 857.5533447265625, Entropy 467.00634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10938/20000], Loss: 834.1693115234375, Entropy 467.8633728027344, Learning Rate: 3.90625e-05\n",
      "Epoch [10939/20000], Loss: 829.024169921875, Entropy 482.9988708496094, Learning Rate: 3.90625e-05\n",
      "Epoch [10940/20000], Loss: 852.7437744140625, Entropy 469.5143127441406, Learning Rate: 3.90625e-05\n",
      "Epoch [10941/20000], Loss: 849.3507690429688, Entropy 474.72711181640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10942/20000], Loss: 855.0850830078125, Entropy 466.7823181152344, Learning Rate: 3.90625e-05\n",
      "Epoch [10943/20000], Loss: 820.775146484375, Entropy 455.2767028808594, Learning Rate: 3.90625e-05\n",
      "Epoch [10944/20000], Loss: 893.9688720703125, Entropy 463.7891845703125, Learning Rate: 3.90625e-05\n",
      "Epoch [10945/20000], Loss: 857.593994140625, Entropy 465.1275634765625, Learning Rate: 3.90625e-05\n",
      "Epoch [10946/20000], Loss: 840.958740234375, Entropy 464.2281799316406, Learning Rate: 3.90625e-05\n",
      "Epoch [10947/20000], Loss: 845.4046630859375, Entropy 459.0278015136719, Learning Rate: 3.90625e-05\n",
      "Epoch [10948/20000], Loss: 861.1561889648438, Entropy 465.09906005859375, Learning Rate: 3.90625e-05\n",
      "Epoch [10949/20000], Loss: 825.239990234375, Entropy 473.0660705566406, Learning Rate: 3.90625e-05\n",
      "Epoch [10950/20000], Loss: 892.4796142578125, Entropy 482.5318298339844, Learning Rate: 3.90625e-05\n",
      "Epoch [10951/20000], Loss: 838.3016357421875, Entropy 485.8408508300781, Learning Rate: 3.90625e-05\n",
      "Epoch [10952/20000], Loss: 832.9449462890625, Entropy 464.7488098144531, Learning Rate: 3.90625e-05\n",
      "Epoch [10953/20000], Loss: 824.2022705078125, Entropy 472.5129699707031, Learning Rate: 3.90625e-05\n",
      "Epoch [10954/20000], Loss: 862.023681640625, Entropy 475.78662109375, Learning Rate: 3.90625e-05\n",
      "Epoch [10955/20000], Loss: 858.2965087890625, Entropy 469.5274963378906, Learning Rate: 3.90625e-05\n",
      "Epoch [10956/20000], Loss: 839.8682861328125, Entropy 457.1274108886719, Learning Rate: 3.90625e-05\n",
      "Epoch [10957/20000], Loss: 876.009765625, Entropy 461.6387939453125, Learning Rate: 3.90625e-05\n",
      "Epoch [10958/20000], Loss: 852.3313598632812, Entropy 466.50726318359375, Learning Rate: 3.90625e-05\n",
      "Epoch [10959/20000], Loss: 836.71240234375, Entropy 457.4559326171875, Learning Rate: 3.90625e-05\n",
      "Epoch [10960/20000], Loss: 855.8718872070312, Entropy 465.97576904296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10961/20000], Loss: 841.904052734375, Entropy 473.3188171386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10962/20000], Loss: 836.6985473632812, Entropy 472.61383056640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10963/20000], Loss: 833.817138671875, Entropy 463.7995910644531, Learning Rate: 3.90625e-05\n",
      "Epoch [10964/20000], Loss: 881.2180786132812, Entropy 479.58685302734375, Learning Rate: 3.90625e-05\n",
      "Epoch [10965/20000], Loss: 893.5142822265625, Entropy 468.1681823730469, Learning Rate: 3.90625e-05\n",
      "Epoch [10966/20000], Loss: 869.4051513671875, Entropy 447.6206970214844, Learning Rate: 3.90625e-05\n",
      "Epoch [10967/20000], Loss: 818.664306640625, Entropy 470.1622619628906, Learning Rate: 3.90625e-05\n",
      "Epoch [10968/20000], Loss: 834.5428466796875, Entropy 476.7342529296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10969/20000], Loss: 883.49169921875, Entropy 463.4172058105469, Learning Rate: 3.90625e-05\n",
      "Epoch [10970/20000], Loss: 827.1135864257812, Entropy 475.21124267578125, Learning Rate: 3.90625e-05\n",
      "Epoch [10971/20000], Loss: 888.2830810546875, Entropy 462.2742614746094, Learning Rate: 3.90625e-05\n",
      "Epoch [10972/20000], Loss: 848.142333984375, Entropy 470.2204284667969, Learning Rate: 3.90625e-05\n",
      "Epoch [10973/20000], Loss: 814.402587890625, Entropy 480.7223815917969, Learning Rate: 3.90625e-05\n",
      "Epoch [10974/20000], Loss: 879.2352294921875, Entropy 458.4889831542969, Learning Rate: 3.90625e-05\n",
      "Epoch [10975/20000], Loss: 867.1681518554688, Entropy 477.56646728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10976/20000], Loss: 882.6285400390625, Entropy 465.0986633300781, Learning Rate: 3.90625e-05\n",
      "Epoch [10977/20000], Loss: 828.2786254882812, Entropy 468.59381103515625, Learning Rate: 3.90625e-05\n",
      "Epoch [10978/20000], Loss: 819.576904296875, Entropy 467.1125793457031, Learning Rate: 3.90625e-05\n",
      "Epoch [10979/20000], Loss: 864.4764404296875, Entropy 466.5308532714844, Learning Rate: 3.90625e-05\n",
      "Epoch [10980/20000], Loss: 836.01123046875, Entropy 464.0598449707031, Learning Rate: 3.90625e-05\n",
      "Epoch [10981/20000], Loss: 848.268798828125, Entropy 459.6147155761719, Learning Rate: 3.90625e-05\n",
      "Epoch [10982/20000], Loss: 854.5311279296875, Entropy 472.8662414550781, Learning Rate: 3.90625e-05\n",
      "Epoch [10983/20000], Loss: 819.6220703125, Entropy 474.0932312011719, Learning Rate: 3.90625e-05\n",
      "Epoch [10984/20000], Loss: 827.00146484375, Entropy 470.389404296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10985/20000], Loss: 884.457763671875, Entropy 472.752685546875, Learning Rate: 3.90625e-05\n",
      "Epoch [10986/20000], Loss: 843.3314208984375, Entropy 463.5747985839844, Learning Rate: 3.90625e-05\n",
      "Epoch [10987/20000], Loss: 832.59814453125, Entropy 478.1938171386719, Learning Rate: 3.90625e-05\n",
      "Epoch [10988/20000], Loss: 817.8675537109375, Entropy 482.4886474609375, Learning Rate: 3.90625e-05\n",
      "Epoch [10989/20000], Loss: 821.8308715820312, Entropy 468.26483154296875, Learning Rate: 3.90625e-05\n",
      "Epoch [10990/20000], Loss: 844.5989990234375, Entropy 489.0314636230469, Learning Rate: 3.90625e-05\n",
      "Epoch [10991/20000], Loss: 832.96826171875, Entropy 471.8905334472656, Learning Rate: 3.90625e-05\n",
      "Epoch [10992/20000], Loss: 836.8958740234375, Entropy 483.3765563964844, Learning Rate: 3.90625e-05\n",
      "Epoch [10993/20000], Loss: 834.1875, Entropy 462.7951965332031, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10994/20000], Loss: 877.9425048828125, Entropy 470.8796081542969, Learning Rate: 3.90625e-05\n",
      "Epoch [10995/20000], Loss: 822.765869140625, Entropy 476.1014709472656, Learning Rate: 3.90625e-05\n",
      "Epoch [10996/20000], Loss: 817.6343994140625, Entropy 455.5978088378906, Learning Rate: 3.90625e-05\n",
      "Epoch [10997/20000], Loss: 865.7161254882812, Entropy 466.98492431640625, Learning Rate: 3.90625e-05\n",
      "Epoch [10998/20000], Loss: 867.19140625, Entropy 462.1589050292969, Learning Rate: 3.90625e-05\n",
      "Epoch [10999/20000], Loss: 838.13720703125, Entropy 477.6111755371094, Learning Rate: 3.90625e-05\n",
      "Epoch [11000/20000], Loss: 861.8345947265625, Entropy 466.3445129394531, Learning Rate: 3.90625e-05\n",
      "Epoch [11001/20000], Loss: 872.64208984375, Entropy 468.5866394042969, Learning Rate: 3.90625e-05\n",
      "Epoch [11002/20000], Loss: 886.3067626953125, Entropy 458.3807067871094, Learning Rate: 3.90625e-05\n",
      "Epoch [11003/20000], Loss: 804.501220703125, Entropy 487.7920227050781, Learning Rate: 3.90625e-05\n",
      "Epoch [11004/20000], Loss: 872.5364990234375, Entropy 476.4765625, Learning Rate: 3.90625e-05\n",
      "Epoch [11005/20000], Loss: 813.7672119140625, Entropy 485.5722961425781, Learning Rate: 3.90625e-05\n",
      "Epoch [11006/20000], Loss: 889.52294921875, Entropy 448.9024963378906, Learning Rate: 3.90625e-05\n",
      "Epoch [11007/20000], Loss: 855.6962890625, Entropy 466.6210021972656, Learning Rate: 3.90625e-05\n",
      "Epoch [11008/20000], Loss: 819.380126953125, Entropy 470.3101501464844, Learning Rate: 3.90625e-05\n",
      "Epoch [11009/20000], Loss: 827.6256103515625, Entropy 468.3181457519531, Learning Rate: 3.90625e-05\n",
      "Epoch [11010/20000], Loss: 840.9619140625, Entropy 463.5449523925781, Learning Rate: 3.90625e-05\n",
      "Epoch [11011/20000], Loss: 830.2147216796875, Entropy 472.1805725097656, Learning Rate: 3.90625e-05\n",
      "Epoch [11012/20000], Loss: 870.7481689453125, Entropy 480.7351379394531, Learning Rate: 3.90625e-05\n",
      "Epoch [11013/20000], Loss: 836.6796875, Entropy 473.0064392089844, Learning Rate: 3.90625e-05\n",
      "Epoch [11014/20000], Loss: 860.1729736328125, Entropy 466.9354553222656, Learning Rate: 3.90625e-05\n",
      "Epoch [11015/20000], Loss: 846.853759765625, Entropy 471.9633483886719, Learning Rate: 3.90625e-05\n",
      "Epoch [11016/20000], Loss: 843.5137939453125, Entropy 474.7390441894531, Learning Rate: 3.90625e-05\n",
      "Epoch [11017/20000], Loss: 824.96044921875, Entropy 465.8855285644531, Learning Rate: 3.90625e-05\n",
      "Epoch [11018/20000], Loss: 840.3287963867188, Entropy 475.35174560546875, Learning Rate: 3.90625e-05\n",
      "Epoch [11019/20000], Loss: 835.620849609375, Entropy 479.4641418457031, Learning Rate: 3.90625e-05\n",
      "Epoch [11020/20000], Loss: 878.123291015625, Entropy 468.6365051269531, Learning Rate: 3.90625e-05\n",
      "Epoch [11021/20000], Loss: 862.6668701171875, Entropy 476.1802978515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11022/20000], Loss: 880.9853515625, Entropy 479.8611755371094, Learning Rate: 3.90625e-05\n",
      "Epoch [11023/20000], Loss: 833.427734375, Entropy 464.4709777832031, Learning Rate: 3.90625e-05\n",
      "Epoch [11024/20000], Loss: 832.1787719726562, Entropy 469.52374267578125, Learning Rate: 3.90625e-05\n",
      "Epoch [11025/20000], Loss: 832.05615234375, Entropy 465.6935119628906, Learning Rate: 3.90625e-05\n",
      "Epoch [11026/20000], Loss: 865.932373046875, Entropy 466.9168701171875, Learning Rate: 3.90625e-05\n",
      "Epoch [11027/20000], Loss: 833.0587158203125, Entropy 467.4535827636719, Learning Rate: 3.90625e-05\n",
      "Epoch [11028/20000], Loss: 862.0623779296875, Entropy 482.6524963378906, Learning Rate: 3.90625e-05\n",
      "Epoch [11029/20000], Loss: 832.6239013671875, Entropy 471.6014709472656, Learning Rate: 3.90625e-05\n",
      "Epoch [11030/20000], Loss: 821.7391357421875, Entropy 476.4623718261719, Learning Rate: 3.90625e-05\n",
      "Epoch [11031/20000], Loss: 817.592529296875, Entropy 468.8992919921875, Learning Rate: 3.90625e-05\n",
      "Epoch [11032/20000], Loss: 888.12548828125, Entropy 472.96484375, Learning Rate: 3.90625e-05\n",
      "Epoch [11033/20000], Loss: 852.7186279296875, Entropy 469.92919921875, Learning Rate: 3.90625e-05\n",
      "Epoch [11034/20000], Loss: 838.8970947265625, Entropy 471.0559997558594, Learning Rate: 3.90625e-05\n",
      "Epoch [11035/20000], Loss: 852.6300048828125, Entropy 474.4482727050781, Learning Rate: 3.90625e-05\n",
      "Epoch [11036/20000], Loss: 895.849365234375, Entropy 463.5467224121094, Learning Rate: 3.90625e-05\n",
      "Epoch [11037/20000], Loss: 821.8131103515625, Entropy 478.8624572753906, Learning Rate: 3.90625e-05\n",
      "Epoch [11038/20000], Loss: 867.5362548828125, Entropy 467.1673583984375, Learning Rate: 3.90625e-05\n",
      "Epoch [11039/20000], Loss: 843.4451293945312, Entropy 468.35406494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11040/20000], Loss: 807.4296875, Entropy 469.5030212402344, Learning Rate: 3.90625e-05\n",
      "Epoch [11041/20000], Loss: 831.8516235351562, Entropy 465.77984619140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11042/20000], Loss: 874.7518310546875, Entropy 462.1220703125, Learning Rate: 3.90625e-05\n",
      "Epoch [11043/20000], Loss: 807.2730712890625, Entropy 471.5396728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11044/20000], Loss: 831.1033325195312, Entropy 488.19818115234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11045/20000], Loss: 857.1951293945312, Entropy 461.99078369140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11046/20000], Loss: 834.0797729492188, Entropy 475.75445556640625, Learning Rate: 3.90625e-05\n",
      "Epoch [11047/20000], Loss: 820.8309326171875, Entropy 484.5172119140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11048/20000], Loss: 816.4613037109375, Entropy 465.9578857421875, Learning Rate: 3.90625e-05\n",
      "Epoch [11049/20000], Loss: 840.3304443359375, Entropy 465.6077575683594, Learning Rate: 3.90625e-05\n",
      "Epoch [11050/20000], Loss: 839.3333129882812, Entropy 460.44366455078125, Learning Rate: 3.90625e-05\n",
      "Epoch [11051/20000], Loss: 805.895263671875, Entropy 469.8209533691406, Learning Rate: 3.90625e-05\n",
      "Epoch [11052/20000], Loss: 874.3516845703125, Entropy 463.2711486816406, Learning Rate: 3.90625e-05\n",
      "Epoch [11053/20000], Loss: 885.930419921875, Entropy 458.0646057128906, Learning Rate: 3.90625e-05\n",
      "Epoch [11054/20000], Loss: 829.85107421875, Entropy 457.329833984375, Learning Rate: 3.90625e-05\n",
      "Epoch [11055/20000], Loss: 861.9730224609375, Entropy 488.4560852050781, Learning Rate: 3.90625e-05\n",
      "Epoch [11056/20000], Loss: 836.2781372070312, Entropy 469.07647705078125, Learning Rate: 3.90625e-05\n",
      "Epoch [11057/20000], Loss: 839.3406982421875, Entropy 475.5358581542969, Learning Rate: 3.90625e-05\n",
      "Epoch [11058/20000], Loss: 838.16357421875, Entropy 472.9498291015625, Learning Rate: 3.90625e-05\n",
      "Epoch [11059/20000], Loss: 869.2900390625, Entropy 460.1405334472656, Learning Rate: 3.90625e-05\n",
      "Epoch [11060/20000], Loss: 847.3175048828125, Entropy 467.3175354003906, Learning Rate: 3.90625e-05\n",
      "Epoch [11061/20000], Loss: 874.868896484375, Entropy 470.4075622558594, Learning Rate: 3.90625e-05\n",
      "Epoch [11062/20000], Loss: 845.603759765625, Entropy 470.7685546875, Learning Rate: 3.90625e-05\n",
      "Epoch [11063/20000], Loss: 898.0966186523438, Entropy 466.01959228515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11064/20000], Loss: 862.4561767578125, Entropy 460.8082580566406, Learning Rate: 3.90625e-05\n",
      "Epoch [11065/20000], Loss: 814.641845703125, Entropy 468.6266174316406, Learning Rate: 3.90625e-05\n",
      "Epoch [11066/20000], Loss: 906.1644287109375, Entropy 480.3356018066406, Learning Rate: 3.90625e-05\n",
      "Epoch [11067/20000], Loss: 836.385986328125, Entropy 464.7135925292969, Learning Rate: 3.90625e-05\n",
      "Epoch [11068/20000], Loss: 850.6424560546875, Entropy 471.8756103515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11069/20000], Loss: 802.5286865234375, Entropy 480.9537658691406, Learning Rate: 3.90625e-05\n",
      "Epoch [11070/20000], Loss: 831.098876953125, Entropy 470.1620178222656, Learning Rate: 3.90625e-05\n",
      "Epoch [11071/20000], Loss: 847.8241577148438, Entropy 465.52239990234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11072/20000], Loss: 835.2765502929688, Entropy 464.08831787109375, Learning Rate: 3.90625e-05\n",
      "Epoch [11073/20000], Loss: 846.946533203125, Entropy 462.7984619140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11074/20000], Loss: 877.142578125, Entropy 468.9761657714844, Learning Rate: 3.90625e-05\n",
      "Epoch [11075/20000], Loss: 866.3410034179688, Entropy 471.21429443359375, Learning Rate: 3.90625e-05\n",
      "Epoch [11076/20000], Loss: 833.7628173828125, Entropy 484.5329284667969, Learning Rate: 3.90625e-05\n",
      "Epoch [11077/20000], Loss: 875.163818359375, Entropy 483.2289733886719, Learning Rate: 3.90625e-05\n",
      "Epoch [11078/20000], Loss: 853.1500244140625, Entropy 454.2091979980469, Learning Rate: 3.90625e-05\n",
      "Epoch [11079/20000], Loss: 895.02392578125, Entropy 468.8584289550781, Learning Rate: 3.90625e-05\n",
      "Epoch [11080/20000], Loss: 897.714111328125, Entropy 465.4593505859375, Learning Rate: 3.90625e-05\n",
      "Epoch [11081/20000], Loss: 814.0880126953125, Entropy 486.8143615722656, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11082/20000], Loss: 842.1342163085938, Entropy 465.77581787109375, Learning Rate: 3.90625e-05\n",
      "Epoch [11083/20000], Loss: 834.2848510742188, Entropy 475.31353759765625, Learning Rate: 3.90625e-05\n",
      "Epoch [11084/20000], Loss: 882.663818359375, Entropy 475.9717712402344, Learning Rate: 3.90625e-05\n",
      "Epoch [11085/20000], Loss: 927.0982055664062, Entropy 462.30584716796875, Learning Rate: 3.90625e-05\n",
      "Epoch [11086/20000], Loss: 893.265625, Entropy 468.4131774902344, Learning Rate: 3.90625e-05\n",
      "Epoch [11087/20000], Loss: 860.364990234375, Entropy 465.4112243652344, Learning Rate: 3.90625e-05\n",
      "Epoch [11088/20000], Loss: 814.9925537109375, Entropy 473.3271789550781, Learning Rate: 3.90625e-05\n",
      "Epoch [11089/20000], Loss: 816.58740234375, Entropy 465.8420104980469, Learning Rate: 3.90625e-05\n",
      "Epoch [11090/20000], Loss: 873.7952880859375, Entropy 465.6773681640625, Learning Rate: 3.90625e-05\n",
      "Epoch [11091/20000], Loss: 833.4774169921875, Entropy 466.140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11092/20000], Loss: 872.4688720703125, Entropy 477.5845947265625, Learning Rate: 3.90625e-05\n",
      "Epoch [11093/20000], Loss: 857.3983154296875, Entropy 473.2088928222656, Learning Rate: 3.90625e-05\n",
      "Epoch [11094/20000], Loss: 869.7310791015625, Entropy 473.1658630371094, Learning Rate: 3.90625e-05\n",
      "Epoch [11095/20000], Loss: 871.234619140625, Entropy 464.359130859375, Learning Rate: 3.90625e-05\n",
      "Epoch [11096/20000], Loss: 851.3138427734375, Entropy 469.9072570800781, Learning Rate: 3.90625e-05\n",
      "Epoch [11097/20000], Loss: 847.3587646484375, Entropy 482.9330749511719, Learning Rate: 3.90625e-05\n",
      "Epoch [11098/20000], Loss: 873.2476806640625, Entropy 455.6244812011719, Learning Rate: 3.90625e-05\n",
      "Epoch [11099/20000], Loss: 848.4187622070312, Entropy 469.87603759765625, Learning Rate: 3.90625e-05\n",
      "Epoch [11100/20000], Loss: 866.7409057617188, Entropy 458.77630615234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11101/20000], Loss: 869.8038330078125, Entropy 458.3199768066406, Learning Rate: 3.90625e-05\n",
      "Epoch [11102/20000], Loss: 855.6696166992188, Entropy 465.09991455078125, Learning Rate: 3.90625e-05\n",
      "Epoch [11103/20000], Loss: 824.57080078125, Entropy 470.0910339355469, Learning Rate: 3.90625e-05\n",
      "Epoch [11104/20000], Loss: 844.011962890625, Entropy 473.6728820800781, Learning Rate: 3.90625e-05\n",
      "Epoch [11105/20000], Loss: 876.1863403320312, Entropy 467.00115966796875, Learning Rate: 3.90625e-05\n",
      "Epoch [11106/20000], Loss: 835.0562133789062, Entropy 479.15130615234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11107/20000], Loss: 852.2547607421875, Entropy 464.6912841796875, Learning Rate: 3.90625e-05\n",
      "Epoch [11108/20000], Loss: 886.6239013671875, Entropy 459.5598449707031, Learning Rate: 3.90625e-05\n",
      "Epoch [11109/20000], Loss: 809.267333984375, Entropy 492.58203125, Learning Rate: 3.90625e-05\n",
      "Epoch [11110/20000], Loss: 901.1578979492188, Entropy 466.38702392578125, Learning Rate: 3.90625e-05\n",
      "Epoch [11111/20000], Loss: 811.8848876953125, Entropy 468.1318664550781, Learning Rate: 3.90625e-05\n",
      "Epoch [11112/20000], Loss: 848.2467651367188, Entropy 467.11541748046875, Learning Rate: 3.90625e-05\n",
      "Epoch [11113/20000], Loss: 846.0835571289062, Entropy 464.17498779296875, Learning Rate: 3.90625e-05\n",
      "Epoch [11114/20000], Loss: 855.252685546875, Entropy 471.0848388671875, Learning Rate: 3.90625e-05\n",
      "Epoch [11115/20000], Loss: 849.6617431640625, Entropy 472.4200744628906, Learning Rate: 3.90625e-05\n",
      "Epoch [11116/20000], Loss: 849.9384765625, Entropy 452.4533996582031, Learning Rate: 3.90625e-05\n",
      "Epoch [11117/20000], Loss: 826.8458862304688, Entropy 467.97967529296875, Learning Rate: 3.90625e-05\n",
      "Epoch [11118/20000], Loss: 845.3939208984375, Entropy 472.4723205566406, Learning Rate: 3.90625e-05\n",
      "Epoch [11119/20000], Loss: 853.950439453125, Entropy 473.7579040527344, Learning Rate: 3.90625e-05\n",
      "Epoch [11120/20000], Loss: 800.7659912109375, Entropy 481.65185546875, Learning Rate: 3.90625e-05\n",
      "Epoch [11121/20000], Loss: 828.8104248046875, Entropy 465.0558166503906, Learning Rate: 3.90625e-05\n",
      "Epoch [11122/20000], Loss: 862.4783935546875, Entropy 467.98388671875, Learning Rate: 3.90625e-05\n",
      "Epoch [11123/20000], Loss: 825.412841796875, Entropy 473.6566162109375, Learning Rate: 3.90625e-05\n",
      "Epoch [11124/20000], Loss: 860.2430419921875, Entropy 468.0262451171875, Learning Rate: 3.90625e-05\n",
      "Epoch [11125/20000], Loss: 891.1322021484375, Entropy 484.1278076171875, Learning Rate: 3.90625e-05\n",
      "Epoch [11126/20000], Loss: 854.4251098632812, Entropy 462.53131103515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11127/20000], Loss: 827.784912109375, Entropy 473.8692321777344, Learning Rate: 3.90625e-05\n",
      "Epoch [11128/20000], Loss: 901.9232177734375, Entropy 462.04638671875, Learning Rate: 3.90625e-05\n",
      "Epoch [11129/20000], Loss: 863.8603515625, Entropy 469.3111572265625, Learning Rate: 3.90625e-05\n",
      "Epoch [11130/20000], Loss: 811.9222412109375, Entropy 486.0584716796875, Learning Rate: 3.90625e-05\n",
      "Epoch [11131/20000], Loss: 870.2392578125, Entropy 477.9749755859375, Learning Rate: 3.90625e-05\n",
      "Epoch [11132/20000], Loss: 836.2711181640625, Entropy 474.6239318847656, Learning Rate: 3.90625e-05\n",
      "Epoch [11133/20000], Loss: 827.10693359375, Entropy 466.8174743652344, Learning Rate: 3.90625e-05\n",
      "Epoch [11134/20000], Loss: 835.1610107421875, Entropy 463.4762268066406, Learning Rate: 3.90625e-05\n",
      "Epoch [11135/20000], Loss: 886.0155029296875, Entropy 476.4613037109375, Learning Rate: 3.90625e-05\n",
      "Epoch [11136/20000], Loss: 890.9613037109375, Entropy 476.4556884765625, Learning Rate: 3.90625e-05\n",
      "Epoch [11137/20000], Loss: 873.066650390625, Entropy 461.5227966308594, Learning Rate: 3.90625e-05\n",
      "Epoch [11138/20000], Loss: 837.7100830078125, Entropy 474.2916564941406, Learning Rate: 3.90625e-05\n",
      "Epoch [11139/20000], Loss: 826.4996337890625, Entropy 478.6711730957031, Learning Rate: 3.90625e-05\n",
      "Epoch [11140/20000], Loss: 847.235107421875, Entropy 467.21240234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11141/20000], Loss: 870.7012329101562, Entropy 466.00982666015625, Learning Rate: 3.90625e-05\n",
      "Epoch [11142/20000], Loss: 796.6934204101562, Entropy 471.74957275390625, Learning Rate: 3.90625e-05\n",
      "Epoch [11143/20000], Loss: 837.016357421875, Entropy 471.4850158691406, Learning Rate: 3.90625e-05\n",
      "Epoch [11144/20000], Loss: 867.6630859375, Entropy 475.8778381347656, Learning Rate: 3.90625e-05\n",
      "Epoch [11145/20000], Loss: 863.898193359375, Entropy 466.1092529296875, Learning Rate: 3.90625e-05\n",
      "Epoch [11146/20000], Loss: 876.7926025390625, Entropy 463.7068786621094, Learning Rate: 3.90625e-05\n",
      "Epoch [11147/20000], Loss: 827.0953979492188, Entropy 488.88873291015625, Learning Rate: 3.90625e-05\n",
      "Epoch [11148/20000], Loss: 869.2857666015625, Entropy 468.8298034667969, Learning Rate: 3.90625e-05\n",
      "Epoch [11149/20000], Loss: 864.0106811523438, Entropy 464.49993896484375, Learning Rate: 3.90625e-05\n",
      "Epoch [11150/20000], Loss: 848.4227294921875, Entropy 470.0735168457031, Learning Rate: 3.90625e-05\n",
      "Epoch [11151/20000], Loss: 901.9307861328125, Entropy 459.6785583496094, Learning Rate: 3.90625e-05\n",
      "Epoch [11152/20000], Loss: 873.2584228515625, Entropy 467.8966369628906, Learning Rate: 3.90625e-05\n",
      "Epoch [11153/20000], Loss: 917.7201538085938, Entropy 471.32281494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11154/20000], Loss: 831.775390625, Entropy 471.8623962402344, Learning Rate: 3.90625e-05\n",
      "Epoch [11155/20000], Loss: 852.4288940429688, Entropy 461.44781494140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11156/20000], Loss: 859.1300048828125, Entropy 471.6883850097656, Learning Rate: 3.90625e-05\n",
      "Epoch [11157/20000], Loss: 829.0050048828125, Entropy 464.9227294921875, Learning Rate: 3.90625e-05\n",
      "Epoch [11158/20000], Loss: 880.5831298828125, Entropy 472.7207336425781, Learning Rate: 3.90625e-05\n",
      "Epoch [11159/20000], Loss: 809.8211669921875, Entropy 471.7956848144531, Learning Rate: 3.90625e-05\n",
      "Epoch [11160/20000], Loss: 910.7666015625, Entropy 464.724365234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11161/20000], Loss: 881.4075927734375, Entropy 472.4177551269531, Learning Rate: 3.90625e-05\n",
      "Epoch [11162/20000], Loss: 819.67822265625, Entropy 473.4059143066406, Learning Rate: 3.90625e-05\n",
      "Epoch [11163/20000], Loss: 855.1478271484375, Entropy 462.0779113769531, Learning Rate: 3.90625e-05\n",
      "Epoch [11164/20000], Loss: 911.9214477539062, Entropy 456.48052978515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11165/20000], Loss: 845.3533935546875, Entropy 473.3515930175781, Learning Rate: 3.90625e-05\n",
      "Epoch [11166/20000], Loss: 873.0379638671875, Entropy 471.3023376464844, Learning Rate: 3.90625e-05\n",
      "Epoch [11167/20000], Loss: 858.7659912109375, Entropy 475.4840393066406, Learning Rate: 3.90625e-05\n",
      "Epoch [11168/20000], Loss: 871.4476318359375, Entropy 469.3965759277344, Learning Rate: 3.90625e-05\n",
      "Epoch [11169/20000], Loss: 859.22216796875, Entropy 467.8338317871094, Learning Rate: 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11170/20000], Loss: 842.2501220703125, Entropy 478.50048828125, Learning Rate: 3.90625e-05\n",
      "Epoch [11171/20000], Loss: 814.102783203125, Entropy 474.7362365722656, Learning Rate: 3.90625e-05\n",
      "Epoch [11172/20000], Loss: 846.2420654296875, Entropy 476.7088928222656, Learning Rate: 3.90625e-05\n",
      "Epoch [11173/20000], Loss: 820.8966064453125, Entropy 470.1194763183594, Learning Rate: 3.90625e-05\n",
      "Epoch [11174/20000], Loss: 829.1008911132812, Entropy 464.65155029296875, Learning Rate: 3.90625e-05\n",
      "Epoch [11175/20000], Loss: 872.9351806640625, Entropy 464.273193359375, Learning Rate: 3.90625e-05\n",
      "Epoch [11176/20000], Loss: 824.05126953125, Entropy 462.7543640136719, Learning Rate: 3.90625e-05\n",
      "Epoch [11177/20000], Loss: 818.279052734375, Entropy 471.7846374511719, Learning Rate: 3.90625e-05\n",
      "Epoch [11178/20000], Loss: 851.3638916015625, Entropy 455.5897216796875, Learning Rate: 3.90625e-05\n",
      "Epoch [11179/20000], Loss: 811.3526611328125, Entropy 473.4820251464844, Learning Rate: 3.90625e-05\n",
      "Epoch [11180/20000], Loss: 830.72314453125, Entropy 467.9463195800781, Learning Rate: 3.90625e-05\n",
      "Epoch [11181/20000], Loss: 845.8494873046875, Entropy 473.8904113769531, Learning Rate: 3.90625e-05\n",
      "Epoch [11182/20000], Loss: 873.1090087890625, Entropy 469.6603088378906, Learning Rate: 3.90625e-05\n",
      "Epoch [11183/20000], Loss: 864.015869140625, Entropy 468.24609375, Learning Rate: 3.90625e-05\n",
      "Epoch [11184/20000], Loss: 807.5250244140625, Entropy 466.1114196777344, Learning Rate: 3.90625e-05\n",
      "Epoch [11185/20000], Loss: 833.776611328125, Entropy 456.9967956542969, Learning Rate: 3.90625e-05\n",
      "Epoch [11186/20000], Loss: 852.9832763671875, Entropy 474.8878479003906, Learning Rate: 3.90625e-05\n",
      "Epoch [11187/20000], Loss: 874.2705078125, Entropy 455.797607421875, Learning Rate: 3.90625e-05\n",
      "Epoch [11188/20000], Loss: 847.9296264648438, Entropy 469.71405029296875, Learning Rate: 3.90625e-05\n",
      "Epoch [11189/20000], Loss: 835.588134765625, Entropy 470.363037109375, Learning Rate: 3.90625e-05\n",
      "Epoch [11190/20000], Loss: 856.8214111328125, Entropy 462.4592590332031, Learning Rate: 3.90625e-05\n",
      "Epoch [11191/20000], Loss: 842.2282104492188, Entropy 473.14898681640625, Learning Rate: 3.90625e-05\n",
      "Epoch [11192/20000], Loss: 888.0938720703125, Entropy 468.7521057128906, Learning Rate: 3.90625e-05\n",
      "Epoch [11193/20000], Loss: 849.9034423828125, Entropy 468.818359375, Learning Rate: 3.90625e-05\n",
      "Epoch [11194/20000], Loss: 882.5835571289062, Entropy 471.66888427734375, Learning Rate: 3.90625e-05\n",
      "Epoch [11195/20000], Loss: 837.5289306640625, Entropy 473.9840393066406, Learning Rate: 3.90625e-05\n",
      "Epoch [11196/20000], Loss: 908.3375244140625, Entropy 462.212646484375, Learning Rate: 3.90625e-05\n",
      "Epoch [11197/20000], Loss: 865.08203125, Entropy 470.182373046875, Learning Rate: 3.90625e-05\n",
      "Epoch [11198/20000], Loss: 863.2335205078125, Entropy 460.8324890136719, Learning Rate: 3.90625e-05\n",
      "Epoch [11199/20000], Loss: 839.2122802734375, Entropy 460.4237060546875, Learning Rate: 3.90625e-05\n",
      "Epoch [11200/20000], Loss: 883.6060791015625, Entropy 469.0808410644531, Learning Rate: 3.90625e-05\n",
      "Epoch [11201/20000], Loss: 838.0443725585938, Entropy 478.76116943359375, Learning Rate: 3.90625e-05\n",
      "Epoch [11202/20000], Loss: 857.1950073242188, Entropy 470.96343994140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11203/20000], Loss: 839.0067749023438, Entropy 466.65618896484375, Learning Rate: 3.90625e-05\n",
      "Epoch [11204/20000], Loss: 829.7989501953125, Entropy 470.7663879394531, Learning Rate: 3.90625e-05\n",
      "Epoch [11205/20000], Loss: 879.314208984375, Entropy 468.0004577636719, Learning Rate: 3.90625e-05\n",
      "Epoch [11206/20000], Loss: 848.1436767578125, Entropy 475.4670104980469, Learning Rate: 3.90625e-05\n",
      "Epoch [11207/20000], Loss: 863.1162109375, Entropy 467.8502197265625, Learning Rate: 3.90625e-05\n",
      "Epoch [11208/20000], Loss: 865.775634765625, Entropy 464.2847595214844, Learning Rate: 3.90625e-05\n",
      "Epoch [11209/20000], Loss: 835.59423828125, Entropy 475.1998596191406, Learning Rate: 3.90625e-05\n",
      "Epoch [11210/20000], Loss: 820.3311767578125, Entropy 472.3429870605469, Learning Rate: 3.90625e-05\n",
      "Epoch [11211/20000], Loss: 812.2024536132812, Entropy 455.03851318359375, Learning Rate: 3.90625e-05\n",
      "Epoch [11212/20000], Loss: 894.323486328125, Entropy 468.72021484375, Learning Rate: 3.90625e-05\n",
      "Epoch [11213/20000], Loss: 818.8362426757812, Entropy 475.12896728515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11214/20000], Loss: 837.2576293945312, Entropy 468.58453369140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11215/20000], Loss: 859.894287109375, Entropy 471.7698974609375, Learning Rate: 3.90625e-05\n",
      "Epoch [11216/20000], Loss: 830.3916015625, Entropy 469.4452209472656, Learning Rate: 3.90625e-05\n",
      "Epoch [11217/20000], Loss: 896.3351440429688, Entropy 464.97222900390625, Learning Rate: 3.90625e-05\n",
      "Epoch [11218/20000], Loss: 854.911376953125, Entropy 462.8171691894531, Learning Rate: 3.90625e-05\n",
      "Epoch [11219/20000], Loss: 879.3441772460938, Entropy 466.94390869140625, Learning Rate: 3.90625e-05\n",
      "Epoch [11220/20000], Loss: 824.8306884765625, Entropy 468.1921081542969, Learning Rate: 3.90625e-05\n",
      "Epoch [11221/20000], Loss: 820.4235229492188, Entropy 476.26202392578125, Learning Rate: 3.90625e-05\n",
      "Epoch [11222/20000], Loss: 800.7879028320312, Entropy 468.19281005859375, Learning Rate: 3.90625e-05\n",
      "Epoch [11223/20000], Loss: 900.75732421875, Entropy 471.4932556152344, Learning Rate: 3.90625e-05\n",
      "Epoch [11224/20000], Loss: 855.85302734375, Entropy 479.1100769042969, Learning Rate: 3.90625e-05\n",
      "Epoch [11225/20000], Loss: 860.5252685546875, Entropy 464.2916259765625, Learning Rate: 3.90625e-05\n",
      "Epoch [11226/20000], Loss: 873.3967895507812, Entropy 466.72662353515625, Learning Rate: 3.90625e-05\n",
      "Epoch [11227/20000], Loss: 801.044189453125, Entropy 489.0861511230469, Learning Rate: 3.90625e-05\n",
      "Epoch [11228/20000], Loss: 849.7744750976562, Entropy 466.98773193359375, Learning Rate: 3.90625e-05\n",
      "Epoch [11229/20000], Loss: 881.191650390625, Entropy 473.3333740234375, Learning Rate: 3.90625e-05\n",
      "Epoch [11230/20000], Loss: 894.65771484375, Entropy 464.5638122558594, Learning Rate: 1.953125e-05\n",
      "Epoch [11231/20000], Loss: 863.3463134765625, Entropy 462.2817077636719, Learning Rate: 1.953125e-05\n",
      "Epoch [11232/20000], Loss: 875.36474609375, Entropy 456.7447509765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11233/20000], Loss: 895.5916748046875, Entropy 461.30126953125, Learning Rate: 1.953125e-05\n",
      "Epoch [11234/20000], Loss: 849.0546264648438, Entropy 462.35992431640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11235/20000], Loss: 878.49267578125, Entropy 456.4353942871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11236/20000], Loss: 830.5599975585938, Entropy 473.75897216796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11237/20000], Loss: 841.6253051757812, Entropy 481.36773681640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11238/20000], Loss: 855.284423828125, Entropy 462.2870178222656, Learning Rate: 1.953125e-05\n",
      "Epoch [11239/20000], Loss: 844.4486083984375, Entropy 459.2096252441406, Learning Rate: 1.953125e-05\n",
      "Epoch [11240/20000], Loss: 877.7454833984375, Entropy 464.6201171875, Learning Rate: 1.953125e-05\n",
      "Epoch [11241/20000], Loss: 825.90673828125, Entropy 469.3876037597656, Learning Rate: 1.953125e-05\n",
      "Epoch [11242/20000], Loss: 821.48876953125, Entropy 479.6865539550781, Learning Rate: 1.953125e-05\n",
      "Epoch [11243/20000], Loss: 828.2797241210938, Entropy 465.78143310546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11244/20000], Loss: 812.2877197265625, Entropy 464.9954528808594, Learning Rate: 1.953125e-05\n",
      "Epoch [11245/20000], Loss: 873.5023803710938, Entropy 464.96527099609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11246/20000], Loss: 812.712890625, Entropy 479.777099609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11247/20000], Loss: 821.6241455078125, Entropy 477.7141418457031, Learning Rate: 1.953125e-05\n",
      "Epoch [11248/20000], Loss: 825.841552734375, Entropy 468.3208923339844, Learning Rate: 1.953125e-05\n",
      "Epoch [11249/20000], Loss: 863.4923706054688, Entropy 470.83416748046875, Learning Rate: 1.953125e-05\n",
      "Epoch [11250/20000], Loss: 869.8634033203125, Entropy 468.9124450683594, Learning Rate: 1.953125e-05\n",
      "Epoch [11251/20000], Loss: 848.398681640625, Entropy 468.7503356933594, Learning Rate: 1.953125e-05\n",
      "Epoch [11252/20000], Loss: 826.9928588867188, Entropy 465.84869384765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11253/20000], Loss: 824.1370849609375, Entropy 475.2253723144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11254/20000], Loss: 862.124267578125, Entropy 471.0799560546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11255/20000], Loss: 848.8499755859375, Entropy 472.1785888671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11256/20000], Loss: 879.3697509765625, Entropy 464.1602783203125, Learning Rate: 1.953125e-05\n",
      "Epoch [11257/20000], Loss: 815.3291625976562, Entropy 480.13177490234375, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11258/20000], Loss: 834.12255859375, Entropy 453.5404052734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11259/20000], Loss: 851.481201171875, Entropy 478.9993591308594, Learning Rate: 1.953125e-05\n",
      "Epoch [11260/20000], Loss: 798.801513671875, Entropy 480.0618591308594, Learning Rate: 1.953125e-05\n",
      "Epoch [11261/20000], Loss: 859.1591186523438, Entropy 456.50616455078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11262/20000], Loss: 872.0267944335938, Entropy 466.40240478515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11263/20000], Loss: 799.3204345703125, Entropy 481.1022033691406, Learning Rate: 1.953125e-05\n",
      "Epoch [11264/20000], Loss: 857.009033203125, Entropy 460.3949890136719, Learning Rate: 1.953125e-05\n",
      "Epoch [11265/20000], Loss: 817.570068359375, Entropy 470.3791198730469, Learning Rate: 1.953125e-05\n",
      "Epoch [11266/20000], Loss: 869.5885620117188, Entropy 474.97186279296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11267/20000], Loss: 834.2413330078125, Entropy 466.6796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11268/20000], Loss: 824.165771484375, Entropy 468.0625, Learning Rate: 1.953125e-05\n",
      "Epoch [11269/20000], Loss: 848.9095458984375, Entropy 472.09130859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11270/20000], Loss: 852.4776000976562, Entropy 476.58538818359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11271/20000], Loss: 852.7552490234375, Entropy 478.0687255859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11272/20000], Loss: 861.10791015625, Entropy 472.85107421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11273/20000], Loss: 872.773681640625, Entropy 479.6881408691406, Learning Rate: 1.953125e-05\n",
      "Epoch [11274/20000], Loss: 844.6524658203125, Entropy 471.1221618652344, Learning Rate: 1.953125e-05\n",
      "Epoch [11275/20000], Loss: 849.02099609375, Entropy 451.69189453125, Learning Rate: 1.953125e-05\n",
      "Epoch [11276/20000], Loss: 853.780029296875, Entropy 479.9627990722656, Learning Rate: 1.953125e-05\n",
      "Epoch [11277/20000], Loss: 851.1459350585938, Entropy 469.66998291015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11278/20000], Loss: 885.2987060546875, Entropy 451.357177734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11279/20000], Loss: 833.337890625, Entropy 481.5186462402344, Learning Rate: 1.953125e-05\n",
      "Epoch [11280/20000], Loss: 810.1846923828125, Entropy 467.8602294921875, Learning Rate: 1.953125e-05\n",
      "Epoch [11281/20000], Loss: 825.3592529296875, Entropy 465.8402099609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11282/20000], Loss: 851.859619140625, Entropy 479.7809753417969, Learning Rate: 1.953125e-05\n",
      "Epoch [11283/20000], Loss: 831.4166259765625, Entropy 466.9284973144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11284/20000], Loss: 867.44970703125, Entropy 457.3739013671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11285/20000], Loss: 834.947998046875, Entropy 483.0032043457031, Learning Rate: 1.953125e-05\n",
      "Epoch [11286/20000], Loss: 840.6339721679688, Entropy 481.91693115234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11287/20000], Loss: 920.576171875, Entropy 455.4555358886719, Learning Rate: 1.953125e-05\n",
      "Epoch [11288/20000], Loss: 871.8895263671875, Entropy 464.0375671386719, Learning Rate: 1.953125e-05\n",
      "Epoch [11289/20000], Loss: 860.6116943359375, Entropy 467.9211730957031, Learning Rate: 1.953125e-05\n",
      "Epoch [11290/20000], Loss: 803.4692993164062, Entropy 476.99468994140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11291/20000], Loss: 888.3282470703125, Entropy 477.1036682128906, Learning Rate: 1.953125e-05\n",
      "Epoch [11292/20000], Loss: 834.19091796875, Entropy 477.0715637207031, Learning Rate: 1.953125e-05\n",
      "Epoch [11293/20000], Loss: 896.7235107421875, Entropy 478.4583435058594, Learning Rate: 1.953125e-05\n",
      "Epoch [11294/20000], Loss: 871.3927612304688, Entropy 482.05230712890625, Learning Rate: 1.953125e-05\n",
      "Epoch [11295/20000], Loss: 822.151611328125, Entropy 467.9046630859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11296/20000], Loss: 848.076416015625, Entropy 466.8775634765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11297/20000], Loss: 836.0489501953125, Entropy 468.7633361816406, Learning Rate: 1.953125e-05\n",
      "Epoch [11298/20000], Loss: 840.150390625, Entropy 481.3125, Learning Rate: 1.953125e-05\n",
      "Epoch [11299/20000], Loss: 836.771728515625, Entropy 463.0306091308594, Learning Rate: 1.953125e-05\n",
      "Epoch [11300/20000], Loss: 835.3215942382812, Entropy 469.35272216796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11301/20000], Loss: 827.6673583984375, Entropy 480.2808532714844, Learning Rate: 1.953125e-05\n",
      "Epoch [11302/20000], Loss: 862.687744140625, Entropy 465.2837829589844, Learning Rate: 1.953125e-05\n",
      "Epoch [11303/20000], Loss: 850.217041015625, Entropy 476.6063537597656, Learning Rate: 1.953125e-05\n",
      "Epoch [11304/20000], Loss: 832.5228271484375, Entropy 471.7809143066406, Learning Rate: 1.953125e-05\n",
      "Epoch [11305/20000], Loss: 847.36328125, Entropy 476.7760925292969, Learning Rate: 1.953125e-05\n",
      "Epoch [11306/20000], Loss: 858.0667114257812, Entropy 472.44451904296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11307/20000], Loss: 867.5304565429688, Entropy 456.08416748046875, Learning Rate: 1.953125e-05\n",
      "Epoch [11308/20000], Loss: 880.32666015625, Entropy 483.4753723144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11309/20000], Loss: 806.55810546875, Entropy 470.0025634765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11310/20000], Loss: 840.478271484375, Entropy 470.4067077636719, Learning Rate: 1.953125e-05\n",
      "Epoch [11311/20000], Loss: 842.2954711914062, Entropy 459.59515380859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11312/20000], Loss: 869.1441650390625, Entropy 456.8001708984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11313/20000], Loss: 858.156005859375, Entropy 465.1204528808594, Learning Rate: 1.953125e-05\n",
      "Epoch [11314/20000], Loss: 824.1305541992188, Entropy 466.19342041015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11315/20000], Loss: 862.716064453125, Entropy 468.98876953125, Learning Rate: 1.953125e-05\n",
      "Epoch [11316/20000], Loss: 857.76171875, Entropy 462.3563232421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11317/20000], Loss: 863.3364868164062, Entropy 468.38507080078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11318/20000], Loss: 818.029541015625, Entropy 465.53564453125, Learning Rate: 1.953125e-05\n",
      "Epoch [11319/20000], Loss: 831.1732177734375, Entropy 478.542724609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11320/20000], Loss: 827.48095703125, Entropy 478.662109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11321/20000], Loss: 875.349609375, Entropy 455.1614990234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11322/20000], Loss: 850.792724609375, Entropy 466.0622253417969, Learning Rate: 1.953125e-05\n",
      "Epoch [11323/20000], Loss: 827.6278076171875, Entropy 474.5904846191406, Learning Rate: 1.953125e-05\n",
      "Epoch [11324/20000], Loss: 808.9121704101562, Entropy 464.79486083984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11325/20000], Loss: 879.632080078125, Entropy 461.9734191894531, Learning Rate: 1.953125e-05\n",
      "Epoch [11326/20000], Loss: 871.078125, Entropy 458.360107421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11327/20000], Loss: 915.6787109375, Entropy 468.9883117675781, Learning Rate: 1.953125e-05\n",
      "Epoch [11328/20000], Loss: 868.5757446289062, Entropy 464.08013916015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11329/20000], Loss: 887.2528076171875, Entropy 458.8646240234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11330/20000], Loss: 782.73828125, Entropy 477.7602233886719, Learning Rate: 1.953125e-05\n",
      "Epoch [11331/20000], Loss: 867.131103515625, Entropy 465.8412780761719, Learning Rate: 1.953125e-05\n",
      "Epoch [11332/20000], Loss: 841.142578125, Entropy 476.9145202636719, Learning Rate: 1.953125e-05\n",
      "Epoch [11333/20000], Loss: 883.9961547851562, Entropy 476.81195068359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11334/20000], Loss: 853.9190673828125, Entropy 457.7888488769531, Learning Rate: 1.953125e-05\n",
      "Epoch [11335/20000], Loss: 828.9157104492188, Entropy 476.77679443359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11336/20000], Loss: 845.6475830078125, Entropy 479.5894470214844, Learning Rate: 1.953125e-05\n",
      "Epoch [11337/20000], Loss: 834.3394165039062, Entropy 448.96380615234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11338/20000], Loss: 839.3656005859375, Entropy 459.4167785644531, Learning Rate: 1.953125e-05\n",
      "Epoch [11339/20000], Loss: 855.484130859375, Entropy 471.2150573730469, Learning Rate: 1.953125e-05\n",
      "Epoch [11340/20000], Loss: 864.5245361328125, Entropy 484.0816345214844, Learning Rate: 1.953125e-05\n",
      "Epoch [11341/20000], Loss: 849.7718505859375, Entropy 469.1835021972656, Learning Rate: 1.953125e-05\n",
      "Epoch [11342/20000], Loss: 885.4385986328125, Entropy 466.2226867675781, Learning Rate: 1.953125e-05\n",
      "Epoch [11343/20000], Loss: 862.3728637695312, Entropy 476.69427490234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11344/20000], Loss: 833.2528686523438, Entropy 476.56658935546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11345/20000], Loss: 872.521728515625, Entropy 471.7443542480469, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11346/20000], Loss: 861.142333984375, Entropy 463.4263916015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11347/20000], Loss: 815.9553833007812, Entropy 465.53424072265625, Learning Rate: 1.953125e-05\n",
      "Epoch [11348/20000], Loss: 807.5017700195312, Entropy 474.73663330078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11349/20000], Loss: 826.1329345703125, Entropy 479.75537109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11350/20000], Loss: 853.1184692382812, Entropy 458.28607177734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11351/20000], Loss: 843.2608642578125, Entropy 461.4724426269531, Learning Rate: 1.953125e-05\n",
      "Epoch [11352/20000], Loss: 825.66943359375, Entropy 469.5110168457031, Learning Rate: 1.953125e-05\n",
      "Epoch [11353/20000], Loss: 896.92919921875, Entropy 466.4419860839844, Learning Rate: 1.953125e-05\n",
      "Epoch [11354/20000], Loss: 834.059814453125, Entropy 470.056396484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11355/20000], Loss: 839.8935546875, Entropy 478.0285949707031, Learning Rate: 1.953125e-05\n",
      "Epoch [11356/20000], Loss: 893.7538452148438, Entropy 468.02484130859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11357/20000], Loss: 890.6288452148438, Entropy 460.15130615234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11358/20000], Loss: 848.1219482421875, Entropy 459.3586730957031, Learning Rate: 1.953125e-05\n",
      "Epoch [11359/20000], Loss: 829.9307861328125, Entropy 479.3009948730469, Learning Rate: 1.953125e-05\n",
      "Epoch [11360/20000], Loss: 846.3927001953125, Entropy 465.5450744628906, Learning Rate: 1.953125e-05\n",
      "Epoch [11361/20000], Loss: 825.6633911132812, Entropy 482.28240966796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11362/20000], Loss: 855.5740966796875, Entropy 476.0788269042969, Learning Rate: 1.953125e-05\n",
      "Epoch [11363/20000], Loss: 836.4676513671875, Entropy 478.2589416503906, Learning Rate: 1.953125e-05\n",
      "Epoch [11364/20000], Loss: 852.1878662109375, Entropy 485.1756591796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11365/20000], Loss: 829.2247924804688, Entropy 477.84429931640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11366/20000], Loss: 857.615234375, Entropy 460.6705322265625, Learning Rate: 1.953125e-05\n",
      "Epoch [11367/20000], Loss: 869.4078369140625, Entropy 470.863037109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11368/20000], Loss: 843.8599243164062, Entropy 469.84210205078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11369/20000], Loss: 858.1683349609375, Entropy 473.2063293457031, Learning Rate: 1.953125e-05\n",
      "Epoch [11370/20000], Loss: 866.649658203125, Entropy 468.0849609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11371/20000], Loss: 844.7702026367188, Entropy 472.00823974609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11372/20000], Loss: 817.0533447265625, Entropy 479.4704284667969, Learning Rate: 1.953125e-05\n",
      "Epoch [11373/20000], Loss: 873.223388671875, Entropy 470.7146911621094, Learning Rate: 1.953125e-05\n",
      "Epoch [11374/20000], Loss: 855.889404296875, Entropy 454.319091796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11375/20000], Loss: 885.884033203125, Entropy 478.3768005371094, Learning Rate: 1.953125e-05\n",
      "Epoch [11376/20000], Loss: 814.5939331054688, Entropy 473.93780517578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11377/20000], Loss: 808.2877197265625, Entropy 469.5875549316406, Learning Rate: 1.953125e-05\n",
      "Epoch [11378/20000], Loss: 828.4512329101562, Entropy 469.49420166015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11379/20000], Loss: 831.3975830078125, Entropy 474.2698059082031, Learning Rate: 1.953125e-05\n",
      "Epoch [11380/20000], Loss: 841.664794921875, Entropy 480.2168273925781, Learning Rate: 1.953125e-05\n",
      "Epoch [11381/20000], Loss: 840.5770874023438, Entropy 479.04803466796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11382/20000], Loss: 813.0975341796875, Entropy 483.5357971191406, Learning Rate: 1.953125e-05\n",
      "Epoch [11383/20000], Loss: 860.3787231445312, Entropy 461.20306396484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11384/20000], Loss: 856.4884033203125, Entropy 471.9748229980469, Learning Rate: 1.953125e-05\n",
      "Epoch [11385/20000], Loss: 870.512939453125, Entropy 467.0575256347656, Learning Rate: 1.953125e-05\n",
      "Epoch [11386/20000], Loss: 867.2369384765625, Entropy 467.9103088378906, Learning Rate: 1.953125e-05\n",
      "Epoch [11387/20000], Loss: 840.6787109375, Entropy 458.9534606933594, Learning Rate: 1.953125e-05\n",
      "Epoch [11388/20000], Loss: 879.8095703125, Entropy 461.9049987792969, Learning Rate: 1.953125e-05\n",
      "Epoch [11389/20000], Loss: 865.8077392578125, Entropy 471.10302734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11390/20000], Loss: 836.836669921875, Entropy 479.6761474609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11391/20000], Loss: 866.0257568359375, Entropy 467.6304626464844, Learning Rate: 1.953125e-05\n",
      "Epoch [11392/20000], Loss: 868.050537109375, Entropy 468.3746643066406, Learning Rate: 1.953125e-05\n",
      "Epoch [11393/20000], Loss: 876.8089599609375, Entropy 464.6519470214844, Learning Rate: 1.953125e-05\n",
      "Epoch [11394/20000], Loss: 835.5311279296875, Entropy 455.8942565917969, Learning Rate: 1.953125e-05\n",
      "Epoch [11395/20000], Loss: 863.912841796875, Entropy 479.60546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11396/20000], Loss: 871.322998046875, Entropy 469.1515197753906, Learning Rate: 1.953125e-05\n",
      "Epoch [11397/20000], Loss: 859.72314453125, Entropy 461.1831970214844, Learning Rate: 1.953125e-05\n",
      "Epoch [11398/20000], Loss: 801.690673828125, Entropy 469.7112121582031, Learning Rate: 1.953125e-05\n",
      "Epoch [11399/20000], Loss: 832.6153564453125, Entropy 469.8232727050781, Learning Rate: 1.953125e-05\n",
      "Epoch [11400/20000], Loss: 859.5300903320312, Entropy 467.25689697265625, Learning Rate: 1.953125e-05\n",
      "Epoch [11401/20000], Loss: 863.7119140625, Entropy 475.8485107421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11402/20000], Loss: 898.7578735351562, Entropy 472.01715087890625, Learning Rate: 1.953125e-05\n",
      "Epoch [11403/20000], Loss: 822.151123046875, Entropy 467.1765441894531, Learning Rate: 1.953125e-05\n",
      "Epoch [11404/20000], Loss: 811.0859985351562, Entropy 459.55706787109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11405/20000], Loss: 888.3411865234375, Entropy 458.4552917480469, Learning Rate: 1.953125e-05\n",
      "Epoch [11406/20000], Loss: 885.487548828125, Entropy 462.6617736816406, Learning Rate: 1.953125e-05\n",
      "Epoch [11407/20000], Loss: 883.4581298828125, Entropy 464.9397888183594, Learning Rate: 1.953125e-05\n",
      "Epoch [11408/20000], Loss: 848.184326171875, Entropy 473.0534973144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11409/20000], Loss: 840.6378173828125, Entropy 469.1923828125, Learning Rate: 1.953125e-05\n",
      "Epoch [11410/20000], Loss: 857.8682861328125, Entropy 461.4564208984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11411/20000], Loss: 843.2132568359375, Entropy 468.9903259277344, Learning Rate: 1.953125e-05\n",
      "Epoch [11412/20000], Loss: 853.2066650390625, Entropy 461.5462341308594, Learning Rate: 1.953125e-05\n",
      "Epoch [11413/20000], Loss: 849.765869140625, Entropy 466.6875, Learning Rate: 1.953125e-05\n",
      "Epoch [11414/20000], Loss: 855.6763916015625, Entropy 462.5386657714844, Learning Rate: 1.953125e-05\n",
      "Epoch [11415/20000], Loss: 855.2860107421875, Entropy 470.3852233886719, Learning Rate: 1.953125e-05\n",
      "Epoch [11416/20000], Loss: 847.4154052734375, Entropy 474.5705261230469, Learning Rate: 1.953125e-05\n",
      "Epoch [11417/20000], Loss: 857.1395263671875, Entropy 474.3560791015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11418/20000], Loss: 818.8926391601562, Entropy 471.14654541015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11419/20000], Loss: 895.3500366210938, Entropy 480.68023681640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11420/20000], Loss: 834.9769287109375, Entropy 458.4465637207031, Learning Rate: 1.953125e-05\n",
      "Epoch [11421/20000], Loss: 872.0505981445312, Entropy 463.25421142578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11422/20000], Loss: 829.938720703125, Entropy 475.4605712890625, Learning Rate: 1.953125e-05\n",
      "Epoch [11423/20000], Loss: 886.8946533203125, Entropy 475.2438049316406, Learning Rate: 1.953125e-05\n",
      "Epoch [11424/20000], Loss: 808.201171875, Entropy 472.0625, Learning Rate: 1.953125e-05\n",
      "Epoch [11425/20000], Loss: 859.3056030273438, Entropy 467.58782958984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11426/20000], Loss: 826.079345703125, Entropy 471.7430114746094, Learning Rate: 1.953125e-05\n",
      "Epoch [11427/20000], Loss: 854.077392578125, Entropy 464.5053405761719, Learning Rate: 1.953125e-05\n",
      "Epoch [11428/20000], Loss: 925.169189453125, Entropy 468.2358093261719, Learning Rate: 1.953125e-05\n",
      "Epoch [11429/20000], Loss: 849.1060791015625, Entropy 479.1084289550781, Learning Rate: 1.953125e-05\n",
      "Epoch [11430/20000], Loss: 812.8590087890625, Entropy 495.4403076171875, Learning Rate: 1.953125e-05\n",
      "Epoch [11431/20000], Loss: 845.7640380859375, Entropy 477.0464782714844, Learning Rate: 1.953125e-05\n",
      "Epoch [11432/20000], Loss: 857.548583984375, Entropy 464.2621765136719, Learning Rate: 1.953125e-05\n",
      "Epoch [11433/20000], Loss: 851.9715576171875, Entropy 482.5535888671875, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11434/20000], Loss: 868.9627075195312, Entropy 468.98065185546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11435/20000], Loss: 809.5831298828125, Entropy 474.4322509765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11436/20000], Loss: 895.6048583984375, Entropy 467.238037109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11437/20000], Loss: 854.034423828125, Entropy 469.44970703125, Learning Rate: 1.953125e-05\n",
      "Epoch [11438/20000], Loss: 815.5100708007812, Entropy 479.65777587890625, Learning Rate: 1.953125e-05\n",
      "Epoch [11439/20000], Loss: 869.3055419921875, Entropy 462.7571105957031, Learning Rate: 1.953125e-05\n",
      "Epoch [11440/20000], Loss: 879.33740234375, Entropy 466.9510192871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11441/20000], Loss: 843.114990234375, Entropy 474.7462463378906, Learning Rate: 1.953125e-05\n",
      "Epoch [11442/20000], Loss: 837.2269287109375, Entropy 461.582763671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11443/20000], Loss: 860.2649536132812, Entropy 480.10662841796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11444/20000], Loss: 870.8533935546875, Entropy 479.8519287109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11445/20000], Loss: 859.4163208007812, Entropy 468.85015869140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11446/20000], Loss: 844.55615234375, Entropy 489.1829528808594, Learning Rate: 1.953125e-05\n",
      "Epoch [11447/20000], Loss: 845.0747680664062, Entropy 475.37335205078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11448/20000], Loss: 838.1387939453125, Entropy 474.7850036621094, Learning Rate: 1.953125e-05\n",
      "Epoch [11449/20000], Loss: 846.899658203125, Entropy 472.2362365722656, Learning Rate: 1.953125e-05\n",
      "Epoch [11450/20000], Loss: 833.77197265625, Entropy 472.0011901855469, Learning Rate: 1.953125e-05\n",
      "Epoch [11451/20000], Loss: 831.1600341796875, Entropy 482.57177734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11452/20000], Loss: 825.6112060546875, Entropy 470.9122009277344, Learning Rate: 1.953125e-05\n",
      "Epoch [11453/20000], Loss: 816.6765747070312, Entropy 465.61077880859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11454/20000], Loss: 886.9913330078125, Entropy 459.8795166015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11455/20000], Loss: 869.2281494140625, Entropy 470.79052734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11456/20000], Loss: 840.2841796875, Entropy 463.6613464355469, Learning Rate: 1.953125e-05\n",
      "Epoch [11457/20000], Loss: 819.5733642578125, Entropy 469.2325744628906, Learning Rate: 1.953125e-05\n",
      "Epoch [11458/20000], Loss: 828.551513671875, Entropy 475.741943359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11459/20000], Loss: 847.48193359375, Entropy 472.6950378417969, Learning Rate: 1.953125e-05\n",
      "Epoch [11460/20000], Loss: 832.7056884765625, Entropy 470.2295227050781, Learning Rate: 1.953125e-05\n",
      "Epoch [11461/20000], Loss: 913.7646484375, Entropy 449.8382263183594, Learning Rate: 1.953125e-05\n",
      "Epoch [11462/20000], Loss: 830.0753173828125, Entropy 476.8638916015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11463/20000], Loss: 832.920166015625, Entropy 481.4494323730469, Learning Rate: 1.953125e-05\n",
      "Epoch [11464/20000], Loss: 868.19775390625, Entropy 471.58349609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11465/20000], Loss: 880.774658203125, Entropy 460.6355285644531, Learning Rate: 1.953125e-05\n",
      "Epoch [11466/20000], Loss: 853.474853515625, Entropy 473.8337707519531, Learning Rate: 1.953125e-05\n",
      "Epoch [11467/20000], Loss: 886.99560546875, Entropy 470.6402282714844, Learning Rate: 1.953125e-05\n",
      "Epoch [11468/20000], Loss: 864.4263305664062, Entropy 463.10772705078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11469/20000], Loss: 841.4189453125, Entropy 472.3407287597656, Learning Rate: 1.953125e-05\n",
      "Epoch [11470/20000], Loss: 861.904296875, Entropy 470.8385009765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11471/20000], Loss: 860.54052734375, Entropy 464.7335510253906, Learning Rate: 1.953125e-05\n",
      "Epoch [11472/20000], Loss: 885.3406982421875, Entropy 468.2354431152344, Learning Rate: 1.953125e-05\n",
      "Epoch [11473/20000], Loss: 818.3380126953125, Entropy 485.1947937011719, Learning Rate: 1.953125e-05\n",
      "Epoch [11474/20000], Loss: 845.6781005859375, Entropy 472.5967102050781, Learning Rate: 1.953125e-05\n",
      "Epoch [11475/20000], Loss: 864.2323608398438, Entropy 450.49664306640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11476/20000], Loss: 825.8421020507812, Entropy 476.98443603515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11477/20000], Loss: 851.051025390625, Entropy 479.060546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11478/20000], Loss: 850.8287353515625, Entropy 474.8403015136719, Learning Rate: 1.953125e-05\n",
      "Epoch [11479/20000], Loss: 858.17724609375, Entropy 475.6654968261719, Learning Rate: 1.953125e-05\n",
      "Epoch [11480/20000], Loss: 847.9072875976562, Entropy 470.93084716796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11481/20000], Loss: 895.5599975585938, Entropy 465.79998779296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11482/20000], Loss: 875.7315063476562, Entropy 473.22686767578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11483/20000], Loss: 876.672607421875, Entropy 464.4145202636719, Learning Rate: 1.953125e-05\n",
      "Epoch [11484/20000], Loss: 837.548095703125, Entropy 477.2662353515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11485/20000], Loss: 831.9503784179688, Entropy 480.11273193359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11486/20000], Loss: 822.6285400390625, Entropy 474.9285888671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11487/20000], Loss: 839.664794921875, Entropy 470.333740234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11488/20000], Loss: 880.849853515625, Entropy 464.3629455566406, Learning Rate: 1.953125e-05\n",
      "Epoch [11489/20000], Loss: 800.3319091796875, Entropy 478.748046875, Learning Rate: 1.953125e-05\n",
      "Epoch [11490/20000], Loss: 820.3714599609375, Entropy 469.6387023925781, Learning Rate: 1.953125e-05\n",
      "Epoch [11491/20000], Loss: 865.9575805664062, Entropy 461.90155029296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11492/20000], Loss: 820.825439453125, Entropy 465.5300598144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11493/20000], Loss: 802.8960571289062, Entropy 481.98004150390625, Learning Rate: 1.953125e-05\n",
      "Epoch [11494/20000], Loss: 868.3822631835938, Entropy 471.86627197265625, Learning Rate: 1.953125e-05\n",
      "Epoch [11495/20000], Loss: 833.4019775390625, Entropy 476.5088806152344, Learning Rate: 1.953125e-05\n",
      "Epoch [11496/20000], Loss: 876.1953125, Entropy 473.2880859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11497/20000], Loss: 819.0826416015625, Entropy 474.4256896972656, Learning Rate: 1.953125e-05\n",
      "Epoch [11498/20000], Loss: 850.6412353515625, Entropy 473.0144348144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11499/20000], Loss: 849.8521728515625, Entropy 479.4940490722656, Learning Rate: 1.953125e-05\n",
      "Epoch [11500/20000], Loss: 866.3277587890625, Entropy 471.9781188964844, Learning Rate: 1.953125e-05\n",
      "Epoch [11501/20000], Loss: 845.3416748046875, Entropy 467.00341796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11502/20000], Loss: 844.6889038085938, Entropy 458.51568603515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11503/20000], Loss: 861.9265747070312, Entropy 459.77593994140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11504/20000], Loss: 842.8359375, Entropy 478.7858581542969, Learning Rate: 1.953125e-05\n",
      "Epoch [11505/20000], Loss: 864.5863037109375, Entropy 470.5470886230469, Learning Rate: 1.953125e-05\n",
      "Epoch [11506/20000], Loss: 873.93994140625, Entropy 466.5724792480469, Learning Rate: 1.953125e-05\n",
      "Epoch [11507/20000], Loss: 836.0450439453125, Entropy 481.8542785644531, Learning Rate: 1.953125e-05\n",
      "Epoch [11508/20000], Loss: 893.1323852539062, Entropy 466.03643798828125, Learning Rate: 1.953125e-05\n",
      "Epoch [11509/20000], Loss: 819.0986328125, Entropy 474.3154296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11510/20000], Loss: 905.1575927734375, Entropy 463.7186584472656, Learning Rate: 1.953125e-05\n",
      "Epoch [11511/20000], Loss: 858.4605102539062, Entropy 477.51971435546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11512/20000], Loss: 866.730224609375, Entropy 469.4366149902344, Learning Rate: 1.953125e-05\n",
      "Epoch [11513/20000], Loss: 865.789306640625, Entropy 464.0147705078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11514/20000], Loss: 865.2911376953125, Entropy 455.9593505859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11515/20000], Loss: 863.0821533203125, Entropy 461.5168762207031, Learning Rate: 1.953125e-05\n",
      "Epoch [11516/20000], Loss: 834.4691162109375, Entropy 467.9761657714844, Learning Rate: 1.953125e-05\n",
      "Epoch [11517/20000], Loss: 839.8268432617188, Entropy 461.48138427734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11518/20000], Loss: 845.475830078125, Entropy 455.1709289550781, Learning Rate: 1.953125e-05\n",
      "Epoch [11519/20000], Loss: 862.1644287109375, Entropy 475.1793518066406, Learning Rate: 1.953125e-05\n",
      "Epoch [11520/20000], Loss: 870.1488037109375, Entropy 455.6922912597656, Learning Rate: 1.953125e-05\n",
      "Epoch [11521/20000], Loss: 822.450439453125, Entropy 464.9566345214844, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11522/20000], Loss: 843.76220703125, Entropy 480.5539245605469, Learning Rate: 1.953125e-05\n",
      "Epoch [11523/20000], Loss: 881.048583984375, Entropy 467.4398193359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11524/20000], Loss: 834.8866577148438, Entropy 471.59307861328125, Learning Rate: 1.953125e-05\n",
      "Epoch [11525/20000], Loss: 860.4617919921875, Entropy 475.9438171386719, Learning Rate: 1.953125e-05\n",
      "Epoch [11526/20000], Loss: 849.7257080078125, Entropy 472.4199523925781, Learning Rate: 1.953125e-05\n",
      "Epoch [11527/20000], Loss: 818.4059448242188, Entropy 468.04327392578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11528/20000], Loss: 857.0113525390625, Entropy 481.5938415527344, Learning Rate: 1.953125e-05\n",
      "Epoch [11529/20000], Loss: 869.3099975585938, Entropy 468.17498779296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11530/20000], Loss: 866.5489501953125, Entropy 465.8606872558594, Learning Rate: 1.953125e-05\n",
      "Epoch [11531/20000], Loss: 803.333984375, Entropy 477.5535888671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11532/20000], Loss: 849.1527099609375, Entropy 468.9887390136719, Learning Rate: 1.953125e-05\n",
      "Epoch [11533/20000], Loss: 845.9757080078125, Entropy 476.7736511230469, Learning Rate: 1.953125e-05\n",
      "Epoch [11534/20000], Loss: 875.2880859375, Entropy 475.9608154296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11535/20000], Loss: 859.902587890625, Entropy 466.7120056152344, Learning Rate: 1.953125e-05\n",
      "Epoch [11536/20000], Loss: 889.9923095703125, Entropy 463.4178161621094, Learning Rate: 1.953125e-05\n",
      "Epoch [11537/20000], Loss: 840.0406494140625, Entropy 476.0437927246094, Learning Rate: 1.953125e-05\n",
      "Epoch [11538/20000], Loss: 849.4749755859375, Entropy 475.6668701171875, Learning Rate: 1.953125e-05\n",
      "Epoch [11539/20000], Loss: 870.40380859375, Entropy 469.8355407714844, Learning Rate: 1.953125e-05\n",
      "Epoch [11540/20000], Loss: 846.746826171875, Entropy 468.8778381347656, Learning Rate: 1.953125e-05\n",
      "Epoch [11541/20000], Loss: 869.7413330078125, Entropy 468.2566223144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11542/20000], Loss: 898.1099853515625, Entropy 457.2574768066406, Learning Rate: 1.953125e-05\n",
      "Epoch [11543/20000], Loss: 866.8941040039062, Entropy 452.03631591796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11544/20000], Loss: 868.4281005859375, Entropy 472.4541015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11545/20000], Loss: 864.3056640625, Entropy 468.2395935058594, Learning Rate: 1.953125e-05\n",
      "Epoch [11546/20000], Loss: 879.8533325195312, Entropy 465.16558837890625, Learning Rate: 1.953125e-05\n",
      "Epoch [11547/20000], Loss: 815.6240844726562, Entropy 476.23077392578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11548/20000], Loss: 878.68017578125, Entropy 462.3367004394531, Learning Rate: 1.953125e-05\n",
      "Epoch [11549/20000], Loss: 881.6180419921875, Entropy 470.1441345214844, Learning Rate: 1.953125e-05\n",
      "Epoch [11550/20000], Loss: 825.921875, Entropy 484.1627197265625, Learning Rate: 1.953125e-05\n",
      "Epoch [11551/20000], Loss: 864.385498046875, Entropy 466.7297668457031, Learning Rate: 1.953125e-05\n",
      "Epoch [11552/20000], Loss: 804.5164184570312, Entropy 478.27935791015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11553/20000], Loss: 841.4296875, Entropy 473.8572692871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11554/20000], Loss: 838.5670776367188, Entropy 484.04425048828125, Learning Rate: 1.953125e-05\n",
      "Epoch [11555/20000], Loss: 905.1482543945312, Entropy 459.30487060546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11556/20000], Loss: 866.7035522460938, Entropy 471.51202392578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11557/20000], Loss: 831.9112548828125, Entropy 486.7165222167969, Learning Rate: 1.953125e-05\n",
      "Epoch [11558/20000], Loss: 846.2672729492188, Entropy 459.74224853515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11559/20000], Loss: 903.48974609375, Entropy 469.9568786621094, Learning Rate: 1.953125e-05\n",
      "Epoch [11560/20000], Loss: 815.92919921875, Entropy 471.7334289550781, Learning Rate: 1.953125e-05\n",
      "Epoch [11561/20000], Loss: 813.9595947265625, Entropy 471.8822021484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11562/20000], Loss: 860.4315185546875, Entropy 459.4725646972656, Learning Rate: 1.953125e-05\n",
      "Epoch [11563/20000], Loss: 841.264892578125, Entropy 475.1609191894531, Learning Rate: 1.953125e-05\n",
      "Epoch [11564/20000], Loss: 791.504150390625, Entropy 467.0031433105469, Learning Rate: 1.953125e-05\n",
      "Epoch [11565/20000], Loss: 893.5496215820312, Entropy 466.55133056640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11566/20000], Loss: 829.2407836914062, Entropy 466.70123291015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11567/20000], Loss: 808.1734619140625, Entropy 470.8735046386719, Learning Rate: 1.953125e-05\n",
      "Epoch [11568/20000], Loss: 859.1099853515625, Entropy 464.9108581542969, Learning Rate: 1.953125e-05\n",
      "Epoch [11569/20000], Loss: 830.46533203125, Entropy 477.2111511230469, Learning Rate: 1.953125e-05\n",
      "Epoch [11570/20000], Loss: 846.5175170898438, Entropy 471.12750244140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11571/20000], Loss: 821.538818359375, Entropy 486.2499084472656, Learning Rate: 1.953125e-05\n",
      "Epoch [11572/20000], Loss: 810.0325927734375, Entropy 471.1912536621094, Learning Rate: 1.953125e-05\n",
      "Epoch [11573/20000], Loss: 835.1439208984375, Entropy 468.5353698730469, Learning Rate: 1.953125e-05\n",
      "Epoch [11574/20000], Loss: 864.6925048828125, Entropy 471.4801940917969, Learning Rate: 1.953125e-05\n",
      "Epoch [11575/20000], Loss: 850.1636962890625, Entropy 471.15966796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11576/20000], Loss: 854.2112426757812, Entropy 473.21185302734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11577/20000], Loss: 810.2789306640625, Entropy 473.7698059082031, Learning Rate: 1.953125e-05\n",
      "Epoch [11578/20000], Loss: 863.5789794921875, Entropy 479.0202941894531, Learning Rate: 1.953125e-05\n",
      "Epoch [11579/20000], Loss: 887.40576171875, Entropy 476.9901428222656, Learning Rate: 1.953125e-05\n",
      "Epoch [11580/20000], Loss: 826.3228759765625, Entropy 473.5691223144531, Learning Rate: 1.953125e-05\n",
      "Epoch [11581/20000], Loss: 872.791259765625, Entropy 465.0164794921875, Learning Rate: 1.953125e-05\n",
      "Epoch [11582/20000], Loss: 853.38720703125, Entropy 468.95458984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11583/20000], Loss: 859.6719970703125, Entropy 477.2542724609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11584/20000], Loss: 851.4600219726562, Entropy 476.80621337890625, Learning Rate: 1.953125e-05\n",
      "Epoch [11585/20000], Loss: 809.216064453125, Entropy 462.1502380371094, Learning Rate: 1.953125e-05\n",
      "Epoch [11586/20000], Loss: 821.1331787109375, Entropy 480.3260498046875, Learning Rate: 1.953125e-05\n",
      "Epoch [11587/20000], Loss: 858.2298583984375, Entropy 484.1619567871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11588/20000], Loss: 803.520751953125, Entropy 473.0690612792969, Learning Rate: 1.953125e-05\n",
      "Epoch [11589/20000], Loss: 887.2208251953125, Entropy 463.8721008300781, Learning Rate: 1.953125e-05\n",
      "Epoch [11590/20000], Loss: 850.286376953125, Entropy 478.9085693359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11591/20000], Loss: 872.7445068359375, Entropy 473.603271484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11592/20000], Loss: 784.2609252929688, Entropy 474.23638916015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11593/20000], Loss: 850.5584716796875, Entropy 460.822021484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11594/20000], Loss: 839.3477783203125, Entropy 481.5802917480469, Learning Rate: 1.953125e-05\n",
      "Epoch [11595/20000], Loss: 831.9400634765625, Entropy 469.0997619628906, Learning Rate: 1.953125e-05\n",
      "Epoch [11596/20000], Loss: 868.3358764648438, Entropy 460.01202392578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11597/20000], Loss: 863.6678466796875, Entropy 470.0986328125, Learning Rate: 1.953125e-05\n",
      "Epoch [11598/20000], Loss: 848.18017578125, Entropy 467.1346130371094, Learning Rate: 1.953125e-05\n",
      "Epoch [11599/20000], Loss: 849.384521484375, Entropy 472.641357421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11600/20000], Loss: 812.623779296875, Entropy 476.8751525878906, Learning Rate: 1.953125e-05\n",
      "Epoch [11601/20000], Loss: 858.1502685546875, Entropy 467.536865234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11602/20000], Loss: 897.3467407226562, Entropy 463.22882080078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11603/20000], Loss: 841.9742431640625, Entropy 462.1352233886719, Learning Rate: 1.953125e-05\n",
      "Epoch [11604/20000], Loss: 864.6079711914062, Entropy 463.75531005859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11605/20000], Loss: 848.5029296875, Entropy 469.6628112792969, Learning Rate: 1.953125e-05\n",
      "Epoch [11606/20000], Loss: 868.4227294921875, Entropy 474.578857421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11607/20000], Loss: 832.712646484375, Entropy 469.892333984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11608/20000], Loss: 855.2694091796875, Entropy 470.3005676269531, Learning Rate: 1.953125e-05\n",
      "Epoch [11609/20000], Loss: 849.230712890625, Entropy 446.0822448730469, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11610/20000], Loss: 847.4729614257812, Entropy 466.19622802734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11611/20000], Loss: 858.6405029296875, Entropy 471.5433349609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11612/20000], Loss: 845.968505859375, Entropy 472.8439636230469, Learning Rate: 1.953125e-05\n",
      "Epoch [11613/20000], Loss: 803.03662109375, Entropy 473.3556213378906, Learning Rate: 1.953125e-05\n",
      "Epoch [11614/20000], Loss: 882.338623046875, Entropy 462.931396484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11615/20000], Loss: 799.2715454101562, Entropy 479.25128173828125, Learning Rate: 1.953125e-05\n",
      "Epoch [11616/20000], Loss: 888.3740234375, Entropy 462.7578125, Learning Rate: 1.953125e-05\n",
      "Epoch [11617/20000], Loss: 850.69775390625, Entropy 473.35888671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11618/20000], Loss: 857.5872802734375, Entropy 475.572265625, Learning Rate: 1.953125e-05\n",
      "Epoch [11619/20000], Loss: 862.9984741210938, Entropy 465.73834228515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11620/20000], Loss: 843.7027587890625, Entropy 474.1768493652344, Learning Rate: 1.953125e-05\n",
      "Epoch [11621/20000], Loss: 817.801025390625, Entropy 482.3307189941406, Learning Rate: 1.953125e-05\n",
      "Epoch [11622/20000], Loss: 806.0802001953125, Entropy 475.5224609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11623/20000], Loss: 843.822998046875, Entropy 473.0193176269531, Learning Rate: 1.953125e-05\n",
      "Epoch [11624/20000], Loss: 835.3731689453125, Entropy 474.1209411621094, Learning Rate: 1.953125e-05\n",
      "Epoch [11625/20000], Loss: 871.9129638671875, Entropy 477.619140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11626/20000], Loss: 830.3238525390625, Entropy 472.5075988769531, Learning Rate: 1.953125e-05\n",
      "Epoch [11627/20000], Loss: 825.3016357421875, Entropy 460.8563232421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11628/20000], Loss: 864.8145751953125, Entropy 470.4666442871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11629/20000], Loss: 860.1705932617188, Entropy 468.57733154296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11630/20000], Loss: 835.024658203125, Entropy 474.1471862792969, Learning Rate: 1.953125e-05\n",
      "Epoch [11631/20000], Loss: 854.228271484375, Entropy 479.2377624511719, Learning Rate: 1.953125e-05\n",
      "Epoch [11632/20000], Loss: 848.9923095703125, Entropy 476.3341979980469, Learning Rate: 1.953125e-05\n",
      "Epoch [11633/20000], Loss: 832.2102661132812, Entropy 476.66461181640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11634/20000], Loss: 880.600830078125, Entropy 461.1853942871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11635/20000], Loss: 846.6888427734375, Entropy 459.3819885253906, Learning Rate: 1.953125e-05\n",
      "Epoch [11636/20000], Loss: 835.049560546875, Entropy 485.8753662109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11637/20000], Loss: 906.116943359375, Entropy 475.7923583984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11638/20000], Loss: 824.3997802734375, Entropy 469.8596496582031, Learning Rate: 1.953125e-05\n",
      "Epoch [11639/20000], Loss: 861.9888916015625, Entropy 481.4535827636719, Learning Rate: 1.953125e-05\n",
      "Epoch [11640/20000], Loss: 884.5545043945312, Entropy 467.96295166015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11641/20000], Loss: 845.58349609375, Entropy 474.7705078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11642/20000], Loss: 866.2814331054688, Entropy 465.66107177734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11643/20000], Loss: 880.7237548828125, Entropy 476.91650390625, Learning Rate: 1.953125e-05\n",
      "Epoch [11644/20000], Loss: 857.6187744140625, Entropy 475.390380859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11645/20000], Loss: 850.604248046875, Entropy 471.0397644042969, Learning Rate: 1.953125e-05\n",
      "Epoch [11646/20000], Loss: 875.7825317382812, Entropy 468.99749755859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11647/20000], Loss: 824.2274169921875, Entropy 472.369140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11648/20000], Loss: 871.8984375, Entropy 462.951171875, Learning Rate: 1.953125e-05\n",
      "Epoch [11649/20000], Loss: 905.9473876953125, Entropy 460.4978942871094, Learning Rate: 1.953125e-05\n",
      "Epoch [11650/20000], Loss: 893.7015380859375, Entropy 454.79296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11651/20000], Loss: 852.0426025390625, Entropy 480.3853454589844, Learning Rate: 1.953125e-05\n",
      "Epoch [11652/20000], Loss: 839.0267333984375, Entropy 466.4068603515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11653/20000], Loss: 859.8406982421875, Entropy 481.4513854980469, Learning Rate: 1.953125e-05\n",
      "Epoch [11654/20000], Loss: 832.2992553710938, Entropy 473.80780029296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11655/20000], Loss: 857.0791015625, Entropy 477.2983093261719, Learning Rate: 1.953125e-05\n",
      "Epoch [11656/20000], Loss: 846.1168212890625, Entropy 475.9624938964844, Learning Rate: 1.953125e-05\n",
      "Epoch [11657/20000], Loss: 837.7470703125, Entropy 465.0269470214844, Learning Rate: 1.953125e-05\n",
      "Epoch [11658/20000], Loss: 819.6121215820312, Entropy 454.30133056640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11659/20000], Loss: 852.6280517578125, Entropy 466.5494384765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11660/20000], Loss: 891.0337524414062, Entropy 471.90740966796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11661/20000], Loss: 856.2603759765625, Entropy 465.6023254394531, Learning Rate: 1.953125e-05\n",
      "Epoch [11662/20000], Loss: 820.9205322265625, Entropy 477.7424011230469, Learning Rate: 1.953125e-05\n",
      "Epoch [11663/20000], Loss: 863.9146728515625, Entropy 477.6174621582031, Learning Rate: 1.953125e-05\n",
      "Epoch [11664/20000], Loss: 824.8060913085938, Entropy 480.06109619140625, Learning Rate: 1.953125e-05\n",
      "Epoch [11665/20000], Loss: 823.5206298828125, Entropy 460.3289794921875, Learning Rate: 1.953125e-05\n",
      "Epoch [11666/20000], Loss: 856.2156982421875, Entropy 460.4327697753906, Learning Rate: 1.953125e-05\n",
      "Epoch [11667/20000], Loss: 868.6531372070312, Entropy 462.84967041015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11668/20000], Loss: 900.7408447265625, Entropy 459.1649169921875, Learning Rate: 1.953125e-05\n",
      "Epoch [11669/20000], Loss: 869.5057373046875, Entropy 471.6326599121094, Learning Rate: 1.953125e-05\n",
      "Epoch [11670/20000], Loss: 879.73486328125, Entropy 461.4129638671875, Learning Rate: 1.953125e-05\n",
      "Epoch [11671/20000], Loss: 901.2926025390625, Entropy 461.2235107421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11672/20000], Loss: 866.16259765625, Entropy 468.1952209472656, Learning Rate: 1.953125e-05\n",
      "Epoch [11673/20000], Loss: 850.750732421875, Entropy 473.8111267089844, Learning Rate: 1.953125e-05\n",
      "Epoch [11674/20000], Loss: 828.1322021484375, Entropy 483.7115478515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11675/20000], Loss: 892.46826171875, Entropy 459.9006652832031, Learning Rate: 1.953125e-05\n",
      "Epoch [11676/20000], Loss: 865.7918701171875, Entropy 472.3392028808594, Learning Rate: 1.953125e-05\n",
      "Epoch [11677/20000], Loss: 898.6695556640625, Entropy 474.2258605957031, Learning Rate: 1.953125e-05\n",
      "Epoch [11678/20000], Loss: 889.2843017578125, Entropy 466.9700927734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11679/20000], Loss: 845.9716796875, Entropy 467.9291687011719, Learning Rate: 1.953125e-05\n",
      "Epoch [11680/20000], Loss: 830.1029052734375, Entropy 469.109130859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11681/20000], Loss: 889.4743041992188, Entropy 476.14068603515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11682/20000], Loss: 795.51416015625, Entropy 492.6492919921875, Learning Rate: 1.953125e-05\n",
      "Epoch [11683/20000], Loss: 836.6650390625, Entropy 460.9744873046875, Learning Rate: 1.953125e-05\n",
      "Epoch [11684/20000], Loss: 850.087158203125, Entropy 468.6856994628906, Learning Rate: 1.953125e-05\n",
      "Epoch [11685/20000], Loss: 870.9610595703125, Entropy 472.4284362792969, Learning Rate: 1.953125e-05\n",
      "Epoch [11686/20000], Loss: 829.3822021484375, Entropy 464.7126770019531, Learning Rate: 1.953125e-05\n",
      "Epoch [11687/20000], Loss: 875.6292724609375, Entropy 459.107421875, Learning Rate: 1.953125e-05\n",
      "Epoch [11688/20000], Loss: 821.68994140625, Entropy 472.3309631347656, Learning Rate: 1.953125e-05\n",
      "Epoch [11689/20000], Loss: 843.4800415039062, Entropy 468.98333740234375, Learning Rate: 1.953125e-05\n",
      "Epoch [11690/20000], Loss: 838.4644775390625, Entropy 465.5028076171875, Learning Rate: 1.953125e-05\n",
      "Epoch [11691/20000], Loss: 879.6773071289062, Entropy 466.60198974609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11692/20000], Loss: 844.5505981445312, Entropy 475.72845458984375, Learning Rate: 1.953125e-05\n",
      "Epoch [11693/20000], Loss: 880.6351928710938, Entropy 473.04693603515625, Learning Rate: 1.953125e-05\n",
      "Epoch [11694/20000], Loss: 838.9961547851562, Entropy 451.39166259765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11695/20000], Loss: 867.61767578125, Entropy 489.7332458496094, Learning Rate: 1.953125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11696/20000], Loss: 864.470458984375, Entropy 460.6014099121094, Learning Rate: 1.953125e-05\n",
      "Epoch [11697/20000], Loss: 920.772216796875, Entropy 448.4524230957031, Learning Rate: 1.953125e-05\n",
      "Epoch [11698/20000], Loss: 896.0253295898438, Entropy 462.90850830078125, Learning Rate: 1.953125e-05\n",
      "Epoch [11699/20000], Loss: 832.07666015625, Entropy 459.4420166015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11700/20000], Loss: 877.3679809570312, Entropy 459.02789306640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11701/20000], Loss: 844.240234375, Entropy 459.6422424316406, Learning Rate: 1.953125e-05\n",
      "Epoch [11702/20000], Loss: 890.96142578125, Entropy 455.461669921875, Learning Rate: 1.953125e-05\n",
      "Epoch [11703/20000], Loss: 856.6253662109375, Entropy 459.0810546875, Learning Rate: 1.953125e-05\n",
      "Epoch [11704/20000], Loss: 862.462646484375, Entropy 468.6278076171875, Learning Rate: 1.953125e-05\n",
      "Epoch [11705/20000], Loss: 849.8663940429688, Entropy 477.92633056640625, Learning Rate: 1.953125e-05\n",
      "Epoch [11706/20000], Loss: 828.84375, Entropy 463.8210754394531, Learning Rate: 1.953125e-05\n",
      "Epoch [11707/20000], Loss: 803.1514892578125, Entropy 486.0491943359375, Learning Rate: 1.953125e-05\n",
      "Epoch [11708/20000], Loss: 913.7398681640625, Entropy 464.5604248046875, Learning Rate: 1.953125e-05\n",
      "Epoch [11709/20000], Loss: 882.4971923828125, Entropy 454.2379150390625, Learning Rate: 1.953125e-05\n",
      "Epoch [11710/20000], Loss: 882.726318359375, Entropy 461.7950439453125, Learning Rate: 1.953125e-05\n",
      "Epoch [11711/20000], Loss: 848.6326904296875, Entropy 481.4100341796875, Learning Rate: 1.953125e-05\n",
      "Epoch [11712/20000], Loss: 831.322509765625, Entropy 482.87646484375, Learning Rate: 1.953125e-05\n",
      "Epoch [11713/20000], Loss: 848.4658203125, Entropy 465.5826721191406, Learning Rate: 1.953125e-05\n",
      "Epoch [11714/20000], Loss: 873.4608154296875, Entropy 483.0522155761719, Learning Rate: 1.953125e-05\n",
      "Epoch [11715/20000], Loss: 876.200439453125, Entropy 474.7356262207031, Learning Rate: 1.953125e-05\n",
      "Epoch [11716/20000], Loss: 852.8407592773438, Entropy 478.80609130859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11717/20000], Loss: 859.6001586914062, Entropy 471.63482666015625, Learning Rate: 1.953125e-05\n",
      "Epoch [11718/20000], Loss: 855.63818359375, Entropy 483.19677734375, Learning Rate: 1.953125e-05\n",
      "Epoch [11719/20000], Loss: 834.4356079101562, Entropy 471.47796630859375, Learning Rate: 1.953125e-05\n",
      "Epoch [11720/20000], Loss: 830.1058349609375, Entropy 469.6014099121094, Learning Rate: 1.953125e-05\n",
      "Epoch [11721/20000], Loss: 839.1253051757812, Entropy 464.49139404296875, Learning Rate: 1.953125e-05\n",
      "Epoch [11722/20000], Loss: 862.736083984375, Entropy 467.8849792480469, Learning Rate: 1.953125e-05\n",
      "Epoch [11723/20000], Loss: 817.5508422851562, Entropy 471.39556884765625, Learning Rate: 1.953125e-05\n",
      "Epoch [11724/20000], Loss: 855.06103515625, Entropy 471.8683776855469, Learning Rate: 1.953125e-05\n",
      "Epoch [11725/20000], Loss: 860.24853515625, Entropy 470.1946105957031, Learning Rate: 1.953125e-05\n",
      "Epoch [11726/20000], Loss: 812.873046875, Entropy 473.5827331542969, Learning Rate: 1.953125e-05\n",
      "Epoch [11727/20000], Loss: 857.7908935546875, Entropy 459.1527099609375, Learning Rate: 1.953125e-05\n",
      "Epoch [11728/20000], Loss: 806.003173828125, Entropy 462.8502502441406, Learning Rate: 1.953125e-05\n",
      "Epoch [11729/20000], Loss: 860.5745849609375, Entropy 471.5159912109375, Learning Rate: 1.953125e-05\n",
      "Epoch [11730/20000], Loss: 822.1661376953125, Entropy 477.0686950683594, Learning Rate: 1.953125e-05\n",
      "Epoch [11731/20000], Loss: 912.555419921875, Entropy 460.1640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11732/20000], Loss: 795.4117431640625, Entropy 480.0419006347656, Learning Rate: 9.765625e-06\n",
      "Epoch [11733/20000], Loss: 859.3677978515625, Entropy 473.0043640136719, Learning Rate: 9.765625e-06\n",
      "Epoch [11734/20000], Loss: 866.6095581054688, Entropy 459.15130615234375, Learning Rate: 9.765625e-06\n",
      "Epoch [11735/20000], Loss: 920.42236328125, Entropy 472.6486511230469, Learning Rate: 9.765625e-06\n",
      "Epoch [11736/20000], Loss: 848.0240478515625, Entropy 461.2059326171875, Learning Rate: 9.765625e-06\n",
      "Epoch [11737/20000], Loss: 857.6539306640625, Entropy 468.0865478515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11738/20000], Loss: 842.6936645507812, Entropy 468.86773681640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11739/20000], Loss: 803.141357421875, Entropy 473.3528747558594, Learning Rate: 9.765625e-06\n",
      "Epoch [11740/20000], Loss: 854.528564453125, Entropy 482.8612365722656, Learning Rate: 9.765625e-06\n",
      "Epoch [11741/20000], Loss: 837.3294677734375, Entropy 473.9888610839844, Learning Rate: 9.765625e-06\n",
      "Epoch [11742/20000], Loss: 811.787841796875, Entropy 478.1409912109375, Learning Rate: 9.765625e-06\n",
      "Epoch [11743/20000], Loss: 822.30078125, Entropy 472.1949768066406, Learning Rate: 9.765625e-06\n",
      "Epoch [11744/20000], Loss: 799.760498046875, Entropy 477.6796875, Learning Rate: 9.765625e-06\n",
      "Epoch [11745/20000], Loss: 862.3590087890625, Entropy 468.7315368652344, Learning Rate: 9.765625e-06\n",
      "Epoch [11746/20000], Loss: 826.568359375, Entropy 468.2606201171875, Learning Rate: 9.765625e-06\n",
      "Epoch [11747/20000], Loss: 827.185546875, Entropy 473.1807556152344, Learning Rate: 9.765625e-06\n",
      "Epoch [11748/20000], Loss: 874.0469970703125, Entropy 471.7627868652344, Learning Rate: 9.765625e-06\n",
      "Epoch [11749/20000], Loss: 838.573974609375, Entropy 481.7637023925781, Learning Rate: 9.765625e-06\n",
      "Epoch [11750/20000], Loss: 860.359130859375, Entropy 466.6840515136719, Learning Rate: 9.765625e-06\n",
      "Epoch [11751/20000], Loss: 855.1171875, Entropy 470.7490539550781, Learning Rate: 9.765625e-06\n",
      "Epoch [11752/20000], Loss: 857.6578979492188, Entropy 468.85992431640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11753/20000], Loss: 846.0066528320312, Entropy 466.21734619140625, Learning Rate: 9.765625e-06\n",
      "Epoch [11754/20000], Loss: 835.410888671875, Entropy 466.0027160644531, Learning Rate: 9.765625e-06\n",
      "Epoch [11755/20000], Loss: 841.637451171875, Entropy 470.6053161621094, Learning Rate: 9.765625e-06\n",
      "Epoch [11756/20000], Loss: 868.049072265625, Entropy 462.4283752441406, Learning Rate: 9.765625e-06\n",
      "Epoch [11757/20000], Loss: 816.4122314453125, Entropy 485.0489196777344, Learning Rate: 9.765625e-06\n",
      "Epoch [11758/20000], Loss: 830.6851806640625, Entropy 468.53857421875, Learning Rate: 9.765625e-06\n",
      "Epoch [11759/20000], Loss: 889.5612182617188, Entropy 470.81280517578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11760/20000], Loss: 829.951416015625, Entropy 484.7384948730469, Learning Rate: 9.765625e-06\n",
      "Epoch [11761/20000], Loss: 839.015380859375, Entropy 472.7381286621094, Learning Rate: 9.765625e-06\n",
      "Epoch [11762/20000], Loss: 883.9647216796875, Entropy 469.7340393066406, Learning Rate: 9.765625e-06\n",
      "Epoch [11763/20000], Loss: 876.7828369140625, Entropy 462.0006103515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11764/20000], Loss: 833.4712524414062, Entropy 470.38018798828125, Learning Rate: 9.765625e-06\n",
      "Epoch [11765/20000], Loss: 826.3945922851562, Entropy 462.93878173828125, Learning Rate: 9.765625e-06\n",
      "Epoch [11766/20000], Loss: 828.3118896484375, Entropy 462.8663330078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11767/20000], Loss: 833.18994140625, Entropy 477.7019348144531, Learning Rate: 9.765625e-06\n",
      "Epoch [11768/20000], Loss: 884.7286987304688, Entropy 461.12835693359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11769/20000], Loss: 829.3564453125, Entropy 469.5494384765625, Learning Rate: 9.765625e-06\n",
      "Epoch [11770/20000], Loss: 841.6729736328125, Entropy 470.4510803222656, Learning Rate: 9.765625e-06\n",
      "Epoch [11771/20000], Loss: 856.348388671875, Entropy 476.1640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11772/20000], Loss: 792.1329956054688, Entropy 480.00921630859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11773/20000], Loss: 823.6163330078125, Entropy 460.5242004394531, Learning Rate: 9.765625e-06\n",
      "Epoch [11774/20000], Loss: 870.070068359375, Entropy 457.23193359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11775/20000], Loss: 813.709716796875, Entropy 458.70263671875, Learning Rate: 9.765625e-06\n",
      "Epoch [11776/20000], Loss: 820.838134765625, Entropy 471.8714294433594, Learning Rate: 9.765625e-06\n",
      "Epoch [11777/20000], Loss: 823.71435546875, Entropy 458.0210876464844, Learning Rate: 9.765625e-06\n",
      "Epoch [11778/20000], Loss: 822.6375122070312, Entropy 463.39459228515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11779/20000], Loss: 839.0369873046875, Entropy 459.6678466796875, Learning Rate: 9.765625e-06\n",
      "Epoch [11780/20000], Loss: 853.98046875, Entropy 485.068359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11781/20000], Loss: 885.96435546875, Entropy 464.966552734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11782/20000], Loss: 849.3934326171875, Entropy 470.18359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11783/20000], Loss: 850.5, Entropy 487.322021484375, Learning Rate: 9.765625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11784/20000], Loss: 848.1596069335938, Entropy 461.99163818359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11785/20000], Loss: 840.683837890625, Entropy 467.1924133300781, Learning Rate: 9.765625e-06\n",
      "Epoch [11786/20000], Loss: 833.0394287109375, Entropy 470.8288269042969, Learning Rate: 9.765625e-06\n",
      "Epoch [11787/20000], Loss: 867.0880126953125, Entropy 464.5105285644531, Learning Rate: 9.765625e-06\n",
      "Epoch [11788/20000], Loss: 855.5604248046875, Entropy 471.4083557128906, Learning Rate: 9.765625e-06\n",
      "Epoch [11789/20000], Loss: 849.11572265625, Entropy 474.30126953125, Learning Rate: 9.765625e-06\n",
      "Epoch [11790/20000], Loss: 908.3248291015625, Entropy 472.703857421875, Learning Rate: 9.765625e-06\n",
      "Epoch [11791/20000], Loss: 817.3193359375, Entropy 491.5531005859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11792/20000], Loss: 841.125, Entropy 474.9812316894531, Learning Rate: 9.765625e-06\n",
      "Epoch [11793/20000], Loss: 834.4280395507812, Entropy 476.10406494140625, Learning Rate: 9.765625e-06\n",
      "Epoch [11794/20000], Loss: 845.20068359375, Entropy 467.7448425292969, Learning Rate: 9.765625e-06\n",
      "Epoch [11795/20000], Loss: 857.8685302734375, Entropy 481.3567810058594, Learning Rate: 9.765625e-06\n",
      "Epoch [11796/20000], Loss: 875.50537109375, Entropy 456.8615417480469, Learning Rate: 9.765625e-06\n",
      "Epoch [11797/20000], Loss: 851.4692993164062, Entropy 461.63507080078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11798/20000], Loss: 832.7510986328125, Entropy 474.18408203125, Learning Rate: 9.765625e-06\n",
      "Epoch [11799/20000], Loss: 822.0768432617188, Entropy 485.45794677734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11800/20000], Loss: 877.1434326171875, Entropy 469.2711181640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11801/20000], Loss: 867.15478515625, Entropy 471.1813049316406, Learning Rate: 9.765625e-06\n",
      "Epoch [11802/20000], Loss: 834.7627563476562, Entropy 469.17193603515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11803/20000], Loss: 851.0825805664062, Entropy 473.00701904296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11804/20000], Loss: 806.7939453125, Entropy 463.1924133300781, Learning Rate: 9.765625e-06\n",
      "Epoch [11805/20000], Loss: 866.974853515625, Entropy 467.43505859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11806/20000], Loss: 835.2042236328125, Entropy 470.7860107421875, Learning Rate: 9.765625e-06\n",
      "Epoch [11807/20000], Loss: 858.066650390625, Entropy 462.3702392578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11808/20000], Loss: 838.6407470703125, Entropy 466.6726379394531, Learning Rate: 9.765625e-06\n",
      "Epoch [11809/20000], Loss: 841.2635498046875, Entropy 453.3481140136719, Learning Rate: 9.765625e-06\n",
      "Epoch [11810/20000], Loss: 841.9188842773438, Entropy 472.72845458984375, Learning Rate: 9.765625e-06\n",
      "Epoch [11811/20000], Loss: 919.3519287109375, Entropy 458.0749206542969, Learning Rate: 9.765625e-06\n",
      "Epoch [11812/20000], Loss: 853.0062866210938, Entropy 468.91998291015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11813/20000], Loss: 888.52490234375, Entropy 463.6949768066406, Learning Rate: 9.765625e-06\n",
      "Epoch [11814/20000], Loss: 860.8056030273438, Entropy 460.84185791015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11815/20000], Loss: 898.8212280273438, Entropy 462.21514892578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11816/20000], Loss: 857.243896484375, Entropy 469.2373352050781, Learning Rate: 9.765625e-06\n",
      "Epoch [11817/20000], Loss: 873.474853515625, Entropy 471.564453125, Learning Rate: 9.765625e-06\n",
      "Epoch [11818/20000], Loss: 834.5067138671875, Entropy 471.2220458984375, Learning Rate: 9.765625e-06\n",
      "Epoch [11819/20000], Loss: 861.1953735351562, Entropy 478.07647705078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11820/20000], Loss: 861.6224365234375, Entropy 459.7342224121094, Learning Rate: 9.765625e-06\n",
      "Epoch [11821/20000], Loss: 876.0848388671875, Entropy 460.2847900390625, Learning Rate: 9.765625e-06\n",
      "Epoch [11822/20000], Loss: 852.257568359375, Entropy 471.2839660644531, Learning Rate: 9.765625e-06\n",
      "Epoch [11823/20000], Loss: 821.6173095703125, Entropy 480.00341796875, Learning Rate: 9.765625e-06\n",
      "Epoch [11824/20000], Loss: 849.7554321289062, Entropy 464.76019287109375, Learning Rate: 9.765625e-06\n",
      "Epoch [11825/20000], Loss: 859.50146484375, Entropy 473.277099609375, Learning Rate: 9.765625e-06\n",
      "Epoch [11826/20000], Loss: 854.86083984375, Entropy 484.8395080566406, Learning Rate: 9.765625e-06\n",
      "Epoch [11827/20000], Loss: 874.0831909179688, Entropy 486.10552978515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11828/20000], Loss: 842.8035278320312, Entropy 479.75140380859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11829/20000], Loss: 866.6129150390625, Entropy 465.8330078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11830/20000], Loss: 845.7236328125, Entropy 467.6189270019531, Learning Rate: 9.765625e-06\n",
      "Epoch [11831/20000], Loss: 828.5328979492188, Entropy 467.13763427734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11832/20000], Loss: 845.6470947265625, Entropy 461.0399169921875, Learning Rate: 9.765625e-06\n",
      "Epoch [11833/20000], Loss: 816.412353515625, Entropy 470.0149230957031, Learning Rate: 9.765625e-06\n",
      "Epoch [11834/20000], Loss: 864.23779296875, Entropy 473.7198181152344, Learning Rate: 9.765625e-06\n",
      "Epoch [11835/20000], Loss: 804.9118041992188, Entropy 463.14361572265625, Learning Rate: 9.765625e-06\n",
      "Epoch [11836/20000], Loss: 827.85498046875, Entropy 482.8447570800781, Learning Rate: 9.765625e-06\n",
      "Epoch [11837/20000], Loss: 866.9544677734375, Entropy 452.2153015136719, Learning Rate: 9.765625e-06\n",
      "Epoch [11838/20000], Loss: 801.5824584960938, Entropy 483.68951416015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11839/20000], Loss: 849.166748046875, Entropy 470.4869384765625, Learning Rate: 9.765625e-06\n",
      "Epoch [11840/20000], Loss: 900.2474365234375, Entropy 462.1953430175781, Learning Rate: 9.765625e-06\n",
      "Epoch [11841/20000], Loss: 866.54638671875, Entropy 481.243896484375, Learning Rate: 9.765625e-06\n",
      "Epoch [11842/20000], Loss: 834.423828125, Entropy 483.6304931640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11843/20000], Loss: 864.8863525390625, Entropy 464.8502197265625, Learning Rate: 9.765625e-06\n",
      "Epoch [11844/20000], Loss: 857.583984375, Entropy 469.9412536621094, Learning Rate: 9.765625e-06\n",
      "Epoch [11845/20000], Loss: 853.7530517578125, Entropy 464.8650207519531, Learning Rate: 9.765625e-06\n",
      "Epoch [11846/20000], Loss: 844.1884765625, Entropy 467.1705017089844, Learning Rate: 9.765625e-06\n",
      "Epoch [11847/20000], Loss: 834.4109497070312, Entropy 468.36810302734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11848/20000], Loss: 884.6104125976562, Entropy 482.57733154296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11849/20000], Loss: 825.7164306640625, Entropy 468.6965637207031, Learning Rate: 9.765625e-06\n",
      "Epoch [11850/20000], Loss: 879.270751953125, Entropy 463.5292053222656, Learning Rate: 9.765625e-06\n",
      "Epoch [11851/20000], Loss: 819.3340454101562, Entropy 481.49029541015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11852/20000], Loss: 880.2327880859375, Entropy 460.76025390625, Learning Rate: 9.765625e-06\n",
      "Epoch [11853/20000], Loss: 797.34228515625, Entropy 483.95703125, Learning Rate: 9.765625e-06\n",
      "Epoch [11854/20000], Loss: 810.9849853515625, Entropy 473.3561706542969, Learning Rate: 9.765625e-06\n",
      "Epoch [11855/20000], Loss: 825.2636108398438, Entropy 462.10186767578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11856/20000], Loss: 883.4974365234375, Entropy 462.9693603515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11857/20000], Loss: 864.379150390625, Entropy 464.5501403808594, Learning Rate: 9.765625e-06\n",
      "Epoch [11858/20000], Loss: 788.2821044921875, Entropy 483.9856872558594, Learning Rate: 9.765625e-06\n",
      "Epoch [11859/20000], Loss: 851.1043701171875, Entropy 462.7655334472656, Learning Rate: 9.765625e-06\n",
      "Epoch [11860/20000], Loss: 864.2801513671875, Entropy 466.5407409667969, Learning Rate: 9.765625e-06\n",
      "Epoch [11861/20000], Loss: 862.077880859375, Entropy 458.21923828125, Learning Rate: 9.765625e-06\n",
      "Epoch [11862/20000], Loss: 885.6041259765625, Entropy 459.7802734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11863/20000], Loss: 851.6221923828125, Entropy 473.7618713378906, Learning Rate: 9.765625e-06\n",
      "Epoch [11864/20000], Loss: 877.1963500976562, Entropy 462.40960693359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11865/20000], Loss: 817.0232543945312, Entropy 482.29608154296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11866/20000], Loss: 869.849853515625, Entropy 466.3641357421875, Learning Rate: 9.765625e-06\n",
      "Epoch [11867/20000], Loss: 883.9410400390625, Entropy 471.9981384277344, Learning Rate: 9.765625e-06\n",
      "Epoch [11868/20000], Loss: 845.938232421875, Entropy 468.94873046875, Learning Rate: 9.765625e-06\n",
      "Epoch [11869/20000], Loss: 862.099853515625, Entropy 477.3051452636719, Learning Rate: 9.765625e-06\n",
      "Epoch [11870/20000], Loss: 833.686767578125, Entropy 472.5276184082031, Learning Rate: 9.765625e-06\n",
      "Epoch [11871/20000], Loss: 818.2362060546875, Entropy 473.00927734375, Learning Rate: 9.765625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11872/20000], Loss: 895.9072265625, Entropy 466.5240478515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11873/20000], Loss: 871.5842895507812, Entropy 465.97369384765625, Learning Rate: 9.765625e-06\n",
      "Epoch [11874/20000], Loss: 822.546875, Entropy 458.9581298828125, Learning Rate: 9.765625e-06\n",
      "Epoch [11875/20000], Loss: 889.1212158203125, Entropy 481.0285949707031, Learning Rate: 9.765625e-06\n",
      "Epoch [11876/20000], Loss: 854.271484375, Entropy 473.9474182128906, Learning Rate: 9.765625e-06\n",
      "Epoch [11877/20000], Loss: 819.1226806640625, Entropy 484.5129089355469, Learning Rate: 9.765625e-06\n",
      "Epoch [11878/20000], Loss: 843.0987548828125, Entropy 468.4259948730469, Learning Rate: 9.765625e-06\n",
      "Epoch [11879/20000], Loss: 854.3604125976562, Entropy 467.55426025390625, Learning Rate: 9.765625e-06\n",
      "Epoch [11880/20000], Loss: 829.8326416015625, Entropy 472.8907775878906, Learning Rate: 9.765625e-06\n",
      "Epoch [11881/20000], Loss: 855.8128662109375, Entropy 484.8161926269531, Learning Rate: 9.765625e-06\n",
      "Epoch [11882/20000], Loss: 816.98876953125, Entropy 488.0955810546875, Learning Rate: 9.765625e-06\n",
      "Epoch [11883/20000], Loss: 815.9136352539062, Entropy 480.38616943359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11884/20000], Loss: 843.75341796875, Entropy 456.0835876464844, Learning Rate: 9.765625e-06\n",
      "Epoch [11885/20000], Loss: 852.6712646484375, Entropy 479.845703125, Learning Rate: 9.765625e-06\n",
      "Epoch [11886/20000], Loss: 825.8485107421875, Entropy 467.0872802734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11887/20000], Loss: 828.2738647460938, Entropy 468.11859130859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11888/20000], Loss: 804.9658813476562, Entropy 469.93377685546875, Learning Rate: 9.765625e-06\n",
      "Epoch [11889/20000], Loss: 838.2334594726562, Entropy 479.30279541015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11890/20000], Loss: 867.867919921875, Entropy 478.103271484375, Learning Rate: 9.765625e-06\n",
      "Epoch [11891/20000], Loss: 800.2217407226562, Entropy 473.77764892578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11892/20000], Loss: 838.4625854492188, Entropy 471.12811279296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11893/20000], Loss: 855.3193359375, Entropy 475.9715270996094, Learning Rate: 9.765625e-06\n",
      "Epoch [11894/20000], Loss: 823.8049926757812, Entropy 482.66363525390625, Learning Rate: 9.765625e-06\n",
      "Epoch [11895/20000], Loss: 809.2706298828125, Entropy 470.2845153808594, Learning Rate: 9.765625e-06\n",
      "Epoch [11896/20000], Loss: 874.1995849609375, Entropy 473.7369079589844, Learning Rate: 9.765625e-06\n",
      "Epoch [11897/20000], Loss: 842.733642578125, Entropy 466.7124938964844, Learning Rate: 9.765625e-06\n",
      "Epoch [11898/20000], Loss: 807.544921875, Entropy 468.9832763671875, Learning Rate: 9.765625e-06\n",
      "Epoch [11899/20000], Loss: 840.1453247070312, Entropy 471.57513427734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11900/20000], Loss: 852.2943725585938, Entropy 470.95123291015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11901/20000], Loss: 860.0701904296875, Entropy 465.64404296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11902/20000], Loss: 789.1336669921875, Entropy 478.2565002441406, Learning Rate: 9.765625e-06\n",
      "Epoch [11903/20000], Loss: 869.686279296875, Entropy 481.30810546875, Learning Rate: 9.765625e-06\n",
      "Epoch [11904/20000], Loss: 882.5584716796875, Entropy 473.5877380371094, Learning Rate: 9.765625e-06\n",
      "Epoch [11905/20000], Loss: 857.9390869140625, Entropy 472.8897399902344, Learning Rate: 9.765625e-06\n",
      "Epoch [11906/20000], Loss: 900.1441650390625, Entropy 471.2069091796875, Learning Rate: 9.765625e-06\n",
      "Epoch [11907/20000], Loss: 838.503173828125, Entropy 465.0498046875, Learning Rate: 9.765625e-06\n",
      "Epoch [11908/20000], Loss: 846.4907836914062, Entropy 472.71685791015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11909/20000], Loss: 861.2227783203125, Entropy 470.3865661621094, Learning Rate: 9.765625e-06\n",
      "Epoch [11910/20000], Loss: 812.1214599609375, Entropy 484.495849609375, Learning Rate: 9.765625e-06\n",
      "Epoch [11911/20000], Loss: 917.8721923828125, Entropy 463.3038635253906, Learning Rate: 9.765625e-06\n",
      "Epoch [11912/20000], Loss: 832.1625366210938, Entropy 458.37640380859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11913/20000], Loss: 894.6724243164062, Entropy 468.57757568359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11914/20000], Loss: 874.930419921875, Entropy 465.921630859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11915/20000], Loss: 831.1846923828125, Entropy 487.909912109375, Learning Rate: 9.765625e-06\n",
      "Epoch [11916/20000], Loss: 851.106201171875, Entropy 462.1881103515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11917/20000], Loss: 848.8157348632812, Entropy 467.84918212890625, Learning Rate: 9.765625e-06\n",
      "Epoch [11918/20000], Loss: 881.5357055664062, Entropy 467.05889892578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11919/20000], Loss: 856.8416137695312, Entropy 466.48272705078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11920/20000], Loss: 831.6109619140625, Entropy 465.0086669921875, Learning Rate: 9.765625e-06\n",
      "Epoch [11921/20000], Loss: 849.1104736328125, Entropy 458.2457580566406, Learning Rate: 9.765625e-06\n",
      "Epoch [11922/20000], Loss: 805.958251953125, Entropy 466.5026550292969, Learning Rate: 9.765625e-06\n",
      "Epoch [11923/20000], Loss: 821.8494262695312, Entropy 460.13519287109375, Learning Rate: 9.765625e-06\n",
      "Epoch [11924/20000], Loss: 871.3322143554688, Entropy 476.61334228515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11925/20000], Loss: 814.4854736328125, Entropy 473.112060546875, Learning Rate: 9.765625e-06\n",
      "Epoch [11926/20000], Loss: 852.0228271484375, Entropy 468.027099609375, Learning Rate: 9.765625e-06\n",
      "Epoch [11927/20000], Loss: 857.0209350585938, Entropy 470.66937255859375, Learning Rate: 9.765625e-06\n",
      "Epoch [11928/20000], Loss: 851.7786254882812, Entropy 473.94622802734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11929/20000], Loss: 877.1069946289062, Entropy 470.81292724609375, Learning Rate: 9.765625e-06\n",
      "Epoch [11930/20000], Loss: 856.6336669921875, Entropy 467.2639465332031, Learning Rate: 9.765625e-06\n",
      "Epoch [11931/20000], Loss: 809.5303344726562, Entropy 469.86834716796875, Learning Rate: 9.765625e-06\n",
      "Epoch [11932/20000], Loss: 848.4765625, Entropy 474.181640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11933/20000], Loss: 863.0206298828125, Entropy 470.2309265136719, Learning Rate: 9.765625e-06\n",
      "Epoch [11934/20000], Loss: 856.863525390625, Entropy 477.455078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11935/20000], Loss: 823.2299194335938, Entropy 469.07061767578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11936/20000], Loss: 861.083984375, Entropy 482.4430236816406, Learning Rate: 9.765625e-06\n",
      "Epoch [11937/20000], Loss: 859.4612426757812, Entropy 471.96185302734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11938/20000], Loss: 812.1171875, Entropy 480.1924743652344, Learning Rate: 9.765625e-06\n",
      "Epoch [11939/20000], Loss: 942.87158203125, Entropy 444.9461975097656, Learning Rate: 9.765625e-06\n",
      "Epoch [11940/20000], Loss: 814.543212890625, Entropy 476.0670471191406, Learning Rate: 9.765625e-06\n",
      "Epoch [11941/20000], Loss: 833.3308715820312, Entropy 481.35113525390625, Learning Rate: 9.765625e-06\n",
      "Epoch [11942/20000], Loss: 857.9664306640625, Entropy 455.1302185058594, Learning Rate: 9.765625e-06\n",
      "Epoch [11943/20000], Loss: 863.7770385742188, Entropy 453.21575927734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11944/20000], Loss: 821.9061279296875, Entropy 479.4977722167969, Learning Rate: 9.765625e-06\n",
      "Epoch [11945/20000], Loss: 845.437255859375, Entropy 472.763671875, Learning Rate: 9.765625e-06\n",
      "Epoch [11946/20000], Loss: 863.3824462890625, Entropy 472.4897155761719, Learning Rate: 9.765625e-06\n",
      "Epoch [11947/20000], Loss: 827.328857421875, Entropy 463.7723388671875, Learning Rate: 9.765625e-06\n",
      "Epoch [11948/20000], Loss: 844.3770751953125, Entropy 469.9986572265625, Learning Rate: 9.765625e-06\n",
      "Epoch [11949/20000], Loss: 878.723388671875, Entropy 465.7633056640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11950/20000], Loss: 845.6931762695312, Entropy 455.47100830078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11951/20000], Loss: 858.86572265625, Entropy 467.9826354980469, Learning Rate: 9.765625e-06\n",
      "Epoch [11952/20000], Loss: 852.8179321289062, Entropy 469.32037353515625, Learning Rate: 9.765625e-06\n",
      "Epoch [11953/20000], Loss: 924.746337890625, Entropy 465.5852355957031, Learning Rate: 9.765625e-06\n",
      "Epoch [11954/20000], Loss: 838.249755859375, Entropy 462.6971740722656, Learning Rate: 9.765625e-06\n",
      "Epoch [11955/20000], Loss: 855.4591064453125, Entropy 472.4934997558594, Learning Rate: 9.765625e-06\n",
      "Epoch [11956/20000], Loss: 849.2163696289062, Entropy 473.05389404296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11957/20000], Loss: 885.2029418945312, Entropy 458.32342529296875, Learning Rate: 9.765625e-06\n",
      "Epoch [11958/20000], Loss: 871.96044921875, Entropy 464.0292053222656, Learning Rate: 9.765625e-06\n",
      "Epoch [11959/20000], Loss: 846.032958984375, Entropy 473.0286560058594, Learning Rate: 9.765625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11960/20000], Loss: 855.4200439453125, Entropy 463.1304931640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11961/20000], Loss: 822.4697265625, Entropy 458.32666015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11962/20000], Loss: 862.14208984375, Entropy 475.6634521484375, Learning Rate: 9.765625e-06\n",
      "Epoch [11963/20000], Loss: 859.6064453125, Entropy 465.203857421875, Learning Rate: 9.765625e-06\n",
      "Epoch [11964/20000], Loss: 856.5030517578125, Entropy 460.6605224609375, Learning Rate: 9.765625e-06\n",
      "Epoch [11965/20000], Loss: 876.0350341796875, Entropy 464.5793151855469, Learning Rate: 9.765625e-06\n",
      "Epoch [11966/20000], Loss: 809.9046630859375, Entropy 459.4107666015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11967/20000], Loss: 846.1632690429688, Entropy 467.56988525390625, Learning Rate: 9.765625e-06\n",
      "Epoch [11968/20000], Loss: 837.9649658203125, Entropy 478.5484313964844, Learning Rate: 9.765625e-06\n",
      "Epoch [11969/20000], Loss: 857.23046875, Entropy 468.73388671875, Learning Rate: 9.765625e-06\n",
      "Epoch [11970/20000], Loss: 855.3154296875, Entropy 478.3208923339844, Learning Rate: 9.765625e-06\n",
      "Epoch [11971/20000], Loss: 874.5897216796875, Entropy 443.8110046386719, Learning Rate: 9.765625e-06\n",
      "Epoch [11972/20000], Loss: 897.5821533203125, Entropy 454.3219299316406, Learning Rate: 9.765625e-06\n",
      "Epoch [11973/20000], Loss: 839.2767944335938, Entropy 473.10601806640625, Learning Rate: 9.765625e-06\n",
      "Epoch [11974/20000], Loss: 858.1226196289062, Entropy 465.28057861328125, Learning Rate: 9.765625e-06\n",
      "Epoch [11975/20000], Loss: 845.8406982421875, Entropy 470.1783752441406, Learning Rate: 9.765625e-06\n",
      "Epoch [11976/20000], Loss: 839.9659423828125, Entropy 466.7328796386719, Learning Rate: 9.765625e-06\n",
      "Epoch [11977/20000], Loss: 863.053466796875, Entropy 477.0083923339844, Learning Rate: 9.765625e-06\n",
      "Epoch [11978/20000], Loss: 839.5675659179688, Entropy 459.67608642578125, Learning Rate: 9.765625e-06\n",
      "Epoch [11979/20000], Loss: 853.58837890625, Entropy 459.5828552246094, Learning Rate: 9.765625e-06\n",
      "Epoch [11980/20000], Loss: 868.549560546875, Entropy 463.1481628417969, Learning Rate: 9.765625e-06\n",
      "Epoch [11981/20000], Loss: 830.2454833984375, Entropy 470.8846740722656, Learning Rate: 9.765625e-06\n",
      "Epoch [11982/20000], Loss: 864.1344604492188, Entropy 464.41607666015625, Learning Rate: 9.765625e-06\n",
      "Epoch [11983/20000], Loss: 791.7796630859375, Entropy 473.5882568359375, Learning Rate: 9.765625e-06\n",
      "Epoch [11984/20000], Loss: 861.0906982421875, Entropy 469.1043701171875, Learning Rate: 9.765625e-06\n",
      "Epoch [11985/20000], Loss: 845.974853515625, Entropy 466.1151428222656, Learning Rate: 9.765625e-06\n",
      "Epoch [11986/20000], Loss: 851.949462890625, Entropy 470.2575378417969, Learning Rate: 9.765625e-06\n",
      "Epoch [11987/20000], Loss: 811.7816162109375, Entropy 477.7099914550781, Learning Rate: 9.765625e-06\n",
      "Epoch [11988/20000], Loss: 832.4544677734375, Entropy 464.7886657714844, Learning Rate: 9.765625e-06\n",
      "Epoch [11989/20000], Loss: 857.609375, Entropy 470.4912109375, Learning Rate: 9.765625e-06\n",
      "Epoch [11990/20000], Loss: 836.3023071289062, Entropy 471.16339111328125, Learning Rate: 9.765625e-06\n",
      "Epoch [11991/20000], Loss: 879.2327880859375, Entropy 457.9815673828125, Learning Rate: 9.765625e-06\n",
      "Epoch [11992/20000], Loss: 846.0763549804688, Entropy 454.78997802734375, Learning Rate: 9.765625e-06\n",
      "Epoch [11993/20000], Loss: 848.4320068359375, Entropy 463.0257263183594, Learning Rate: 9.765625e-06\n",
      "Epoch [11994/20000], Loss: 832.7550048828125, Entropy 487.4126892089844, Learning Rate: 9.765625e-06\n",
      "Epoch [11995/20000], Loss: 889.8131103515625, Entropy 467.0230407714844, Learning Rate: 9.765625e-06\n",
      "Epoch [11996/20000], Loss: 799.0387573242188, Entropy 468.72198486328125, Learning Rate: 9.765625e-06\n",
      "Epoch [11997/20000], Loss: 834.8822021484375, Entropy 464.4836730957031, Learning Rate: 9.765625e-06\n",
      "Epoch [11998/20000], Loss: 856.3615112304688, Entropy 488.27569580078125, Learning Rate: 9.765625e-06\n",
      "Epoch [11999/20000], Loss: 834.725830078125, Entropy 468.6592712402344, Learning Rate: 9.765625e-06\n",
      "Epoch [12000/20000], Loss: 809.6376953125, Entropy 465.62646484375, Learning Rate: 9.765625e-06\n",
      "Epoch [12001/20000], Loss: 896.7713012695312, Entropy 469.82647705078125, Learning Rate: 9.765625e-06\n",
      "Epoch [12002/20000], Loss: 836.6560668945312, Entropy 472.78936767578125, Learning Rate: 9.765625e-06\n",
      "Epoch [12003/20000], Loss: 815.8035888671875, Entropy 472.6326599121094, Learning Rate: 9.765625e-06\n",
      "Epoch [12004/20000], Loss: 873.51708984375, Entropy 473.1109924316406, Learning Rate: 9.765625e-06\n",
      "Epoch [12005/20000], Loss: 826.7059326171875, Entropy 469.6662902832031, Learning Rate: 9.765625e-06\n",
      "Epoch [12006/20000], Loss: 812.3031005859375, Entropy 477.1692810058594, Learning Rate: 9.765625e-06\n",
      "Epoch [12007/20000], Loss: 847.9275512695312, Entropy 463.14349365234375, Learning Rate: 9.765625e-06\n",
      "Epoch [12008/20000], Loss: 843.2596435546875, Entropy 462.6214599609375, Learning Rate: 9.765625e-06\n",
      "Epoch [12009/20000], Loss: 805.095703125, Entropy 457.0958557128906, Learning Rate: 9.765625e-06\n",
      "Epoch [12010/20000], Loss: 859.82421875, Entropy 468.1695861816406, Learning Rate: 9.765625e-06\n",
      "Epoch [12011/20000], Loss: 837.988525390625, Entropy 471.1882019042969, Learning Rate: 9.765625e-06\n",
      "Epoch [12012/20000], Loss: 888.6705322265625, Entropy 474.495849609375, Learning Rate: 9.765625e-06\n",
      "Epoch [12013/20000], Loss: 846.8975830078125, Entropy 485.1520080566406, Learning Rate: 9.765625e-06\n",
      "Epoch [12014/20000], Loss: 825.0897216796875, Entropy 474.7660827636719, Learning Rate: 9.765625e-06\n",
      "Epoch [12015/20000], Loss: 858.2247314453125, Entropy 476.4880676269531, Learning Rate: 9.765625e-06\n",
      "Epoch [12016/20000], Loss: 873.823486328125, Entropy 471.3746337890625, Learning Rate: 9.765625e-06\n",
      "Epoch [12017/20000], Loss: 874.2371826171875, Entropy 470.615234375, Learning Rate: 9.765625e-06\n",
      "Epoch [12018/20000], Loss: 852.3826293945312, Entropy 478.09234619140625, Learning Rate: 9.765625e-06\n",
      "Epoch [12019/20000], Loss: 868.5916137695312, Entropy 482.75115966796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12020/20000], Loss: 829.0123291015625, Entropy 471.957763671875, Learning Rate: 9.765625e-06\n",
      "Epoch [12021/20000], Loss: 840.7057495117188, Entropy 468.93218994140625, Learning Rate: 9.765625e-06\n",
      "Epoch [12022/20000], Loss: 858.2644653320312, Entropy 468.98138427734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12023/20000], Loss: 868.534912109375, Entropy 460.8049011230469, Learning Rate: 9.765625e-06\n",
      "Epoch [12024/20000], Loss: 838.9178466796875, Entropy 472.1096496582031, Learning Rate: 9.765625e-06\n",
      "Epoch [12025/20000], Loss: 834.648193359375, Entropy 455.9079284667969, Learning Rate: 9.765625e-06\n",
      "Epoch [12026/20000], Loss: 846.740478515625, Entropy 463.4588623046875, Learning Rate: 9.765625e-06\n",
      "Epoch [12027/20000], Loss: 864.9222412109375, Entropy 466.4867858886719, Learning Rate: 9.765625e-06\n",
      "Epoch [12028/20000], Loss: 805.41748046875, Entropy 474.0714416503906, Learning Rate: 9.765625e-06\n",
      "Epoch [12029/20000], Loss: 882.43115234375, Entropy 477.7809753417969, Learning Rate: 9.765625e-06\n",
      "Epoch [12030/20000], Loss: 827.1781005859375, Entropy 475.0802917480469, Learning Rate: 9.765625e-06\n",
      "Epoch [12031/20000], Loss: 833.1015625, Entropy 464.8662109375, Learning Rate: 9.765625e-06\n",
      "Epoch [12032/20000], Loss: 831.9359130859375, Entropy 462.6622619628906, Learning Rate: 9.765625e-06\n",
      "Epoch [12033/20000], Loss: 857.7798461914062, Entropy 462.16851806640625, Learning Rate: 9.765625e-06\n",
      "Epoch [12034/20000], Loss: 831.64990234375, Entropy 467.1290588378906, Learning Rate: 9.765625e-06\n",
      "Epoch [12035/20000], Loss: 822.0028076171875, Entropy 461.4920349121094, Learning Rate: 9.765625e-06\n",
      "Epoch [12036/20000], Loss: 868.7847900390625, Entropy 459.0371398925781, Learning Rate: 9.765625e-06\n",
      "Epoch [12037/20000], Loss: 859.8715209960938, Entropy 470.94561767578125, Learning Rate: 9.765625e-06\n",
      "Epoch [12038/20000], Loss: 818.71435546875, Entropy 469.1478271484375, Learning Rate: 9.765625e-06\n",
      "Epoch [12039/20000], Loss: 843.61279296875, Entropy 466.3606262207031, Learning Rate: 9.765625e-06\n",
      "Epoch [12040/20000], Loss: 907.2108764648438, Entropy 476.70318603515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12041/20000], Loss: 878.8895263671875, Entropy 455.6343688964844, Learning Rate: 9.765625e-06\n",
      "Epoch [12042/20000], Loss: 868.5217895507812, Entropy 468.65948486328125, Learning Rate: 9.765625e-06\n",
      "Epoch [12043/20000], Loss: 837.19287109375, Entropy 479.1745910644531, Learning Rate: 9.765625e-06\n",
      "Epoch [12044/20000], Loss: 836.7570190429688, Entropy 473.02642822265625, Learning Rate: 9.765625e-06\n",
      "Epoch [12045/20000], Loss: 843.9841918945312, Entropy 478.80755615234375, Learning Rate: 9.765625e-06\n",
      "Epoch [12046/20000], Loss: 832.75, Entropy 470.8049011230469, Learning Rate: 9.765625e-06\n",
      "Epoch [12047/20000], Loss: 843.90869140625, Entropy 472.3129577636719, Learning Rate: 9.765625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12048/20000], Loss: 813.5091552734375, Entropy 469.7159118652344, Learning Rate: 9.765625e-06\n",
      "Epoch [12049/20000], Loss: 871.0588989257812, Entropy 464.26654052734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12050/20000], Loss: 882.8657836914062, Entropy 471.96929931640625, Learning Rate: 9.765625e-06\n",
      "Epoch [12051/20000], Loss: 848.7568969726562, Entropy 465.32147216796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12052/20000], Loss: 839.8604125976562, Entropy 470.08795166015625, Learning Rate: 9.765625e-06\n",
      "Epoch [12053/20000], Loss: 882.4229125976562, Entropy 459.44427490234375, Learning Rate: 9.765625e-06\n",
      "Epoch [12054/20000], Loss: 878.3421630859375, Entropy 481.4471740722656, Learning Rate: 9.765625e-06\n",
      "Epoch [12055/20000], Loss: 857.7596435546875, Entropy 466.6700134277344, Learning Rate: 9.765625e-06\n",
      "Epoch [12056/20000], Loss: 856.0208740234375, Entropy 477.6603698730469, Learning Rate: 9.765625e-06\n",
      "Epoch [12057/20000], Loss: 842.8875732421875, Entropy 472.7376708984375, Learning Rate: 9.765625e-06\n",
      "Epoch [12058/20000], Loss: 798.5386962890625, Entropy 482.0870056152344, Learning Rate: 9.765625e-06\n",
      "Epoch [12059/20000], Loss: 848.19384765625, Entropy 460.0640869140625, Learning Rate: 9.765625e-06\n",
      "Epoch [12060/20000], Loss: 802.175048828125, Entropy 484.1201477050781, Learning Rate: 9.765625e-06\n",
      "Epoch [12061/20000], Loss: 865.1063232421875, Entropy 462.6703796386719, Learning Rate: 9.765625e-06\n",
      "Epoch [12062/20000], Loss: 848.385498046875, Entropy 475.2230224609375, Learning Rate: 9.765625e-06\n",
      "Epoch [12063/20000], Loss: 839.8744506835938, Entropy 475.99334716796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12064/20000], Loss: 843.2557983398438, Entropy 463.97357177734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12065/20000], Loss: 881.0166015625, Entropy 473.1921081542969, Learning Rate: 9.765625e-06\n",
      "Epoch [12066/20000], Loss: 857.34326171875, Entropy 466.1012268066406, Learning Rate: 9.765625e-06\n",
      "Epoch [12067/20000], Loss: 812.3436279296875, Entropy 471.1455993652344, Learning Rate: 9.765625e-06\n",
      "Epoch [12068/20000], Loss: 840.8685302734375, Entropy 466.7410888671875, Learning Rate: 9.765625e-06\n",
      "Epoch [12069/20000], Loss: 849.6574096679688, Entropy 474.01568603515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12070/20000], Loss: 822.8583984375, Entropy 472.935302734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12071/20000], Loss: 880.4931030273438, Entropy 465.57061767578125, Learning Rate: 9.765625e-06\n",
      "Epoch [12072/20000], Loss: 844.603515625, Entropy 470.1392822265625, Learning Rate: 9.765625e-06\n",
      "Epoch [12073/20000], Loss: 835.95263671875, Entropy 465.1011657714844, Learning Rate: 9.765625e-06\n",
      "Epoch [12074/20000], Loss: 878.6715087890625, Entropy 470.7825012207031, Learning Rate: 9.765625e-06\n",
      "Epoch [12075/20000], Loss: 857.8358154296875, Entropy 478.9191589355469, Learning Rate: 9.765625e-06\n",
      "Epoch [12076/20000], Loss: 828.4767456054688, Entropy 477.62261962890625, Learning Rate: 9.765625e-06\n",
      "Epoch [12077/20000], Loss: 895.879638671875, Entropy 461.1839599609375, Learning Rate: 9.765625e-06\n",
      "Epoch [12078/20000], Loss: 859.601318359375, Entropy 453.3650817871094, Learning Rate: 9.765625e-06\n",
      "Epoch [12079/20000], Loss: 864.2119140625, Entropy 466.6285095214844, Learning Rate: 9.765625e-06\n",
      "Epoch [12080/20000], Loss: 834.3551025390625, Entropy 461.2878112792969, Learning Rate: 9.765625e-06\n",
      "Epoch [12081/20000], Loss: 867.3216552734375, Entropy 454.3958435058594, Learning Rate: 9.765625e-06\n",
      "Epoch [12082/20000], Loss: 815.220458984375, Entropy 470.4306945800781, Learning Rate: 9.765625e-06\n",
      "Epoch [12083/20000], Loss: 880.51416015625, Entropy 457.3854064941406, Learning Rate: 9.765625e-06\n",
      "Epoch [12084/20000], Loss: 897.4837646484375, Entropy 448.6738586425781, Learning Rate: 9.765625e-06\n",
      "Epoch [12085/20000], Loss: 818.9078369140625, Entropy 458.4292907714844, Learning Rate: 9.765625e-06\n",
      "Epoch [12086/20000], Loss: 797.574951171875, Entropy 472.1183776855469, Learning Rate: 9.765625e-06\n",
      "Epoch [12087/20000], Loss: 838.86376953125, Entropy 472.0783386230469, Learning Rate: 9.765625e-06\n",
      "Epoch [12088/20000], Loss: 844.3087158203125, Entropy 473.9371643066406, Learning Rate: 9.765625e-06\n",
      "Epoch [12089/20000], Loss: 841.2002563476562, Entropy 477.78265380859375, Learning Rate: 9.765625e-06\n",
      "Epoch [12090/20000], Loss: 817.0784912109375, Entropy 470.1720886230469, Learning Rate: 9.765625e-06\n",
      "Epoch [12091/20000], Loss: 825.029296875, Entropy 473.1050720214844, Learning Rate: 9.765625e-06\n",
      "Epoch [12092/20000], Loss: 887.4808349609375, Entropy 476.1219787597656, Learning Rate: 9.765625e-06\n",
      "Epoch [12093/20000], Loss: 839.043212890625, Entropy 471.9000549316406, Learning Rate: 9.765625e-06\n",
      "Epoch [12094/20000], Loss: 839.7581787109375, Entropy 479.8603820800781, Learning Rate: 9.765625e-06\n",
      "Epoch [12095/20000], Loss: 882.7977294921875, Entropy 478.4014587402344, Learning Rate: 9.765625e-06\n",
      "Epoch [12096/20000], Loss: 859.4337768554688, Entropy 465.10162353515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12097/20000], Loss: 844.1822509765625, Entropy 476.8620910644531, Learning Rate: 9.765625e-06\n",
      "Epoch [12098/20000], Loss: 827.42333984375, Entropy 457.6722106933594, Learning Rate: 9.765625e-06\n",
      "Epoch [12099/20000], Loss: 851.7846069335938, Entropy 468.51300048828125, Learning Rate: 9.765625e-06\n",
      "Epoch [12100/20000], Loss: 810.3272705078125, Entropy 467.3348693847656, Learning Rate: 9.765625e-06\n",
      "Epoch [12101/20000], Loss: 847.9525146484375, Entropy 470.0080261230469, Learning Rate: 9.765625e-06\n",
      "Epoch [12102/20000], Loss: 877.49853515625, Entropy 472.1020202636719, Learning Rate: 9.765625e-06\n",
      "Epoch [12103/20000], Loss: 849.2091064453125, Entropy 472.7468566894531, Learning Rate: 9.765625e-06\n",
      "Epoch [12104/20000], Loss: 902.857666015625, Entropy 451.0728759765625, Learning Rate: 9.765625e-06\n",
      "Epoch [12105/20000], Loss: 843.1957397460938, Entropy 464.96807861328125, Learning Rate: 9.765625e-06\n",
      "Epoch [12106/20000], Loss: 883.3935546875, Entropy 463.5138244628906, Learning Rate: 9.765625e-06\n",
      "Epoch [12107/20000], Loss: 822.7589721679688, Entropy 471.30621337890625, Learning Rate: 9.765625e-06\n",
      "Epoch [12108/20000], Loss: 829.6145629882812, Entropy 460.80108642578125, Learning Rate: 9.765625e-06\n",
      "Epoch [12109/20000], Loss: 858.5950927734375, Entropy 473.3482971191406, Learning Rate: 9.765625e-06\n",
      "Epoch [12110/20000], Loss: 856.0745849609375, Entropy 472.6744079589844, Learning Rate: 9.765625e-06\n",
      "Epoch [12111/20000], Loss: 857.7266845703125, Entropy 482.782958984375, Learning Rate: 9.765625e-06\n",
      "Epoch [12112/20000], Loss: 881.0004272460938, Entropy 479.48675537109375, Learning Rate: 9.765625e-06\n",
      "Epoch [12113/20000], Loss: 813.8575439453125, Entropy 484.8265075683594, Learning Rate: 9.765625e-06\n",
      "Epoch [12114/20000], Loss: 810.7933349609375, Entropy 473.1805419921875, Learning Rate: 9.765625e-06\n",
      "Epoch [12115/20000], Loss: 864.6490478515625, Entropy 474.8912353515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12116/20000], Loss: 860.6056518554688, Entropy 479.12115478515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12117/20000], Loss: 809.56640625, Entropy 470.1723327636719, Learning Rate: 9.765625e-06\n",
      "Epoch [12118/20000], Loss: 838.818359375, Entropy 465.4756164550781, Learning Rate: 9.765625e-06\n",
      "Epoch [12119/20000], Loss: 856.0696411132812, Entropy 476.27569580078125, Learning Rate: 9.765625e-06\n",
      "Epoch [12120/20000], Loss: 833.67529296875, Entropy 481.3587341308594, Learning Rate: 9.765625e-06\n",
      "Epoch [12121/20000], Loss: 841.136962890625, Entropy 467.1981201171875, Learning Rate: 9.765625e-06\n",
      "Epoch [12122/20000], Loss: 840.841552734375, Entropy 482.7836608886719, Learning Rate: 9.765625e-06\n",
      "Epoch [12123/20000], Loss: 855.6875, Entropy 466.5648193359375, Learning Rate: 9.765625e-06\n",
      "Epoch [12124/20000], Loss: 867.8836669921875, Entropy 472.7801208496094, Learning Rate: 9.765625e-06\n",
      "Epoch [12125/20000], Loss: 889.432373046875, Entropy 468.2232971191406, Learning Rate: 9.765625e-06\n",
      "Epoch [12126/20000], Loss: 879.654541015625, Entropy 462.43359375, Learning Rate: 9.765625e-06\n",
      "Epoch [12127/20000], Loss: 843.36474609375, Entropy 481.7820129394531, Learning Rate: 9.765625e-06\n",
      "Epoch [12128/20000], Loss: 844.4974975585938, Entropy 474.86468505859375, Learning Rate: 9.765625e-06\n",
      "Epoch [12129/20000], Loss: 877.2052612304688, Entropy 476.58599853515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12130/20000], Loss: 879.5614013671875, Entropy 471.3108825683594, Learning Rate: 9.765625e-06\n",
      "Epoch [12131/20000], Loss: 857.5621337890625, Entropy 455.5406799316406, Learning Rate: 9.765625e-06\n",
      "Epoch [12132/20000], Loss: 838.9425048828125, Entropy 475.2194519042969, Learning Rate: 9.765625e-06\n",
      "Epoch [12133/20000], Loss: 888.4208984375, Entropy 461.4407043457031, Learning Rate: 9.765625e-06\n",
      "Epoch [12134/20000], Loss: 856.0350341796875, Entropy 457.4858093261719, Learning Rate: 9.765625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12135/20000], Loss: 891.507080078125, Entropy 453.4119567871094, Learning Rate: 9.765625e-06\n",
      "Epoch [12136/20000], Loss: 878.1005859375, Entropy 465.4236755371094, Learning Rate: 9.765625e-06\n",
      "Epoch [12137/20000], Loss: 865.2830810546875, Entropy 458.8968505859375, Learning Rate: 9.765625e-06\n",
      "Epoch [12138/20000], Loss: 844.4396362304688, Entropy 476.20404052734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12139/20000], Loss: 848.8723754882812, Entropy 468.86053466796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12140/20000], Loss: 875.1953125, Entropy 467.0821228027344, Learning Rate: 9.765625e-06\n",
      "Epoch [12141/20000], Loss: 834.15087890625, Entropy 457.8546142578125, Learning Rate: 9.765625e-06\n",
      "Epoch [12142/20000], Loss: 828.7998046875, Entropy 466.9898376464844, Learning Rate: 9.765625e-06\n",
      "Epoch [12143/20000], Loss: 824.0457763671875, Entropy 467.9581604003906, Learning Rate: 9.765625e-06\n",
      "Epoch [12144/20000], Loss: 825.3053588867188, Entropy 470.60052490234375, Learning Rate: 9.765625e-06\n",
      "Epoch [12145/20000], Loss: 867.3544921875, Entropy 481.8988952636719, Learning Rate: 9.765625e-06\n",
      "Epoch [12146/20000], Loss: 825.76708984375, Entropy 465.7071838378906, Learning Rate: 9.765625e-06\n",
      "Epoch [12147/20000], Loss: 852.707763671875, Entropy 468.1868591308594, Learning Rate: 9.765625e-06\n",
      "Epoch [12148/20000], Loss: 855.6810913085938, Entropy 460.16925048828125, Learning Rate: 9.765625e-06\n",
      "Epoch [12149/20000], Loss: 856.189453125, Entropy 456.4212341308594, Learning Rate: 9.765625e-06\n",
      "Epoch [12150/20000], Loss: 911.645263671875, Entropy 467.928466796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12151/20000], Loss: 832.4129638671875, Entropy 475.76953125, Learning Rate: 9.765625e-06\n",
      "Epoch [12152/20000], Loss: 801.1448974609375, Entropy 471.4778747558594, Learning Rate: 9.765625e-06\n",
      "Epoch [12153/20000], Loss: 813.6035766601562, Entropy 480.23919677734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12154/20000], Loss: 843.4871215820312, Entropy 468.29937744140625, Learning Rate: 9.765625e-06\n",
      "Epoch [12155/20000], Loss: 824.228759765625, Entropy 475.71044921875, Learning Rate: 9.765625e-06\n",
      "Epoch [12156/20000], Loss: 876.8380126953125, Entropy 474.6481628417969, Learning Rate: 9.765625e-06\n",
      "Epoch [12157/20000], Loss: 812.0750732421875, Entropy 484.8713684082031, Learning Rate: 9.765625e-06\n",
      "Epoch [12158/20000], Loss: 845.3037109375, Entropy 472.7503662109375, Learning Rate: 9.765625e-06\n",
      "Epoch [12159/20000], Loss: 853.5599365234375, Entropy 468.3127136230469, Learning Rate: 9.765625e-06\n",
      "Epoch [12160/20000], Loss: 832.7283935546875, Entropy 484.9318542480469, Learning Rate: 9.765625e-06\n",
      "Epoch [12161/20000], Loss: 875.8110961914062, Entropy 468.12420654296875, Learning Rate: 9.765625e-06\n",
      "Epoch [12162/20000], Loss: 832.0692749023438, Entropy 466.75543212890625, Learning Rate: 9.765625e-06\n",
      "Epoch [12163/20000], Loss: 867.3075561523438, Entropy 478.22882080078125, Learning Rate: 9.765625e-06\n",
      "Epoch [12164/20000], Loss: 840.6160888671875, Entropy 475.0577087402344, Learning Rate: 9.765625e-06\n",
      "Epoch [12165/20000], Loss: 841.5889282226562, Entropy 480.94171142578125, Learning Rate: 9.765625e-06\n",
      "Epoch [12166/20000], Loss: 838.1690063476562, Entropy 467.79522705078125, Learning Rate: 9.765625e-06\n",
      "Epoch [12167/20000], Loss: 882.3261108398438, Entropy 467.31842041015625, Learning Rate: 9.765625e-06\n",
      "Epoch [12168/20000], Loss: 850.2890625, Entropy 470.2828674316406, Learning Rate: 9.765625e-06\n",
      "Epoch [12169/20000], Loss: 857.2032470703125, Entropy 464.9241943359375, Learning Rate: 9.765625e-06\n",
      "Epoch [12170/20000], Loss: 836.2431640625, Entropy 469.6214599609375, Learning Rate: 9.765625e-06\n",
      "Epoch [12171/20000], Loss: 814.2952880859375, Entropy 484.7733459472656, Learning Rate: 9.765625e-06\n",
      "Epoch [12172/20000], Loss: 856.7479858398438, Entropy 466.81060791015625, Learning Rate: 9.765625e-06\n",
      "Epoch [12173/20000], Loss: 872.539794921875, Entropy 474.6989440917969, Learning Rate: 9.765625e-06\n",
      "Epoch [12174/20000], Loss: 821.34912109375, Entropy 476.0851745605469, Learning Rate: 9.765625e-06\n",
      "Epoch [12175/20000], Loss: 818.08203125, Entropy 479.5749816894531, Learning Rate: 9.765625e-06\n",
      "Epoch [12176/20000], Loss: 880.8756103515625, Entropy 458.6930847167969, Learning Rate: 9.765625e-06\n",
      "Epoch [12177/20000], Loss: 811.848388671875, Entropy 480.7604675292969, Learning Rate: 9.765625e-06\n",
      "Epoch [12178/20000], Loss: 839.8463134765625, Entropy 480.7301330566406, Learning Rate: 9.765625e-06\n",
      "Epoch [12179/20000], Loss: 842.353515625, Entropy 455.5350341796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12180/20000], Loss: 809.6849365234375, Entropy 474.5835876464844, Learning Rate: 9.765625e-06\n",
      "Epoch [12181/20000], Loss: 879.7508544921875, Entropy 471.9761962890625, Learning Rate: 9.765625e-06\n",
      "Epoch [12182/20000], Loss: 841.0205078125, Entropy 481.1583557128906, Learning Rate: 9.765625e-06\n",
      "Epoch [12183/20000], Loss: 827.1051025390625, Entropy 474.4678649902344, Learning Rate: 9.765625e-06\n",
      "Epoch [12184/20000], Loss: 842.60205078125, Entropy 461.6021728515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12185/20000], Loss: 868.6411743164062, Entropy 467.56500244140625, Learning Rate: 9.765625e-06\n",
      "Epoch [12186/20000], Loss: 871.42626953125, Entropy 470.637451171875, Learning Rate: 9.765625e-06\n",
      "Epoch [12187/20000], Loss: 849.4452514648438, Entropy 475.00628662109375, Learning Rate: 9.765625e-06\n",
      "Epoch [12188/20000], Loss: 844.945068359375, Entropy 474.0588073730469, Learning Rate: 9.765625e-06\n",
      "Epoch [12189/20000], Loss: 799.3604736328125, Entropy 480.8902893066406, Learning Rate: 9.765625e-06\n",
      "Epoch [12190/20000], Loss: 878.86181640625, Entropy 464.81591796875, Learning Rate: 9.765625e-06\n",
      "Epoch [12191/20000], Loss: 848.1959838867188, Entropy 479.36651611328125, Learning Rate: 9.765625e-06\n",
      "Epoch [12192/20000], Loss: 804.593994140625, Entropy 460.6512451171875, Learning Rate: 9.765625e-06\n",
      "Epoch [12193/20000], Loss: 888.7523803710938, Entropy 447.96038818359375, Learning Rate: 9.765625e-06\n",
      "Epoch [12194/20000], Loss: 867.2093505859375, Entropy 468.060302734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12195/20000], Loss: 840.15234375, Entropy 491.0828552246094, Learning Rate: 9.765625e-06\n",
      "Epoch [12196/20000], Loss: 830.1719970703125, Entropy 475.7966003417969, Learning Rate: 9.765625e-06\n",
      "Epoch [12197/20000], Loss: 844.0476684570312, Entropy 466.15545654296875, Learning Rate: 9.765625e-06\n",
      "Epoch [12198/20000], Loss: 867.75146484375, Entropy 481.1048583984375, Learning Rate: 9.765625e-06\n",
      "Epoch [12199/20000], Loss: 818.2352294921875, Entropy 483.6667175292969, Learning Rate: 9.765625e-06\n",
      "Epoch [12200/20000], Loss: 819.484130859375, Entropy 472.9145202636719, Learning Rate: 9.765625e-06\n",
      "Epoch [12201/20000], Loss: 859.4586181640625, Entropy 469.0531921386719, Learning Rate: 9.765625e-06\n",
      "Epoch [12202/20000], Loss: 841.121337890625, Entropy 481.1756286621094, Learning Rate: 9.765625e-06\n",
      "Epoch [12203/20000], Loss: 869.154296875, Entropy 473.5550231933594, Learning Rate: 9.765625e-06\n",
      "Epoch [12204/20000], Loss: 885.6470947265625, Entropy 462.994140625, Learning Rate: 9.765625e-06\n",
      "Epoch [12205/20000], Loss: 821.659912109375, Entropy 464.8771057128906, Learning Rate: 9.765625e-06\n",
      "Epoch [12206/20000], Loss: 818.2825927734375, Entropy 466.8807067871094, Learning Rate: 9.765625e-06\n",
      "Epoch [12207/20000], Loss: 806.7774658203125, Entropy 467.1256103515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12208/20000], Loss: 796.9984741210938, Entropy 470.67193603515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12209/20000], Loss: 818.9525756835938, Entropy 470.79302978515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12210/20000], Loss: 851.34228515625, Entropy 471.8240661621094, Learning Rate: 9.765625e-06\n",
      "Epoch [12211/20000], Loss: 870.2974853515625, Entropy 464.2243347167969, Learning Rate: 9.765625e-06\n",
      "Epoch [12212/20000], Loss: 860.4632568359375, Entropy 461.462646484375, Learning Rate: 9.765625e-06\n",
      "Epoch [12213/20000], Loss: 848.6158447265625, Entropy 465.1428527832031, Learning Rate: 9.765625e-06\n",
      "Epoch [12214/20000], Loss: 807.15087890625, Entropy 469.1678161621094, Learning Rate: 9.765625e-06\n",
      "Epoch [12215/20000], Loss: 836.0498046875, Entropy 453.4788818359375, Learning Rate: 9.765625e-06\n",
      "Epoch [12216/20000], Loss: 852.723876953125, Entropy 466.6120910644531, Learning Rate: 9.765625e-06\n",
      "Epoch [12217/20000], Loss: 854.2576904296875, Entropy 472.9939880371094, Learning Rate: 9.765625e-06\n",
      "Epoch [12218/20000], Loss: 829.1220703125, Entropy 473.8880310058594, Learning Rate: 9.765625e-06\n",
      "Epoch [12219/20000], Loss: 839.6442260742188, Entropy 471.49224853515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12220/20000], Loss: 834.7959594726562, Entropy 458.11029052734375, Learning Rate: 9.765625e-06\n",
      "Epoch [12221/20000], Loss: 837.9182739257812, Entropy 472.99798583984375, Learning Rate: 9.765625e-06\n",
      "Epoch [12222/20000], Loss: 803.2518310546875, Entropy 474.1393737792969, Learning Rate: 9.765625e-06\n",
      "Epoch [12223/20000], Loss: 816.7130126953125, Entropy 476.0961608886719, Learning Rate: 9.765625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12224/20000], Loss: 852.407958984375, Entropy 486.1044006347656, Learning Rate: 9.765625e-06\n",
      "Epoch [12225/20000], Loss: 844.89794921875, Entropy 459.4840393066406, Learning Rate: 9.765625e-06\n",
      "Epoch [12226/20000], Loss: 795.494384765625, Entropy 473.65380859375, Learning Rate: 9.765625e-06\n",
      "Epoch [12227/20000], Loss: 845.348876953125, Entropy 480.68603515625, Learning Rate: 9.765625e-06\n",
      "Epoch [12228/20000], Loss: 843.5891723632812, Entropy 459.69476318359375, Learning Rate: 9.765625e-06\n",
      "Epoch [12229/20000], Loss: 833.8955078125, Entropy 467.3084411621094, Learning Rate: 9.765625e-06\n",
      "Epoch [12230/20000], Loss: 825.389892578125, Entropy 472.3132019042969, Learning Rate: 9.765625e-06\n",
      "Epoch [12231/20000], Loss: 839.1162109375, Entropy 469.1336364746094, Learning Rate: 9.765625e-06\n",
      "Epoch [12232/20000], Loss: 882.2779541015625, Entropy 472.7744445800781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12233/20000], Loss: 811.5886840820312, Entropy 470.40435791015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12234/20000], Loss: 861.583740234375, Entropy 467.4874572753906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12235/20000], Loss: 830.28173828125, Entropy 473.5823974609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12236/20000], Loss: 804.8002319335938, Entropy 482.32354736328125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12237/20000], Loss: 868.7938232421875, Entropy 473.4339294433594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12238/20000], Loss: 847.232421875, Entropy 476.8855285644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12239/20000], Loss: 863.0191650390625, Entropy 463.3748474121094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12240/20000], Loss: 886.5096435546875, Entropy 459.28173828125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12241/20000], Loss: 868.5206298828125, Entropy 474.1082458496094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12242/20000], Loss: 845.261962890625, Entropy 464.695068359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12243/20000], Loss: 860.7490234375, Entropy 469.8018493652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12244/20000], Loss: 843.53955078125, Entropy 475.0242004394531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12245/20000], Loss: 868.0101318359375, Entropy 479.1129455566406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12246/20000], Loss: 853.0711669921875, Entropy 468.2819519042969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12247/20000], Loss: 809.85400390625, Entropy 472.0514221191406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12248/20000], Loss: 868.942138671875, Entropy 462.64404296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12249/20000], Loss: 830.9310913085938, Entropy 484.01507568359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12250/20000], Loss: 823.2364501953125, Entropy 467.3688049316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12251/20000], Loss: 908.0682373046875, Entropy 463.1299133300781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12252/20000], Loss: 800.4097900390625, Entropy 470.6291198730469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12253/20000], Loss: 834.285400390625, Entropy 469.1397399902344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12254/20000], Loss: 835.6966552734375, Entropy 472.0788879394531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12255/20000], Loss: 808.316162109375, Entropy 472.2239074707031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12256/20000], Loss: 839.7044067382812, Entropy 468.17864990234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12257/20000], Loss: 853.0274658203125, Entropy 468.8662109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12258/20000], Loss: 833.1007080078125, Entropy 468.7976379394531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12259/20000], Loss: 881.3028564453125, Entropy 479.1833190917969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12260/20000], Loss: 872.9441528320312, Entropy 477.07672119140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12261/20000], Loss: 852.9774169921875, Entropy 480.3212890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12262/20000], Loss: 836.766845703125, Entropy 471.96044921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12263/20000], Loss: 845.179443359375, Entropy 485.8746032714844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12264/20000], Loss: 875.7393188476562, Entropy 478.18084716796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12265/20000], Loss: 874.663330078125, Entropy 466.0765075683594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12266/20000], Loss: 842.5743408203125, Entropy 467.8564758300781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12267/20000], Loss: 826.5988159179688, Entropy 469.91632080078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12268/20000], Loss: 842.552978515625, Entropy 466.1932678222656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12269/20000], Loss: 830.99462890625, Entropy 476.6871643066406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12270/20000], Loss: 893.4948120117188, Entropy 469.86334228515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12271/20000], Loss: 862.053955078125, Entropy 458.7303771972656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12272/20000], Loss: 840.5352172851562, Entropy 481.46319580078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12273/20000], Loss: 873.7938232421875, Entropy 476.8064880371094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12274/20000], Loss: 875.9425659179688, Entropy 470.44158935546875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12275/20000], Loss: 858.8222045898438, Entropy 469.26788330078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12276/20000], Loss: 834.5648193359375, Entropy 479.7754821777344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12277/20000], Loss: 863.0242919921875, Entropy 478.6150817871094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12278/20000], Loss: 825.6993408203125, Entropy 474.5808410644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12279/20000], Loss: 864.273193359375, Entropy 462.9167785644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12280/20000], Loss: 844.6622314453125, Entropy 481.80029296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12281/20000], Loss: 856.2267456054688, Entropy 474.67633056640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12282/20000], Loss: 824.62646484375, Entropy 478.7789611816406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12283/20000], Loss: 857.2325439453125, Entropy 482.3570861816406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12284/20000], Loss: 832.8922729492188, Entropy 474.92388916015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12285/20000], Loss: 870.9815673828125, Entropy 472.947021484375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12286/20000], Loss: 825.3857421875, Entropy 474.7182312011719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12287/20000], Loss: 838.784912109375, Entropy 473.1517028808594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12288/20000], Loss: 850.768798828125, Entropy 468.8662414550781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12289/20000], Loss: 865.7130737304688, Entropy 466.30718994140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12290/20000], Loss: 891.9342041015625, Entropy 477.7266540527344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12291/20000], Loss: 866.0835571289062, Entropy 477.12298583984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12292/20000], Loss: 859.3665771484375, Entropy 482.3517761230469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12293/20000], Loss: 804.4339599609375, Entropy 476.5096130371094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12294/20000], Loss: 842.999267578125, Entropy 466.6976318359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12295/20000], Loss: 880.427490234375, Entropy 472.4596862792969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12296/20000], Loss: 905.3983764648438, Entropy 466.61724853515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12297/20000], Loss: 865.899169921875, Entropy 464.5754699707031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12298/20000], Loss: 895.3694458007812, Entropy 459.81243896484375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12299/20000], Loss: 823.5791015625, Entropy 467.2938232421875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12300/20000], Loss: 840.701904296875, Entropy 477.64404296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12301/20000], Loss: 878.724853515625, Entropy 476.2567443847656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12302/20000], Loss: 878.72216796875, Entropy 461.6497497558594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12303/20000], Loss: 833.5380249023438, Entropy 477.80706787109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12304/20000], Loss: 848.390380859375, Entropy 474.3680419921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12305/20000], Loss: 822.079833984375, Entropy 465.6176452636719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12306/20000], Loss: 829.7965087890625, Entropy 472.9675598144531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12307/20000], Loss: 877.2526245117188, Entropy 461.15362548828125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12308/20000], Loss: 854.7714233398438, Entropy 475.82757568359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12309/20000], Loss: 890.689208984375, Entropy 459.2186584472656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12310/20000], Loss: 872.041259765625, Entropy 459.8138122558594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12311/20000], Loss: 822.73046875, Entropy 475.3645324707031, Learning Rate: 4.8828125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12312/20000], Loss: 825.7192993164062, Entropy 466.55303955078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12313/20000], Loss: 877.83740234375, Entropy 472.8938293457031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12314/20000], Loss: 879.159423828125, Entropy 460.8968505859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12315/20000], Loss: 852.285400390625, Entropy 471.4670715332031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12316/20000], Loss: 832.2659912109375, Entropy 475.1521911621094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12317/20000], Loss: 823.7518920898438, Entropy 461.63812255859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12318/20000], Loss: 858.054931640625, Entropy 466.5506896972656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12319/20000], Loss: 856.4779663085938, Entropy 488.86529541015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12320/20000], Loss: 869.628662109375, Entropy 469.4226379394531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12321/20000], Loss: 805.0361328125, Entropy 474.9557800292969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12322/20000], Loss: 810.1175537109375, Entropy 456.1164245605469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12323/20000], Loss: 892.4464111328125, Entropy 472.6844482421875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12324/20000], Loss: 875.4815673828125, Entropy 469.07275390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12325/20000], Loss: 825.2470703125, Entropy 468.8308410644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12326/20000], Loss: 837.4755249023438, Entropy 480.32366943359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12327/20000], Loss: 873.5879516601562, Entropy 466.60858154296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12328/20000], Loss: 822.7908935546875, Entropy 476.46044921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12329/20000], Loss: 849.845458984375, Entropy 458.8699035644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12330/20000], Loss: 886.16943359375, Entropy 466.7642822265625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12331/20000], Loss: 844.0634765625, Entropy 461.638427734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12332/20000], Loss: 846.3836669921875, Entropy 469.1628723144531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12333/20000], Loss: 862.5087280273438, Entropy 468.87030029296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12334/20000], Loss: 862.616943359375, Entropy 474.144287109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12335/20000], Loss: 816.4909057617188, Entropy 477.45452880859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12336/20000], Loss: 872.9645385742188, Entropy 461.98089599609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12337/20000], Loss: 843.5560302734375, Entropy 479.0667419433594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12338/20000], Loss: 833.284423828125, Entropy 477.8497009277344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12339/20000], Loss: 855.1067504882812, Entropy 470.99822998046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12340/20000], Loss: 834.8551635742188, Entropy 473.68182373046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12341/20000], Loss: 863.9971923828125, Entropy 458.6390380859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12342/20000], Loss: 847.080810546875, Entropy 474.1050720214844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12343/20000], Loss: 897.040771484375, Entropy 463.2825927734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12344/20000], Loss: 829.3682861328125, Entropy 465.427490234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12345/20000], Loss: 864.6273193359375, Entropy 467.83203125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12346/20000], Loss: 842.1939697265625, Entropy 490.3282165527344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12347/20000], Loss: 868.8317260742188, Entropy 462.11871337890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12348/20000], Loss: 811.4104614257812, Entropy 482.21917724609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12349/20000], Loss: 862.7242431640625, Entropy 470.7223815917969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12350/20000], Loss: 860.930908203125, Entropy 464.3894348144531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12351/20000], Loss: 841.2825317382812, Entropy 462.74261474609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12352/20000], Loss: 850.7483520507812, Entropy 481.77569580078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12353/20000], Loss: 873.348388671875, Entropy 474.84912109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12354/20000], Loss: 845.649658203125, Entropy 465.83203125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12355/20000], Loss: 851.1771240234375, Entropy 470.9757385253906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12356/20000], Loss: 884.5330810546875, Entropy 481.8450012207031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12357/20000], Loss: 832.9442138671875, Entropy 478.26171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12358/20000], Loss: 892.62353515625, Entropy 460.358154296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12359/20000], Loss: 847.4208984375, Entropy 467.7950744628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12360/20000], Loss: 909.4342651367188, Entropy 467.64605712890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12361/20000], Loss: 848.7389526367188, Entropy 478.05755615234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12362/20000], Loss: 880.5520629882812, Entropy 471.70428466796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12363/20000], Loss: 871.7010498046875, Entropy 465.7878723144531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12364/20000], Loss: 861.1055908203125, Entropy 463.8279724121094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12365/20000], Loss: 817.4055786132812, Entropy 478.94818115234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12366/20000], Loss: 869.3387451171875, Entropy 468.365234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12367/20000], Loss: 848.364501953125, Entropy 471.9906921386719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12368/20000], Loss: 857.8829956054688, Entropy 478.47906494140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12369/20000], Loss: 841.501708984375, Entropy 473.3175964355469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12370/20000], Loss: 847.845458984375, Entropy 479.2147521972656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12371/20000], Loss: 845.2118530273438, Entropy 470.54937744140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12372/20000], Loss: 807.11279296875, Entropy 479.9954528808594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12373/20000], Loss: 850.3065185546875, Entropy 465.2227478027344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12374/20000], Loss: 840.8123779296875, Entropy 476.61474609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12375/20000], Loss: 835.0262451171875, Entropy 464.5964660644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12376/20000], Loss: 866.7212524414062, Entropy 470.78179931640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12377/20000], Loss: 850.0636596679688, Entropy 467.84625244140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12378/20000], Loss: 905.0518798828125, Entropy 455.4932861328125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12379/20000], Loss: 837.4035034179688, Entropy 476.74444580078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12380/20000], Loss: 828.980712890625, Entropy 470.1875915527344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12381/20000], Loss: 867.119384765625, Entropy 470.0643615722656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12382/20000], Loss: 794.2959594726562, Entropy 480.58319091796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12383/20000], Loss: 837.904541015625, Entropy 468.76513671875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12384/20000], Loss: 868.532470703125, Entropy 469.4097595214844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12385/20000], Loss: 845.9539794921875, Entropy 460.7801208496094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12386/20000], Loss: 893.0889892578125, Entropy 473.3684997558594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12387/20000], Loss: 871.362060546875, Entropy 466.5157775878906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12388/20000], Loss: 819.5283203125, Entropy 470.9178466796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12389/20000], Loss: 859.1226196289062, Entropy 466.59625244140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12390/20000], Loss: 843.956787109375, Entropy 466.2889099121094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12391/20000], Loss: 831.4667358398438, Entropy 464.55853271484375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12392/20000], Loss: 874.8077392578125, Entropy 465.0628662109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12393/20000], Loss: 848.12939453125, Entropy 480.0282287597656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12394/20000], Loss: 874.0826416015625, Entropy 466.7244567871094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12395/20000], Loss: 856.450927734375, Entropy 463.9440612792969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12396/20000], Loss: 819.2657470703125, Entropy 475.5071716308594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12397/20000], Loss: 852.7650146484375, Entropy 478.0576477050781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12398/20000], Loss: 845.12841796875, Entropy 480.7640380859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12399/20000], Loss: 890.8192138671875, Entropy 466.2391052246094, Learning Rate: 4.8828125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12400/20000], Loss: 844.930908203125, Entropy 470.3570861816406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12401/20000], Loss: 852.7713623046875, Entropy 481.2571105957031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12402/20000], Loss: 818.985595703125, Entropy 470.5677490234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12403/20000], Loss: 821.8681640625, Entropy 473.40771484375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12404/20000], Loss: 849.0213623046875, Entropy 453.7273864746094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12405/20000], Loss: 784.3604736328125, Entropy 476.1064758300781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12406/20000], Loss: 877.259521484375, Entropy 471.8685302734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12407/20000], Loss: 812.2640380859375, Entropy 473.13623046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12408/20000], Loss: 803.649658203125, Entropy 481.8631286621094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12409/20000], Loss: 876.41015625, Entropy 479.52685546875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12410/20000], Loss: 832.63525390625, Entropy 471.8642578125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12411/20000], Loss: 874.1112060546875, Entropy 472.5730895996094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12412/20000], Loss: 823.6854858398438, Entropy 473.57427978515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12413/20000], Loss: 819.7283935546875, Entropy 478.1143493652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12414/20000], Loss: 860.1982421875, Entropy 468.86083984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12415/20000], Loss: 813.0916748046875, Entropy 478.9163818359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12416/20000], Loss: 836.8359375, Entropy 473.894287109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12417/20000], Loss: 797.7803955078125, Entropy 472.3602294921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12418/20000], Loss: 866.8607177734375, Entropy 476.2814636230469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12419/20000], Loss: 838.5376586914062, Entropy 479.67913818359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12420/20000], Loss: 825.7352294921875, Entropy 482.4278869628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12421/20000], Loss: 852.2646484375, Entropy 482.795654296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12422/20000], Loss: 880.2095947265625, Entropy 466.6731872558594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12423/20000], Loss: 843.063720703125, Entropy 481.6912536621094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12424/20000], Loss: 865.8812255859375, Entropy 476.9393005371094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12425/20000], Loss: 859.1619873046875, Entropy 479.9748229980469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12426/20000], Loss: 850.0943603515625, Entropy 471.59375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12427/20000], Loss: 825.1585693359375, Entropy 470.2649841308594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12428/20000], Loss: 867.4227294921875, Entropy 466.8791198730469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12429/20000], Loss: 879.1875, Entropy 456.0115051269531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12430/20000], Loss: 871.9974975585938, Entropy 461.58514404296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12431/20000], Loss: 827.3186645507812, Entropy 473.65167236328125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12432/20000], Loss: 791.739501953125, Entropy 474.1515808105469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12433/20000], Loss: 797.832763671875, Entropy 475.0696716308594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12434/20000], Loss: 804.4312744140625, Entropy 485.740234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12435/20000], Loss: 859.8094482421875, Entropy 467.5258483886719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12436/20000], Loss: 867.5992431640625, Entropy 475.5911560058594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12437/20000], Loss: 842.8538208007812, Entropy 477.30584716796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12438/20000], Loss: 904.529541015625, Entropy 469.8824462890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12439/20000], Loss: 865.5045776367188, Entropy 475.19097900390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12440/20000], Loss: 861.6180419921875, Entropy 467.2594299316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12441/20000], Loss: 892.77197265625, Entropy 470.2154235839844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12442/20000], Loss: 863.833740234375, Entropy 476.6645202636719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12443/20000], Loss: 835.2540893554688, Entropy 477.01617431640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12444/20000], Loss: 850.3732299804688, Entropy 484.17340087890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12445/20000], Loss: 839.5980224609375, Entropy 465.9450988769531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12446/20000], Loss: 890.373779296875, Entropy 479.1702880859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12447/20000], Loss: 787.9754028320312, Entropy 478.12725830078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12448/20000], Loss: 863.2847900390625, Entropy 462.4411315917969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12449/20000], Loss: 866.7813110351562, Entropy 468.93255615234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12450/20000], Loss: 890.7412719726562, Entropy 460.63287353515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12451/20000], Loss: 856.8365478515625, Entropy 475.2135925292969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12452/20000], Loss: 874.5743408203125, Entropy 466.6633605957031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12453/20000], Loss: 823.1484375, Entropy 473.4800720214844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12454/20000], Loss: 870.73876953125, Entropy 482.60498046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12455/20000], Loss: 813.7628784179688, Entropy 481.91741943359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12456/20000], Loss: 861.5880737304688, Entropy 467.11724853515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12457/20000], Loss: 875.3197631835938, Entropy 476.64447021484375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12458/20000], Loss: 821.923095703125, Entropy 469.9094543457031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12459/20000], Loss: 914.7803955078125, Entropy 459.6734924316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12460/20000], Loss: 844.1192626953125, Entropy 478.7490539550781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12461/20000], Loss: 884.5992431640625, Entropy 458.6954345703125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12462/20000], Loss: 799.4378662109375, Entropy 484.0168762207031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12463/20000], Loss: 889.92578125, Entropy 467.7563171386719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12464/20000], Loss: 837.533203125, Entropy 475.3874816894531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12465/20000], Loss: 821.9581298828125, Entropy 470.1872863769531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12466/20000], Loss: 872.8544921875, Entropy 462.1275634765625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12467/20000], Loss: 861.450927734375, Entropy 458.875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12468/20000], Loss: 848.8033447265625, Entropy 471.0525817871094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12469/20000], Loss: 870.64306640625, Entropy 465.0590515136719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12470/20000], Loss: 880.7552490234375, Entropy 469.6310119628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12471/20000], Loss: 816.857666015625, Entropy 489.0391540527344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12472/20000], Loss: 825.8473510742188, Entropy 481.37164306640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12473/20000], Loss: 875.3484497070312, Entropy 460.92498779296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12474/20000], Loss: 857.268310546875, Entropy 472.931396484375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12475/20000], Loss: 873.51416015625, Entropy 466.5077209472656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12476/20000], Loss: 852.6622314453125, Entropy 481.4424133300781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12477/20000], Loss: 857.1525268554688, Entropy 477.41156005859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12478/20000], Loss: 797.5224609375, Entropy 471.164794921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12479/20000], Loss: 882.1107177734375, Entropy 469.8295593261719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12480/20000], Loss: 859.64013671875, Entropy 465.4832458496094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12481/20000], Loss: 825.704833984375, Entropy 473.6181640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12482/20000], Loss: 875.30859375, Entropy 456.0107727050781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12483/20000], Loss: 819.2727661132812, Entropy 468.41253662109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12484/20000], Loss: 822.7728881835938, Entropy 471.25335693359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12485/20000], Loss: 850.5640258789062, Entropy 476.64483642578125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12486/20000], Loss: 845.1068115234375, Entropy 470.3341369628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12487/20000], Loss: 840.1087646484375, Entropy 467.1766357421875, Learning Rate: 4.8828125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12488/20000], Loss: 834.5623779296875, Entropy 472.9949951171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12489/20000], Loss: 865.6661376953125, Entropy 468.8308410644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12490/20000], Loss: 868.8671875, Entropy 463.9731140136719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12491/20000], Loss: 830.9168701171875, Entropy 464.55712890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12492/20000], Loss: 833.8984375, Entropy 470.2926025390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12493/20000], Loss: 820.686767578125, Entropy 476.5362243652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12494/20000], Loss: 808.699951171875, Entropy 465.45703125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12495/20000], Loss: 845.4622802734375, Entropy 473.9485778808594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12496/20000], Loss: 863.34521484375, Entropy 472.2772521972656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12497/20000], Loss: 864.216064453125, Entropy 470.8248596191406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12498/20000], Loss: 848.132080078125, Entropy 472.9284973144531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12499/20000], Loss: 894.117431640625, Entropy 459.1395263671875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12500/20000], Loss: 839.59130859375, Entropy 469.2855224609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12501/20000], Loss: 856.3133544921875, Entropy 468.4541931152344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12502/20000], Loss: 920.2705688476562, Entropy 463.05108642578125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12503/20000], Loss: 879.0711669921875, Entropy 463.334716796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12504/20000], Loss: 846.106689453125, Entropy 474.0344543457031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12505/20000], Loss: 855.9575805664062, Entropy 473.49749755859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12506/20000], Loss: 858.6365966796875, Entropy 466.1837463378906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12507/20000], Loss: 838.5068969726562, Entropy 465.04388427734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12508/20000], Loss: 860.040771484375, Entropy 464.0686340332031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12509/20000], Loss: 793.98779296875, Entropy 481.19921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12510/20000], Loss: 861.38720703125, Entropy 470.4737243652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12511/20000], Loss: 880.470458984375, Entropy 460.5509948730469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12512/20000], Loss: 868.9739990234375, Entropy 472.9554443359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12513/20000], Loss: 882.55322265625, Entropy 458.7470703125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12514/20000], Loss: 868.7408447265625, Entropy 476.5272521972656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12515/20000], Loss: 834.840576171875, Entropy 479.3053283691406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12516/20000], Loss: 884.032958984375, Entropy 462.6070556640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12517/20000], Loss: 856.0311889648438, Entropy 467.45501708984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12518/20000], Loss: 823.4781494140625, Entropy 486.4973449707031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12519/20000], Loss: 826.31640625, Entropy 481.2013854980469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12520/20000], Loss: 849.664794921875, Entropy 472.2931213378906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12521/20000], Loss: 842.6339111328125, Entropy 478.265380859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12522/20000], Loss: 860.9566040039062, Entropy 461.53350830078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12523/20000], Loss: 858.208984375, Entropy 467.0569152832031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12524/20000], Loss: 850.262939453125, Entropy 481.1126403808594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12525/20000], Loss: 796.37353515625, Entropy 473.304443359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12526/20000], Loss: 878.344970703125, Entropy 471.6917724609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12527/20000], Loss: 856.4835205078125, Entropy 470.5186462402344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12528/20000], Loss: 869.9410400390625, Entropy 457.1004333496094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12529/20000], Loss: 879.8189697265625, Entropy 466.6236267089844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12530/20000], Loss: 828.9552612304688, Entropy 474.34466552734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12531/20000], Loss: 871.5664672851562, Entropy 466.07818603515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12532/20000], Loss: 804.1207885742188, Entropy 468.04437255859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12533/20000], Loss: 801.4010009765625, Entropy 473.1996765136719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12534/20000], Loss: 853.50341796875, Entropy 461.5065612792969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12535/20000], Loss: 887.8921508789062, Entropy 482.69647216796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12536/20000], Loss: 872.1537475585938, Entropy 465.74432373046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12537/20000], Loss: 821.67041015625, Entropy 483.3519287109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12538/20000], Loss: 857.989990234375, Entropy 477.3851318359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12539/20000], Loss: 869.5460205078125, Entropy 474.0638427734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12540/20000], Loss: 865.2430419921875, Entropy 460.4656677246094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12541/20000], Loss: 871.3992919921875, Entropy 465.19384765625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12542/20000], Loss: 860.4945678710938, Entropy 463.34576416015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12543/20000], Loss: 841.5962524414062, Entropy 470.33319091796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12544/20000], Loss: 902.4806518554688, Entropy 456.03240966796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12545/20000], Loss: 854.151123046875, Entropy 468.4275817871094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12546/20000], Loss: 880.6917724609375, Entropy 462.3043518066406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12547/20000], Loss: 883.4629516601562, Entropy 464.36761474609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12548/20000], Loss: 869.9241943359375, Entropy 476.1341552734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12549/20000], Loss: 886.2515869140625, Entropy 466.2406005859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12550/20000], Loss: 821.0537109375, Entropy 480.6667785644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12551/20000], Loss: 861.169921875, Entropy 467.1183166503906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12552/20000], Loss: 885.6124267578125, Entropy 448.7058410644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12553/20000], Loss: 832.5023193359375, Entropy 480.1050720214844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12554/20000], Loss: 867.6387939453125, Entropy 470.6737365722656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12555/20000], Loss: 829.6030883789062, Entropy 479.67584228515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12556/20000], Loss: 810.7825927734375, Entropy 482.63525390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12557/20000], Loss: 809.167724609375, Entropy 470.628662109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12558/20000], Loss: 855.3155517578125, Entropy 479.0420837402344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12559/20000], Loss: 817.1236572265625, Entropy 460.1226501464844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12560/20000], Loss: 877.8291015625, Entropy 483.8896789550781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12561/20000], Loss: 833.744384765625, Entropy 473.4495849609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12562/20000], Loss: 851.5152587890625, Entropy 475.1422424316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12563/20000], Loss: 840.7427978515625, Entropy 467.4765625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12564/20000], Loss: 849.5125732421875, Entropy 463.2742919921875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12565/20000], Loss: 895.16796875, Entropy 467.5328674316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12566/20000], Loss: 856.429931640625, Entropy 477.0846252441406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12567/20000], Loss: 865.5936889648438, Entropy 458.93194580078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12568/20000], Loss: 859.4547119140625, Entropy 475.2740173339844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12569/20000], Loss: 837.13525390625, Entropy 468.0494689941406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12570/20000], Loss: 843.9244384765625, Entropy 461.79150390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12571/20000], Loss: 814.1072998046875, Entropy 471.3248291015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12572/20000], Loss: 821.8017578125, Entropy 462.1085205078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12573/20000], Loss: 875.4812622070312, Entropy 464.94622802734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12574/20000], Loss: 872.2489013671875, Entropy 465.4588623046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12575/20000], Loss: 846.736572265625, Entropy 475.5436706542969, Learning Rate: 4.8828125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12576/20000], Loss: 877.0394897460938, Entropy 461.82952880859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12577/20000], Loss: 825.29931640625, Entropy 453.4001770019531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12578/20000], Loss: 843.5099487304688, Entropy 474.95172119140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12579/20000], Loss: 847.1897583007812, Entropy 474.36517333984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12580/20000], Loss: 828.7401733398438, Entropy 467.34136962890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12581/20000], Loss: 834.9351806640625, Entropy 479.74755859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12582/20000], Loss: 798.890380859375, Entropy 473.0895080566406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12583/20000], Loss: 841.9061279296875, Entropy 464.2831115722656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12584/20000], Loss: 861.8297119140625, Entropy 463.1886901855469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12585/20000], Loss: 851.0447387695312, Entropy 467.52301025390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12586/20000], Loss: 828.651123046875, Entropy 463.13818359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12587/20000], Loss: 850.869873046875, Entropy 460.5559997558594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12588/20000], Loss: 832.4132080078125, Entropy 480.3487243652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12589/20000], Loss: 824.5081787109375, Entropy 473.3478088378906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12590/20000], Loss: 879.0826416015625, Entropy 465.4703674316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12591/20000], Loss: 856.4381103515625, Entropy 472.2465515136719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12592/20000], Loss: 872.7111206054688, Entropy 465.18572998046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12593/20000], Loss: 866.1062622070312, Entropy 467.08734130859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12594/20000], Loss: 843.9505615234375, Entropy 472.462890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12595/20000], Loss: 818.3878173828125, Entropy 471.7571716308594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12596/20000], Loss: 848.9066772460938, Entropy 479.66607666015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12597/20000], Loss: 865.35400390625, Entropy 452.8563537597656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12598/20000], Loss: 899.35400390625, Entropy 465.170654296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12599/20000], Loss: 798.618408203125, Entropy 483.3497619628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12600/20000], Loss: 829.2999267578125, Entropy 471.18701171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12601/20000], Loss: 853.32666015625, Entropy 464.6600036621094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12602/20000], Loss: 919.177978515625, Entropy 467.1207275390625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12603/20000], Loss: 840.074951171875, Entropy 476.2059326171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12604/20000], Loss: 821.7041015625, Entropy 468.29833984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12605/20000], Loss: 862.223876953125, Entropy 474.9826354980469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12606/20000], Loss: 828.6415405273438, Entropy 474.20904541015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12607/20000], Loss: 893.2362670898438, Entropy 471.57342529296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12608/20000], Loss: 877.3932495117188, Entropy 469.71697998046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12609/20000], Loss: 869.7488403320312, Entropy 474.92242431640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12610/20000], Loss: 869.85205078125, Entropy 466.8170166015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12611/20000], Loss: 866.8629150390625, Entropy 464.99560546875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12612/20000], Loss: 847.548095703125, Entropy 466.1756896972656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12613/20000], Loss: 929.30517578125, Entropy 463.8379211425781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12614/20000], Loss: 870.1943359375, Entropy 470.6500549316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12615/20000], Loss: 825.9461669921875, Entropy 479.772216796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12616/20000], Loss: 838.7972412109375, Entropy 471.8648681640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12617/20000], Loss: 853.5235595703125, Entropy 473.53076171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12618/20000], Loss: 838.0457763671875, Entropy 462.3355407714844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12619/20000], Loss: 856.3916625976562, Entropy 482.41302490234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12620/20000], Loss: 884.47607421875, Entropy 472.58984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12621/20000], Loss: 837.8466796875, Entropy 469.64208984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12622/20000], Loss: 890.9404296875, Entropy 467.8263244628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12623/20000], Loss: 873.09033203125, Entropy 472.5240478515625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12624/20000], Loss: 900.1973876953125, Entropy 462.3924255371094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12625/20000], Loss: 849.07275390625, Entropy 466.185302734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12626/20000], Loss: 915.9121704101562, Entropy 465.39312744140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12627/20000], Loss: 862.448974609375, Entropy 474.3508605957031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12628/20000], Loss: 843.5826416015625, Entropy 458.5909729003906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12629/20000], Loss: 841.2259521484375, Entropy 484.0674743652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12630/20000], Loss: 845.0418701171875, Entropy 463.7516174316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12631/20000], Loss: 861.7099609375, Entropy 458.3327331542969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12632/20000], Loss: 840.8656005859375, Entropy 469.3284912109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12633/20000], Loss: 855.1885375976562, Entropy 468.08428955078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12634/20000], Loss: 839.447021484375, Entropy 465.5074462890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12635/20000], Loss: 836.848388671875, Entropy 480.1940612792969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12636/20000], Loss: 829.5233154296875, Entropy 479.5018615722656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12637/20000], Loss: 830.2847900390625, Entropy 466.1468505859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12638/20000], Loss: 878.2105102539062, Entropy 471.20147705078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12639/20000], Loss: 859.3267822265625, Entropy 465.0455017089844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12640/20000], Loss: 855.12353515625, Entropy 473.3948974609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12641/20000], Loss: 807.8689575195312, Entropy 482.07720947265625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12642/20000], Loss: 881.1637573242188, Entropy 466.60467529296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12643/20000], Loss: 828.2631225585938, Entropy 470.63177490234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12644/20000], Loss: 856.3017578125, Entropy 482.3606262207031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12645/20000], Loss: 851.536376953125, Entropy 459.3459777832031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12646/20000], Loss: 885.567626953125, Entropy 469.0447998046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12647/20000], Loss: 825.155517578125, Entropy 467.64404296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12648/20000], Loss: 826.1722412109375, Entropy 470.4759216308594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12649/20000], Loss: 846.3273315429688, Entropy 476.95452880859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12650/20000], Loss: 827.28173828125, Entropy 463.6826477050781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12651/20000], Loss: 834.658447265625, Entropy 474.8739013671875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12652/20000], Loss: 871.2510986328125, Entropy 473.816162109375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12653/20000], Loss: 890.164306640625, Entropy 466.4405212402344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12654/20000], Loss: 818.267578125, Entropy 480.9871826171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12655/20000], Loss: 794.72802734375, Entropy 474.0026550292969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12656/20000], Loss: 812.0471801757812, Entropy 471.85015869140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12657/20000], Loss: 801.105712890625, Entropy 481.6091003417969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12658/20000], Loss: 838.3570556640625, Entropy 479.2009582519531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12659/20000], Loss: 876.9586181640625, Entropy 467.2350769042969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12660/20000], Loss: 851.5125122070312, Entropy 474.18841552734375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12661/20000], Loss: 874.5755615234375, Entropy 476.8225402832031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12662/20000], Loss: 815.1944580078125, Entropy 464.5461730957031, Learning Rate: 4.8828125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12663/20000], Loss: 841.836669921875, Entropy 474.355224609375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12664/20000], Loss: 833.70703125, Entropy 478.3404541015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12665/20000], Loss: 826.2276611328125, Entropy 473.634765625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12666/20000], Loss: 845.482421875, Entropy 466.757568359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12667/20000], Loss: 814.48828125, Entropy 475.4107360839844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12668/20000], Loss: 800.5262451171875, Entropy 477.0844421386719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12669/20000], Loss: 884.6419067382812, Entropy 462.02398681640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12670/20000], Loss: 828.7750244140625, Entropy 463.0129699707031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12671/20000], Loss: 855.9967041015625, Entropy 475.9051513671875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12672/20000], Loss: 838.908935546875, Entropy 467.4241638183594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12673/20000], Loss: 838.5052490234375, Entropy 477.087890625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12674/20000], Loss: 872.4962768554688, Entropy 467.99713134765625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12675/20000], Loss: 819.5426635742188, Entropy 463.79132080078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12676/20000], Loss: 882.0491333007812, Entropy 478.88006591796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12677/20000], Loss: 880.161865234375, Entropy 459.1496887207031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12678/20000], Loss: 860.701416015625, Entropy 486.4112243652344, Learning Rate: 4.8828125e-06\n",
      "Epoch [12679/20000], Loss: 825.23291015625, Entropy 474.3294372558594, Learning Rate: 4.8828125e-06\n",
      "Epoch [12680/20000], Loss: 796.1734619140625, Entropy 482.1412658691406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12681/20000], Loss: 807.76904296875, Entropy 469.1374816894531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12682/20000], Loss: 845.0673828125, Entropy 477.3639831542969, Learning Rate: 4.8828125e-06\n",
      "Epoch [12683/20000], Loss: 807.48974609375, Entropy 460.9481201171875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12684/20000], Loss: 898.038330078125, Entropy 466.6578674316406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12685/20000], Loss: 863.6983642578125, Entropy 468.429443359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12686/20000], Loss: 847.44482421875, Entropy 478.0652160644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12687/20000], Loss: 821.6820068359375, Entropy 473.0997619628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12688/20000], Loss: 840.6924438476562, Entropy 471.25286865234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12689/20000], Loss: 830.65673828125, Entropy 480.6896667480469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12690/20000], Loss: 813.261474609375, Entropy 462.0747985839844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12691/20000], Loss: 874.4027099609375, Entropy 476.662841796875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12692/20000], Loss: 837.323486328125, Entropy 487.1996765136719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12693/20000], Loss: 870.810302734375, Entropy 469.8015441894531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12694/20000], Loss: 874.107177734375, Entropy 464.0440673828125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12695/20000], Loss: 873.6591796875, Entropy 471.2684020996094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12696/20000], Loss: 859.7445068359375, Entropy 463.5780029296875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12697/20000], Loss: 821.27392578125, Entropy 463.3137512207031, Learning Rate: 4.8828125e-06\n",
      "Epoch [12698/20000], Loss: 826.7025146484375, Entropy 476.6598205566406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12699/20000], Loss: 893.4984130859375, Entropy 452.9303283691406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12700/20000], Loss: 840.32666015625, Entropy 477.5886535644531, Learning Rate: 4.8828125e-06\n",
      "Epoch [12701/20000], Loss: 855.3754272460938, Entropy 473.73248291015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12702/20000], Loss: 881.866455078125, Entropy 453.8531494140625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12703/20000], Loss: 890.6785888671875, Entropy 471.8826599121094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12704/20000], Loss: 820.7576293945312, Entropy 463.03155517578125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12705/20000], Loss: 846.8931884765625, Entropy 464.1126708984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12706/20000], Loss: 854.8621215820312, Entropy 463.02239990234375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12707/20000], Loss: 819.221435546875, Entropy 475.1856994628906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12708/20000], Loss: 855.0877685546875, Entropy 464.8213195800781, Learning Rate: 4.8828125e-06\n",
      "Epoch [12709/20000], Loss: 871.042724609375, Entropy 472.1476135253906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12710/20000], Loss: 857.696533203125, Entropy 475.3382568359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12711/20000], Loss: 891.2469482421875, Entropy 462.7351989746094, Learning Rate: 4.8828125e-06\n",
      "Epoch [12712/20000], Loss: 865.41455078125, Entropy 477.0258483886719, Learning Rate: 4.8828125e-06\n",
      "Epoch [12713/20000], Loss: 855.8720092773438, Entropy 484.92767333984375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12714/20000], Loss: 881.8472900390625, Entropy 471.6077880859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12715/20000], Loss: 832.925537109375, Entropy 466.5021057128906, Learning Rate: 4.8828125e-06\n",
      "Epoch [12716/20000], Loss: 858.623779296875, Entropy 471.7720947265625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12717/20000], Loss: 861.879638671875, Entropy 469.2545166015625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12718/20000], Loss: 845.7722778320312, Entropy 480.31695556640625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12719/20000], Loss: 887.2183837890625, Entropy 461.4390563964844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12720/20000], Loss: 817.4388427734375, Entropy 484.48046875, Learning Rate: 4.8828125e-06\n",
      "Epoch [12721/20000], Loss: 833.3186645507812, Entropy 473.32354736328125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12722/20000], Loss: 847.501220703125, Entropy 464.7752990722656, Learning Rate: 4.8828125e-06\n",
      "Epoch [12723/20000], Loss: 852.7322998046875, Entropy 474.97265625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12724/20000], Loss: 865.276611328125, Entropy 467.0549011230469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12725/20000], Loss: 834.2611083984375, Entropy 460.632568359375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12726/20000], Loss: 858.3009033203125, Entropy 477.7809143066406, Learning Rate: 4.8828125e-06\n",
      "Epoch [12727/20000], Loss: 845.526611328125, Entropy 466.4996032714844, Learning Rate: 4.8828125e-06\n",
      "Epoch [12728/20000], Loss: 865.5193481445312, Entropy 464.66339111328125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12729/20000], Loss: 903.8699340820312, Entropy 475.23968505859375, Learning Rate: 4.8828125e-06\n",
      "Epoch [12730/20000], Loss: 855.0990600585938, Entropy 467.67486572265625, Learning Rate: 4.8828125e-06\n",
      "Epoch [12731/20000], Loss: 844.364013671875, Entropy 469.3293151855469, Learning Rate: 4.8828125e-06\n",
      "Epoch [12732/20000], Loss: 849.1961059570312, Entropy 476.82257080078125, Learning Rate: 4.8828125e-06\n",
      "Epoch [12733/20000], Loss: 874.41552734375, Entropy 468.3963928222656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12734/20000], Loss: 868.594970703125, Entropy 475.169677734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12735/20000], Loss: 812.2200927734375, Entropy 474.4210510253906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12736/20000], Loss: 844.7314453125, Entropy 470.970703125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12737/20000], Loss: 875.0108642578125, Entropy 468.546630859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12738/20000], Loss: 847.8745727539062, Entropy 475.67620849609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12739/20000], Loss: 881.3826904296875, Entropy 470.23193359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12740/20000], Loss: 850.0584716796875, Entropy 466.2105407714844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12741/20000], Loss: 833.8956298828125, Entropy 474.8483581542969, Learning Rate: 2.44140625e-06\n",
      "Epoch [12742/20000], Loss: 896.73779296875, Entropy 465.5656433105469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12743/20000], Loss: 835.6419677734375, Entropy 478.7588806152344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12744/20000], Loss: 840.1175537109375, Entropy 477.8870849609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12745/20000], Loss: 867.6080322265625, Entropy 462.7152099609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12746/20000], Loss: 828.6553955078125, Entropy 473.4184265136719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12747/20000], Loss: 865.130126953125, Entropy 472.8266296386719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12748/20000], Loss: 864.250244140625, Entropy 470.8692932128906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12749/20000], Loss: 827.3143310546875, Entropy 468.4414978027344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12750/20000], Loss: 852.7449951171875, Entropy 461.8828430175781, Learning Rate: 2.44140625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12751/20000], Loss: 837.6492919921875, Entropy 473.7659912109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12752/20000], Loss: 829.2942504882812, Entropy 462.45050048828125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12753/20000], Loss: 884.1036376953125, Entropy 464.5176696777344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12754/20000], Loss: 845.2838134765625, Entropy 455.2253723144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12755/20000], Loss: 836.5657958984375, Entropy 457.8940124511719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12756/20000], Loss: 863.38671875, Entropy 466.4429931640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12757/20000], Loss: 839.7807006835938, Entropy 487.97650146484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12758/20000], Loss: 829.1295166015625, Entropy 474.4017028808594, Learning Rate: 2.44140625e-06\n",
      "Epoch [12759/20000], Loss: 840.755126953125, Entropy 469.1519470214844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12760/20000], Loss: 873.0152587890625, Entropy 473.1728820800781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12761/20000], Loss: 854.3699951171875, Entropy 463.27685546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12762/20000], Loss: 898.2747192382812, Entropy 457.45843505859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12763/20000], Loss: 892.4056396484375, Entropy 470.6496276855469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12764/20000], Loss: 879.655517578125, Entropy 455.4256896972656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12765/20000], Loss: 906.058837890625, Entropy 473.9793701171875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12766/20000], Loss: 838.1204833984375, Entropy 474.8204040527344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12767/20000], Loss: 838.2801513671875, Entropy 470.6969299316406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12768/20000], Loss: 865.0631103515625, Entropy 479.0463562011719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12769/20000], Loss: 833.528564453125, Entropy 465.6947937011719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12770/20000], Loss: 814.7056884765625, Entropy 479.4949035644531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12771/20000], Loss: 844.1380615234375, Entropy 484.2459411621094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12772/20000], Loss: 864.1483764648438, Entropy 465.24163818359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12773/20000], Loss: 823.36279296875, Entropy 466.4969177246094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12774/20000], Loss: 872.40478515625, Entropy 473.6444396972656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12775/20000], Loss: 889.2049560546875, Entropy 462.5675354003906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12776/20000], Loss: 840.3544921875, Entropy 457.6373291015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12777/20000], Loss: 824.1793823242188, Entropy 476.68658447265625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12778/20000], Loss: 868.2544555664062, Entropy 468.93255615234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12779/20000], Loss: 841.477783203125, Entropy 471.1324157714844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12780/20000], Loss: 836.328125, Entropy 482.9388427734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12781/20000], Loss: 846.4943237304688, Entropy 466.05780029296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12782/20000], Loss: 784.5208740234375, Entropy 471.4650573730469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12783/20000], Loss: 792.8702392578125, Entropy 461.9552307128906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12784/20000], Loss: 814.151611328125, Entropy 474.6296691894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12785/20000], Loss: 843.1561279296875, Entropy 477.1453857421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12786/20000], Loss: 873.1317138671875, Entropy 468.387451171875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12787/20000], Loss: 858.4717407226562, Entropy 469.75640869140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12788/20000], Loss: 861.4754028320312, Entropy 467.17962646484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12789/20000], Loss: 871.0037841796875, Entropy 464.9786071777344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12790/20000], Loss: 847.8419189453125, Entropy 456.5054931640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12791/20000], Loss: 838.6356811523438, Entropy 471.83343505859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12792/20000], Loss: 849.0279541015625, Entropy 477.40185546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12793/20000], Loss: 852.986328125, Entropy 473.3507995605469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12794/20000], Loss: 857.3848876953125, Entropy 472.1670837402344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12795/20000], Loss: 818.330322265625, Entropy 476.6412353515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12796/20000], Loss: 882.8907470703125, Entropy 463.1746826171875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12797/20000], Loss: 869.0431518554688, Entropy 457.86138916015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12798/20000], Loss: 856.089111328125, Entropy 468.3143615722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12799/20000], Loss: 890.885009765625, Entropy 457.1163330078125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12800/20000], Loss: 878.3604736328125, Entropy 486.0513916015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12801/20000], Loss: 825.168701171875, Entropy 478.71826171875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12802/20000], Loss: 817.2908935546875, Entropy 467.4041748046875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12803/20000], Loss: 864.8837890625, Entropy 463.3288269042969, Learning Rate: 2.44140625e-06\n",
      "Epoch [12804/20000], Loss: 846.928466796875, Entropy 466.4453125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12805/20000], Loss: 890.9434204101562, Entropy 473.40277099609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12806/20000], Loss: 831.2724609375, Entropy 470.9495849609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12807/20000], Loss: 844.4013671875, Entropy 468.33984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12808/20000], Loss: 850.5399169921875, Entropy 470.0566711425781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12809/20000], Loss: 834.5306396484375, Entropy 477.7277526855469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12810/20000], Loss: 858.1953125, Entropy 473.7490539550781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12811/20000], Loss: 865.9482421875, Entropy 484.9328918457031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12812/20000], Loss: 876.2962646484375, Entropy 471.2642822265625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12813/20000], Loss: 891.4969482421875, Entropy 473.3324890136719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12814/20000], Loss: 850.7987060546875, Entropy 480.7264404296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12815/20000], Loss: 841.975830078125, Entropy 471.6837463378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12816/20000], Loss: 843.3472900390625, Entropy 471.4263916015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12817/20000], Loss: 849.8599853515625, Entropy 464.6140441894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12818/20000], Loss: 830.4182739257812, Entropy 481.13092041015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12819/20000], Loss: 812.805908203125, Entropy 487.1770324707031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12820/20000], Loss: 842.07421875, Entropy 480.0998229980469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12821/20000], Loss: 853.8594970703125, Entropy 464.1099853515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12822/20000], Loss: 832.9732666015625, Entropy 475.189208984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12823/20000], Loss: 817.4376220703125, Entropy 480.80810546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12824/20000], Loss: 815.6328125, Entropy 474.3724060058594, Learning Rate: 2.44140625e-06\n",
      "Epoch [12825/20000], Loss: 852.453125, Entropy 468.4383239746094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12826/20000], Loss: 823.4725341796875, Entropy 478.2730712890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12827/20000], Loss: 830.0676879882812, Entropy 466.07183837890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12828/20000], Loss: 803.533447265625, Entropy 484.9845275878906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12829/20000], Loss: 862.7700805664062, Entropy 468.14739990234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12830/20000], Loss: 866.1434326171875, Entropy 472.6022033691406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12831/20000], Loss: 829.8819580078125, Entropy 474.8719177246094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12832/20000], Loss: 905.8271484375, Entropy 477.4297180175781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12833/20000], Loss: 846.51025390625, Entropy 473.8972473144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12834/20000], Loss: 860.618408203125, Entropy 468.9080505371094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12835/20000], Loss: 876.2942504882812, Entropy 477.35882568359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12836/20000], Loss: 854.567138671875, Entropy 478.5438232421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12837/20000], Loss: 840.1572265625, Entropy 474.7718505859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12838/20000], Loss: 836.6807861328125, Entropy 461.4978332519531, Learning Rate: 2.44140625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12839/20000], Loss: 869.9093017578125, Entropy 465.3819274902344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12840/20000], Loss: 873.2363891601562, Entropy 463.23150634765625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12841/20000], Loss: 866.4332275390625, Entropy 460.5060729980469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12842/20000], Loss: 871.200439453125, Entropy 467.9978332519531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12843/20000], Loss: 861.7747802734375, Entropy 475.376708984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12844/20000], Loss: 869.3231201171875, Entropy 461.0464782714844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12845/20000], Loss: 844.749755859375, Entropy 466.0672607421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12846/20000], Loss: 839.8384399414062, Entropy 463.60638427734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12847/20000], Loss: 854.3462524414062, Entropy 473.54107666015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12848/20000], Loss: 861.84521484375, Entropy 467.170654296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12849/20000], Loss: 878.6559448242188, Entropy 464.35601806640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12850/20000], Loss: 844.9478759765625, Entropy 478.5445861816406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12851/20000], Loss: 851.746337890625, Entropy 465.4620666503906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12852/20000], Loss: 905.7724609375, Entropy 468.8531799316406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12853/20000], Loss: 899.9305419921875, Entropy 463.4338073730469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12854/20000], Loss: 829.510009765625, Entropy 472.3589782714844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12855/20000], Loss: 836.6785888671875, Entropy 471.9404602050781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12856/20000], Loss: 865.816162109375, Entropy 472.5057373046875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12857/20000], Loss: 879.4758911132812, Entropy 469.34661865234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12858/20000], Loss: 836.951416015625, Entropy 465.0680847167969, Learning Rate: 2.44140625e-06\n",
      "Epoch [12859/20000], Loss: 848.6837158203125, Entropy 483.7464599609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12860/20000], Loss: 852.462890625, Entropy 472.5376892089844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12861/20000], Loss: 849.7932739257812, Entropy 470.76080322265625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12862/20000], Loss: 820.13232421875, Entropy 477.9061279296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12863/20000], Loss: 828.1202392578125, Entropy 474.0439758300781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12864/20000], Loss: 869.5111083984375, Entropy 460.8616943359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12865/20000], Loss: 892.0475463867188, Entropy 455.34661865234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12866/20000], Loss: 891.518798828125, Entropy 465.4645080566406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12867/20000], Loss: 879.5547485351562, Entropy 451.40740966796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12868/20000], Loss: 849.7735595703125, Entropy 481.6140441894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12869/20000], Loss: 837.3780517578125, Entropy 466.9251403808594, Learning Rate: 2.44140625e-06\n",
      "Epoch [12870/20000], Loss: 868.3479614257812, Entropy 467.94476318359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12871/20000], Loss: 853.2155151367188, Entropy 476.31854248046875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12872/20000], Loss: 933.7821044921875, Entropy 463.73974609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12873/20000], Loss: 860.1658325195312, Entropy 459.45526123046875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12874/20000], Loss: 872.968994140625, Entropy 477.974365234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12875/20000], Loss: 876.7408447265625, Entropy 471.6300354003906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12876/20000], Loss: 795.1022338867188, Entropy 470.92901611328125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12877/20000], Loss: 849.9356689453125, Entropy 467.76708984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12878/20000], Loss: 849.35888671875, Entropy 482.8508605957031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12879/20000], Loss: 822.4259033203125, Entropy 469.2473449707031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12880/20000], Loss: 884.0294189453125, Entropy 467.37353515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12881/20000], Loss: 854.7724609375, Entropy 460.1003723144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12882/20000], Loss: 831.591064453125, Entropy 481.5451965332031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12883/20000], Loss: 872.6224365234375, Entropy 456.3961486816406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12884/20000], Loss: 837.4239501953125, Entropy 481.8881530761719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12885/20000], Loss: 826.216064453125, Entropy 453.56005859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12886/20000], Loss: 834.4298095703125, Entropy 466.1556091308594, Learning Rate: 2.44140625e-06\n",
      "Epoch [12887/20000], Loss: 848.4827880859375, Entropy 468.2579040527344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12888/20000], Loss: 906.3196411132812, Entropy 459.10162353515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12889/20000], Loss: 843.1408081054688, Entropy 477.78741455078125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12890/20000], Loss: 863.1102294921875, Entropy 475.9352111816406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12891/20000], Loss: 895.4959716796875, Entropy 470.5185852050781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12892/20000], Loss: 887.2235717773438, Entropy 474.27581787109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12893/20000], Loss: 887.0767822265625, Entropy 468.7384338378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12894/20000], Loss: 814.4471435546875, Entropy 476.0955505371094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12895/20000], Loss: 847.9622802734375, Entropy 471.02294921875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12896/20000], Loss: 840.3603515625, Entropy 470.107421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12897/20000], Loss: 875.232421875, Entropy 474.7882385253906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12898/20000], Loss: 823.29150390625, Entropy 473.9832763671875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12899/20000], Loss: 847.458984375, Entropy 478.0449523925781, Learning Rate: 2.44140625e-06\n",
      "Epoch [12900/20000], Loss: 845.7940673828125, Entropy 467.6037902832031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12901/20000], Loss: 850.947998046875, Entropy 472.6878662109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12902/20000], Loss: 855.5933837890625, Entropy 472.4122619628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12903/20000], Loss: 819.415771484375, Entropy 471.2857666015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12904/20000], Loss: 876.8509521484375, Entropy 468.078125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12905/20000], Loss: 836.43310546875, Entropy 468.6343688964844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12906/20000], Loss: 852.832763671875, Entropy 472.990966796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12907/20000], Loss: 861.1978759765625, Entropy 472.8556213378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12908/20000], Loss: 880.4332275390625, Entropy 471.8805236816406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12909/20000], Loss: 810.9081420898438, Entropy 474.69427490234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12910/20000], Loss: 845.0029907226562, Entropy 471.24163818359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12911/20000], Loss: 839.765380859375, Entropy 475.128662109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12912/20000], Loss: 844.701904296875, Entropy 472.4241943359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12913/20000], Loss: 880.3782958984375, Entropy 468.728515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12914/20000], Loss: 874.3128051757812, Entropy 477.03179931640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12915/20000], Loss: 843.9361572265625, Entropy 467.322265625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12916/20000], Loss: 836.3532104492188, Entropy 466.96099853515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12917/20000], Loss: 844.1832275390625, Entropy 472.0691223144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12918/20000], Loss: 839.2838134765625, Entropy 471.5462341308594, Learning Rate: 2.44140625e-06\n",
      "Epoch [12919/20000], Loss: 830.8765869140625, Entropy 478.9328918457031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12920/20000], Loss: 842.5310668945312, Entropy 470.11614990234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12921/20000], Loss: 873.603759765625, Entropy 474.5850524902344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12922/20000], Loss: 817.3697509765625, Entropy 467.4200744628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12923/20000], Loss: 846.5482177734375, Entropy 487.7980041503906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12924/20000], Loss: 807.668212890625, Entropy 476.3891296386719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12925/20000], Loss: 828.0039672851562, Entropy 471.18646240234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12926/20000], Loss: 876.61328125, Entropy 466.7493896484375, Learning Rate: 2.44140625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12927/20000], Loss: 852.9339599609375, Entropy 472.0038146972656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12928/20000], Loss: 888.0238037109375, Entropy 492.021484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12929/20000], Loss: 827.9733276367188, Entropy 469.09710693359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12930/20000], Loss: 848.6357421875, Entropy 457.3502502441406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12931/20000], Loss: 814.1179809570312, Entropy 474.45123291015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12932/20000], Loss: 848.1875, Entropy 470.7652282714844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12933/20000], Loss: 846.5629272460938, Entropy 472.49078369140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12934/20000], Loss: 867.0908813476562, Entropy 472.76483154296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12935/20000], Loss: 915.3612060546875, Entropy 472.81591796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12936/20000], Loss: 815.6499633789062, Entropy 474.41021728515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12937/20000], Loss: 810.9987182617188, Entropy 469.56927490234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12938/20000], Loss: 810.5588989257812, Entropy 479.82904052734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12939/20000], Loss: 855.6756591796875, Entropy 460.0671691894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12940/20000], Loss: 862.9488525390625, Entropy 477.5467224121094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12941/20000], Loss: 818.3642578125, Entropy 473.6677551269531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12942/20000], Loss: 803.6568603515625, Entropy 474.5099792480469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12943/20000], Loss: 868.4249267578125, Entropy 470.2044372558594, Learning Rate: 2.44140625e-06\n",
      "Epoch [12944/20000], Loss: 816.3707275390625, Entropy 474.3434143066406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12945/20000], Loss: 835.5802001953125, Entropy 479.3077087402344, Learning Rate: 2.44140625e-06\n",
      "Epoch [12946/20000], Loss: 831.9820556640625, Entropy 475.2062072753906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12947/20000], Loss: 848.8555908203125, Entropy 466.5124816894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12948/20000], Loss: 839.2249755859375, Entropy 470.0032958984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12949/20000], Loss: 836.75390625, Entropy 479.042724609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12950/20000], Loss: 829.3709716796875, Entropy 473.2366027832031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12951/20000], Loss: 855.8681640625, Entropy 475.4755859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12952/20000], Loss: 843.5617065429688, Entropy 480.45013427734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12953/20000], Loss: 829.0584716796875, Entropy 469.1900634765625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12954/20000], Loss: 831.957763671875, Entropy 480.9256591796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12955/20000], Loss: 822.15234375, Entropy 476.7655334472656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12956/20000], Loss: 854.7305908203125, Entropy 475.9909973144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12957/20000], Loss: 837.5712890625, Entropy 494.8624572753906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12958/20000], Loss: 838.3990478515625, Entropy 480.7956237792969, Learning Rate: 2.44140625e-06\n",
      "Epoch [12959/20000], Loss: 804.5095825195312, Entropy 474.40350341796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12960/20000], Loss: 821.09033203125, Entropy 476.234130859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12961/20000], Loss: 864.7860107421875, Entropy 466.3746643066406, Learning Rate: 2.44140625e-06\n",
      "Epoch [12962/20000], Loss: 806.5445556640625, Entropy 478.6837463378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [12963/20000], Loss: 831.4862060546875, Entropy 474.1021728515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12964/20000], Loss: 856.13330078125, Entropy 474.85693359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12965/20000], Loss: 827.0538940429688, Entropy 477.59393310546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12966/20000], Loss: 854.769775390625, Entropy 474.0686340332031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12967/20000], Loss: 889.0221557617188, Entropy 459.96624755859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12968/20000], Loss: 838.018310546875, Entropy 476.2674865722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12969/20000], Loss: 829.643310546875, Entropy 462.8425598144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12970/20000], Loss: 873.6822509765625, Entropy 476.9154968261719, Learning Rate: 2.44140625e-06\n",
      "Epoch [12971/20000], Loss: 813.2699584960938, Entropy 476.45562744140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12972/20000], Loss: 836.453369140625, Entropy 481.6550598144531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12973/20000], Loss: 849.0740966796875, Entropy 469.247802734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12974/20000], Loss: 844.3782958984375, Entropy 475.4627990722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12975/20000], Loss: 820.9708251953125, Entropy 469.4862365722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [12976/20000], Loss: 870.5930786132812, Entropy 461.24237060546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12977/20000], Loss: 825.26904296875, Entropy 463.0132751464844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12978/20000], Loss: 871.4026489257812, Entropy 487.31195068359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12979/20000], Loss: 893.468994140625, Entropy 479.3212890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12980/20000], Loss: 828.9013671875, Entropy 477.609130859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12981/20000], Loss: 807.521484375, Entropy 469.3810729980469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12982/20000], Loss: 870.6130981445312, Entropy 488.39752197265625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12983/20000], Loss: 838.519287109375, Entropy 464.2643737792969, Learning Rate: 2.44140625e-06\n",
      "Epoch [12984/20000], Loss: 825.8605346679688, Entropy 474.33831787109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12985/20000], Loss: 829.8336791992188, Entropy 478.61041259765625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12986/20000], Loss: 821.2513427734375, Entropy 468.1624755859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12987/20000], Loss: 829.125, Entropy 468.3625183105469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12988/20000], Loss: 902.853515625, Entropy 468.7815246582031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12989/20000], Loss: 815.003173828125, Entropy 469.4412536621094, Learning Rate: 2.44140625e-06\n",
      "Epoch [12990/20000], Loss: 825.945556640625, Entropy 473.09619140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [12991/20000], Loss: 867.41357421875, Entropy 463.643310546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12992/20000], Loss: 876.4671630859375, Entropy 456.1893310546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [12993/20000], Loss: 846.7529907226562, Entropy 472.07257080078125, Learning Rate: 2.44140625e-06\n",
      "Epoch [12994/20000], Loss: 824.849609375, Entropy 460.8015441894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [12995/20000], Loss: 845.1766357421875, Entropy 464.9173583984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [12996/20000], Loss: 860.4827880859375, Entropy 473.3765563964844, Learning Rate: 2.44140625e-06\n",
      "Epoch [12997/20000], Loss: 848.1383056640625, Entropy 471.6067199707031, Learning Rate: 2.44140625e-06\n",
      "Epoch [12998/20000], Loss: 840.71435546875, Entropy 475.2424011230469, Learning Rate: 2.44140625e-06\n",
      "Epoch [12999/20000], Loss: 823.2719116210938, Entropy 470.51666259765625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13000/20000], Loss: 834.642822265625, Entropy 478.2115173339844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13001/20000], Loss: 830.407958984375, Entropy 500.7958068847656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13002/20000], Loss: 861.0449829101562, Entropy 475.61749267578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13003/20000], Loss: 793.5859375, Entropy 473.9223327636719, Learning Rate: 2.44140625e-06\n",
      "Epoch [13004/20000], Loss: 863.2406005859375, Entropy 459.7752990722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13005/20000], Loss: 850.455078125, Entropy 479.5828857421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13006/20000], Loss: 866.541259765625, Entropy 469.0911560058594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13007/20000], Loss: 819.5230102539062, Entropy 470.47576904296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13008/20000], Loss: 835.1805419921875, Entropy 460.9179992675781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13009/20000], Loss: 821.9400024414062, Entropy 476.94476318359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13010/20000], Loss: 845.6781005859375, Entropy 472.88916015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13011/20000], Loss: 805.539794921875, Entropy 483.7819519042969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13012/20000], Loss: 843.4428100585938, Entropy 479.80877685546875, Learning Rate: 2.44140625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13013/20000], Loss: 800.0870361328125, Entropy 482.4137268066406, Learning Rate: 2.44140625e-06\n",
      "Epoch [13014/20000], Loss: 871.2876586914062, Entropy 466.84075927734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13015/20000], Loss: 808.1258544921875, Entropy 455.8029479980469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13016/20000], Loss: 836.9298706054688, Entropy 474.36138916015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13017/20000], Loss: 892.448974609375, Entropy 451.796630859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13018/20000], Loss: 895.8280639648438, Entropy 453.49017333984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13019/20000], Loss: 851.81005859375, Entropy 480.4295349121094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13020/20000], Loss: 833.16943359375, Entropy 459.3690185546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13021/20000], Loss: 840.763427734375, Entropy 472.5130310058594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13022/20000], Loss: 848.5126953125, Entropy 472.6173400878906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13023/20000], Loss: 881.99072265625, Entropy 454.4010925292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13024/20000], Loss: 808.5562744140625, Entropy 464.6311340332031, Learning Rate: 2.44140625e-06\n",
      "Epoch [13025/20000], Loss: 857.751708984375, Entropy 470.7741394042969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13026/20000], Loss: 867.6309204101562, Entropy 456.66619873046875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13027/20000], Loss: 877.3756713867188, Entropy 455.02935791015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13028/20000], Loss: 853.574462890625, Entropy 466.5026550292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13029/20000], Loss: 826.8553466796875, Entropy 476.2013244628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13030/20000], Loss: 828.068115234375, Entropy 495.6170959472656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13031/20000], Loss: 832.3388671875, Entropy 477.37060546875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13032/20000], Loss: 845.2017822265625, Entropy 462.9532775878906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13033/20000], Loss: 857.7012329101562, Entropy 469.81060791015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13034/20000], Loss: 816.4716796875, Entropy 474.7398681640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13035/20000], Loss: 856.079833984375, Entropy 479.9151306152344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13036/20000], Loss: 853.7263793945312, Entropy 487.16107177734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13037/20000], Loss: 869.1510009765625, Entropy 465.6092224121094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13038/20000], Loss: 925.9862670898438, Entropy 468.22686767578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13039/20000], Loss: 837.4356079101562, Entropy 484.32904052734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13040/20000], Loss: 883.3587646484375, Entropy 461.5040588378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13041/20000], Loss: 908.2769775390625, Entropy 463.3956298828125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13042/20000], Loss: 863.5738525390625, Entropy 461.8334655761719, Learning Rate: 2.44140625e-06\n",
      "Epoch [13043/20000], Loss: 851.62060546875, Entropy 467.11767578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13044/20000], Loss: 849.9786376953125, Entropy 466.2232971191406, Learning Rate: 2.44140625e-06\n",
      "Epoch [13045/20000], Loss: 849.851806640625, Entropy 464.3556823730469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13046/20000], Loss: 856.07080078125, Entropy 468.8610534667969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13047/20000], Loss: 830.8482055664062, Entropy 465.42498779296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13048/20000], Loss: 802.8819580078125, Entropy 485.0097961425781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13049/20000], Loss: 825.5059814453125, Entropy 479.0085754394531, Learning Rate: 2.44140625e-06\n",
      "Epoch [13050/20000], Loss: 873.9368286132812, Entropy 470.02093505859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13051/20000], Loss: 844.6749267578125, Entropy 477.78125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13052/20000], Loss: 869.6036987304688, Entropy 473.10406494140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13053/20000], Loss: 880.2548828125, Entropy 456.8215637207031, Learning Rate: 2.44140625e-06\n",
      "Epoch [13054/20000], Loss: 843.4893798828125, Entropy 464.6519470214844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13055/20000], Loss: 801.9263916015625, Entropy 481.2228698730469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13056/20000], Loss: 889.8360595703125, Entropy 460.6197509765625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13057/20000], Loss: 849.9282836914062, Entropy 474.57232666015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13058/20000], Loss: 809.105712890625, Entropy 475.7998962402344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13059/20000], Loss: 829.165771484375, Entropy 476.3927917480469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13060/20000], Loss: 822.5601806640625, Entropy 473.872802734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13061/20000], Loss: 844.371826171875, Entropy 472.0704040527344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13062/20000], Loss: 889.2880859375, Entropy 447.1056213378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13063/20000], Loss: 829.1033935546875, Entropy 480.59521484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13064/20000], Loss: 852.2854614257812, Entropy 476.84320068359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13065/20000], Loss: 884.3399658203125, Entropy 468.8475646972656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13066/20000], Loss: 850.462646484375, Entropy 473.5570068359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13067/20000], Loss: 856.50390625, Entropy 472.2610778808594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13068/20000], Loss: 841.9059448242188, Entropy 481.26165771484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13069/20000], Loss: 876.7996826171875, Entropy 451.9455261230469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13070/20000], Loss: 824.208251953125, Entropy 463.2673645019531, Learning Rate: 2.44140625e-06\n",
      "Epoch [13071/20000], Loss: 861.3604125976562, Entropy 465.15765380859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13072/20000], Loss: 821.2423095703125, Entropy 469.3743896484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13073/20000], Loss: 860.0516357421875, Entropy 466.3057556152344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13074/20000], Loss: 843.9136962890625, Entropy 465.9651794433594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13075/20000], Loss: 873.69189453125, Entropy 470.0018005371094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13076/20000], Loss: 840.5162963867188, Entropy 471.10601806640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13077/20000], Loss: 818.2036743164062, Entropy 465.09405517578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13078/20000], Loss: 801.98974609375, Entropy 479.613037109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13079/20000], Loss: 885.9434814453125, Entropy 449.4471740722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13080/20000], Loss: 880.1612548828125, Entropy 478.4411926269531, Learning Rate: 2.44140625e-06\n",
      "Epoch [13081/20000], Loss: 873.0874633789062, Entropy 484.10345458984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13082/20000], Loss: 883.9384765625, Entropy 474.2574462890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13083/20000], Loss: 861.86669921875, Entropy 475.3101806640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13084/20000], Loss: 860.39697265625, Entropy 467.441162109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13085/20000], Loss: 825.641357421875, Entropy 472.0399169921875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13086/20000], Loss: 865.3123779296875, Entropy 478.695068359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13087/20000], Loss: 851.8428955078125, Entropy 479.9644470214844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13088/20000], Loss: 840.2124633789062, Entropy 470.11968994140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13089/20000], Loss: 854.63818359375, Entropy 474.01611328125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13090/20000], Loss: 860.8019409179688, Entropy 462.66400146484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13091/20000], Loss: 824.6036987304688, Entropy 474.29608154296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13092/20000], Loss: 819.5263671875, Entropy 477.3510437011719, Learning Rate: 2.44140625e-06\n",
      "Epoch [13093/20000], Loss: 857.2704467773438, Entropy 475.92608642578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13094/20000], Loss: 819.160888671875, Entropy 465.4422912597656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13095/20000], Loss: 893.2708129882812, Entropy 453.70074462890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13096/20000], Loss: 913.1481323242188, Entropy 463.78375244140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13097/20000], Loss: 824.8812866210938, Entropy 468.35552978515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13098/20000], Loss: 856.1859130859375, Entropy 462.4432067871094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13099/20000], Loss: 878.635498046875, Entropy 475.406005859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13100/20000], Loss: 831.233642578125, Entropy 473.9781799316406, Learning Rate: 2.44140625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13101/20000], Loss: 840.39306640625, Entropy 465.8327941894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [13102/20000], Loss: 842.0994873046875, Entropy 469.5104675292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13103/20000], Loss: 820.712890625, Entropy 477.4402770996094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13104/20000], Loss: 863.9892578125, Entropy 465.8747253417969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13105/20000], Loss: 871.5086669921875, Entropy 477.6519775390625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13106/20000], Loss: 889.8856201171875, Entropy 461.8807067871094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13107/20000], Loss: 896.9385375976562, Entropy 482.53546142578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13108/20000], Loss: 828.4362182617188, Entropy 470.35162353515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13109/20000], Loss: 833.410888671875, Entropy 473.7127990722656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13110/20000], Loss: 865.7000732421875, Entropy 471.7945251464844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13111/20000], Loss: 794.640869140625, Entropy 469.1283874511719, Learning Rate: 2.44140625e-06\n",
      "Epoch [13112/20000], Loss: 835.1986083984375, Entropy 461.1373291015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13113/20000], Loss: 815.9351806640625, Entropy 483.4020690917969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13114/20000], Loss: 865.653564453125, Entropy 469.6335144042969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13115/20000], Loss: 825.7734985351562, Entropy 465.56695556640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13116/20000], Loss: 880.762939453125, Entropy 473.2716369628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13117/20000], Loss: 853.3438720703125, Entropy 465.68701171875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13118/20000], Loss: 826.603759765625, Entropy 462.2330322265625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13119/20000], Loss: 834.094482421875, Entropy 466.2984924316406, Learning Rate: 2.44140625e-06\n",
      "Epoch [13120/20000], Loss: 864.236572265625, Entropy 477.4709167480469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13121/20000], Loss: 866.2872924804688, Entropy 464.90264892578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13122/20000], Loss: 844.4603271484375, Entropy 461.7464599609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13123/20000], Loss: 840.8372802734375, Entropy 470.6319274902344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13124/20000], Loss: 831.341064453125, Entropy 492.96240234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13125/20000], Loss: 870.626220703125, Entropy 468.4649963378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13126/20000], Loss: 824.2608642578125, Entropy 468.68359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13127/20000], Loss: 823.0742797851562, Entropy 470.02532958984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13128/20000], Loss: 850.1341552734375, Entropy 466.8670959472656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13129/20000], Loss: 869.0728759765625, Entropy 474.6405334472656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13130/20000], Loss: 829.0224609375, Entropy 469.00537109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13131/20000], Loss: 834.2715454101562, Entropy 470.96087646484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13132/20000], Loss: 853.8797607421875, Entropy 462.5120849609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13133/20000], Loss: 844.895263671875, Entropy 467.5997619628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13134/20000], Loss: 849.1301879882812, Entropy 462.48553466796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13135/20000], Loss: 797.2308349609375, Entropy 466.4739685058594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13136/20000], Loss: 853.6251220703125, Entropy 481.2255859375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13137/20000], Loss: 840.971923828125, Entropy 476.8753662109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13138/20000], Loss: 869.4638671875, Entropy 464.845458984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13139/20000], Loss: 882.692626953125, Entropy 475.46484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13140/20000], Loss: 850.2869873046875, Entropy 479.5841369628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13141/20000], Loss: 843.154052734375, Entropy 476.4845886230469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13142/20000], Loss: 885.273193359375, Entropy 481.2741394042969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13143/20000], Loss: 871.3742065429688, Entropy 480.40948486328125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13144/20000], Loss: 824.7586059570312, Entropy 469.84686279296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13145/20000], Loss: 824.5382080078125, Entropy 466.6707763671875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13146/20000], Loss: 840.6937255859375, Entropy 471.4474792480469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13147/20000], Loss: 828.5568237304688, Entropy 461.83905029296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13148/20000], Loss: 865.777587890625, Entropy 463.9981994628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13149/20000], Loss: 885.8740234375, Entropy 462.7728271484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13150/20000], Loss: 826.1298828125, Entropy 469.97119140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13151/20000], Loss: 856.556396484375, Entropy 468.4725646972656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13152/20000], Loss: 882.2821044921875, Entropy 447.6437072753906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13153/20000], Loss: 858.4283447265625, Entropy 464.1447448730469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13154/20000], Loss: 880.8490600585938, Entropy 445.90179443359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13155/20000], Loss: 826.7401123046875, Entropy 473.4482727050781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13156/20000], Loss: 875.5443115234375, Entropy 476.7586975097656, Learning Rate: 2.44140625e-06\n",
      "Epoch [13157/20000], Loss: 823.1988525390625, Entropy 480.5555419921875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13158/20000], Loss: 822.6116943359375, Entropy 464.2904052734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13159/20000], Loss: 848.5343017578125, Entropy 467.4759216308594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13160/20000], Loss: 865.5289306640625, Entropy 472.0359802246094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13161/20000], Loss: 811.687744140625, Entropy 471.3133544921875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13162/20000], Loss: 897.6116333007812, Entropy 466.63726806640625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13163/20000], Loss: 896.8548583984375, Entropy 476.7101135253906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13164/20000], Loss: 876.87255859375, Entropy 461.2964782714844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13165/20000], Loss: 858.788330078125, Entropy 469.9840087890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13166/20000], Loss: 854.9931640625, Entropy 464.5002746582031, Learning Rate: 2.44140625e-06\n",
      "Epoch [13167/20000], Loss: 862.5922241210938, Entropy 484.48358154296875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13168/20000], Loss: 827.1697387695312, Entropy 477.77276611328125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13169/20000], Loss: 828.6010131835938, Entropy 484.52459716796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13170/20000], Loss: 814.831298828125, Entropy 465.3538818359375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13171/20000], Loss: 848.8815307617188, Entropy 482.66143798828125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13172/20000], Loss: 846.536376953125, Entropy 473.4996337890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13173/20000], Loss: 850.6494750976562, Entropy 462.25982666015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13174/20000], Loss: 844.5262451171875, Entropy 468.9368591308594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13175/20000], Loss: 852.566650390625, Entropy 491.6266784667969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13176/20000], Loss: 896.1085815429688, Entropy 462.40325927734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13177/20000], Loss: 890.203857421875, Entropy 470.9792175292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13178/20000], Loss: 841.5572509765625, Entropy 456.3478088378906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13179/20000], Loss: 821.199951171875, Entropy 452.3257751464844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13180/20000], Loss: 867.1055908203125, Entropy 464.5501403808594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13181/20000], Loss: 835.005615234375, Entropy 478.9591979980469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13182/20000], Loss: 886.657470703125, Entropy 461.14013671875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13183/20000], Loss: 885.5980224609375, Entropy 475.7047424316406, Learning Rate: 2.44140625e-06\n",
      "Epoch [13184/20000], Loss: 828.3284912109375, Entropy 475.0715637207031, Learning Rate: 2.44140625e-06\n",
      "Epoch [13185/20000], Loss: 842.512451171875, Entropy 483.5224914550781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13186/20000], Loss: 866.8138427734375, Entropy 474.6343688964844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13187/20000], Loss: 808.218505859375, Entropy 491.2959899902344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13188/20000], Loss: 816.6053466796875, Entropy 476.3543395996094, Learning Rate: 2.44140625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13189/20000], Loss: 850.7999267578125, Entropy 478.808349609375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13190/20000], Loss: 830.00537109375, Entropy 467.1802673339844, Learning Rate: 2.44140625e-06\n",
      "Epoch [13191/20000], Loss: 856.6414184570312, Entropy 471.28118896484375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13192/20000], Loss: 824.49609375, Entropy 476.0202331542969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13193/20000], Loss: 877.9083251953125, Entropy 480.2057800292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13194/20000], Loss: 887.8478393554688, Entropy 471.14459228515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13195/20000], Loss: 874.25, Entropy 473.7990417480469, Learning Rate: 2.44140625e-06\n",
      "Epoch [13196/20000], Loss: 833.9995727539062, Entropy 474.87786865234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13197/20000], Loss: 852.56787109375, Entropy 464.9131164550781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13198/20000], Loss: 821.0311279296875, Entropy 473.5129699707031, Learning Rate: 2.44140625e-06\n",
      "Epoch [13199/20000], Loss: 842.9654541015625, Entropy 479.0685119628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13200/20000], Loss: 847.1011962890625, Entropy 471.5478820800781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13201/20000], Loss: 823.4047241210938, Entropy 484.96185302734375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13202/20000], Loss: 866.0300903320312, Entropy 480.49334716796875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13203/20000], Loss: 844.7698974609375, Entropy 472.156982421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13204/20000], Loss: 847.6343994140625, Entropy 454.3797607421875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13205/20000], Loss: 904.5928955078125, Entropy 469.6767883300781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13206/20000], Loss: 890.1578369140625, Entropy 481.6140441894531, Learning Rate: 2.44140625e-06\n",
      "Epoch [13207/20000], Loss: 884.8671875, Entropy 477.6162109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13208/20000], Loss: 859.950439453125, Entropy 464.9323425292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13209/20000], Loss: 858.2559814453125, Entropy 474.4980773925781, Learning Rate: 2.44140625e-06\n",
      "Epoch [13210/20000], Loss: 865.24169921875, Entropy 478.3957824707031, Learning Rate: 2.44140625e-06\n",
      "Epoch [13211/20000], Loss: 831.371337890625, Entropy 488.7839660644531, Learning Rate: 2.44140625e-06\n",
      "Epoch [13212/20000], Loss: 814.140380859375, Entropy 484.1856994628906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13213/20000], Loss: 836.7788696289062, Entropy 469.87347412109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13214/20000], Loss: 898.503662109375, Entropy 470.23046875, Learning Rate: 2.44140625e-06\n",
      "Epoch [13215/20000], Loss: 818.2939453125, Entropy 455.661865234375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13216/20000], Loss: 885.7088623046875, Entropy 470.28515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13217/20000], Loss: 877.184326171875, Entropy 471.6253662109375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13218/20000], Loss: 878.8847045898438, Entropy 462.45025634765625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13219/20000], Loss: 838.8587036132812, Entropy 480.35577392578125, Learning Rate: 2.44140625e-06\n",
      "Epoch [13220/20000], Loss: 880.32275390625, Entropy 467.3741149902344, Learning Rate: 2.44140625e-06\n",
      "Epoch [13221/20000], Loss: 859.947021484375, Entropy 472.9923400878906, Learning Rate: 2.44140625e-06\n",
      "Epoch [13222/20000], Loss: 841.1813354492188, Entropy 462.14642333984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13223/20000], Loss: 806.707275390625, Entropy 466.17333984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13224/20000], Loss: 836.8587646484375, Entropy 462.470458984375, Learning Rate: 2.44140625e-06\n",
      "Epoch [13225/20000], Loss: 831.7291259765625, Entropy 473.8455505371094, Learning Rate: 2.44140625e-06\n",
      "Epoch [13226/20000], Loss: 870.8701171875, Entropy 461.0484619140625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13227/20000], Loss: 811.6221923828125, Entropy 468.96337890625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13228/20000], Loss: 887.9129638671875, Entropy 470.7076416015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13229/20000], Loss: 826.3632202148438, Entropy 471.51568603515625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13230/20000], Loss: 875.4363403320312, Entropy 463.44342041015625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13231/20000], Loss: 901.082275390625, Entropy 466.6243591308594, Learning Rate: 2.44140625e-06\n",
      "Epoch [13232/20000], Loss: 875.895751953125, Entropy 476.9870300292969, Learning Rate: 2.44140625e-06\n",
      "Epoch [13233/20000], Loss: 876.1554565429688, Entropy 459.37457275390625, Learning Rate: 2.44140625e-06\n",
      "Epoch [13234/20000], Loss: 812.180419921875, Entropy 471.8741149902344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13235/20000], Loss: 873.7216796875, Entropy 471.5365905761719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13236/20000], Loss: 883.1595458984375, Entropy 461.3957824707031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13237/20000], Loss: 883.653076171875, Entropy 456.1731262207031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13238/20000], Loss: 836.5782470703125, Entropy 473.9757995605469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13239/20000], Loss: 792.8333740234375, Entropy 481.3305358886719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13240/20000], Loss: 840.8995971679688, Entropy 470.82769775390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13241/20000], Loss: 873.867919921875, Entropy 458.4261474609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13242/20000], Loss: 934.4218139648438, Entropy 473.85662841796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13243/20000], Loss: 826.1593017578125, Entropy 475.7450256347656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13244/20000], Loss: 830.3470458984375, Entropy 476.0231628417969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13245/20000], Loss: 795.944091796875, Entropy 476.0075988769531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13246/20000], Loss: 833.6981201171875, Entropy 479.25341796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13247/20000], Loss: 832.3466796875, Entropy 480.1032409667969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13248/20000], Loss: 820.4234619140625, Entropy 476.2816162109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13249/20000], Loss: 846.2149047851562, Entropy 480.79351806640625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13250/20000], Loss: 862.052001953125, Entropy 474.1108093261719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13251/20000], Loss: 822.2301025390625, Entropy 478.9969177246094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13252/20000], Loss: 898.3055419921875, Entropy 456.5572204589844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13253/20000], Loss: 827.8414306640625, Entropy 467.8096008300781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13254/20000], Loss: 861.1962890625, Entropy 470.84130859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13255/20000], Loss: 841.499267578125, Entropy 463.720458984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13256/20000], Loss: 825.7694091796875, Entropy 476.5107421875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13257/20000], Loss: 866.5804443359375, Entropy 471.0569763183594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13258/20000], Loss: 886.0406494140625, Entropy 466.3599853515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13259/20000], Loss: 861.414306640625, Entropy 468.5138854980469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13260/20000], Loss: 868.448974609375, Entropy 461.4723205566406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13261/20000], Loss: 867.2024536132812, Entropy 471.21783447265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13262/20000], Loss: 839.302734375, Entropy 467.74560546875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13263/20000], Loss: 835.0239868164062, Entropy 477.06939697265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13264/20000], Loss: 892.3643798828125, Entropy 474.9817199707031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13265/20000], Loss: 824.4078369140625, Entropy 475.7727966308594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13266/20000], Loss: 865.10302734375, Entropy 471.9909362792969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13267/20000], Loss: 797.8240966796875, Entropy 478.4781494140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13268/20000], Loss: 832.9306640625, Entropy 458.0102233886719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13269/20000], Loss: 808.946044921875, Entropy 476.0437927246094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13270/20000], Loss: 815.586669921875, Entropy 469.7962646484375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13271/20000], Loss: 847.5235595703125, Entropy 473.4049377441406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13272/20000], Loss: 858.4462280273438, Entropy 468.33062744140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13273/20000], Loss: 804.131103515625, Entropy 474.572265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13274/20000], Loss: 840.89892578125, Entropy 461.99169921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13275/20000], Loss: 854.934814453125, Entropy 476.0439758300781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13276/20000], Loss: 823.45166015625, Entropy 467.4740905761719, Learning Rate: 1.220703125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13277/20000], Loss: 836.2264404296875, Entropy 450.65185546875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13278/20000], Loss: 878.6900634765625, Entropy 472.4421081542969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13279/20000], Loss: 870.0718994140625, Entropy 458.21240234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13280/20000], Loss: 830.1318359375, Entropy 479.0744323730469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13281/20000], Loss: 841.3782958984375, Entropy 461.9577941894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13282/20000], Loss: 850.556884765625, Entropy 459.60693359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13283/20000], Loss: 833.531005859375, Entropy 463.1836242675781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13284/20000], Loss: 810.9407958984375, Entropy 473.2406005859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13285/20000], Loss: 887.0028686523438, Entropy 475.83599853515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13286/20000], Loss: 870.2786865234375, Entropy 459.3367919921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13287/20000], Loss: 883.46435546875, Entropy 485.5096740722656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13288/20000], Loss: 823.20361328125, Entropy 472.6022644042969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13289/20000], Loss: 803.13232421875, Entropy 483.5895080566406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13290/20000], Loss: 846.3842163085938, Entropy 461.38812255859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13291/20000], Loss: 822.76806640625, Entropy 479.1750793457031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13292/20000], Loss: 850.0501708984375, Entropy 461.5403747558594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13293/20000], Loss: 843.695068359375, Entropy 485.7346496582031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13294/20000], Loss: 842.57568359375, Entropy 472.41845703125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13295/20000], Loss: 858.5047607421875, Entropy 470.1112060546875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13296/20000], Loss: 890.8240356445312, Entropy 463.54779052734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13297/20000], Loss: 834.9647827148438, Entropy 472.93255615234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13298/20000], Loss: 851.92919921875, Entropy 451.0699462890625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13299/20000], Loss: 880.0797119140625, Entropy 478.5749206542969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13300/20000], Loss: 897.9422607421875, Entropy 462.0526123046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13301/20000], Loss: 807.1884765625, Entropy 483.4909362792969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13302/20000], Loss: 884.4091796875, Entropy 464.31982421875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13303/20000], Loss: 861.2345581054688, Entropy 469.51519775390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13304/20000], Loss: 846.5423583984375, Entropy 472.1229248046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13305/20000], Loss: 806.3404541015625, Entropy 486.3067932128906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13306/20000], Loss: 889.4859619140625, Entropy 468.8438415527344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13307/20000], Loss: 883.7230834960938, Entropy 474.83685302734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13308/20000], Loss: 817.5855712890625, Entropy 474.5655822753906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13309/20000], Loss: 860.1343383789062, Entropy 471.20599365234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13310/20000], Loss: 884.1043701171875, Entropy 469.6825256347656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13311/20000], Loss: 821.364990234375, Entropy 471.5965576171875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13312/20000], Loss: 826.293212890625, Entropy 480.1649475097656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13313/20000], Loss: 850.34130859375, Entropy 472.3882751464844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13314/20000], Loss: 836.8796997070312, Entropy 466.44732666015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13315/20000], Loss: 876.1514892578125, Entropy 467.2525939941406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13316/20000], Loss: 859.1722412109375, Entropy 455.1883544921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13317/20000], Loss: 855.279296875, Entropy 469.98876953125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13318/20000], Loss: 827.8636474609375, Entropy 471.6134338378906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13319/20000], Loss: 794.478759765625, Entropy 478.8294372558594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13320/20000], Loss: 829.4041748046875, Entropy 466.6842041015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13321/20000], Loss: 890.8447265625, Entropy 473.5589599609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13322/20000], Loss: 850.2359619140625, Entropy 475.0984191894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13323/20000], Loss: 843.06005859375, Entropy 471.1980285644531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13324/20000], Loss: 828.962646484375, Entropy 477.0026550292969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13325/20000], Loss: 854.281982421875, Entropy 464.9490051269531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13326/20000], Loss: 843.5888671875, Entropy 466.5115661621094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13327/20000], Loss: 885.8819580078125, Entropy 472.6154479980469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13328/20000], Loss: 832.13916015625, Entropy 456.7683410644531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13329/20000], Loss: 895.8097534179688, Entropy 460.96490478515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13330/20000], Loss: 825.7194213867188, Entropy 470.94342041015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13331/20000], Loss: 840.7869873046875, Entropy 473.0970153808594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13332/20000], Loss: 866.8616943359375, Entropy 485.0437316894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13333/20000], Loss: 804.0847778320312, Entropy 488.74432373046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13334/20000], Loss: 872.5303955078125, Entropy 459.3074951171875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13335/20000], Loss: 873.3409423828125, Entropy 477.6905212402344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13336/20000], Loss: 835.408935546875, Entropy 472.0024108886719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13337/20000], Loss: 828.5949096679688, Entropy 468.96148681640625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13338/20000], Loss: 822.8770751953125, Entropy 465.4432067871094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13339/20000], Loss: 851.942138671875, Entropy 469.2293701171875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13340/20000], Loss: 853.5302124023438, Entropy 471.18414306640625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13341/20000], Loss: 903.234619140625, Entropy 459.1752624511719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13342/20000], Loss: 876.3419799804688, Entropy 466.02142333984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13343/20000], Loss: 844.8795776367188, Entropy 466.78338623046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13344/20000], Loss: 847.2447509765625, Entropy 481.6360168457031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13345/20000], Loss: 838.4427490234375, Entropy 472.9483337402344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13346/20000], Loss: 830.6624755859375, Entropy 463.6154479980469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13347/20000], Loss: 893.92626953125, Entropy 472.4768371582031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13348/20000], Loss: 847.6814575195312, Entropy 482.39849853515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13349/20000], Loss: 819.2796630859375, Entropy 480.0010681152344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13350/20000], Loss: 822.9815673828125, Entropy 478.5340881347656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13351/20000], Loss: 857.004638671875, Entropy 469.6761474609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13352/20000], Loss: 874.270263671875, Entropy 461.20751953125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13353/20000], Loss: 856.6939086914062, Entropy 468.02105712890625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13354/20000], Loss: 858.5380249023438, Entropy 461.99615478515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13355/20000], Loss: 852.0496215820312, Entropy 461.39312744140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13356/20000], Loss: 847.18505859375, Entropy 468.6008605957031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13357/20000], Loss: 882.26123046875, Entropy 468.69189453125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13358/20000], Loss: 825.1602783203125, Entropy 470.6209411621094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13359/20000], Loss: 835.322021484375, Entropy 478.4693603515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13360/20000], Loss: 819.163330078125, Entropy 463.9187316894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13361/20000], Loss: 871.5110473632812, Entropy 470.78436279296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13362/20000], Loss: 836.5257568359375, Entropy 465.6891174316406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13363/20000], Loss: 846.4158935546875, Entropy 483.3970642089844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13364/20000], Loss: 887.8651733398438, Entropy 469.04693603515625, Learning Rate: 1.220703125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13365/20000], Loss: 874.8682861328125, Entropy 466.8752136230469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13366/20000], Loss: 855.1953735351562, Entropy 477.59771728515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13367/20000], Loss: 824.3612060546875, Entropy 468.7293395996094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13368/20000], Loss: 883.3173828125, Entropy 474.7210693359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13369/20000], Loss: 857.3848266601562, Entropy 468.06390380859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13370/20000], Loss: 844.7804565429688, Entropy 486.73858642578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13371/20000], Loss: 849.23974609375, Entropy 471.8414306640625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13372/20000], Loss: 882.8529052734375, Entropy 472.9289245605469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13373/20000], Loss: 899.167236328125, Entropy 459.5436706542969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13374/20000], Loss: 827.4572143554688, Entropy 473.71405029296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13375/20000], Loss: 867.7200927734375, Entropy 472.59521484375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13376/20000], Loss: 899.6014404296875, Entropy 460.3263244628906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13377/20000], Loss: 886.0650024414062, Entropy 476.86187744140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13378/20000], Loss: 847.0274047851562, Entropy 475.83038330078125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13379/20000], Loss: 872.5555419921875, Entropy 471.8302917480469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13380/20000], Loss: 814.7923583984375, Entropy 466.6383361816406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13381/20000], Loss: 859.185302734375, Entropy 470.3043518066406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13382/20000], Loss: 796.8360595703125, Entropy 468.1474914550781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13383/20000], Loss: 811.5765991210938, Entropy 472.19354248046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13384/20000], Loss: 825.3837890625, Entropy 477.6979675292969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13385/20000], Loss: 883.876220703125, Entropy 476.7874755859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13386/20000], Loss: 859.44677734375, Entropy 460.8064880371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13387/20000], Loss: 826.8320922851562, Entropy 489.49224853515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13388/20000], Loss: 840.099609375, Entropy 478.8897399902344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13389/20000], Loss: 836.585693359375, Entropy 480.2502136230469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13390/20000], Loss: 846.92724609375, Entropy 470.4084167480469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13391/20000], Loss: 849.6505126953125, Entropy 465.9792175292969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13392/20000], Loss: 825.0397338867188, Entropy 468.87725830078125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13393/20000], Loss: 828.5925903320312, Entropy 488.80279541015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13394/20000], Loss: 858.5074462890625, Entropy 476.5159912109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13395/20000], Loss: 811.093017578125, Entropy 476.2336120605469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13396/20000], Loss: 850.8223876953125, Entropy 470.2995910644531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13397/20000], Loss: 821.5914306640625, Entropy 485.6116943359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13398/20000], Loss: 820.8126220703125, Entropy 482.9334411621094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13399/20000], Loss: 872.1497192382812, Entropy 467.95428466796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13400/20000], Loss: 851.5550537109375, Entropy 458.5548400878906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13401/20000], Loss: 845.6026611328125, Entropy 478.4986572265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13402/20000], Loss: 836.7679443359375, Entropy 480.2678527832031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13403/20000], Loss: 846.0086669921875, Entropy 471.827880859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13404/20000], Loss: 865.943603515625, Entropy 475.4415588378906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13405/20000], Loss: 839.1650390625, Entropy 461.9588928222656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13406/20000], Loss: 825.6485595703125, Entropy 465.1402893066406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13407/20000], Loss: 815.1693725585938, Entropy 479.73773193359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13408/20000], Loss: 897.396484375, Entropy 466.2727966308594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13409/20000], Loss: 833.74560546875, Entropy 479.4563903808594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13410/20000], Loss: 841.2943115234375, Entropy 459.0108642578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13411/20000], Loss: 831.0780029296875, Entropy 477.1662292480469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13412/20000], Loss: 811.6248779296875, Entropy 475.3719482421875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13413/20000], Loss: 834.178955078125, Entropy 476.8172302246094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13414/20000], Loss: 845.8857421875, Entropy 472.2922668457031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13415/20000], Loss: 813.5701904296875, Entropy 473.67236328125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13416/20000], Loss: 859.6358642578125, Entropy 466.2760009765625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13417/20000], Loss: 823.3856201171875, Entropy 467.5807800292969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13418/20000], Loss: 849.0556640625, Entropy 484.4309997558594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13419/20000], Loss: 825.9586181640625, Entropy 473.6256103515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13420/20000], Loss: 863.4993896484375, Entropy 465.0530090332031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13421/20000], Loss: 817.75439453125, Entropy 474.9801025390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13422/20000], Loss: 859.2861328125, Entropy 463.1905517578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13423/20000], Loss: 850.2173461914062, Entropy 454.32025146484375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13424/20000], Loss: 851.3203125, Entropy 481.2496643066406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13425/20000], Loss: 806.461669921875, Entropy 474.6262512207031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13426/20000], Loss: 889.203369140625, Entropy 459.13916015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13427/20000], Loss: 839.3904418945312, Entropy 480.24249267578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13428/20000], Loss: 838.4226684570312, Entropy 468.63470458984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13429/20000], Loss: 854.8253784179688, Entropy 461.87054443359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13430/20000], Loss: 861.7156982421875, Entropy 483.0613098144531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13431/20000], Loss: 821.854736328125, Entropy 475.0374755859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13432/20000], Loss: 849.3383178710938, Entropy 472.36419677734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13433/20000], Loss: 863.231201171875, Entropy 460.2918701171875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13434/20000], Loss: 844.0213623046875, Entropy 476.9586486816406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13435/20000], Loss: 845.6038818359375, Entropy 465.5301208496094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13436/20000], Loss: 833.3275756835938, Entropy 478.51580810546875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13437/20000], Loss: 885.9739990234375, Entropy 462.0953063964844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13438/20000], Loss: 885.7650146484375, Entropy 468.3529968261719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13439/20000], Loss: 866.4733276367188, Entropy 475.95159912109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13440/20000], Loss: 849.8751220703125, Entropy 468.1072998046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13441/20000], Loss: 884.1665649414062, Entropy 471.57244873046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13442/20000], Loss: 861.4344482421875, Entropy 478.2659912109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13443/20000], Loss: 854.00927734375, Entropy 466.8578796386719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13444/20000], Loss: 907.774658203125, Entropy 464.4456481933594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13445/20000], Loss: 820.736328125, Entropy 475.6805419921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13446/20000], Loss: 810.3997802734375, Entropy 477.5156555175781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13447/20000], Loss: 822.27978515625, Entropy 467.5592041015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13448/20000], Loss: 863.202392578125, Entropy 467.62939453125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13449/20000], Loss: 833.1118774414062, Entropy 472.99859619140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13450/20000], Loss: 817.8973999023438, Entropy 477.07037353515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13451/20000], Loss: 831.119140625, Entropy 475.5110168457031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13452/20000], Loss: 813.5172119140625, Entropy 463.2952880859375, Learning Rate: 1.220703125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13453/20000], Loss: 861.5704345703125, Entropy 468.4817199707031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13454/20000], Loss: 858.927001953125, Entropy 468.4352111816406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13455/20000], Loss: 848.565673828125, Entropy 466.4998779296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13456/20000], Loss: 837.8927001953125, Entropy 481.0852355957031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13457/20000], Loss: 871.7745361328125, Entropy 472.3619689941406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13458/20000], Loss: 831.2198486328125, Entropy 495.5921630859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13459/20000], Loss: 807.912109375, Entropy 478.1045837402344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13460/20000], Loss: 882.1865234375, Entropy 456.2467956542969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13461/20000], Loss: 824.8677978515625, Entropy 487.1419372558594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13462/20000], Loss: 856.9005737304688, Entropy 475.79437255859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13463/20000], Loss: 843.9307861328125, Entropy 470.923583984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13464/20000], Loss: 811.4769897460938, Entropy 463.10638427734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13465/20000], Loss: 845.44580078125, Entropy 463.8624267578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13466/20000], Loss: 821.5285034179688, Entropy 480.02593994140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13467/20000], Loss: 813.39794921875, Entropy 470.0992126464844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13468/20000], Loss: 830.974609375, Entropy 474.6867980957031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13469/20000], Loss: 845.484130859375, Entropy 475.5710144042969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13470/20000], Loss: 855.4413452148438, Entropy 468.64849853515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13471/20000], Loss: 887.36669921875, Entropy 468.8118591308594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13472/20000], Loss: 852.20068359375, Entropy 473.6564636230469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13473/20000], Loss: 872.1492919921875, Entropy 474.1297607421875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13474/20000], Loss: 893.28173828125, Entropy 478.0848388671875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13475/20000], Loss: 865.0104370117188, Entropy 475.69818115234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13476/20000], Loss: 869.4517822265625, Entropy 478.4212646484375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13477/20000], Loss: 867.9146728515625, Entropy 465.9061279296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13478/20000], Loss: 821.7857666015625, Entropy 478.7874450683594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13479/20000], Loss: 851.912353515625, Entropy 476.5176086425781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13480/20000], Loss: 867.67236328125, Entropy 464.7535400390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13481/20000], Loss: 836.0303955078125, Entropy 473.4626770019531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13482/20000], Loss: 862.4292602539062, Entropy 461.39349365234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13483/20000], Loss: 835.3704223632812, Entropy 475.73468017578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13484/20000], Loss: 822.517333984375, Entropy 485.2597961425781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13485/20000], Loss: 883.5106201171875, Entropy 466.1990966796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13486/20000], Loss: 821.80322265625, Entropy 460.2991027832031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13487/20000], Loss: 856.4376220703125, Entropy 471.1864013671875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13488/20000], Loss: 845.2554931640625, Entropy 480.5226745605469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13489/20000], Loss: 873.877197265625, Entropy 471.8320617675781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13490/20000], Loss: 836.5116577148438, Entropy 469.69427490234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13491/20000], Loss: 854.2474365234375, Entropy 466.6316223144531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13492/20000], Loss: 858.51904296875, Entropy 461.5939636230469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13493/20000], Loss: 808.4677124023438, Entropy 477.92132568359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13494/20000], Loss: 869.9176025390625, Entropy 468.4418640136719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13495/20000], Loss: 809.5845336914062, Entropy 464.42962646484375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13496/20000], Loss: 885.635498046875, Entropy 461.14990234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13497/20000], Loss: 780.5363159179688, Entropy 476.14703369140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13498/20000], Loss: 839.4696044921875, Entropy 476.7747802734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13499/20000], Loss: 854.1063232421875, Entropy 477.7174377441406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13500/20000], Loss: 888.60791015625, Entropy 465.402099609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13501/20000], Loss: 846.8384399414062, Entropy 454.04132080078125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13502/20000], Loss: 871.32275390625, Entropy 456.2191162109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13503/20000], Loss: 857.6190185546875, Entropy 481.4237365722656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13504/20000], Loss: 808.3311767578125, Entropy 467.470458984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13505/20000], Loss: 890.81591796875, Entropy 460.3096923828125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13506/20000], Loss: 852.1424560546875, Entropy 469.94287109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13507/20000], Loss: 828.5418701171875, Entropy 474.2751159667969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13508/20000], Loss: 839.3277587890625, Entropy 472.0316162109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13509/20000], Loss: 885.6146850585938, Entropy 460.80413818359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13510/20000], Loss: 858.8570556640625, Entropy 460.9041442871094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13511/20000], Loss: 831.938720703125, Entropy 480.2205505371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13512/20000], Loss: 838.3187255859375, Entropy 469.4161071777344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13513/20000], Loss: 856.4146728515625, Entropy 483.6825256347656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13514/20000], Loss: 847.2635498046875, Entropy 470.7336730957031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13515/20000], Loss: 852.0426635742188, Entropy 462.12506103515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13516/20000], Loss: 827.837890625, Entropy 477.9360046386719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13517/20000], Loss: 875.776611328125, Entropy 469.7702941894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13518/20000], Loss: 856.23095703125, Entropy 475.1658630371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13519/20000], Loss: 824.7125244140625, Entropy 468.4234619140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13520/20000], Loss: 865.50390625, Entropy 471.5504455566406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13521/20000], Loss: 830.2623901367188, Entropy 475.48199462890625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13522/20000], Loss: 835.3131103515625, Entropy 469.6561279296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13523/20000], Loss: 906.3851318359375, Entropy 465.1561279296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13524/20000], Loss: 820.8128662109375, Entropy 464.9730224609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13525/20000], Loss: 864.9179077148438, Entropy 463.37615966796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13526/20000], Loss: 873.5215454101562, Entropy 461.95794677734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13527/20000], Loss: 848.3802490234375, Entropy 457.3484191894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13528/20000], Loss: 880.7657470703125, Entropy 470.5245666503906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13529/20000], Loss: 827.2630004882812, Entropy 464.43206787109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13530/20000], Loss: 799.0498046875, Entropy 466.2508544921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13531/20000], Loss: 839.8241577148438, Entropy 468.65875244140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13532/20000], Loss: 889.384521484375, Entropy 464.0189208984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13533/20000], Loss: 798.96484375, Entropy 477.6675720214844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13534/20000], Loss: 865.120361328125, Entropy 476.1553649902344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13535/20000], Loss: 853.9625854492188, Entropy 470.56365966796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13536/20000], Loss: 864.6134643554688, Entropy 466.47906494140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13537/20000], Loss: 827.5341796875, Entropy 486.4302673339844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13538/20000], Loss: 850.5157470703125, Entropy 449.2366943359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13539/20000], Loss: 844.0311279296875, Entropy 473.5838928222656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13540/20000], Loss: 849.1893310546875, Entropy 480.7086486816406, Learning Rate: 1.220703125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13541/20000], Loss: 823.7137451171875, Entropy 474.0281066894531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13542/20000], Loss: 883.826904296875, Entropy 479.8290100097656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13543/20000], Loss: 875.853515625, Entropy 470.6895446777344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13544/20000], Loss: 896.8851318359375, Entropy 461.057373046875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13545/20000], Loss: 834.410400390625, Entropy 471.9267578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13546/20000], Loss: 881.8232421875, Entropy 463.4698486328125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13547/20000], Loss: 871.6444091796875, Entropy 469.1935119628906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13548/20000], Loss: 890.2005004882812, Entropy 480.24029541015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13549/20000], Loss: 809.0186767578125, Entropy 466.9625549316406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13550/20000], Loss: 867.519287109375, Entropy 462.8760986328125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13551/20000], Loss: 868.5980224609375, Entropy 475.3246765136719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13552/20000], Loss: 821.8048706054688, Entropy 469.60748291015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13553/20000], Loss: 843.0501708984375, Entropy 471.6741943359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13554/20000], Loss: 855.497314453125, Entropy 462.7301330566406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13555/20000], Loss: 862.2447509765625, Entropy 479.8180236816406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13556/20000], Loss: 813.4473876953125, Entropy 471.8667907714844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13557/20000], Loss: 825.80029296875, Entropy 484.7353515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13558/20000], Loss: 823.0817260742188, Entropy 467.25836181640625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13559/20000], Loss: 868.0322265625, Entropy 468.7130432128906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13560/20000], Loss: 807.5487060546875, Entropy 475.0484924316406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13561/20000], Loss: 862.0743408203125, Entropy 462.8377380371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13562/20000], Loss: 840.3194580078125, Entropy 464.6475524902344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13563/20000], Loss: 841.41650390625, Entropy 470.421630859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13564/20000], Loss: 876.3172607421875, Entropy 473.8405456542969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13565/20000], Loss: 846.0321044921875, Entropy 470.7720947265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13566/20000], Loss: 873.6963500976562, Entropy 466.95599365234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13567/20000], Loss: 860.6343994140625, Entropy 465.0955505371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13568/20000], Loss: 867.056640625, Entropy 466.0612487792969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13569/20000], Loss: 810.914306640625, Entropy 471.4893493652344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13570/20000], Loss: 822.0077514648438, Entropy 474.10211181640625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13571/20000], Loss: 815.3265380859375, Entropy 466.8531188964844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13572/20000], Loss: 890.730224609375, Entropy 464.4067077636719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13573/20000], Loss: 847.0206298828125, Entropy 462.6222229003906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13574/20000], Loss: 813.7076416015625, Entropy 470.1443786621094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13575/20000], Loss: 818.5062255859375, Entropy 473.1143493652344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13576/20000], Loss: 841.38232421875, Entropy 477.7288513183594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13577/20000], Loss: 828.634765625, Entropy 470.8470458984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13578/20000], Loss: 849.1065673828125, Entropy 460.4438171386719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13579/20000], Loss: 849.7041015625, Entropy 472.5943908691406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13580/20000], Loss: 858.66455078125, Entropy 470.933349609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13581/20000], Loss: 839.9547729492188, Entropy 463.36749267578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13582/20000], Loss: 846.243408203125, Entropy 475.3090515136719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13583/20000], Loss: 854.253173828125, Entropy 471.7245178222656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13584/20000], Loss: 857.994384765625, Entropy 462.20458984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13585/20000], Loss: 873.9105224609375, Entropy 472.4789733886719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13586/20000], Loss: 885.5623779296875, Entropy 472.2369384765625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13587/20000], Loss: 858.9903564453125, Entropy 466.0408630371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13588/20000], Loss: 853.8206787109375, Entropy 474.6270446777344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13589/20000], Loss: 889.5394897460938, Entropy 469.31011962890625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13590/20000], Loss: 864.7867431640625, Entropy 470.3662109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13591/20000], Loss: 873.4241943359375, Entropy 473.8827209472656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13592/20000], Loss: 846.8748779296875, Entropy 474.6602478027344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13593/20000], Loss: 855.9634399414062, Entropy 473.61553955078125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13594/20000], Loss: 888.3251953125, Entropy 467.1175537109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13595/20000], Loss: 848.0457763671875, Entropy 470.0261535644531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13596/20000], Loss: 838.3902587890625, Entropy 465.2414855957031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13597/20000], Loss: 800.313720703125, Entropy 473.8322448730469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13598/20000], Loss: 860.4591064453125, Entropy 467.241943359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13599/20000], Loss: 814.088134765625, Entropy 466.1199645996094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13600/20000], Loss: 865.1213989257812, Entropy 473.22747802734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13601/20000], Loss: 833.828369140625, Entropy 470.3074645996094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13602/20000], Loss: 854.5904541015625, Entropy 467.9202575683594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13603/20000], Loss: 834.36083984375, Entropy 466.3233947753906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13604/20000], Loss: 830.1622314453125, Entropy 475.3194885253906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13605/20000], Loss: 836.91259765625, Entropy 472.2196350097656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13606/20000], Loss: 834.9053344726562, Entropy 465.94952392578125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13607/20000], Loss: 849.1679077148438, Entropy 469.09490966796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13608/20000], Loss: 848.7264404296875, Entropy 466.1111145019531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13609/20000], Loss: 873.2996826171875, Entropy 463.4594421386719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13610/20000], Loss: 879.9492797851562, Entropy 465.46319580078125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13611/20000], Loss: 843.8894653320312, Entropy 467.23052978515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13612/20000], Loss: 865.6217651367188, Entropy 477.08319091796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13613/20000], Loss: 858.1455078125, Entropy 476.3234558105469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13614/20000], Loss: 887.3108520507812, Entropy 458.97210693359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13615/20000], Loss: 857.6923217773438, Entropy 480.15484619140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13616/20000], Loss: 883.812744140625, Entropy 465.1631774902344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13617/20000], Loss: 876.8790283203125, Entropy 467.9602355957031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13618/20000], Loss: 895.21484375, Entropy 453.2684631347656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13619/20000], Loss: 823.7821044921875, Entropy 481.0692138671875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13620/20000], Loss: 881.3924560546875, Entropy 470.818115234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13621/20000], Loss: 830.4771728515625, Entropy 468.8542785644531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13622/20000], Loss: 874.2518310546875, Entropy 469.8463134765625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13623/20000], Loss: 853.8609619140625, Entropy 479.34130859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13624/20000], Loss: 818.3114013671875, Entropy 491.8638916015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13625/20000], Loss: 850.2088623046875, Entropy 475.9049377441406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13626/20000], Loss: 823.4485473632812, Entropy 481.36041259765625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13627/20000], Loss: 837.2550048828125, Entropy 480.63525390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13628/20000], Loss: 847.208740234375, Entropy 472.5312805175781, Learning Rate: 1.220703125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13629/20000], Loss: 811.37353515625, Entropy 469.54296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13630/20000], Loss: 850.0267333984375, Entropy 462.3628845214844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13631/20000], Loss: 855.351318359375, Entropy 465.1111755371094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13632/20000], Loss: 805.7445678710938, Entropy 475.16302490234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13633/20000], Loss: 827.419677734375, Entropy 460.9381408691406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13634/20000], Loss: 835.28857421875, Entropy 465.0174560546875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13635/20000], Loss: 872.3477783203125, Entropy 489.0318908691406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13636/20000], Loss: 837.1839599609375, Entropy 466.21923828125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13637/20000], Loss: 894.1465454101562, Entropy 470.83123779296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13638/20000], Loss: 853.9366455078125, Entropy 476.7770690917969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13639/20000], Loss: 862.6389770507812, Entropy 471.43402099609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13640/20000], Loss: 869.0909423828125, Entropy 460.5123291015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13641/20000], Loss: 819.7946166992188, Entropy 466.04107666015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13642/20000], Loss: 803.814208984375, Entropy 476.8832702636719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13643/20000], Loss: 862.9223022460938, Entropy 484.18609619140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13644/20000], Loss: 873.1660766601562, Entropy 477.99017333984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13645/20000], Loss: 832.4572143554688, Entropy 465.62615966796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13646/20000], Loss: 846.669677734375, Entropy 474.119140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13647/20000], Loss: 864.955078125, Entropy 478.2767028808594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13648/20000], Loss: 871.4708251953125, Entropy 475.7703857421875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13649/20000], Loss: 875.4085693359375, Entropy 464.8164367675781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13650/20000], Loss: 829.6690673828125, Entropy 472.1301574707031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13651/20000], Loss: 830.7440795898438, Entropy 464.60638427734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13652/20000], Loss: 826.3968505859375, Entropy 464.5504150390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13653/20000], Loss: 842.0874633789062, Entropy 470.14373779296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13654/20000], Loss: 855.120849609375, Entropy 472.0724792480469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13655/20000], Loss: 817.01806640625, Entropy 466.14013671875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13656/20000], Loss: 865.8038330078125, Entropy 465.4368591308594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13657/20000], Loss: 821.586669921875, Entropy 463.314453125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13658/20000], Loss: 811.0877685546875, Entropy 473.5244445800781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13659/20000], Loss: 815.6954345703125, Entropy 474.0374755859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13660/20000], Loss: 851.1646728515625, Entropy 472.4276428222656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13661/20000], Loss: 818.464599609375, Entropy 464.7203063964844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13662/20000], Loss: 832.1156005859375, Entropy 454.314208984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13663/20000], Loss: 906.1734619140625, Entropy 469.6179504394531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13664/20000], Loss: 825.6451416015625, Entropy 467.7870178222656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13665/20000], Loss: 850.1076049804688, Entropy 466.95709228515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13666/20000], Loss: 850.269287109375, Entropy 474.9372863769531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13667/20000], Loss: 787.8156127929688, Entropy 471.16705322265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13668/20000], Loss: 836.6748657226562, Entropy 477.05023193359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13669/20000], Loss: 840.7858276367188, Entropy 460.68267822265625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13670/20000], Loss: 818.116943359375, Entropy 471.4806823730469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13671/20000], Loss: 834.3677978515625, Entropy 479.8013916015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13672/20000], Loss: 846.44921875, Entropy 476.384521484375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13673/20000], Loss: 881.2280883789062, Entropy 466.94061279296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13674/20000], Loss: 849.2586669921875, Entropy 475.0581970214844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13675/20000], Loss: 844.9722900390625, Entropy 479.0709228515625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13676/20000], Loss: 813.2734375, Entropy 473.8934326171875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13677/20000], Loss: 905.788330078125, Entropy 471.1499938964844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13678/20000], Loss: 859.1834716796875, Entropy 462.7161865234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13679/20000], Loss: 856.47265625, Entropy 479.4827880859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13680/20000], Loss: 842.51708984375, Entropy 468.1932067871094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13681/20000], Loss: 830.262939453125, Entropy 467.8709411621094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13682/20000], Loss: 830.7771606445312, Entropy 479.41265869140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13683/20000], Loss: 880.3413696289062, Entropy 469.09295654296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13684/20000], Loss: 832.7030639648438, Entropy 464.69342041015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13685/20000], Loss: 891.242919921875, Entropy 467.818359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13686/20000], Loss: 865.9595336914062, Entropy 466.07952880859375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13687/20000], Loss: 824.1893310546875, Entropy 474.0941162109375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13688/20000], Loss: 892.053466796875, Entropy 459.8913269042969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13689/20000], Loss: 865.9022827148438, Entropy 470.50482177734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13690/20000], Loss: 855.0292358398438, Entropy 473.27435302734375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13691/20000], Loss: 826.7161865234375, Entropy 483.4650573730469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13692/20000], Loss: 850.7591552734375, Entropy 464.6342468261719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13693/20000], Loss: 836.2681884765625, Entropy 466.9298400878906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13694/20000], Loss: 858.7347412109375, Entropy 459.8714599609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13695/20000], Loss: 817.7510375976562, Entropy 472.57354736328125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13696/20000], Loss: 940.1602172851562, Entropy 452.01397705078125, Learning Rate: 1.220703125e-06\n",
      "Epoch [13697/20000], Loss: 874.7344970703125, Entropy 468.6282043457031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13698/20000], Loss: 822.475830078125, Entropy 475.9161071777344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13699/20000], Loss: 854.4849853515625, Entropy 464.1806945800781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13700/20000], Loss: 823.6524658203125, Entropy 467.5232849121094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13701/20000], Loss: 854.0572509765625, Entropy 472.179443359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13702/20000], Loss: 884.5679931640625, Entropy 468.0466003417969, Learning Rate: 1.220703125e-06\n",
      "Epoch [13703/20000], Loss: 855.555908203125, Entropy 465.7464599609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13704/20000], Loss: 854.6257934570312, Entropy 453.79937744140625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13705/20000], Loss: 828.8383178710938, Entropy 467.78240966796875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13706/20000], Loss: 873.6885986328125, Entropy 472.8719482421875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13707/20000], Loss: 844.6639404296875, Entropy 484.0285339355469, Learning Rate: 1.220703125e-06\n",
      "Epoch [13708/20000], Loss: 840.9641723632812, Entropy 476.19061279296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13709/20000], Loss: 862.9736328125, Entropy 464.0654296875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13710/20000], Loss: 844.3743896484375, Entropy 467.7415466308594, Learning Rate: 1.220703125e-06\n",
      "Epoch [13711/20000], Loss: 793.9542236328125, Entropy 467.4638671875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13712/20000], Loss: 859.557373046875, Entropy 455.458984375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13713/20000], Loss: 858.0984497070312, Entropy 482.25335693359375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13714/20000], Loss: 805.477783203125, Entropy 473.3676452636719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13715/20000], Loss: 818.2596435546875, Entropy 480.1614074707031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13716/20000], Loss: 844.1122436523438, Entropy 469.26788330078125, Learning Rate: 1.220703125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13717/20000], Loss: 814.3843994140625, Entropy 464.9054260253906, Learning Rate: 1.220703125e-06\n",
      "Epoch [13718/20000], Loss: 841.25732421875, Entropy 473.8826599121094, Learning Rate: 1.220703125e-06\n",
      "Epoch [13719/20000], Loss: 833.6881103515625, Entropy 469.9463806152344, Learning Rate: 1.220703125e-06\n",
      "Epoch [13720/20000], Loss: 844.1907958984375, Entropy 467.6916809082031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13721/20000], Loss: 857.785400390625, Entropy 461.044921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13722/20000], Loss: 877.1539306640625, Entropy 464.7239990234375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13723/20000], Loss: 838.0760498046875, Entropy 474.2834777832031, Learning Rate: 1.220703125e-06\n",
      "Epoch [13724/20000], Loss: 830.7265014648438, Entropy 478.71441650390625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13725/20000], Loss: 867.543701171875, Entropy 463.8211975097656, Learning Rate: 1.220703125e-06\n",
      "Epoch [13726/20000], Loss: 858.626953125, Entropy 470.3446044921875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13727/20000], Loss: 839.132080078125, Entropy 480.1314392089844, Learning Rate: 1.220703125e-06\n",
      "Epoch [13728/20000], Loss: 849.467041015625, Entropy 467.82666015625, Learning Rate: 1.220703125e-06\n",
      "Epoch [13729/20000], Loss: 834.9954833984375, Entropy 461.7533874511719, Learning Rate: 1.220703125e-06\n",
      "Epoch [13730/20000], Loss: 828.9816284179688, Entropy 471.83612060546875, Learning Rate: 1.220703125e-06\n",
      "Epoch [13731/20000], Loss: 832.6912841796875, Entropy 474.2490539550781, Learning Rate: 1.220703125e-06\n",
      "Epoch [13732/20000], Loss: 846.0155029296875, Entropy 468.6012268066406, Learning Rate: 1.220703125e-06\n",
      "Epoch [13733/20000], Loss: 832.7152099609375, Entropy 478.7273254394531, Learning Rate: 1.220703125e-06\n",
      "Epoch [13734/20000], Loss: 884.1879272460938, Entropy 471.98870849609375, Learning Rate: 1.220703125e-06\n",
      "Epoch [13735/20000], Loss: 841.2327880859375, Entropy 481.185302734375, Learning Rate: 6.103515625e-07\n",
      "10728\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    optimizer = GeNVariationalInference(logtarget,\n",
    "\t\t                                    0, 100, 1000, 50, 100,\n",
    "\t\t                                    20000, .01, .000001, 500, .5,\n",
    "\t\t                                    device, True, temp_dir, save_best=True)\n",
    "    best_epoch, scores=optimizer.run(GeN)\n",
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nLPP: 1.1677169 (0.32374805)\n",
      "Squared Error: 0.27561927 (1.0433357)\n"
     ]
    }
   ],
   "source": [
    "nLPP_train, nLPP_validation, nLPP_test, RSE_train, RSE_validation, RSE_test=setup.evaluate_metrics(GeN(1000).detach(),device)\n",
    "print('nLPP: '+str(nLPP_test[0].float().cpu().numpy())+' ('+str(nLPP_test[1].float().cpu().numpy())+')')\n",
    "print('Squared Error: '+str(RSE_test[0].float().cpu().numpy())+' ('+str(RSE_test[1].float().cpu().numpy())+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup.plot:\n",
    "    fig=makePlot(setup,GeN,noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27000, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27000, 751])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z=GeN.components[0].hnet(noise.to(device)).detach().squeeze(0)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4782606363296509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27000, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "myTSNE=TSNE(n_components=3,init='pca',perplexity=30)\n",
    "X_embedded =myTSNE.fit_transform(Z.cpu())\n",
    "print(myTSNE.kl_divergence_)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"864\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, '3D t-SNE of 751-dimensional transformed noise')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(X_embedded[:,0],X_embedded[:,1],X_embedded[:,2], c=colors, linewidth=0.2)\n",
    "plt.title('3D t-SNE of '+str(param_count)+'-dimensional transformed noise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
