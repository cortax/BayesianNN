{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "#from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class GatedRecurrentUnitOutputAttentionNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, \n",
    "                        window_size, hidden_size, num_layers, \n",
    "                        target_type_string='Regression',\n",
    "                        bias=True, batch_first=True, \n",
    "                        bidirectional=False,\n",
    "                        dropout_hidden=0, dropout_output=0):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seq_len = window_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            bias=bias, \n",
    "                            batch_first=batch_first, \n",
    "                            dropout=dropout_hidden, \n",
    "                            bidirectional=bidirectional)\n",
    "        self.output_dropout_layer = nn.Dropout(dropout_output)\n",
    "\n",
    "        self.attention_layer = nn.Linear(hidden_size * (bidirectional + 1) , 1)\n",
    "        self.predict_layer = nn.Linear(hidden_size * (bidirectional + 1), output_size) #(num_directions * hidden_size)\n",
    "        \n",
    "        self.target_type_string = target_type_string\n",
    "        if target_type_string=='Regression':\n",
    "            self.loss_function = nn.MSELoss()\n",
    "        elif target_type_string=='Classification':\n",
    "            self.loss_function = nn.CrossEntropyLoss()\n",
    "             \n",
    "    def forward(self, input):\n",
    "        #print('batch:', input)\n",
    "        #print(input.size())\n",
    "        #print(input[0])\n",
    "        #print(input[0][0])\n",
    "        gru_out, h_n = self.gru(input) #shape gru_out: (batch, seq_len, num_directions * hidden_size)\n",
    "        #print('gru_out:', gru_out)\n",
    "        #print('gru_out size:', gru_out.size(0), gru_out.size(1), gru_out.size(2))\n",
    "        attn = self.attention_layer(gru_out)\n",
    "        #print('attn:', attn)\n",
    "        #print('attn size:', attn.size(0), attn.size(1), attn.size(2))\n",
    "        sm_attn = func.softmax(attn, dim=1)\n",
    "        #print('sm_attn:', sm_attn)\n",
    "        #print('sm_attn size:', sm_attn.size(0), sm_attn.size(1), sm_attn.size(2))\n",
    "        \n",
    "        mul = gru_out*sm_attn\n",
    "        #print('mul:', mul)\n",
    "        #print('mul size:', mul.size(0), mul.size(1), mul.size(2))\n",
    "        \n",
    "        summ = torch.sum(mul, dim=1)\n",
    "        #print('summ:', summ)\n",
    "\n",
    "        out_dropout = self.output_dropout_layer(summ)\n",
    "        predict = self.predict_layer(out_dropout) #predict est vertical\n",
    "        #print('predict:', predict)\n",
    "        #print('predict size:', predict.size())\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1\n",
    "window_size = 2\n",
    "hidden_size = 5\n",
    "num_layers = 3\n",
    "target_type_string='Regression'\n",
    "bias=True\n",
    "batch_first=True\n",
    "bidirectional=False\n",
    "dropout_hidden=0\n",
    "dropout_output=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GatedRecurrentUnitOutputAttentionNet(input_size, output_size, \n",
    "                                window_size, hidden_size, num_layers, \n",
    "                                target_type_string,\n",
    "                                bias, batch_first, \n",
    "                                bidirectional,\n",
    "                                dropout_hidden, dropout_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[[5.9300e-04, 1.0390e-01],[5.9300e-04, 1.0390e-01],[8.2390e-04, 2.8946e-01]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[[7.9018e-04, 1.2779e-01],[7.9018e-04, 1.2779e-01]],\n",
    "        [[5.2380e-04, 1.9846e-01],[5.2380e-04, 1.9846e-01]],\n",
    "        [[8.2390e-04, 2.8946e-01],[8.2390e-04, 2.8946e-01]],\n",
    "        [[5.9300e-04, 1.0390e-01],[5.9300e-04, 1.0390e-01]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(inputs).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_out: tensor([[[-0.1287, -0.0386,  0.0901,  0.0267, -0.0070],\n",
      "         [-0.1909, -0.1221,  0.1289,  0.0328,  0.0081]],\n",
      "\n",
      "        [[-0.1286, -0.0387,  0.0893,  0.0262, -0.0067],\n",
      "         [-0.1901, -0.1219,  0.1266,  0.0313,  0.0087]],\n",
      "\n",
      "        [[-0.1284, -0.0389,  0.0882,  0.0254, -0.0063],\n",
      "         [-0.1889, -0.1214,  0.1238,  0.0294,  0.0094]],\n",
      "\n",
      "        [[-0.1288, -0.0385,  0.0904,  0.0269, -0.0071],\n",
      "         [-0.1912, -0.1222,  0.1296,  0.0333,  0.0079]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "gru_out size: 4 2 5\n",
      "sm_attn: tensor([[[0.4851],\n",
      "         [0.5149]],\n",
      "\n",
      "        [[0.4852],\n",
      "         [0.5148]],\n",
      "\n",
      "        [[0.4854],\n",
      "         [0.5146]],\n",
      "\n",
      "        [[0.4851],\n",
      "         [0.5149]]], grad_fn=<SoftmaxBackward>)\n",
      "sm_attn size: 4 2 1\n",
      "mul: tensor([[[-0.0624, -0.0187,  0.0437,  0.0130, -0.0034],\n",
      "         [-0.0983, -0.0629,  0.0663,  0.0169,  0.0042]],\n",
      "\n",
      "        [[-0.0624, -0.0188,  0.0433,  0.0127, -0.0032],\n",
      "         [-0.0978, -0.0627,  0.0652,  0.0161,  0.0045]],\n",
      "\n",
      "        [[-0.0623, -0.0189,  0.0428,  0.0123, -0.0031],\n",
      "         [-0.0972, -0.0625,  0.0637,  0.0151,  0.0048]],\n",
      "\n",
      "        [[-0.0625, -0.0187,  0.0439,  0.0131, -0.0034],\n",
      "         [-0.0985, -0.0629,  0.0667,  0.0171,  0.0040]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "mul size: 4 2 5\n",
      "summ: tensor([[-0.1607, -0.0816,  0.1101,  0.0298,  0.0008],\n",
      "        [-0.1602, -0.0815,  0.1085,  0.0288,  0.0012],\n",
      "        [-0.1595, -0.0814,  0.1065,  0.0275,  0.0018],\n",
      "        [-0.1609, -0.0816,  0.1106,  0.0302,  0.0006]], grad_fn=<SumBackward2>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0346],\n",
       "        [-0.0344],\n",
       "        [-0.0341],\n",
       "        [-0.0346]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru(torch.Tensor(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[-0.0149, -0.0224, -0.0442, -0.0559,  0.0038,  0.1103,  0.0143,\n",
    "          -0.0553,  0.1497, -0.0139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=[-0.0266, -0.0397, -0.0583, -0.0963,  0.0111,  0.0910,  0.0135,\n",
    "          -0.0536,  0.1376, -0.0254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[-0.0278, -0.0543, -0.0618, -0.1240,  0.0149,  0.0585,  0.0118,\n",
    "          -0.0443,  0.1054, -0.0272]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0693, -0.1164, -0.1643, -0.2762, 0.0298, 0.2598, 0.039599999999999996, -0.1532, 0.3927, -0.0665]\n"
     ]
    }
   ],
   "source": [
    "g=[]\n",
    "for i in range(10):\n",
    "    #print(i)\n",
    "    g.append(d[i]+e[i]+f[i])\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [-0.1694,  0.0919, -0.3994,  0.2005, -0.1659, -0.2772, -0.2371,\n",
    "          -0.3158, -0.1634, -0.1596]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.056749,\n",
       " 0.0307865,\n",
       " -0.133799,\n",
       " 0.0671675,\n",
       " -0.0555765,\n",
       " -0.092862,\n",
       " -0.07942850000000001,\n",
       " -0.10579300000000001,\n",
       " -0.054739,\n",
       " -0.053466]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [x * 0.3350 for x in a]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.0567,  0.0308, -0.1338,  0.0672, -0.0556, -0.0928, -0.0794,\n",
    "          -0.1058, -0.0547, -0.0535"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
