{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Header Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#list of dataframes into non overlapping sliding windows\n",
    "def list_df_to_contiguous_sliding_windows(list_df, window_size, rem_beg=True):\n",
    "    all_windows = []\n",
    "    for dfs in list_df:\n",
    "        windows = df_to_contiguous_sliding_windows(dfs, window_size, rem_beg=True)\n",
    "        all_windows.extend(windows)\n",
    "    return all_windows\n",
    "\n",
    "#single dataframe into non overlapping sliding windows\n",
    "def df_to_contiguous_sliding_windows(df, window_size, rem_beg=True):\n",
    "    amount_to_remove = len(df)%window_size\n",
    "    if rem_beg:\n",
    "        df_rem = remove_df_starting_rows(df, amount_to_remove)\n",
    "    elif not rem_beg:\n",
    "        df_rem = remove_df_ending_rows(df, amount_to_remove)\n",
    "    \n",
    "    rows = []\n",
    "    windows = []\n",
    "    for index, row in df_rem.iterrows():\n",
    "        rows.append(row.values.tolist())\n",
    "        if len(rows)==window_size:\n",
    "            windows.append(rows)\n",
    "            rows = []\n",
    "    return windows\n",
    "\n",
    "#list of dataframes into overlapping sliding windows\n",
    "def list_df_to_overlapping_sliding_windows(list_df, window_size):\n",
    "    all_windows = []\n",
    "    for dfs in list_df:\n",
    "        windows = df_to_overlapping_sliding_windows(dfs, window_size)\n",
    "        all_windows.extend(windows)\n",
    "    return all_windows\n",
    "\n",
    "#single dataframe into overlapping sliding windows\n",
    "def df_to_overlapping_sliding_windows(dataframe, window_size):\n",
    "    values_array = dataframe.values\n",
    "    s0, s1 = values_array.strides\n",
    "    row, col = values_array.shape\n",
    "    windows = np.lib.stride_tricks.as_strided(values_array, shape=(row-window_size+1, window_size, col), strides=(s0, s0, s1))\n",
    "    return windows\n",
    "\n",
    "#function to remove N starting rows from a dataframe\n",
    "def remove_df_starting_rows(dataframe, amount_to_remove):\n",
    "    if amount_to_remove > 0:\n",
    "        df = dataframe.iloc[amount_to_remove:]                 \n",
    "        return df\n",
    "    else:\n",
    "        return dataframe\n",
    "\n",
    "#function to remove N trailing rows from a dataframe\n",
    "def remove_df_ending_rows(dataframe, amount_to_remove):\n",
    "    if amount_to_remove > 0:\n",
    "        df = dataframe.iloc[:-amount_to_remove]                 \n",
    "        return df\n",
    "    else:\n",
    "        return dataframe\n",
    "\n",
    "#function for ordering files. Very basic (hardcoded positions)\n",
    "def sortKeyFunc(s):\n",
    "    return int(os.path.basename(s)[12:-4])\n",
    "\n",
    "#list of dataframe rows into vectors\n",
    "def list_df_rows_to_vectors(list_df):\n",
    "    all_vectors = []\n",
    "    for dfs in list_df:\n",
    "        vectors = df_rows_to_vectors(dfs)\n",
    "        all_vectors.extend(vectors)\n",
    "    return all_vectors\n",
    "\n",
    "#dataframe rows into a vector\n",
    "def df_rows_to_vectors(df):\n",
    "    vectors = []\n",
    "    for rows in range(len(df)):\n",
    "        row = df.iloc[rows]\n",
    "        vectors.append(row.values.tolist())\n",
    "    return vectors\n",
    "\n",
    "#splitting a pythong list or ndarray into 2 parts according to specificied ratio\n",
    "def split_list_on_ratio(liste, ratio, shuffle=False, random_seed=42):\n",
    "    len_list = len(liste)\n",
    "    if shuffle:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(liste)\n",
    "    \n",
    "    index_where_to_split = math.floor(len_list * ratio)\n",
    "\n",
    "    list_part_a = liste[:index_where_to_split]\n",
    "    list_part_b = liste[index_where_to_split:]\n",
    "    \n",
    "    return list_part_a, list_part_b\n",
    "\n",
    "#loading multiple csv into multiple dataframes, where each csv is a dataframe. Partly hardcoded for a bombardier flight test CSV files.\n",
    "def bomb_csv_to_df(csv_stringLoader):\n",
    "    list_df = []\n",
    "    list_data_units = []\n",
    "    list_data_label_type = []\n",
    "    allFiles = sorted(glob.glob(csv_stringLoader), key=sortKeyFunc)\n",
    "\n",
    "    for files in allFiles:\n",
    "        print('Loading:{}'.format(files))\n",
    "        df = pd.read_csv(files)\n",
    "        df = df.drop('Description', axis=1)\n",
    "        df = df.set_index('TIME OF DAY IN SECONDS')\n",
    "\n",
    "        data_units = df.iloc[0]\n",
    "        data_units.name = 'Unit'\n",
    "\n",
    "        data_label_type = df.iloc[1]\n",
    "        data_label_type.name = 'Type'\n",
    "\n",
    "        df = df.iloc[3:].reset_index()\n",
    "        \n",
    "        list_df.append(df)\n",
    "        list_data_units.append(data_units)\n",
    "        list_data_label_type.append(data_label_type)\n",
    "        \n",
    "    return list_df, list_data_units, list_data_label_type\n",
    "\n",
    "#TODO: Func to verify if list_data_units and list_data_label_type are all the same\n",
    "\n",
    "#purely exogeneous (non-regressive)\n",
    "def list_df_to_exogeneous_df(list_df, target_choice):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list]\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#purely endogenous (non-autoregressive)\n",
    "#to verify if the model can learn copying data\n",
    "def list_df_to_endogeneous_df(list_df, target_choice):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list]\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#exogeneous & endogenous (non-autoregressive)\n",
    "#to verify if the model can learn copying data with more data\n",
    "def list_df_to_endo_exo_df(list_df, target_choice):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow'] + ['2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list]\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#forecasting (endogeneous)\n",
    "def list_df_forecasting_endo_df(list_df, target_choice, shift_delta=1):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list].shift(-shift_delta)\n",
    "        \n",
    "        df_features = df_features.drop(df_features.tail(shift_delta).index)\n",
    "        df_targets = df_targets.drop(df_targets.tail(shift_delta).index)\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#forecasting (exogeneous)\n",
    "def list_df_forecasting_exo_df(list_df, target_choice, shift_delta=1):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list].shift(-shift_delta)\n",
    "        \n",
    "        df_features = df_features.drop(df_features.tail(shift_delta).index)\n",
    "        df_targets = df_targets.drop(df_targets.tail(shift_delta).index)\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#forecasting (endogeneous & exogeneous)\n",
    "def list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta=1):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow'] + ['2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list].shift(-shift_delta)\n",
    "        \n",
    "        df_features = df_features.drop(df_features.tail(shift_delta).index)\n",
    "        df_targets = df_targets.drop(df_targets.tail(shift_delta).index)\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "#from source.utils.preprocessing import *\n",
    "\n",
    "\n",
    "def get_vectors_datasets(csv_files_path, forecasting, feature_endo, feature_exo, target_choice, shift_delta, train_test_ratio, train_valid_ratio, shuffle=False, random_seed=42):\n",
    "    #loading CSV\n",
    "    list_df, list_data_units, list_data_label_type = bomb_csv_to_df(csv_files_path)\n",
    "    \n",
    "    #Note: Train test and valid are made on flights, not the amount of vectors in total!\n",
    "    \n",
    "    #Splitting list of df into train-test\n",
    "    list_df_train, list_df_test = split_list_on_ratio(list_df, train_test_ratio, shuffle, random_seed)\n",
    "    #Splitting list of train into train-valid\n",
    "    list_df_train, list_df_valid = split_list_on_ratio(list_df_train, train_valid_ratio, shuffle, random_seed)\n",
    "    \n",
    "    sfv_ds_train = VectorsDataset(list_df_train, forecasting, feature_endo, feature_exo, target_choice, shift_delta)\n",
    "    sfv_ds_valid = VectorsDataset(list_df_valid, forecasting, feature_endo, feature_exo, target_choice, shift_delta)\n",
    "    sfv_ds_test = VectorsDataset(list_df_test, forecasting, feature_endo, feature_exo, target_choice, shift_delta)\n",
    "    \n",
    "    return sfv_ds_train, sfv_ds_valid, sfv_ds_test\n",
    "    \n",
    "class VectorsDataset(data.Dataset):\n",
    "    def __init__(self, list_df, forecasting, feature_endo, feature_exo, target_choice, shift_delta=1, target_type_string='Regression'):\n",
    "        #target_choice is a parameter to pick if we use bay 1 (1), bay 2 (2) or both bays (0) as targets\n",
    "        #Forecasting decides if the targets are N steps ahead(if True), or if we predict the current time step (if False)\n",
    "        #Endo is if we want to use the bay temperature in the features\n",
    "        #Exo is if we want to use the other data (the data that arent bay temp) in the features\n",
    "        #Target type string is either Regression or Classification. Required for other objects down the training pipeline.\n",
    "        self.target_type_string = target_type_string\n",
    "        #Shift Delta is the parameter for forecasting that decides the N step ahead for target prediction\n",
    "        \n",
    "        if forecasting: #forecasting task (N step ahead)\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_exo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "\n",
    "        if not forecasting: #Intra step prediction\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endogeneous_df(list_df, target_choice)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_to_exogeneous_df(list_df, target_choice)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "\n",
    "        all_vectors_features = list_df_rows_to_vectors(list_df_features)\n",
    "        all_vectors_targets = list_df_rows_to_vectors(list_df_targets)\n",
    "        \n",
    "        self.features = all_vectors_features\n",
    "        self.targets = all_vectors_targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features_item = self.features[index]\n",
    "        targets_item = self.targets[index]\n",
    "        \n",
    "        #TODO: Verify if returns as \"Lists\" are problematics for the dataloaders (might want Tensors and basetypes such as floats)\n",
    "        return features_item, targets_item\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.features)==len(self.targets):\n",
    "            return len(self.targets)\n",
    "        else:\n",
    "            raise('The dataset does not have one target per feature and vice versa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_files_path = \"../DataBombardier/flight_test_*.csv\"\n",
    "forecasting = False\n",
    "feature_endo = False\n",
    "feature_exo = True\n",
    "target_choice = 0\n",
    "shift_delta = 1\n",
    "train_test_ratio = 0.8\n",
    "train_valid_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:../DataBombardier/flight_test_1.csv\n",
      "Loading:../DataBombardier/flight_test_2.csv\n",
      "Loading:../DataBombardier/flight_test_3.csv\n",
      "Loading:../DataBombardier/flight_test_4.csv\n",
      "Loading:../DataBombardier/flight_test_5.csv\n",
      "Loading:../DataBombardier/flight_test_6.csv\n",
      "Loading:../DataBombardier/flight_test_7.csv\n",
      "Loading:../DataBombardier/flight_test_8.csv\n",
      "Loading:../DataBombardier/flight_test_9.csv\n",
      "Loading:../DataBombardier/flight_test_10.csv\n",
      "Loading:../DataBombardier/flight_test_11.csv\n",
      "Loading:../DataBombardier/flight_test_12.csv\n",
      "Loading:../DataBombardier/flight_test_13.csv\n"
     ]
    }
   ],
   "source": [
    "sfv_ds_train, sfv_ds_valid, sfv_ds_test = get_vectors_datasets(csv_files_path,\n",
    "                                                                forecasting, feature_endo, feature_exo, target_choice, shift_delta, \n",
    "                                                                train_test_ratio, train_valid_ratio, \n",
    "                                                                shuffle=False, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sfvf, sfvt = sfv_ds_train[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17926',\n",
       " '5.159813',\n",
       " '17.693799',\n",
       " '29.449458',\n",
       " '26.194133',\n",
       " '2364.0',\n",
       " '0.008864',\n",
       " '8.542919',\n",
       " '15.155848']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35.230574', '33.70978508573387']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfvt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contiguous Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "#from source.utils.preprocessing import *\n",
    "\n",
    "\n",
    "def get_contiguous_windows_datasets(csv_files_path, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, train_test_ratio, train_valid_ratio, remove_beg_rows=True, shuffle=False, random_seed=42):\n",
    "    #loading CSV\n",
    "    list_df, list_data_units, list_data_label_type = bomb_csv_to_df(csv_files_path)\n",
    "    \n",
    "    #Note: Train test and valid are made on flights, not the amount of vectors in total!\n",
    "    \n",
    "    #Splitting list of df into train-test\n",
    "    list_df_train, list_df_test = split_list_on_ratio(list_df, train_test_ratio, shuffle, random_seed)\n",
    "    #Splitting list of train into train-valid\n",
    "    list_df_train, list_df_valid = split_list_on_ratio(list_df_train, train_valid_ratio, shuffle, random_seed)\n",
    "    \n",
    "    cw_ds_train = ContiguousWindowsDataset(list_df_train, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, remove_beg_rows)\n",
    "    cw_ds_valid = ContiguousWindowsDataset(list_df_valid, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, remove_beg_rows)\n",
    "    cw_ds_test = ContiguousWindowsDataset(list_df_test, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, remove_beg_rows)\n",
    "    \n",
    "    return cw_ds_train, cw_ds_valid, cw_ds_test\n",
    "    \n",
    "class ContiguousWindowsDataset(data.Dataset):\n",
    "    def __init__(self, list_df, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta=1, remove_beg_rows=True, target_type_string='Regression'):\n",
    "        #target_choice is a parameter to pick if we use bay 1 (1), bay 2 (2) or both bays (0) as targets\n",
    "        #Forecasting decides if the targets are N steps ahead(if True), or if we predict the current time step (if False)\n",
    "        #Endo is if we want to use the bay temperature in the features\n",
    "        #Exo is if we want to use the other data (the data that arent bay temp) in the features\n",
    "        #Target type string is either Regression or Classification. Required for other objects down the training pipeline.\n",
    "        self.target_type_string = target_type_string\n",
    "        #Shift Delta is the parameter for forecasting that decides the N step ahead for target prediction\n",
    "        \n",
    "        if forecasting: #forecasting task (N step ahead)\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_exo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "\n",
    "        if not forecasting: #Intra step prediction\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endogeneous_df(list_df, target_choice)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_to_exogeneous_df(list_df, target_choice)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "\n",
    "        all_contiguous_features_windows = list_df_to_contiguous_sliding_windows(list_df_features, windows_size, rem_beg=remove_beg_rows)\n",
    "        all_contiguous_targets_windows = list_df_to_contiguous_sliding_windows(list_df_targets, windows_size, rem_beg=remove_beg_rows)\n",
    "        \n",
    "        self.features = all_contiguous_features_windows\n",
    "        self.targets = all_contiguous_targets_windows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features_item = self.features[index]\n",
    "        targets_item = self.targets[index][-1]\n",
    "        \n",
    "        #TODO: Verify if returns as \"Lists\" are problematics for the dataloaders (might want Tensors and basetypes such as floats)\n",
    "        return features_item, targets_item\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.features)==len(self.targets):\n",
    "            return len(self.targets)\n",
    "        else:\n",
    "            raise('The dataset does not have one target per feature and vice versa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_files_path = \"../DataBombardier/flight_test_*.csv\"\n",
    "forecasting = False\n",
    "feature_endo = True\n",
    "feature_exo = False\n",
    "target_choice = 0\n",
    "shift_delta = 3\n",
    "windows_size = 4\n",
    "train_test_ratio = 0.8\n",
    "train_valid_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:../DataBombardier/flight_test_1.csv\n",
      "Loading:../DataBombardier/flight_test_2.csv\n",
      "Loading:../DataBombardier/flight_test_3.csv\n",
      "Loading:../DataBombardier/flight_test_4.csv\n",
      "Loading:../DataBombardier/flight_test_5.csv\n",
      "Loading:../DataBombardier/flight_test_6.csv\n",
      "Loading:../DataBombardier/flight_test_7.csv\n",
      "Loading:../DataBombardier/flight_test_8.csv\n",
      "Loading:../DataBombardier/flight_test_9.csv\n",
      "Loading:../DataBombardier/flight_test_10.csv\n",
      "Loading:../DataBombardier/flight_test_11.csv\n",
      "Loading:../DataBombardier/flight_test_12.csv\n",
      "Loading:../DataBombardier/flight_test_13.csv\n"
     ]
    }
   ],
   "source": [
    "cw_ds_train, cw_ds_valid, cw_ds_test = get_contiguous_windows_datasets(csv_files_path, \n",
    "                                                                       forecasting, feature_endo, feature_exo, target_choice, \n",
    "                                                                       windows_size, shift_delta, \n",
    "                                                                       train_test_ratio, train_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwf, cwt = cw_ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['17902', '35.240755', '33.76746076717663'],\n",
       " ['17904', '35.250933', '33.78781427556584'],\n",
       " ['17906', '35.233968', '33.77085186112588'],\n",
       " ['17908', '35.244148', '33.78781427556584']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35.244148', '33.78781427556584']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "#from source.utils.preprocessing import *\n",
    "\n",
    "\n",
    "def get_overlapping_windows_datasets(csv_files_path, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, train_test_ratio, train_valid_ratio, shuffle=False, random_seed=42):\n",
    "    #loading CSV\n",
    "    list_df, list_data_units, list_data_label_type = bomb_csv_to_df(csv_files_path)\n",
    "    \n",
    "    #Note: Train test and valid are made on flights, not the amount of vectors in total!\n",
    "    \n",
    "    #Splitting list of df into train-test\n",
    "    list_df_train, list_df_test = split_list_on_ratio(list_df, train_test_ratio, shuffle, random_seed)\n",
    "    #Splitting list of train into train-valid\n",
    "    list_df_train, list_df_valid = split_list_on_ratio(list_df_train, train_valid_ratio, shuffle, random_seed)\n",
    "    \n",
    "    ow_ds_train = OverlappingWindowsDataset(list_df_train, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta)\n",
    "    ow_ds_valid = OverlappingWindowsDataset(list_df_valid, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta)\n",
    "    ow_ds_test = OverlappingWindowsDataset(list_df_test, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta)\n",
    "    \n",
    "    return ow_ds_train, ow_ds_valid, ow_ds_test\n",
    "    \n",
    "class OverlappingWindowsDataset(data.Dataset):\n",
    "    def __init__(self, list_df, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta=1, target_type_string='Regression'):\n",
    "        #target_choice is a parameter to pick if we use bay 1 (1), bay 2 (2) or both bays (0) as targets\n",
    "        #Forecasting decides if the targets are N steps ahead(if True), or if we predict the current time step (if False)\n",
    "        #Endo is if we want to use the bay temperature in the features\n",
    "        #Exo is if we want to use the other data (the data that arent bay temp) in the features\n",
    "        #Target type string is either Regression or Classification. Required for other objects down the training pipeline.\n",
    "        self.target_type_string = target_type_string\n",
    "        #Shift Delta is the parameter for forecasting that decides the N step ahead for target prediction\n",
    "        \n",
    "        if forecasting: #forecasting task (N step ahead)\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_exo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "\n",
    "        if not forecasting: #Intra step prediction\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endogeneous_df(list_df, target_choice)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_to_exogeneous_df(list_df, target_choice)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "\n",
    "        all_overlapping_features_windows = list_df_to_overlapping_sliding_windows(list_df_features, windows_size)\n",
    "        all_overlapping_targets_windows = list_df_to_overlapping_sliding_windows(list_df_targets, windows_size)\n",
    "        \n",
    "        self.features = all_overlapping_features_windows\n",
    "        self.targets = all_overlapping_targets_windows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features_item = self.features[index].tolist()\n",
    "        targets_item = self.targets[index][-1].tolist()\n",
    "        \n",
    "        #TODO: Verify if returns as \"Lists\" are problematics for the dataloaders (might want Tensors and basetypes such as floats)\n",
    "        return features_item, targets_item\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.features)==len(self.targets):\n",
    "            return len(self.targets)\n",
    "        else:\n",
    "            raise('The dataset does not have one target per feature and vice versa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_files_path = \"../DataBombardier/flight_test_*.csv\"\n",
    "forecasting = False\n",
    "feature_endo = True\n",
    "feature_exo = False\n",
    "target_choice = 0\n",
    "shift_delta = 1\n",
    "windows_size = 4\n",
    "train_test_ratio = 0.8\n",
    "train_valid_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:../DataBombardier\\flight_test_1.csv\n",
      "Loading:../DataBombardier\\flight_test_2.csv\n",
      "Loading:../DataBombardier\\flight_test_3.csv\n",
      "Loading:../DataBombardier\\flight_test_4.csv\n",
      "Loading:../DataBombardier\\flight_test_5.csv\n",
      "Loading:../DataBombardier\\flight_test_6.csv\n",
      "Loading:../DataBombardier\\flight_test_7.csv\n",
      "Loading:../DataBombardier\\flight_test_8.csv\n",
      "Loading:../DataBombardier\\flight_test_9.csv\n",
      "Loading:../DataBombardier\\flight_test_10.csv\n",
      "Loading:../DataBombardier\\flight_test_11.csv\n",
      "Loading:../DataBombardier\\flight_test_12.csv\n",
      "Loading:../DataBombardier\\flight_test_13.csv\n"
     ]
    }
   ],
   "source": [
    "ow_ds_train, ow_ds_valid, ow_ds_test = get_overlapping_windows_datasets(csv_files_path, \n",
    "                                                                       forecasting, feature_endo, feature_exo, target_choice, \n",
    "                                                                       windows_size, shift_delta, \n",
    "                                                                       train_test_ratio, train_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "owf, owt = ow_ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['17902', '35.240755', '33.76746076717663'],\n",
       " ['17904', '35.250933', '33.78781427556584'],\n",
       " ['17906', '35.233968', '33.77085186112588'],\n",
       " ['17908', '35.244148', '33.78781427556584']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35.244148', '33.78781427556584']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
