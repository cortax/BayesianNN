{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Header Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#list of dataframes into non overlapping sliding windows\n",
    "def list_df_to_contiguous_sliding_windows(list_df, window_size, rem_beg=True):\n",
    "    all_windows = []\n",
    "    for dfs in list_df:\n",
    "        windows = df_to_contiguous_sliding_windows(dfs, window_size, rem_beg=True)\n",
    "        all_windows.extend(windows)\n",
    "    return all_windows\n",
    "\n",
    "#single dataframe into non overlapping sliding windows\n",
    "def df_to_contiguous_sliding_windows(df, window_size, rem_beg=True):\n",
    "    amount_to_remove = len(df)%window_size\n",
    "    if rem_beg:\n",
    "        df_rem = remove_df_starting_rows(df, amount_to_remove)\n",
    "    elif not rem_beg:\n",
    "        df_rem = remove_df_ending_rows(df, amount_to_remove)\n",
    "    \n",
    "    rows = []\n",
    "    windows = []\n",
    "    for index, row in df_rem.iterrows():\n",
    "        rows.append(row.values.tolist())\n",
    "        if len(rows)==window_size:\n",
    "            windows.append(rows)\n",
    "            rows = []\n",
    "    return windows\n",
    "\n",
    "#list of dataframes into overlapping sliding windows\n",
    "def list_df_to_overlapping_sliding_windows(list_df, window_size):\n",
    "    all_windows = []\n",
    "    for dfs in list_df:\n",
    "        windows = df_to_overlapping_sliding_windows(dfs, window_size)\n",
    "        all_windows.extend(windows)\n",
    "    return all_windows\n",
    "\n",
    "#single dataframe into overlapping sliding windows\n",
    "def df_to_overlapping_sliding_windows(dataframe, window_size):\n",
    "    values_array = dataframe.values\n",
    "    s0, s1 = values_array.strides\n",
    "    row, col = values_array.shape\n",
    "    windows = np.lib.stride_tricks.as_strided(values_array, shape=(row-window_size+1, window_size, col), strides=(s0, s0, s1))\n",
    "    return windows\n",
    "\n",
    "#function to remove N starting rows from a dataframe\n",
    "def remove_df_starting_rows(dataframe, amount_to_remove):\n",
    "    if amount_to_remove > 0:\n",
    "        df = dataframe.iloc[amount_to_remove:]                 \n",
    "        return df\n",
    "    else:\n",
    "        return dataframe\n",
    "\n",
    "#function to remove N trailing rows from a dataframe\n",
    "def remove_df_ending_rows(dataframe, amount_to_remove):\n",
    "    if amount_to_remove > 0:\n",
    "        df = dataframe.iloc[:-amount_to_remove]                 \n",
    "        return df\n",
    "    else:\n",
    "        return dataframe\n",
    "\n",
    "#function for ordering files. Very basic (hardcoded positions)\n",
    "def sortKeyFunc(s):\n",
    "    return int(os.path.basename(s)[12:-4])\n",
    "\n",
    "#list of dataframe rows into vectors\n",
    "def list_df_rows_to_vectors(list_df):\n",
    "    all_vectors = []\n",
    "    for dfs in list_df:\n",
    "        vectors = df_rows_to_vectors(dfs)\n",
    "        all_vectors.extend(vectors)\n",
    "    return all_vectors\n",
    "\n",
    "#dataframe rows into a vector\n",
    "def df_rows_to_vectors(df):\n",
    "    vectors = []\n",
    "    for rows in range(len(df)):\n",
    "        row = df.iloc[rows]\n",
    "        vectors.append(row.values.tolist())\n",
    "    return vectors\n",
    "\n",
    "#splitting a pythong list or ndarray into 2 parts according to specificied ratio\n",
    "def split_list_on_ratio(liste, ratio, shuffle=False, random_seed=42):\n",
    "    len_list = len(liste)\n",
    "    if shuffle:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(liste)\n",
    "    \n",
    "    index_where_to_split = math.floor(len_list * ratio)\n",
    "\n",
    "    list_part_a = liste[:index_where_to_split]\n",
    "    list_part_b = liste[index_where_to_split:]\n",
    "    \n",
    "    return list_part_a, list_part_b\n",
    "\n",
    "#loading multiple csv into multiple dataframes, where each csv is a dataframe. Partly hardcoded for a bombardier flight test CSV files.\n",
    "def bomb_csv_to_df(csv_stringLoader):\n",
    "    list_df = []\n",
    "    list_data_units = []\n",
    "    list_data_label_type = []\n",
    "    allFiles = sorted(glob.glob(csv_stringLoader), key=sortKeyFunc)\n",
    "\n",
    "    for files in allFiles:\n",
    "        print('Loading:{}'.format(files))\n",
    "        df = pd.read_csv(files)\n",
    "        df = df.drop('Description', axis=1)\n",
    "        df = df.set_index('TIME OF DAY IN SECONDS')\n",
    "\n",
    "        data_units = df.iloc[0]\n",
    "        data_units.name = 'Unit'\n",
    "\n",
    "        data_label_type = df.iloc[1]\n",
    "        data_label_type.name = 'Type'\n",
    "\n",
    "        df = df.iloc[3:].reset_index()\n",
    "        df = df.apply(pd.to_numeric)\n",
    "        \n",
    "        list_df.append(df)\n",
    "        list_data_units.append(data_units)\n",
    "        list_data_label_type.append(data_label_type)\n",
    "        \n",
    "    return list_df, list_data_units, list_data_label_type\n",
    "\n",
    "#TODO: Func to verify if list_data_units and list_data_label_type are all the same\n",
    "\n",
    "#List df to max array\n",
    "def list_df_to_max_array(list_df):\n",
    "    maxdflist = []\n",
    "    for df in list_df:\n",
    "        maxdflist.append(df.describe(include='all').loc[ \"max\", :].to_numpy())\n",
    "        #print(df.describe(include='all').loc[ \"max\", :].to_numpy())\n",
    "    for m in range(len(maxdflist)):\n",
    "        #print(m)\n",
    "        if m==0:\n",
    "            maxarray = maxdflist[m]\n",
    "        else:\n",
    "            maxarray = np.maximum(maxarray, maxdflist[m])\n",
    "    #print(maxarray)\n",
    "    return maxarray\n",
    "\n",
    "#list df to min array\n",
    "def list_df_to_min_array(list_df):\n",
    "    mindflist = []\n",
    "    for df in list_df:\n",
    "        mindflist.append(df.describe(include='all').loc[ \"min\", :].to_numpy())\n",
    "        #print(df.describe(include='all').loc[ \"max\", :].to_numpy())\n",
    "    for m in range(len(mindflist)):\n",
    "        #print(m)\n",
    "        if m==0:\n",
    "            minarray = mindflist[m]\n",
    "        else:\n",
    "            minarray = np.minimum(minarray, mindflist[m])\n",
    "    #print(minarray)\n",
    "    return minarray\n",
    "\n",
    "#max and min array to rescaling array (bigger values of both, column-wise)\n",
    "def min_max_arrays_to_rescaling_array(minarray, maxarray):\n",
    "    rescaling_array = np.maximum(np.absolute(minarray), maxarray)\n",
    "    return rescaling_array\n",
    "\n",
    "#to rescale columns of a single df from a rescaling array\n",
    "def rescale_single_df(df, rescaling_array):\n",
    "    rescaled_df = pd.DataFrame()\n",
    "    for e, (columnName, columnData) in enumerate(df.iteritems()):\n",
    "        #print(e)\n",
    "        #print(columnName)\n",
    "        #print(columnData)\n",
    "        rescaled_df[columnName] = columnData/(rescaling_array[e]+1)\n",
    "    return rescaled_df\n",
    "\n",
    "#rescale a list of df, column-wise\n",
    "def rescale_list_of_df(list_df):\n",
    "    minarray = list_df_to_min_array(list_df)\n",
    "    maxarray = list_df_to_max_array(list_df)\n",
    "    rescaling_array = min_max_arrays_to_rescaling_array(minarray, maxarray)\n",
    "    \n",
    "    rescaled_list_df = []\n",
    "    for df in list_df:\n",
    "        rescaled_list_df.append(rescale_single_df(df, rescaling_array))\n",
    "    return rescaled_list_df\n",
    "\n",
    "#purely exogeneous (non-regressive)\n",
    "def list_df_to_exogeneous_df(list_df, target_choice):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list]\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#purely endogenous (non-autoregressive)\n",
    "#to verify if the model can learn copying data\n",
    "def list_df_to_endogeneous_df(list_df, target_choice):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list]\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#exogeneous & endogenous (non-autoregressive)\n",
    "#to verify if the model can learn copying data with more data\n",
    "def list_df_to_endo_exo_df(list_df, target_choice):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow'] + ['2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list]\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#forecasting (endogeneous)\n",
    "def list_df_forecasting_endo_df(list_df, target_choice, shift_delta=1):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list].shift(-shift_delta)\n",
    "        \n",
    "        df_features = df_features.drop(df_features.tail(shift_delta).index)\n",
    "        df_targets = df_targets.drop(df_targets.tail(shift_delta).index)\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#forecasting (exogeneous)\n",
    "def list_df_forecasting_exo_df(list_df, target_choice, shift_delta=1):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list].shift(-shift_delta)\n",
    "        \n",
    "        df_features = df_features.drop(df_features.tail(shift_delta).index)\n",
    "        df_targets = df_targets.drop(df_targets.tail(shift_delta).index)\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n",
    "\n",
    "#forecasting (endogeneous & exogeneous)\n",
    "def list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta=1):\n",
    "    list_df_features = []\n",
    "    list_df_targets = []\n",
    "\n",
    "    for df in list_df:\n",
    "        if target_choice==0:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow', '2nd Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP', '2nd AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==1:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        elif target_choice==2:\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '2nd Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '2nd Underfloor flow'] + ['2nd AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['2nd AVIONICS BAY BULK TEMP']\n",
    "        else:\n",
    "            target_choice=1\n",
    "            features_list = ['TIME OF DAY IN SECONDS', '1st Cooling Sys MASS FLOW', 'ACS_Zone_Actual_Temperature', 'Outside Air Temperature_OAT', 'Pressure Altitude', 'Mach', '1st Underfloor flow'] + ['1st AVIONICS BAY BULK TEMP']\n",
    "            targets_list = ['1st AVIONICS BAY BULK TEMP']\n",
    "        \n",
    "        df_features = df[features_list]\n",
    "        df_targets = df[targets_list].shift(-shift_delta)\n",
    "        \n",
    "        df_features = df_features.drop(df_features.tail(shift_delta).index)\n",
    "        df_targets = df_targets.drop(df_targets.tail(shift_delta).index)\n",
    "        \n",
    "        list_df_features.append(df_features)\n",
    "        list_df_targets.append(df_targets)\n",
    "        \n",
    "    return list_df_features, list_df_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from source.utils.preprocessing import *\n",
    "\n",
    "\n",
    "def get_vectors_datasets(csv_files_path,\n",
    "                            forecasting, feature_endo, feature_exo, target_choice, \n",
    "                            shift_delta, \n",
    "                            train_test_ratio, train_valid_ratio, \n",
    "                            shuffle=False, random_seed=42):\n",
    "    #loading CSV\n",
    "    list_df, list_data_units, list_data_label_type = bomb_csv_to_df(csv_files_path)\n",
    "    rescaled_list_df = rescale_list_of_df(list_df)\n",
    "    \n",
    "    #Note: Train test and valid are made on flights, not the amount of vectors in total!\n",
    "    \n",
    "    #Splitting list of df into train-test\n",
    "    list_df_train, list_df_test = split_list_on_ratio(rescaled_list_df, train_test_ratio, shuffle, random_seed)\n",
    "    #Splitting list of train into train-valid\n",
    "    list_df_train, list_df_valid = split_list_on_ratio(list_df_train, train_valid_ratio, shuffle, random_seed)\n",
    "    \n",
    "    sfv_ds_train = VectorsDataset(list_df_train, forecasting, feature_endo, feature_exo, target_choice, shift_delta)\n",
    "    sfv_ds_valid = VectorsDataset(list_df_valid, forecasting, feature_endo, feature_exo, target_choice, shift_delta)\n",
    "    sfv_ds_test = VectorsDataset(list_df_test, forecasting, feature_endo, feature_exo, target_choice, shift_delta)\n",
    "    \n",
    "    return sfv_ds_train, sfv_ds_valid, sfv_ds_test\n",
    "    \n",
    "class VectorsDataset(data.Dataset):\n",
    "    def __init__(self, list_df, forecasting, feature_endo, feature_exo, target_choice, shift_delta=1, target_type_string='Regression'):\n",
    "        #target_choice is a parameter to pick if we use bay 1 (1), bay 2 (2) or both bays (0) as targets\n",
    "        #Forecasting decides if the targets are N steps ahead(if True), or if we predict the current time step (if False)\n",
    "        #Endo is if we want to use the bay temperature in the features\n",
    "        #Exo is if we want to use the other data (the data that arent bay temp) in the features\n",
    "        #Target type string is either Regression or Classification. Required for other objects down the training pipeline.\n",
    "        self.target_type_string = target_type_string\n",
    "        #Shift Delta is the parameter for forecasting that decides the N step ahead for target prediction\n",
    "        \n",
    "        if forecasting: #forecasting task (N step ahead)\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_exo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "\n",
    "        if not forecasting: #Intra step prediction\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endogeneous_df(list_df, target_choice)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_to_exogeneous_df(list_df, target_choice)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "\n",
    "        all_vectors_features = list_df_rows_to_vectors(list_df_features)\n",
    "        all_vectors_targets = list_df_rows_to_vectors(list_df_targets)\n",
    "        \n",
    "        self.features = all_vectors_features\n",
    "        self.targets = all_vectors_targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features_item = self.features[index]\n",
    "        targets_item = self.targets[index]\n",
    "        \n",
    "        #TODO: Verify if returns typage is \"ok\"\n",
    "        return torch.Tensor(features_item), torch.Tensor(targets_item)\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.features)==len(self.targets):\n",
    "            return len(self.targets)\n",
    "        else:\n",
    "            raise('The dataset does not have one target per feature and vice versa')\n",
    "\n",
    "    def features_size(self, index=0):\n",
    "        return len(self.features[index])\n",
    "\n",
    "    def labels_size(self, index=0):\n",
    "        return len(self.targets[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_path = \"../DataBombardier/2sec/flight_test_*.csv\"\n",
    "forecasting = True\n",
    "feature_endo = True\n",
    "feature_exo = True\n",
    "target_choice = 0\n",
    "shift_delta = 2\n",
    "train_test_ratio = 0.8\n",
    "train_valid_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_vectors_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-14b050f6ac6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m sfv_ds_train, sfv_ds_valid, sfv_ds_test = get_vectors_datasets(csv_files_path,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                                 \u001b[0mforecasting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_endo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_exo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_choice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift_delta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                                 \u001b[0mtrain_test_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_valid_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                 shuffle=False, random_seed=42)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_vectors_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "sfv_ds_train, sfv_ds_valid, sfv_ds_test = get_vectors_datasets(csv_files_path,\n",
    "                                                                forecasting, feature_endo, feature_exo, target_choice, shift_delta, \n",
    "                                                                train_test_ratio, train_valid_ratio, \n",
    "                                                                shuffle=False, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sfvf, sfvt = sfv_ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7902e+04, 5.1191e+00, 1.7831e+01, 2.9710e+01, 2.6151e+01, 2.3650e+03,\n",
       "        8.8510e-03, 8.6523e+00, 1.5142e+01, 3.5241e+01, 3.3767e+01])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.2340, 33.7709])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfv_ds_train.features_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfv_ds_train.labels_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contiguous Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from source.utils.preprocessing import *\n",
    "\n",
    "\n",
    "def get_contiguous_windows_datasets(csv_files_path, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, train_test_ratio, train_valid_ratio, remove_beg_rows=True, shuffle=False, random_seed=42):\n",
    "    #loading CSV\n",
    "    list_df, list_data_units, list_data_label_type = bomb_csv_to_df(csv_files_path)\n",
    "    rescaled_list_df = rescale_list_of_df(list_df)\n",
    "\n",
    "    #Note: Train test and valid are made on flights, not the amount of vectors in total!\n",
    "    \n",
    "    #Splitting list of df into train-test\n",
    "    list_df_train, list_df_test = split_list_on_ratio(rescaled_list_df, train_test_ratio, shuffle, random_seed)\n",
    "    #Splitting list of train into train-valid\n",
    "    list_df_train, list_df_valid = split_list_on_ratio(list_df_train, train_valid_ratio, shuffle, random_seed)\n",
    "    \n",
    "    cw_ds_train = ContiguousWindowsDataset(list_df_train, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, remove_beg_rows)\n",
    "    cw_ds_valid = ContiguousWindowsDataset(list_df_valid, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, remove_beg_rows)\n",
    "    cw_ds_test = ContiguousWindowsDataset(list_df_test, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, remove_beg_rows)\n",
    "    \n",
    "    return cw_ds_train, cw_ds_valid, cw_ds_test\n",
    "    \n",
    "class ContiguousWindowsDataset(data.Dataset):\n",
    "    def __init__(self, list_df, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta=1, remove_beg_rows=True, target_type_string='Regression'):\n",
    "        #target_choice is a parameter to pick if we use bay 1 (1), bay 2 (2) or both bays (0) as targets\n",
    "        #Forecasting decides if the targets are N steps ahead(if True), or if we predict the current time step (if False)\n",
    "        #Endo is if we want to use the bay temperature in the features\n",
    "        #Exo is if we want to use the other data (the data that arent bay temp) in the features\n",
    "        #Target type string is either Regression or Classification. Required for other objects down the training pipeline.\n",
    "        self.target_type_string = target_type_string\n",
    "        #Shift Delta is the parameter for forecasting that decides the N step ahead for target prediction\n",
    "        \n",
    "        if forecasting: #forecasting task (N step ahead)\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_exo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "\n",
    "        if not forecasting: #Intra step prediction\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endogeneous_df(list_df, target_choice)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_to_exogeneous_df(list_df, target_choice)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "\n",
    "        all_contiguous_features_windows = list_df_to_contiguous_sliding_windows(list_df_features, windows_size, rem_beg=remove_beg_rows)\n",
    "        all_contiguous_targets_windows = list_df_to_contiguous_sliding_windows(list_df_targets, windows_size, rem_beg=remove_beg_rows)\n",
    "        \n",
    "        self.features = all_contiguous_features_windows\n",
    "        self.targets = all_contiguous_targets_windows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features_item = self.features[index]\n",
    "        targets_item = self.targets[index][-1]\n",
    "        \n",
    "        #TODO: Verify if returns typage is \"ok\"\n",
    "        return torch.Tensor(features_item), torch.Tensor(targets_item)\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.features)==len(self.targets):\n",
    "            return len(self.targets)\n",
    "        else:\n",
    "            raise('The dataset does not have one target per feature and vice versa')\n",
    "\n",
    "    def features_size(self, index=0):\n",
    "        return len(self.features[index][-1])\n",
    "\n",
    "    def labels_size(self, index=0):\n",
    "        return len(self.targets[index][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_path = \"../DataBombardier/2sec/flight_test_*.csv\"\n",
    "forecasting = False\n",
    "feature_endo = True\n",
    "feature_exo = False\n",
    "target_choice = 0\n",
    "shift_delta = 3\n",
    "windows_size = 4\n",
    "train_test_ratio = 0.8\n",
    "train_valid_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:../DataBombardier/2sec\\flight_test_1.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_3.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_4.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_5.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_6.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_7.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_8.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_9.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_10.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_11.csv\n"
     ]
    }
   ],
   "source": [
    "cw_ds_train, cw_ds_valid, cw_ds_test = get_contiguous_windows_datasets(csv_files_path, \n",
    "                                                                       forecasting, feature_endo, feature_exo, target_choice, \n",
    "                                                                       windows_size, shift_delta, \n",
    "                                                                       train_test_ratio, train_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwf, cwt = cw_ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17902.0000,    35.2408,    33.7675],\n",
       "        [17904.0000,    35.2509,    33.7878],\n",
       "        [17906.0000,    35.2340,    33.7709],\n",
       "        [17908.0000,    35.2441,    33.7878]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.2441, 33.7878])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_ds_train.features_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_ds_train.labels_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "#from source.utils.preprocessing import *\n",
    "\n",
    "\n",
    "def get_overlapping_windows_datasets(csv_files_path, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta, train_test_ratio, train_valid_ratio, shuffle=False, random_seed=42):\n",
    "    #loading CSV\n",
    "    list_df, list_data_units, list_data_label_type = bomb_csv_to_df(csv_files_path)\n",
    "    rescaled_list_df = rescale_list_of_df(list_df)\n",
    "\n",
    "    #Note: Train test and valid are made on flights, not the amount of vectors in total!\n",
    "    \n",
    "    #Splitting list of df into train-test\n",
    "    list_df_train, list_df_test = split_list_on_ratio(rescaled_list_df, train_test_ratio, shuffle, random_seed)\n",
    "    #Splitting list of train into train-valid\n",
    "    list_df_train, list_df_valid = split_list_on_ratio(list_df_train, train_valid_ratio, shuffle, random_seed)\n",
    "    \n",
    "    ow_ds_train = OverlappingWindowsDataset(list_df_train, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta)\n",
    "    ow_ds_valid = OverlappingWindowsDataset(list_df_valid, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta)\n",
    "    ow_ds_test = OverlappingWindowsDataset(list_df_test, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta)\n",
    "    \n",
    "    return ow_ds_train, ow_ds_valid, ow_ds_test\n",
    "    \n",
    "class OverlappingWindowsDataset(data.Dataset):\n",
    "    def __init__(self, list_df, forecasting, feature_endo, feature_exo, target_choice, windows_size, shift_delta=1, target_type_string='Regression'):\n",
    "        #target_choice is a parameter to pick if we use bay 1 (1), bay 2 (2) or both bays (0) as targets\n",
    "        #Forecasting decides if the targets are N steps ahead(if True), or if we predict the current time step (if False)\n",
    "        #Endo is if we want to use the bay temperature in the features\n",
    "        #Exo is if we want to use the other data (the data that arent bay temp) in the features\n",
    "        #Target type string is either Regression or Classification. Required for other objects down the training pipeline.\n",
    "        self.target_type_string = target_type_string\n",
    "        #Shift Delta is the parameter for forecasting that decides the N step ahead for target prediction\n",
    "        \n",
    "        if forecasting: #forecasting task (N step ahead)\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_exo_df(list_df, target_choice, shift_delta)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_forecasting_endo_exo_df(list_df, target_choice, shift_delta)\n",
    "\n",
    "        if not forecasting: #Intra step prediction\n",
    "            if feature_endo and not feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endogeneous_df(list_df, target_choice)\n",
    "            elif feature_exo and not feature_endo:\n",
    "                list_df_features, list_df_targets = list_df_to_exogeneous_df(list_df, target_choice)\n",
    "            elif feature_endo and feature_exo:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "            else:\n",
    "                list_df_features, list_df_targets = list_df_to_endo_exo_df(list_df, target_choice)\n",
    "\n",
    "        all_overlapping_features_windows = list_df_to_overlapping_sliding_windows(list_df_features, windows_size)\n",
    "        all_overlapping_targets_windows = list_df_to_overlapping_sliding_windows(list_df_targets, windows_size)\n",
    "        \n",
    "        self.features = all_overlapping_features_windows\n",
    "        self.targets = all_overlapping_targets_windows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features_item = self.features[index].tolist()\n",
    "        targets_item = self.targets[index][-1].tolist()\n",
    "        \n",
    "        #TODO: Verify if returns typage is \"ok\"\n",
    "        return torch.Tensor(features_item), torch.Tensor(targets_item)\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.features)==len(self.targets):\n",
    "            return len(self.targets)\n",
    "        else:\n",
    "            raise('The dataset does not have one target per feature and vice versa')\n",
    "        \n",
    "    def features_size(self, index=0):\n",
    "        return len(self.features[index][-1].tolist())\n",
    "\n",
    "    def labels_size(self, index=0):\n",
    "        return len(self.targets[index][-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_path = \"../DataBombardier/2sec/flight_test_*.csv\"\n",
    "forecasting = True\n",
    "feature_endo = False\n",
    "feature_exo = True\n",
    "target_choice = 1\n",
    "shift_delta = 1\n",
    "windows_size = 32\n",
    "stride = 30\n",
    "train_test_ratio = 0.8\n",
    "train_valid_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:../DataBombardier/2sec\\flight_test_1.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_3.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_4.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_5.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_6.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_7.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_8.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_9.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_10.csv\n",
      "Loading:../DataBombardier/2sec\\flight_test_11.csv\n"
     ]
    }
   ],
   "source": [
    "ow_ds_train, ow_ds_valid, ow_ds_test = get_overlapping_windows_datasets(csv_files_path, \n",
    "                                                                       forecasting, feature_endo, feature_exo, target_choice, \n",
    "                                                                       windows_size, shift_delta, stride,\n",
    "                                                                       train_test_ratio, train_valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "owf, owt = ow_ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5283, 0.3999, 0.7865, 0.6450, 0.0540, 0.0012, 0.2709],\n",
       "        [0.5283, 0.3990, 0.7865, 0.6453, 0.0540, 0.0044, 0.2698],\n",
       "        [0.5283, 0.3985, 0.7865, 0.6458, 0.0540, 0.0047, 0.2681],\n",
       "        [0.5283, 0.3987, 0.7865, 0.6455, 0.0540, 0.0044, 0.2682],\n",
       "        [0.5284, 0.3992, 0.7865, 0.6458, 0.0540, 0.0026, 0.2713],\n",
       "        [0.5284, 0.3987, 0.7865, 0.6458, 0.0540, 0.0021, 0.2750],\n",
       "        [0.5284, 0.3990, 0.7865, 0.6461, 0.0540, 0.0035, 0.2770],\n",
       "        [0.5284, 0.3997, 0.7865, 0.6463, 0.0540, 0.0033, 0.2785],\n",
       "        [0.5285, 0.4000, 0.7865, 0.6466, 0.0540, 0.0025, 0.2805],\n",
       "        [0.5285, 0.4002, 0.7865, 0.6466, 0.0540, 0.0030, 0.2810],\n",
       "        [0.5285, 0.4007, 0.7837, 0.6469, 0.0539, 0.0023, 0.2799],\n",
       "        [0.5285, 0.4011, 0.7865, 0.6469, 0.0539, 0.0036, 0.2787],\n",
       "        [0.5285, 0.4016, 0.7837, 0.6466, 0.0540, 0.0035, 0.2770],\n",
       "        [0.5286, 0.4011, 0.7837, 0.6466, 0.0540, 0.0049, 0.2755],\n",
       "        [0.5286, 0.4000, 0.7865, 0.6469, 0.0540, 0.0038, 0.2745],\n",
       "        [0.5286, 0.3987, 0.7865, 0.6469, 0.0540, 0.0027, 0.2746],\n",
       "        [0.5286, 0.3985, 0.7865, 0.6469, 0.0540, 0.0041, 0.2734],\n",
       "        [0.5287, 0.3988, 0.7865, 0.6469, 0.0540, 0.0032, 0.2720],\n",
       "        [0.5287, 0.3997, 0.7865, 0.6469, 0.0540, 0.0053, 0.2725],\n",
       "        [0.5287, 0.4000, 0.7865, 0.6469, 0.0540, 0.0038, 0.2738],\n",
       "        [0.5287, 0.3993, 0.7865, 0.6469, 0.0540, 0.0040, 0.2737],\n",
       "        [0.5288, 0.3985, 0.7837, 0.6466, 0.0540, 0.0044, 0.2716],\n",
       "        [0.5288, 0.3982, 0.7865, 0.6466, 0.0539, 0.0040, 0.2700],\n",
       "        [0.5288, 0.3977, 0.7865, 0.6469, 0.0540, 0.0018, 0.2719],\n",
       "        [0.5288, 0.3973, 0.7894, 0.6471, 0.0540, 0.0044, 0.2714],\n",
       "        [0.5288, 0.3968, 0.7894, 0.6471, 0.0540, 0.0037, 0.2712],\n",
       "        [0.5289, 0.3968, 0.7894, 0.6471, 0.0540, 0.0038, 0.2705],\n",
       "        [0.5289, 0.3968, 0.7922, 0.6469, 0.0540, 0.0043, 0.2716],\n",
       "        [0.5289, 0.3968, 0.7894, 0.6469, 0.0540, 0.0054, 0.2739],\n",
       "        [0.5289, 0.3976, 0.7922, 0.6466, 0.0540, 0.0037, 0.2768],\n",
       "        [0.5290, 0.3983, 0.7922, 0.6471, 0.0540, 0.0027, 0.2790],\n",
       "        [0.5290, 0.3993, 0.7922, 0.6477, 0.0540, 0.0044, 0.2787]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8601])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow_ds_train.features_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow_ds_train.labels_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OverlappingWindowsDataset at 0x22875b08ef0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow_ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
