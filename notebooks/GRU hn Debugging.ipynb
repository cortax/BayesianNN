{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class GatedRecurrentUnitHnNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, \n",
    "                        window_size, hidden_size, num_layers, \n",
    "                        target_type_string='Regression',\n",
    "                        bias=True, batch_first=True, \n",
    "                        bidirectional=False,\n",
    "                        dropout_hidden=0, dropout_Hn=0):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seq_len = window_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            bias=bias,\n",
    "                            batch_first=batch_first,\n",
    "                            dropout=dropout_hidden, \n",
    "                            bidirectional=bidirectional)\n",
    "        self.hn_dropout_layer = nn.Dropout(dropout_Hn)\n",
    "        self.predict_layer = nn.Linear(hidden_size * num_layers * (bidirectional + 1), output_size) #(hidden*layers*1, 1)\n",
    "        \n",
    "        self.target_type_string = target_type_string\n",
    "        if target_type_string=='Regression':\n",
    "            self.loss_function = nn.MSELoss()\n",
    "        elif target_type_string=='Classification':\n",
    "            self.loss_function = nn.CrossEntropyLoss()\n",
    "             \n",
    "    def forward(self, input):\n",
    "        print('batch:', input)\n",
    "        print(input.size())\n",
    "        #print(input[0])\n",
    "        #print(input[0][0])\n",
    "\n",
    "        gru_out, h_n = self.gru(input) #h_n shape: (num_layers * num_directions, batch, hidden_size)\n",
    "        print('h_n:', h_n)\n",
    "        print('h_n size:', h_n.size(0), h_n.size(1), h_n.size(2))\n",
    "        h_n_transpose = torch.transpose(h_n, 0, 1).contiguous() #shape: (batch, num_layers * num_directions, hidden_size)\n",
    "        print('h_n_transpose:', h_n_transpose)\n",
    "        print('h_n_transpose size:', h_n_transpose.size(0), h_n_transpose.size(1), h_n_transpose.size(2))\n",
    "        \n",
    "        h_n_view = h_n_transpose.view(input.size(0), -1) #shape: (batch, num_layers * num_directions * hidden_size)\n",
    "        print('h_n_view:', h_n_view)\n",
    "        print('h_n_view size:', h_n_view.size(0), h_n_view.size(1))\n",
    "        \n",
    "        h_n_dropout = self.hn_dropout_layer(h_n_view)\n",
    "        predict = self.predict_layer(h_n_dropout) #predict est vertical\n",
    "        #print('predict:', predict)\n",
    "        #print('predict size:', predict.size())\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1\n",
    "window_size = 2\n",
    "hidden_size = 8\n",
    "num_layers = 3\n",
    "target_type_string='Regression'\n",
    "bias=True\n",
    "batch_first=True\n",
    "bidirectional=True\n",
    "dropout_hidden=0\n",
    "dropout_Hn=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru = GatedRecurrentUnitHnNet(input_size, output_size, \n",
    "                        window_size, hidden_size, num_layers, \n",
    "                        target_type_string,\n",
    "                        bias, batch_first, \n",
    "                        bidirectional,\n",
    "                        dropout_hidden, dropout_Hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = [[[7.9018e-04, 1.2779e-01],[7.9018e-04, 1.2779e-01]],\n",
    "        [[5.9300e-04, 1.0390e-01],[5.9300e-04, 1.0390e-01]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: tensor([[[0.0008, 0.1278],\n",
      "         [0.0008, 0.1278]],\n",
      "\n",
      "        [[0.0006, 0.1039],\n",
      "         [0.0006, 0.1039]]])\n",
      "torch.Size([2, 2, 2])\n",
      "h_n: tensor([[[-0.1338,  0.0955, -0.0209, -0.0913, -0.0366, -0.1782, -0.2123,\n",
      "          -0.1955],\n",
      "         [-0.1291,  0.0997, -0.0187, -0.0849, -0.0343, -0.1804, -0.2111,\n",
      "          -0.1968]],\n",
      "\n",
      "        [[-0.0472,  0.1072,  0.1520,  0.0925,  0.0693, -0.2980, -0.1162,\n",
      "          -0.0873],\n",
      "         [-0.0481,  0.1090,  0.1542,  0.0952,  0.0638, -0.3011, -0.1202,\n",
      "          -0.0824]],\n",
      "\n",
      "        [[-0.2283,  0.1388, -0.1411, -0.0077, -0.2246,  0.0055,  0.1565,\n",
      "           0.0815],\n",
      "         [-0.2270,  0.1399, -0.1395, -0.0109, -0.2270,  0.0048,  0.1546,\n",
      "           0.0838]],\n",
      "\n",
      "        [[ 0.0263, -0.0926, -0.0592, -0.2959,  0.0132, -0.0678,  0.1275,\n",
      "          -0.1417],\n",
      "         [ 0.0268, -0.0952, -0.0589, -0.2967,  0.0140, -0.0641,  0.1273,\n",
      "          -0.1432]],\n",
      "\n",
      "        [[-0.0621, -0.2374,  0.1402, -0.0332,  0.1971,  0.0300,  0.1999,\n",
      "           0.3470],\n",
      "         [-0.0644, -0.2372,  0.1402, -0.0338,  0.1963,  0.0310,  0.1995,\n",
      "           0.3489]],\n",
      "\n",
      "        [[ 0.0593,  0.0531,  0.3917,  0.0952,  0.1625, -0.0887,  0.2237,\n",
      "           0.0670],\n",
      "         [ 0.0604,  0.0516,  0.3925,  0.0950,  0.1618, -0.0895,  0.2223,\n",
      "           0.0658]]], grad_fn=<StackBackward>)\n",
      "h_n size: 6 2 8\n",
      "h_n_transpose: tensor([[[-0.1338,  0.0955, -0.0209, -0.0913, -0.0366, -0.1782, -0.2123,\n",
      "          -0.1955],\n",
      "         [-0.0472,  0.1072,  0.1520,  0.0925,  0.0693, -0.2980, -0.1162,\n",
      "          -0.0873],\n",
      "         [-0.2283,  0.1388, -0.1411, -0.0077, -0.2246,  0.0055,  0.1565,\n",
      "           0.0815],\n",
      "         [ 0.0263, -0.0926, -0.0592, -0.2959,  0.0132, -0.0678,  0.1275,\n",
      "          -0.1417],\n",
      "         [-0.0621, -0.2374,  0.1402, -0.0332,  0.1971,  0.0300,  0.1999,\n",
      "           0.3470],\n",
      "         [ 0.0593,  0.0531,  0.3917,  0.0952,  0.1625, -0.0887,  0.2237,\n",
      "           0.0670]],\n",
      "\n",
      "        [[-0.1291,  0.0997, -0.0187, -0.0849, -0.0343, -0.1804, -0.2111,\n",
      "          -0.1968],\n",
      "         [-0.0481,  0.1090,  0.1542,  0.0952,  0.0638, -0.3011, -0.1202,\n",
      "          -0.0824],\n",
      "         [-0.2270,  0.1399, -0.1395, -0.0109, -0.2270,  0.0048,  0.1546,\n",
      "           0.0838],\n",
      "         [ 0.0268, -0.0952, -0.0589, -0.2967,  0.0140, -0.0641,  0.1273,\n",
      "          -0.1432],\n",
      "         [-0.0644, -0.2372,  0.1402, -0.0338,  0.1963,  0.0310,  0.1995,\n",
      "           0.3489],\n",
      "         [ 0.0604,  0.0516,  0.3925,  0.0950,  0.1618, -0.0895,  0.2223,\n",
      "           0.0658]]], grad_fn=<CloneBackward>)\n",
      "h_n_transpose size: 2 6 8\n",
      "h_n_view: tensor([[-0.1338,  0.0955, -0.0209, -0.0913, -0.0366, -0.1782, -0.2123, -0.1955,\n",
      "         -0.0472,  0.1072,  0.1520,  0.0925,  0.0693, -0.2980, -0.1162, -0.0873,\n",
      "         -0.2283,  0.1388, -0.1411, -0.0077, -0.2246,  0.0055,  0.1565,  0.0815,\n",
      "          0.0263, -0.0926, -0.0592, -0.2959,  0.0132, -0.0678,  0.1275, -0.1417,\n",
      "         -0.0621, -0.2374,  0.1402, -0.0332,  0.1971,  0.0300,  0.1999,  0.3470,\n",
      "          0.0593,  0.0531,  0.3917,  0.0952,  0.1625, -0.0887,  0.2237,  0.0670],\n",
      "        [-0.1291,  0.0997, -0.0187, -0.0849, -0.0343, -0.1804, -0.2111, -0.1968,\n",
      "         -0.0481,  0.1090,  0.1542,  0.0952,  0.0638, -0.3011, -0.1202, -0.0824,\n",
      "         -0.2270,  0.1399, -0.1395, -0.0109, -0.2270,  0.0048,  0.1546,  0.0838,\n",
      "          0.0268, -0.0952, -0.0589, -0.2967,  0.0140, -0.0641,  0.1273, -0.1432,\n",
      "         -0.0644, -0.2372,  0.1402, -0.0338,  0.1963,  0.0310,  0.1995,  0.3489,\n",
      "          0.0604,  0.0516,  0.3925,  0.0950,  0.1618, -0.0895,  0.2223,  0.0658]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "h_n_view size: 2 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0327],\n",
       "        [-0.0320]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru(torch.Tensor(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.Tensor([[1,2,3,4,5], [6,7,8,9,10]])\n",
    "d2 = torch.Tensor([[11,12,13,14,15], [16,17,18,19,20]])\n",
    "d1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19., 20.]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = torch.cat((d1, d2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5., 11., 12., 13., 14., 15.],\n",
       "        [ 6.,  7.,  8.,  9., 10., 16., 17., 18., 19., 20.]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
