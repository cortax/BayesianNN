{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ne pas oublier d'ajuster le code dépendamment de si les targets sont placés au début ou à la fin du fichier. Aussi, changer le délimiteur au besoin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de commande: make_datasets('redwine', 0.9, StandardScaler(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(txt, size_train):\n",
    "\n",
    "#    data = np.loadtxt(txt + '/' + txt + '.txt')\n",
    "    data = np.genfromtxt(txt + '/' + txt + '.csv', delimiter=';')\n",
    "    \n",
    "    # Les targets sont à la fin. \n",
    "    X = data[:, range(data.shape[1] - 1) ]\n",
    "    y = data[:, data.shape[1] - 1]\n",
    "    \n",
    "    # Les targets sont au début. \n",
    "#    X = data[:, 0:]\n",
    "#    y = data[:, 0]\n",
    "\n",
    "\n",
    "    size_train = np.round(X.shape[0] * size_train)\n",
    "    permutation = np.random.choice(range (X.shape[0]), X.shape[0], replace = False)\n",
    "    index_train = permutation[0 : int(size_train)]\n",
    "    index_test = permutation[int(size_train) : ]\n",
    "\n",
    "    X_train = X[index_train, :]\n",
    "    y_train = y[index_train]\n",
    "    X_test = X[index_test, :]\n",
    "    y_test = y[index_test]\n",
    "\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train).unsqueeze(-1)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_test = torch.from_numpy(y_test).unsqueeze(-1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(txt, size_train, scaler):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_data(txt, size_train)\n",
    "    \n",
    "    scaler_X = scaler\n",
    "    scaler_y = scaler\n",
    "    inverse_scaler_y = scaler_y.inverse_transform\n",
    "\n",
    "    X_train = torch.as_tensor(scaler_X.fit_transform(X_train)).float()\n",
    "    y_train = torch.as_tensor(scaler_y.fit_transform(y_train)).float()\n",
    "    \n",
    "    X_test = torch.as_tensor(scaler_X.transform(X_test)).float()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test.float(), inverse_scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(txt, size_train, scaler, n_splits):    \n",
    "    \n",
    "    for i in range(0, n_splits):\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = load_data(txt, size_train)\n",
    "        \n",
    "        torch.save(X_train, txt + '/data/' + txt + '_X_train_(' + str(i) + ').pt')\n",
    "        torch.save(y_train, txt + '/data/' + txt + '_y_train_(' + str(i) + ').pt')\n",
    "        torch.save(X_test, txt + '/data/' + txt + '_X_test_(' + str(i) + ').pt')\n",
    "        torch.save(y_test, txt + '/data/' + txt + '_y_test_(' + str(i) + ').pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
