{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ne pas oublier d'ajuster le code dépendamment de si les targets sont placés au début ou à la fin du fichier. Aussi, changer le délimiteur au besoin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de commande: make_datasets('redwine', 0.9, StandardScaler(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1030, 8), (1030,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(txt):\n",
    "\n",
    "#    data = np.loadtxt(txt + '/' + txt + '.txt')\n",
    "    data = np.genfromtxt(txt + '/' + txt + '.csv', delimiter=',')\n",
    "\n",
    "    # Les targets sont à la fin. \n",
    "    X = data[:, range(data.shape[1] - 1) ]\n",
    "    y = data[:, data.shape[1] - 1]\n",
    "    \n",
    "    # Les targets sont au début. \n",
    "#    X = data[:, 0:]\n",
    "#    y = data[:, 0]\n",
    "    data=X,y\n",
    "    torch.save(data, txt + '/data.pt' )\n",
    "    return data\n",
    "\n",
    "X,y=load_data('concrete')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1030, 8]), torch.Size([1030]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-52537e3c6f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mboston\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSetup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mboston\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BayesianNN/Experiments/boston/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mExperiments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractRegressionSetup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Experiments'"
     ]
    }
   ],
   "source": [
    "from boston import Setup\n",
    "boston=Setup(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(txt, size_train):\n",
    "\n",
    "#    data = np.loadtxt(txt + '/' + txt + '.txt')\n",
    "    data = np.genfromtxt(txt + '/' + txt + '.csv', delimiter=';')\n",
    "    \n",
    "    # Les targets sont à la fin. \n",
    "    X = data[:, range(data.shape[1] - 1) ]\n",
    "    y = data[:, data.shape[1] - 1]\n",
    "    \n",
    "    # Les targets sont au début. \n",
    "#    X = data[:, 0:]\n",
    "#    y = data[:, 0]\n",
    "\n",
    "\n",
    "    size_train = np.round(X.shape[0] * size_train)\n",
    "    permutation = np.random.choice(range (X.shape[0]), X.shape[0], replace = False)\n",
    "    index_train = permutation[0 : int(size_train)]\n",
    "    index_test = permutation[int(size_train) : ]\n",
    "\n",
    "    X_train = X[index_train, :]\n",
    "    y_train = y[index_train]\n",
    "    X_test = X[index_test, :]\n",
    "    y_test = y[index_test]\n",
    "\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train).unsqueeze(-1)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_test = torch.from_numpy(y_test).unsqueeze(-1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(txt, size_train, scaler):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_data(txt, size_train)\n",
    "    \n",
    "    scaler_X = scaler\n",
    "    scaler_y = scaler\n",
    "    inverse_scaler_y = scaler_y.inverse_transform\n",
    "\n",
    "    X_train = torch.as_tensor(scaler_X.fit_transform(X_train)).float()\n",
    "    y_train = torch.as_tensor(scaler_y.fit_transform(y_train)).float()\n",
    "    \n",
    "    X_test = torch.as_tensor(scaler_X.transform(X_test)).float()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test.float(), inverse_scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(txt, size_train, scaler, n_splits):    \n",
    "    \n",
    "    for i in range(0, n_splits):\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = load_data(txt, size_train)\n",
    "        \n",
    "        torch.save(X_train, txt + '/data/' + txt + '_X_train_(' + str(i) + ').pt')\n",
    "        torch.save(y_train, txt + '/data/' + txt + '_y_train_(' + str(i) + ').pt')\n",
    "        torch.save(X_test, txt + '/data/' + txt + '_X_test_(' + str(i) + ').pt')\n",
    "        torch.save(y_test, txt + '/data/' + txt + '_y_test_(' + str(i) + ').pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
